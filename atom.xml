<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Leilei&#39;s Blog | 磊磊的博客</title>
  
  <subtitle>Because it&#39;s there</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.llchen60.com/"/>
  <updated>2020-10-06T22:55:54.435Z</updated>
  <id>https://www.llchen60.com/</id>
  
  <author>
    <name>Leilei Chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>缓存的常见问题</title>
    <link href="https://www.llchen60.com/%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>https://www.llchen60.com/%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</id>
    <published>2020-10-06T22:55:09.000Z</published>
    <updated>2020-10-06T22:55:54.435Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-缓存雪崩"><a href="#1-缓存雪崩" class="headerlink" title="1. 缓存雪崩"></a>1. 缓存雪崩</h1><p>缓存系统的IOPS比数据库高很多，因此需要注意短时间内的大量缓存失效的情况。这种情况一旦发生，可能就会在瞬间有大量的数据需要回源到数据库查询，对数据库造成极大的压力，极限情况下甚至导致后端数据库直接崩溃。这就是我们说的缓存雪崩。</p><p>产生雪崩的原因有两种：</p><ul><li>缓存系统本身不可用，导致大量请求直接回源到数据库</li><li>应用设计层面大量的Key在同一时间过期，导致大量的数据回源<ul><li>解决方法<ul><li>差异化缓存过期时间<ul><li>不让大量的Key在同一时间过期</li><li>初始化缓存的时候，设置缓存的过期时间为30秒 + 10秒以内的随机延迟（扰动值）。这样key就不会集中在30秒这个时刻过期，而是会分散在30 - 40秒之间</li></ul></li><li>让缓存不主动过期<ul><li>初始化缓存数据的时候设置缓存永不过期，然后启动一个后台线程30秒一次定时将所有数据更新到缓存，通过适当的休眠，控制从数据库更新数据的频率，降低数据库的压力</li><li>如果无法全量缓存所有的数据，那么就无法使用该种方案</li></ul></li></ul></li></ul></li></ul><pre><code>// 差异化缓存过期时间@PostConstructpublic void rightInit1() {    //这次缓存的过期时间是30秒+10秒内的随机延迟    IntStream.rangeClosed(1, 1000).forEach(i -&gt; stringRedisTemplate.opsForValue().set(&quot;city&quot; + i, getCityFromDb(i), 30 + ThreadLocalRandom.current().nextInt(10), TimeUnit.SECONDS));    log.info(&quot;Cache init finished&quot;);    //同样1秒一次输出数据库QPS：   Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&gt; {        log.info(&quot;DB QPS : {}&quot;, atomicInteger.getAndSet(0));    }, 0, 1, TimeUnit.SECONDS);}// 让缓存不主动过期@PostConstructpublic void rightInit2() throws InterruptedException {    CountDownLatch countDownLatch = new CountDownLatch(1);    //每隔30秒全量更新一次缓存     Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&gt; {        IntStream.rangeClosed(1, 1000).forEach(i -&gt; {            String data = getCityFromDb(i);            //模拟更新缓存需要一定的时间            try {                TimeUnit.MILLISECONDS.sleep(20);            } catch (InterruptedException e) { }            if (!StringUtils.isEmpty(data)) {                //缓存永不过期，被动更新                stringRedisTemplate.opsForValue().set(&quot;city&quot; + i, data);            }        });        log.info(&quot;Cache update finished&quot;);        //启动程序的时候需要等待首次更新缓存完成        countDownLatch.countDown();    }, 0, 30, TimeUnit.SECONDS);    Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&gt; {        log.info(&quot;DB QPS : {}&quot;, atomicInteger.getAndSet(0));    }, 0, 1, TimeUnit.SECONDS);    countDownLatch.await();}</code></pre><h1 id="2-缓存击穿"><a href="#2-缓存击穿" class="headerlink" title="2. 缓存击穿"></a>2. 缓存击穿</h1><p>在某些Key属于极端热点数据并且并发量很大的情况下，如果这个Key过期，可能会在某个瞬间出现大量的并发请求同时回源，相当于大量的并发请求直接打到了数据库。这就是我们所说的缓存击穿或缓存并发问题。</p><p>如果说回源操作比较昂贵的话，那么这种并发就不能忽略不计了。可以考虑使用锁机制来限制回源的并发，或者可以使用类似Semaphore的工具来限制并发数，比如限制为10.这样子既限制了回源并发数不至于太大，又能够使得一定量的线程可以同时回源。</p><h1 id="3-缓存穿透"><a href="#3-缓存穿透" class="headerlink" title="3. 缓存穿透"></a>3. 缓存穿透</h1><p>缓存穿透指的是实际上缓存里有key 和value，但是其value可能为空，如果没做正确处理，那我们的逻辑可能会认为没有对当前的key做好缓存，会对所有的请求都回源到数据库上，这就会给数据库造成压力了。</p><p>针对这种问题，可以用以下方案解决：</p><ul><li><p>对于不存在的数据，同样设置一个特殊的Value到缓存当中，比如NODATA，这样子就不会有缓存穿透的问题</p><ul><li>可能会将大量无效的数据加入到缓存当中</li></ul></li><li><p>使用布隆过滤器</p><ul><li>放在缓存数据读取前先进行过滤操作</li><li>Google Guava BloomFilter </li></ul></li></ul><pre><code>private BloomFilter&lt;Integer&gt; bloomFilter;@PostConstructpublic void init() {    //创建布隆过滤器，元素数量10000，期望误判率1%    bloomFilter = BloomFilter.create(Funnels.integerFunnel(), 10000, 0.01);    //填充布隆过滤器    IntStream.rangeClosed(1, 10000).forEach(bloomFilter::put);}@GetMapping(&quot;right2&quot;)public String right2(@RequestParam(&quot;id&quot;) int id) {    String data = &quot;&quot;;    //通过布隆过滤器先判断    if (bloomFilter.mightContain(id)) {        String key = &quot;user&quot; + id;        //走缓存查询        data = stringRedisTemplate.opsForValue().get(key);        if (StringUtils.isEmpty(data)) {            //走数据库查询            data = getCityFromDb(id);            stringRedisTemplate.opsForValue().set(key, data, 30, TimeUnit.SECONDS);        }    }    return data;}</code></pre><h1 id="4-缓存数据同步策略"><a href="#4-缓存数据同步策略" class="headerlink" title="4. 缓存数据同步策略"></a>4. 缓存数据同步策略</h1><ul><li>当原始数据被修改了以后，我们很可能会采用主动更新缓存的策略<ul><li>可能的策略有<ul><li>先更新缓存，再更新数据库<ul><li>不可行</li><li>数据库操作失败是有可能的，会导致缓存和数据库当中的数据不一致</li></ul></li><li>先更新数据库，再更新缓存<ul><li>不可行</li><li>多线程情况下数据库中更新的顺序和缓存更新的顺序会不同，可能会导致旧数据最后到，导致问题的出现</li></ul></li><li>先删除缓存，再更新数据库，访问的时候按需加载数据到缓存当中<ul><li>很可能删除缓存以后还没来得及更新数据库，就有另外一个线程先读取了旧值到缓存中</li></ul></li><li>先更新数据库，再删除缓存，访问的时候按需加载数据到缓存当中<ul><li>出现缓存不一致的概率很低</li></ul></li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-缓存雪崩&quot;&gt;&lt;a href=&quot;#1-缓存雪崩&quot; class=&quot;headerlink&quot; title=&quot;1. 缓存雪崩&quot;&gt;&lt;/a&gt;1. 缓存雪崩&lt;/h1&gt;&lt;p&gt;缓存系统的IOPS比数据库高很多，因此需要注意短时间内的大量缓存失效的情况。这种情况一旦发生，可能就会在
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
  </entry>
  
  <entry>
    <title>利用注解 + 反射消除重复代码</title>
    <link href="https://www.llchen60.com/%E5%88%A9%E7%94%A8%E6%B3%A8%E8%A7%A3-%E5%8F%8D%E5%B0%84%E6%B6%88%E9%99%A4%E9%87%8D%E5%A4%8D%E4%BB%A3%E7%A0%81/"/>
    <id>https://www.llchen60.com/%E5%88%A9%E7%94%A8%E6%B3%A8%E8%A7%A3-%E5%8F%8D%E5%B0%84%E6%B6%88%E9%99%A4%E9%87%8D%E5%A4%8D%E4%BB%A3%E7%A0%81/</id>
    <published>2020-10-04T00:37:32.000Z</published>
    <updated>2020-10-04T00:38:18.211Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-案例分析"><a href="#1-案例分析" class="headerlink" title="1. 案例分析"></a>1. 案例分析</h1><h2 id="1-1-案例场景"><a href="#1-1-案例场景" class="headerlink" title="1.1 案例场景"></a>1.1 案例场景</h2><p>假设银行提供了一些 API 接口，对参数的序列化有点特殊，不使用 JSON，而是需要我们把参数依次拼在一起构成一个大字符串</p><ul><li>按照银行提供的API文档顺序，将所有的参数构成定长的数据，并且拼接在一起作为一整个字符串</li><li>因为每一种参数都有固定长度，未达到长度需要进行填充处理<ul><li>字符串类型参数不满长度部分要以下划线右填充，即字符串内容靠左</li><li>数字类型的参数不满长度部分以0左填充，即实际数字靠右</li><li>货币类型的表示需要把金额向下舍入2位到分，以分为单位，作为数字类型同样进行左填充</li><li>参数做MD5 操作作为签名</li></ul></li></ul><h2 id="1-2-初步代码实现"><a href="#1-2-初步代码实现" class="headerlink" title="1.2 初步代码实现"></a>1.2 初步代码实现</h2><pre><code>public class BankService {    //创建用户方法    public static String createUser(String name, String identity, String mobile, int age) throws IOException {        StringBuilder stringBuilder = new StringBuilder();        //字符串靠左，多余的地方填充_        stringBuilder.append(String.format(&quot;%-10s&quot;, name).replace(&#39; &#39;, &#39;_&#39;));        //字符串靠左，多余的地方填充_        stringBuilder.append(String.format(&quot;%-18s&quot;, identity).replace(&#39; &#39;, &#39;_&#39;));        //数字靠右，多余的地方用0填充        stringBuilder.append(String.format(&quot;%05d&quot;, age));        //字符串靠左，多余的地方用_填充        stringBuilder.append(String.format(&quot;%-11s&quot;, mobile).replace(&#39; &#39;, &#39;_&#39;));        //最后加上MD5作为签名        stringBuilder.append(DigestUtils.md2Hex(stringBuilder.toString()));        return Request.Post(&quot;http://localhost:45678/reflection/bank/createUser&quot;)                .bodyString(stringBuilder.toString(), ContentType.APPLICATION_JSON)                .execute().returnContent().asString();    }    //支付方法    public static String pay(long userId, BigDecimal amount) throws IOException {        StringBuilder stringBuilder = new StringBuilder();        //数字靠右，多余的地方用0填充        stringBuilder.append(String.format(&quot;%020d&quot;, userId));        //金额向下舍入2位到分，以分为单位，作为数字靠右，多余的地方用0填充        stringBuilder.append(String.format(&quot;%010d&quot;, amount.setScale(2, RoundingMode.DOWN).multiply(new BigDecimal(&quot;100&quot;)).longValue()));        //最后加上MD5作为签名        stringBuilder.append(DigestUtils.md2Hex(stringBuilder.toString()));        return Request.Post(&quot;http://localhost:45678/reflection/bank/pay&quot;)                .bodyString(stringBuilder.toString(), ContentType.APPLICATION_JSON)                .execute().returnContent().asString();    }}</code></pre><ul><li>这样做能够基本满足需求，但是存在一些问题：<ul><li>处理逻辑互相之间有重复，稍有不慎就会出现Bug</li><li>处理流程中字符串拼接、加签和发请求的逻辑，在所有方法重复</li><li>实际方法的入参的参数类型和顺序，不一定和接口要求一致，容易出错</li><li>代码层面参数硬编码，无法清晰进行核对</li></ul></li></ul><h2 id="1-3-使用接口和反射优化代码"><a href="#1-3-使用接口和反射优化代码" class="headerlink" title="1.3 使用接口和反射优化代码"></a>1.3 使用接口和反射优化代码</h2><h3 id="1-3-1-实现定义了所有接口参数的POJO类"><a href="#1-3-1-实现定义了所有接口参数的POJO类" class="headerlink" title="1.3.1 实现定义了所有接口参数的POJO类"></a>1.3.1 实现定义了所有接口参数的POJO类</h3><pre><code>@Datapublic class CreateUserAPI {    private String name;    private String identity;    private String mobile;    private int age;}</code></pre><h3 id="1-3-2-定义注解本身"><a href="#1-3-2-定义注解本身" class="headerlink" title="1.3.2 定义注解本身"></a>1.3.2 定义注解本身</h3><pre><code>@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Inheritedpublic @interface BankAPI {    String desc() default &quot;&quot;;    String url() default &quot;&quot;;}@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)@Documented@Inheritedpublic @interface BankAPIField {    int order() default -1;    int length() default -1;    String type() default &quot;&quot;;}</code></pre><h3 id="1-3-3-反射配合注解实现动态的接口参数组装"><a href="#1-3-3-反射配合注解实现动态的接口参数组装" class="headerlink" title="1.3.3 反射配合注解实现动态的接口参数组装"></a>1.3.3 反射配合注解实现动态的接口参数组装</h3><pre><code>private static String remoteCall(AbstractAPI api) throws IOException {    //从BankAPI注解获取请求地址    BankAPI bankAPI = api.getClass().getAnnotation(BankAPI.class);    bankAPI.url();    StringBuilder stringBuilder = new StringBuilder();    Arrays.stream(api.getClass().getDeclaredFields()) //获得所有字段            .filter(field -&gt; field.isAnnotationPresent(BankAPIField.class)) //查找标记了注解的字段            .sorted(Comparator.comparingInt(a -&gt; a.getAnnotation(BankAPIField.class).order())) //根据注解中的order对字段排序            .peek(field -&gt; field.setAccessible(true)) //设置可以访问私有字段            .forEach(field -&gt; {                //获得注解                BankAPIField bankAPIField = field.getAnnotation(BankAPIField.class);                Object value = &quot;&quot;;                try {                    //反射获取字段值                    value = field.get(api);                } catch (IllegalAccessException e) {                    e.printStackTrace();                }                //根据字段类型以正确的填充方式格式化字符串                switch (bankAPIField.type()) {                    case &quot;S&quot;: {                        stringBuilder.append(String.format(&quot;%-&quot; + bankAPIField.length() + &quot;s&quot;, value.toString()).replace(&#39; &#39;, &#39;_&#39;));                        break;                    }                    case &quot;N&quot;: {                        stringBuilder.append(String.format(&quot;%&quot; + bankAPIField.length() + &quot;s&quot;, value.toString()).replace(&#39; &#39;, &#39;0&#39;));                        break;                    }                    case &quot;M&quot;: {                        if (!(value instanceof BigDecimal))                            throw new RuntimeException(String.format(&quot;{} 的 {} 必须是BigDecimal&quot;, api, field));                        stringBuilder.append(String.format(&quot;%0&quot; + bankAPIField.length() + &quot;d&quot;, ((BigDecimal) value).setScale(2, RoundingMode.DOWN).multiply(new BigDecimal(&quot;100&quot;)).longValue()));                        break;                    }                    default:                        break;                }            });    //签名逻辑   stringBuilder.append(DigestUtils.md2Hex(stringBuilder.toString()));    String param = stringBuilder.toString();    long begin = System.currentTimeMillis();    //发请求    String result = Request.Post(&quot;http://localhost:45678/reflection&quot; + bankAPI.url())            .bodyString(param, ContentType.APPLICATION_JSON)            .execute().returnContent().asString();    log.info(&quot;调用银行API {} url:{} 参数:{} 耗时:{}ms&quot;, bankAPI.desc(), bankAPI.url(), param, System.currentTimeMillis() - begin);    return result;}</code></pre><p>通过反射来动态获得class的信息，并在runtime的时候完成组装过程。这样做的好处是开发的时候会方便直观很多，然后将逻辑与细节隐藏起来，并且集中放到了一个方法当中，减少了重复，以及维护当中bug的出现。</p><h3 id="1-3-4-在代码中的应用"><a href="#1-3-4-在代码中的应用" class="headerlink" title="1.3.4 在代码中的应用"></a>1.3.4 在代码中的应用</h3><pre><code>@BankAPI(url = &quot;/bank/createUser&quot;, desc = &quot;创建用户接口&quot;)@Datapublic class CreateUserAPI extends AbstractAPI {    @BankAPIField(order = 1, type = &quot;S&quot;, length = 10)    private String name;    @BankAPIField(order = 2, type = &quot;S&quot;, length = 18)    private String identity;    @BankAPIField(order = 4, type = &quot;S&quot;, length = 11) //注意这里的order需要按照API表格中的顺序    private String mobile;    @BankAPIField(order = 3, type = &quot;N&quot;, length = 5)    private int age;}@BankAPI(url = &quot;/bank/pay&quot;, desc = &quot;支付接口&quot;)@Datapublic class PayAPI extends AbstractAPI {    @BankAPIField(order = 1, type = &quot;N&quot;, length = 20)    private long userId;    @BankAPIField(order = 2, type = &quot;M&quot;, length = 10)    private BigDecimal amount;}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-案例分析&quot;&gt;&lt;a href=&quot;#1-案例分析&quot; class=&quot;headerlink&quot; title=&quot;1. 案例分析&quot;&gt;&lt;/a&gt;1. 案例分析&lt;/h1&gt;&lt;h2 id=&quot;1-1-案例场景&quot;&gt;&lt;a href=&quot;#1-1-案例场景&quot; class=&quot;headerlink
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Java" scheme="https://www.llchen60.com/tags/Java/"/>
    
      <category term="Annotations" scheme="https://www.llchen60.com/tags/Annotations/"/>
    
      <category term="Reflection" scheme="https://www.llchen60.com/tags/Reflection/"/>
    
      <category term="注解" scheme="https://www.llchen60.com/tags/%E6%B3%A8%E8%A7%A3/"/>
    
      <category term="反射" scheme="https://www.llchen60.com/tags/%E5%8F%8D%E5%B0%84/"/>
    
  </entry>
  
  <entry>
    <title>Spring IoC, AOP浅析</title>
    <link href="https://www.llchen60.com/Spring-IoC-AOP%E6%B5%85%E6%9E%90/"/>
    <id>https://www.llchen60.com/Spring-IoC-AOP%E6%B5%85%E6%9E%90/</id>
    <published>2020-10-02T02:43:05.000Z</published>
    <updated>2020-10-02T02:43:41.325Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-IoC"><a href="#1-IoC" class="headerlink" title="1. IoC"></a>1. IoC</h1><h2 id="1-1-Overview"><a href="#1-1-Overview" class="headerlink" title="1.1 Overview"></a>1.1 Overview</h2><ul><li><p>Inversion of control </p><ul><li>控制反转</li><li>将设计好的对象交给Spring容器来控制，而不是在对象内部控制</li></ul></li><li><p>好处</p><ul><li>可以无侵入的调整对象的关系</li><li>同时可以无侵入的调整对象的属性，甚至实现对象的替换</li></ul></li></ul><h2 id="1-2-单例Bean注入Prototype的Bean"><a href="#1-2-单例Bean注入Prototype的Bean" class="headerlink" title="1.2 单例Bean注入Prototype的Bean"></a>1.2 单例Bean注入Prototype的Bean</h2><p>Spring创建的Bean默认是单例的，但是当Bean遇到继承的时候，是会忽略这一点的。</p><pre><code>@Slf4jpublic abstract class SayService {    List&lt;String&gt; data = new ArrayList&lt;&gt;();    public void say() {        data.add(IntStream.rangeClosed(1, 1000000)                .mapToObj(__ -&gt; &quot;a&quot;)                .collect(Collectors.joining(&quot;&quot;)) + UUID.randomUUID().toString());        log.info(&quot;I&#39;m {} size:{}&quot;, this, data.size());    }}@Service@Slf4jpublic class SayHello extends SayService {    @Override    public void say() {        super.say();        log.info(&quot;hello&quot;);    }}@Service@Slf4jpublic class SayBye extends SayService {    @Override    public void say() {        super.say();        log.info(&quot;bye&quot;);    }}</code></pre><p>上述代码中，基类SayService是有状态的，dataList一直在增加。当SayHello类继承基类，并且声明为Service的时候，将其注册为Bean。这时候有状态的基类就很有可能造成内存泄露或者线程安全的问题了。</p><p>正确做法是在将类标记为<code>@Service</code>并交给容器进行管理之前，需要首先评估一下类是否有状态，然后为Bean设置合适的Scope。</p><pre><code>@Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE, proxyMode = ScopedProxyMode.TARGET_CLASS)</code></pre><p>让其以代理的方式注入，这样虽然controller还是单例的，但是每次都从代理那里获得Service，这样prototype范围的配置才会真正生效。</p><h1 id="2-AOP"><a href="#2-AOP" class="headerlink" title="2. AOP"></a>2. AOP</h1><ul><li><p>体现了松耦合，高内聚</p></li><li><p>在切面集中实现横切关注点</p><ul><li>缓存</li><li>权限</li><li>日志</li></ul></li><li><p>然后通过切点配置将代码注入到合适的地方</p></li><li><p>关键点</p><ul><li><p>连接点 Join Point </p><ul><li>实现AOP的地方</li><li>方法执行</li></ul></li><li><p>切点 PointCut</p><ul><li>告诉程序在哪里做切入</li><li>Spring中默认使用AspectJ查询表达式，通过在连接点运行查询表达式来匹配切入点</li></ul></li><li><p>增强 Advice</p><ul><li>定义了切入切点后增强的方式<ul><li>前</li><li>后</li><li>环绕</li></ul></li></ul></li><li><p>切面 Aspect</p><ul><li>切面 = 切点 + 增强 </li><li>实现整个AOP操作</li></ul></li></ul></li></ul><h2 id="2-1-实现整个日志记录，异常处理，方法耗时的统一切面"><a href="#2-1-实现整个日志记录，异常处理，方法耗时的统一切面" class="headerlink" title="2.1 实现整个日志记录，异常处理，方法耗时的统一切面"></a>2.1 实现整个日志记录，异常处理，方法耗时的统一切面</h2><pre><code>// 定义一个自定义注解Metrics @Retention(RetentionPolicy.RUNTIME)@Target({ElementType.METHOD, ElementType.TYPE})public @interface Metrics {    /**     * 在方法成功执行后打点，记录方法的执行时间发送到指标系统，默认开启     *     * @return     */    boolean recordSuccessMetrics() default true;    /**     * 在方法成功失败后打点，记录方法的执行时间发送到指标系统，默认开启     *     * @return     */    boolean recordFailMetrics() default true;    /**     * 通过日志记录请求参数，默认开启     *     * @return     */    boolean logParameters() default true;    /**     * 通过日志记录方法返回值，默认开启     *     * @return     */    boolean logReturn() default true;    /**     * 出现异常后通过日志记录异常信息，默认开启     *     * @return     */    boolean logException() default true;    /**     * 出现异常后忽略异常返回默认值，默认关闭     *     * @return     */    boolean ignoreException() default false;}</code></pre><pre><code>// 实现一个切面完成Metrics注解提供的功能@Aspect@Component@Slf4jpublic class MetricsAspect {    @Autowired    private ObjectMapper ObjectMapper;    //实现一个返回Java基本类型默认值的工具。其实，你也可以逐一写很多if-else判断类型，然后手动设置其默认值。    //这里为了减少代码量用了一个小技巧，即通过初始化一个具有1个元素的数组，然后通过获取这个数组的值来获取基本类型默认值     //Array.newInstance(Class&lt;?&gt; componentType, int length) 创建一个有特定的类的类型和长度的对象    private static final Map&lt;Class&lt;?&gt;, Object&gt; DEFAULT_VALUES =         Stream.of(boolean.class, byte.class, char.class, double.class, float.class, int.class, long.class, short.class)             .collect(toMap(clazz -&gt; (Class) clazz, clazz -&gt; Array.get(Array.newInstance(clazz, 1), 0)));     public static T getDefaultValue(Class clazz) {         return (T) DEFAULT_VALUES.get(clazz);     }    // 实现了对标记了Metrics注解的方法进行匹配    @PointCut(&quot;within(@org.cleilei.commonmistakes.springpart1.aopmetrics.Metrics *)&quot;)    public void withMetricsAnnotation() {    }    // 实现了匹配类型上标记了@RestController注解的方法    @PointCut(&quot;within(@org.springframework.web.bind.annotation.RestController *)&quot;)    public void controllerBean() {    }    @Around(&quot;controllerBean() || withMetricsAnnotation()&quot;)    public Object metrics(ProceedingJoinPoint pjp) throws Throwable {        // 通过连接点获取方法签名和方法上Metrics的注解，并根据方法签名生成日志中要输出的方法定义描述        MethodSignature signature = (MethodSignature)pjp.getSignature();        Metrics metrics = signature.getMethod().getAnnotation(Metrics.class);        String name = String.format(&quot;%s %s&quot;, signature.getDeclaringType().toString(), signature.toLongString());        if (metrics == null) {            @Metrics            final class c {}             metrics = c.class.getAnnotation(Metrics.class);        }        // 尝试从上下文获取请求的URL，来方便定位问题        RequestAttributes RequestAttributes = RequestContextHolder.getRequestAttributes();        if (requestAttributes != null) {            HttpServletRequest request = ((ServletRequestAttributes) requestAttributes).getRequest();            if (request != null) {                name += String.format(&quot; %s &quot;, request.getRequestURL().toString());            }        }        // 记录参数        if (metrics.logParameters()) {            log.info(String.format(&quot;Call method %s with parameters %s&quot;, name. objectMapper.writeValueAsString(pjp.getArgs())));        }        // 记录方法的执行，break points, 异常时记录        Object returnValue;        Instant start = Instant.now();        try {            returnValue = pjp.proceed();            if (metrics.recordSuccessMetrics())                //在生产级代码中，我们应考虑使用类似Micrometer的指标框架，把打点信息记录到时间序列数据库中，实现通过图表来查看方法的调用次数和执行时间                log.info(String.format(&quot;Call method %s succeed，time used：%d ms&quot;, name, Duration.between(start, Instant.now()).toMillis()));        } catch (Exception ex) {            if (metrics.recordFailMetrics())                log.info(String.format(&quot;Call method %s fail，time used：%d ms&quot;, name, Duration.between(start, Instant.now()).toMillis()));            if (metrics.logException())                log.error(String.format(&quot;Call method %s with exceptions&quot;, name), ex);            //忽略异常的时候，使用一开始定义的getDefaultValue方法，来获取基本类型的默认值            if (metrics.ignoreException())                returnValue = getDefaultValue(signature.getReturnType());            else                throw ex;        }        //实现了返回值的日志输出        if (metrics.logReturn())            log.info(String.format(&quot;Call method %s with result: %s&quot;, name, returnValue));        return returnValue;    }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-IoC&quot;&gt;&lt;a href=&quot;#1-IoC&quot; class=&quot;headerlink&quot; title=&quot;1. IoC&quot;&gt;&lt;/a&gt;1. IoC&lt;/h1&gt;&lt;h2 id=&quot;1-1-Overview&quot;&gt;&lt;a href=&quot;#1-1-Overview&quot; class=&quot;header
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Spring" scheme="https://www.llchen60.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>Java8 日期时间类</title>
    <link href="https://www.llchen60.com/Java8-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E7%B1%BB/"/>
    <id>https://www.llchen60.com/Java8-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E7%B1%BB/</id>
    <published>2020-09-28T21:20:22.000Z</published>
    <updated>2020-09-28T21:20:43.184Z</updated>
    
    <content type="html"><![CDATA[<p>在Java8之前，处理日期时间需求的时候需要使用Data, Calendar, SimpleDateFormat来声明时间戳，使用日历处理日期和格式化解析日期时间，Java8之后有了新的日期时间类，定义的比原来要清晰很多，且支持线程安全。</p><p>这篇文章看看时间错乱问题背后的原因，看看使用遗留的日期时间类，来处理日期时间初始化，格式化，解析，计算等可能会遇到的问题，以及如何使用新日期时间类来解决。</p><h1 id="初始化日期时间"><a href="#初始化日期时间" class="headerlink" title="初始化日期时间"></a>初始化日期时间</h1><h2 id="使用Date初始化日期时间"><a href="#使用Date初始化日期时间" class="headerlink" title="使用Date初始化日期时间"></a>使用Date初始化日期时间</h2><pre><code>Date date = new Date(2019, 12, 31, 11, 12, 13);System.out.println(date);// Output Sat Jan 31 11:12:13 CST 3920</code></pre><p>这是因为Date初始化时间的时候是用的和1970的差值，月的值是从0- 11 的</p><p>我们可以使用Calendar来定义时区的信息 </p><h1 id="时区问题"><a href="#时区问题" class="headerlink" title="时区问题"></a>时区问题</h1><pre><code>Calendar calendar = Calendar.getInstance();calendar.set(2019, 11, 31, 11, 12, 13);System.out.println(calendar.getTime());Calendar calendar2 = Calendar.getInstance(TimeZone.getTimeZone(&quot;America/New_York&quot;));calendar2.set(2019, Calendar.DECEMBER, 31, 11, 12, 13);System.out.println(calendar2.getTime());</code></pre><ul><li>Date类<ul><li>Date本身没有时区的问题，都是保存的UTC时间</li><li>Date当中保存的是一个时间戳，是从1970-1-1 0点到现在的毫秒数</li><li>保存方法<ul><li>以UTC保存</li><li>以字面量保存<ul><li>年月日 时分秒  时区信息</li></ul></li></ul></li></ul></li></ul><ul><li><p>ZoneId </p><ul><li><code>ZoneId.of</code>用来初始化一个标准的时区</li><li><code>ZoneOffset.ofHours</code> 通过offset来初始化具有指定的时间差的时区</li></ul></li><li><p>LocalDateTime</p><ul><li>不带有时区属性，是本地时区的日期时间</li></ul></li><li><p>ZonedDateTime </p><ul><li>= LocalDateTime + ZoneId </li></ul></li><li><p>DateTimeFormatter</p><ul><li>可以通过withZone方法直接设置需要使用的时区</li></ul></li><li><p>因此对于国际化时间的处理，应当使用Java8的日期时间类，通过ZonedDateTime来保存时间</p></li></ul><h1 id="日期时间格式化和解析"><a href="#日期时间格式化和解析" class="headerlink" title="日期时间格式化和解析"></a>日期时间格式化和解析</h1><ul><li>SimpleDateFormat的问题<ul><li>注意使用SimpleDateFormat的时候，大写的YYYY表示的是week year，即所在的周属于哪一年，yyyy表示的是年</li><li>static 的SimpleDateFormat可能会出现线程安全的问题，其解析和格式化操作是非线程安全的</li><li>SimpleDateFormat对于格式不匹配表现的非常宽容，可能会隐藏一些错误，要注意格式上的不同</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在Java8之前，处理日期时间需求的时候需要使用Data, Calendar, SimpleDateFormat来声明时间戳，使用日历处理日期和格式化解析日期时间，Java8之后有了新的日期时间类，定义的比原来要清晰很多，且支持线程安全。&lt;/p&gt;
&lt;p&gt;这篇文章看看时间错乱
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
  </entry>
  
  <entry>
    <title>Java文件读写Tips</title>
    <link href="https://www.llchen60.com/Java%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99Tips/"/>
    <id>https://www.llchen60.com/Java%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99Tips/</id>
    <published>2020-09-22T04:11:35.000Z</published>
    <updated>2020-09-22T04:12:02.059Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-字符编码问题"><a href="#1-字符编码问题" class="headerlink" title="1. 字符编码问题"></a>1. 字符编码问题</h1><p>FileReader是以当前机器的默认字符集来读取文件的，如果希望指定字符集的话，需要直接使用InputStreamReader和FileInputStream </p><p>因此对于字符编码问题，我们应当使用FileInputStream来读取文件流，然后使用InputStreamReader读取字符流，并且制定字符集</p><h1 id="2-Files类的静态方法"><a href="#2-Files类的静态方法" class="headerlink" title="2. Files类的静态方法"></a>2. Files类的静态方法</h1><ul><li><p><code>Files.readAllLines</code> </p><ul><li>可以很方便的一行代码完成文件内容的读取</li><li>但是读取超出内存大小的大文件的时候会出现OOM<ul><li>是因为readAllLines读取文件所有内容之后会放到一个List<String>当中返回，如果内存无法容纳这个List，就会OOM </li></ul></li></ul></li><li><p><code>Files.lines</code></p><ul><li>返回的是Stream<String></li><li>使得我们在需要的时候可以不断读取，使用文件中的内容，而不是一次性的把所有内容都读取到内存当中，因此避免了OOM</li></ul></li><li><p>对于返回是Stream的方法要注意关闭句柄，可以通过使用try with resources 的方式来确保流的close方法可以调用释放资源</p></li></ul><pre><code>LongAdder longAdder = new LongAdder();IntStream.rangeClosed(1, 1000000).forEach(i -&gt; {    try (Stream&lt;String&gt; lines = Files.lines(Paths.get(&quot;demo.txt&quot;))) {        lines.forEach(line -&gt; longAdder.increment());    } catch (IOException e) {        e.printStackTrace();    }});log.info(&quot;total : {}&quot;, longAdder.longValue());</code></pre><h1 id="3-读写文件的缓冲区设置"><a href="#3-读写文件的缓冲区设置" class="headerlink" title="3. 读写文件的缓冲区设置"></a>3. 读写文件的缓冲区设置</h1><h2 id="3-1-为什么执行缓慢？"><a href="#3-1-为什么执行缓慢？" class="headerlink" title="3.1 为什么执行缓慢？"></a>3.1 为什么执行缓慢？</h2><pre><code>private static void perByteOperation() throws IOException {    try (FileInputStream fileInputStream = new FileInputStream(&quot;src.txt&quot;);         FileOutputStream fileOutputStream = new FileOutputStream(&quot;dest.txt&quot;)) {        int i;        while ((i = fileInputStream.read()) != -1) {            fileOutputStream.write(i);        }    }}</code></pre><ul><li>上述代码运行起来功能上完全没有问题<ul><li>但是会非常缓慢</li><li>原因是每读取一个字节，每写入一个字节就进行一次IO操作，代价太大了</li><li>解决方案是可以使用缓冲区作为过渡，一次性从原文件当中读取一定数量的数据到缓冲区当中，一次性写入一定数量的数据到目标文件</li></ul></li></ul><pre><code>private static void bufferOperationWith100Buffer() throws IOException {    try (FileInputStream fileInputStream = new FileInputStream(&quot;src.txt&quot;);         FileOutputStream fileOutputStream = new FileOutputStream(&quot;dest.txt&quot;)) {        byte[] buffer = new byte[100];        int len = 0;        while ((len = fileInputStream.read(buffer)) != -1) {            fileOutputStream.write(buffer, 0, len);        }    }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-字符编码问题&quot;&gt;&lt;a href=&quot;#1-字符编码问题&quot; class=&quot;headerlink&quot; title=&quot;1. 字符编码问题&quot;&gt;&lt;/a&gt;1. 字符编码问题&lt;/h1&gt;&lt;p&gt;FileReader是以当前机器的默认字符集来读取文件的，如果希望指定字符集的话，需要直
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="IO" scheme="https://www.llchen60.com/tags/IO/"/>
    
  </entry>
  
  <entry>
    <title>前端请求的timeout设置</title>
    <link href="https://www.llchen60.com/%E5%89%8D%E7%AB%AF%E8%AF%B7%E6%B1%82%E7%9A%84timeout%E8%AE%BE%E7%BD%AE/"/>
    <id>https://www.llchen60.com/%E5%89%8D%E7%AB%AF%E8%AF%B7%E6%B1%82%E7%9A%84timeout%E8%AE%BE%E7%BD%AE/</id>
    <published>2020-09-18T04:09:01.000Z</published>
    <updated>2020-09-18T04:09:42.640Z</updated>
    
    <content type="html"><![CDATA[<p>当我们发出一个网络请求，但是没有做超时设置，一个隐含的假设是我们认为这个请求一定会成功。然而，我们无法做出请求一定会成功的保证的。</p><ul><li>当你发出的同步请求从没有返回的时候，线程会一直被占用的</li><li>异步请求未返回的线程也无法继续复用，因为sockets会有泄露，socket池的容量是有限的，未返回结果的线程会一直开着连接，最终可能会导致连接的短缺</li></ul><p>因此best practice应当是对于ajax请求，做好timeout的设置，因为XMLHttpRequest的默认timeout是0，即没有超时设置。</p><p>Client端的timeout设置和server端一样重要，浏览器可以开的socket的数量也是有限的，我们应该通过设置timeout来充分利用socket pool。Fetch API是当前比较流行的XMLHttpRequest API的替代品，然而现在还没有一个直接的设置timeout的方法，最近刚刚推出了abort API，可以用来支持timeout。</p><p>用法比如： </p><pre><code>const controller = new AbortController();const signal = controller.signal;const fetchPromise = fetch(url, {signal});  // No timeout by default!setTimeout(() =&gt; controller.abort(), 10000); </code></pre><p>而对于Jquery的ajax call，我们可以使用： </p><pre><code>$.ajax({    url: &quot;test.html&quot;,    error: function(){        // will fire when timeout is reached    },    success: function(){        //do something    },    timeout: 3000 // sets timeout to 3 seconds});</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://robertovitillo.com/default-timeouts/" target="_blank" rel="noopener">https://robertovitillo.com/default-timeouts/</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;当我们发出一个网络请求，但是没有做超时设置，一个隐含的假设是我们认为这个请求一定会成功。然而，我们无法做出请求一定会成功的保证的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当你发出的同步请求从没有返回的时候，线程会一直被占用的&lt;/li&gt;
&lt;li&gt;异步请求未返回的线程也无法继续复用，因为s
      
    
    </summary>
    
    
      <category term="FrontEnd" scheme="https://www.llchen60.com/categories/FrontEnd/"/>
    
    
  </entry>
  
  <entry>
    <title>Java日志记录Tips</title>
    <link href="https://www.llchen60.com/Java%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95Tips/"/>
    <id>https://www.llchen60.com/Java%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95Tips/</id>
    <published>2020-09-15T03:03:32.000Z</published>
    <updated>2020-09-15T03:04:02.755Z</updated>
    
    <content type="html"><![CDATA[<p>使用Java来记录日志有几个需要注意的地方的</p><ul><li>首先日志框架很多，不同的类库有可能会使用不同的日志框架，如何兼容是一个问题</li><li>配置文件的复杂性</li></ul><p>Java体系的日志框架有：</p><ul><li>Logback</li><li>Log4j</li><li>Log4j2</li><li>commons-logging </li><li>JDK 自带的Java.util.logging</li></ul><p>如果不同的包使用不同的日志框架的话，那管理就会变得非常麻烦。为了解决这个问题，就有了SLF4J – Simple Logging Facade For Java </p><ul><li>提供了统一的日志门面API，实现了中立的日志记录API</li><li>桥接功能<ul><li>可以将各种日志框架的API桥接到SLF4J API上。这样一来，即便你的程序试用了各种日志API记录日志，最终都可以桥接到Slf4j门面API上</li></ul></li><li>适配功能<ul><li>实现slf4j和实际日志框架的绑定</li><li>slf4j知识日志标准，还是需要一个实际的日志框架</li></ul></li></ul><p>下面一起梳理下常见的日志记录中的错误</p><h1 id="1-理解Logback配置，避免重复记录"><a href="#1-理解Logback配置，避免重复记录" class="headerlink" title="1. 理解Logback配置，避免重复记录"></a>1. 理解Logback配置，避免重复记录</h1><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;configuration&gt;    &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;            &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt;        &lt;/layout&gt;    &lt;/appender&gt;    &lt;logger name=&quot;org.geekbang.time.commonmistakes.logging&quot; level=&quot;DEBUG&quot;&gt;        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;    &lt;/logger&gt;    &lt;root level=&quot;INFO&quot;&gt;        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;</code></pre><p>要注意在使用appender的时候，appender是如何挂载的，上述代码将appender挂载在了两个不同的地方，而且两个都定义在了root下，所以会造成重复。 </p><p>对于需要将不同的日志放到不同的文件的应用场景，可以通过设置Logger的additivity属性来实现这个操作</p><pre><code> &lt;logger name=&quot;org.geekbang.time.commonmistakes.logging&quot; level=&quot;DEBUG&quot; additivity=&quot;false&quot;&gt;            &lt;appender-ref ref=&quot;FILE&quot;/&gt;     &lt;/logger&gt;</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用Java来记录日志有几个需要注意的地方的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先日志框架很多，不同的类库有可能会使用不同的日志框架，如何兼容是一个问题&lt;/li&gt;
&lt;li&gt;配置文件的复杂性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Java体系的日志框架有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logb
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
  </entry>
  
  <entry>
    <title>《网易一千零一夜》读书笔记</title>
    <link href="https://www.llchen60.com/%E3%80%8A%E7%BD%91%E6%98%93%E4%B8%80%E5%8D%83%E9%9B%B6%E4%B8%80%E5%A4%9C%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>https://www.llchen60.com/%E3%80%8A%E7%BD%91%E6%98%93%E4%B8%80%E5%8D%83%E9%9B%B6%E4%B8%80%E5%A4%9C%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</id>
    <published>2020-09-09T04:35:15.000Z</published>
    <updated>2020-09-16T04:29:15.133Z</updated>
    
    <content type="html"><![CDATA[<h1 id="0-为什么开始看这本书？"><a href="#0-为什么开始看这本书？" class="headerlink" title="0. 为什么开始看这本书？"></a>0. 为什么开始看这本书？</h1><p>接到了让人兴奋的项目，小振奋，然后突然意识到项目的复杂程度，需要涉及的方方面面可能已经超过了我能够处理的能力范畴，所以需要补课了…</p><p>看了很多知乎的答案啊，看着看着意识到当自己在努力寻找沉淀下来的经过思考的单领域的内容的时候，从知乎或者其他快节奏的平台找倒是真的有点舍本逐末哎。项目管理还是有很多核心理念是可以也已经沉淀下来的，所以就开始了找书看，对照着自己现在的境况，一点点解决的状态。</p><p>另外踩的一个小坑是太追求优质的工具，即疯狂比较各种管理记录的软件，比较omniplan vs xxx vs blablabla, 瞎倒腾了好一顿才意识到对于一个不懂项目管理的我来说，倒腾哪个都是白瞎。一定会按照完全不是软件本身设定的方式，来使用它，应该说是完全解决不了问题。</p><p>所以还是踏踏实实的带着敬畏感的从一本不太学术的书开始，从互联网公司 – 网易的产品经理的视角，来看看怎么做项目管理，怎么跟进项目的进程，如何应对各种过程中的设计变化，如何做各种取舍。</p><h1 id="1-项目管理Overview"><a href="#1-项目管理Overview" class="headerlink" title="1. 项目管理Overview"></a>1. 项目管理Overview</h1><h2 id="1-1-High-Level的建议"><a href="#1-1-High-Level的建议" class="headerlink" title="1.1 High Level的建议"></a>1.1 High Level的建议</h2><ul><li><p>项目到底需要什么</p><ul><li>接手一个项目之前，应当与项目的重要干系人加强沟通，理解前因后果<ul><li>对于技术项目，理解整个大致技术实现的思路，其中的痛点难点，潜在的不确定因素<ul><li>比如跨组的合作</li></ul></li></ul></li><li>而后，理解项目到底需要什么<ul><li>时间成本质量要素的权衡与取舍<ul><li>范围</li><li>时间</li><li>成本和质量</li></ul></li><li>各个角色目前的痛点</li></ul></li><li>大家对项目管理的认知和接受度<ul><li>通过怎样的途径，是全面推进，还是步步改善？ </li><li>从哪一个角度切入？ </li><li>蓝图是否清晰？</li><li>是否与项目负责人沟通到位并且达成一致？ </li></ul></li></ul></li><li><p>不要凡事事必躬亲</p><ul><li>替别人待办他们本该做的事情，对于团队来说反而效率最低</li><li>需要努力让别人能够做好这件事情<ul><li>Awareness<ul><li>使得团队成员知道需要做什么 </li></ul></li><li>Desire<ul><li>需要给予某方面的动能<ul><li>技术挑战程度？</li><li>项目完成以后的影响力？ </li><li>升职加薪？ </li></ul></li></ul></li><li>Ability <ul><li>确保其有足够的能力来做好这件事情<ul><li>初期的辅助</li><li>必要的培训等</li></ul></li></ul></li></ul></li></ul></li></ul><ul><li><p>不要追在别人屁股后面做监工</p><ul><li>项目经历不是监督事情做得怎么样的人</li><li>他是应该和大家一起将整个事情环节捋顺的人，需要建议<u><strong>一套对应的流程规则</strong></u>，明确各个角色在过程中的职责</li><li>获得认同，使得这个机制自行运转起来</li><li>努力做到是<strong>规则在约束大家的行为</strong>，而不是靠人看着来做</li></ul></li><li><p>言必信，行必果</p><ul><li><p>无权力下的领导力 – leadership without authority </p><ul><li>在弱矩阵结构下项目经历必修课</li></ul></li><li><p>需要构建起团队对你的信任，建立自己的可信度，打造个人品牌</p></li><li><p>信任的获取需要一点一滴的积累了</p></li><li><p>专业度上</p><ul><li>确定自己足够专业</li><li>至少相对更专业</li></ul></li><li><p>跟进</p><ul><li>会议，发布，邮件，承诺</li></ul></li></ul></li><li><p>处理争端</p><ul><li>与人一起解决问题，会因为不同的对于事情的看法产生很多争论</li><li>需要找出一致的地方并且努力放大</li></ul></li></ul><h2 id="1-2-关于时间估算"><a href="#1-2-关于时间估算" class="headerlink" title="1.2 关于时间估算"></a>1.2 关于时间估算</h2><ul><li><p>有没有必要进行时间估算以及进行到什么程度的时间估算？</p><ul><li><p>现状</p><ul><li>用了很多时间，但是最终的实际使用时间往往和估算的有不小的偏差</li></ul></li><li><p>房子从凌乱到整洁需要20%的努力，从整洁到一尘不染可能需要80%</p><ul><li>有估算实际上是完成了相对性价比比较高的一段</li></ul></li><li><p>估算可以给一个相对合理的计划，使得用户，管理层和团队都有一个稳定的预期</p></li></ul></li></ul><ul><li><p>估算单位</p><ul><li><p>理想人日</p><ul><li>指成员在不受干扰的情况下，全部时间用来开发需求所需的天数</li><li>劣势<ul><li>人的不同会导致整个估算的不同</li><li>这样的差异会导致我们队任务规模认识的偏差，很难衡量项目的实际大小</li></ul></li></ul></li><li><p>理想人时</p><ul><li>对应理想人日而存在</li><li>在充分理解需求的情况下，能帮助团队做到更靠近真实值的估算</li></ul></li><li><p>故事点</p><ul><li><p>对任务规模的估计，是一种相对的概念</p></li><li><p>优势</p><ul><li>基于故事点的估算不会因为开发人员的变更，时间的推移而改变</li></ul></li><li><p>劣势</p><ul><li>难以找到合适的估算单位</li></ul></li></ul></li></ul></li><li><p>估算的方式</p><ul><li><p>自下而上的估算</p><ul><li><p>每个开发人员估算自己的任务时间，然后将所有的任务汇总</p></li><li><p>团队特征</p><ul><li>成员间业务独立性强</li><li>相互之间业务熟悉度不高，熟悉成本高</li><li>各成员相对经验比较丰富</li></ul></li><li><p>优势</p><ul><li>估算效率高</li><li>准确度也会比较高</li></ul></li></ul></li><li><p>专家判断</p><ul><li>专家根据响应开发的情况给出任务的估算值</li></ul></li><li><p>扑克估算</p><ul><li><p>流程</p><ul><li>每个估计者都会分到一叠扑克牌，每张上有一个数值</li><li>由负责人对某个需求进行估算的需求或者任务进行讲解</li><li>讲解后，所有人都可以向该负责人提问关于该条需求或者任务的问题，直至足够了解</li><li>然后所有成员挑选一张扑克牌代表自己对该条目的估算</li><li>如果差值比较大，就需要人员说明各自给出这个估值的理由，然后再进行下一轮的估算</li><li>最后取平均值</li></ul></li><li><p>优势</p><ul><li>多成员一件，更客观</li><li>估算过程中，强化了大家对于需求和任务的理解，将任务考虑得更加细致，降低了不确定性给计划带来的冲击</li><li>使得相对严肃的计划和估算变得更加有趣，但是会花费更多的时间成本</li><li>需求探索的会更加深入，估算也会更加全面细致</li><li>让潜在的冲突公开化，台面化，让大家去充分碰撞，然后用一种近似游戏化的方式再去化解掉</li></ul></li></ul></li></ul></li><li><p>估算的注意事项</p><ul><li>估算仅仅是预测，当对外承诺项目完成时间的时候，最好提供一个日期范围，让听者知道你的估算只是预测</li><li>将任务分成更细的粒度是会有利于估算的</li><li>团队需要练习估算方式并且收集反馈，有迭代，有过去的数据，就可以做分析，来进行优化</li><li>估算需要进行反复进行，当项目进行一半，发现估算过于乐观的话，就需要对剩下的工作进行重新估算</li></ul></li><li><p>估算与Scrum</p><ul><li>在Scrum项目当中，我们会以迭代Sprint为周期来做增量交付</li><li>和传统的项目不一样的是在每个迭代计划当中我们不需要确定日期，只需要估算一个迭代我们能完成多少工作</li></ul></li></ul><h2 id="1-3-进度计划"><a href="#1-3-进度计划" class="headerlink" title="1.3 进度计划"></a>1.3 进度计划</h2><ul><li><p>制定计划的重要性</p><ul><li>计划的本质是团队对何时完成任务的承诺</li><li>排斥做计划的原因，在于人们不愿轻易做出承诺。人们都会有一种言行一致的愿望，一旦做出承诺，来自内心和外部的压力会迫使我们按照承诺去做。</li></ul></li><li><p>制定计划的时间点</p><ul><li>应该尽量早的制定出计划<ul><li>因为在混沌不清的时候，需要某种方式来做锚定，相当于挖个坑，根据少量的信息给出期望值，然后让人们一点点来填满它</li><li>当有了坑以后，就让大家一起来填</li></ul></li></ul></li><li><p>调整计划的注意事项</p><ul><li>计划是调整的基础和依据，但是调整计划需要注意：<ul><li>确保项目的每一个人都知道当前的计划是什么</li><li>调整计划需要怎样的决策过程</li><li>需要谁参与决策</li></ul></li></ul></li><li><p>如何做好计划</p><ul><li><p>项目立项前</p><ul><li>将目标按照功能体系分割成几个重大的里程碑</li><li>这个时候注意要给出立项的时间表 – 能够使得各个资源方有明确的预期，以便提前做好资源的调配<ul><li>什么时候完成初期调研和评估</li><li>何时做好立项准备</li><li>何时启动项目</li></ul></li></ul></li><li><p>项目立项后</p><ul><li>根据启动过程当中对于里程碑的大致预期，进一步推导出<ul><li>需求确认</li><li>设计确认</li><li>功能完成</li></ul></li></ul></li><li><p>需求确认后</p><ul><li>由设计，开发，测试一起做WBS，将工作细化分解<ul><li>注意的几个节点<ul><li>设计确认</li><li>功能完成</li><li>no bug</li><li>发布前的代码冻结</li></ul></li></ul></li></ul></li><li><p>完成标准</p><ul><li><p>需求设计确认</p><ul><li>团队要准备好怎么编写，在哪里编写代码</li></ul></li><li><p>功能完成</p><ul><li>所有定义的功能都已经完成，已经通过测试，允许质量差距和少量的Bug存在</li></ul></li><li><p>里程碑完成</p><ul><li>质量已达到适当水平，可以上线发布，或者开始下一个里程碑</li></ul></li></ul></li><li><p>Tips</p><ul><li>计划本质上是一种承诺，因此应该让团队共同参与制定出来</li><li>想让承诺有效，必须要是当事人积极公开且经过一番努力后自由选择得来的  </li></ul></li></ul></li></ul><h2 id="1-4-每日站会"><a href="#1-4-每日站会" class="headerlink" title="1.4 每日站会"></a>1.4 每日站会</h2><ul><li>定位在沟通交流<ul><li>不是汇报会</li><li>是用来分享信息，做出承诺以及提出路障的，解决的是团队协同的问题</li><li>需要让人参与进来<ul><li>红黄绿三牌的方式<ul><li>黄牌 – 进行相关提问，向发言者了解协同和依赖的信息</li><li>红牌 – 用来打断谈话，避免过度的讨论和无结果的时间浪费，提高站会效率</li><li>绿牌 – 代表每个人的发言权，将牌归还给主持人则意味着站会结束</li></ul></li></ul></li></ul></li></ul><h2 id="1-5-周会周报"><a href="#1-5-周会周报" class="headerlink" title="1.5 周会周报"></a>1.5 周会周报</h2><ul><li><p>周会的目的</p><ul><li>不仅仅是同步状态，汇总团队信息，这些是邮件，文件共享就可以实现的</li><li>目的在于<ul><li>面对面感受项目当前的整体状态，重要问题，接下去的目标，以及所需的调整</li><li>借此对项目当前重要的问题有一致的认识，进行小幅度的讨论，并形成下一步的工作事项 </li></ul></li></ul></li><li><p>Tips</p><ul><li><p>控制规模和时间</p><ul><li>最多10 - 15</li><li>1.5h maximum </li></ul></li><li><p>要不要轮流汇报？</p><ul><li>大部分项目整体情况可以通过项目经历事先收集来直接做整体概述</li><li>对于部分方向性或者商务性的小组，可以简单汇报主要工作和主要问题</li></ul></li><li><p>什么适合在周会中讨论？</p><ul><li>急事不适合</li><li>非跨团队的问题不适合周会讨论</li><li>纯执行细节问题不适合周会讨论</li><li>大方向决策问题不适合</li><li>可以讨论跨团队的涉及整体性计划的问题</li><li>中期改进型问题</li></ul></li><li><p>说话比例</p><ul><li>三分<ul><li>会议主持人，更新整体状态，主持讨论</li><li>需要回报的与会者的发言</li><li>所有与会者的讨论</li></ul></li></ul></li></ul></li><li><p>全体类周会</p></li><li><p>组长类周会</p></li><li><p>三方类 – 产品，运营，市场三方周会</p></li></ul><h2 id="1-6-工作汇报"><a href="#1-6-工作汇报" class="headerlink" title="1.6 工作汇报"></a>1.6 工作汇报</h2><ul><li><p>工作汇报的目的</p><ul><li><p>将状态，问题，风险知会相关干系人</p></li><li><p>寻求帮助</p><ul><li>需要在遇到问题的初期就积极主动寻求帮助，进而迅速的去解决</li></ul></li><li><p>自我审视</p><ul><li>周报是一种自我审视的过程，看看自己制定的目标和项目的完成情况</li></ul></li></ul></li><li><p>个人周报</p><ul><li><p>内容</p><ul><li><p>本周工作完成程度</p><ul><li>做了什么</li><li>完成结果如何</li></ul></li><li><p>下周工作计划</p><ul><li>需要做什么</li><li>时间点</li><li>完成的定义</li></ul></li><li><p>工作中遇到的问题和建议</p></li><li><p>个人感言和建议</p><ul><li>工作中的总结和分享，让上司知道你在想什么</li></ul></li></ul></li></ul></li></ul><ul><li>团队工作周报<ul><li>团队周报更多聚焦在结果和计划上，而非个人微观层面的事件总结</li><li>计划的时间跨度根据团队规模大小不同可以从1个月到3个月不等</li><li>内容<ul><li>上周达成的结果<ul><li>量化的结果指标<ul><li>销售额</li><li>用户数等</li></ul></li></ul></li><li>未来一段时间的规划<ul><li>通过图形化的方式言简意赅地列出任务的时间点和期望达到的结果</li></ul></li><li>达成如上规划图的风险/ 需要的协助<ul><li>资源风险</li><li>合作方风险</li><li>建议的应对方案</li></ul></li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;0-为什么开始看这本书？&quot;&gt;&lt;a href=&quot;#0-为什么开始看这本书？&quot; class=&quot;headerlink&quot; title=&quot;0. 为什么开始看这本书？&quot;&gt;&lt;/a&gt;0. 为什么开始看这本书？&lt;/h1&gt;&lt;p&gt;接到了让人兴奋的项目，小振奋，然后突然意识到项目的复杂程
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
      <category term="项目管理" scheme="https://www.llchen60.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>《你早该这么玩Excel》</title>
    <link href="https://www.llchen60.com/%E3%80%8A%E4%BD%A0%E6%97%A9%E8%AF%A5%E8%BF%99%E4%B9%88%E7%8E%A9Excel%E3%80%8B/"/>
    <id>https://www.llchen60.com/%E3%80%8A%E4%BD%A0%E6%97%A9%E8%AF%A5%E8%BF%99%E4%B9%88%E7%8E%A9Excel%E3%80%8B/</id>
    <published>2020-09-05T20:06:45.000Z</published>
    <updated>2020-09-07T04:37:36.593Z</updated>
    
    <content type="html"><![CDATA[<p>一次对Excel的了解和正视之旅。相较于编程实现与通过Excel进行数据分析，编程在Scalability上胜出的，但是对于操作的便捷性，以及验证假设的速度上，确确实实Excel要胜出一筹。尤其是学到了三表的操作，VLookUp这种函数之后，开始理解Excel在数据分析上的巨大的作用。</p><ul><li><p>Highlights</p><ul><li>三表<ul><li>参数表</li><li>源数据表</li><li>分类汇总表</li></ul></li><li>巧用各种函数</li></ul></li><li><p>源数据表</p><ul><li>应当只有一张，对于每一个你想要研究的领域</li><li>应当为一维数据格式</li><li>标题内容不要写在表格当中，因为我们很可能需要索引的，<ul><li>可以对工作簿， 工作表进行命名来做区分</li></ul></li><li>源数据顺序<ul><li>应该按照工作当中的逻辑顺序来对列进行排序</li><li>列数据位置调整，shift + 拖动</li></ul></li><li>凡是同一种属性的数据都应该记录在同一列当中的</li><li>多个单元格批量录入<ul><li>选定多个单元格</li><li>在一个单元格当中输入内容</li><li>Ctrl + enter 输入一次的内容会被加载到你选中的所有单元格上</li></ul></li><li>源数据表当中不应该使用合并居中这种操作<ul><li>明细数据应当有一条记录一条</li><li>所有单元格应该被填满</li><li>每一行数据必须完整且整齐</li><li>合并单元格会导致只有首个单元格有数据，其他的都是空白单元格</li></ul></li><li>元数据只保留在一张表当中，放在多张表当中的话合并会非常非常麻烦</li><li>源数据表是为了商业上的use case服务的，需要理清楚需要什么数据<ul><li>按照逻辑顺序来分清各个column</li><li>在这之后可以按照可能的手动输入，复制粘贴来做cluster</li></ul></li></ul></li><li><p>三张表的定义</p><ul><li>参数表<ul><li>系统的配置参数，供源数据表和分类汇总表来调用</li><li>表示数据匹配关系或者某属性明细不会经常变更的数据</li></ul></li><li>源数据表<ul><li>数据的录入</li><li>一切与数据录入相关的工作都应该在源数据表当中进行</li><li>应满足一下条件<ul><li>一维数据</li><li>一个标题行</li><li>字段分类清晰</li><li>数据属性完整</li><li>数据连续</li><li>无合并单元格</li><li>无合计行</li><li>无分隔行/ 列</li><li>无空白单元格</li><li>单元格内容禁用短语句子</li></ul></li><li>分类汇总表<ul><li>希望是通过函数关联等从数据表当中获取一切所需的数据</li></ul></li><li>Thoughts <ul><li>企业信息化是必须的，需要有ERP, CRM, WMS, OA等企业系统</li><li>但是对于信息的个性化处理上来说，Excel会更占上风，可以更快速的给出各类数据</li></ul></li></ul></li></ul></li><li><p>数据透视表</p><ul><li>在源数据表当中选中想要做分析的数据，然后来生成Pivot table</li><li>步骤<ul><li>确认数据来源和待创建的报表类型</li><li>确认选定的数据区域</li><li>标题行需要被包含在内</li></ul></li><li>Tips<ul><li>分类多的字段尽量作为航字段</li></ul></li></ul></li><li><p>录入安全</p><ul><li>设置有关于数据有效性的限制，比如规定必须输入某种日期格式</li><li>对于包含公式的部分，可以直接进行锁定，这样其他人就无法对其进行修改了</li><li>手工录入，复制粘贴，公式链接的数据区域要用不同的填充色区分，来告知使用者什么地方需要填写，什么地方需要复制粘贴</li></ul></li><li><p>Vlookup</p><ul><li>查找引用函数<ul><li>查找某单元格数据在源数据库中是否存在，如果存在，就返回源数据库中同行指定列的单元格内容</li></ul></li><li>四个参数<ul><li>用什么找</li><li>在哪个表找</li><li>找到了返回什么值</li><li>精确找还是模糊找</li></ul></li></ul></li><li><p>图表</p><ul><li>做图表的目的是为了能够更加准确直观的诠释数据</li><li>饼状图<ul><li>说明比例关系</li></ul></li><li>柱状图<ul><li>比较数值</li></ul></li><li>折线图<ul><li>关注趋势</li></ul></li><li>概念图<ul><li>左右对比，适合男女</li><li>生成图标的源数据当中制造负数，来生成这种向两边延伸的效</li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一次对Excel的了解和正视之旅。相较于编程实现与通过Excel进行数据分析，编程在Scalability上胜出的，但是对于操作的便捷性，以及验证假设的速度上，确确实实Excel要胜出一筹。尤其是学到了三表的操作，VLookUp这种函数之后，开始理解Excel在数据分析上的
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
      <category term="Excel" scheme="https://www.llchen60.com/tags/Excel/"/>
    
  </entry>
  
  <entry>
    <title>Java 集合处理/ 空值处理/ 异常处理</title>
    <link href="https://www.llchen60.com/Java-%E9%9B%86%E5%90%88%E5%A4%84%E7%90%86-%E5%92%8C-%E7%A9%BA%E5%80%BC%E5%A4%84%E7%90%86/"/>
    <id>https://www.llchen60.com/Java-%E9%9B%86%E5%90%88%E5%A4%84%E7%90%86-%E5%92%8C-%E7%A9%BA%E5%80%BC%E5%A4%84%E7%90%86/</id>
    <published>2020-09-04T03:48:11.000Z</published>
    <updated>2020-09-07T17:15:59.334Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Arrays-asList"><a href="#1-Arrays-asList" class="headerlink" title="1. Arrays.asList"></a>1. <code>Arrays.asList</code></h1><p>业务开发当中，我们常常会将原始的数组转换为List类数据结构，来继续展开各种Stream操作</p><ul><li><p>Arrays.asList无法转换基本类型的数组，可以使用Arrays.stream来进行转换</p></li><li><p>Arrays.asList返回的list是不支持增删操作的，其返回的List是Arrays的内部类ArrayList。内部继承自AbstractList，没有覆写父类的add方法</p></li><li><p>对原始数组的修改会影响到我们获得的那个List</p><ul><li>ArrayList实际上是使用了原始的数组，因此在使用的时候，最好再使用New ArrayList来实现解耦</li></ul></li></ul><h1 id="2-空值处理"><a href="#2-空值处理" class="headerlink" title="2. 空值处理"></a>2. 空值处理</h1><h2 id="2-1-NullPointerException"><a href="#2-1-NullPointerException" class="headerlink" title="2.1 NullPointerException"></a>2.1 NullPointerException</h2><ul><li>可能出现的场景<ul><li>参数值是Integer等包装类型，使用时因为自动拆箱出现了空指针异常</li><li>字符串比较</li><li>ConcurrentHashMap这种容器不支持Key和Value为null，强行put null的key或Value会出现空指针异常</li><li>方法或远程服务返回的list是null，没做判空就直接调用，出现空指针异常</li><li>联级调用的null check</li></ul></li></ul><ul><li>best practice<ul><li><code>string.equalsTo(variableName)</code></li><li><code>Optional.ofNullable()</code></li><li><code>orElse()</code></li></ul></li></ul><h1 id="3-异常处理"><a href="#3-异常处理" class="headerlink" title="3. 异常处理"></a>3. 异常处理</h1><h2 id="3-1-在业务代码层面考虑异常处理"><a href="#3-1-在业务代码层面考虑异常处理" class="headerlink" title="3.1 在业务代码层面考虑异常处理"></a>3.1 在业务代码层面考虑异常处理</h2><ul><li><p>大多数业务应用都采用三层架构</p><ul><li><p>Controller层</p><ul><li>负责信息收集，参数校验，转换服务层处理的数据适配前端，轻业务逻辑</li><li>Controller 捕获异常，然后需要给用户友好用户的提示</li></ul></li><li><p>Service层</p><ul><li>负责核心业务逻辑，包括外部服务调用，访问数据库，缓存处理，消息处理等</li><li>一般会涉及到数据库事务，出现异常不适合捕获，否则事务无法自动回滚</li></ul></li><li><p>Repository层</p><ul><li>负责数据访问实现，一般没有业务逻辑</li><li>根据情况来做忽略，降级，或者转化为一个友好的异常</li></ul></li></ul></li><li><p>框架层面的异常处理</p><ul><li>尽量不要在框架层面做异常的自动，统一的处理</li><li>框架应当来做兜底工作，如果异常上升到最上层逻辑还是无法处理的话，可以用统一的方式进行异常转换<ul><li><code>@RestControllerAdvice</code></li><li><code>@ExceptionHandler</code></li></ul></li></ul></li></ul><h2 id="3-2-不要直接生吞异常"><a href="#3-2-不要直接生吞异常" class="headerlink" title="3.2 不要直接生吞异常"></a>3.2 不要直接生吞异常</h2><p>捕获了异常以后不应该生吞，因为吞掉的异常如果没有正常处理的话，出现Bug会很难发现。</p><p>需要有合适的转化成用户友好的异常，或者至少在warn， error级别来做log</p><h2 id="3-3-保留原始的信息"><a href="#3-3-保留原始的信息" class="headerlink" title="3.3 保留原始的信息"></a>3.3 保留原始的信息</h2><p>在捕捉了异常之后，一定要记得在log 或者在向外扔出的异常之中记录原始异常信息</p><pre><code>catch (IOException e) {    //只保留了异常消息，栈没有记录    log.error(&quot;文件读取错误, {}&quot;, e.getMessage());    throw new RuntimeException(&quot;系统忙请稍后再试&quot;);}catch (IOException e) {    throw new RuntimeException(&quot;系统忙请稍后再试&quot;, e);}</code></pre><h2 id="3-4-小心finally中的异常-try-with-resources"><a href="#3-4-小心finally中的异常-try-with-resources" class="headerlink" title="3.4 小心finally中的异常 + try with resources"></a>3.4 小心finally中的异常 + try with resources</h2><p>注意在资源释放处理等收尾操作的时候也可能会出现异常，这种时候，如果try block逻辑和finnally逻辑都有异常抛出的话，try当中的异常会被finnally中的异常覆盖掉，这会让问题变得非常不明显</p><pre><code>@GetMapping(&quot;wrong&quot;)public void wrong() {    try {        log.info(&quot;try&quot;);        //异常丢失        throw new RuntimeException(&quot;try&quot;);    } finally {        log.info(&quot;finally&quot;);        throw new RuntimeException(&quot;finally&quot;);    }}</code></pre><p>对于实现了AutoCloseable接口的资源，可以使用try-with-resources来释放资源，就是在try中带资源的声明</p><ul><li>try catch finally vs try with resources </li></ul><pre><code>Scanner scanner = null;try {    scanner = new Scanner(new File(&quot;test.txt&quot;));    while (scanner.hasNext()) {        System.out.println(scanner.nextLine());    }} catch (FileNotFoundException e) {    e.printStackTrace();} finally {    if (scanner != null) {        scanner.close();    }}try (Scanner scanner = new Scanner(new File(&quot;test.txt&quot;))) {    while (scanner.hasNext()) {        System.out.println(scanner.nextLine());    }} catch (FileNotFoundException fnfe) {    fnfe.printStackTrace();}</code></pre><h2 id="3-5-线程池任务的异常处理"><a href="#3-5-线程池任务的异常处理" class="headerlink" title="3.5 线程池任务的异常处理"></a>3.5 线程池任务的异常处理</h2><ul><li>设置自定义的异常处理程序作为保底，比如在声明线程池时自定义线程池的未捕获异常处理程序</li></ul><pre><code>new ThreadFactoryBuilder()  .setNameFormat(prefix+&quot;%d&quot;)  .setUncaughtExceptionHandler((thread, throwable)-&gt; log.error(&quot;ThreadPool {} got exception&quot;, thread, throwable))  .get()</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.baeldung.com/java-try-with-resources" target="_blank" rel="noopener">https://www.baeldung.com/java-try-with-resources</a> </li><li><a href="https://time.geekbang.org/column/article/220230" target="_blank" rel="noopener">https://time.geekbang.org/column/article/220230</a> </li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Arrays-asList&quot;&gt;&lt;a href=&quot;#1-Arrays-asList&quot; class=&quot;headerlink&quot; title=&quot;1. Arrays.asList&quot;&gt;&lt;/a&gt;1. &lt;code&gt;Arrays.asList&lt;/code&gt;&lt;/h1&gt;&lt;p&gt;业务开
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Java" scheme="https://www.llchen60.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java数值计算精度问题</title>
    <link href="https://www.llchen60.com/Java%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98/"/>
    <id>https://www.llchen60.com/Java%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98/</id>
    <published>2020-09-01T05:29:02.000Z</published>
    <updated>2020-09-01T05:29:27.985Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Double"><a href="#1-Double" class="headerlink" title="1. Double"></a>1. Double</h1><pre><code>System.out.println(0.1+0.2);System.out.println(1.0-0.8);System.out.println(4.015*100);System.out.println(123.3/100);double amount1 = 2.15;double amount2 = 1.10;if (amount1 - amount2 == 1.05)    System.out.println(&quot;OK&quot;);// Output 0.300000000000000040.19999999999999996401.499999999999941.2329999999999999</code></pre><p>上述问题出现的原因是因为计算机是以二进制存储数值的，浮点数也是如此。 Java采用的是IEEE754标准来实现浮点数的表达和运算，当将一个10进制的数值转化成浮点数的时候，会出现无限循环的结果。当使用二进制表示是无限循环的时候，转换成10进制就会造成精度的缺失了。</p><h1 id="2-BigDecimal"><a href="#2-BigDecimal" class="headerlink" title="2. BigDecimal"></a>2. BigDecimal</h1><p>BigDecimal可以用于浮点数精确表达的场景，但是使用BigDecimal的时候，一定要注意使用字符串的构造方法来初始化</p><pre><code>System.out.println(new BigDecimal(&quot;0.1&quot;).add(new BigDecimal(&quot;0.2&quot;)));System.out.println(new BigDecimal(&quot;1.0&quot;).subtract(new BigDecimal(&quot;0.8&quot;)));System.out.println(new BigDecimal(&quot;4.015&quot;).multiply(new BigDecimal(&quot;100&quot;)));System.out.println(new BigDecimal(&quot;123.3&quot;).divide(new BigDecimal(&quot;100&quot;)));0.30.2401.5001.233</code></pre><ul><li><p>BigDecimal </p><ul><li>有scale, Precision的概念</li><li>scale 表示小数点右边的位数</li><li>precision 表示精度，即有效数字的长度</li></ul></li><li><p>BigDecimal的equals判等</p><ul><li>比较的是value和scale 两个值的！</li></ul></li></ul><pre><code>System.out.println(new BigDecimal(&quot;1.0&quot;).equals(new BigDecimal(&quot;1&quot;)))false</code></pre><pre><code>/** * Compares this {@code BigDecimal} with the specified * {@code Object} for equality.  Unlike {@link * #compareTo(BigDecimal) compareTo}, this method considers two * {@code BigDecimal} objects equal only if they are equal in * value and scale (thus 2.0 is not equal to 2.00 when compared by * this method). * * @param  x {@code Object} to which this {@code BigDecimal} is *         to be compared. * @return {@code true} if and only if the specified {@code Object} is a *         {@code BigDecimal} whose value and scale are equal to this *         {@code BigDecimal}&#39;s. * @see    #compareTo(java.math.BigDecimal) * @see    #hashCode */@Overridepublic boolean equals(Object x)</code></pre><h1 id="3-数值溢出问题"><a href="#3-数值溢出问题" class="headerlink" title="3. 数值溢出问题"></a>3. 数值溢出问题</h1><p>所有的基本数值类型都有超出表达范围的可能性，而且是没有任何异常的默默的溢出</p><ul><li>可以使用Math类的addExact, substractExact等方法进行数值运算，在溢出的时候主动抛出异常</li><li>也可以使用BigInteger，也会主动抛出异常</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Double&quot;&gt;&lt;a href=&quot;#1-Double&quot; class=&quot;headerlink&quot; title=&quot;1. Double&quot;&gt;&lt;/a&gt;1. Double&lt;/h1&gt;&lt;pre&gt;&lt;code&gt;System.out.println(0.1+0.2);
System.
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Java" scheme="https://www.llchen60.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java 判等问题</title>
    <link href="https://www.llchen60.com/Java-%E5%88%A4%E7%AD%89%E9%97%AE%E9%A2%98/"/>
    <id>https://www.llchen60.com/Java-%E5%88%A4%E7%AD%89%E9%97%AE%E9%A2%98/</id>
    <published>2020-08-26T20:16:43.000Z</published>
    <updated>2020-08-26T20:17:17.758Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-equals-vs"><a href="#1-equals-vs" class="headerlink" title="1. equals vs =="></a>1. equals vs <code>==</code></h1><ul><li>对于基本类型，应使用==，比较的是值 </li><li>对于引用类型，需要使用equals，进行内容判等。使用<code>==</code>判断的是指针 –&gt; 代表的是两个对象在内存中的地址</li></ul><p>这里要注意的是Java是有字符串常量池机制的，当代码中出现双引号形式创建字符串对象的时候，JVM会先对字符串进行检查，如果字符串常量池存在相同内容的字符串对象的引用，就将这个引用返回；否则就创建新的字符串对象，然后将这个引用放入字符串常量池当中，并返回该引用</p><p>另外一个小坑是Integer在[-128,127]之间的数值是会做缓存的，即对于这中间的数值，即便你直接用<code>==</code>进行判断，有可能是直接会过的…</p><pre><code>public static Integer valueOf(int i) {    if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)        return IntegerCache.cache[i + (-IntegerCache.low)];    return new Integer(i);}</code></pre><h2 id="1-1-equals方法的实现"><a href="#1-1-equals方法的实现" class="headerlink" title="1.1 equals方法的实现"></a>1.1 equals方法的实现</h2><ul><li>equals在Object类当中的定义比较的是对象的引用</li></ul><pre><code>public boolean equals(Object obj) {    return (this == obj);}</code></pre><ul><li>而Integer，String类都重写了这个方法</li></ul><pre><code>public boolean equals(Object anObject) {    if (this == anObject) {        return true;    }    if (anObject instanceof String) {        String anotherString = (String)anObject;        int n = value.length;        if (n == anotherString.value.length) {            char v1[] = value;            char v2[] = anotherString.value;            int i = 0;            while (n-- != 0) {                if (v1[i] != v2[i])                    return false;                i++;            }            return true;        }    }    return false;}</code></pre><p>上述代码是先比较了引用，如果引用的地址一致，那么久可以直接返回true了。如果不一致，那就首先判断类的类型，如果是String类，再进行长度判断，如果长度一致，就逐个比较字符</p><ul><li>实现一个equals方法，需要注意<ul><li>首先进行指针判断，如果对象相同直接返回true</li><li>需要对另一方进行判空，空对象和自身的比较结果一定是false</li><li>需要判断两个对象的类型，如果类型都不同，那么直接返回false</li><li>在确保类型相同的情况下进行类型的强制转换，然后逐一判断所有字段<ul><li>需要进行类型强制转换是因为我们override的equals方法默认的输入参数是Object</li></ul></li></ul></li></ul><h2 id="1-2-使用Lombok的小坑"><a href="#1-2-使用Lombok的小坑" class="headerlink" title="1.2 使用Lombok的小坑"></a>1.2 使用Lombok的小坑</h2><p>Lombok的@Data注解会帮助我们实现equals和hashcode方法，但是有继承关系的时候，Lombok自动生成的方法是不会考虑到父类的</p><ul><li><p>对于不想进行equals和hashCode判断的参数，可以使用：</p><ul><li><code>@EqualsAndHashCode.Exclude</code></li></ul></li><li><p>对于想要使用父类属性的场景，可以使用</p><ul><li><code>@EqualsAndHashCode(callSuper = true)</code></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-equals-vs&quot;&gt;&lt;a href=&quot;#1-equals-vs&quot; class=&quot;headerlink&quot; title=&quot;1. equals vs ==&quot;&gt;&lt;/a&gt;1. equals vs &lt;code&gt;==&lt;/code&gt;&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;对于基本类型，
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Java" scheme="https://www.llchen60.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Spring @Transactional 事务Tips</title>
    <link href="https://www.llchen60.com/Spring-Transactional-%E4%BA%8B%E5%8A%A1Tips/"/>
    <id>https://www.llchen60.com/Spring-Transactional-%E4%BA%8B%E5%8A%A1Tips/</id>
    <published>2020-08-25T03:31:52.000Z</published>
    <updated>2020-08-26T18:08:52.862Z</updated>
    
    <content type="html"><![CDATA[<p>Spring针对Transaction APi, JDBC, Hibernate, Java Persistence API等事务API，实现了一致的编程模型，而Spring的声明式事务功能提供了非常方便的事务配置方式，使用<code>@Transactional</code>注解，就可以一键开启方法的事务性配置。</p><p>但是不是加上标注就能实现事务的，还是需要去关注事务是否有效，出错以后事务是否会正确回滚，当业务代码设计到多个子业务逻辑的时候，怎么正确处理事务。</p><h1 id="1-事务生效问题"><a href="#1-事务生效问题" class="headerlink" title="1. 事务生效问题"></a>1. 事务生效问题</h1><pre><code>@Entity@Datapublic class UserEntity {    @Id    @GeneratedValue(strategy = AUTO)    private Long id;    private String name;    public UserEntity() { }    public UserEntity(String name) {        this.name = name;    }}@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity, Long&gt; {    List&lt;UserEntity&gt; findByName(String name);}@Service@Slf4jpublic class UserService {    @Autowired    private UserRepository userRepository;    //一个公共方法供Controller调用，内部调用事务性的私有方法    public int createUserWrong1(String name) {        try {            this.createUserPrivate(new UserEntity(name));        } catch (Exception ex) {            log.error(&quot;create user failed because {}&quot;, ex.getMessage());        }        return userRepository.findByName(name).size();    }    //标记了@Transactional的private方法    @Transactional    private void createUserPrivate(UserEntity entity) {        userRepository.save(entity);        if (entity.getName().contains(&quot;test&quot;))            throw new RuntimeException(&quot;invalid username!&quot;);    }    //根据用户名查询用户数    public int getUserCount(String name) {        return userRepository.findByName(name).size();    }}</code></pre><p>上述代码使用JPA做数据库访问，Entity定义在UserEntity当中，在服务层，声明了createUsr方法，当名字包含test的时候，希望抛出异常，然后实现数据库的回滚（只是例子，当然实际实现上将判断和数据库存储执行顺序换过来就能避开这里的问题了）</p><p>当调用的时候，发现即使用户名不合法，也能够调用成功，这是因为上述代码将注解定义到了private方法，因此不生效</p><blockquote><p>只有定义在public方法上的@Transactional才能生效，因为Spring默认通过动态代理的方式实现AOP，对目标方法进行增强，private方法无法代理到，Spring也就无法使用动态增强事务处理的逻辑了。</p></blockquote><p>然而就算把上述的private方法改为public transactional依旧不会生效，这是因为：</p><blockquote><p>Transactional需要通过代理过的类从外部调用目标方法才能生效</p></blockquote><p>Spring通过AOP技术对方法进行增强，要调用增强过的方法必然是调用代理之后的对象</p><p>因此我们可以在controller层调用这个逻辑，来实现整个transactional的支持。即你需要使用Spring注入的类，通过代理调用才有机会来进行动态的增强。</p><h1 id="2-事务回滚问题"><a href="#2-事务回滚问题" class="headerlink" title="2. 事务回滚问题"></a>2. 事务回滚问题</h1><p>通过AOP锁实现的事务处理可以理解为使用try catch来包裹标记了<code>@Transactional</code>注解的方法，当方法出现了异常并且满足一定条件的时候，在catch里面我们可以设置事务回滚，没有异常则直接提交事务。</p><ol><li>只有异常传播出标记了注解的方法，事务才能回滚</li></ol><pre><code>try {   // This is an around advice: Invoke the next interceptor in the chain.   // This will normally result in a target object being invoked.   retVal = invocation.proceedWithInvocation();}catch (Throwable ex) {   // target invocation exception   completeTransactionAfterThrowing(txInfo, ex);   throw ex;}finally {   cleanupTransactionInfo(txInfo);}</code></pre><ol start="2"><li>默认情况下，出现RuntimeException或者Error的时候，Spring才会回滚事务</li></ol><p>在必要的时候，可以选择手动进行回滚，以及遇到所有的Exception都回滚事务</p><pre><code>@Transactionalpublic void createUserRight1(String name) {    try {        userRepository.save(new UserEntity(name));        throw new RuntimeException(&quot;error&quot;);    } catch (Exception ex) {        log.error(&quot;create user failed&quot;, ex);        TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();    }}@Transactional(rollbackFor = Exception.class)public void createUserRight2(String name) throws IOException {    userRepository.save(new UserEntity(name));    otherTask();}</code></pre><ul><li>有时我们会遇到嵌套逻辑，分别需要实现事务的问题，而子逻辑事务的回滚不希望影响到父逻辑，可以使用<code>@Transactional(propagation = Propagation.REQUIRES_NEW)</code>, 以此来设置事务传播策略，即执行到这个方法的时候需要开启新的事务，并挂起当前事务。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Spring针对Transaction APi, JDBC, Hibernate, Java Persistence API等事务API，实现了一致的编程模型，而Spring的声明式事务功能提供了非常方便的事务配置方式，使用&lt;code&gt;@Transactional&lt;/cod
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="事务" scheme="https://www.llchen60.com/tags/%E4%BA%8B%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>HTTP调用的超时，并发</title>
    <link href="https://www.llchen60.com/HTTP%E8%B0%83%E7%94%A8%E7%9A%84%E8%B6%85%E6%97%B6%EF%BC%8C%E5%B9%B6%E5%8F%91/"/>
    <id>https://www.llchen60.com/HTTP%E8%B0%83%E7%94%A8%E7%9A%84%E8%B6%85%E6%97%B6%EF%BC%8C%E5%B9%B6%E5%8F%91/</id>
    <published>2020-08-23T21:43:11.000Z</published>
    <updated>2020-08-23T21:44:10.267Z</updated>
    
    <content type="html"><![CDATA[<p>HTTP调用的时候，是通过HTTP协议进行一次网络请求，网络请求会有超时的可能性，我们需要考虑到：</p><ul><li>使用的框架设置的默认超时的合理性</li><li>超时后的请求重试需要考虑到服务端接口的幂等性 – 即任意多次执行所产生的影响是否与一次执行的影响相同</li><li>需要考虑框架是否会限制并发连接数，以免在服务并发很大的情况下，HTTP调用的并发数限制成为瓶颈 </li></ul><p>常用框架： </p><ul><li>Spring Cloud <ul><li>需要使用Feign进行声明式的服务调用</li></ul></li><li>Spring Boot<ul><li>使用Apache HttpClient进行服务调用</li></ul></li></ul><h1 id="1-如何配置连接超时"><a href="#1-如何配置连接超时" class="headerlink" title="1. 如何配置连接超时"></a>1. 如何配置连接超时</h1><ul><li><p>HTTP调用应用层走的是HTTP协议，但是网络层还是TCP/IP协议的</p><ul><li><p>TCP/ IP协议是面向连接的协议，在传输数据之前需要建立连接</p></li><li><p>网络框架会提供两个超时参数</p><ul><li><p>连接超时参数 ConnectTimeout</p><ul><li>建立连接阶段的最长等待时间</li><li>应该配置在1 - 5s之间，因为TCP的三次握手建立连接需要的时间实际上是非常短的，超出往往是网络或者防火墙配置的问题</li></ul></li><li><p>读取超时参数 ReadTimeout</p><ul><li><p>用来控制从Socket上读取数据的最长等待时间</p></li><li><p>读取超时包括</p><ul><li>网络问题</li><li>服务端处理业务逻辑的时间</li></ul></li><li><p>参数配置不应过大</p><ul><li>HTTP请求一般是同步调用，如果超时很长，在等待服务端返回数据的同时，客户端线程也在等待</li><li>当下游服务出现大量超时的时候，程序可能也会受到拖累创建大量线程，最终崩溃</li></ul></li></ul></li></ul></li></ul></li></ul><ul><li>首先对于超时本身<ul><li>是客户端和服务端需要都有贡献的</li><li>有一致的时间估计</li><li>平衡吞吐量和错误率</li></ul></li></ul><h1 id="2-HTTP调用并发问题"><a href="#2-HTTP调用并发问题" class="headerlink" title="2. HTTP调用并发问题"></a>2. HTTP调用并发问题</h1><p>如果使用Apache 的httpClient，在PoolingHttpClientConnectionManager当中，定义的参数： </p><ul><li>defaultMaxPerRoute = 2<ul><li>同一个主机最大的并发请求书为2</li></ul></li><li>maxTotal = 20<ul><li>主机的最大并发为20</li></ul></li></ul><pre><code>httpClient2 = HttpClients.custom().setMaxConnPerRoute(10).setMaxConnTotal(20).build();</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;HTTP调用的时候，是通过HTTP协议进行一次网络请求，网络请求会有超时的可能性，我们需要考虑到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用的框架设置的默认超时的合理性&lt;/li&gt;
&lt;li&gt;超时后的请求重试需要考虑到服务端接口的幂等性 – 即任意多次执行所产生的影响是否与一次执行的影响
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
      <category term="HTTP" scheme="https://www.llchen60.com/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>线程池创建: Executors  vs ThreadPoolExecutor</title>
    <link href="https://www.llchen60.com/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%9B%E5%BB%BA-Executors-vs-ThreadPoolExecutor/"/>
    <id>https://www.llchen60.com/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%9B%E5%BB%BA-Executors-vs-ThreadPoolExecutor/</id>
    <published>2020-08-16T22:17:49.000Z</published>
    <updated>2020-08-16T22:18:46.296Z</updated>
    
    <content type="html"><![CDATA[<p>工程上对于线程池的使用必不可少，很多人会选择使用Executors class定义的<code>newCachedThreadPool</code>以及<code>newFixedThreadPool</code>。这篇博文就稍微分析一下二者适用的场景，以及我们应该使用Executors的方法还是直接调用ThreadPoolExecutor来创建线程池。</p><p>首先让我们一起看看二者的源码</p><pre><code>   /**     * Creates a thread pool that reuses a fixed number of threads     * operating off a shared unbounded queue.  At any point, at most     * {@code nThreads} threads will be active processing tasks.     * If additional tasks are submitted when all threads are active,     * they will wait in the queue until a thread is available.     * If any thread terminates due to a failure during execution     * prior to shutdown, a new one will take its place if needed to     * execute subsequent tasks.  The threads in the pool will exist     * until it is explicitly {@link ExecutorService#shutdown shutdown}.     *     * @param nThreads the number of threads in the pool     * @return the newly created thread pool     * @throws IllegalArgumentException if {@code nThreads &lt;= 0}     */    public static ExecutorService newFixedThreadPool(int nThreads) {        return new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());    }    /**     * Creates a thread pool that creates new threads as needed, but     * will reuse previously constructed threads when they are     * available.  These pools will typically improve the performance     * of programs that execute many short-lived asynchronous tasks.     * Calls to {@code execute} will reuse previously constructed     * threads if available. If no existing thread is available, a new     * thread will be created and added to the pool. Threads that have     * not been used for sixty seconds are terminated and removed from     * the cache. Thus, a pool that remains idle for long enough will     * not consume any resources. Note that pools with similar     * properties but different details (for example, timeout parameters)     * may be created using {@link ThreadPoolExecutor} constructors.     *     * @return the newly created thread pool     */    public static ExecutorService newCachedThreadPool() {        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                      60L, TimeUnit.SECONDS,                                      new SynchronousQueue&lt;Runnable&gt;());    } </code></pre><p>二者对比，你会发现实际上他们都是调用的ThreadPoolExecutor,只是参数是不一样的。那让我们看看ThreadPoolExecutor的源码</p><pre><code>    /**     * Creates a new {@code ThreadPoolExecutor} with the given initial     * parameters and default thread factory and rejected execution handler.     * It may be more convenient to use one of the {@link Executors} factory     * methods instead of this general purpose constructor.     *     * @param corePoolSize the number of threads to keep in the pool, even     *        if they are idle, unless {@code allowCoreThreadTimeOut} is set     * @param maximumPoolSize the maximum number of threads to allow in the     *        pool     * @param keepAliveTime when the number of threads is greater than     *        the core, this is the maximum time that excess idle threads     *        will wait for new tasks before terminating.     * @param unit the time unit for the {@code keepAliveTime} argument     * @param workQueue the queue to use for holding tasks before they are     *        executed.  This queue will hold only the {@code Runnable}     *        tasks submitted by the {@code execute} method.     * @throws IllegalArgumentException if one of the following holds:&lt;br&gt;     *         {@code corePoolSize &lt; 0}&lt;br&gt;     *         {@code keepAliveTime &lt; 0}&lt;br&gt;     *         {@code maximumPoolSize &lt;= 0}&lt;br&gt;     *         {@code maximumPoolSize &lt; corePoolSize}     * @throws NullPointerException if {@code workQueue} is null     */    public ThreadPoolExecutor(int corePoolSize,                              int maximumPoolSize,                              long keepAliveTime,                              TimeUnit unit,                              BlockingQueue&lt;Runnable&gt; workQueue) {        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,             Executors.defaultThreadFactory(), defaultHandler);    }</code></pre><p>看一下其中需要的几个参数：</p><ul><li><p>corePoolSize</p><ul><li>在线程池中最少要保持的线程数量，哪怕已经超过了定义的keepAliveTime </li></ul></li><li><p>maximumPoolSize</p><ul><li>线程池允许的最大线程数量</li></ul></li><li><p>keepAliveTime</p><ul><li>当当前线程数超过核心线程数量的时候，就会检查闲置的线程，如果在这段时间没有新的任务，就暂停当前线程</li></ul></li><li><p>unit</p><ul><li>定义事件单位</li></ul></li><li><p>workQueue</p><ul><li>在任务还没有执行之前，被用来持有这些任务的</li><li>queue之后持有execute方法提交的Runnable任务</li></ul></li></ul><p>带着这些信息我们再来看Executors.newFixedThreadPool的定义，方法传入了线程数量，然后核心线程数和最大线程数被设为一样的数值，让我们来看看在不同情况下他的表现：</p><ul><li><p>任务数小于等于设定的线程数</p><ul><li>一切运行正常</li><li>限制的线程不会被关闭</li></ul></li><li><p>任务数大于设定的线程数</p><ul><li>任务会加入到队列当中，进行等待</li><li>值得注意的是在实例化LinkedBlockingQueue的时候，传入的参数是<code>this(Integer.MAX_VALUE);</code><ul><li>这意味着如果任务在线程中执行的时间非常长，任务可以在队列中堆积到无限大，最终结果会是内存被占满..程序崩溃</li></ul></li></ul></li></ul><p>而对于Executors.newCachedThreadPool来说，其定义的核心线程数量为0，最大线程数是<code>Integer.MAX_VALUE</code>,即理论上是可以有无限多的线程，keepAliveTime是60秒，使用的是SynchrounousQueue。</p><ul><li>当任务进来的时候<ul><li>会增加线程</li><li>有多少任务进来，就会使用ThreadFactory开多少线程，因为允许的最大线程数时无限大，所以可以一直这么开下去</li><li>而其workqueue是SynchrounousQueue,其大小始终为0，在这里我们可以直接任务当任务进来的时候，如果没有空闲的线程，会直接让ThreadFactory来构建新的线程了</li><li>那么当任务无限多的时候，就会创建无数多的线程，直接撑爆内存了</li></ul></li></ul><p>由此可以看出来使用Executors的两个方法直接构建线程池因为设定的参数是无界的，可能会导致OOM的错误，更好的方式是自己根据当前线程池的应用场景，来设定参数。</p><p>根据应用场景的不同，根据doc，我们有三大类的queue可以选择，分别为：</p><ul><li><p><code>Synchronous queue</code></p><ul><li>直接讲任务交给线程</li><li>自己本身不持有任何任务的</li><li>针对的应用场景可以是各个线程之间任务的执行有某些内在的联系，阻碍一个的执行可能会影响另外一个</li><li>为了不拒绝新的线程的创建，就必须设定线程池的大小为Integer.MAX_VALUE</li><li>这样如果处理速度低于新任务的提交速度的话，可能会导致非常非常大的线程池</li></ul></li><li><p><code>LinkedBlockingQueue</code></p><ul><li>使用没有边界的queue</li><li>这样当所有核心线程都忙碌的时候，任务就都会在队列当中排队</li><li>这种方式可以环节突发性的峰值，但是如果处理速度慢于任务堆积的速度，queue会变得很大</li></ul></li><li><p><code>ArrayBlockingQueue</code></p><ul><li>有限长的queue</li><li>这样可以防止资源耗尽，但是也很难做调整和优化</li><li>队列的大小和最大线程数相互影响，很难做到优化</li><li>使用大队列，小线程池可以减少对于CPU的使用，线程切换的损耗，但是单位时间处理速度不会太高</li><li>使用小队列，大线程池可以让CPU更忙碌，但是切换线程会有不小的损耗</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.ibm.com/developerworks/library/j-jtp0730/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/library/j-jtp0730/index.html</a> </li><li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;工程上对于线程池的使用必不可少，很多人会选择使用Executors class定义的&lt;code&gt;newCachedThreadPool&lt;/code&gt;以及&lt;code&gt;newFixedThreadPool&lt;/code&gt;。这篇博文就稍微分析一下二者适用的场景，以及我们应该使用Ex
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Executors" scheme="https://www.llchen60.com/tags/Executors/"/>
    
      <category term="ThreadPoolExecutor" scheme="https://www.llchen60.com/tags/ThreadPoolExecutor/"/>
    
  </entry>
  
  <entry>
    <title>AWS CDK Overview</title>
    <link href="https://www.llchen60.com/AWS-CDK-Overview/"/>
    <id>https://www.llchen60.com/AWS-CDK-Overview/</id>
    <published>2020-08-14T03:17:35.000Z</published>
    <updated>2020-08-14T03:18:06.405Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>AWS CDK </p><ul><li><p>Open source software development framework </p></li><li><p>Model and provision your cloud application resources</p></li><li><p>To resolve what issue? </p><ul><li>provision cloud applications is challenging cause require<ul><li>manual actions</li><li>custom scripts </li><li>maintain templates </li><li>domain specific languages </li></ul></li></ul></li><li><p>How does CDK resolve the issue?</p><ul><li>Provides with high level component that pre-configure cloud resources with proven defaults</li><li>Provision your resources through AWS CloudFormation </li></ul></li></ul></li></ul><h2 id="1-1-Workflow"><a href="#1-1-Workflow" class="headerlink" title="1.1 Workflow"></a>1.1 Workflow</h2><ul><li>Creating an Amazon ECS service with AWS Fargate launch type </li></ul><pre><code>public class MyEcsConstructStack extends Stack {    public MyEcsConstructStack(final Construct scope, final String id) {        this(scope, id, null);    }    public MyEcsConstructStack(final Construct scope, final String id,            StackProps props) {        super(scope, id, props);        Vpc vpc = Vpc.Builder.create(this, &quot;MyVpc&quot;).maxAzs(3).build();        Cluster cluster = Cluster.Builder.create(this, &quot;MyCluster&quot;)                .vpc(vpc).build();        ApplicationLoadBalancedFargateService.Builder.create(this, &quot;MyFargateService&quot;)                .cluster(cluster)                .cpu(512)                .desiredCount(6)                .taskImageOptions(                       ApplicationLoadBalancedTaskImageOptions.builder()                               .image(ContainerImage                                       .fromRegistry(&quot;amazon/amazon-ecs-sample&quot;))                               .build()).memoryLimitMiB(2048)                .publicLoadBalancer(true).build();    }}</code></pre><ul><li><p>Basic workflow</p><ul><li>create the app from a template provided by the AWS CDK</li><li>add code to the app to create resources within stacks</li><li>build the app </li><li>synthesize one or more stacks in the app to create an AWS CloudFormation template </li><li>deploy one or more stacks to your AWS account </li></ul></li><li><p>Benefits </p><ul><li>Could use logic when defining infrastructure </li><li>Use object-oriented techniques to create a model of system </li><li>Define high level abstractions</li></ul></li><li><p>Tools</p><ul><li><p><a href="https://docs.aws.amazon.com/cdk/latest/guide/cli.html" target="_blank" rel="noopener">CDK Toolkit</a> </p><ul><li>CLI for interacting with CDK apps </li><li>Enable developers to synthesize artifacts such as AWS CloudFormation templates, deploy stacks to development AWS accounts, and diff against a deployed stack to understand the impact of a code change </li></ul></li><li><p><a href="https://docs.aws.amazon.com/cdk/latest/guide/constructs.html" target="_blank" rel="noopener">AWS Construct Library</a></p><ul><li>contains constructs representing AWS resources </li><li>encapsulate the details of how to create resources for an Amazon or AWS service </li></ul></li></ul></li></ul><h2 id="1-1-1-Create-and-build-the-app"><a href="#1-1-1-Create-and-build-the-app" class="headerlink" title="1.1.1 Create and build the app"></a>1.1.1 Create and build the app</h2><pre><code>mkdir hello-cdk &amp;&amp; cd hello-cdkcdk init TEMPLATE --language LANGUAGE cdk init app --language java// In your IDE, import it as maven project mvn compile cdk ls </code></pre><h3 id="1-1-2-Add-an-Amazon-S3-Bucket"><a href="#1-1-2-Add-an-Amazon-S3-Bucket" class="headerlink" title="1.1.2 Add an Amazon S3 Bucket"></a>1.1.2 Add an Amazon S3 Bucket</h3><pre><code>// Add dependencies to pom.xml &lt;dependency&gt;    &lt;groupId&gt;software.amazon.awscdk&lt;/groupId&gt;    &lt;artifactId&gt;s3&lt;/artifactId&gt;    &lt;version&gt;${cdk.version}&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>Define an Amazon S3 bucket in the stack using L2 construct </p><pre><code>package com.myorg;import software.amazon.awscdk.core.*;import software.amazon.awscdk.services.s3.Bucket;public class HelloCdkStack extends Stack {    public HelloCdkStack(final Construct scope, final String id) {        this(scope, id, null);    }    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {        super(scope, id, props);        Bucket.Builder.create(this, &quot;MyFirstBucket&quot;)            .versioned(true).build();    }}</code></pre><h3 id="1-1-3-Systhesize-an-AWS-CloudFormation-Template"><a href="#1-1-3-Systhesize-an-AWS-CloudFormation-Template" class="headerlink" title="1.1.3 Systhesize an AWS CloudFormation Template"></a>1.1.3 Systhesize an AWS CloudFormation Template</h3><pre><code>cdk synth</code></pre><h3 id="1-1-4-Deploying-the-stack"><a href="#1-1-4-Deploying-the-stack" class="headerlink" title="1.1.4 Deploying the stack"></a>1.1.4 Deploying the stack</h3><p><code>cdk deploy</code></p><h3 id="1-1-5-Modifying-the-stack"><a href="#1-1-5-Modifying-the-stack" class="headerlink" title="1.1.5 Modifying the stack"></a>1.1.5 Modifying the stack</h3><pre><code>// after make your change cdk diff cdk deploy // Possibly destroy cdk destroy </code></pre><ul><li>Synthesize before deploying <h1 id="2-Basic-concepts"><a href="#2-Basic-concepts" class="headerlink" title="2. Basic concepts"></a>2. Basic concepts</h1></li></ul><h2 id="2-1-Constructs"><a href="#2-1-Constructs" class="headerlink" title="2.1 Constructs"></a>2.1 Constructs</h2><h3 id="2-1-1-Basics"><a href="#2-1-1-Basics" class="headerlink" title="2.1.1 Basics"></a>2.1.1 Basics</h3><ul><li><p>Constructs </p><ul><li><p>Basic building blocks </p></li><li><p>represents a cloud component, encapsulates everything AWS CloudFormation needs to create the component </p></li><li><p>[AWS Construct Library](<a href="https://docs.aws.amazon.com/cdk/api/latest/docs/aws-construct-library.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/cdk/api/latest/docs/aws-construct-library.html</a></p></li><li><p>defferent level of constructs </p><ul><li><p>CFN Resources/ L1 </p><ul><li>directly represent all of the AWS resources that are available in AWS CloudFormation </li><li>named as CfnXyz, where xyz is name of the resource </li><li><strong>When you use CFN resources, you must explicitly configure all resource properties, which requires a complete understanding of the details of the underlying AWS CloudFormation resource model</strong></li></ul></li><li><p>AWS Reousources/ L2 Constrcuts</p><ul><li>higher level, intent based API </li><li>provide defaults, boilerplate, and glue logic you’d be writing with a CFN resource construct</li><li>Offer convenient defaults thus reduce the need for the detail of AWS resources  </li></ul></li><li><p>Patterns - higher level constructs </p><ul><li>designed to help you complete common tasks in AWS, often involving multiple kinds of resources </li></ul></li></ul></li></ul></li></ul><pre><code>// L1 ConstructCfnBucket bucket = CfnBucket.Builder.create(this, &quot;MyBucket&quot;)                        .bucketName(&quot;MyBucket&quot;)                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()                                .allowedOrigins(Arrays.asList(&quot;*&quot;))                                .allowedMethods(Arrays.asList(&quot;GET&quot;))                                .build()))                            .build())                        .build();// L2 Constructimport software.amazon.awscdk.services.s3.*;public class HelloCdkStack extends Stack {    public HelloCdkStack(final Construct scope, final String id) {        this(scope, id, null);    }    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {        super(scope, id, props);        Bucket.Builder.create(this, &quot;MyFirstBucket&quot;)                .versioned(true).build();    }}</code></pre><h3 id="2-1-2-Hierarchy-Composition"><a href="#2-1-2-Hierarchy-Composition" class="headerlink" title="2.1.2 Hierarchy - Composition"></a>2.1.2 Hierarchy - Composition</h3><ul><li><p>Composition </p><ul><li>High level construct can be composed from any number of lower level constructs </li><li>In turn, those could be composed from even lower level constructs</li><li>Scoping pattern results in a hierarchy of constructs known as a construct tree </li></ul></li><li><p>Composition means you can define reusable components and share them like any other code </p></li></ul><h3 id="2-1-3-Initialization"><a href="#2-1-3-Initialization" class="headerlink" title="2.1.3 Initialization"></a>2.1.3 Initialization</h3><ul><li><p>Being implemented in classes that extend the Construct base class </p></li><li><p>3 parameters </p><ul><li><p>scope </p><ul><li>the construct within which this construct is defined </li></ul></li><li><p>id </p><ul><li>an identifier that much be unique within this scope </li><li>serves as a namespace for everything that’s encapsulated within the scope’s subtree </li><li>used to allocate unique identities such as resource names and AWS CloudFormation logical IDs </li></ul></li><li><p>props </p><ul><li>a set of properties or keyword arguments </li><li>define the construct’s initial configuration </li></ul></li></ul></li></ul><h1 id="3-Java-Related"><a href="#3-Java-Related" class="headerlink" title="3. Java Related"></a>3. Java Related</h1><h2 id="3-1-AWS-CDK-idioms-in-Java"><a href="#3-1-AWS-CDK-idioms-in-Java" class="headerlink" title="3.1 AWS CDK idioms in Java"></a>3.1 AWS CDK idioms in Java</h2><ul><li>Props <ul><li>expressed with Builder pattern </li><li>define a bundle of key/ value pairs that the construct uses to configure the resources it creates </li></ul></li></ul><pre><code>Bucket bucket = new Bucket(this, &quot;MyBucket&quot;, new BucketProps.Builder()                           .versioned(true)                           .encryption(BucketEncryption.KMS_MANAGED)                           .build());</code></pre><ul><li>missing values <ul><li>it will be represented by <code>null</code></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. Overview&quot;&gt;&lt;/a&gt;1. Overview&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;AWS CDK &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Op
      
    
    </summary>
    
    
      <category term="Cloud" scheme="https://www.llchen60.com/categories/Cloud/"/>
    
    
  </entry>
  
  <entry>
    <title>Git 流程</title>
    <link href="https://www.llchen60.com/Git-%E6%B5%81%E7%A8%8B/"/>
    <id>https://www.llchen60.com/Git-%E6%B5%81%E7%A8%8B/</id>
    <published>2020-08-12T00:41:26.000Z</published>
    <updated>2020-08-12T00:41:52.187Z</updated>
    
    <content type="html"><![CDATA[<p>解决git conflict永远都是件很让人头疼的事情，为了让生活更简单，还是需要设定正确的git流程的。现在有如下几种git 流程</p><h1 id="1-基本的Git-流程"><a href="#1-基本的Git-流程" class="headerlink" title="1. 基本的Git 流程"></a>1. 基本的Git 流程</h1><p>只有一个branch – master. 开发者直接commit进去，然后会进入到alpha，beta, gamma, prod等不同的生产状态当中。</p><p>一般来说，除非你在自己单独完成某项小任务，是很不推荐这样做的。</p><p>缺陷在于：</p><ul><li>代码上的合作变得很困难，可能会有多次冲突，需要逐次进行解决</li></ul><h1 id="2-Git-feature分支流程"><a href="#2-Git-feature分支流程" class="headerlink" title="2. Git feature分支流程"></a>2. Git feature分支流程</h1><p>当在同一个codebase我们有多个工程师共同工作的时候，使用feature分治就变成了必不可少的事情了。</p><p>如果现在有两个工程师在同一个branch上工作，来提交自己的代码，那最终一定是冲突不断的，很容易出现各种问题。</p><p>为了避免出现这种情况，两个开发者可以创建两个不同的分支，分别在自己的分治上来开发自己的项目。</p><p>这样做的好处是不用担心大量需要解决的冲突了。</p><h1 id="3-Git-feature分支流程与Develop分支"><a href="#3-Git-feature分支流程与Develop分支" class="headerlink" title="3. Git feature分支流程与Develop分支"></a>3. Git feature分支流程与Develop分支</h1><p>和上述的feature分支流程很类似，只是又加了一个Develop分支，在这个流程下，master 分支永远反映一个prod ready的状态。</p><p>无论何时，当小组想要将代码部署到prod的时候，他们从master分支来进行部署</p><p>develop branch反映的是带着最新的为了下次发布准备的所有改动。开发者fork develop 分支的代码，来做独立开发。一旦项目做好，经过了测试，就合并到develop分支当中，在develop分支来做充分的测试，然后再merge到master分支当中去。</p><p>这样做的好处是能够允许小组持续merge新的功能，做持续集成。不过过程相对比较麻烦。个人观点是在小规模的前提下，使用特征分支就足够了，再加上持续集成的工具，譬如Jerkins，很安全，效率也很不错。</p><p><a href="https://zepel.io/blog/5-git-workflows-to-improve-development/" target="_blank" rel="noopener">https://zepel.io/blog/5-git-workflows-to-improve-development/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;解决git conflict永远都是件很让人头疼的事情，为了让生活更简单，还是需要设定正确的git流程的。现在有如下几种git 流程&lt;/p&gt;
&lt;h1 id=&quot;1-基本的Git-流程&quot;&gt;&lt;a href=&quot;#1-基本的Git-流程&quot; class=&quot;headerlink&quot; tit
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="git" scheme="https://www.llchen60.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>Java Notes</title>
    <link href="https://www.llchen60.com/Java-Notes/"/>
    <id>https://www.llchen60.com/Java-Notes/</id>
    <published>2020-08-04T02:19:37.000Z</published>
    <updated>2020-08-21T03:01:01.558Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-并发"><a href="#1-并发" class="headerlink" title="1. 并发"></a>1. 并发</h1><h2 id="1-1-ThreadLocal复用问题"><a href="#1-1-ThreadLocal复用问题" class="headerlink" title="1.1 ThreadLocal复用问题"></a>1.1 ThreadLocal复用问题</h2><p>ThreadLocal适用于变量在线程间隔离，而在方法或类之间共享的场景。如果用户信息的获取比较昂贵，那么在ThreadLocal中缓存数据时比较合适的做法。</p><pre><code>private static final ThreadLocal&lt;Integer&gt; currentUser = ThreadLocal.withInitial(() -&gt; null);@GetMapping(&quot;wrong&quot;)public Map wrong(@RequestParam(&quot;userId&quot;) Integer userId) {    //设置用户信息之前先查询一次ThreadLocal中的用户信息    String before  = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();    //设置用户信息到ThreadLocal    currentUser.set(userId);    //设置用户信息之后再查询一次ThreadLocal中的用户信息    String after  = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();    //汇总输出两次查询结果    Map result = new HashMap();    result.put(&quot;before&quot;, before);    result.put(&quot;after&quot;, after);    return result;}</code></pre><p>上述例子当中，我们在设置前设置后都做了记录，来看threadLocal当中都记录了什么信息，。值得注意的是程序是运行在Tomcat当中的，执行程序的线程是Tomcat的工作线程，而Tomcat的工作线程是基于线程池的。</p><p>即会重用几个固定的线程，一旦线程重用，那么很可能首次从ThreadLocal获取的值是之前其他用户的请求遗留的值。这时ThreadLocal中的用户信息就是其他用户的信息了。</p><p>Take Away: </p><ol><li>代码中没用多线程不以为着你的程序没有使用多线程，Tomcat的Web服务器的业务代码，本身就运行在一个多线程环境当中</li><li>使用线程池处理数据就意味着线程是会被重用的，使用类似ThreadLocal工具来存放一些数据的时候，需要注意在代码运行完之后，显式去清空设置的数据。</li></ol><p>修正复用的问题的bug： </p><pre><code>private static final ThreadLocal&lt;Integer&gt; currentUser = ThreadLocal.withInitial(() -&gt; null);@GetMapping(&quot;right&quot;)public Map right(@RequestParam(&quot;userId&quot;) Integer userId) {    String before  = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();    currentUser.set(userId);    try {        String after = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();        Map result = new HashMap();        result.put(&quot;before&quot;, before);        result.put(&quot;after&quot;, after);        return result;    } finally {        //在finally代码块中删除ThreadLocal中的数据，确保数据不串        currentUser.remove();    }}</code></pre><h2 id="1-2-ConcurrentHashMap"><a href="#1-2-ConcurrentHashMap" class="headerlink" title="1.2 ConcurrentHashMap"></a>1.2 ConcurrentHashMap</h2><ul><li>ConcurrentHashMap是线程安全的哈希表容器，这里的线程安全是指原子性读写操作是线程安全的。</li><li>例子 – 10个线程一起来补充总共100个元素进去</li></ul><pre><code>    //线程个数    private static int THREAD_COUNT = 10;    //总元素数量    private static int ITEM_COUNT = 1000;    //帮助方法，用来获得一个指定元素数量模拟数据的ConcurrentHashMap    private ConcurrentHashMap&lt;String, Long&gt; getData(int count) {        return LongStream.rangeClosed(1, count)                .boxed()                .collect(Collectors.toConcurrentMap(i -&gt; UUID.randomUUID().toString(), Function.identity(),                        (o1, o2) -&gt; o1, ConcurrentHashMap::new));    }    @GetMapping(&quot;wrong&quot;)    public String wrong() throws InterruptedException {        ConcurrentHashMap&lt;String, Long&gt; concurrentHashMap = getData(ITEM_COUNT - 100);        //初始900个元素        log.info(&quot;init size:{}&quot;, concurrentHashMap.size());        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);        //使用线程池并发处理逻辑        forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, 10).parallel().forEach(i -&gt; {            //查询还需要补充多少个元素            int gap = ITEM_COUNT - concurrentHashMap.size();            log.info(&quot;gap size:{}&quot;, gap);            //补充元素            concurrentHashMap.putAll(getData(gap));        }));        //等待所有任务完成        forkJoinPool.shutdown();        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);        //最后元素个数会是1000吗？        log.info(&quot;finish size:{}&quot;, concurrentHashMap.size());        return &quot;OK&quot;;    }</code></pre><p>这样子执行的结果就是加入远远超过预期的数量，因为ConcurrentHashMap可以保证多个worker工作的时候不会互相干扰，但是无法保证看到的当前ConcurrentHashMap数据数量的同步</p><ul><li>Take Aways<ul><li>使用ConcurrentHashMap，不代表对其多个操作之间的状态是一致的，是没有其他线程在操作它的，如果需要确保，需要手动加锁</li><li>诸如size,isEmpty和containsValue等聚合方法，在并发情况下可能会反映ConcurrentHashMap的<strong>中间状态</strong>，因此在并发情况下，<strong>*这些方法的返回值只能用作参考，而不能用于流程控制</strong></li></ul></li></ul><p>解决方案就是通过加锁，使得同时只有一个线程可以操作ConcurrentHashMap</p><pre><code>@GetMapping(&quot;right&quot;)public String right() throws InterruptedException {    ConcurrentHashMap&lt;String, Long&gt; concurrentHashMap = getData(ITEM_COUNT - 100);    log.info(&quot;init size:{}&quot;, concurrentHashMap.size());    ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);    forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, 10).parallel().forEach(i -&gt; {        //下面的这段复合逻辑需要锁一下这个ConcurrentHashMap        synchronized (concurrentHashMap) {            int gap = ITEM_COUNT - concurrentHashMap.size();            log.info(&quot;gap size:{}&quot;, gap);            concurrentHashMap.putAll(getData(gap));        }    }));    forkJoinPool.shutdown();    forkJoinPool.awaitTermination(1, TimeUnit.HOURS);    log.info(&quot;finish size:{}&quot;, concurrentHashMap.size());    return &quot;OK&quot;;}</code></pre><ul><li>充分使用ConcurrentHashMap的特性<ul><li>例如面对一个使用Map来统计Key出现次数的场景</li><li>key范围为10， 最多使用10个并发，循环操作1000万次，每次操作累加随机的key</li><li>如果key不存在的话，首次设置值为1 </li></ul></li></ul><pre><code>    //循环次数    private static int LOOP_COUNT = 10000000;    //线程数量    private static int THREAD_COUNT = 10;    //元素数量    private static int ITEM_COUNT = 10;    private Map&lt;String, Long&gt; normaluse() throws InterruptedException {        ConcurrentHashMap&lt;String, Long&gt; freqs = new ConcurrentHashMap&lt;&gt;(ITEM_COUNT);        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);        forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&gt; {            //获得一个随机的Key            String key = &quot;item&quot; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);                    synchronized (freqs) {                              if (freqs.containsKey(key)) {                            //Key存在则+1                            freqs.put(key, freqs.get(key) + 1);                        } else {                            //Key不存在则初始化为1                            freqs.put(key, 1L);                        }                    }                }        ));        forkJoinPool.shutdown();        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);        return freqs;    }</code></pre><p>但是实际上ConcurrentHashMap本身是使用的Java自带的CAS操作的，在虚拟机层面确保了写入数据的原子性，比加锁的效率高很多，因此相较于直接加synchronized重量锁，我们可以通过computeIfAbsent()操作，和线程安全累加器LongAdder来更有效率的实现我们的统计目的</p><pre><code>private Map&lt;String, Long&gt; gooduse() throws InterruptedException {    ConcurrentHashMap&lt;String, LongAdder&gt; freqs = new ConcurrentHashMap&lt;&gt;(ITEM_COUNT);    ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);    forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&gt; {        String key = &quot;item&quot; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);                //利用computeIfAbsent()方法来实例化LongAdder，然后利用LongAdder来进行线程安全计数                freqs.computeIfAbsent(key, k -&gt; new LongAdder()).increment();            }    ));    forkJoinPool.shutdown();    forkJoinPool.awaitTermination(1, TimeUnit.HOURS);    //因为我们的Value是LongAdder而不是Long，所以需要做一次转换才能返回    return freqs.entrySet().stream()            .collect(Collectors.toMap(                    e -&gt; e.getKey(),                    e -&gt; e.getValue().longValue())            );}</code></pre><ul><li>上述代码中，直接使用了ConcurrentHashMap的原子性方法computeIfAbsent来做符合逻辑操作，判断Key是否存在Value，如果不存在则把Lambda表达式运行后的结果放入Map作为Value</li><li>LongAdder是线程安全的累加器，因此可以直接调用其increment()方法来做累加。</li></ul><h2 id="1-3-锁"><a href="#1-3-锁" class="headerlink" title="1.3 锁"></a>1.3 锁</h2><ul><li>加锁前需要知道锁和被保护的对象是不是一个层面上的<ul><li>静态字段属于类，需要类级别的锁来进行保护</li><li>非静态字段属于类实例，实例级别的锁就可以保护</li></ul></li></ul><pre><code>// 定义一个静态int字段counter和一个非静态的wrong方法，实现counter字段的累加操作class Data {    @Getter    private static int counter = 0;    public static int reset() {        counter = 0;        return counter;    }    public synchronized void wrong() {        counter++;    }}// 测试代码@GetMapping(&quot;wrong&quot;)public int wrong(@RequestParam(value = &quot;count&quot;, defaultValue = &quot;1000000&quot;) int count) {    Data.reset();    //多线程循环一定次数调用Data类不同实例的wrong方法    IntStream.rangeClosed(1, count).parallel().forEach(i -&gt; new Data().wrong());    return Data.getCounter();}</code></pre><p>输出结果，因为默认运行100万次，但是页面输出的并不会是100万。</p><ul><li>在非静态的wrong方法上加锁，只能够保证多个线程无法执行同一个实例的wrong方法，但无法保证其不会执行不同实例的wrong方法。而静态的counter是被共享的</li><li>解决方案时保证在一个实例的方法操作静态变量的时候，其他的实例无法操作这个静态变量</li></ul><pre><code>class Data {    @Getter    private static int counter = 0;    private static Object locker = new Object();    public void right() {        synchronized (locker) {            counter++;        }    }}</code></pre><ul><li>除此以外，对锁可以做的优化还包括<ul><li>精细化锁应用的范围</li><li>区分读写场景以及资源的访问冲突，考虑使用悲观锁还是乐观锁<ul><li>对于读写比例差异明显的场景，考虑使用ReentrantReadWriteLock细化区分读写锁，来提高性能</li><li>如果共享资源冲突概率不大，可以考虑使用StampedLock的乐观读的特性，进一步提高性能</li></ul></li></ul></li></ul><h2 id="1-4-线程池"><a href="#1-4-线程池" class="headerlink" title="1.4 线程池"></a>1.4 线程池</h2><p>开发当中，我们会使用各种池化技术来缓存创建昂贵的对象，比如线程池，连接池，内存池。一般是预先创建一些对象放入到池当中，使用的时候直接取出使用，用完归还以便复用。通过一定的策略调整池中缓存对象的数量，实现池的动态伸缩。</p><ul><li>应当手动进行线程池的声明<ul><li>Java Executors定义了一些快捷的工具办法，来帮助我们快速创建线程池</li><li>应当禁止使用这些方法来创建线程池，应当手动new ThreadPoolExecutor来创建线程池<ul><li>资源耗尽导致OOM问题<ul><li>newFixedThreadPool</li><li>newCachedThreadPool</li></ul></li></ul></li></ul></li></ul><h3 id="1-4-1-newFixedThreadPool-OOM-问题"><a href="#1-4-1-newFixedThreadPool-OOM-问题" class="headerlink" title="1.4.1 newFixedThreadPool OOM 问题"></a>1.4.1 newFixedThreadPool OOM 问题</h3><pre><code>    @GetMapping(&quot;oom1&quot;)    public void oom1() throws InterruptedException {        ThreadPoolExecutor threadPool = (ThreadPoolExecutor) Executors.newFixedThreadPool(1);        //打印线程池的信息，稍后我会解释这段代码        printStats(threadPool);         for (int i = 0; i &lt; 100000000; i++) {            threadPool.execute(() -&gt; {                String payload = IntStream.rangeClosed(1, 1000000)                        .mapToObj(__ -&gt; &quot;a&quot;)                        .collect(Collectors.joining(&quot;&quot;)) + UUID.randomUUID().toString();                try {                    TimeUnit.HOURS.sleep(1);                } catch (InterruptedException e) {                }                log.info(payload);            });        }        threadPool.shutdown();        threadPool.awaitTermination(1, TimeUnit.HOURS);    }</code></pre><ul><li>日志显示出现了OOM</li><li>newFixedThreadPool源码：</li></ul><pre><code>    public static ExecutorService newFixedThreadPool(int nThreads) {        return new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());    }    public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt;            implements BlockingQueue&lt;E&gt;, java.io.Serializable {        ...        /**         * Creates a {@code LinkedBlockingQueue} with a capacity of         * {@link Integer#MAX_VALUE}.         */        public LinkedBlockingQueue() {            this(Integer.MAX_VALUE);        }    ...    }</code></pre><ul><li>直接使用了一个LinkedBlockingQueue，而默认构造方法是一个Integer.MAX_VALUE长度的队列，是无界的。</li><li>尽管使用newFixedThreadPool可以把工作线程控制在固定的数量上，但任务队列是无界的。如果任务比较多并且执行比较慢的话，队列可能会迅速积压，撑爆内存导致OOM</li></ul><h3 id="1-4-2-newCachedThreadPool-OOM问题"><a href="#1-4-2-newCachedThreadPool-OOM问题" class="headerlink" title="1.4.2 newCachedThreadPool OOM问题"></a>1.4.2 newCachedThreadPool OOM问题</h3><pre><code>public static ExecutorService newCachedThreadPool() {    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                  60L, TimeUnit.SECONDS,                                  new SynchronousQueue&lt;Runnable&gt;());</code></pre><ul><li>线程池最大线程数为Integer.MAX_VALUE，是没有上限的，其工作队列SynchronizedQueue是一个没有存储空间的阻塞队列。</li><li>SynchronousQueue是没有存储空间的阻塞队列，有请求到来的时候，必须要找到一条工作线程来处理，如果当前没有空闲的线程就再创建一条新的</li></ul><h3 id="1-4-3-线程池配置Best-Practice"><a href="#1-4-3-线程池配置Best-Practice" class="headerlink" title="1.4.3 线程池配置Best Practice"></a>1.4.3 线程池配置Best Practice</h3><ul><li><p>根据自己的场景，并发情况来评估线程池的几个核心参数，需要设置有界的工作队列和可控的线程数</p><ul><li>核心线程数</li><li>最大线程数</li><li>线程回收策略</li><li>工作队列的类型</li><li>拒绝策略</li></ul></li><li><p>为线程池指定有意义的名称，来方便问题的排查，当出现线程数暴增，线程死锁，线程占用大量CPU这类问题的时候，会抓取线程栈来进行分析，这个时候有意义的线程名称，可以很大程度上方便我们对问题的定位</p></li><li><p>Metrics， alarm来观察线程池的状态</p></li></ul><ul><li>线程池特性<ul><li>不会初始化corePoolSize个线程，有任务来了才创建工作线程</li><li>当核心线程满了之后不会立即扩容线程池，而是把任务堆积到工作队列当中</li><li>当工作队列满了之后扩容线程池，一直到线程个数达到maximumPoolSize为止</li><li>如果队列已满其达到了最大线程后还有任务来，就按照拒绝策略来处理</li><li>当线程数大于核心线程数时，线程等待KeepAliveTime后还没有任务需要处理的话，收缩线程到核心线程数</li></ul></li></ul><pre><code>@GetMapping(&quot;right&quot;)public int right() throws InterruptedException {    //使用一个计数器跟踪完成的任务数    AtomicInteger atomicInteger = new AtomicInteger();    //创建一个具有2个核心线程、5个最大线程，使用容量为10的ArrayBlockingQueue阻塞队列作为工作队列的线程池，使用默认的AbortPolicy拒绝策略    ThreadPoolExecutor threadPool = new ThreadPoolExecutor(            2, 5,            5, TimeUnit.SECONDS,            new ArrayBlockingQueue&lt;&gt;(10),            new ThreadFactoryBuilder().setNameFormat(&quot;demo-threadpool-%d&quot;).get(),            new ThreadPoolExecutor.AbortPolicy());    printStats(threadPool);    //每隔1秒提交一次，一共提交20次任务    IntStream.rangeClosed(1, 20).forEach(i -&gt; {        try {            TimeUnit.SECONDS.sleep(1);        } catch (InterruptedException e) {            e.printStackTrace();        }        int id = atomicInteger.incrementAndGet();        try {            threadPool.submit(() -&gt; {                log.info(&quot;{} started&quot;, id);                //每个任务耗时10秒                try {                    TimeUnit.SECONDS.sleep(10);                } catch (InterruptedException e) {                }                log.info(&quot;{} finished&quot;, id);            });        } catch (Exception ex) {            //提交出现异常的话，打印出错信息并为计数器减一            log.error(&quot;error submitting task {}&quot;, id, ex);            atomicInteger.decrementAndGet();        }    });    TimeUnit.SECONDS.sleep(60);    return atomicInteger.intValue();}</code></pre><h3 id="1-4-4-线程池本身不复用"><a href="#1-4-4-线程池本身不复用" class="headerlink" title="1.4.4 线程池本身不复用"></a>1.4.4 线程池本身不复用</h3><pre><code>@GetMapping(&quot;wrong&quot;)public String wrong() throws InterruptedException {    ThreadPoolExecutor threadPool = ThreadPoolHelper.getThreadPool();    IntStream.rangeClosed(1, 10).forEach(i -&gt; {        threadPool.execute(() -&gt; {            ...            try {                TimeUnit.SECONDS.sleep(1);            } catch (InterruptedException e) {            }        });    });    return &quot;OK&quot;;}class ThreadPoolHelper {    public static ThreadPoolExecutor getThreadPool() {        //线程池没有复用        return (ThreadPoolExecutor) Executors.newCachedThreadPool();    }}</code></pre><p>通过这种方式，会不停产生新的线程，整个业务程序会不停产生新的threadPool，因为newCachedThreadPool的核心线程数是0， keepAliveTime是60秒，过了60s以后线程就会被回收了。</p><h3 id="1-4-5-线程池的使用策略"><a href="#1-4-5-线程池的使用策略" class="headerlink" title="1.4.5 线程池的使用策略"></a>1.4.5 线程池的使用策略</h3><ul><li>对于线程池如何使用，放什么样的任务进去，是需要根据任务的轻重缓急来指定线程池的核心参数，包括线程数，回收策略和任务队列<ul><li>对于执行比较慢，数量不大的IO任务，可以考虑更多的线程数，而不需要太大的队列</li><li>对于吞吐量比较大的计算型任务，线程数量不应该过多，可以是CPU核心数，或者核心数 x 2。<ul><li>因为线程是需要调度到某个CPU当中进行的，如果任务本身是CPU绑定的任务，那么过多的线程只会增加线程切换的开销，并不能提升吞吐量</li><li>需要比较长的队列来做缓冲</li></ul></li></ul></li></ul><h1 id="2-连接池"><a href="#2-连接池" class="headerlink" title="2. 连接池"></a>2. 连接池</h1><h2 id="2-1-连接池定义"><a href="#2-1-连接池定义" class="headerlink" title="2.1 连接池定义"></a>2.1 连接池定义</h2><ul><li>对外提供获得连接</li><li>归还连接的接口给客户端使用</li><li>暴露最小空闲连接数，最大连接数等可配置参数</li><li>内部实现连接建立，连接心跳保持，连接管理，空闲连接回收，连接可用性检测等功能</li></ul><p><img src="https://i.loli.net/2020/08/21/8qialtrxJoB2MNF.png" alt="连接池.png"></p><ul><li>应用场景<ul><li>数据库连接池</li><li>Redis连接池</li><li>HTTP连接池</li></ul></li></ul><h2 id="2-2-应用场景"><a href="#2-2-应用场景" class="headerlink" title="2.2 应用场景"></a>2.2 应用场景</h2><h3 id="2-2-1-判断客户端SDK是否基于连接池"><a href="#2-2-1-判断客户端SDK是否基于连接池" class="headerlink" title="2.2.1 判断客户端SDK是否基于连接池"></a>2.2.1 判断客户端SDK是否基于连接池</h3><ul><li><p>使用第三方客户端进行网络通信的时候，需要确定客户端SDK是否是基于连接池技术实现的</p><ul><li><p>TCP是面向连接的基于字节流的协议</p><ul><li><p>面向连接</p><ul><li>连接需要先创建，需要先做三次握手，是有开销的</li></ul></li><li><p>基于字节流</p><ul><li>字节是发送数据的最小单元</li><li>TCP是数据读写的通道，本身不知道哪些是完整的消息体，也不知道是否有多个客户端在使用同一个TCP连接</li></ul></li></ul></li></ul></li><li><p>客户端SDK对外提供API的方式</p><ul><li>连接池和连接分离的 API：有一个 XXXPool 类负责连接池实现，先从其获得连接 XXXConnection，然后用获得的连接进行服务端请求，完成后使用者需要归还连接。通常，XXXPool 是线程安全的，可以并发获取和归还连接，而 XXXConnection 是非线程安全的。对应到连接池的结构示意图中，XXXPool 就是右边连接池那个框，左边的客户端是我们自己的代码</li><li>内部带有连接池的 API：对外提供一个 XXXClient 类，通过这个类可以直接进行服务端请求；这个类内部维护了连接池，SDK 使用者无需考虑连接的获取和归还问题。一般而言，XXXClient 是线程安全的。对应到连接池的结构示意图中，整个 API 就是蓝色框包裹的部分</li><li>非连接池的 API：一般命名为 XXXConnection，以区分其是基于连接池还是单连接的，而不建议命名为 XXXClient 或直接是 XXX。直接连接方式的 API 基于单一连接，每次使用都需要创建和断开连接，性能一般，且通常不是线程安全的。对应到连接池的结构示意图中，这种形式相当于没有右边连接池那个框，客户端直接连接服务端创建连接</li></ul></li></ul><h3 id="2-2-2-复用连接池"><a href="#2-2-2-复用连接池" class="headerlink" title="2.2.2 复用连接池"></a>2.2.2 复用连接池</h3><ul><li>创建连接池的时候很可能一次性创建了多个连接，大多数连接池考虑到性能，会在初始化的时候维护一定数量的最小连接（毕竟初始化连接池的过程一般是一次性的），可以直接使用。如果每次使用连接池都按需创建连接池，那么很可能你只用到一个连接，但是创建了 N 个连接</li><li>连接池有管理模块，会有闲置超时，定时来回收闲置的连接，将活跃连接数降到最低连接的配置值，以此减轻服务端的压力</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-并发&quot;&gt;&lt;a href=&quot;#1-并发&quot; class=&quot;headerlink&quot; title=&quot;1. 并发&quot;&gt;&lt;/a&gt;1. 并发&lt;/h1&gt;&lt;h2 id=&quot;1-1-ThreadLocal复用问题&quot;&gt;&lt;a href=&quot;#1-1-ThreadLocal复用问题&quot; cla
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Java" scheme="https://www.llchen60.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>设计模式-行为型-备忘录模式</title>
    <link href="https://www.llchen60.com/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/"/>
    <id>https://www.llchen60.com/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/</id>
    <published>2020-07-30T04:06:40.000Z</published>
    <updated>2020-07-30T04:07:06.831Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-备忘录模式的原理与实现"><a href="#1-备忘录模式的原理与实现" class="headerlink" title="1. 备忘录模式的原理与实现"></a>1. 备忘录模式的原理与实现</h1><ul><li>snapshot模式 <ul><li>Memento Design Pattern </li><li>Captures and externalizes an object’s internal state so that it can be restored later, all without violating encapsulation </li><li>在不违背封装原则的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便之后恢复对象先前的状态。<ul><li>存储副本以便后期恢复</li><li>在不违背封装原则的前提下，进行对象的备份和恢复</li></ul></li></ul></li></ul><pre><code>    public class InputText {      private StringBuilder text = new StringBuilder();      public String getText() {        return text.toString();      }      public void append(String input) {        text.append(input);      }      public Snapshot createSnapshot() {        return new Snapshot(text.toString());      }      public void restoreSnapshot(Snapshot snapshot) {        this.text.replace(0, this.text.length(), snapshot.getText());      }    }    public class Snapshot {      private String text;      public Snapshot(String text) {        this.text = text;      }      public String getText() {        return this.text;      }    }    public class SnapshotHolder {      private Stack&lt;Snapshot&gt; snapshots = new Stack&lt;&gt;();      public Snapshot popSnapshot() {        return snapshots.pop();      }      public void pushSnapshot(Snapshot snapshot) {        snapshots.push(snapshot);      }    }    public class ApplicationMain {      public static void main(String[] args) {        InputText inputText = new InputText();        SnapshotHolder snapshotsHolder = new SnapshotHolder();        Scanner scanner = new Scanner(System.in);        while (scanner.hasNext()) {          String input = scanner.next();          if (input.equals(&quot;:list&quot;)) {            System.out.println(inputText.toString());          } else if (input.equals(&quot;:undo&quot;)) {            Snapshot snapshot = snapshotsHolder.popSnapshot();            inputText.restoreSnapshot(snapshot);          } else {            snapshotsHolder.pushSnapshot(inputText.createSnapshot());            inputText.append(input);          }        }      }    }</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-备忘录模式的原理与实现&quot;&gt;&lt;a href=&quot;#1-备忘录模式的原理与实现&quot; class=&quot;headerlink&quot; title=&quot;1. 备忘录模式的原理与实现&quot;&gt;&lt;/a&gt;1. 备忘录模式的原理与实现&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;snapshot模式 &lt;ul&gt;
&lt;l
      
    
    </summary>
    
    
      <category term="SystemDesign" scheme="https://www.llchen60.com/categories/SystemDesign/"/>
    
    
      <category term="备忘录模式" scheme="https://www.llchen60.com/tags/%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>《目标：简单而有效的常识管理》</title>
    <link href="https://www.llchen60.com/%E3%80%8A%E7%9B%AE%E6%A0%87%EF%BC%9A%E7%AE%80%E5%8D%95%E8%80%8C%E6%9C%89%E6%95%88%E7%9A%84%E5%B8%B8%E8%AF%86%E7%AE%A1%E7%90%86%E3%80%8B/"/>
    <id>https://www.llchen60.com/%E3%80%8A%E7%9B%AE%E6%A0%87%EF%BC%9A%E7%AE%80%E5%8D%95%E8%80%8C%E6%9C%89%E6%95%88%E7%9A%84%E5%B8%B8%E8%AF%86%E7%AE%A1%E7%90%86%E3%80%8B/</id>
    <published>2020-07-27T00:51:12.000Z</published>
    <updated>2020-08-01T04:04:04.970Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-企业问题的着手点"><a href="#1-企业问题的着手点" class="headerlink" title="1. 企业问题的着手点"></a>1. 企业问题的着手点</h1><ul><li><p>着眼于每个环节的改善 vs 从系统视角着手</p></li><li><p>系统</p><ul><li>首先要掌握和妥善处理这个系统内各个环节间的互动关系</li><li>TOC – 希望能够指导企业如何集中利用有限资源，将其用在整个系统中最重要的地方，来达到最大的效益。</li></ul></li><li><p>现状</p><ul><li>企业势必会遇到无数问题<ul><li>而这些问题往往会使得管理人员废寝忘食，疲于奔命</li><li>需要去寻找在这些问题背后，是受到什么东西支配着的，有没有什么规律法则和秩序可以遵循</li></ul></li></ul></li></ul><h1 id="2-TOC"><a href="#2-TOC" class="headerlink" title="2. TOC"></a>2. TOC</h1><h2 id="2-1-目标是什么？"><a href="#2-1-目标是什么？" class="headerlink" title="2.1 目标是什么？"></a>2.1 目标是什么？</h2><ul><li><p>赚钱 目标</p><ul><li><p>本质就是赚钱 – 下述的是具体的方法</p><ul><li>采购发挥成本效益</li><li>雇佣好的人才</li><li>高科技，生产有品质的产品</li><li>销售有品质的产品</li><li>争取市场占有率</li><li>良好的沟通，顾客满意度</li></ul></li><li><p>关注指标</p><ul><li>利润</li><li>投资回报率</li><li>现金流量</li></ul></li><li><p>将实际运作状况和关注的各个指标再连接起来，如何做连接呢？？？？？？？？？？  – 用你建立的指标来表达你的目标</p><ul><li>有效产出 throughput<ul><li>系统通过销售获取金钱的速度</li></ul></li><li>存货 inventory<ul><li>整个系统投资在采购上的钱</li><li>采购的是打算卖出去的东西</li><li>可以借销售回收的投资都算是存货</li></ul></li><li>营运费用  operationalExpense<ul><li>系统为了把存货转为有效产出而花的钱 </li></ul></li></ul></li></ul></li></ul><h2 id="2-2-如何达成目标"><a href="#2-2-如何达成目标" class="headerlink" title="2.2 如何达成目标"></a>2.2 如何达成目标</h2><ul><li><p>一些列详尽的指标</p><ul><li>在改善一个指标的时候，要思考对其他指标的影响</li><li>单纯面向一个指标的改善可能对整个企业的改善并不是最有利的</li></ul></li><li><p>依存关系</p><ul><li>在一条链上，越到下游受影响越大，牛鞭效应，因为上游不确定太大，平均时间无法说明每天的实际状况</li><li>下游只能追上上游的速度，而不能超过上游的速度，因此不会是各种不同速度的相互抵消平均，而会是统计波动的累积</li><li>有效产出要看的是最终端的产出，即要看的是整体生产环节这个角度上的生产效率</li><li>优先解决瓶颈！ </li></ul></li><li><p>统计波动</p><ul><li>生产率的波动</li><li>生产线最后部分的产能应该比开始的时候高，需要能够处理更大的波动</li></ul></li><li><p>区分资源</p><ul><li><p>瓶颈资源</p><ul><li>产能等于或少于其需求</li><li>当出现瓶颈的时候，其成本已不能按照单环节的成本来计算了，相反的，他直接影响了产品的产出，所以要从全局成本的角度来进行考虑。</li><li>制定优先级，严格按照优先级顺序来执行</li></ul></li><li><p>非瓶颈资源</p><ul><li>产能大于需求</li></ul></li><li><p>需要在产品在工厂当中的流量和市场需求之间获取平衡</p></li></ul></li></ul><h2 id="2-3-Under-the-hood"><a href="#2-3-Under-the-hood" class="headerlink" title="2.3 Under the hood"></a>2.3 Under the hood</h2><p>一群人如何试图了解世界运转的窍门，并且因此改善周遭的一切。</p><p>科学代表着的是我们对于这个世界如何运作，以及为何如此运作的理解。但是他也只代表着我们现在所知的。</p><p>没有绝对的真理，绝对的真理反而会阻碍我们追求更深入的理解。</p><h2 id="2-4-制约理论"><a href="#2-4-制约理论" class="headerlink" title="2.4 制约理论"></a>2.4 制约理论</h2><ul><li><p>任何系统都至少存在着一个制约因素 – 瓶颈，否则它就可能有无限的产出。</p></li><li><p>核心步骤</p><ul><li><p>寻找约束</p><ul><li>确定生产速度和需求速度</li></ul></li><li><p>利用约束</p><ul><li>最大限度开发利用瓶颈工序，使得瓶颈工序产出量最大化</li></ul></li><li><p>服从约束</p><ul><li>使得企业的所有其他活动服从关于约束的各种措施，确保企业的所有活动，都是基于最大化利用瓶颈工序而展开的</li></ul></li><li><p>打破约束</p><ul><li>如果无法有效提高瓶颈工序的利用率，就需要采取其他方法来打破约束</li></ul></li><li><p>寻找新的约束</p><ul><li>重新寻找新的约束，重新解决问题</li></ul></li></ul></li></ul><h1 id="3-案例分析"><a href="#3-案例分析" class="headerlink" title="3. 案例分析"></a>3. 案例分析</h1><h2 id="3-1-现状分析"><a href="#3-1-现状分析" class="headerlink" title="3.1 现状分析"></a>3.1 现状分析</h2><ul><li><p>工厂</p><ul><li><p>技术，机器齐备</p></li><li><p>员工</p><ul><li>优质</li><li>技术实力过硬</li></ul></li><li><p>良好的工会关系</p></li><li><p>问题</p><ul><li>无法按时交付</li></ul></li></ul></li><li><p>当你升级机器了以后，真的能够提升效率么？ </p><ul><li><p>宣传当中，升级了机器，效率会提高，即单位时间生产速度会得到提升</p></li><li><p>问题在于</p><ul><li>会解雇人么？ 即生产成本得到降低了么？</li><li>出货数量有提升么？ </li><li>中间生产物的堆积量以及平均存储时间怎么样呢？ </li></ul></li><li><p>回到上述问题，首先要做的是对生产力给一个更合理的定义</p><ul><li>怎么样才算有生产力？ <ul><li>工作上的输出</li><li>通过目标来量化自己的生产力</li><li>能更接近目标的行动才是有生产力的行动</li><li>所以要问的是你的目标到底是什么</li></ul></li></ul></li></ul></li><li><p>窘境</p><ul><li>将人在做事和能带来效益等价</li><li>通过调动人员来保证有事可做？ </li><li>看到的各种数据报表当中的数据真的能够反映出赚钱能力么？ <ul><li>做满工作时数？ </li><li>产品成本？</li><li>直接人工差异？ </li></ul></li></ul></li></ul><h2 id="3-2-策略"><a href="#3-2-策略" class="headerlink" title="3.2 策略"></a>3.2 策略</h2><ul><li><p>thought 1: 通过改变各个环节的在供应链当中的顺序，尝试缓解依存关系； 尝试通过增加机器，缓解某个缓解的瓶颈</p><ul><li>投入成本高</li><li>时间长</li><li>既定工序难以改变</li></ul></li><li><p>thought 2：识别出瓶颈之后，分析瓶颈处机器的时间利用</p><ul><li>人需要按照工会要求每4小时休息30min，但是机器需要尽可能运转</li><li>质检不应该只放在成品前，在瓶颈前就进行检查，确保瓶颈处加工的产品在那个时刻是合格的，相当于省了加工坏损品的时间 </li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zhuanlan.zhihu.com/p/51536566" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/51536566</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-企业问题的着手点&quot;&gt;&lt;a href=&quot;#1-企业问题的着手点&quot; class=&quot;headerlink&quot; title=&quot;1. 企业问题的着手点&quot;&gt;&lt;/a&gt;1. 企业问题的着手点&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;着眼于每个环节的改善 vs 从系统视角着手&lt;/p&gt;
&lt;
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
  </entry>
  
</feed>
