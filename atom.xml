<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Leilei&#39;s Blog | Á£äÁ£äÁöÑÂçöÂÆ¢</title>
  
  <subtitle>Because it&#39;s there</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.llchen60.com/"/>
  <updated>2022-01-29T02:20:03.851Z</updated>
  <id>https://www.llchen60.com/</id>
  
  <author>
    <name>Leilei Chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Real time data‚Äôs unifying abstraction</title>
    <link href="https://www.llchen60.com/Real-time-data%E2%80%99s-unifying-abstraction/"/>
    <id>https://www.llchen60.com/Real-time-data%E2%80%99s-unifying-abstraction/</id>
    <published>2022-01-29T02:14:20.000Z</published>
    <updated>2022-01-29T02:20:03.851Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Real-time-data‚Äôs-unifying-abstraction"><a href="#Real-time-data‚Äôs-unifying-abstraction" class="headerlink" title="Real time data‚Äôs unifying abstraction"></a>Real time data‚Äôs unifying abstraction</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>Logs play a key role in distributed data systems and real time application architectures.<ul><li>write ahead log</li><li>commit log</li><li>transaction logs</li></ul></li></ul><h1 id="2-What-is-a-log"><a href="#2-What-is-a-log" class="headerlink" title="2. What is a log?"></a>2. What is a log?</h1><h2 id="2-1-Some-Concepts"><a href="#2-1-Some-Concepts" class="headerlink" title="2.1 Some Concepts"></a>2.1 Some Concepts</h2><ul><li>Storage abstraction<ul><li>append only</li><li>totally ordered sequence of records ordered by time</li></ul></li><li>Records<ul><li>appended to the end of the log</li><li>read from left to right</li><li>each entry has a unique sequential log entry number</li></ul></li><li>Log<ul><li>record what happened and when</li><li>for distributed system, that‚Äôs the very heart of the problem</li><li>types<ul><li>text logs<ul><li>meant primarily for humans to read</li></ul></li><li>journal/ data logs<ul><li>built for programmatic access</li></ul></li></ul></li></ul></li></ul><h2 id="2-2-Log-in-different-scenario"><a href="#2-2-Log-in-different-scenario" class="headerlink" title="2.2 Log in different scenario"></a>2.2 Log in different scenario</h2><h3 id="2-2-1-Logs-in-DB"><a href="#2-2-1-Logs-in-DB" class="headerlink" title="2.2.1 Logs in DB"></a>2.2.1 Logs in DB</h3><ul><li>Function 1: Authoritative source for restoring data<ul><li>DB need to keep in sync the variety of data structures and indexes in the presense of crashes</li><li>To make this atomic and durable, a db uses a log to <strong>write out information about the records</strong> they will be modifying, <strong>before applying the changes</strong> to all the various data structures it maintains</li><li>Since the log is <strong>immediately persisted</strong> it is used as the <strong>authoritative source</strong> in restoring all other persistent structures in the event of a crash.</li></ul></li><li>Function 2: Replicating data between DBs<ul><li>Oracle, MySQL and Postgres SQL include <strong>log shipping protocols</strong> to <strong>transmit portions of log to replica databases</strong> which act as slaves</li></ul></li></ul><h3 id="2-2-2-Logs-in-distributed-systems"><a href="#2-2-2-Logs-in-distributed-systems" class="headerlink" title="2.2.2 Logs in distributed systems"></a>2.2.2 Logs in distributed systems</h3><ul><li>Log Centric Approach</li></ul><aside>üí° State Machine Replication Principle: If two identical, deterministic processes begin in the same state and get the same inputs in the same order, they will produce the same output and end in the same state.</aside><ul><li>we could reduce the problem of making multiple machines all do the same thing to the problem of <strong>implementing a distributed consistent log to feed these processes input</strong><ul><li>squeeze all the non-determinism out of the input stream to ensure that each replica processing this input stays in sync.</li><li>time stamps that index the log now act as <strong>the clock for the state of the replicas</strong>‚Äîyou can describe each replica by a single number, the timestamp for the maximum log entry it has processed.</li></ul></li></ul><h1 id="3-Log-Types"><a href="#3-Log-Types" class="headerlink" title="3. Log Types"></a>3. Log Types</h1><ul><li>What we could put in log<ul><li>log the incoming requests to a service</li><li>the state changes the service undergoes in response to request</li><li>the transformation commands it executes.</li></ul></li><li>For DB usage<ul><li>physical logging<ul><li>log the contents of each row that is changed</li></ul></li><li>logical logging<ul><li>log not the changed rows but the SQL commands that lead to the row chagnes</li></ul></li></ul></li><li>For Distributed Systems to process and replicate<ul><li>Primary Backup<ul><li>elect one replica as the leader</li><li>allow this leader to process requests in the order they arrive</li><li>log out the changes to its state from processing the requests.</li><li>The other replicas apply in order the state changes the leader makes so that they will be in sync and ready to take over as leader should the leader fail.</li><li><strong>backup will copy the result from the primary, no logical action to walk through all action primary did</strong></li></ul></li></ul></li></ul><pre><code>- State Machine Replication    - active-active model where we keep a log of the incoming requests and each replica processes each request    - **each machine will do real execution, do the logical stuff**    ![State Machine Replication](https://s2.loli.net/2022/01/29/6JtLFNpmXBYW9wO.png)</code></pre><aside>üí° Below 3 sections has a centric idea:  Log as a stand-alone service. The usefulness of the log comes from simple function that the log provides: **producing a persistent, re-playable record of history**. At the core of these problems is the ability to **have many machines playback history at their own rate in a deterministic manner**</aside><h1 id="4-Changelog-in-Database"><a href="#4-Changelog-in-Database" class="headerlink" title="4. Changelog in Database"></a>4. Changelog in Database</h1><ul><li>duality between a log of changes and a table<ul><li>The log is similar to the list of all credits and debits and bank processes;</li><li>a table is all the current account balances.</li><li>If you have a log of changes, you can apply these changes in order to create the table capturing the current state.</li></ul></li><li>if you have a table taking updates, you can record these changes and publish a ‚Äúchangelog‚Äù of all the updates to the state of the table. This changelog is exactly what you need to <strong>support near-real-time replicas</strong>.</li><li>Table support data at rest and logs capture changes</li></ul><aside>üí° The magic of the log is that if it‚Äôs complete log of changes, it holds not only the contents of the final version of the table, but also allows recreating all other versions that might have existed. That‚Äôs a backup of every previous state of the table</aside><h1 id="5-Data-Integration"><a href="#5-Data-Integration" class="headerlink" title="5. Data Integration"></a>5. Data Integration</h1><blockquote><p>Make all of an organization‚Äôs data easily available in all its storage and processing systems</p></blockquote><h2 id="5-1-Expected-workflow-for-data-integration"><a href="#5-1-Expected-workflow-for-data-integration" class="headerlink" title="5.1 Expected workflow for data integration"></a>5.1 Expected workflow for data integration</h2><ul><li>Definition in author‚Äôs scope: Making all the data an organization has available in all its services and systems.</li><li>Effective Use of Data<ul><li>Capture all relevant data</li><li>Put it together in an applicable processing env<ul><li>real time query system</li><li>text files</li><li>python scripts, etc.</li></ul></li><li>Infra to process data<ul><li>mapReduce</li><li>Real time query systems</li></ul></li><li>Good data models and consistent well understood semantics</li><li>Sophisticated processing<ul><li>visualization</li><li>reporting</li><li>algorithmic processing and prediction</li></ul></li></ul></li></ul><h2 id="5-2-Problem1-The-event-data-firehose"><a href="#5-2-Problem1-The-event-data-firehose" class="headerlink" title="5.2 Problem1: The event data firehose"></a>5.2 Problem1: The event data firehose</h2><ul><li>Event data rising</li><li>google‚Äôs fortune is actually generated by a relevance pipeline built on clicks and impressions ‚Äî events</li><li>that would be huge amount of data,</li></ul><h2 id="5-3-Problem-2-The-explosion-of-specialized-data-systems"><a href="#5-3-Problem-2-The-explosion-of-specialized-data-systems" class="headerlink" title="5.3 Problem 2: The explosion of specialized data systems"></a>5.3 Problem 2: The explosion of specialized data systems</h2><ul><li>Explosion of specialized data systems</li><li>The combination of more data of more varieties and a desire to get this data into more systems leads to a huge data integration problem.</li></ul><h2 id="5-4-Log-Structured-Data-Flow"><a href="#5-4-Log-Structured-Data-Flow" class="headerlink" title="5.4 Log Structured Data Flow"></a>5.4 Log Structured Data Flow</h2><h3 id="5-4-1-How-the-flow-work"><a href="#5-4-1-How-the-flow-work" class="headerlink" title="5.4.1 How the flow work"></a>5.4.1 How the flow work</h3><ul><li>Recipe: Take all the organization‚Äôs data and put it into a central log for <strong>real time subscription</strong></li><li>How the flow works<ul><li>Each logical data source can be modeled as its own log</li><li>A data source could be an application that logs out events, or a db table that accepts modifications</li><li>each subscribing system reads from this log <strong>as quickly as it can</strong>, <strong>applied each new record to its own store</strong>, and <strong>advances its position</strong> in the log</li></ul></li></ul><p><img src="https://s2.loli.net/2022/01/29/ykIEs4XwnBD3LUF.png" alt="How the flow work"></p><ul><li><p>Log gives a <strong>logical clock</strong> for each change against which all subscriber can be measured</p><ul><li>Consider a case where there is a database and a collection of caching servers</li><li>log provides a way to synchronize the updates to all these systems and reason about the point of time of each of these systems</li><li>Let‚Äôs say we <strong>write a record with log entry X</strong> and then need to do a read from the cache. If we want to guarantee we don‚Äôt see stale data, we just need to ensure we <strong>don‚Äôt read from any cache which has not replicated up to X.</strong></li></ul></li><li><p>Log also acts as a <strong>buffer</strong> that makes <strong>data production asynchronous from data consumption</strong></p><ul><li>satisfy different requirements like<ul><li>A batch system such as Hadoop or a data warehouse may consume only hourly or daily,</li><li>A real-time query system may need to be up-to-the-second.</li></ul></li></ul></li><li><p>Consumer only need to know about the log and not any details of the system of origin</p></li><li><p>What values most from author perspective</p><ul><li>The pipeline they built for process data, though a bit of a mess, were actually extremely valuable . Just the process of makeing data available in a new processing system (Hadoop) unblocked a lot of possibilities<ul><li>Many new products and analysis just came from putting together multiple pieces of data that had previously been locked up in specialized systems</li></ul></li></ul></li><li><p>LinkedIn Went Through from O(N^2) to O(2N)</p></li></ul><p><img src="https://s2.loli.net/2022/01/29/fXnmrpYFLSVGoR9.png" alt="Pre Architecture LinkedIn"><br><img src="https://s2.loli.net/2022/01/29/9dZa67tYEl1yc8e.png" alt="Cur Architecture LinkedIn"></p><ul><li>Actions for the migration<ul><li>Isolate each consumer from the source of the data</li><li>Create a new data system to be both a data source and a data destination</li><li>Here LinkedIn create Kafka</li><li>Kinesis is similar to Kafka as AWS use it to connects all different distributed systems as a piping</li></ul></li></ul><h3 id="5-4-2-Relationship-to-ETL-and-the-Data-Warehouse"><a href="#5-4-2-Relationship-to-ETL-and-the-Data-Warehouse" class="headerlink" title="5.4.2  Relationship to ETL and the Data Warehouse"></a>5.4.2  Relationship to ETL and the Data Warehouse</h3><ul><li><p>Data Warehouse</p><ul><li>target<ul><li>A repository of the clean, integrated data structured to support analysis</li></ul></li><li>what be involved<ul><li>periodically extracting data from source databases</li><li>munging it into some kind of understandable form</li><li>loading it into a central data warehouse</li></ul></li><li>Problems<ul><li>coupling the clean integrated data to the data warehouse.<ul><li>cannot get real time feed</li></ul></li><li>organization perspective<ul><li>The incentives are not aligned: data producers are often not very aware of the use of the data in the data warehouse and end up creating data that is hard to extract or requires heavy, hard to scale transformation to get into usable form.</li><li>the central team never quite manages to scale to match the pace of the rest of the organization, so data coverage is always spotty, data flow is fragile, and changes are slow.</li></ul></li></ul></li></ul></li><li><p>ETL</p><ul><li>tasks<ul><li>extraction and data cleanup process, liberating data locked up in a variety of systems in the organization and removing an system-specific non-sense</li><li>data is restructured for data warehousing queries (i.e. made to fit the type system of a relational DB, forced into a star or snowflake schema, perhaps broken up into a high performance <a href="http://parquet.io/">column</a> <a href="http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.0.0.2/ds_Hive/orcfile.html">format</a>,</li></ul></li><li>problems<ul><li>still, we need such data in real time as well for low latency processing as well as indexing in real time storage systems</li></ul></li></ul></li><li><p>A better approach as ETL and Data Warehouse substitution</p><ul><li><p>Have a central pipeline, the log, with a well defined API for adding data</p></li><li><p>Responsibility Classification</p><ul><li><p>Producer of the data feed: integrating with this pipeline and providing a clean, well-structured data feed</p></li><li><p>Datawarehouse team now <strong>only care about loading structured feeds</strong> of data from the <strong>central log</strong> and <strong>carrying out transformation specific to their system</strong></p><p>  <img src="https://s2.loli.net/2022/01/29/fMl9IQwDGk8TL4o.png" alt="Workflow and ownership classification">            </p></li></ul></li></ul></li></ul><h3 id="5-4-3-Log-Files-and-Events"><a href="#5-4-3-Log-Files-and-Events" class="headerlink" title="5.4.3 Log Files and Events"></a>5.4.3 Log Files and Events</h3><ul><li>Current structure also enables decoupled and event driven systems</li></ul><h3 id="5-4-4-How-to-build-scalable-logs"><a href="#5-4-4-How-to-build-scalable-logs" class="headerlink" title="5.4.4 How to build scalable logs"></a>5.4.4 How to build scalable logs</h3><ul><li>Need a log system that‚Äôs fast, cheap, scalable enough to make this practical at scale</li><li>LinkedIn in 2013 actually has already support 60 billion unique message writes through Kafka per day</li><li>Kafka achieve such high throughput via<ul><li>Partitioning the log<ul><li>each partition is a <strong>totally ordered log</strong>, but there is <strong>no global ordering between partitions</strong></li><li>Assignment of the messages to a particular partition is controllable by the writer, with most users choosing to partition by some kind of key</li><li>Replication<ul><li>Each partition is replicated across a configurable number of replicas</li><li>At any time, a single one of them will act as the leader, if the leader fails, one of the replicas will take over as leader</li></ul></li><li>Order Guarantee<ul><li>each partition is order preserving, and Kafka guarantees that appends to a particular partition from a single sender will be delivered in the order they are sent.</li></ul></li></ul></li><li>Optimizing throughput by batching reads and writes<ul><li>occurs when<ul><li>sending data</li><li>writes to disk</li><li>replication between servers</li><li>data transfer to consumers</li><li>acknowledging committed data</li></ul></li></ul></li><li>Avoiding needless data copies<ul><li>Use a simple binary format that is maintained between in memory log, on disk log and in network data transfers</li><li>Thus we could make use of numerous optimizations including zero copy data transfer <a href="https://en.wikipedia.org/wiki/Zero-copy">https://en.wikipedia.org/wiki/Zero-copy</a></li></ul></li></ul></li></ul><h1 id="6-Real-Time-Data-Processing"><a href="#6-Real-Time-Data-Processing" class="headerlink" title="6. Real Time Data Processing"></a>6. Real Time Data Processing</h1><blockquote><p>Computing derived data streams</p></blockquote><h2 id="6-1-Definition-of-Stream-Processing"><a href="#6-1-Definition-of-Stream-Processing" class="headerlink" title="6.1 Definition of Stream Processing"></a>6.1 Definition of Stream Processing</h2><ul><li>Infrastructure for continuous data processing<ul><li>computational model can be general like MapReduce or other distributed processing frameworks,</li><li>need the ability to produce low latency results</li></ul></li><li>Instead of batch get and process, we could do continuous changes</li><li>it is just processing which includes a notion of time in the underlying data being processed and does not require a static snapshot of the data so it can produce output at a user-controlled frequency instead of waiting for the ‚Äúend‚Äù of the data set to be reached. In this sense, stream processing is a generalization of batch processing, and, given the prevalence of real-time data, a very important generalization</li><li>Log role<ul><li>making data available in real-time multi-subscriber data feeds.</li></ul></li></ul><h2 id="6-2-Stateful-Real-Time-Processing"><a href="#6-2-Stateful-Real-Time-Processing" class="headerlink" title="6.2 Stateful Real Time Processing"></a>6.2 Stateful Real Time Processing</h2><ul><li>Stateful real time processing means some more sophisticated operations, like counts, aggregations, or joins over windows in the stream</li><li>We need to maintain certain state in such case</li><li>Strategies for that<ul><li>Keep state in memory<ul><li>cons<ul><li>if the process crash, it would lose its intermediate state</li><li>if the state is only maintained over a window, the process could fall back to the point where the window began</li></ul></li></ul></li><li>Store all state in a remote storage system, and join over the network to that store<ul><li>cons<ul><li>no locality of data and lots of network round trips</li></ul></li></ul></li><li>Duality of tables and logs<ul><li>a stream processor can keep its state in a local table or index ‚Äî a bdb, leveldb</li><li>the contents of this store is fed from its input streams</li><li>it could journal out a changelog for this local index it keeps to allow it to restore its state in the event of a crash and restart</li><li>This mechanism allows a generic mechanism for keeping co-partitioned state in arbitrary index types local with the incoming stream data.</li><li>when facing process fails<ul><li>recover its index from the changelog</li><li>changelog itself is the transformation of the local state into a sort of incremental record at a time backup</li></ul></li></ul></li></ul></li></ul><h2 id="6-3-Log-Compaction"><a href="#6-3-Log-Compaction" class="headerlink" title="6.3 Log Compaction"></a>6.3 Log Compaction</h2><ul><li>Log need to be cleaned up someway to save the space</li><li>In Kafka, clean up has two options depending on whether the data contains keyed updates or event data<ul><li>for event data, supports just retain a window of data<ul><li>configured to be few days</li><li>also could be configured as space</li></ul></li><li>for keyed data<ul><li>as the complete log give you ability to replay it to recreate the state of the source system</li><li>but we could do log compaction by removing obsolete records ‚Äî records whose primary key has a more recent update</li></ul></li></ul></li></ul><h1 id="7-Distributed-System-Design"><a href="#7-Distributed-System-Design" class="headerlink" title="7. Distributed System Design"></a>7. Distributed System Design</h1><blockquote><p>How practical systems can be simplified with a log centric design</p></blockquote><h2 id="7-1-Distributed-system-design-thought"><a href="#7-1-Distributed-system-design-thought" class="headerlink" title="7.1 Distributed system design thought"></a>7.1 Distributed system design thought</h2><p>Log here is responsible for data flow, consistency and recovery </p><ul><li><p>Directions</p><ul><li>Coalescing lots of little instances of each system into a few big clusters</li></ul></li><li><p>Possibility 1</p><ul><li>separation of systems remains more or less as it is for a good deal longer.</li><li>an external log that integrates data will be very important.</li></ul></li><li><p>Possibility 2</p><ul><li>re-consolidation in which a single system with enough generality starts to merge back in all the different functions into a single uber-system.</li><li>extremely hard</li></ul></li><li><p>Possibility 3</p><ul><li>data infrastructure could be unbundled into a collection of services and application-facing system apis</li><li>use open source, like in Java stacks<ul><li>zookeeper<ul><li>handle system coordination</li></ul></li><li>mesos and yarn<ul><li>process virtualization</li><li>resource management</li></ul></li><li>netty, jetty<ul><li>handle remote communication</li></ul></li><li>protobuf<ul><li>handle serialization</li></ul></li><li>kafka and bookeeper<ul><li>provide a backing log</li></ul></li></ul></li><li>path towards getting the simplicity of the single system in a more diverse and modular world that continues to evolve. If the implementation time for a distributed system goes from years to weeks because reliable, flexible building blocks emerge, then the pressure to coalesce into a single monolithic system disappears.</li></ul></li></ul><h2 id="7-2-Usage-of-log-in-system-architecture"><a href="#7-2-Usage-of-log-in-system-architecture" class="headerlink" title="7.2 Usage of log in system architecture"></a>7.2 Usage of log in system architecture</h2><ul><li><p>Usage of log in system architecture</p><ul><li>Handle data consistency (whether eventual or immediate) by sequencing concurrent updates to nodes</li><li>Provide data replication between nodes</li><li>Provide ‚Äúcommit‚Äù semantics to the writer (i.e. acknowledging only when your write guaranteed not to be lost)</li><li>Provide the external data subscription feed from the system</li><li>Provide the capability to restore failed replicas that lost their data or bootstrap new replicas</li><li>Handle rebalancing of data between nodes.</li></ul></li><li><p>What mentioned above is actually a large portion of what a distributed data system does. left over is mainly related with client facing query API and indexing strategy</p></li><li><p>System Look</p><ul><li>System is divided into two logical pieces<ul><li>log<ul><li>capture the state changes in sequential order</li></ul></li><li>serving layer<ul><li>store whatever index is required to serve queries</li></ul></li></ul></li><li>writes could go directly to the log or may be proxied by the serving layer</li><li>writes to the log yields a logical timestamp, if the system is partitioned, then the log and serving nodes will have the same number of partitions, though they may have very different numbers of machines</li></ul></li></ul><p><img src="https://s2.loli.net/2022/01/29/EXfRmnKxbGs8kHT.png" alt="Log and serving layer">    </p><ul><li><p>The client can get <strong>read-your-write semantics</strong> from any node by providing the <strong>timestamp of a write</strong> as part of its query‚Äîa serving node receiving such a query will <strong>compare the desired timestamp</strong> to <strong>its own index point</strong> and if necessary delay the request until it has indexed up to at least that time to avoid serving stale data.</p></li><li><p>For handling restoring failed nodes or moving partitions from node to node</p><ul><li>have the log retain only a fixed window of data and combine this with a snapshot of the data stored in the partition</li><li>it‚Äôs possible for the log to retain a complete copy of data and garbage collect the log itself</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying">https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying</a> </li><li><a href="https://kafka.apache.org/documentation.html#design">https://kafka.apache.org/documentation.html#design</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Real-time-data‚Äôs-unifying-abstraction&quot;&gt;&lt;a href=&quot;#Real-time-data‚Äôs-unifying-abstraction&quot; class=&quot;headerlink&quot; title=&quot;Real time data‚Äôs u
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
      <category term="log" scheme="https://www.llchen60.com/tags/log/"/>
    
      <category term="distributed system" scheme="https://www.llchen60.com/tags/distributed-system/"/>
    
  </entry>
  
  <entry>
    <title>Flyway</title>
    <link href="https://www.llchen60.com/Flyway/"/>
    <id>https://www.llchen60.com/Flyway/</id>
    <published>2022-01-01T13:57:09.000Z</published>
    <updated>2022-01-01T13:57:52.879Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>An open source database migration tool</li><li>Favors simplicity and convention over configuration</li><li>has 7 basic commands<ul><li>migrate</li><li>clean</li><li>info</li><li>validate</li><li>undo</li><li>baseline</li><li>repair</li></ul></li></ul><h2 id="1-1-Why-DB-migrations"><a href="#1-1-Why-DB-migrations" class="headerlink" title="1.1 Why DB migrations?"></a>1.1 Why DB migrations?</h2><ul><li>we need a way to version the table</li><li>we need to know what state is the db on this machine</li><li>database migration help us<ul><li>recreate a database from scratch</li><li>make it clear at all times what state a database is in</li><li>migrate in a deterministic way from your current version of the database to a newer one</li></ul></li></ul><h2 id="1-2-How-Flyway-works"><a href="#1-2-How-Flyway-works" class="headerlink" title="1.2 How Flyway works?"></a>1.2 How Flyway works?</h2><ul><li><p>Flyway first try to locate its schema history table</p><ul><li>if db empty, then flyway will create it instead</li><li>this default db named as <code>flyway_schema_history</code></li></ul></li><li><p>Then flyway will begin scanning the filesystem or the classpath of the application for migrations</p></li><li><p>The migrations are then sorted based on the version number and applied in order</p></li><li><p>The schema history table will be updated accordingly as each migration gets applied</p></li><li><p>we use <code>flyway migrate</code> to execute the migration</p></li></ul><h1 id="2-Flyway-Commands"><a href="#2-Flyway-Commands" class="headerlink" title="2. Flyway Commands"></a>2. Flyway Commands</h1><h2 id="2-1-migrate"><a href="#2-1-migrate" class="headerlink" title="2.1 migrate"></a>2.1 <code>migrate</code></h2><ul><li>help migrate the db</li></ul><h2 id="2-2-clean"><a href="#2-2-clean" class="headerlink" title="2.2 clean"></a>2.2 <code>clean</code></h2><ul><li>drop all objects in the confgured schemas</li></ul><h2 id="2-3-info"><a href="#2-3-info" class="headerlink" title="2.3 info"></a>2.3 <code>info</code></h2><ul><li>print the details and status information about all migrations</li></ul><h2 id="2-4-validate"><a href="#2-4-validate" class="headerlink" title="2.4 validate"></a>2.4 <code>validate</code></h2><ul><li>validates the applied migrations against the ones available on the classpath</li></ul><h2 id="2-5-undo"><a href="#2-5-undo" class="headerlink" title="2.5 undo"></a>2.5 <code>undo</code></h2><ul><li>undoes the most recently applied versioned migration</li></ul><h2 id="2-6-baseline"><a href="#2-6-baseline" class="headerlink" title="2.6 baseline"></a>2.6 <code>baseline</code></h2><ul><li>baselines an existing database, excluding all migrations up and including baseline version</li></ul><h2 id="2-7-repair"><a href="#2-7-repair" class="headerlink" title="2.7 repair"></a>2.7 <code>repair</code></h2><ul><li>repair the schema history table</li></ul><h1 id="3-Concepts"><a href="#3-Concepts" class="headerlink" title="3. Concepts"></a>3. Concepts</h1><h2 id="3-1-Migrations"><a href="#3-1-Migrations" class="headerlink" title="3.1 Migrations"></a>3.1 Migrations</h2><ul><li>all changes to the db are called migrations</li><li>migrations can be<ul><li>versioned<ul><li>types<ul><li>regular</li><li>undo<ul><li>the effect can be undone by supplying an undo migration</li></ul></li></ul></li><li>contains<ul><li><strong>version</strong><ul><li>must be unique</li></ul></li><li><strong>description</strong><ul><li>purely informative for you to be able to remember what each migration does</li></ul></li><li><strong>checksum</strong><ul><li>detect accidental changes</li></ul></li></ul></li></ul></li><li>repeatable<ul><li>contains<ul><li><strong>description</strong></li><li><strong>checksum</strong></li></ul></li><li>instead of being run just once, they are re-applied every time their checksum changes</li><li>Within a single migration run, repeatable migrations are always <strong>applied last</strong>, after all pending versioned migrations have been executed. Repeatable migrations are applied in the order of their description</li></ul></li></ul></li></ul><h3 id="3-1-1-Versioned-Migrations"><a href="#3-1-1-Versioned-Migrations" class="headerlink" title="3.1.1 Versioned Migrations"></a>3.1.1 Versioned Migrations</h3><ul><li>contains<ul><li>version<ul><li><strong>must be unique</strong></li><li>applied in order exactly once</li></ul></li><li>description<ul><li>purely informative for you to be able to remember what each migration does</li></ul></li><li>checksum<ul><li>detect accidental changes</li></ul></li></ul></li><li>used for<ul><li>creating/ altering/ dropping tables/ indexes/ foreign keys/ enums</li><li>reference data updates</li><li>user data corrections</li></ul></li></ul><h3 id="3-1-2-Undo-Migrations"><a href="#3-1-2-Undo-Migrations" class="headerlink" title="3.1.2 Undo Migrations"></a>3.1.2 Undo Migrations</h3><ul><li>A migration can fail at any point. If you have 10 statements, it is possible for the 1st, the 5th, the 7th or the 10th to fail. There is simply no way to know in advance. In contrast, undo migrations are written to undo an entire versioned migration and will not help under such conditions.</li><li>we should <strong>maintain backwards compatibility</strong> between the <strong>DB and all versions of the code</strong> currently deployed in production</li></ul><h3 id="3-1-3-Repeatable-Migrations"><a href="#3-1-3-Repeatable-Migrations" class="headerlink" title="3.1.3 Repeatable Migrations"></a>3.1.3 Repeatable Migrations</h3><ul><li><p>contains</p><ul><li>description and a checksum, but no version</li></ul></li><li><p>repeatable migrations are re-applied every time their checksum changes</p></li><li><p>Very useful for managing database objects whose definition can then simply be maintained in a single file in version control</p></li><li><p>Repeatable migrations are always applied last, after all pending versioned migrations have been executed; always applied in the order of their description</p></li></ul><h3 id="3-1-4-SQL-Based-Migrations"><a href="#3-1-4-SQL-Based-Migrations" class="headerlink" title="3.1.4 SQL Based Migrations"></a>3.1.4 SQL Based Migrations</h3><ul><li>used for<ul><li>DDL change ‚Äî CREATE/ALTER/DROP statements for TABLES,VIEWS,TRIGGERS,SEQUENCES,‚Ä¶</li><li>Simple reference data changes</li><li>simple bulk data changes</li></ul></li><li>Naming  Patterns<ul><li>Prefix<ul><li>v for versioned</li><li>u for undo</li><li>r for repeatable migrations</li></ul></li><li>version<ul><li>with dots or underscores separate as many parts as you like</li></ul></li><li>Separator<ul><li>__ two underscores</li></ul></li><li>Suffix<ul><li><code>.sql</code></li></ul></li></ul></li><li>Discovery<ul><li>Flyway discover sql migrations from directories <strong>referenced by the location property</strong></li></ul></li></ul><h3 id="3-1-5-Script-Based-Migrations"><a href="#3-1-5-Script-Based-Migrations" class="headerlink" title="3.1.5 Script Based Migrations"></a>3.1.5 Script Based Migrations</h3><ul><li>name patten<ul><li>``V1__execute_batch_tool.sh`</li></ul></li><li>could be used for<ul><li>triggering execution of a 3rd party application as part of the migrations</li><li>cleaning up local files</li></ul></li></ul><h3 id="3-1-6-Transactions"><a href="#3-1-6-Transactions" class="headerlink" title="3.1.6 Transactions"></a>3.1.6 Transactions</h3><ul><li>By default, Flyway <strong>wraps the execution of an entire migration within a single transaction</strong></li></ul><h2 id="3-2-Callbacks"><a href="#3-2-Callbacks" class="headerlink" title="3.2 Callbacks"></a>3.2 Callbacks</h2><ul><li><p>For the case we need to execute same action over and over again</p></li><li><p>we could hook into its lifecycle</p></li><li><p>there are certain keywords we could use, and invoke them during the process</p></li></ul><p><a href="https://flywaydb.org/documentation/concepts/callbacks">https://flywaydb.org/documentation/concepts/callbacks</a> </p><h2 id="3-3-Error-Overrides"><a href="#3-3-Error-Overrides" class="headerlink" title="3.3 Error Overrides"></a>3.3 Error Overrides</h2><ul><li>By default, in case an error is returned, flyway displays it with all necessary details, marks the migration as failed and automatically rolls it back if possible</li><li>But we could change the behavior like<ul><li>treat an error as a waring</li><li>treat a waring as an error</li><li>perform an additional action</li></ul></li></ul><h2 id="3-4-Dry-Runs"><a href="#3-4-Dry-Runs" class="headerlink" title="3.4 Dry Runs"></a>3.4 Dry Runs</h2><ul><li>Used for<ul><li>preview changes Flyway will make to the db</li><li>submit the SQL statements for review</li><li>use Flyway to determine what needs updating,</li></ul></li><li>how it works<ul><li>flyway sets up a read only connection to the db,</li><li>assesses what migrations need to run and generates a single SQL file containing all statements it would have executed in case of a regular migration run</li></ul></li></ul><h2 id="3-5-Baseline-Migrations"><a href="#3-5-Baseline-Migrations" class="headerlink" title="3.5 Baseline Migrations"></a>3.5 Baseline Migrations</h2><ul><li><p>Over the lifetime of a project, there would be tons of db objects be created/ destroyed across many migrations</p><ul><li>we want to simplify with a single, cumulative migration that represents the state of db after all of those migrations have been applied without disrupting existing env</li></ul></li><li><p>How it works?</p><ul><li>Prefixed with B followed by the version of your db they represent</li><li>Only used when deploying to new env</li><li>If used in an env where some Flyway migrations have already been applied, <strong>baseline migrations will be ignored,</strong> <strong>new env will choose the latest baseline migration as the starting point</strong><ul><li>every migration with a version below the latest baseline migration‚Äôs version is marked as ignored</li></ul></li><li>baseline migration are executed during the migrate process</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://flywaydb.org/documentation/">https://flywaydb.org/documentation/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. Overview&quot;&gt;&lt;/a&gt;1. Overview&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;An open source database migrat
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="database" scheme="https://www.llchen60.com/tags/database/"/>
    
      <category term="migration" scheme="https://www.llchen60.com/tags/migration/"/>
    
  </entry>
  
  <entry>
    <title>Protobuf Rampup</title>
    <link href="https://www.llchen60.com/Protobuf-Rampup/"/>
    <id>https://www.llchen60.com/Protobuf-Rampup/</id>
    <published>2021-12-25T02:09:49.000Z</published>
    <updated>2021-12-25T02:11:09.003Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Protobuf-Learning"><a href="#Protobuf-Learning" class="headerlink" title="Protobuf Learning"></a>Protobuf Learning</h1><h1 id="1-What-are-Protocol-Buffers"><a href="#1-What-are-Protocol-Buffers" class="headerlink" title="1. What are Protocol Buffers?"></a>1. What are Protocol Buffers?</h1><ul><li>Google‚Äôs language-neutral, platform-neutral, extensible mechanism for serializing structured data ‚Äì think XML, but smaller, faster, and simpler.</li><li>You <strong>define how you want your data to be structured</strong> once, then you <strong>use special generated source code to easily write and read your structured data</strong></li></ul><h1 id="2-Why-use-Protocol-Buffers"><a href="#2-Why-use-Protocol-Buffers" class="headerlink" title="2. Why use Protocol Buffers?"></a>2. Why use Protocol Buffers?</h1><ul><li>XML is human readable and wide language supports<ul><li>but is notoriously space intensive</li><li>encoding/ decoding can impose a huge performance penalty on applications</li></ul></li><li>With protocol buffers<ul><li>write a <code>.proto</code> description of the data structure</li><li>the <strong>protocol buffer compiler</strong> then <strong>creates a class</strong> that implements <strong>automatic encoding and parsing</strong> of the protocol buffer data with an <strong>efficient binary format</strong></li><li>the generated class <strong>provides getters and setters</strong> for the fields</li><li>take care of the details of reading and writing the protocol buffer <strong>as a unit</strong></li></ul></li></ul><h1 id="3-Java-Tutorial-In-Proto2"><a href="#3-Java-Tutorial-In-Proto2" class="headerlink" title="3. Java Tutorial (In Proto2)"></a>3. Java Tutorial (In Proto2)</h1><h2 id="3-1-Define-Protocol-Format"><a href="#3-1-Define-Protocol-Format" class="headerlink" title="3.1 Define Protocol Format"></a>3.1 Define Protocol Format</h2><pre><code class="protobuf">syntax = &quot;proto2&quot;;// starts with package delcaration // we should define this to get rid of name conflict package tutorial;// enable generating a separate .java file for each generated class option java_multiple_files = true;// specify in what java package name your generated classes should live// if not set here, it will simply match the pkg name given by the package declaration option java_package = &quot;com.example.tutorial.protos&quot;;// define the class name of the wrapper class which will represent this file // if not given, it will be auto generated by converting the file name to upper camel case option java_outer_classname = &quot;AddressBookProtos&quot;;/**Message Definition: An aggregate containing a set of typed fields Contain certain standard types    + boo1    + int32     + float     + double     + string we could also add further structure to msgs by using other msg types as field types + marker     + identify the unique tag field use in binary encoding     + try to use 1 - 15 as it neeeds one less byte+ modifier     + optional         + field may or may not be set         + if not, a default value will be used             + we could set our own default values             + or system will provide defaults                 + numeric types -- zero                 + strings -- empty string                 + bools -- false                 + embedded messages -- default instance or prototype of the message, which has none of its fields set     + repeated         + the field may be repeated any number of times [0, xxx)         + order will be preserved in the protocol buffer         + act like a dynamic sized array     + required         + a value for the field must be provided        + try to build an uninitialized msg will throw runtime exception         + parse an uninitialzied msg will throw IOException         + required is not favored as it cannot be backward compatible */message Person &#123;    // =1 marker identify the unique tag that field uses in the binary encoding   optional string name = 1;  optional int32 id = 2;  optional string email = 3;  enum PhoneType &#123;    MOBILE = 0;    HOME = 1;    WORK = 2;  &#125;  message PhoneNumber &#123;    optional string number = 1;    optional PhoneType type = 2 [default = HOME];  &#125;  repeated PhoneNumber phones = 4;&#125;message AddressBook &#123;  repeated Person people = 1;&#125;</code></pre><h2 id="3-2-Compiling-Protocol-Buffers"><a href="#3-2-Compiling-Protocol-Buffers" class="headerlink" title="3.2 Compiling Protocol Buffers"></a>3.2 Compiling Protocol Buffers</h2><ul><li>To generate the classes, we need to run the protocol buffer compiler</li><li>specify the source directory, the destination directory and the path to our <code>.proto</code></li></ul><pre><code class="protobuf">protoc -I=$SRC_DIR --java_out=$DST_DIR $SRC_DIR/addressbook.proto </code></pre><h2 id="3-3-Protocol-Buffer-API"><a href="#3-3-Protocol-Buffer-API" class="headerlink" title="3.3 Protocol Buffer API"></a>3.3 Protocol Buffer API</h2><ul><li>compiler helps auto generate source file<ul><li>getters and setters</li><li>each field also has <code>clear</code> method to set the field back to its empty state</li></ul></li><li>Builders vs Messages<ul><li>message classes are immutable</li><li>builder is used when you first construct a builder, then we could call the builder‚Äôs build() method</li></ul></li><li>standard message methods<ul><li><code>isInitialized</code> check if all the required fields have been set</li><li><code>toString</code> returns a human readable representation of the msg</li><li><code>mergeFrom(Message other)</code> merge the contents of other into this msg, overwrite singular scalar fields</li><li><code>clear</code> clear all the fields back to the empty state</li></ul></li><li>Parsing and Serialization<ul><li><code>byte[] toByteArray();</code><ul><li>serializes the msg and returns a byte array containing its raw bytes</li></ul></li><li><code>static xxx parseFrom(byte[] data);</code><ul><li>parse a msg from the given byte array</li></ul></li><li><code>void writeTo(OutputStream output);</code><ul><li>serialize the msg and writes to an OutputStream</li></ul></li><li><code>static xxx parseFrom(InputStream input);</code><ul><li>reads and parses a msg from an InputStream</li></ul></li></ul></li></ul><h2 id="3-4-How-to-extend-a-Protocol-Buffer"><a href="#3-4-How-to-extend-a-Protocol-Buffer" class="headerlink" title="3.4 How to extend a Protocol Buffer"></a>3.4 How to extend a Protocol Buffer</h2><ul><li>In the new version of the protocol buffer<ul><li>must not change the tag numbers of any existing fields</li><li>must not add or delete any required fields</li><li>may delete optional or repeated fields</li><li>may add new optional or repeated fields but must use fresh tag numbers</li></ul></li></ul><h1 id="4-Overall-Guide-In-Proto3"><a href="#4-Overall-Guide-In-Proto3" class="headerlink" title="4. Overall Guide (In Proto3)"></a>4. Overall Guide (In Proto3)</h1><h2 id="4-1-Define-message-type"><a href="#4-1-Define-message-type" class="headerlink" title="4.1 Define message type"></a>4.1 Define message type</h2><ul><li>Each field in the msg definition need to have a <strong>unique number</strong><ul><li>those numbers are used to identify fields in the message binary format</li><li>the number should never be changed</li></ul></li><li>specify field rules<ul><li>singular<ul><li>default field rule for proto3 syntax</li><li>can have <strong>zero or one of this field</strong></li></ul></li><li>repeated<ul><li>can be repeated any number of times (including zero)</li></ul></li></ul></li><li>reserved fields<ul><li>if you update a msg type by entirely removing a field or commenting it out, future users can reuse the field number but it would bring severe issues,</li><li>thus we could reserved the number for deleted fields and tag number</li></ul></li></ul><pre><code class="protobuf">message Foo &#123;  reserved 2, 15, 9 to 11;  reserved &quot;foo&quot;, &quot;bar&quot;;&#125;</code></pre><ul><li>Post compiler running<ul><li>Compiler generates a <code>.java</code> file with a class for each message type, as well as Builder classes for creating message class instances</li></ul></li><li>For enum values<ul><li>every enum definition must contain a constant that maps to zero as its first element</li><li>we can allow alias thus we could assign the same value to different enum constants</li></ul></li><li>import<ul><li>we could do import thus we could use definitions from other <code>.proto</code> file</li></ul></li></ul><h2 id="4-2-Scalar-Value-Types"><a href="#4-2-Scalar-Value-Types" class="headerlink" title="4.2 Scalar Value Types"></a>4.2 Scalar Value Types</h2><p><a href="https://developers.google.com/protocol-buffers/docs/proto3#scalar">Language Guide (proto3) | Protocol Buffers | Google Developers</a></p><h2 id="4-3-Nested-Types"><a href="#4-3-Nested-Types" class="headerlink" title="4.3 Nested Types"></a>4.3 Nested Types</h2><ul><li>we could define and use msg types inside other msg types</li></ul><pre><code class="protobuf">message SearchResponse &#123;  message Result &#123;    string url = 1;    string title = 2;    repeated string snippets = 3;  &#125;  repeated Result results = 1;&#125;// to use the msg type outside its parent message type message SomeOtherMessage &#123;  SearchResponse.Result result = 1;&#125;</code></pre><h2 id="4-4-Updating-a-Message-Type"><a href="#4-4-Updating-a-Message-Type" class="headerlink" title="4.4 Updating a Message Type"></a>4.4 Updating a Message Type</h2><ul><li>don‚Äôt change the field numbers for any existing fields</li><li>if you add new fields, any msg serialized by code using your old msg format can still be parsed by your new generated code<ul><li>keep in mind the default values for these elements so that new code can properly interact with msgs generated by old code</li></ul></li><li>to remove a field<ul><li>rename the field with prefix like <code>OBSOLETE_</code></li><li>or make the filed number reserved,</li></ul></li><li>int32, uint32, int64, uint64 and bool are all compatible</li><li>string and bytes are compatible as long as the bytes are valid UTF-8</li></ul><h2 id="4-5-Special-Keywords"><a href="#4-5-Special-Keywords" class="headerlink" title="4.5 Special Keywords"></a>4.5 Special Keywords</h2><h3 id="4-5-1-Any"><a href="#4-5-1-Any" class="headerlink" title="4.5.1 Any"></a>4.5.1 <code>Any</code></h3><ul><li>let you use messages as embedded types without having their .proto definition</li><li>it contains an aribitrary serialized messages as bytes</li></ul><h3 id="4-5-2-Oneof"><a href="#4-5-2-Oneof" class="headerlink" title="4.5.2 Oneof"></a>4.5.2 Oneof</h3><ul><li>if we have a msg with many fields and where at most one field will be set at the same time, we can enforce the behavior and save memory by using the oneof feature</li><li>at most one field can be set at the same time</li><li>setting any member of the oneof automatically clears all the other members</li></ul><h2 id="4-6-Maps"><a href="#4-6-Maps" class="headerlink" title="4.6 Maps"></a>4.6 Maps</h2><ul><li><code>map&lt;key_type, value_type&gt; map_field = N;</code></li></ul><h2 id="4-7-Define-Service"><a href="#4-7-Define-Service" class="headerlink" title="4.7 Define Service"></a>4.7 Define Service</h2><ul><li>If you want to use message types with an RPC system, we can define an RPC service interface in a <code>.proto</code> file</li><li>then the protocol buffer compiler will <strong>generate service interface code and stubs</strong> in chosen language</li></ul><h2 id="4-8-Options"><a href="#4-8-Options" class="headerlink" title="4.8 Options"></a>4.8 Options</h2><ul><li><p>Options do not change the overall meaning of a declaration, but may affect the way it is handled in a particular context.</p></li><li><p>java_package</p><ul><li>pkg you want to use for your generated Java classes</li></ul></li><li><p>java_outer_classname</p><ul><li>class name for the wrapper java class you want to generate</li></ul></li><li><p>java_multiple_files</p></li><li><p><code>optimize_for</code></p><ul><li><code>SPEED</code><ul><li>Compiler will generate code for serializing, parsing and performing other common operations on your msg types.</li><li>Code is highly optimized</li></ul></li><li><code>CODE_SIZE</code><ul><li>generate minimal classes</li><li>operations will be slower</li></ul></li><li><code>LITE_RUNTIME</code><ul><li>only depend on the lite runtime library</li><li>usefyl for apps running on constrained platform like mobile phones</li></ul></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Overview <a href="https://developers.google.com/protocol-buffers">https://developers.google.com/protocol-buffers</a> </li><li>Language Guide <a href="https://developers.google.com/protocol-buffers/docs/overview">https://developers.google.com/protocol-buffers/docs/overview</a> </li><li>Java Tutorial <a href="https://developers.google.com/protocol-buffers/docs/javatutorial">https://developers.google.com/protocol-buffers/docs/javatutorial</a> </li><li>Java Generated Code <a href="https://developers.google.com/protocol-buffers/docs/reference/java-generated">https://developers.google.com/protocol-buffers/docs/reference/java-generated</a> </li><li>Java Encoding <a href="https://developers.google.com/protocol-buffers/docs/encoding">https://developers.google.com/protocol-buffers/docs/encoding</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Protobuf-Learning&quot;&gt;&lt;a href=&quot;#Protobuf-Learning&quot; class=&quot;headerlink&quot; title=&quot;Protobuf Learning&quot;&gt;&lt;/a&gt;Protobuf Learning&lt;/h1&gt;&lt;h1 id=&quot;1-Wha
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Protobuf" scheme="https://www.llchen60.com/tags/Protobuf/"/>
    
  </entry>
  
  <entry>
    <title>Bazel Intro</title>
    <link href="https://www.llchen60.com/Bazel-Intro/"/>
    <id>https://www.llchen60.com/Bazel-Intro/</id>
    <published>2021-12-22T02:05:15.000Z</published>
    <updated>2021-12-22T02:07:14.224Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-What-is-Bazel"><a href="#1-What-is-Bazel" class="headerlink" title="1. What is Bazel?"></a>1. What is Bazel?</h1><ul><li><p>Bazel is a build and test tool built that supports building and testing multiple projects for multiple languages and build outputs</p></li><li><p>What</p><ul><li>Build and Test tool similar to Make, Maven, Gradle</li><li>Caches all the previously done work, tests or builds faster everytime</li><li>Support multi languages, multi platforms,</li><li>Support large code base across multi repos</li><li>build, test, and query to trace dependencies in the code</li></ul></li><li><p>Why</p><ul><li>scales</li><li>multi platform</li></ul></li><li><p>How</p><ul><li>Need a BUILD file</li></ul></li></ul><h1 id="2-Concepts"><a href="#2-Concepts" class="headerlink" title="2. Concepts"></a>2. Concepts</h1><ul><li>Workspace - With WORKSPACE<ul><li>dir contains the source file</li><li>considered as root</li></ul></li><li>WORKSPACE<ul><li>a blank text file, which identifies the directory and its content as a Bazel workspace</li><li>at the root of the project‚Äôs directory structure</li></ul></li><li>Repos - With WORKSPACE<ul><li>External repos are defined in the WORKSPACE file using workspace rules</li></ul></li><li>Packages - With BUILD<ul><li>A package is defined as a directory containing a file named BUILD or BUILD.bazel</li><li>which reside beneath top level directory in the ws</li><li>This file has instructions on how to <strong>run or build or test</strong> the project</li></ul></li><li>Rules<ul><li>written using a DSL named Starlark</li><li>thus are built for certain language already like rules_java, etc.</li></ul></li><li>Targets<ul><li>Pkg is container, element of pkg ‚Äî- target</li><li>Most targets are files or rules<ul><li>File<ul><li>source files - written by people</li><li>generated files ‚Äî generated by build tool</li></ul></li><li>rule<ul><li>specify relationship between set of inputs and output</li><li>output are always generated files</li></ul></li></ul></li></ul></li></ul><h1 id="3-Best-Practices"><a href="#3-Best-Practices" class="headerlink" title="3. Best Practices"></a>3. Best Practices</h1><ul><li>A project should always be able to run <code>bazel build //...</code> and <code>bazel test //...</code></li><li>You may declare third party dependencies<ul><li>either declare them as remote repositories in the WORKSPACE file</li><li>or put them in a directory called third_party under workspace directory</li></ul></li><li>everything should be built from source whenever possible, instead of depending on a library so file, we should create a BUILD file and build so from its sources, then depend on that target</li><li>for project specific options, use the configuration file under <code>workspace/.bazelrc</code></li><li>every directory that contains buildable files should be a package</li></ul><h1 id="4-Build-a-Java-Project"><a href="#4-Build-a-Java-Project" class="headerlink" title="4. Build a Java Project"></a>4. Build a Java Project</h1><h2 id="4-1-Bazel-Jave-Basic"><a href="#4-1-Bazel-Jave-Basic" class="headerlink" title="4.1 Bazel Jave Basic"></a>4.1 Bazel Jave Basic</h2><ul><li><p>Refer <a href="https://docs.bazel.build/versions/1.2.0/tutorial/java.html">https://docs.bazel.build/versions/1.2.0/tutorial/java.html</a></p></li><li><p>build rule tells bazel how to build the desired outputs, executable binaries or libraries</p><ul><li>the java binary rule tells bazel to build a jar file and a wrapper shell script</li></ul></li><li><p><code>bazel build //:ProjectRunner</code></p><ul><li>the <code>//</code> part is the location of our BUILD file relative to the root of the workspace</li><li><code>ProjectRunner</code> is the target name we define in the BUILD file</li></ul></li><li><p>we could review our dependency graph by using</p><ul><li><code>bazel query --notool_deps --noimplicit_deps &quot;deps(//:ProjectRunner)&quot; --output graph</code></li></ul></li></ul><pre><code class="ruby">// generate graph for class in use, and output as a svg file bazel query  --notool_deps --noimplicit_deps &quot;deps(//booking)&quot; --output graph &gt; /Users/lchen1/Documents/bookingGraph.in dot -Tsvg &lt; bookingGraph.in &gt; graph.svg</code></pre><h2 id="4-2-Specify-multiple-build-targets"><a href="#4-2-Specify-multiple-build-targets" class="headerlink" title="4.2 Specify multiple build targets"></a>4.2 Specify multiple build targets</h2><ul><li><p>Package Splits</p><ul><li><p>for larger project, we may want to split into multiple targets and packages to allow for fast incremental builds, this could also speed up builds by building multiple parts of a project at once</p><pre><code class="json">java_binary(  name = &quot;ProjectRunner&quot;,  srcs = [&quot;src/main/java/com/example/ProjectRunner.java&quot;],  main_class = &quot;com.example.ProjectRunner&quot;,  deps = [&quot;:greeter&quot;],)java_library(  name = &quot;greeter&quot;,  srcs = [&quot;src/main/java/com/example/Greeting.java&quot;],)</code></pre></li></ul></li></ul><ul><li>with this configuration, bazel will first build greeter library, then the projectRunner binary<ul><li>deps attribute tells bazel the greeter library is required to build the projectRunner binary</li></ul></li></ul><h2 id="4-3-Use-multiple-packages"><a href="#4-3-Use-multiple-packages" class="headerlink" title="4.3 Use multiple packages"></a>4.3 Use multiple packages</h2><pre><code class="json">java_binary(    name = &quot;runner&quot;,    srcs = [&quot;Runner.java&quot;],    main_class = &quot;com.example.cmdline.Runner&quot;,    deps = [&quot;//:greeter&quot;])</code></pre><ul><li>To make sure above works, we need to let greeter be visible to cmdline.Runner<ul><li>Let the resource owner set the visibility attribute</li><li>we need to do this cause Bazel by default makes target only visible to other targets in the same BUILD file</li><li>bazel uses target visibility to prevent issues such as libraries containing implementation details leaking into public APIs</li></ul></li></ul><pre><code class="json">java_library(    name = &quot;greeter&quot;,    srcs = [&quot;src/main/java/com/example/Greeting.java&quot;],    visibility = [&quot;//src/main/java/com/example/cmdline:__pkg__&quot;],    )</code></pre><h2 id="4-4-Use-labels-to-reference-targets"><a href="#4-4-Use-labels-to-reference-targets" class="headerlink" title="4.4 Use labels to reference targets"></a>4.4 Use labels to reference targets</h2><ul><li>Bazel uses target labels to reference targets<ul><li><code>//:ProjectRunner</code></li><li>sync as follow:<ul><li><code>//path/to/package:target-name</code></li></ul></li></ul></li><li>when referencing targets within the same BUILD file, we can skip the <code>//</code> workspace root identifier and just use <code>:target_name</code></li></ul><h1 id="5-E-G"><a href="#5-E-G" class="headerlink" title="5. E.G"></a>5. E.G</h1><ul><li>java_binary<ul><li>pre defined rule telling bazel to create a binary when a target is invoked</li></ul></li></ul><pre><code class="json">java_binary(        // target name     name = &quot;mymain&quot;,        // all source files, passed as glob, inside the fully qualified directory names on classpath     srcs = glob([&quot;src/main/java/com/abhi/*.java&quot;]),        // main runner class     main_class = &quot;com.abhi.MyMain&quot;,        // dependent classes/ interfaces to be included, not part of srcs     deps = [&quot;//another-dir:animal&quot;])</code></pre><ul><li>java_library<ul><li>pre-defined to create library as the name suggests</li></ul></li></ul><pre><code class="json">java_library(    name = &quot;animal&quot;,    srcs = [&quot;src/main/java/com/abhi/Animal.java&quot;],        // if other class is implemented in a different pkg, it has to be visible to main-dir     visibility = [&quot;//main-dir:__pkg__&quot;])</code></pre><ul><li>CLI Reference<ul><li><code>bazel build //main-dir:mymain</code><ul><li>// means a valid package name</li><li>mymain is the target name</li></ul></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Bazel best practice <a href="https://docs.bazel.build/versions/main/best-practices.html">https://docs.bazel.build/versions/main/best-practices.html</a> </li><li>Bazel Overview  <a href="https://docs.bazel.build/versions/1.2.0/bazel-overview.html">https://docs.bazel.build/versions/1.2.0/bazel-overview.html</a> </li><li>Java Tutorial <a href="https://docs.bazel.build/versions/1.2.0/tutorial/java.html">https://docs.bazel.build/versions/1.2.0/tutorial/java.html</a> </li><li>How to specify targets to build <a href="https://docs.bazel.build/versions/main/guide.html#target-patterns">https://docs.bazel.build/versions/main/guide.html#target-patterns</a> </li></ol><p><a href="https://docs.bazel.build/versions/4.2.1/command-line-reference.html">Command-Line Reference</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-What-is-Bazel&quot;&gt;&lt;a href=&quot;#1-What-is-Bazel&quot; class=&quot;headerlink&quot; title=&quot;1. What is Bazel?&quot;&gt;&lt;/a&gt;1. What is Bazel?&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Bazel
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Bazel" scheme="https://www.llchen60.com/tags/Bazel/"/>
    
      <category term="Package Management" scheme="https://www.llchen60.com/tags/Package-Management/"/>
    
  </entry>
  
  <entry>
    <title>GraphQL Read</title>
    <link href="https://www.llchen60.com/GraphQL-Read/"/>
    <id>https://www.llchen60.com/GraphQL-Read/</id>
    <published>2021-12-04T09:29:50.000Z</published>
    <updated>2021-12-04T09:31:23.613Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GraphQL-Read"><a href="#GraphQL-Read" class="headerlink" title="GraphQL Read"></a>GraphQL Read</h1><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><ul><li>QraphQL is<ul><li>a query language</li><li>a server side runtime for executing queries using a type system you define</li></ul></li></ul><h1 id="2-Queries-and-Mutations"><a href="#2-Queries-and-Mutations" class="headerlink" title="2. Queries and Mutations"></a>2. Queries and Mutations</h1><ul><li>Fields<ul><li>GraphQL is about asking specific fields on objects</li><li>Query has the same shape as result<ul><li>server knows exactly what fields the client is asking for</li></ul></li></ul></li></ul><pre><code class="ruby">&#123;    hero &#123;        name    &#125;&#125;&#123;    &quot;data&quot;: &#123;        &quot;hero&quot;: &#123;            &quot;name&quot;: &quot;12test&quot;        &#125;    &#125;&#125;</code></pre><ul><li><p>Arguments</p><ul><li>we could pass arguments to fields</li><li>comparing with Restful, in GraphQL every field and nested object can get its own set of arguments, making GraphQL a complete replacement for making multiple APU fetches</li></ul></li><li><p>Fragments</p><ul><li>That‚Äôs the reusable units in GraphQL</li><li>Fragments let you construct sets of fields, and then include them in queries where you need to</li><li>It‚Äôs commonly used to split complicated application data requirements into smaller chunks</li></ul></li><li><p>Operation Name</p><ul><li>Operation Type<ul><li>Query</li><li>Mutation</li><li>Subscription</li></ul></li><li>Operation Name</li></ul></li><li><p>Variables</p><ul><li>It want to give dynamic power to graphql, as in most applications, the arguments to fields will be dynamic</li><li>Graphql supports this use case via variables</li><li>we could do:<ul><li>replace the static value in the query with <code>$variable</code></li><li>declare <code>$variable</code> as one of the variables accepted by the query</li><li>pass <code>variable: value</code> in the separate transport specific variables dictionary</li></ul></li><li>using variable could help us denote which arguments are expected to be dynamic</li><li>we should never do string interpolation to construct queries from user supplied values</li></ul></li></ul><pre><code class="ruby">query HeroNameAndFriends($episode: Episode) &#123;  hero(episode: $episode) &#123;    name    friends &#123;      name    &#125;  &#125;&#125;&#123;  &quot;episode&quot;: &quot;JEDI&quot;&#125; </code></pre><ul><li>Default variables</li></ul><pre><code class="ruby">query HeroNameAndFriends($episode: Episode = &quot;defaultOne&quot;) &#123;  hero(episode: $episode) &#123;    name    friends &#123;      name    &#125;  &#125;&#125;&#123;  &quot;episode&quot;: &quot;JEDI&quot;&#125; </code></pre><ul><li><p>Directives</p><ul><li>use this variable to dynamically change the structure and shape of our queries using variables</li><li><code>@include(if: Boolean)</code> only includes this field in the result if the argument is true</li><li><code>@skip(if: Boolean)</code> skip this field if the argument is true</li></ul></li><li><p>Mutations</p><ul><li>A way to modify server side data</li><li>A convention that any operations that cause writes should be sent explicitly via a mutation</li><li>!!! While query fields are executed in parallel, mutation fields run in series, one after the other<ul><li>means if we send two incrementCredits mutations in one request, the first is guranteed to finish before the second begins, ensuring that we don‚Äôt end up with a race condition with ourselves</li></ul></li></ul></li><li><p>Inline Fragments</p><ul><li><p>GraphQL schemas include the ability to define interfaces and union types</p></li><li><p>EG below, we need to return different attributes based on hero character</p><pre><code class="ruby">query HeroForEpisode($ep: Episode!) &#123;hero(episode: $ep) &#123;  name  ... on Droid &#123;    primaryFunction  &#125;  ... on Human &#123;    height  &#125;&#125;&#125;</code></pre></li></ul></li><li><p>Meta fields</p><ul><li>there are situations where you don‚Äôt know what type you‚Äôll get back from the service</li><li>we need to determine how to handle that data on the client</li><li>we could use <code>__typename</code></li></ul></li></ul><h1 id="3-Schemas-and-Types"><a href="#3-Schemas-and-Types" class="headerlink" title="3. Schemas and Types"></a>3. Schemas and Types</h1><h2 id="3-1-how-the-schema-work"><a href="#3-1-how-the-schema-work" class="headerlink" title="3.1 how the schema work"></a>3.1 how the schema work</h2><ul><li><p>How does GraphQL work</p><ul><li><p>start with a <code>root</code> object</p></li><li><p>select the hero field on that</p></li><li><p>for the object returned by hero, we select the name and appearsIn fields</p><pre><code class="ruby">&#123;hero &#123;  name  appearsIn&#125;&#125;</code></pre></li></ul></li><li><p>we should know what we could query for</p><ul><li>an exact description of the data we can ask for</li><li>what kind of objects might they return</li><li>what fields are available on those sub objects</li></ul></li><li><p>Schema</p><ul><li>Each graphQL services defines a set of types which completely describe the set of possible data you can query on the service</li></ul></li></ul><h2 id="3-2-Type-Language"><a href="#3-2-Type-Language" class="headerlink" title="3.2 Type Language"></a>3.2 Type Language</h2><ul><li>GraphQL use its won Schema Language</li></ul><h3 id="3-2-1-Object-Types-and-Fields"><a href="#3-2-1-Object-Types-and-Fields" class="headerlink" title="3.2.1 Object Types and Fields"></a>3.2.1 Object Types and Fields</h3><ul><li>Object types<ul><li>represent a kind of object you can fetch from your service, and what fields it has</li></ul></li></ul><pre><code class="ruby">type Character &#123;  name: String!// means an array of Episode objects, notnull, 0 or more items, and each item would be an episode object   appearsIn: [Episode!]!&#125;</code></pre><h3 id="3-2-2-Query-and-Mutation-types"><a href="#3-2-2-Query-and-Mutation-types" class="headerlink" title="3.2.2 Query and Mutation types"></a>3.2.2 Query and Mutation types</h3><ul><li>Entry points into the schema</li></ul><h3 id="3-2-3-Scalar-Types"><a href="#3-2-3-Scalar-Types" class="headerlink" title="3.2.3 Scalar Types"></a>3.2.3 Scalar Types</h3><ul><li>Scalar types represent the leaves of the query</li><li>default scalar types<ul><li>Int</li><li>Float</li><li>String</li><li>Boolean</li><li>ID<ul><li>it represents a unique identifier</li><li>The ID type is serialized in the same way as a String, but it means it‚Äôs not intended to be human readable</li></ul></li></ul></li><li>We could also define our own Scalar type in this way<ul><li><code>scalar Date</code></li></ul></li></ul><h3 id="3-2-4-Enumeration-Types"><a href="#3-2-4-Enumeration-Types" class="headerlink" title="3.2.4 Enumeration Types"></a>3.2.4 Enumeration Types</h3><ul><li>Restricted to a particular set of allowed values</li><li>Allow you to<ul><li>validate that any arguments of this type are one of the allowed values</li><li>communicate through the type system that a field will always be one of a finite set of values</li></ul></li></ul><h3 id="3-2-5-Lists-and-Non-Null"><a href="#3-2-5-Lists-and-Non-Null" class="headerlink" title="3.2.5 Lists and Non-Null"></a>3.2.5 Lists and Non-Null</h3><pre><code>type Character &#123;  name: String!  appearsIn: [Episode]!&#125;</code></pre><ul><li>We could use <code>!</code> to indicate it should never return null</li><li>We could use <code>[]</code> to indicate that should be an array</li></ul><h3 id="3-2-6-Interfaces"><a href="#3-2-6-Interfaces" class="headerlink" title="3.2.6 Interfaces"></a>3.2.6 Interfaces</h3><ul><li>An abstract type that includes a certain set of fields that a type must include to implement the interface</li></ul><pre><code class="ruby">interface Character &#123;    id: ID!  name: String!  friends: [Character]  appearsIn: [Episode]!&#125;type Human implements Character &#123;  id: ID!  name: String!  friends: [Character]  appearsIn: [Episode]!  starships: [Starship]  totalCredits: Int&#125;type Droid implements Character &#123;  id: ID!  name: String!  friends: [Character]  appearsIn: [Episode]!  primaryFunction: String&#125;</code></pre><ul><li>Type implement the interface need to have all those fields, but they could also have their own fields</li></ul><h3 id="3-2-7-Union-Types"><a href="#3-2-7-Union-Types" class="headerlink" title="3.2.7 Union Types"></a>3.2.7 Union Types</h3><p><code>union SearchResult = Human | Droid | Starship</code></p><h3 id="3-2-8-Input-Types"><a href="#3-2-8-Input-Types" class="headerlink" title="3.2.8 Input Types"></a>3.2.8 Input Types</h3><ul><li>we need to pass complex objects especially when we are using mutations, where we want to pass in a whole object to be created</li></ul><pre><code class="ruby">input ReviewInput &#123;  stars: Int!  commentary: String&#125;mutation CreateReviewForEpisode($ep: Episode!, $review: ReviewInput!) &#123;  createReview(episode: $ep, review: $review) &#123;    stars    commentary  &#125;&#125;</code></pre><h1 id="4-Validation"><a href="#4-Validation" class="headerlink" title="4. Validation"></a>4. Validation</h1><ul><li>Graph ql has validation module to fulfill the validation phase of fulfilling a graphQL result</li></ul><h1 id="5-Execution"><a href="#5-Execution" class="headerlink" title="5. Execution"></a>5. Execution</h1><h2 id="5-1-Resolvers"><a href="#5-1-Resolvers" class="headerlink" title="5.1 Resolvers"></a>5.1 Resolvers</h2><ul><li>Each field in a GraphQL query is a function or method of the previous type which returns the next type</li><li>Each field is backed by a function called the resolver. When a field is executed, the corresponding resolver is called to produce the next value</li><li>The resolver continue to work until reach scalar values</li></ul><h2 id="5-2-Root-fields"><a href="#5-2-Root-fields" class="headerlink" title="5.2 Root fields"></a>5.2 Root fields</h2><pre><code class="ruby">Query: &#123;  human(obj, args, context, info) &#123;    return context.db.loadHumanByID(args.id).then(      userData =&gt; new Human(userData)    )  &#125;&#125;</code></pre><ul><li>obj<ul><li>previous object</li></ul></li><li>args<ul><li>arguments provided to the field in the graphQL query</li></ul></li><li>context<ul><li>a value which is provided to every resolver and holds important contextual information like the currently logged in user, or access to a database</li></ul></li><li>info<ul><li>a value which holds field specific information relevant to the current query as well as the schema details</li></ul></li></ul><h1 id="6-Best-Practices"><a href="#6-Best-Practices" class="headerlink" title="6. Best Practices"></a>6. Best Practices</h1><h2 id="6-1-HTTP"><a href="#6-1-HTTP" class="headerlink" title="6.1 HTTP"></a>6.1 HTTP</h2><ul><li><p>Mostly use HTTP with graphQL</p></li><li><p>Normally web frameworks use a pipeline model where requests are passed through a stack of middle ware</p></li><li><p>Requests could be inspected, transformed, modified or terminated with a response</p></li><li><p>GraphQL should be placed after all authentication middleware‚Äî thus you have access to the same session and user info you would in your HTTP endpoints handler</p></li><li><p>GraphQL server operates on a single URL/ endpoint, usually <code>graphql</code> , and all graphql requests for a given service should be directed at this endpoint</p></li></ul><h2 id="6-2-JSON-with-GZIP"><a href="#6-2-JSON-with-GZIP" class="headerlink" title="6.2 JSON with GZIP"></a>6.2 JSON with GZIP</h2><ul><li>typically respond using JSON, and we compress it with GZIP</li></ul><h2 id="6-3-Versioning"><a href="#6-3-Versioning" class="headerlink" title="6.3 Versioning"></a>6.3 Versioning</h2><ul><li>No need to do versioning for graphql api</li><li>Why do most APIs version? When there‚Äôs limited control over the data that‚Äôs returned from an API endpoint, <em>any change</em> can be considered a breaking change, and breaking changes require a new version. If adding new features to an API requires a new version, then a tradeoff emerges between releasing often and having many incremental versions versus the understandability and maintainability of the API.</li><li>In contrast, GraphQL only returns the data that‚Äôs explicitly requested, so new capabilities can be added via new types and new fields on those types without creating a breaking change. This has led to a common practice of always avoiding breaking changes and serving a versionless API.</li></ul><h2 id="6-4-Nullability"><a href="#6-4-Nullability" class="headerlink" title="6.4 Nullability"></a>6.4 Nullability</h2><ul><li>GraphQL default to nullable unless you specifically declare nonnull</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.graphql-java-kickstart.com/">https://www.graphql-java-kickstart.com/</a>  </li><li><a href="https://graphql.org/learn/">https://graphql.org/learn/</a>  </li><li><a href="https://www.apollographql.com/docs/federation/">https://www.apollographql.com/docs/federation/</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;GraphQL-Read&quot;&gt;&lt;a href=&quot;#GraphQL-Read&quot; class=&quot;headerlink&quot; title=&quot;GraphQL Read&quot;&gt;&lt;/a&gt;GraphQL Read&lt;/h1&gt;&lt;h1 id=&quot;1-Introduction&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
  </entry>
  
  <entry>
    <title>Â¶Ç‰ΩïÁºìËß£Áñ≤Âä≥</title>
    <link href="https://www.llchen60.com/%E5%A6%82%E4%BD%95%E7%BC%93%E8%A7%A3%E7%96%B2%E5%8A%B3/"/>
    <id>https://www.llchen60.com/%E5%A6%82%E4%BD%95%E7%BC%93%E8%A7%A3%E7%96%B2%E5%8A%B3/</id>
    <published>2021-11-02T13:31:04.000Z</published>
    <updated>2021-11-02T13:34:58.934Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2021/11/02/zEvGV8uDnJxoITr.png" alt="Â¶Ç‰ΩïÊäµÊäóÁºìËß£Áñ≤Âä≥.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/11/02/zEvGV8uDnJxoITr.png&quot; alt=&quot;Â¶Ç‰ΩïÊäµÊäóÁºìËß£Áñ≤Âä≥.png&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
  </entry>
  
  <entry>
    <title>Á¢≥ËææÂ≥∞‰∏éÁ¢≥‰∏≠Âíå</title>
    <link href="https://www.llchen60.com/%E7%A2%B3%E8%BE%BE%E5%B3%B0%E4%B8%8E%E7%A2%B3%E4%B8%AD%E5%92%8C/"/>
    <id>https://www.llchen60.com/%E7%A2%B3%E8%BE%BE%E5%B3%B0%E4%B8%8E%E7%A2%B3%E4%B8%AD%E5%92%8C/</id>
    <published>2021-09-30T02:21:14.000Z</published>
    <updated>2021-09-30T02:22:44.858Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2021/09/30/XGS6Qey4qHki2FC.png" alt="Á¢≥ËææÂ≥∞‰∏éÁ¢≥‰∏≠Âíå"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/09/30/XGS6Qey4qHki2FC.png&quot; alt=&quot;Á¢≥ËææÂ≥∞‰∏éÁ¢≥‰∏≠Âíå&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
  </entry>
  
  <entry>
    <title>Cassandra</title>
    <link href="https://www.llchen60.com/Cassandra/"/>
    <id>https://www.llchen60.com/Cassandra/</id>
    <published>2021-09-17T13:05:55.000Z</published>
    <updated>2021-09-17T13:41:43.051Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://i.loli.net/2021/09/17/IGdzKBJwD9TbZ6f.png" alt="Cassandra MindMap.png"></p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><h2 id="1-1-Background"><a href="#1-1-Background" class="headerlink" title="1.1 Background"></a>1.1 Background</h2><ul><li>We wanna have a distributed and scalable system that can store a <strong>huge amount of structured data</strong>, which is indexed by a row key where each row can have an <strong>unbounded</strong> number of columns.</li><li>Cassandra was originally developed at Facebook in 2007 for index search feature. It‚Äôs designed to provide scalability, availability, and reliability to store large amounts of data.</li><li>It combines nature of Dynamo which is a <strong>key value store</strong> and the data model of Bigtable which is a <strong>column based</strong> data store</li><li>Cassandra is in favor of availability and partition tolerance, it could be tuned with <strong>replication factor</strong> and <strong>consistency levels</strong> to meet <strong>strong consistency</strong> requirements, and of course with a performance cost.</li><li>It uses peer to peer architecture, with each node connected to all other nodes</li><li>Each Cassandra node performs all database operations and can serve client requests without the need for any leader node.</li></ul><h2 id="1-2-Use-cases"><a href="#1-2-Use-cases" class="headerlink" title="1.2 Use cases"></a>1.2 Use cases</h2><ul><li>Store key value data with high availability</li><li>Time series data model<ul><li>Due to its data model and log structured storage engine, cassandra benefits from high performing write operations, This also make it well suited for storing and analyzing sequentially captured metrics</li></ul></li><li>Write Heavy Applications<ul><li>Suited for write intensive applications such as time series streaming services, sensor logs, and IoT applications</li></ul></li></ul><h1 id="2-High-Level-Architecture"><a href="#2-High-Level-Architecture" class="headerlink" title="2. High Level Architecture"></a>2. High Level Architecture</h1><h2 id="2-1-Common-Terms"><a href="#2-1-Common-Terms" class="headerlink" title="2.1 Common Terms"></a>2.1 Common Terms</h2><p><img src="https://i.loli.net/2021/09/17/IrfBD5HFqAX76NJ.png" alt="Primary and Clustering Keys"></p><ul><li>Column<ul><li>A key value pair and is the most basic unit of data structure</li><li>Column Key: Uniquely identifies a column in a row</li><li>Column Value: Store a value or a collection of values</li></ul></li><li>Row<ul><li>A container for columns referenced by primary key. Cassandra does not store a column that has a null value, this saves a lot of space</li></ul></li><li>Table<ul><li>A container of rows</li></ul></li><li>Keyspace<ul><li>A container for tables that span over one or more Cassandra nodes</li></ul></li><li>Cluster<ul><li>Container of Keyspace</li></ul></li><li>Node<ul><li>A computer system running an instance of Cassandra,</li><li>Can be a physical host, a machine instance in the cloud or even a docker container</li></ul></li></ul><h2 id="2-2-Data-Partitioning"><a href="#2-2-Data-Partitioning" class="headerlink" title="2.2 Data Partitioning"></a>2.2 Data Partitioning</h2><ul><li>Cassandra use consistent hashing as DynamoDB does</li></ul><h2 id="2-3-Primary-Key"><a href="#2-3-Primary-Key" class="headerlink" title="2.3 Primary Key"></a>2.3 Primary Key</h2><ul><li>The primary key consists of two parts:  E.G Primary Key as (city_id, employee_id)<ul><li>Partition Key<ul><li>Decides how data is distributed across nodes</li><li>city_id is the primary key, means the data will be partitioned by the city_id field, all rows with the same city_id will reside on the same node</li></ul></li><li>Clustering Key<ul><li>Decides how data is stored within a node</li><li>We could have multiple clustering keys, clustering columns specify the order that the data is arranged on a node.</li><li>employee_id is the clustering key. Within each node, the data is stored in sorted order according to the employee_id column.</li></ul></li></ul></li></ul><h2 id="2-4-Partitioner"><a href="#2-4-Partitioner" class="headerlink" title="2.4 Partitioner"></a>2.4 Partitioner</h2><p><img src="https://i.loli.net/2021/09/17/3NdkOaXUpbgnWq9.png" alt="Partitioner Flow"></p><ul><li>Responsible for determining how data is distributed on the consistent hash ring.</li><li>Cassandra use <strong>Murmur3 hashing function</strong> ‚Äî which will always produce the same hash for a given partition key</li><li>All Cassandra nodes learn about the <strong>token assignments of other nodes</strong> through gossip. This means any node can handle a request for any other node‚Äôs range. The node receiving the request is called the <strong>coordinator</strong>, and any node can act in this role. If a key does not belong to the coordinator‚Äôs range, it <strong>forwards the request</strong> to the replicas responsible for that range.</li></ul><h2 id="2-5-Coordinator-Node"><a href="#2-5-Coordinator-Node" class="headerlink" title="2.5 Coordinator Node"></a>2.5 Coordinator Node</h2><ul><li>A client may connect to any node in the cluster to initiate a read or write query. This node is known as the coordinator node, the coordinator identifies the nodes responsible for the data that is being written or read    and forwards the queries to them</li></ul><h1 id="3-Low-Level-Architecture"><a href="#3-Low-Level-Architecture" class="headerlink" title="3. Low Level Architecture"></a>3. Low Level Architecture</h1><h2 id="3-1-Replication-Strategy"><a href="#3-1-Replication-Strategy" class="headerlink" title="3.1 Replication Strategy"></a>3.1 Replication Strategy</h2><ul><li><p>Each node in Cassandra serves as a replica for a different range of data.</p></li><li><p>It stores <strong>multiple copies of data</strong> and <strong>spreads them across various replicas</strong>.</p></li><li><p>The replication behavior is controlled by two factors</p><ul><li><p>Replication Factor</p><ul><li>Decides how many replicas the system will have</li><li>This represents the <strong>number of nodes that will receive the copy of the same data</strong></li><li>Each keyspace in cassandra can have a different replication factor</li></ul></li><li><p>Replication Strategy</p><ul><li><p>Decides which nodes will be responsible for the replicas</p></li><li><p>The node that owns the range in which the hash of the partition key falls will be the first replica</p></li><li><p>All the additional replicas are placed on the <strong>consecutive nodes</strong></p></li><li><p>Cassandra places the subsequent replicas on the next nodes in a clockwise manner</p></li><li><p>Two kinds of replication strategies</p><ul><li><p>Simple Replication Strategy</p><p>  <img src="https://i.loli.net/2021/09/17/cnz12lGFWEPw4fS.png" alt="Simple Replication Strategy"></p><ul><li>Used for a <strong>single data center cluster</strong></li><li>Cassandra places the first replica on a node determined by the partitioner and the subsequent replicas on the next node in a clockwise manner</li></ul></li><li><p>Network Topology Strategy</p><p>  <img src="https://i.loli.net/2021/09/17/TSAZbXKCYf9IsoN.png" alt="Network Topology Strategy"></p><ul><li>Used for multiple data centers</li><li>We can specify different replication factors for different data centers. We could then specify how many replicas will be placed in each data center</li><li>Additional replicas, in the same data center, are placed by <strong>walking the ring clockwise until reaching the 1st node in another rack</strong>. This is done to guard against a complete rack failure, as nodes in the same rack(or similar physical grouping) tend to fail together due to power, cooling or network issues.</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="3-2-Consistency-Levels"><a href="#3-2-Consistency-Levels" class="headerlink" title="3.2 Consistency Levels"></a>3.2 Consistency Levels</h2><ul><li>Definition<ul><li><strong>Minimum number of nodes</strong> that must fulfill a read or write operation before the operation can be considered successful</li><li>It allows use to <strong>specify different consistency levels</strong> for read and write</li><li>It also has <strong>tunable consistency level</strong></li><li>Tradeoff between consistency and response time<ul><li>As a higher consistency level means more nodes need to respond to a read or write query, giving user more assurance that the values present on each replica are the same</li></ul></li></ul></li></ul><h3 id="3-2-1-Write-Consistency-Levels"><a href="#3-2-1-Write-Consistency-Levels" class="headerlink" title="3.2.1 Write Consistency Levels"></a>3.2.1 Write Consistency Levels</h3><ul><li>Consistency Levels specify how many replica nodes must respond for the write to be reported as successful to the client</li><li>Level is specified <strong>per query by the client</strong></li><li>Cassandra is eventually consistent, updates to other replica nodes may continue in the background</li><li>How does Cassandra perform a write operation?<ul><li>Coordinator node contacts all replicas, as determined by the <strong>replication factor</strong> , and consider the write successful when a number of replicas equal to the consistency level acknowledge the write</li></ul></li><li>Write Consistency Levels List:<ul><li>One/ Two/ Three<ul><li>The data must be written to at least the specified number of replica nodes before a write is considered successful</li></ul></li><li>Quorum<ul><li>Data must be written to at least a quorum of replica nodes</li><li>Quorum is defined as <code>floor(RF/2 + 1)</code>  RF represents replication factor</li></ul></li><li>All<ul><li>ensures the data is written to all replica nodes</li><li>provides the highest consistency but lowest availability as writes will fail if any replica is down</li></ul></li><li>Local Quorum<ul><li>Ensure that data is written to a quorum of nodes in the same datacenter as the coordinator</li><li>Does not wait for the response from the other data centers</li></ul></li><li>Each Quorum<ul><li>Ensures that the data is written to a quorum of nodes in each datacenter</li></ul></li><li>Any<ul><li>The data must be written to at least one node</li><li>In the extreme case, when all replica nodes for the given partition key are down, the write can still succeed after a hinted handoff (see 3.2.4 section) has been written.<ul><li>In this case, an any write could succeed with hinted handoff, but it will not be readable until the replica nodes for that partition has recovered and the latest data is written on them</li></ul></li></ul></li></ul></li></ul><h3 id="3-2-2-Read-Consistency-Levels"><a href="#3-2-2-Read-Consistency-Levels" class="headerlink" title="3.2.2 Read Consistency Levels"></a>3.2.2 Read Consistency Levels</h3><ul><li><p>Read Query Consistency Level specify how many replica nodes must respond to a read request before returning the data</p></li><li><p>It has the same consistency levels for read operations as that of write operations exception Each_Quorum cause it‚Äôs too expensive</p></li><li><p>To achieve strong consistency, we need to do <code>R + W &gt; RF</code> R represents read replica count, W represents write replication count, RF represents replication factor</p><ul><li>All client reads will see the most recent write in this scenario, and we will have strong consistency</li></ul></li><li><p>How does Cassandra perform a read operation?</p><ul><li><p>Coordinator always sends the read request to the fastest node</p><ul><li>E.G  for quorum=2, the coordinator sends the requests to the fastest node and the <strong>digest of the data</strong> from the second fastest node<ul><li>digest is the checksum of the data, we use this to save network bandwidth</li></ul></li></ul></li><li><p>if the digest doesn‚Äôt match, means some replica do not have the latest version of data</p><ul><li><p>Coordinator then <strong>reads the data from all the replicas</strong> to determine the latest data</p></li><li><p>Then coordinator <strong>returns the latest data to the client and initiates a read repair request</strong></p></li><li><p>The read repair request will help push the newer version of data to nodes with the older version</p><p>  <img src="https://i.loli.net/2021/09/17/sPM6HnKthBpT945.png" alt="Read Operation with Snitch"></p></li></ul></li><li><p>latest write timestamp is used as a mark for the correct version of data, read repair operation is performed only in a portion of the total reads to avoid performance degradation</p></li></ul></li></ul><h3 id="3-2-3-Snitch"><a href="#3-2-3-Snitch" class="headerlink" title="3.2.3 Snitch"></a>3.2.3 Snitch</h3><ul><li><p>Functions</p><ul><li>Application that determines the proximity of nodes within the ring, also tells which nodes are faster ‚Äî monitor the read latencies</li><li>It keeps track of the network topology of Cassandra nodes, determines which <strong>data centers and racks</strong> nodes belong to</li><li>Replication strategy use this information provided by the Snitch to spread the replicas across the cluster intelligently. It could do its best by not having more than one replica on the same rack</li></ul></li><li><p>Cassandra nodes use this info to route read/ write requests efficiently</p><p>  <img src="https://i.loli.net/2021/09/17/ZnaOJqIvgdcMmAW.png" alt="Request when set consistency to one"></p></li></ul><h3 id="3-2-4-Hinted-Handoff"><a href="#3-2-4-Hinted-Handoff" class="headerlink" title="3.2.4 Hinted Handoff"></a>3.2.4 Hinted Handoff</h3><p><img src="https://i.loli.net/2021/09/17/QvSmb5wntE2AHJd.png" alt="Hinted Handoff"></p><ul><li>To let Cassandra still serve write requests even when nodes are down</li><li>When a node is down, the coordinator nodes <strong>writes a hint in a text file on local disk</strong><ul><li>Hint contains the data itself along with information about which node the data belongs to</li><li>Recover from gossiper ‚Äî When the coordinator node discovers from the gossiper that a node for which it holds hints has recovered, it forwards the write request for each hint to the target</li><li>Recover from routine call ‚Äî each node every ten minutes checks to see if the failing node, for which it is holding any hints, has recovered</li></ul></li><li>With consistency level ‚ÄòAny,‚Äô<ul><li>if all the replica nodes are down, the coordinator node will <strong>write the hints for all the nodes and report success to the client.</strong></li><li>However, this data will <strong>not reappear in any subsequent reads</strong> until one of the replica nodes comes back online, and the coordinator node successfully forwards the write requests to it.</li><li>This is assuming that the coordinator node is up when the replica node comes back.</li><li>This also means that we can lose our data if the coordinator node dies and never comes back. For this reason, we should avoid using the ‚ÄòAny‚Äô consistency level</li></ul></li><li>For node offline for quite long<ul><li>Hints can build up considerably on other nodes</li><li>When it back online, other nodes tend to flood that node with write requests</li><li>It would cause issues on the node, as it is already trying to come back after a failure</li><li>To address this, Cassandra <strong>limits the storage of hints to a configurable time window</strong></li><li>By default, set the time window to 3 hours. Post that, older hints will be removed  ‚Äî now the recovered nodes will have stale data<ul><li>The stale data would be fixed during the read path, it will issue a read repair when it sees the stale data</li></ul></li></ul></li><li>When the cluster cannot meet the consistency level specified by the client, Cassandra fails the write request and does not store a hint .</li></ul><h2 id="3-3-Gossiper"><a href="#3-3-Gossiper" class="headerlink" title="3.3 Gossiper"></a>3.3 Gossiper</h2><h3 id="3-3-1-How-does-Cassandra-use-Gossip-Protocol"><a href="#3-3-1-How-does-Cassandra-use-Gossip-Protocol" class="headerlink" title="3.3.1 How does Cassandra use Gossip Protocol?"></a>3.3.1 How does Cassandra use Gossip Protocol?</h3><ul><li>What‚Äôs for?<ul><li>Cassandra uses gossip protocol that allows each node to keep track of state information about the other nodes in the cluster.</li><li>It‚Äôs a Peer to Peer communication mechanism in which nodes <strong>periodically exchange state information about themselves and other nodes they know about</strong></li></ul></li><li>How it works?<ul><li>Each node initiates a gossip round every second to exchange state info about themselves with one to three other random nodes</li><li>Each gossip message has a version associated with it, so during a gossip exchange, older info is overwritten with the most current state for a particular node</li></ul></li><li>Generation number<ul><li>Each node stores a generation number which will be incremented every time a node restart</li><li>Node receiving the gossip message can compare the generation number it knows and the gossip message‚Äôs generation number</li><li>If the generation number in the gossip message is higher, it knows the node was restarted</li></ul></li><li>Seed nodes<ul><li>For node starting up for the first time</li><li>Assist in gossip convergence, thus guarantee schema/ state changes propagate regularly</li></ul></li></ul><h3 id="3-3-2-Node-Failure-Detection"><a href="#3-3-2-Node-Failure-Detection" class="headerlink" title="3.3.2 Node Failure Detection"></a>3.3.2 Node Failure Detection</h3><ul><li>Disadvantages for heartbeat<ul><li>outputs a boolean value telling us if the system is alive or not;</li><li>there is no middle ground.</li><li>Heartbeating uses a fixed timeout, and if there is no heartbeat from a server, the system, after the timeout, assumes that the server has crashed.</li><li>If we keep the timeout short, the system will be able to detect failures quickly but with many false positives due to slow machines or faulty networks.</li><li>On the other hand, if we keep the timeout long, the false positives will be reduced, but the system will not perform efficiently for being slow in detecting failures.</li></ul></li><li>Use adaptive failure detection mechanism  ‚Äî‚Äî Phi Accrual Failure Detector<ul><li>Use historical heartbeat information to make the threshold adaptive</li><li>It outputs the suspicion level about a server</li><li>As a node‚Äôs suspicion level increases, the system can gradually decide to stop sending new requests to it</li><li>It makes the distributed system efficient as it takes into account fluctuations in the network env and other intermittent server issues before declaring a system completely dead</li></ul></li></ul><h2 id="3-4-Anatomy-of-Cassandra‚Äôs-Write-Operation"><a href="#3-4-Anatomy-of-Cassandra‚Äôs-Write-Operation" class="headerlink" title="3.4 Anatomy of Cassandra‚Äôs Write Operation"></a>3.4 Anatomy of Cassandra‚Äôs Write Operation</h2><p>Cassandra stores data both <strong>in memory and on disk</strong> to provide both high performance and durability. Every write includes a timestamp, write path involves a lot of components: </p><p><img src="https://i.loli.net/2021/09/17/LrMK7ckIS2zEsU1.png" alt="Write Path"></p><ul><li>Each write is appended to a commit log, which is stored on disk</li><li>It is then written to Memtable in memory</li><li>Periodically, MemTables are flushed to SSTables on the disk</li><li>Periodically, compaction runs to merge SSTables</li></ul><h3 id="3-4-1-Commit-Log"><a href="#3-4-1-Commit-Log" class="headerlink" title="3.4.1 Commit Log"></a>3.4.1 Commit Log</h3><ul><li>When a node receives a write request, it immediately writes data to a commit log</li><li>Commit log is a <strong>write ahead log</strong> stored on disk</li><li>Used as a crash recovery mechanism to support Cassandra‚Äôs durability goals</li><li>A write will not be considered successful on the node until it‚Äôs <strong>written to the commit log</strong><ul><li>This ensures if a write operation does not make it to the in-memory store, it will still be possible to recover the data</li></ul></li><li>If we shut down the node or it crashes unexpectedly, the commit log can ensure that data is not lost; that‚Äôs because if the node restart, the commit log gets replayed</li></ul><h3 id="3-4-2-MemTable"><a href="#3-4-2-MemTable" class="headerlink" title="3.4.2 MemTable"></a>3.4.2 MemTable</h3><ul><li>After written to the commit log, the data is written to a memory resident data structure called memTable<ul><li>Each node has a MemTable in memory for each Cassandra table</li><li>Each MemTable contains data for a specific Cassandra table, and it resembles that table in memory</li><li>Each MemTable accrues writes and <strong>provides reads for data not yet flushed to disk</strong></li><li>Commit log stores all the writes in sequential order, with each new write appended to the end; whereas MemTable stores data in the sorted order of partition key and clustering columns</li><li>After writing data to the commit log and MemTable, the node <strong>sends an acknowledgement to the coordinator</strong> that the data has been successfully written</li></ul></li></ul><h3 id="3-4-3-SStable"><a href="#3-4-3-SStable" class="headerlink" title="3.4.3 SStable"></a>3.4.3 SStable</h3><ul><li>When the number of objects stored in the MemTable reaches a threshold, the contents of the MemTable are <strong>flushed to disk</strong> in a file called <strong>SSTable</strong><ul><li>At this point, a new MemTable is created to store subsequent data</li><li>The flush is non blocking operation</li><li>Multiple Memtables may exist for a single table<ul><li>One current, and the rest waiting to be flushed</li></ul></li><li>When the MemTable is flushed to SStables, <strong>corresponding entries in the commit log</strong> are removed</li></ul></li><li>SStable ‚ÄîSorted String Table<ul><li>Once a MemTable is flushed to disk as an SStable, it is immutable and cannot be changed later</li><li>Each delete or update is considered as a new write operation</li></ul></li><li>The current data state of a Cassandra table consists of its MemTables in memory and SSTables on the disk.<ul><li>Therefore, on reads, Cassandra will read both SSTables and MemTables to find data values, as the MemTable may contain values that have not yet been flushed to the disk.</li><li>The MemTable works like a write-back cache that Cassandra looks up by key</li></ul></li></ul><p><img src="https://i.loli.net/2021/09/17/Qd7x4M6HRrtuAoZ.png" alt="Whole Write Path"></p><h2 id="3-5-Anatomy-of-Cassandra‚Äôs-Read-Operation"><a href="#3-5-Anatomy-of-Cassandra‚Äôs-Read-Operation" class="headerlink" title="3.5 Anatomy of Cassandra‚Äôs Read Operation"></a>3.5 Anatomy of Cassandra‚Äôs Read Operation</h2><p><img src="https://i.loli.net/2021/09/17/wIZKE97YqVNAsrP.png" alt="Whole Read Path"></p><h3 id="3-5-1-Caching"><a href="#3-5-1-Caching" class="headerlink" title="3.5.1 Caching"></a>3.5.1 Caching</h3><ul><li>Row Cache<ul><li>Cache frequently read/ hot rows</li><li>Stores a complete data row, which can be returned directly to the client if requested by a read operation</li><li>Could significantly speed up read access for frequently accessed rows, at the cost of more memory usage</li></ul></li><li>Key Cache<ul><li>Stores a map of recently read partition keys to their <strong>SSTable offsets</strong></li><li>This facilitates faster read access into SSTables and improves the read performance</li><li>Use less memory comparing with row cache and provides a considerable improvement for read operations</li></ul></li><li>Chunk Cache<ul><li>Chunk Cache is used to store umcompressed chunks of data read from SSTable files that are accessed frequently</li></ul></li></ul><h3 id="3-5-2-Read-From-MemTable"><a href="#3-5-2-Read-From-MemTable" class="headerlink" title="3.5.2 Read From MemTable"></a>3.5.2 Read From MemTable</h3><ul><li>When a read request come in, node performs a binary search on the partition key to find the required partition and then return the row</li></ul><h3 id="3-5-3-Read-From-SSTable"><a href="#3-5-3-Read-From-SSTable" class="headerlink" title="3.5.3 Read From SSTable"></a>3.5.3 Read From SSTable</h3><ul><li><p>Bloom Filters</p><ul><li>Each SSTable has a Bloom Filter associated with it, which tells if a particular key is present in it or not</li><li>Used to boost performance of read operations</li><li>It‚Äôs a very fast, non deterministic algorithms for testing whether an element is a member of a set</li><li>It‚Äôs possible to get a false positive but never a false negative</li><li>Theory<ul><li>It works by <strong>mapping the values in a data set into a bit array</strong> and <strong>condensing a larger data set into a digest string</strong> with a hash function</li><li>Filters are stored in memory and are used to improve performance by reducing the need for disk access on key lookups</li></ul></li></ul></li><li><p>How are SSTables stored on the disk?</p><ul><li><p>Consists of two files</p><ul><li><p>Data File</p><ul><li>Actual data is stored here</li><li>It has partitions and rows associated with those partitions</li><li>Partitions are in sorted order</li></ul></li><li><p>Partition Index File</p><ul><li><p>Stored on disk, partition index file stores the sorted partition keys mapped to their SSTable offsets</p></li><li><p>Enable locating a partition exactly in an SSTable rather than scanning data</p><p><img src="https://i.loli.net/2021/09/17/9gUpTXZyLSksDdK.png" alt="Read via Partition Index File"></p></li></ul></li></ul></li></ul></li><li><p>Partition Index Summary File</p><ul><li><p>It‚Äôs stored in memory, stores the summary of the partition index file for performance improvement</p><ul><li><p>Two level index, e.g, search for key=19</p></li><li><p>in partition index summary file, it lays to key range 10 - 21</p></li><li><p>then we could go to byte offset 32,</p></li><li><p>in partition index file , we start from 32, to find partition key 19, and then we could go to 5450</p><p><img src="https://i.loli.net/2021/09/17/efsVEmvGAkIldF6.png" alt="Read via Partition Index Summary File"></p></li></ul></li></ul></li><li><p>Read from KeyCache</p><ul><li><p>As the Key Cache stores a map of recently read partition keys to their SSTable offset, it‚Äôs the fastest way to find the required row in the SSTable</p><p>  <img src="https://i.loli.net/2021/09/17/5KPTohGmWpecr1a.png" alt="Read From KeyCache"></p></li></ul></li><li><p>Overall workflow</p><p>  <img src="https://i.loli.net/2021/09/17/2zKlRtS48NQYkud.png" alt="Overall Workflow"></p></li></ul><h2 id="3-6-Compaction"><a href="#3-6-Compaction" class="headerlink" title="3.6 Compaction"></a>3.6 Compaction</h2><h3 id="3-6-1-Why-we-need-compaction-And-How-it-Works"><a href="#3-6-1-Why-we-need-compaction-And-How-it-Works" class="headerlink" title="3.6.1 Why we need compaction? And How it Works?"></a>3.6.1 Why we need compaction? And How it Works?</h3><p><img src="https://i.loli.net/2021/09/17/2DgirVjkeq6AI4T.png" alt="Compaction"></p><ul><li>SSTables are immutable, which helps Cassandra achieve high write speeds</li><li>And flushing from MemTable to SSTable is a continuous process, which means we could have a large number of SSTables lying on the disk</li><li>It‚Äôs tedious to scan all these SSTables while reading</li><li>We need compaction thus we could merge multiple related SSTables into a single one to improve reading speed</li><li>During compaction, the data in SSTables is merged, keys are merged, columns are combined, obsolete values are discarded, and a new index is created</li></ul><h3 id="3-6-2-Compaction-Strategies"><a href="#3-6-2-Compaction-Strategies" class="headerlink" title="3.6.2 Compaction Strategies"></a>3.6.2 Compaction Strategies</h3><ul><li>SizeTiered Compaction Strategy<ul><li>Suitable for insert-heavy and general workloads</li><li>Triggered when multiple SSTables of a similar size are present</li></ul></li><li>Leveled Compaction Strategy<ul><li>Optimize read performance</li><li>Groups SSTables into levels, each of which has a fixed size limit which is ten times larger than the previous level</li></ul></li><li>Time Window Compaction Strategy<ul><li>Work on time series data</li><li>Compact SSTables within a configured time window</li><li>Ideal for time series data which is immutable after a fixed time interval</li></ul></li></ul><h3 id="3-6-3-Sequential-Writes"><a href="#3-6-3-Sequential-Writes" class="headerlink" title="3.6.3 Sequential Writes"></a>3.6.3 Sequential Writes</h3><ul><li>Main reason that writes perform so well in Cassandra</li><li>No reads or seeks of any kind are required for writing a value to Cassandra because all writes are append operations</li><li>Compaction is intended to amortize the reorganization of data, but it uses sequential I/O to do so, which makes it efficient</li></ul><h2 id="3-7-Tombstones"><a href="#3-7-Tombstones" class="headerlink" title="3.7 Tombstones"></a>3.7 Tombstones</h2><h3 id="3-7-1-What-are-Tombstones"><a href="#3-7-1-What-are-Tombstones" class="headerlink" title="3.7.1 What are Tombstones?"></a>3.7.1 What are Tombstones?</h3><ul><li>Scenario<ul><li>We delete some data for a node that is down or unreachable, it would miss a delete</li><li>When the node com back online later and a repair occurs, the node could resurrect the data due to re-sharing it with other nodes</li><li>To prevent deleted data from being reintroduced, Cassandra used a concept of a Tombstone</li></ul></li><li>Tombstone<ul><li>Similar to the idea of soft delete from the relational database</li><li>When we delete, Cassandra does not delete it right away, instead, it associated a tombstone with it, with Time to Expiry</li><li>It‚Äôs a marker to indicate data that has been deleted</li><li>When we execute a delete operation, data is not immediately deleted</li><li>Instead, it‚Äôs treated as an update operation that places a tombstone on the value</li><li>Default Time to Expiry is set to 10 days<ul><li>If the node is down longer than this value, it should be treated as failed and replaced</li></ul></li><li>Tombstones are removed as part of compaction</li></ul></li></ul><h3 id="3-7-2-Common-problems-associated-with-Tombstones"><a href="#3-7-2-Common-problems-associated-with-Tombstones" class="headerlink" title="3.7.2 Common problems associated with Tombstones"></a>3.7.2 Common problems associated with Tombstones</h3><ul><li>Takes storage space</li><li>When a table accumulates many tombstones, read queries on that table could become slow and can cause serious performance problems like timeouts.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/09/17/IGdzKBJwD9TbZ6f.png&quot; alt=&quot;Cassandra MindMap.png&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;1-Introduction&quot;&gt;&lt;a href=&quot;#1-Introdu
      
    
    </summary>
    
    
      <category term="SystemDesign" scheme="https://www.llchen60.com/categories/SystemDesign/"/>
    
    
      <category term="Cassandra" scheme="https://www.llchen60.com/tags/Cassandra/"/>
    
  </entry>
  
  <entry>
    <title>Logical Fallacies</title>
    <link href="https://www.llchen60.com/Logical-Fallacies/"/>
    <id>https://www.llchen60.com/Logical-Fallacies/</id>
    <published>2021-09-12T01:23:39.000Z</published>
    <updated>2021-09-12T01:50:35.560Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Logical-Fallacies"><a href="#Logical-Fallacies" class="headerlink" title="Logical Fallacies"></a>Logical Fallacies</h1><h2 id="Overconfidence"><a href="#Overconfidence" class="headerlink" title="Overconfidence"></a>Overconfidence</h2><ul><li>Overconfidence ‚Äî wishful thinking bias<ul><li>most people think they are above avg</li><li>overestimate possibilities that they want to happen</li><li><strong>this could explain the trade in financial market</strong></li><li>overconfidence in friends and leaders</li></ul></li></ul><h2 id="Cognitive-Dissonance"><a href="#Cognitive-Dissonance" class="headerlink" title="Cognitive Dissonance"></a>Cognitive Dissonance</h2><ul><li>Cognitive Dissonance  ËÆ§Áü•Â§±Ë∞É<ul><li>this concept used to describe the mental discomfort that results from holding two conflicting beliefs, values or attitudes</li><li>People tend to seek consistency in their attitudes and perceptions, so this conflict causes feelings of unease or discomfort</li><li>This inconsistency between <strong>what people believe and how they behave</strong> motivates people to <strong>engage in actions</strong> that will help minimize feelings of discomfort</li><li>when we made decision, most people will still look for info about it, to self prove hisself right‚Ä¶ in a lot different aspects‚Ä¶ to make themselves happy, and to prove they are make right decision</li><li>disposition effect ‚Äî gonna avoid that</li><li>what‚Äôs the causes for that?<ul><li>Forced Compliance<ul><li>Engaging in behaviors that are opposed to your own beliefs due to external expectations, often for work, school, or a social situation</li></ul></li><li>New Information</li><li>Decisions<ul><li>People make decisions both large and small, on a daily basis</li><li>When faced with two similar choices, people often are left with feelings of dissonance because both options are equally appealing</li><li>Once they make decisions, people need to find a way to <strong>reduce feelings of discomfort</strong></li><li>Accomplish by justifying why their choice was the best option so that they can believe they made the right decision</li></ul></li></ul></li></ul></li></ul><h2 id="Mental-Compartments"><a href="#Mental-Compartments" class="headerlink" title="Mental Compartments"></a>Mental Compartments</h2><ul><li>Mental compartments<ul><li>people don‚Äôt look at whole portfolio, in fact, people has two or more portfolio<ul><li>usually they have a safe part and a risky part</li></ul></li></ul></li></ul><h2 id="Attention-Anomalies"><a href="#Attention-Anomalies" class="headerlink" title="Attention Anomalies"></a>Attention Anomalies</h2><ul><li>Attention Anomalies<ul><li>We cannot pay attention to anything</li><li>Attention is fundamental aspect of human intelligence and its limits</li><li>Social Basis for attention<ul><li>We incline to pay more attention to what other s pay attention to</li></ul></li></ul></li></ul><h2 id="Anchoring"><a href="#Anchoring" class="headerlink" title="Anchoring"></a>Anchoring</h2><ul><li>Anchoring<ul><li>A tendency in ambiguous situations to allow one‚Äôs decisions to be affected by some anchor</li><li>Our subconscious will do anchoring for us, lol</li><li>subjects unaware of their own anchoring behavior</li><li>stock prices anchored to past values, or to other stock in same market</li></ul></li></ul><h2 id="Representativeness-Heuristic"><a href="#Representativeness-Heuristic" class="headerlink" title="Representativeness Heuristic"></a>Representativeness Heuristic</h2><ul><li>Representativeness Heuristic<ul><li>People judge by similarity to familiar types, without regard to <strong>base rate probabilities</strong><ul><li>For example, we describe a person as artist, and skeptical, then what‚Äôs the highest possible occupation of him/ her?<ul><li>two choice: banker, and sculptress</li><li>should be banker, cause there are so many more bank tellers than sculptresses</li></ul></li></ul></li><li>Tendency to see patterns in what is really random walk</li><li>Stock price manipulators try to create patterns to fool investors</li></ul></li></ul><h2 id="Disjunction-Effect"><a href="#Disjunction-Effect" class="headerlink" title="Disjunction Effect"></a>Disjunction Effect</h2><ul><li>inability to make decisions in advance in anticipation of future information</li></ul><h2 id="Magical-Thinking-amp-Quasi-Magical-Thinking"><a href="#Magical-Thinking-amp-Quasi-Magical-Thinking" class="headerlink" title="Magical Thinking  &amp; Quasi Magical Thinking"></a>Magical Thinking  &amp; Quasi Magical Thinking</h2><ul><li>Some coincidence lead you to build superstitious, but there are actually no karma (cause and effect)</li><li>Belief that unrelated events are causally connected despite the absence of any plausible causal link between them, particularly as a result of supernatural effects.</li><li>E.G<ul><li>For voting, though our vote actually has basically 0 possibility to influence president election, but a lot people do it</li><li>For lottery, we somehow put more money if we select the number</li></ul></li></ul><h2 id="Personality-Disorders"><a href="#Personality-Disorders" class="headerlink" title="Personality Disorders"></a>Personality Disorders</h2><ul><li>culture and social contagion ‚Äî collective memory<ul><li>same effect, same memory, then similar decisions</li></ul></li><li>Antisocial Personality Disorder</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Logical-Fallacies&quot;&gt;&lt;a href=&quot;#Logical-Fallacies&quot; class=&quot;headerlink&quot; title=&quot;Logical Fallacies&quot;&gt;&lt;/a&gt;Logical Fallacies&lt;/h1&gt;&lt;h2 id=&quot;Overc
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>ÊäóÈÄÜÂäõ</title>
    <link href="https://www.llchen60.com/%E6%8A%97%E9%80%86%E5%8A%9B/"/>
    <id>https://www.llchen60.com/%E6%8A%97%E9%80%86%E5%8A%9B/</id>
    <published>2021-08-28T19:28:59.000Z</published>
    <updated>2021-08-28T19:30:58.113Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ÂæàÂ∫ÜÂπ∏Âê¨‰∫ÜËøôÂú∫ËÆ≤Â∫ßÔºåÂõûÊÉ≥Ëµ∑ÂéüÂÖàÂÅöÁöÑ‰∏Ä‰∫õÂÜ≥ÂÆöÔºå‰ºöÂõø‰∫éÂõ∫ÂÆöÊÄßÊÄùÁª¥ÔºåÂõ†‰∏∫ÂÆ≥ÊÄïÂ§±Ë¥•ÔºåÂÆ≥ÊÄïË¢´ËØÅÂÆû‰∏çÂ§üËÅ™ÊòéÔºåÂ§±Âéª‰∫ÜÂæàÂ§öÂæàÂ§öÊàêÈïøÁöÑÊú∫‰ºö„ÄÇÊÑüËßâÊó†ËÆ∫ÊòØÂ∑•‰ΩúËøòÊòØÁîüÊ¥ªÔºåÂú®Â∫¶Ëøá‰∫ÜÂàöÂàöÂºÄÂßãÁöÑÁÜüÊÇâ‰∫ÜËß£Èò∂ÊÆµ‰ª•ÂêéÔºåÂêéÊúüÈô§‰∫Ü‰∏ì‰∏öÊäÄËÉΩ‰∏äÁöÑÊèêÂçá‰πãÂ§ñÔºåÊõ¥Âä†ÈáçË¶ÅÁöÑÊòØmindsetÁöÑÊèêÂçá ‚Äî ÂÖ≥‰∫é‰Ω†ÊòØÊÄé‰πàÁúãÂæÖËá™Â∑±ÁöÑÔºåÊÄé‰πàÁúãÂæÖ‰Ω†ÁªèÂéÜÁöÑ‰∫ãÊÉÖ„ÄÇ‰∏çÁü•ÈÅìÊúÄÁªàÁ≠îÊ°àÊòØ‰ªÄ‰πàÔºå‰ΩÜÊòØËøôÁØáÈáåÈù¢ËØ¥ÁöÑ‰∏úË•øËá≥Â∞ëÂëäËØâ‰∫ÜÊàëÊÉ≥Ë¶ÅËææÂà∞ÁêÜÊÉ≥ÁöÑÁä∂ÊÄÅÔºå‰Ω†ÈúÄË¶ÅÊØèÂ§©ÂÅö‰∫õ‰ªÄ‰πà :)  ÂÄºÂæóËøá‰∏ÄÊÆµÊó∂Èó¥ÂõûÊù•ÂÜçÁúãÁúãÂêÑÁßçaction items ÂëÄ</p></blockquote><h1 id="1-ÂøÉÁêÜÈüßÊÄß"><a href="#1-ÂøÉÁêÜÈüßÊÄß" class="headerlink" title="1. ÂøÉÁêÜÈüßÊÄß"></a>1. ÂøÉÁêÜÈüßÊÄß</h1><ul><li>È´òÂøÉÁêÜÈüßÊÄßÊòØÊàêÂäüËÄÖÁöÑÂÖ±ÊÄß<ul><li>Âõ†‰∏∫ÂØπ‰∫é‰ªª‰Ωï‰∏Ä‰∏™ÊàêÂäüËÄÖÊù•ËØ¥ÔºåÁ£®ÈöæÊòØÂøÖ‰∏çÂèØÂ∞ëÁöÑ‰∏ÄÈÉ®ÂàÜ</li><li>ÊàêÂäüËÄÖ ÂùöÈüß‰∏çÊãîÁöÑÁ≤æÁ•û</li><li>ÂøÉÁêÜÂ≠¶Á†îÁ©∂<ul><li>È¢ÑÊµãÊàêÂäüÁöÑÊ¶ÇÁéá Âíå ÂùöÈüß‰∏çÊãîÁöÑÁâπË¥®ÊúâÂæàÊòéÊòæÁöÑÊ≠£Áõ∏ÂÖ≥ÔºåÂíåÊô∫ÂïÜÁöÑÂÖ≥Á≥ªÂèçÂÄíÂπ∂‰∏çÊòØÂæàÂº∫</li><li>ÁîüÂ≠ò‰∏ãÊù•ÁöÑ‰∏çÊòØÊúÄÂº∫Â§ßÁöÑÁîüÁâ©Ôºå‰πü‰∏çÊòØÊúÄËÅ™ÊòéÁöÑÁîüÁâ©ÔºåËÄåÊòØÊúÄËÉΩÂ§üÈÄÇÂ∫îÂèòÂåñÁöÑÁîüÁâ©</li></ul></li></ul></li></ul><h2 id="1-1-ÂøÉÁêÜÂ≠¶ÂÆö‰πâ"><a href="#1-1-ÂøÉÁêÜÂ≠¶ÂÆö‰πâ" class="headerlink" title="1.1 ÂøÉÁêÜÂ≠¶ÂÆö‰πâ"></a>1.1 ÂøÉÁêÜÂ≠¶ÂÆö‰πâ</h2><ul><li>Â§çÂéüÂäõ resilence<ul><li>‰∫∫‰ªéÈÄÜÂ¢ÉÔºåÂÜ≤Á™ÅÔºåÁóõÊ•öÔºåÂ§±Ë¥•ÔºåÂéãÂäõÂΩì‰∏≠ËøÖÈÄüÊÅ¢Â§çÁöÑÂøÉÁêÜËÉΩÂäõ</li></ul></li><li>ÂùöÊØÖÂäõ grip</li><li>Âàõ‰º§ÂêéÁöÑÊàêÈïø PTG ‚Äî Post Traumatic Growth<ul><li>‰∏çÊ∂àÊ≤âÔºåÂ•ãËøõ</li></ul></li></ul><h2 id="1-2-È´òÂøÉÁêÜÈüßÊÄß‰∫∫ÁöÑÁâπË¥®"><a href="#1-2-È´òÂøÉÁêÜÈüßÊÄß‰∫∫ÁöÑÁâπË¥®" class="headerlink" title="1.2 È´òÂøÉÁêÜÈüßÊÄß‰∫∫ÁöÑÁâπË¥®"></a>1.2 È´òÂøÉÁêÜÈüßÊÄß‰∫∫ÁöÑÁâπË¥®</h2><ul><li>ËÉΩÂäõ<ul><li>ÈÄÇÂ∫îÂäõ</li><li>ÊàêÈïøÂäõ</li><li>ÊäóÊå´Âäõ</li><li>ÁßØÊûÅÂäõ ‚Äî ÊÉÖÁª™ÁöÑË∞ÉËäÇÁöÑÊñπÊ≥ï</li><li>ÂÖ≥Á≥ªÂäõ ‚Äî Â¶Ç‰ΩïÂª∫Á´ãÂÖ≥Á≥ª</li><li>ÊéßÂà∂Âäõ ‚Äî Ê∑°ÂÆö‰ªéÂÆπÔºåËá™ÊàëÊéßÂà∂</li></ul></li><li>ÁâπË¥®<ul><li>ÊúâÁßØÊûÅÁöÑËÆ§Áü•ÊñπÂºè  ‚Äî the power of positive thinking<ul><li>ÂÜ≥ÂÆöÊàë‰ª¨ÁöÑÂπ∏Á¶èÊåáÊï∞ÁöÑ‰∏çÊòØ‰∫ãÊÉÖÊú¨Ë∫´ÔºåËÄåÊòØÊàë‰ª¨Â¶Ç‰ΩïÁúãÂæÖËøô‰∏™‰∫ãÊÉÖ</li></ul></li><li>‰πêËßÇÁöÑÊÉÖÁª™Ë∞ÉËäÇ</li><li>ÂÅ•Â∫∑ÁöÑË∫´ÂøÉÁä∂ÊÄÅ</li><li>Âº∫Â§ßÁöÑËá™ÊàëÊïàËÉΩÊÑü  ‚Äî ÊÑüËßâËá™Â∑±ËÉΩÊàêÔºåÊÑüËßâËá™Â∑±ÊúâÁî®  lol<ul><li>ÁªìÂ©öËÉΩËÆ©Áî∑ÊÄßÈïøÂØø7Âπ¥ lol</li></ul></li><li>Ëß£ÂÜ≥ÈóÆÈ¢òÁöÑË°åÂä®Á≤æÁ•û</li><li>ËâØÂ•ΩÁöÑ‰∫∫ÈôÖÂÖ≥Á≥ª</li></ul></li></ul><h1 id="2-Â¶Ç‰ΩïÊèêÂçáÂøÉÁêÜÈüßÊÄß"><a href="#2-Â¶Ç‰ΩïÊèêÂçáÂøÉÁêÜÈüßÊÄß" class="headerlink" title="2. Â¶Ç‰ΩïÊèêÂçáÂøÉÁêÜÈüßÊÄß"></a>2. Â¶Ç‰ΩïÊèêÂçáÂøÉÁêÜÈüßÊÄß</h1><h2 id="2-1-Ëá™ÊàëÊïàËÉΩÊÑüÁöÑÊèêÂçá"><a href="#2-1-Ëá™ÊàëÊïàËÉΩÊÑüÁöÑÊèêÂçá" class="headerlink" title="2.1 Ëá™ÊàëÊïàËÉΩÊÑüÁöÑÊèêÂçá"></a>2.1 Ëá™ÊàëÊïàËÉΩÊÑüÁöÑÊèêÂçá</h2><ul><li>Ëá™ÊàëÊïàËÉΩÊÑüÁöÑÊèêÂçá Self Efficacy<ul><li>ÂÆö‰πâ ‚Äî ÊòØ‰∏™‰∫∫ÂØπËá™Â∑±ÂÆåÊàêÊüêÊñπÈù¢Â∑•‰ΩúËÉΩÂäõÁöÑ‰∏ªËßÇËØÑ‰º∞ÔºåÈÄöËøá‰∏§Êù°Ë∑ØÂæÑ‰ΩìÁé∞Âá∫Êù•</li><li>È´òËá™ÊàëÊïàËÉΩÊÑüÁöÑ‰∫∫ÔºåÁîöËá≥‰ºöÊääÂéãÂäõ Êå´Êäò ÊâìÂáªÂΩìÂÅö‰∏ÄÁßçËØÅÊòéËá™Â∑±ÁöÑËÉΩÂäõÁöÑÊú∫ÈÅá</li><li>‰ΩìÁé∞Ë∑ØÂæÑ<ul><li>ÁªìÊûúÈ¢ÑÊúü<ul><li>Áõ∏‰ø°Ëá™Â∑±ÔºåËÆ§‰∏∫ÊàëÂèØ‰ª•ÂÅöÂà∞ÔºåÊòØ‰∏ÄÁßçËá™ÊàëÂÆûÁé∞ÁöÑÈ¢ÑË®Ä</li></ul></li><li>ÊïàËÉΩÈ¢ÑÊúü<ul><li>ÊàëËÆ§‰∏∫ÊàëËÉΩÂÅöÂà∞‰∏çÊòØÂõ†‰∏∫ËøêÊ∞îÂ•ΩÊàñËÄÖÁéØÂ¢ÉÂ•ΩÔºåËÄåÊòØÂõ†‰∏∫ÊàëÁöÑËÉΩÂäõ</li><li>Âõ†Ê≠§ÊàëË¶ÅÊñΩÂ±ïÊàëÁöÑËÉΩÂäõÔºå‰∏∫ÁªìÊûúÂÅöË∂≥ÂáÜÂ§á</li></ul></li></ul></li></ul></li><li>Â¶Ç‰ΩïÂéªÂÅö<ul><li>ÂÅöÂá∫ÊàêÂäüÁöÑÊ®°Ê†∑<ul><li>Ë£ÖÁßØÊûÅÔºåÊòØ‰ºöÂèòÊàêÁúüÁßØÊûÅÁöÑ</li><li>Ê≠•‰ºêÊõ¥Âø´</li><li>ËØ¥ËØùÊõ¥Â§ö</li><li>ÂÅö‰∫ã‰∏ªÂä®</li><li>Á©øË°£Êõ¥Ê≠£Âºè‰∫õ</li><li>ÈîªÁÇºÊõ¥È¢ëÁπÅ‰∫õ</li></ul></li><li>Ë¢´ÊàêÂäüËÄÖÊé•Á∫≥<ul><li>‰∏éÁßØÊûÅÁöÑ‰∫∫ÂêåË°å</li><li>Êõø‰ª£ÊÄßÂº∫Âåñ<ul><li>ËßÇÂØüËÄÖÁúãÂà∞Ê¶úÊ†∑ÊàñËÄÖ‰ªñ‰∫∫Êî∂Âà∞Âº∫ÂåñÔºåÊàêÂäü‰∫Ü; ‰ªéËÄå‰ΩøÂæóËá™Â∑±‰πüÂÄæÂêë‰∫éÂÅöÂá∫Ê¶úÊ†∑ÁöÑË°å‰∏∫</li></ul></li></ul></li><li>Á§æ‰ºöÊîØÊåÅ<ul><li>ËøõÂåñÈÄâÊã©ÁöÑÊòØÂêà‰ΩúËÄÖ</li><li>Á§æ‰ºöÁΩëÁªúÈù¢ÁßØË∂äÂ§ßÔºåÊõ¥ÂÆπÊòì‰∫ßÁîü‰ºòÂäøÊïàÂ∫î</li><li><strong>Âº±ËÅîÁ≥ªÁöÑÂº∫ÂäøÊïàÂ∫î</strong><ul><li>Âº±ËÅîÁ≥ªÊúâÁùÄÂæàÂø´ÁöÑ‰ΩéÊàêÊú¨ÂíåÈ´òÊïàËÉΩÁöÑ‰º†Êí≠ÊïàÁéá</li><li>Âú®ÂÖ≠Â∫¶ÂàÜÈöîËØïÈ™åÂΩì‰∏≠ÔºåÊ≠£ÊòØÂ±ÇÂ±ÇÂè†Âä†ÁöÑÂº±ËÅîÁ≥ªÂ∞Ü‰∏ñÁïå‰∏äÂéüÊú¨ÊØ´‰∏çÁõ∏ÂÖ≥ÁöÑ‰∫∫ËÅîÁ≥ªÂà∞‰∫Ü‰∏ÄËµ∑</li></ul></li></ul></li><li>Ê®°ÊãüÂÆûÊàò<ul><li>È¢ÑËßÅ</li><li>Â§ßËÑë‰ºëÈó≤ÁöÑÊó∂ÂÄôÂ§Ñ‰∫éÈªòËÆ§Ê®°ÂºèÁä∂ÊÄÅ  hh<ul><li>‰ºöÁïÖÊÉ≥Êú™Êù•ÔºåÊòØ‰∏ÄÁßçÁ´û‰∫â‰ºòÂäøÁöÑ~</li><li>ÂØπ‰∫é‰∫ãÊÉÖËøõË°åÈÅáËßÅÔºåÊòØÂØπÊàë‰ª¨Â∏ÆÂä©ÂæàÂ§ßÁöÑ</li></ul></li><li>Visualization  È¢ÑËßÅÊÉ≥Ë±°<ul><li>Â∞ÜËá™Â∑±Â∞ÜË¶ÅÂÅöÁöÑ‰∫ãÊÉÖÂéªÊèêÂâçÊÉ≥Ë±°‰∏Ä‰∏ã</li><li>Ëøá‰∏ÄÈÅçËá™Â∑±ÈúÄË¶ÅÊÄé‰πàÂÅö</li><li>ËÆ≠ÁªÉË∂äÂ§öÔºåÊÑèÂêëË∂äÊ∏ÖÊô∞</li><li>ËÆæÊÉ≥ÈÅáÂà∞ÊâìÂáªÔºåÂõ∞ÈöæÁöÑÊó∂ÂÄô‰Ω†Ë¶ÅÊÄé‰πàÂÅö</li></ul></li></ul></li><li>‰∏çÊñ≠ÁßØÁ¥ØÊàêÂäü<ul><li>‰∫∫ÊúÄÂèØÊÄïÁöÑÊòØÂèëÁé∞Ëá™Â∑±‰∏ÄÊàê‰∏çÂèò</li><li>Ë¶ÅÂéªÂÅö</li></ul></li></ul></li></ul><h2 id="2-2-ÂüπÂÖªÊàêÈïøÊÄßÊÄùÁª¥"><a href="#2-2-ÂüπÂÖªÊàêÈïøÊÄßÊÄùÁª¥" class="headerlink" title="2.2 ÂüπÂÖªÊàêÈïøÊÄßÊÄùÁª¥"></a>2.2 ÂüπÂÖªÊàêÈïøÊÄßÊÄùÁª¥</h2><ul><li><p>‰∫∫ÁöÑÊÄùÁª¥Ê®°Âºè</p><ul><li>ÊàêÈïøÊÄßÊÄùÁª¥  Growth Mindset<ul><li>Â§©ËµãÂè™ÊòØËµ∑ÁÇπ</li><li>ÊÄÅÂ∫¶ÂíåÂä™ÂäõÂèØ‰ª•ÂÜ≥ÂÆö‰∏ÄÂàá</li><li>ÂèØ‰ª•Â≠¶‰ºö‰ªª‰ΩïÊàëÊÉ≥Â≠¶‰ºöÁöÑ‰∏úË•ø</li><li>ÂñúÊ¨¢Ëá™ÊàëÊåëÊàò</li><li>ÂΩìÊàëÂ§±Ë¥•ÁöÑÊó∂ÂÄôÔºåÊàëÂ≠¶Âà∞‰∫ÜÂæàÂ§ö‰∏úË•ø</li><li>ÊàëÂ∏åÊúõ‰Ω†Ë°®Êâ¨ÊàëÂæàÂä™Âäõ</li><li>Â¶ÇÊûúÂà´‰∫∫ÊàêÂäü‰∫ÜÔºåÊàë‰ºöÊî∂Âà∞Âà´‰∫∫ÁöÑÂêØÂèë</li></ul></li><li>Âõ∫ÂÆöÊÄßÊÄùÁª¥ ‚Äî ÂçìË∂äÁöÑÂåÖË¢±<ul><li>ÊàëÁöÑËÅ™ÊòéÊâçÊô∫ÂÜ≥ÂÆö‰∫Ü‰∏ÄÂàá</li><li>ÊàëÊìÖÈïøÊüê‰∫õ‰∫ãÔºå‰∏çÊìÖÈïøÂè¶Â§ñ‰∏Ä‰∫õ‰∫ã</li><li>Êàë‰∏çÊÉ≥Â∞ùËØïÊàëÂèØËÉΩ‰∏çÊìÖÈïøÁöÑ‰∏úË•ø</li><li>Â¶ÇÊûúÊàëÂ§±Ë¥•‰∫ÜÔºåÊàëÂ∞±Êó†Âú∞Ëá™ÂÆπ‰∫Ü</li><li>ÊàëÂ∏åÊúõ‰Ω†Ë°®Êâ¨ÊàëÂæàËÅ™Êòé</li><li>Â¶ÇÊûúÂà´‰∫∫ÊàêÂäü‰∫ÜÔºå‰ªñ‰ºöÂ®ÅËÉÅÂà∞Êàë</li></ul></li></ul></li><li><p>Âõ∫ÂÆöÊÄßÊÄùÁª¥ÂØπ‰∫é‰∫∫ÁöÑÂΩ±ÂìçÂæàÂ§ß</p><ul><li>‰Ω†‰ºöÂõ†‰∏∫ËÆ§‰∏∫Ëá™Â∑±ËÅ™ÊòéÔºå‰∏çÊï¢ÂÅöÊõ¥Â§ßÁöÑÊåëÊàòÔºåÂõ†‰∏∫‰∏ÄÊó¶Â§±Ë¥•Ôºå‰Ω†‰ºöÂÆ≥ÊÄïÂà´‰∫∫ËÆ§‰∏∫‰Ω†‰∏çËÅ™Êòé‰∫Ü ‰ºöË∂äÊù•Ë∂äÈöæËææÂà∞Âà´‰∫∫ÁöÑÈ¢ÑÊúüÁöÑ</li><li>Ë¢´Ë°®Êâ¨Âä™ÂäõÁöÑÂæÄÂæÄ‰ºöÈÄâÊã©Êõ¥Âä†Âõ∞ÈöæÁöÑ‰ªªÂä°Ôºå‰πü‰ºöÊõ¥ÊÑøÊÑèÈÄöËøáÂ≠¶‰π†ÔºåÂéªÂ∞ùËØïËß£ÂÜ≥ÊñπÊ°à</li><li>ÂçìË∂äÁöÑÂåÖË¢±<ul><li>Ë£ÖÈÖ∑ÁöÑÂ≠©Â≠êÁöÑÂåÖË¢±</li><li>‰∏çÊÑøÊÑèÂéªÂÜíÈô©Ôºå‰∏çÊÑøÊÑèÂéªÂ•ãÊñó</li><li>Âä™ÂäõÊÑöË†¢ÔºåË£ÖËÅ™Êòé</li><li>Á≤æËã±Áà∂ÊØçÁöÑËøáÈ´òÁöÑÊúüÊúõÈÄ†ÊàêÁöÑÂøÉÁêÜÂéãÂäõÂíåÂøÉÁêÜÈò¥ÂΩ±</li><li>‰ºòÁßÄÂ•≥Â≠©ÁöÑËØÖÂííÔºåËøôÁßçÂåÖË¢±ÂæÄÂæÄÂØπÂ•≥Â≠©ÁöÑÊâìÂáªÊõ¥Â§ßÔºåÂ•π‰ª¨ÂæÄÂæÄÊõ¥Âú®ÊÑèÂ§ñÂú®ÁöÑËØÑ‰ª∑Ôºå‰∏çÊï¢ÂÜíÈô©ÂíåÂä™Âäõ</li><li>we are supposed to be dumb all the way, hhh</li></ul></li></ul></li><li><p>Â¶Ç‰ΩïÂüπÂÖªÊàêÈïøÊÄßÊÄùÁª¥</p><ul><li>ÊîπÂèòËÄÉÊ†∏ÁöÑÊ†áÂáÜ<ul><li>ÂÖ≥Ê≥®ËøõÊ≠•ÔºåËÄå‰∏çÊòØÁªìÊûú</li></ul></li><li>ÊîπÂèòÊ≤üÈÄöÁöÑÊñπÂºè<ul><li>Âú®ËØÑ‰ª∑Ë°®Áé∞ÁöÑÊó∂ÂÄôÔºåÁî®ÊöÇÊó∂‰∏çË°å‰ª£ÊõøÂ∞±ÊòØ‰∏çË°å</li><li>Áü≠ÊöÇ Â±ÄÈÉ® ÂèØ‰ª•ÊîπÁöÑ</li><li>‰∏çË¶ÅÊää‰∫ãÊÉÖËØ¥ÊàêÁ®≥ÂÆöÁöÑÈïøÊúüÁöÑ‰∏çÂèØÊîπÂèòÁöÑ</li><li>not yet instead of failed</li></ul></li><li>ÊîπÂèòËÆ§Áü•ÁöÑ‰π†ÊÉØ ‚Äî Albert Ellis ÁöÑËÆ§Áü•Ê≤ªÁñóABC</li><li>ÂèëÊå•Ëæ©ËØÅÊÄùÁª¥ÁöÑ‰ºòÂäø ‚Äî ‰ªéË¥üÈù¢‰ΩìÈ™å‰∏≠Âê∏ÂèñÊàêÂäüÁöÑÁªèÈ™å<ul><li>ÂΩì‰∏Ä‰∏™‰∫∫Âá∫‰∫éËá™Êàë‰øùÊä§ËÄåÊäóÊãíÂÜÖÂøÉÁöÑÂú∞Áã±ÁöÑÊó∂ÂÄôÔºå‰ªñ‰∏ÄÂπ∂ÂàáÊñ≠‰∫ÜÈÄöÂæÄÂÜÖÂú®Â§©Â†ÇÁöÑÈÅìË∑Ø„ÄÇ<ul><li>‰∏çÊâøËÆ§Ëá™Â∑±ÂÜÖÂøÉÁöÑÈò¥ÊöóÈæåÈæäÔºåÈÇ£‰πàÂ∞±Êó†‰ªéÊîπËøõ‰∫Ü</li></ul></li></ul></li></ul></li></ul><ul><li>ËÆ§Áü•Ê≤ªÁñóABC<ul><li>ÊûÑÊàê<ul><li>A ‚Äî Activating Events  ËØ±ÂèëÂà∫ÊøÄ</li><li>B ‚Äî Beliefs  ‰ø°ÂøµÂèçÂ∫î</li><li>C ‚Äî Consequences  Ë°å‰∏∫ÂêéÊûú</li></ul></li><li>ÂéüÁêÜ<ul><li>Êàë‰ª¨ÊòØÊîπ‰∏ç‰∫ÜAÁöÑÔºå‰ΩÜÊòØÊàë‰ª¨ÂèØ‰ª•ÊîπBÔºåÁÑ∂ÂêéCÂ∞±‰ºöÂèëÁîüÂèòÂåñÔºÅÔºÅ</li><li>ÂÖ≥ÈîÆÊòØ‰Ω†ÊÄé‰πàÁúãÂæÖAÁöÑ ÔºÅ ÊîπÂèòËÆ§Áü•</li><li>ÁúüÊ≠£Âõ∞Êâ∞Êàë‰ª¨ÁöÑÂπ∂‰∏çÊòØÂèëÁîüÂú®Êàë‰ª¨Ë∫´‰∏äÁöÑ‰∫ãÊÉÖÔºåËÄåÊòØÊàë‰ª¨Âõ¥ÁªïËøô‰∏™‰∫ãÊÉÖÂØπÂÆÉÁºñÁªáÁöÑÊïÖ‰∫ãÔºåÂíåÁî±Ê≠§ÂºïËµ∑ÁöÑË∫´ÂøÉÂèçÂ∫î</li></ul></li></ul></li><li>ÊÉÖÁª™ÁöÑABCDÁêÜËÆ∫ ‚Äî ÂØπ‰∫éÂ≠©Â≠êËÄåË®Ä<ul><li>Âá∫Áé∞‰∫ÜABC‰ª•ÂêéÔºåÁªô‰∏Ä‰∏™Êú∫‰ºöËÆ©ÂÖ∂ÂèçÈ©≥</li><li>ËÆ©Â≠©Â≠êÂéªÂèçÈ©≥‰ªñÂΩìÊó∂ÁöÑÂøµÂ§¥</li><li>Âπ≤È¢ÑB  ‰ªéËÄåÂπ≤È¢ÑC</li></ul></li></ul><h2 id="2-3-ÊèêÈ´òËá™ÊàëË∞ÉÊéßÁöÑËÉΩÂäõ"><a href="#2-3-ÊèêÈ´òËá™ÊàëË∞ÉÊéßÁöÑËÉΩÂäõ" class="headerlink" title="2.3 ÊèêÈ´òËá™ÊàëË∞ÉÊéßÁöÑËÉΩÂäõ"></a>2.3 ÊèêÈ´òËá™ÊàëË∞ÉÊéßÁöÑËÉΩÂäõ</h2><ul><li>Âª∂ËøüÊª°Ë∂≥Ôºå Ëá™ÊàëÊéßÂà∂</li><li>Ëá™ÊàëË∞ÉÊéßËÉΩÂäõÊòØÂèØ‰ª•ÈîªÁÇº‰ªéËÄåËé∑ÂæóÊèêÂçáÁöÑ</li><li>Â¶Ç‰ΩïËøõË°åËÆ≠ÁªÉ<ul><li>‰ΩìËÇ≤ÈîªÁÇº</li><li>Ê≠£ÂøµÂÜ•ÊÉ≥ ‚Äî ÂÅö‰∫ãÊÉÖÊ≤âÊµ∏ÂÖ∂‰∏≠Â∞±Â•ΩÂïäÔºÅÔºÅ</li><li>Ëá™ÊàëÊåëÊàò</li><li>ÁõÆÊ†áÊÉ≥Ë±°</li><li>ÊúâÊïà‰ºëÊÅØ</li><li>ÁßØÊûÅÂøÉÊÄÅ</li></ul></li></ul><h1 id="3-ÁªÑÁªáÈüßÊÄß"><a href="#3-ÁªÑÁªáÈüßÊÄß" class="headerlink" title="3. ÁªÑÁªáÈüßÊÄß"></a>3. ÁªÑÁªáÈüßÊÄß</h1><ul><li><p>Â§çÂéüÂäõ</p><ul><li>‰ºÅ‰∏öÈÅáÂà∞Âõ∞ÈöæÂêéÔºåÂ¶Ç‰ΩïÂõûÂΩíÊ≠£Â∏∏</li></ul></li><li><p>Â§çÂéüÂêéÁöÑÂèëÂ±ïËÉΩÂäõ</p></li><li><p>ÂΩ±ÂìçÁªÑÁªáÈüßÊÄßÁöÑÁª¥Â∫¶</p><ul><li>ÁªÑÁªáËµÑÊú¨<ul><li>‰∫∫ÂäõËµÑÊ∫êÁöÑ‰øùÈöú<ul><li>‰ªÄ‰πàÊîøÁ≠ñ</li></ul></li></ul></li><li>ÁªÑÁªáÊâøËØ∫<ul><li>ÂëòÂ∑•ÂØπ‰∫éÁªÑÁªáÁöÑÊÑüÊÉÖ</li><li>‰ø°‰ªª</li></ul></li><li>ÁªÑÁªáÈ¢ÜÂØº<ul><li>leaderÊú¨Ë∫´ÁöÑÊÄÅÂ∫¶ÔºåÊÄùËÄÉÔºåÈüßÊÄß</li></ul></li><li>ÁªÑÁªáÂ≠¶‰π†</li><li>ÁªÑÁªáÊñáÂåñ<ul><li>ÁªÑÁªáÁöÑ‰º†ÁªüÂíå‰ø°‰ª∞</li></ul></li><li>Á§æ‰ºöÁΩëÁªú</li></ul></li><li><p>ÊèêÂçáÁªÑÁªáÈüßÊÄßÁöÑÊñπÂºè</p><ul><li>Staff  ÈÄâÊã©ÂøÉÁêÜÈüßÊÄßÈ´òÁöÑ‰∫∫ÊâçÔºåÈîªÁÇºÂøÉÁêÜÈüßÊÄß<ul><li>ÁßØÊûÅÁöÑËá™ÊàëËÆ§ËØÜ</li><li>ÊèêÂÄ°ÁßØÊûÅÁöÑÊÄùÁª¥</li><li>Âä†Âº∫ÂÖ≥Á≥ªÂª∫ËÆæ</li><li>Êú™Êù•ÂØºÂêë</li><li>‰πêËßÇ‰∏ª‰πâÁ≤æÁ•û<ul><li>ÂØπ‰∫éË∑ØÂæÑÁöÑ‰πêËßÇ</li><li>ÂØπ‰∫éÁªìÊûúÁöÑ‰πêËßÇ</li></ul></li></ul></li><li>System ÂàõÈÄ†ÁßØÊûÅÁöÑÂøÉÁêÜÂÅ•Â∫∑ÁéØÂ¢É</li><li>Skill</li></ul></li></ul><h1 id="4-ÂéãÂäõÁöÑÂ∫îÂØπÊäÄÂ∑ß"><a href="#4-ÂéãÂäõÁöÑÂ∫îÂØπÊäÄÂ∑ß" class="headerlink" title="4. ÂéãÂäõÁöÑÂ∫îÂØπÊäÄÂ∑ß"></a>4. ÂéãÂäõÁöÑÂ∫îÂØπÊäÄÂ∑ß</h1><h2 id="4-1-ÂéãÂäõÁöÑÂ∫îÊøÄÂèçÂ∫î"><a href="#4-1-ÂéãÂäõÁöÑÂ∫îÊøÄÂèçÂ∫î" class="headerlink" title="4.1 ÂéãÂäõÁöÑÂ∫îÊøÄÂèçÂ∫î"></a>4.1 ÂéãÂäõÁöÑÂ∫îÊøÄÂèçÂ∫î</h2><ul><li>Â∫îÊøÄÂèçÂ∫îÁöÑ‰∏âËΩ¥ÂøÉ<ul><li>‰∏ã‰∏òËÑë</li><li>ÂûÇ‰Ωì</li><li>ËÇæ‰∏äËÖ∫</li></ul></li><li>‰∏â‰∏™Âô®ÂÆò‰ºöÈáäÊîæÂéãÂäõÊøÄÁ¥†Ôºå‰ΩøÂæóÊàë‰ª¨ÁöÑÂèçÂ∫îÊòØfight or flight lol</li><li>ËÄåÂêéÊøÄÁ¥†Ê∞¥Âπ≥‰∏ãÈôç</li><li>ÂêÑÁßçÊÉÖÁª™<ul><li>ÁÑ¶Ëôë  ‰∏∫Êú™Êù•ÁöÑÊÅêÊÖå</li><li>ÊäëÈÉÅ  ‰∏∫ËøáÂéª‰º§ÂøÉ</li><li>Ëá™ÊÆã</li></ul></li></ul><h2 id="4-2-‰∏éÊÉÖÁª™ÊúâÂÖ≥ÁöÑËÑëÂå∫"><a href="#4-2-‰∏éÊÉÖÁª™ÊúâÂÖ≥ÁöÑËÑëÂå∫" class="headerlink" title="4.2 ‰∏éÊÉÖÁª™ÊúâÂÖ≥ÁöÑËÑëÂå∫"></a>4.2 ‰∏éÊÉÖÁª™ÊúâÂÖ≥ÁöÑËÑëÂå∫</h2><ul><li><p>Êùè‰ªÅÊ†∏  Amygdala</p><ul><li>‰ºöÂΩ±ÂìçÊàë‰ª¨ÁöÑÊÉÖÁª™</li><li>ÊÉÖÁª™‰∏çÂ•ΩÁöÑÊó∂ÂÄô‰ºöËÆ©Êùè‰ªÅÊ†∏ÂÖÖË°ÄÔºåÁÑ∂ÂêéÊùè‰ªÅÊ†∏Ê∏©Â∫¶ÂçáÈ´ò</li></ul></li><li><p>Â§ßËÑëÁöÆÂ±Ç Cerebral Cortex</p></li><li><p>Â¶Ç‰ΩïÂ∫îÂØπÂéãÂäõ ‚Äî <strong>ÊäëÂà∂</strong>Êùè‰ªÅÊ†∏ÁöÑÊ¥ªÂä®</p><ul><li>Âê∏ÂÖ•ÂáâÊ∞îÔºåÈôç‰ΩéÊùè‰ªÅÊ†∏ÁöÑÊ∏©Â∫¶  hhh</li><li>È¶ôÊ∞î  ËÆ©Êàë‰ª¨‰∫ßÁîüÊÑâÊÇ¶ÁöÑÊÑüËßâ</li><li>ÂÜôÂÜôÊó•ËÆ∞</li></ul></li><li><p>ÊøÄÊ¥ªÂ§ßËÑëÁöÑÂ•ñÂä±‰∏≠Êû¢</p><ul><li><p>Á•ûÁªèÂÖÉ‰πãÈó¥ÁöÑÈó¥Èöô Èù†Á•ûÁªèÈÄíË¥®ËøûÊé•</p></li><li><p>ÂΩìÂ•ñËµè‰∏≠Êû¢ÈáäÊîæÁ•ûÁªèÈÄíË¥®ÁöÑÊó∂ÂÄôÔºå‰ºöÈáäÊîæÁßØÊûÅÁöÑÊÉÖÁª™</p></li><li><p>ÔºÅÔºÅÂøÉÁêÜÊ¥ªÂä®‰∏çÊòØ‰∏Ä‰∏™‰∏Ä‰∏™ÁÇπÔºåËÄåÊòØ‰∏ÄÁâá‰∏ÄÁâáÁöÑ‰∫ßÁîüÁöÑ</p></li><li><p>Â§öÂ∑¥ËÉ∫</p><ul><li>Â∫ÜÁ•ùËá™Â∑±ÁöÑÊàêÂäü ‚Äî ËÆ©Ëá™Â∑±ÁöÑÊàêÂäüÂíåÂø´‰πêÁöÑ‰ΩìÈ™åÂª∂Áª≠‰∏ÄÊÆµÊó∂Èó¥<ul><li>Â∞ÜÂø´‰πêÁöÑ‰ΩìÈ™åÂª∂Áª≠4ÂàÜÈíüÔºåÂ∞±ÂèØ‰ª•Âú®Â§ßËÑë‰∏≠ÂΩ¢ÊàêËÆ∞ÂøÜÔºå‰ªéËÄåÂΩ¢Êàê‰∏Ä‰∏™Âø´‰πêÁöÑÁ•ûÁªèÁΩëÁªú</li></ul></li><li>ÂÅöËá™Â∑±ÂñúÊ¨¢ÂÅöÁöÑ‰∫ãÊÉÖ</li><li>‰∫´ÂèóËâ∫ÊúØÁöÑÁæéÂ¶ô</li></ul></li><li><p>Ë°ÄÊ∏ÖÁ¥†</p><ul><li>ËÉΩÂ§üÊåØÂ•ã‰∫∫ÁöÑÂøÉÊÉÖ</li><li>‰ªÄ‰πàÊó∂ÂÄô‰ºöÂàÜÊ≥å<ul><li>‰ΩìÈ™åÂà∞Ëá™ÊàëÁöÑ‰ª∑ÂÄº</li><li>Â∏ÆÂä©Âà´‰∫∫ÁöÑÊó∂ÂÄô</li><li>Ëá™Â∞äÂøÉÁöÑÂëµÊä§<ul><li>‰øùÊä§Ëá™Â∞äÂøÉ  ‰ΩìÁé∞ÂÖ∂‰ª∑ÂÄº</li></ul></li></ul></li><li>‰∏Ä‰∫õË°å‰∏∫<ul><li>ÊôíÂ§™Èò≥~</li></ul></li></ul></li><li><p>ÂÜÖÂï°ËÇΩ</p><ul><li>Âè™ÊúâÊàë‰ª¨Ë∫´ÂøÉÁóõËã¶ÁöÑÊó∂ÂÄôÔºåÊâç‰ºöÈáäÊîæ</li><li>Ë°å‰∏∫<ul><li>ÊúâËßÑÂæãÁöÑËøêÂä®</li><li>ÂÖàËã¶ÂêéÁîúÁöÑ‰ΩìÈ™å</li><li>ÁúãÂñúÂâßÔºåÁõ∏Â£∞~ ÁÉßËÑëÁöÑÂπΩÈªò</li></ul></li></ul></li><li><p>ÂÇ¨‰∫ßÁ¥†</p><ul><li>Áî∑‰∫∫‰πüÊúâÂÇ¨‰∫ßÁ¥†</li><li>‰∏ªË¶Å‰ΩúÁî®ÊòØÂ¢ûÂä†‰∫∫ÁöÑÁà±ÁöÑÊÑüÂèóÔºåËÄå‰∏çÊòØ‰∏∫‰∫ÜÊÄÄÂ≠ï</li><li>Ë°å‰∏∫<ul><li>Â§∏Â•ñÔºåËµûÁæé</li><li>Èô™‰º¥</li></ul></li></ul><h2 id="4-3-Â∫îÂØπÂéãÂäõÁöÑÈïøÊúüÁ≠ñÁï•"><a href="#4-3-Â∫îÂØπÂéãÂäõÁöÑÈïøÊúüÁ≠ñÁï•" class="headerlink" title="4.3 Â∫îÂØπÂéãÂäõÁöÑÈïøÊúüÁ≠ñÁï•"></a>4.3 Â∫îÂØπÂéãÂäõÁöÑÈïøÊúüÁ≠ñÁï•</h2></li><li><p>ÂéãÂäõÂÆπÊòìËÆ©‰∫∫Â§±ÊéßÂ§±Â∏∏</p></li><li><p>ÂüπÂÖªÂ∫îÂØπÂéãÂäõÁöÑÁßØÊûÅ‰π†ÊÉØ</p><ul><li>strength based approach  ÂèëÊå•Ëá™Â∑±ÁöÑÈïøÂ§Ñ‰ºòÂäø  ÊâæÂà∞Ëá™Â∑±ÁöÑ‰ºòÂäøÔºåÁÑ∂ÂêéÂÖÖÂàÜÂú®Â∑•‰ΩúÁîüÊ¥ªÂΩì‰∏≠‰ΩøÁî®  ‰ΩøÁî®Ëá™Â∑±ÁöÑ‰ºòÂäøÔºÅÔºÅÔºÅ</li><li>ÊâæÂà∞Ëá™Â∑±ÁöÑÊµÅ  find your flow<ul><li>ÂñúÊ¨¢ÂÅöÁöÑ‰∫ãÊÉÖÔºåËøõÂÖ•ÂøÉÊµÅÁä∂ÊÄÅ</li></ul></li><li>ÂÄüÂä©‰∏Ä‰∫õÁßëÂ≠¶ÊñπÊ≥ïÔºåËá™‰øÆÔºåÂêå‰øÆÔºå‰∏ì‰øÆ<ul><li>reading &amp; learning</li></ul></li></ul></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li>ÂΩ≠ÂáØÂπ≥ ÊºîËÆ≤  ‚Äî ÊäóÈÄÜÂäõ‚Äî ÈáçÂéã‰∏ãÁöÑÂøÉÁêÜÈüßÊÄß‰∏éÊàêÂäü</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;ÂæàÂ∫ÜÂπ∏Âê¨‰∫ÜËøôÂú∫ËÆ≤Â∫ßÔºåÂõûÊÉ≥Ëµ∑ÂéüÂÖàÂÅöÁöÑ‰∏Ä‰∫õÂÜ≥ÂÆöÔºå‰ºöÂõø‰∫éÂõ∫ÂÆöÊÄßÊÄùÁª¥ÔºåÂõ†‰∏∫ÂÆ≥ÊÄïÂ§±Ë¥•ÔºåÂÆ≥ÊÄïË¢´ËØÅÂÆû‰∏çÂ§üËÅ™ÊòéÔºåÂ§±Âéª‰∫ÜÂæàÂ§öÂæàÂ§öÊàêÈïøÁöÑÊú∫‰ºö„ÄÇÊÑüËßâÊó†ËÆ∫ÊòØÂ∑•‰ΩúËøòÊòØÁîüÊ¥ªÔºåÂú®Â∫¶Ëøá‰∫ÜÂàöÂàöÂºÄÂßãÁöÑÁÜüÊÇâ‰∫ÜËß£Èò∂ÊÆµ‰ª•ÂêéÔºåÂêéÊúüÈô§‰∫Ü‰∏ì‰∏öÊäÄËÉΩ‰∏äÁöÑÊèêÂçá‰πãÂ§ñÔºåÊõ¥Âä†ÈáçË¶ÅÁöÑÊòØmindsetÁöÑÊèêÂçá ‚Äî
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
      <category term="ÁßØÊûÅÂøÉÁêÜÂ≠¶" scheme="https://www.llchen60.com/tags/%E7%A7%AF%E6%9E%81%E5%BF%83%E7%90%86%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>Make Body Language Your Super Power</title>
    <link href="https://www.llchen60.com/Make-Body-Language-Your-Super-Power/"/>
    <id>https://www.llchen60.com/Make-Body-Language-Your-Super-Power/</id>
    <published>2021-08-28T02:24:14.000Z</published>
    <updated>2021-08-28T02:25:19.176Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Stand Strong</li><li>Gesture Effectively</li><li>Mind Your Audience</li></ul><h1 id="1-Posture"><a href="#1-Posture" class="headerlink" title="1. Posture"></a>1. Posture</h1><ul><li>Communication begins before you open your mouth</li><li>How to stand<ul><li>no<ul><li>hands in the pocket  ‚Äî cannot convey strong msg</li><li>hands in the hip ‚Äî tend to look overwhelming and powerful</li><li>hands in front of family jewels lol</li></ul></li><li>yes<ul><li>base posture ‚Äî feet should be shoulder width apart<ul><li>that‚Äôs the first impression</li></ul></li><li>movement<ul><li>give</li><li>show</li><li>chop ‚Äî strong msg</li></ul></li><li>palms up has better impact! comparing with palm down and pointing</li></ul></li></ul></li><li>Where to stand<ul><li>face your audience</li><li>move around in the center box</li><li>get rid of potential distraction<ul><li>like window, by nature we are attracted by moving thing, will break the concentration</li></ul></li></ul></li></ul><h1 id="2-Audience"><a href="#2-Audience" class="headerlink" title="2. Audience"></a>2. Audience</h1><ul><li>Speaker need to understand what audience is doing , make sure we are all in the journey</li><li>How to engage with audience more<ul><li>gesture</li><li>notice<ul><li>how your audience sitting</li><li>eye contact</li></ul></li><li>surprise<ul><li>cold call, lol</li></ul></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.youtube.com/watch?v=cFLjudWTuGQ&ab_channel=StanfordGraduateSchoolofBusiness">https://www.youtube.com/watch?v=cFLjudWTuGQ&amp;ab_channel=StanfordGraduateSchoolofBusiness</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;Stand Strong&lt;/li&gt;
&lt;li&gt;Gesture Effectively&lt;/li&gt;
&lt;li&gt;Mind Your Audience&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;1-Posture&quot;&gt;&lt;a href=&quot;#1-Posture&quot; class=&quot;hea
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
  </entry>
  
  <entry>
    <title>Distributed Messaging System: Kafka</title>
    <link href="https://www.llchen60.com/Distributed-Messaging-System-Kafka/"/>
    <id>https://www.llchen60.com/Distributed-Messaging-System-Kafka/</id>
    <published>2021-08-24T17:07:33.000Z</published>
    <updated>2021-08-24T17:10:35.053Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Overview-of-Messaging-Systems"><a href="#1-Overview-of-Messaging-Systems" class="headerlink" title="1. Overview of Messaging Systems"></a>1. Overview of Messaging Systems</h1><h2 id="1-1-Why-we-need-a-messaging-system"><a href="#1-1-Why-we-need-a-messaging-system" class="headerlink" title="1.1 Why we need a messaging system"></a>1.1 Why we need a messaging system</h2><ul><li><p>Aim:</p><ul><li>Reliably transfer a high throughput of messages between different entities</li></ul></li><li><p>Challenges</p><ul><li>how we handle a spike of messages</li><li>how we divide the work among a set of instances</li><li>how could we receive messages from different types of sources</li><li>what will happen if the service is down?</li></ul></li><li><p>We need messaging systems in distributed architecture due to challenges above</p></li></ul><h2 id="1-2-What-is-a-messaging-system"><a href="#1-2-What-is-a-messaging-system" class="headerlink" title="1.2 What is a messaging system?"></a>1.2 What is a messaging system?</h2><ul><li><p>responsible for transferring data among services /applications/ processes/ servers</p></li><li><p>help decouple different parts of a distributed system by providing an asynchronous way of transferring messaging between the sender and the receiver</p></li><li><p>Two common ways to handle messages</p><ul><li>Queuing<ul><li>msgs are stored sequentially in a queue</li><li>producers push msg to the rear of the queue</li><li>consumers extract the msgs from the front of the queue</li><li>a particular msg can be consumed by a <strong>max of one consumer</strong> only</li></ul></li><li>Publish - Subscribe<ul><li>messages are divided into topics</li><li>a publisher sends a message to a topic</li><li>subscribers subscribe to a topic to receive every message published to that topic</li><li>msg system that stores and maintains the msg named as <strong>message broker</strong></li></ul></li></ul></li></ul><h1 id="2-Kafka"><a href="#2-Kafka" class="headerlink" title="2. Kafka"></a>2. Kafka</h1><h2 id="2-1-General"><a href="#2-1-General" class="headerlink" title="2.1 General"></a>2.1 General</h2><ul><li><strong>publish subscribe based</strong> messaging system</li><li>takes streams of messages from applications known as producers, stores them reliably on a central cluster, and allows those messages to be received by applications that process the messages</li><li>kafka is mainly used for<ul><li>reliably storing a huge amount of data</li><li>enabling high throughput of message transfer between different entities</li><li>streaming real time data</li></ul></li><li>kafka is a distributed commit log ‚Äî write ahead log<ul><li>append-only data structure that can <strong>persistently store a sequence of records</strong></li><li>all messages are stored <strong>on disk</strong></li><li>since all reads and writes happen <strong>in sequence</strong>, Kafka takes advantage of <strong>sequential disk reads</strong></li></ul></li></ul><h2 id="2-2-Use-Cases"><a href="#2-2-Use-Cases" class="headerlink" title="2.2 Use Cases"></a>2.2 Use Cases</h2><ul><li>Metrics<ul><li>collect and aggregate monitoring data</li></ul></li><li>Log Aggregation<ul><li>collect logs from multiple sources and make them available in a standard format to multiple consumers</li></ul></li><li>Stream Processing<ul><li>the raw data consumed from a topic is transformed, enriched, or aggregated and pushed to a <strong>new topic</strong> for further consumption. This way of data processing is known as stream processing.</li></ul></li><li>Commit Log<ul><li>can be used as an external commit log for any distributed system</li><li>Distributed services can log their transactions to Kafka to keep track of what is happening. This transaction data can be used for replication between nodes and also becomes very useful for disaster recovery, for example, to help failed nodes to recover their states.</li></ul></li><li>Website activity tracking<ul><li>Build a user activity tracking pipeline</li><li>User activities like page clicks, searches, etc., are published to Kafka into separate topics. These topics are available for subscription for a range of use cases, including real-time processing, real-time monitoring, or loading into Hadoop or data warehousing systems for offline processing and reporting</li></ul></li><li>Product Suggestion</li></ul><h1 id="3-High-Level-Architecture"><a href="#3-High-Level-Architecture" class="headerlink" title="3. High Level Architecture"></a>3. High Level Architecture</h1><h2 id="3-1-Common-Terms"><a href="#3-1-Common-Terms" class="headerlink" title="3.1 Common Terms"></a>3.1 Common Terms</h2><ul><li>Brokers<ul><li>A Kafka server</li><li>responsible for reliably storing data provided by the producers and making it available to the consumers</li></ul></li><li>Records<ul><li>A message or an event that get stored in Kafka</li><li>A record contains<ul><li>key</li><li>value</li><li>timestamp</li><li>optional metadata headers</li></ul></li></ul></li><li>Topics<ul><li>Messages are divided into categories called topics</li><li>Each msg that Kafka receives from a producer is associated with a topic</li><li>consumers can subscribe to a topic to get notified when new messages are added to the topic</li><li>a topic can have multiple subscribers that read messages from it</li><li>a topic is identified by its name and must be unique</li><li>mes in a topic can be read as often as needed ‚Äî message are not deleted after consumption, instead, Kafka <strong>retains messages for a configurable amount of time or until a storage size is exceeded</strong></li></ul></li><li>Producers<ul><li>Applications that publish or write records to Kafka</li></ul></li><li>Consumers<ul><li>Applications that subscribe to read and process data from Kafka topics</li><li>Consumers subscribe to one or more topics and consume published messages by pulling data from the brokers</li><li>In Kafka, producers and consumers are fully decoupled and agnostic of each other, which is a key design element to achieve the high scalability that Kafka is known for</li></ul></li></ul><h2 id="3-2-Architecture"><a href="#3-2-Architecture" class="headerlink" title="3.2 Architecture"></a>3.2 Architecture</h2><p><img src="https://i.loli.net/2021/08/25/Chuwtvg4mNfFU58.png" alt="Overall Architecture"></p><ul><li>Kafka cluster<ul><li>Kafka is run as a cluster of one or more servers, where each server is responsible for running one Kafka broker</li></ul></li><li>ZooKeeper<ul><li>Distributed key value store</li><li>Used for coordination and storing configurations</li><li>Kafka uses ZooKeeper to coordinate between Kafka brokers; ZooKeeper maintains metadata information about the Kafka cluster</li></ul></li></ul><h2 id="3-3-Performance-concern"><a href="#3-3-Performance-concern" class="headerlink" title="3.3 Performance concern"></a>3.3 Performance concern</h2><h3 id="3-3-1-Storing-messages-to-disks"><a href="#3-3-1-Storing-messages-to-disks" class="headerlink" title="3.3.1 Storing messages to disks"></a>3.3.1 Storing messages to disks</h3><ul><li>there is a huge difference in disk performance between <strong>random block access and sequential access</strong>. Random block access is slower because of <strong>numerous disk seeks</strong>, whereas the sequential nature of writing or reading, enables disk operations to be <strong>thousands of times faster</strong> than random access.</li><li>OS level optimization<ul><li>Read Ahead ‚Äî prefetch large block multiples</li><li>Write Behind ‚Äî group small logical writes into big physical writes</li><li>PageCache ‚Äî cache the disk in free RAM</li></ul></li><li>Zero Copy optimization<ul><li>OS copy data from the pageCache directly to a socket, effectively bypassing the kafka broker application entirely</li></ul></li><li>Kafka protocol to group msg together<ul><li>reduce network overhead</li></ul></li></ul><h1 id="4-Dive-Deep-in-Kafka-Cluster"><a href="#4-Dive-Deep-in-Kafka-Cluster" class="headerlink" title="4. Dive Deep in Kafka Cluster"></a>4. Dive Deep in Kafka Cluster</h1><h2 id="4-1-Topic-Partitions"><a href="#4-1-Topic-Partitions" class="headerlink" title="4.1 Topic Partitions"></a>4.1 Topic Partitions</h2><ul><li><p>Topics are partitioned, spread over a number of fragments</p></li><li><p>Each partition can be placed on a separate Kafka broker</p></li><li><p>A new message get appended to one of the topic‚Äôs partition</p><ul><li>producer controls which partition it publishes to based on the data</li></ul></li><li><p>One partition is an <strong>ordered sequence</strong> of messages</p><ul><li>producers continually append new messages to partition</li><li>ordering of messages is <strong>maintained at the partition level, not across the topic</strong></li></ul></li><li><p>Unique sequence ID ‚Äî offset</p><ul><li>It will get assigned to every message that enters a partition</li><li>used to identify every message‚Äôs sequential position within a topic‚Äôs partition</li><li>offset sequences are unique only to each partition</li><li>to locate a specific message<ul><li>topic</li><li>partition</li><li>offset number</li></ul></li><li>producers can choose to publish a message to any partition<ul><li>if ordering within a partition is not needed, a round robin partition strategy can be used</li><li>Placing each partition on separate Kafka brokers enables multiple consumers to read from a topic in parallel. That means, different consumers can concurrently read different partitions present on separate brokers</li></ul></li></ul></li><li><p>Messages once written to partitions are immutable and cannot be updated.</p></li><li><p>Kafka guarantees that messages with the same key are written to the same partition.</p></li></ul><h2 id="4-2-Dumb-Broker-and-Smart-Consumer"><a href="#4-2-Dumb-Broker-and-Smart-Consumer" class="headerlink" title="4.2 Dumb Broker and Smart Consumer"></a>4.2 Dumb Broker and Smart Consumer</h2><ul><li>Kafka does not keep track of what records are read by the consumer</li><li>Consumers themselves poll kafka for new messages and say what records they want to read<ul><li>this allow them to increment/ decrement the offset they are as they wish</li></ul></li></ul><h2 id="4-3-Leader-and-Follower"><a href="#4-3-Leader-and-Follower" class="headerlink" title="4.3 Leader and Follower"></a>4.3 Leader and Follower</h2><p>Every topic can be replicated to multiple Kafka brokers to make the data fault-tolerant and highly available. Each topic partition has one leader broker and multiple replica (follower) brokers. </p><ul><li>Structure<ul><li>the broker cluster could have multiple brokers, each broker could have multiple partitions which belong to different topics</li><li>Each topic partition would have one lead broker and multiple replica brokers</li></ul></li></ul><h3 id="4-3-1-Leader"><a href="#4-3-1-Leader" class="headerlink" title="4.3.1 Leader"></a>4.3.1 Leader</h3><ul><li>A leader is the node responsible for all reads and writes for the given partition</li><li>Each partition has one kafka broker acting as a leader</li></ul><h3 id="4-3-2-Follower"><a href="#4-3-2-Follower" class="headerlink" title="4.3.2 Follower"></a>4.3.2 Follower</h3><ul><li><p>To handle single point of failure, Kafka replicate partitions and distribute them across multiple broker servers called followers.</p></li><li><p>Each follower‚Äôs responsibility is to replicate the leader‚Äôs data to serve as a backup partition</p><ul><li><p>any follower can take over the leadership if the leader goes down</p><ul><li><p>from the image below, you could see only the leader take read and write requests, follower acts as replica but not take any read and write reqeusts</p><p><img src="https://i.loli.net/2021/08/25/4t7kVJfv3jliZyK.png" alt="Leader and Follower"></p></li></ul></li></ul></li></ul><h3 id="4-3-3-In-Sync-Replicas"><a href="#4-3-3-In-Sync-Replicas" class="headerlink" title="4.3.3 In Sync Replicas"></a>4.3.3 In Sync Replicas</h3><ul><li>In Sync Replicas means the broker has the latest data for a given partition</li><li>A leader is always an in sync replica</li><li>A follower is an in sync replica only if it has fully caught up to the partition it is following</li><li>Only ISRs are eligible to become partition leaders.</li><li>Kafka can choose the minimum number of ISRs required before the data becomes available for consumers to read</li></ul><h3 id="4-3-4-High-Water-mark"><a href="#4-3-4-High-Water-mark" class="headerlink" title="4.3.4 High Water mark"></a>4.3.4 High Water mark</h3><ul><li><p>To ensure data consistency, the leader broker never returns (or exposes) messages which have not been replicated to a minimum set of ISRs</p></li><li><p>For this, brokers keep track of the high-water mark, which is the highest offset that all ISRs of a particular partition share</p></li><li><p>The leader exposes data only up to the high-water mark offset and propagates the high-water mark offset to all followers</p><p>  <img src="https://i.loli.net/2021/08/25/pyDKzGCRow6O2Wu.png" alt="High Water Mark"></p></li></ul><h1 id="5-Consumer-Group"><a href="#5-Consumer-Group" class="headerlink" title="5. Consumer Group"></a>5. Consumer Group</h1><ul><li>A set of one or more consumers working together in parallel to consume messages from topic partitions, messages are equally divided among all the consumers of a group. with no two consumers receiving the same message</li></ul><h2 id="5-1-How-to-distribute-a-specific-message-to-only-a-single-consumer"><a href="#5-1-How-to-distribute-a-specific-message-to-only-a-single-consumer" class="headerlink" title="5.1 How to distribute a specific message to only a single consumer"></a>5.1 How to distribute a specific message to only a single consumer</h2><ul><li><p>only a single consumer reads messages from any partition within a consumer group</p><ul><li>means only one consumer can work on a partition in a consumer group at a time</li><li>every time a consumer is added to or removed from a group, the consumption is rebalanced within the group</li></ul></li><li><p>with consumer groups, consumers can be parallelized so that multiple consumers can read from multiple partitions on a topic, allowing a very high message processing throughput</p></li><li><p>number of partitions impacts consumers‚Äô maximum parallelism. as there cannot be more consumers than partitions</p></li><li><p>Kafka stores the <strong>current offset per consumer group per topic per partition</strong>, as it would for a single consumer. This means that unique messages are only sent to a single consumer in a consumer group, and the load is balanced across consumers as equally as possible</p></li><li><p><strong>Number of consumers in a group = number of partitions:</strong> each consumer consumes one partition.</p></li><li><p><strong>Number of consumers in a group &gt; number of partitions:</strong> some consumers will be idle.</p></li><li><p><strong>Number of consumers in a group &lt; number of partitions:</strong> some consumers will consume more partitions than others.</p></li></ul><h1 id="6-Kafka-Workflow"><a href="#6-Kafka-Workflow" class="headerlink" title="6. Kafka Workflow"></a>6. Kafka Workflow</h1><h2 id="6-1-Pub-sub-messaging"><a href="#6-1-Pub-sub-messaging" class="headerlink" title="6.1 Pub sub messaging"></a>6.1 Pub sub messaging</h2><ul><li>Producer publish messages on a topic</li><li>Kafka broker stores messages in the partitions configured for that particular topic.<ul><li>If the producer did not specify the partition in which the msg should be stored, the broker ensures that the msg are equally shared between partitions</li><li>If the producer sends two msgs and there are two partitions, Kafka will store those two in two partitions separately.</li></ul></li><li>consumer subscribe to a specific topic</li><li>Kafka will provide the current offset of the topic to the consumer and also saves that offset in the zookeeper</li><li>consumer request kafka at regular intervals for new msgs</li><li>once kafka receives msg from producers, it forward these messages to the consumer</li><li>consumer will receive msg and process it</li><li>once processed, consumer will send an acknowledgement to the kafka broker</li><li>upon receiving the acknowledgement, kafka <strong>increments the offset and updates it in the zooKeeper</strong><ul><li>this info is stored in zooKeeper, thus consumer could read the next msg correctly even during broker outages</li></ul></li><li>consumers can rewind/ skip to the desired offset of a topic at any time and read all the subsequent messages</li></ul><h2 id="6-2-Kafka-workflow-for-consumer-group"><a href="#6-2-Kafka-workflow-for-consumer-group" class="headerlink" title="6.2 Kafka workflow for consumer group"></a>6.2 Kafka workflow for consumer group</h2><ul><li>Producers publish messages on a topic.</li><li>Kafka stores all messages in the partitions configured for that particular topic, similar to the earlier scenario.</li><li>A single consumer subscribes to a specific topic, assume <code>Topic-01</code> with Group ID as <code>Group-1</code>.</li><li>Kafka interacts with the consumer in the same way as pub-sub messaging until a new consumer subscribes to the same topic, <code>Topic-01</code>, with the same Group ID as <code>Group-1</code>.</li><li>Once the new consumer arrives, Kafka switches its operation to share mode, such that each message is passed to only one of the subscribers<br>of the consumer group <code>Group-1</code>. This message transfer is<br>similar to queue-based messaging, as only one consumer of the group<br>consumes a message. Contrary to queue-based messaging, messages are not<br>removed after consumption.</li><li>This message transfer can go on until the number of consumers<br>reaches the number of partitions configured for that particular topic.</li><li>Once the number of consumers exceeds the number of partitions, the<br>new consumer will not receive any message until an existing consumer<br>unsubscribes. This scenario arises because each consumer in Kafka will<br>be assigned a minimum of one partition. Once all the partitions are<br>assigned to the existing consumers, the new consumers will have to wait.</li></ul><h1 id="7-ZooKeeper"><a href="#7-ZooKeeper" class="headerlink" title="7. ZooKeeper"></a>7. ZooKeeper</h1><h2 id="7-1-What-is-ZooKeeper"><a href="#7-1-What-is-ZooKeeper" class="headerlink" title="7.1 What is ZooKeeper"></a>7.1 What is ZooKeeper</h2><ul><li>A distributed configuration and synchronization service</li><li>In Kafka case, help to store basic metadata<ul><li>information about brokers</li><li>topics</li><li>partitions</li><li>partition leader/ followers</li><li>consumer offsets</li></ul></li></ul><h2 id="7-2-Act-as-central-coordinator"><a href="#7-2-Act-as-central-coordinator" class="headerlink" title="7.2 Act as central coordinator"></a>7.2 Act as central coordinator</h2><p>ZooKeeper is used for storing all sorts of metadata about the Kafka cluster:</p><ul><li>It maintains the <strong>last offset position</strong> of each consumer group per partition, so that consumers can quickly recover from the last position in case of a failure (although modern clients store offsets in a<br>separate Kafka topic).</li><li>It tracks the topics, number of partitions assigned to those topics, and leaders‚Äô/followers‚Äô location in each partition.</li><li>It also manages the access control lists (ACLs) to different topics in the cluster. ACLs are used to enforce access or authorization.</li></ul><h2 id="7-3-How-to-find-leaders"><a href="#7-3-How-to-find-leaders" class="headerlink" title="7.3 How to find leaders"></a>7.3 How to find leaders</h2><ul><li>The producer connects to any broker and asks for the leader of Partition 1<ul><li>each broker contains metadata</li><li>each brokers will talk to zooKeeper to get the latest metadata</li></ul></li><li>The broker responds with the identification of the leader broker responsible for partition 1</li><li>The producer connects to the leader broker to publish the message</li></ul><h1 id="8-Controller-Broker"><a href="#8-Controller-Broker" class="headerlink" title="8. Controller Broker"></a>8. Controller Broker</h1><ul><li>Within the Kafka cluster, one broker will be elected as the Controller</li><li>Responsibility<ul><li>admin operations<ul><li>creating/ deleting a topic</li><li>adding partitions</li><li>assigning leaders to partitions</li><li>monitoring broker failures</li></ul></li><li>check the health of other brokers in the system periodically</li><li>communicates the result of the partition leader election to other brokers in the system</li></ul></li></ul><h2 id="8-1-Split-brain-issue"><a href="#8-1-Split-brain-issue" class="headerlink" title="8.1 Split brain issue"></a>8.1 Split brain issue</h2><ul><li>some controller has temporary issue, during the period, we assign a new controller, but the previous one auto recover, so we have two controllers and it could bring inconsistency easily.</li><li>Solution:<ul><li>Generation Clock<ul><li>simply a monotonically increasing number to indicate a server‚Äôs generation</li><li>If the old leader had an epoch number of ‚Äò1‚Äô, the new one would have ‚Äò2‚Äô.</li><li>This epoch is included in every request that is sent from the Controller to other brokers.</li><li>This way, brokers can now easily differentiate the real Controller by simply trusting the Controller with the highest number.</li><li>The Controller with the highest number is undoubtedly the latest one, since the epoch number is always increasing.</li><li>This epoch number is stored in ZooKeeper.</li></ul></li></ul></li></ul><h1 id="9-Delivery-Semantics"><a href="#9-Delivery-Semantics" class="headerlink" title="9. Delivery Semantics"></a>9. Delivery Semantics</h1><h2 id="9-1-Producer-Delivery-Semantics"><a href="#9-1-Producer-Delivery-Semantics" class="headerlink" title="9.1 Producer Delivery Semantics"></a>9.1 Producer Delivery Semantics</h2><ul><li>How can a producer know that the data is successfully stored at the leader or that the followers are keeping up with the leader</li><li>Kafka offers three options to denote the <strong>number of brokers</strong> that <strong>must receive the record</strong> before the <strong>producer considers the write as successful</strong><ul><li>Async<ul><li>Producer sends a msg to kafka and does not wait for acknowledgement from the server</li><li>fire-and-forget approach gives the best performance as we can write data to Kafka at network speed, but <strong>no guarantee can be made</strong> that the server has received the record in this case.</li></ul></li><li>Committed to Leader<ul><li>Producer waits for an acknowledgment from the leader.</li><li>This ensures that the data is committed at the leader; it will be slower than the ‚ÄòAsync‚Äô option, as the data has to be written on disk on the leader.</li><li>Under this scenario, the leader will respond without waiting for acknowledgments from the followers.</li><li>In this case, the record <strong>will be lost if the leader crashes immediately after acknowledging the producer but before the followers have replicated it</strong>.</li></ul></li><li>Committed to Leader and Quorum<ul><li>Producer waits for an acknowledgment from the leader and the quorum. This means the leader will wait for the full set of in-sync replicas to acknowledge the record. This will be the slowest write but guarantees that the record will not be lost as long as at least one in-sync replica remains alive. This is the strongest available guarantee.</li></ul></li></ul></li></ul><h2 id="9-2-Consumer-Delivery-Semantics"><a href="#9-2-Consumer-Delivery-Semantics" class="headerlink" title="9.2 Consumer Delivery Semantics"></a>9.2 Consumer Delivery Semantics</h2><ul><li>Ways to provide consistency to the consumer<ul><li>At most once<ul><li>Message may be lost but are never redelivered</li><li>Under this option, the consumer upon receiving a message, commit (or increment) the offset to the broker. Now, if the consumer crashes before fully consuming the message, that message will be lost, as when the consumer restarts, it will receive the next message from the last committed offset.</li></ul></li><li>At least once<ul><li>Messages are never lost but maybe redelivered</li><li>This scenario occurs when the consumer receives a message from Kafka, and it does not immediately commit the offset.</li><li>Instead, it waits till it completes the processing.</li><li>So, if the consumer crashes after processing the message but before committing the offset, it has to reread the message upon restart.</li><li>Since, in this case, the consumer never committed the offset to the broker, the broker will redeliver the same message. Thus, duplicate message delivery could happen in such a scenario.</li></ul></li><li>Exactly once<ul><li>It is very hard to achieve this unless the consumer is working with a transactional system.</li><li>Under this option, the consumer puts the message processing and the offset increment in one transaction.</li><li>This will ensure that the offset increment will happen only if the whole transaction is complete.</li><li>If the consumer crashes while processing, the transaction will be rolled back, and the offset will not be incremented. When the consumer restarts, it can reread the message as it failed to process it last time. This option leads to no data duplication and no data loss but can lead to decreased throughput.</li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Overview-of-Messaging-Systems&quot;&gt;&lt;a href=&quot;#1-Overview-of-Messaging-Systems&quot; class=&quot;headerlink&quot; title=&quot;1. Overview of Messaging Syste
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©</title>
    <link href="https://www.llchen60.com/%E8%B4%A7%E8%BF%90%E4%BB%A3%E7%90%86%E6%B3%95%E5%BE%8B%E9%A3%8E%E9%99%A9/"/>
    <id>https://www.llchen60.com/%E8%B4%A7%E8%BF%90%E4%BB%A3%E7%90%86%E6%B3%95%E5%BE%8B%E9%A3%8E%E9%99%A9/</id>
    <published>2021-08-17T04:29:17.000Z</published>
    <updated>2021-08-19T23:01:27.883Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Âü∫Êú¨ÂÜÖÂÆπ"><a href="#1-Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Âü∫Êú¨ÂÜÖÂÆπ" class="headerlink" title="1. Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Âü∫Êú¨ÂÜÖÂÆπ"></a>1. Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Âü∫Êú¨ÂÜÖÂÆπ</h1><h2 id="1-1-ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ÂÆö‰πâ"><a href="#1-1-ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ÂÆö‰πâ" class="headerlink" title="1.1 ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ÂÆö‰πâ"></a>1.1 ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ÂÆö‰πâ</h2><ul><li>ÂéÜÂè≤ËßÜËßí‰∏äÊù•Áúã<ul><li>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜÁªèÂéÜ‰∫ÜÁî±ÊòæÊòé‰ª£ÁêÜ‰∫∫Âà∞ÈöêÂêç‰ª£ÁêÜ‰∫∫ÂÜçÂà∞<strong>ËøêËæìÂêàÂêåÂΩì‰∫ã‰∫∫</strong>ÁöÑËøáÁ®ã  Fright Agency ‚Äî‚Üí Freight Forwarder</li><li>Á†îÁ©∂ÂÜÖÂÆπ‰ªéÂçïÁ∫ØÁöÑ‰ª£ÁêÜÊ≥ïÂæãÂÖ≥Á≥ªÂêëËøêËæìÊ≥ïÂæãÂÖ≥Á≥ªÊâ©Â±ï</li><li>Áé∞‰ª£Ë¥ßËøê‰ª£ÁêÜÁöÑÂÆö‰πâ 1992 „ÄäË¥ßËøê‰ª£ÁêÜ„Äã<ul><li>Êèê‰æõÂπ∂ÂÆâÊéíË¥ßÁâ©ËøêËæì‰ª•ÂèñÂæóÊä•ÈÖ¨Ôºå</li><li>ÊàñËÄÖ‰∏∫Ë¥ßÁâ©ÂêàÂπ∂ÊãºÁÆ±Âπ∂ÊâøÊãÖÂ∞ÜËøô‰∫õË¥ßÁâ©Áî±Êî∂Ë¥ßÂú∞ËøêËá≥ÁõÆÁöÑÂú∞ÁöÑ<strong>ËøêËæìË¥£‰ªª</strong></li></ul></li><li>2002 „ÄäË¥ßËøê‰ª£ÁêÜÊ≥ï„Äã  Legal Classification of Fright Forwarders<ul><li>Â•†ÂÆö‰∫ÜÂõΩÈôÖË¥ßËøê‰ª£ÁêÜÂà∂Â∫¶ÁöÑFIATAÁöÑÁ´ãÊ≥ïÊ®°Âºè‰∏ãÔºå‰ª•Ë¥ßÁâ©ËøêËæìÂêàÂêåÁöÑÂΩì‰∫ã‰∫∫ (as principal) ÂíåÈùûÂΩì‰∫ã‰∫∫ (except as principal) Êù•Âå∫ÂàÜÂõΩÈôÖË¥ßÁâ©‰ª£ÁêÜ‰ºÅ‰∏ö‰Ωú‰∏∫<strong>Â•ëÁ∫¶ÊâøËøê‰∫∫ÂíåÁ∫ØÁ≤π‰ª£ÁêÜ‰∫∫</strong>ÁöÑÊÉÖÂÜµ</li></ul></li><li>FIATA (International Federation of Freight Forwarders Association)„ÄäÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∏öÁ§∫ËåÉÊ≥ï„Äã<ul><li>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ÊòØÊåá‰∏éÂÆ¢Êà∑ËææÊàêË¥ßËøê‰ª£ÁêÜÂçèÂÆöÔºå‰∏∫ÂÖ∂Êèê‰æõÂêÑÁ±ªËøêËæìÁõ∏ÂÖ≥ÊúçÂä°ÂèäÂÖ∂‰ªñËæÖÂä©ÂíåÂí®ËØ¢ÊúçÂä°ÔºåÊàñËÄÖÂú®ÂâçËø∞ÊúçÂä°‰πãÂ§ñËøò‰ª•‰ΩøÁî®Ëá™ÊúâËøêËæìÂ∑•ÂÖ∑ÊàñËÄÖÁ≠æÂèëËá™Â∑±ÁöÑËøêËæìÂçïÊçÆÁöÑÊñπÂºè‰∏∫ÂÆ¢Êà∑ÊâøËøêË¥ßÁâ©ÁöÑ‰∫∫</li></ul></li></ul></li><li>Êó†ËàπÊâøËøê‰∫∫<ul><li>ÂØπ‰∫éÂÆûÈôÖË¥ß‰∏ªËÄåË®ÄÔºå‰Ωú‰∏∫ÂÖ¨ÂÖ±ÊâøËøê‰∫∫‰∏é‰πãËÆ¢Á´ãÊµ∑‰∏äË¥ßÁâ©ËøêËæìÂêàÂêå</li><li>ÂØπ‰∫éÂÆûÈôÖÊâøËøê‰∫∫ËÄåË®ÄÔºåÂèàÊâøÊãÖÁùÄÊâòËøê‰∫∫ÁöÑ‰πâÂä°</li></ul></li><li>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ÂÆö‰πâ<ul><li>International Freight Forwarder</li></ul></li><li>ÂØπË¥ß‰ª£ÁöÑ‰∏§Á±ªÁïåÂÆö<ul><li>‰ª£ÁêÜ‰∫∫ËØ¥<ul><li>Â∞ÜÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ËßÑÂÆö‰∏∫ÂèóÂßîÊâò‰∫∫ÁöÑÊåáÁ§∫‰∏∫ÂÖ∂Ë¥ßÁâ©Âú®ÂõΩÈôÖÈó¥ÁöÑËøêËæìÂèäÂÖ∂‰ªñÊúâÂÖ≥‰∫ãÂä°Êèê‰æõÂêàÁêÜÂÆ°ÊÖéÊúçÂä°ÁöÑËá™ÁÑ∂‰∫∫ÊàñÁªèÊµéÁªÑÁªáÔºåÊú¨Ë∫´‰∏öÂä°‰∏çÊ∂âÂèäË¥ßÁâ©ÁöÑÊâøËøê</li><li>‰∏éË¥ß‰∏ªÊàñÂßîÊâò‰∫∫‰πãÈó¥ÊòØÁ∫ØÁ≤πÁöÑ‰ª£ÁêÜÂÖ≥Á≥ª</li></ul></li><li>ÂèåÈáçË∫´‰ªΩËØ¥<ul><li>ËßÑÂÆö‰∫ÜÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ÊòØ‰∏∫ÂßîÊâòÊñπ‰ª£ÂäûÂõΩÈôÖË¥ßËøê‰∫ãÂä°ÁöÑ‰ª£ÁêÜ‰∫∫</li><li>ËßÑÂÆö‰∫ÜÂú®‰∏ÄÂÆöÊù°‰ª∂‰∏ãÂèØ‰ª•<strong>Êàê‰∏∫ËøêËæìÂêàÂêåÁöÑÂΩì‰∫ã‰∫∫Âπ∂ÂØπÂ§ñÊâøÊãÖÊâøËøê‰∫∫ÁöÑË¥£‰ªª</strong></li></ul></li></ul></li></ul><h2 id="1-2-Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÂÖ≥Á≥ªËæ®Êûê"><a href="#1-2-Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÂÖ≥Á≥ªËæ®Êûê" class="headerlink" title="1.2 Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÂÖ≥Á≥ªËæ®Êûê"></a>1.2 Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÂÖ≥Á≥ªËæ®Êûê</h2><ul><li>Ê≥ïÂæãÂÖ≥Á≥ª<ul><li>ÊåáÁõ∏ÂÖ≥Êµ∑ËøêÂõΩÈôÖÂÖ¨Á∫¶ÔºåÂêÑÂõΩÂõΩÂÜÖÊ≥ï‰ª•ÂèäË°å‰∏öËßÑËåÉÁ≠âÂú®Ë∞ÉÊï¥ÂõΩÈôÖÊµ∑‰∏äË¥ßËøê‰ª£ÁêÜË°å‰∏∫ÁöÑËøáÁ®ã‰∏≠ÂΩ¢ÊàêÁöÑÂêÑÊúâÂÖ≥‰∏ª‰ΩìÈó¥ÁöÑÊùÉÂà©Âíå‰πâÂä°ÂÖ≥Á≥ª</li><li>ÂõΩÈôÖÊµ∑‰∏äË¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÂÖ≥Á≥ªÂåÖÊã¨<ul><li>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏ö‰Ωú‰∏∫Êµ∑Ëøê‰ª£ÁêÜ‰∫∫ÁöÑÊ≥ïÂæãÂÖ≥Á≥ª</li><li>‰Ωú‰∏∫Êó†ËàπÊâøËøê‰∫∫ÁöÑÊ≥ïÂæãÂÖ≥Á≥ª</li></ul></li></ul></li><li>‰Ωú‰∏∫Êµ∑Ëøê‰ª£ÁêÜ‰∫∫ÁöÑÊ≥ïÂæãÂÖ≥Á≥ª<ul><li>Âú®Êèê‰æõÊµ∑‰∏äË¥ßÁâ©ËøêËæìÁöÑÁõ∏ÂÖ≥‰ª£ÁêÜ‰∏öÂä°ÁöÑÊó∂ÂÄôÔºåÂëàÁé∞Âá∫ÁöÑÂÖ≥Á≥ª</li><li>ÂÜÖÈÉ®ÂßîÊâòÊ≥ïÂæãÂÖ≥Á≥ª<ul><li>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏ö‰∏éÊâòËøê‰∫∫‰πãÈó¥ÁöÑÂßîÊâò‰ª£ÁêÜÂêàÂêåÊ≥ïÂæãÂÖ≥Á≥ª</li></ul></li><li>Â§ñÈÉ®‰ª£ÁêÜÊ≥ïÂæãÂÖ≥Á≥ª<ul><li>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏ö‰∏∫ÊâòËøê‰∫∫ÁöÑÂà©ÁõäÂíåÊâøËøê‰∫∫Á≠æËÆ¢Êµ∑‰∏äË¥ßÁâ©ËøêËæìÂêàÂêåËÄå‰∫ßÁîüÁöÑËøêËæìÂêàÂêåÊ≥ïÂæãÂÖ≥Á≥ª</li><li>Ë¥ß‰ª£‰ºÅ‰∏öÂæÄÂæÄ‰ºö‰ª•Ëá™Â∑±ÁöÑÂêç‰πâ‰ª£ÊõøÂ§öÁ¨îÊï£Ë¥ßÊâòËøê‰∫∫‰∏éÊâøËøê‰∫∫Á≠æËÆ¢‰∏Ä‰∏™ÊÄªÁöÑËøêËæìÂêàÂêåÔºåËá™Â∑±ÂÜçÂàÜÂà´ÂêåÂêÑÊâòËøê‰∫∫Á≠æËÆ¢Ë¥ßËøê‰ª£ÁêÜÂçèËÆÆ</li></ul></li><li>ÊàëÂõΩÂêàÂêåÊ≥ïÂØπ‰∫éÂåÖÊã¨Ë¥ßËøê‰ª£ÁêÜÂêàÂêåÂú®ÂÜÖÁöÑÂßîÊâòÂêàÂêåÈááÁî®ËøáÈîôË¥£‰ªªÂéüÂàô<ul><li>Ë¥ß‰ª£‰ªÖÂú®Ëá™Ë∫´Á°ÆÂÆûÂèóÊâò‰∫ãÈ°πÂ≠òÂú®ËøáÈîôÂπ∂ÈÄ†ÊàêÊâòËøê‰∫∫ÊçüÂ§±ÁöÑÊÉÖÂÜµ‰∏ãÊâøÊãÖËøùÁ∫¶ÊçüÂÆ≥ËµîÂÅøË¥£‰ªª</li><li>‰∏îÂè™Ë¶ÅÂú®Á¨¨‰∏âÊñπÈÄâ‰ªª‰∏äËÉΩÂ§üËØÅÊòéÂ∑≤ÁªèÂ±•Ë°å‰∫ÜÂêàÁêÜÂíåË∞®ÊÖéÁöÑ‰πâÂä°ÔºåÂØπÁî±‰∫éÁ¨¨‰∏âÊñπÈÄ†ÊàêÁöÑÊâòËøê‰∫∫ÊçüÂ§±ÔºåÂèØ‰ª•ÂÖç‰∫éÊâøÊãÖË¥£‰ªª</li></ul></li></ul></li><li>‰Ωú‰∏∫Êó†ËàπÊâøËøê‰∫∫ÁöÑÊ≥ïÂæãÂÖ≥Á≥ª<ul><li>Â•ëÁ∫¶ÊâøËøê‰∫∫ÁöÑ‰∏ÄÁßçÔºåÂç≥‰∏çÊã•ÊúâÊàñËÄÖ‰∏çÁªèËê•ËàπËà∂Ôºå‰∏çËøõË°åÂÆûÈôÖÁöÑË¥ßÁâ©ËøêËæìÊ¥ªÂä®Ôºå‰ª•Á≠æÂèëÊó†ËàπÊâøËøê‰∫∫ÊèêÂçï(Non Vessel Operating Common Carrier Bill of Loading)ÁöÑÊñπÂºèÊòéÁ§∫ÊàñËÄÖÈªòÁ§∫ÂØπËøêËæìË¥üÊúâË¥£‰ªªÁöÑ‰∫∫ÔºåÊâøËøêË¥£‰ªªÊù•Ê∫ê‰∫éÂíåÊâòËøê‰∫∫Á≠æËÆ¢ÁöÑË¥ßÁâ©ËøêËæìÂ•ëÁ∫¶ÔºåËÄå‰∏çÊòØÂÆûÈôÖÁöÑËøêËæìË°å‰∏∫</li><li>Ê≥ïÂæãÂÖ≥Á≥ª<ul><li>Êó†ËàπÊâøËøê‰∫∫ÂíåÊâòËøê‰∫∫‰πãÈó¥ÁöÑÊµ∑‰∏äË¥ßÁâ©ËøêËæìÂêàÂêåÂÖ≥Á≥ª</li><li>Êó†ËàπÊâøËøê‰∫∫ÂíåËàπÂÖ¨Âè∏‰πãÈó¥ÁöÑÊµ∑‰∏äË¥ßÁâ©ËøêËæìÂêàÂêåÂÖ≥Á≥ª<ul><li>Ë¥ß‰ª£‰ª•ÊâòËøê‰∫∫ÁöÑË∫´‰ªΩÂíåËàπÂÖ¨Âè∏ ‚Äî ÂÆûÈôÖÊâøËøê‰∫∫Á≠æËÆ¢ËøêËæìÂêàÂêåÂπ∂Ëé∑ÂæóÊµ∑ËøêÊèêÂçïÁöÑ (Master Bill of Loading MBL)</li><li><strong>Ê†πÊçÆÊµ∑ÂïÜÊ≥ïÔºå Êó†ËàπÊâøËøê‰∫∫ÊâÄÈúÄË¶ÅÊâøÊãÖÁöÑÊ≥ïÂæãË¥£‰ªªÂíåÂÆûÈôÖÊâøËøê‰∫∫ÁöÑË¥£‰ªªÊòØ‰∏ÄÊ†∑ÁöÑ</strong></li><li>Êó†ËàπÊâøËøê‰∫∫‰∏ç‰∫´Êúâ‰∏çÂÆåÂÖ®Ë¥£‰ªªÂà∂<ul><li>ÂΩìÂÖçË¥£‰∫ãÁî±ÂèëÁîüÁöÑÊó∂ÂÄôÔºåËàπÂÖ¨Âè∏ÂèØ‰ª•ÂÖç‰∫éÂØπÊó†ËàπÊâøËøê‰∫∫ÊâøÊãÖË¥£‰ªªÔºåËÄåÊó†ËàπÊâøËøê‰∫∫Êó†Ê≥ï‰ª•Áõ∏ÂêåÁöÑ‰∫ãÁî±ÂØπÊâòËøê‰∫∫ÂÖçË¥£</li></ul></li><li>ÂΩìÊâøËøê‰∫∫ÂíåÂÆûÈôÖÊâøËøê‰∫∫ÈúÄË¶ÅÂØπË¥ßÊçüË¥ßÂ∑ÆÈúÄË¶ÅËøõË°åËµîÂÅøÁöÑÊó∂ÂÄôÔºå‰∫åËÄÖÂú®Ë¥£‰ªªËåÉÂõ¥ÂÜÖÊâøÊãÖËøûÂ∏¶Ë¥£‰ªª</li><li>ÂØπ‰∫éÈô§‰∫ÜÊµ∑‰∏äËøêËæì‰πãÂ§ñÂÆûÈôÖÊâòËøê‰∫∫Êèê‰æõÁöÑÂÖ∂‰ªñËøêËæìÊúçÂä°ÔºåÊó†ËàπÊâøËøê‰∫∫ÂùáÊâøÊãÖ‰∏•Ê†ºË¥£‰ªª</li></ul></li><li>Êó†ËàπÊâøËøê‰∫∫ÂíåËàπÂÖ¨Âè∏‰ª£ÁêÜ‰∫∫‰πãÈó¥ÁöÑÊµ∑‰∏äË¥ßÁâ©ËøêËæìÂêàÂêåÂÖ≥Á≥ª</li></ul></li></ul></li></ul><h1 id="2-È£éÈô©Áä∂ÂÜµÂàÜÊûê"><a href="#2-È£éÈô©Áä∂ÂÜµÂàÜÊûê" class="headerlink" title="2. È£éÈô©Áä∂ÂÜµÂàÜÊûê"></a>2. È£éÈô©Áä∂ÂÜµÂàÜÊûê</h1><ul><li><p>È£éÈô©ÁöÑÂÆö‰πâ</p><ul><li>Áî±‰∫éÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏öÂú®ÂºÄÂ±ïÊµ∑‰∏ä‰∏öÂä°ËøáÁ®ã‰∏≠ÂèóÂà∞ÂÆ¢ËßÇÊ≥ïÂæãÁéØÂ¢ÉÔºåÂåÖÊã¨Ëá™Ë∫´Âú®ÂÜÖÁöÑÂêÑÊµ∑Ê¥ãËøêËæìÁõ∏ÂÖ≥‰∏ª‰ΩìÊâÄÂÆûÊñΩÁöÑÊ≥ïÂæãË°å‰∏∫ÁöÑÂΩ±ÂìçÔºåÂØºËá¥ÂÖ∂ÊùÉÂà©‰πâÂä°Áä∂ÊÄÅÂèëÁîüÊîπÂèòÔºå‰ªéËÄå‰∫ßÁîüÁöÑÂèØËÉΩÁî±ËØ•‰ºÅ‰∏öÊâøÊãÖÁöÑÊ≥ïÂæã‰∏äÁöÑ‰∏çÂà©ÂêéÊûú</li><li>Ê≥ïÂæãÈ£éÈô©Áî±ÁéØÂ¢ÉËØ±Âõ† ‚Äî ÂÆ¢ËßÇÊ≥ïÂæãÁéØÂ¢ÉÔºåË°å‰∏∫ËØ±Âõ† ‚Äî ÂÆûÊñΩÁöÑÊ≥ïÂæãË°å‰∏∫Âèä‰∫åËÄÖÊâÄÂºïÂèëÁöÑ‰∏çÂà©ÂêéÊûúÊûÑÊàê<ul><li>Ê≥ïÂæãÁöÑ‰∏çÂÆåÂñÑÂíå‰∏çÁ°ÆÂÆöÊÄß<ul><li>‰∏çÂÆåÂñÑ ‚Äî Âà∂ÂÆöÊ≥ïÂõ†‰∏∫Êó†Ê≥ïÈÅøÂÖçÂú∞ÊªûÂêé‰∫éÁ§æ‰ºöÁöÑÂèëÂ±ïËÄåÂøÖÁÑ∂Â≠òÂú®ÁöÑÊºèÊ¥ûÂíåÁ©∫ÁôΩ</li><li>‰∏çÁ°ÆÂÆöÊÄß ‚Äî Áî±‰∫éÊ≥ïÂæãÊù°ÊñáÊÑè‰πâÊô¶Ê∂©‰πãÂ§ÑÈúÄË¶ÅÊ≥ïÂÆòÊù•ÈòêÈáäËØ¥ÊòéÔºåÊ≥ïÂÆòÂØπ‰∫éÊ≥ïÂæãÁöÑÁêÜËß£‰ºöÊúâÊâÄ‰∏çÂêåÔºå‰ªéËÄåÂØºËá¥‰∫ÜË£ÅÂà§ÁªìÊûú‰∏çÊÄªÊòØ‰∏ÄËá¥ÁöÑ</li></ul></li><li>Ë°å‰∏∫ËØ±Âõ†<ul><li>Ë¥ß‰ª£ÁöÑ‰∏Ä‰∫õ‰∏çËßÑËåÉÁöÑÊ≥ïÂæãË°å‰∏∫Ôºå</li></ul></li></ul></li></ul></li><li><p>Ë¥ß‰ª£Á∫†Á∫∑Ê°à‰ª∂Á†îÁ©∂ ‰∫âËÆÆÁÑ¶ÁÇπ‰∏ªË¶ÅÂú®Ôºö</p><ul><li>Ê∂âÊ°à‰∏ª‰ΩìÈó¥Ë¥ßËøê‰ª£ÁêÜÂêàÂêåÂÖ≥Á≥ªÁöÑËÆ§ÂÆö<ul><li>Âõ†‰∏∫ËΩ¨ÂßîÊâòËÄåÂºïÂèëÁöÑÂØπÂèåÊñπÈó¥ÊòØÂê¶Â≠òÂú®Áõ¥Êé•Ê≥ïÂæãÂÖ≥Á≥ªÁöÑÂºÇËÆÆ</li><li>Âõ†‰∏∫Ë¥ßËøê‰ª£ÁêÜ‰∫∫ÂíåÊó†ËàπÊâøËøê‰∫∫Ë∫´‰ªΩËØÜÂà´ËÄåÂºïÂèëÁöÑÂØπÂêàÂêåÂÖ≥Á≥ªÊÄßË¥®ÊòØË¥ßÁâ©ËøêËæìÂêàÂêåÊ≥ïÂæãÂÖ≥Á≥ªËøòÊòØË¥ßÁâ©ËøêËæì‰ª£ÁêÜÂêàÂêåÊ≥ïÂæãÂÖ≥Á≥ªÁöÑÂºÇËÆÆ</li></ul></li></ul></li><li><p>‰∏ªË¶ÅÈ£éÈô©ÂàÜÁ±ª</p><ul><li>Ë∫´‰ªΩËÆ§ÂÆö‰∏äÁöÑÈ£éÈô©<ul><li>ÊåáÂØπÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏öÊòØÊ∂âÊ°àË¥ßÁâ©ÁöÑÊµ∑Ëøê‰ª£ÁêÜ‰∫∫ËøòÊòØÊó†ËàπÊâøËøê‰∫∫ÁöÑËÆ§ÂÆöÁªìÊûúÂíå‰ºÅ‰∏öËá™Ë∫´ÂØπÊ≠§ÁöÑËÆ§ËØÜ‰∏çÂêåÈÄ†ÊàêÁöÑÈóÆÈ¢ò</li></ul></li><li>ËΩ¨ÂßîÊâòÂíåÂèåÊñπ‰ª£ÁêÜ‰∏äÁöÑÈ£éÈô©</li><li>Ê∂âÂ§ñÊ≥ïÂæãÈÄÇÁî®‰∏äÁöÑÈ£éÈô©<ul><li>Ë≠¨Â¶ÇÁæéÂõΩÁªü‰∏ÄÂïÜÊ≥ïÂÖ∏ÔºåÂÖÅËÆ∏‰ª•ËÆ∞ÂêçÊèêÂçïÁöÑÊñπÂºèÊîæË¥ßÔºåÂ¶ÇÊûúÂèåÊñπÂú®Ê≥ïÂæãÈÄÇÁî®Êù°Ê¨æÂΩì‰∏≠Á∫¶ÂÆöÈÄÇÁî®ÁæéÂõΩÊ≥ïÔºåÈÇ£‰πàÊµ∑Â§ñ‰ª£ÁêÜÊèêÂçïÊó†ÂçïÊîæË¥ßÁöÑË°å‰∏∫Â∞±‰∏çÂ±û‰∫éËøáÈîôË°å‰∏∫</li></ul></li></ul></li></ul><h1 id="3-È£éÈô©ÊàêÂõ†ÂàÜÊûê"><a href="#3-È£éÈô©ÊàêÂõ†ÂàÜÊûê" class="headerlink" title="3. È£éÈô©ÊàêÂõ†ÂàÜÊûê"></a>3. È£éÈô©ÊàêÂõ†ÂàÜÊûê</h1><h2 id="3-1-Ë∫´‰ªΩËÆ§ÂÆö‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†"><a href="#3-1-Ë∫´‰ªΩËÆ§ÂÆö‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†" class="headerlink" title="3.1 Ë∫´‰ªΩËÆ§ÂÆö‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†"></a>3.1 Ë∫´‰ªΩËÆ§ÂÆö‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†</h2><ul><li>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏öÊòØÊ∂âÊ°àË¥ßÁâ©ÁöÑÊµ∑Ëøê‰ª£ÁêÜ‰∫∫ËøòÊòØÊó†ËàπÊâøËøê‰∫∫ÁöÑËÆ§ÂÆöÁªìÊûúÁöÑ‰∏çÂêåÔºå‰ºöÂØºËá¥‰ºÅ‰∏öÈúÄË¶ÅÊâøÊãÖÁöÑÊ≥ïÂæãË¥£‰ªªÂíåÈ£éÈô©ÂÆåÂÖ®‰∏çÂêå<ul><li>Á´ãÊ≥ï‰∏äÁöÑÂ∞èÊ∑∑‰π±<ul><li>Âõ†‰∏∫ÂæàÊúâÂèØËÉΩË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏öÂêåÊó∂ÊãÖÂΩìÁùÄÊó†ËàπÊâøËøê‰∫∫ËøòÊúâ‰ª£ÁêÜ‰∫∫ÁöÑËßíËâ≤</li></ul></li><li>Âè∏Ê≥ïË£ÅÂà§ÁöÑ‰∏çÁ°ÆÂÆö<ul><li>„ÄäÊµ∑‰∏äË¥ß‰ª£Á∫†Á∫∑ËßÑÂÆö„ÄãÁöÑ‰∏Ä‰∫õÂà§Êñ≠ÈÄªËæë<ul><li>ÂèåÊñπ‰πãÈó¥ÊòØÂê¶ËÆ¢Á´ã‰∫ÜÊµ∑‰∏äË¥ßËøê‰ª£ÁêÜÂêàÂêåÔºåÂèçÊò†Âá∫Êù•ÁöÑÊòØ‰ª£ÁêÜÂçèËÆÆËøòÊòØËøêËæìÂçèËÆÆ</li><li>ÂèóÊâò‰∫∫ÂêëÂßîÊâò‰∫∫ÊòØÂê¶Á≠æÂèë‰∫ÜÊèêÂçïÔºåÊòØÊâøËøêÊèêÂçïËøòÊòØ‰ª£ÁêÜ‰∫∫ÁöÑÂàÜÊèêÂçï</li><li>ÂèóÊâò‰∫∫Êî∂ÂèñË¥πÁî®ÁöÑÂêç‰πâÊòØ‰Ω£ÈáëËøòÊòØËøêË¥π</li><li>ÂèåÊñπ‰ª•ÂæÄÁöÑ‰∫§ÊòìÂéÜÂè≤Âíå‰∫§Êòì‰π†ÊÉØ</li></ul></li></ul></li><li>‰ªé‰∏öËÄÖËá™Ë∫´Ë°å‰∏∫ÁöÑ‰∏çËßÑËåÉ<ul><li>ÊòØÂê¶‰øùÁïô‰∫ÜÈáçË¶ÅÁöÑÂæÄÊù•Êñá‰ª∂ÔºåÂèëÁ•®ÂíåÊèêÂçï</li></ul></li></ul></li></ul><h2 id="3-2-ËΩ¨ÂßîÊâò‰∏éÂèåÊñπ‰ª£ÁêÜ‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†"><a href="#3-2-ËΩ¨ÂßîÊâò‰∏éÂèåÊñπ‰ª£ÁêÜ‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†" class="headerlink" title="3.2 ËΩ¨ÂßîÊâò‰∏éÂèåÊñπ‰ª£ÁêÜ‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†"></a>3.2 ËΩ¨ÂßîÊâò‰∏éÂèåÊñπ‰ª£ÁêÜ‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†</h2><h3 id="3-2-1-ËΩ¨ÂßîÊâòË°å‰∏∫ÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†"><a href="#3-2-1-ËΩ¨ÂßîÊâòË°å‰∏∫ÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†" class="headerlink" title="3.2.1 ËΩ¨ÂßîÊâòË°å‰∏∫ÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†"></a>3.2.1 ËΩ¨ÂßîÊâòË°å‰∏∫ÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†</h3><ul><li>‰ªÄ‰πàÊòØËΩ¨ÂßîÊâò<ul><li>ÂèóÊâò‰∫∫Â∞ÜÂßîÊâò‰∫∫ÂßîÊâòÂÖ∂‰ª£‰∏∫Â§ÑÁêÜÁöÑ‰∫ãÂä°ËΩ¨‰∫§ÁªôÁ¨¨‰∏â‰∫∫Â§ÑÁêÜÁöÑË°å‰∏∫</li></ul></li><li>ËΩ¨ÂßîÊâòË°å‰∏∫ÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†<ul><li>ÂêàÂêåÊ≥ïËßÑÂÆöÔºåÂØπ‰∫éÂßîÊâò‰∫ãÂä°ÔºåÈô§‰∫ÜÁªèËøáÂßîÊâò‰∫∫ÂêåÊÑèÊàñËÄÖÂá∫Áé∞Á¥ßÊÄ•Áä∂ÂÜµÂèØ‰ª•ËΩ¨ÂßîÊâò‰πãÂ§ñÔºåÂèóÊâò‰∫∫ÂùáÂ∫îÂΩì‰∫≤Ëá™Â§ÑÁêÜÔºåÂê¶ÂàôÂ∞±Ë¶Å‰∏∫Á¨¨‰∏â‰∫∫ÁöÑË°å‰∏∫ÊâøÊãÖË¥£‰ªª</li><li>‰ΩÜÊòØÂØπ‰∫éÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÊù•ËØ¥ÔºåËΩ¨ÂßîÊâòÊòØ‰∏Ä‰∏™Â∏∏ËßÑÊñπÂºè<ul><li>ÂéüÂõ†Âú®‰∫éÊµ∑ËøêË¥ß‰ª£ÂßîÊâò‰∫∫Êõ¥‰∏∫ÁúãÈáçÊàêÊú¨ÂíåÊïàÁéáÔºåËÆ©Ë¥ß‰ª£‰ºÅ‰∏öÂéªÂÆåÂÖ®Â§ÑÁêÜÊØè‰∏Ä‰ª∂ÂßîÊâò‰∫ãÂä°ÊòØ‰∏çÁªèÊµé‰πü‰∏çÁé∞ÂÆûÁöÑ</li></ul></li><li>ÈÄ†ÊàêË¥ß‰ª£‰ºÅ‰∏öËΩ¨ÂßîÊâòÈ£éÈô©ÁöÑÊòØÊòØÂê¶ÂèñÂæó‰∫ÜÂßîÊâò‰∫∫ÁöÑÂêåÊÑè</li><li>ÂΩìÂâç„ÄäÊµ∑‰∏äË¥ß‰ª£Á∫†Á∫∑ËßÑÂÆö„ÄãÊòéÁ°ÆÊéíÈô§‰∫ÜÊé®ÂÆöÊâòËøê‰∫∫ÈªòÁ§∫ÂêåÊÑèË¥ßËøê‰ª£ÁêÜ‰∫∫ËΩ¨ÂßîÊâòÁöÑÂèØËÉΩ<ul><li>ËΩ¨ÂßîÊâòÂÖ∑‰ΩìÊùÉÈôêÁ∫¶ÂÆö‰∏çÊòéÁöÑÊó∂ÂÄôÔºåÂßîÊâò‰∫∫Â∞ÜË¥üÊúâÂ∞±‰∏çÊòéÊùÉÈôêÊÉ≥ÂßîÊâò‰∫∫Êä•ÂëäÁöÑ‰πâÂä°</li><li>ÂßîÊâò‰∫∫Âú®ÂèóÊâò‰∫∫ÊåáÁ§∫‰∏ã‰∏éÁ¨¨‰∏â‰∫∫ÁöÑÈÄöÂ∏∏Êé•Ëß¶Ë°å‰∏∫‰∏çËÉΩËÆ§ÂÆö‰∏∫ÂßîÊâò‰∫∫‰ª•ËØ•Ë°å‰∏∫ÂØπËΩ¨ÂßîÊâòÁöÑÊòéÁ°ÆÂêåÊÑè</li></ul></li></ul></li></ul><h3 id="3-2-2-ÂèåÊñπ‰ª£ÁêÜË°å‰∏∫‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†"><a href="#3-2-2-ÂèåÊñπ‰ª£ÁêÜË°å‰∏∫‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†" class="headerlink" title="3.2.2 ÂèåÊñπ‰ª£ÁêÜË°å‰∏∫‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†"></a>3.2.2 ÂèåÊñπ‰ª£ÁêÜË°å‰∏∫‰∏äÁöÑÊ≥ïÂæãÈ£éÈô©ÊàêÂõ†</h3><ul><li>‰ªÄ‰πàÊòØÂèåÊñπ‰ª£ÁêÜÔºü<ul><li>ÊåáÂú®Âêå‰∏ÄÊ≥ïÂæãÂÖ≥Á≥ªÂÜÖÔºå‰∏ÄÊñπÂΩì‰∫ã‰∫∫ÁöÑ‰ª£ÁêÜ‰∫∫ÂêåÊó∂ÂèàÊé•ÂèóÂè¶‰∏ÄÊñπÂΩì‰∫ã‰∫∫ÂßîÊâòÔºåÂπ∂‰∏∫ÂÖ∂‰ª£ÁêÜÁöÑË°å‰∏∫</li><li>Áî±‰∫éÂêàÂêåÂÖ≥Á≥ª‰∏≠ÂèåÊñπÊòØÁõ∏ÂØπÁöÑÔºåÂèåÊñπ‰ª£ÁêÜ‰ºö‰ΩøÂæóÊú¨ÊòØÂÜ≤Á™ÅÁöÑÂêàÂêåÂèåÊñπÊÑèÊÄùË°®Á§∫Ë¢´‰ª£ÁêÜÁöÑ‰∏™‰∫∫ÊÑèÂøó‰∫à‰ª•Êõø‰ª£ÔºåÂÅèÁ¶ª‰∫ÜÂêàÂêåÁöÑÊú¨Ë¥®Â±ûÊÄß</li></ul></li><li>Êµ∑ËøêË¥ß‰ª£Ë°å‰∏öÈúÄË¶ÅËøôÊ†∑ÂÅöÔºåÂõ†‰∏∫ÊïàÁéá‰∏äÁöÑÊèêÂçá„ÄÇ‰ΩÜ‰ºöÊúâÊ≥ïÂæã‰∏äÁöÑÈ£éÈô©</li></ul><h2 id="3-3-Ê∂âÂ§ñÊ≥ïÂæãÈÄÇÁî®‰∏äÁöÑÈ£éÈô©ÊàêÂõ†"><a href="#3-3-Ê∂âÂ§ñÊ≥ïÂæãÈÄÇÁî®‰∏äÁöÑÈ£éÈô©ÊàêÂõ†" class="headerlink" title="3.3 Ê∂âÂ§ñÊ≥ïÂæãÈÄÇÁî®‰∏äÁöÑÈ£éÈô©ÊàêÂõ†"></a>3.3 Ê∂âÂ§ñÊ≥ïÂæãÈÄÇÁî®‰∏äÁöÑÈ£éÈô©ÊàêÂõ†</h2><ul><li>‰Ωú‰∏∫Ê≥ïÈô¢Ë£ÅÂà§‰æùÊçÆÁöÑÂõΩÂ§ñÊ≥ïÂæãËßÑÂÆöÂèØËÉΩ‰ºöËÆ©ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏öÂú®ËØâËÆº‰∏≠Â§Ñ‰∫é‰∏çÂà©Âú∞‰Ωç</li><li>Ê∂âÂ§ñÂïÜ‰∫ã‰ª£ÁêÜÊ≥ïÂæãÂÖ≥Á≥ªÔºå‰ºöÂèóÂà∞ÈÄîÁªèÂõΩÂÆ∂ÁöÑÊ≥ïÂæãÁÆ°Ëæñ</li><li>Â¶ÇÊûúÂèåÊñπÊú™Á∫¶ÂÆöÂáÜÊçÆÊ≥ïÔºåÊàñÊ∂âËØâÁöÑÂõΩÈôÖË¥ß‰ª£‰ºÅ‰∏öÊ≤°ÊúâÂáÜÁ°ÆÁêÜËß£ÂíåÊääÊè°Â∑≤Á∫¶ÂÆöÁöÑÂáÜÊçÆÊ≥ïÔºåÂ∞±‰ºöÂ§ßÂ§ßÂ¢ûÂä†ËØâËÆº‰∏≠ÁöÑ‰∏çÁ®≥ÂÆöÂõ†Á¥†</li><li>Ëã±ÁæéÊ≥ïÁ≥ªÔºåÂà§‰æãÊ≥ïÔºõ ÊàêÊñáÊ≥ïÂõΩÂÆ∂ÔºåÊúâ‰∏ìÈó®ÁöÑË¥ßËøê‰ª£ÁêÜÊ≥ïÂæã</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>„ÄäÂõΩÈôÖÊµ∑‰∏äË¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Á†îÁ©∂„Äã  ÈÇìÂ§ßÈ∏£</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Âü∫Êú¨ÂÜÖÂÆπ&quot;&gt;&lt;a href=&quot;#1-Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Âü∫Êú¨ÂÜÖÂÆπ&quot; class=&quot;headerlink&quot; title=&quot;1. Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Âü∫Êú¨ÂÜÖÂÆπ&quot;&gt;&lt;/a&gt;1. Ë¥ßËøê‰ª£ÁêÜÊ≥ïÂæãÈ£éÈô©Âü∫Êú¨ÂÜÖÂÆπ&lt;/h1&gt;&lt;h2 id=&quot;1-1-ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜ‰∫∫ÂÆö‰πâ&quot;&gt;
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
      <category term="Ë¥ßËøê‰ª£ÁêÜ" scheme="https://www.llchen60.com/tags/%E8%B4%A7%E8%BF%90%E4%BB%A3%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢</title>
    <link href="https://www.llchen60.com/%E5%9B%BD%E9%99%85%E8%B4%A7%E8%BF%90%E4%BB%A3%E7%90%86%E8%A1%8C%E4%B8%9A%E5%88%9D%E6%8E%A2/"/>
    <id>https://www.llchen60.com/%E5%9B%BD%E9%99%85%E8%B4%A7%E8%BF%90%E4%BB%A3%E7%90%86%E8%A1%8C%E4%B8%9A%E5%88%9D%E6%8E%A2/</id>
    <published>2021-08-15T14:52:04.000Z</published>
    <updated>2021-08-19T23:01:51.975Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢"><a href="#ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢" class="headerlink" title="ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢"></a>ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢</h1><h1 id="1-Ë¥ßËøêÂÖ¨Âè∏‰∏öÂä°‰∏éÂ∑•‰ΩúÂÜÖÂÆπ"><a href="#1-Ë¥ßËøêÂÖ¨Âè∏‰∏öÂä°‰∏éÂ∑•‰ΩúÂÜÖÂÆπ" class="headerlink" title="1. Ë¥ßËøêÂÖ¨Âè∏‰∏öÂä°‰∏éÂ∑•‰ΩúÂÜÖÂÆπ"></a>1. Ë¥ßËøêÂÖ¨Âè∏‰∏öÂä°‰∏éÂ∑•‰ΩúÂÜÖÂÆπ</h1><h2 id="1-1-‰∏ªË¶Å‰∏öÂä°"><a href="#1-1-‰∏ªË¶Å‰∏öÂä°" class="headerlink" title="1.1 ‰∏ªË¶Å‰∏öÂä°"></a>1.1 ‰∏ªË¶Å‰∏öÂä°</h2><h3 id="1-1-1-Overview"><a href="#1-1-1-Overview" class="headerlink" title="1.1.1 Overview"></a>1.1.1 Overview</h3><blockquote><p>ÂÆ¢Êà∑ÂßîÊâòË¥ßËøê‰ª£ÁêÜËøêËæìË¥ßÁâ©ÔºåÂÆ¢Êà∑Êú¨‰∫∫Âπ∂‰∏çÊâøÊãÖÊâøËøêË¥£‰ªªÔºõË¥ß‰ª£Êé•ÂèóÂèëË¥ß‰∫∫ÂßîÊâòÂêéÔºå‰∏∫ÂèëË¥ß‰∫∫Êèê‰æõÁõ∏ÂÖ≥ÊúçÂä°ÔºåÊª°Ë∂≥ÂèëË¥ß‰∫∫ÁöÑÂÖ∑‰ΩìË¶ÅÊ±ÇÔºåÂêåÊó∂Ë¶ÅÊ±ÇÂèëË¥ß‰∫∫Ê†πÊçÆÊúçÂä°Êù•ÊîØ‰ªò‰∏ÄÂÆöÊä•ÈÖ¨ÁöÑË°å‰∏ö</p></blockquote><h3 id="1-1-2-‰∏ªËê•‰∏öÂä°"><a href="#1-1-2-‰∏ªËê•‰∏öÂä°" class="headerlink" title="1.1.2 ‰∏ªËê•‰∏öÂä°"></a>1.1.2 ‰∏ªËê•‰∏öÂä°</h3><ul><li>Á∫ØÁ≤π‰ª£ÁêÜ‰∫∫ÁöÑ‰∏öÂä°<ul><li>ÂèñÂæóÂßîÊâò‰∫∫ÊéàÊùÉ</li><li>Ë¥üË¥£Ë¥ßÁâ©Á¶ªÂºÄÊ∏ØÂè£‰ª•ÂèäÂà∞ËææÊ∏ØÂè£ÁöÑÂÖ¨Âä°Â§ÑÁêÜÂ∑•‰Ωú<ul><li>Êä•ÂÖ≥</li><li>Êä•Ê£Ä</li><li>‰øùÈô©</li></ul></li><li>Ëøô‰∏™Ê∏ÖÂÖ≥ÁéØËäÇ‰∏ªË¶ÅÊòØÈÖçÂêàÂΩìÂú∞Êµ∑ÂÖ≥ËøõË°åÊñá‰ª∂ÂáÜÂ§áÂ∑•‰Ωú</li></ul></li><li>ÂõΩÈôÖÂ§öÂºèËÅîËøê‰∏öÂä°<ul><li>Â§öÂºèËÅîËøêÔºåÂèëÂ±ïËá™ÈõÜË£ÖÁÆ±ËøêËæì</li></ul></li><li>Êó†ËàπÊâøËøê‰∏öÂä°<ul><li>ÂÖ∑ÊúâÊó†ËàπÂÖ¨ÂÖ±ÊâøËøê‰∫∫NVOCC (Non Vessel Operating Common Carrier)ËµÑË¥®ÁöÑË¥ß‰ª£‰ºÅ‰∏öÂèØ‰ª•‰ª•ÊâøËøê‰∫∫ÁöÑË∫´‰ªΩÊé•ÂèóË¥ßËΩΩÂßîÊâò</li><li>Ë¥ßÁâ©Ê∏ÖÂÖ≥ÁöÑÊó∂ÂÄôÁî®Ë¥ß‰ª£‰ºÅ‰∏öÁöÑÊèêÂçïÔºåÊâøÊãÖÊâøËøê‰∫∫ÁöÑË¥£‰ªªÔºåÂÆåÊàêË¥ßÁâ©Á¶ªÊ∏ØÂà∞Â≤∏ÁöÑÂõΩÈôÖÊµ∑ËøêÁªèËê•‰∏öÂä°</li><li>Êó†ËàπÊâøËøê‰∫∫Âè™ÊòØÂ•ëÁ∫¶ÊâøËøê‰∫∫ÔºåËÄåÂÆûÈôÖÂÆåÊàêËøêËæìÁöÑÊâøËøê‰∫∫ÊòØË¥ß‰ª£‰ºÅ‰∏öÊâÄÂßîÊâòÁöÑÂÖ∂‰ªñÂõΩÈôÖËàπËà∂ËøêËæìÁªèËê•ËÄÖ</li></ul></li><li>Áâ©ÊµÅ‰∏öÂä°<ul><li>ÂèØ‰ª•ÈíàÂØπ‰∏çÂêåÂÆ¢Êà∑Êèê‰æõÂÆöÂà∂ÂåñÁöÑ‰æõÂ∫îÈìæËß£ÂÜ≥ÊñπÊ°àÔºåÂõäÊã¨‰∫ÜË¥ßÁâ©‰ªéÁîü‰∫ßÔºåÂá∫ÂéÇÔºåËΩ¨ËøêÔºåÊ∏Ö‰ªìÊä•ÂÖ≥ÔºåÂà∞ËææÁõÆÊ†áÂ∏ÇÂú∫Á≠âÂêÑ‰∏™ÁéØËäÇ</li></ul></li><li>ÂõΩÈôÖÂø´ÈÄí‰∏öÂä°</li></ul><h2 id="1-2-Âü∫Êú¨Â∑•‰ΩúÊµÅÁ®ã"><a href="#1-2-Âü∫Êú¨Â∑•‰ΩúÊµÅÁ®ã" class="headerlink" title="1.2 Âü∫Êú¨Â∑•‰ΩúÊµÅÁ®ã"></a>1.2 Âü∫Êú¨Â∑•‰ΩúÊµÅÁ®ã</h2><ul><li>Êµ∑ËøêÊµÅÁ®ã<ul><li>‰ªñÂõΩ‰π∞‰∏ªÂíå‰∏≠ÂõΩ‰ºÅ‰∏öÂ∞±Ë¥∏ÊòìË°å‰∏∫Á≠æËÆ¢Ë¥∏ÊòìÂêàÂêå</li><li>‰∏≠ÂõΩÂ∑•ÂéÇÁ°ÆÂÆöË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏öÔºåÂπ∂‰∏é‰πãÂïÜËÆ®Âá∫Ë¥ß</li><li>‰∏≠ÂõΩË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏öÂíåËàπËøêÂÖ¨Âè∏ÂïÜËÆ®ËÆ¢Ëà±‰∫ãÂÆú</li><li>ÊãøÂà∞ÊâøËΩΩË¥ßÁâ©ÁöÑËàπÁöÑÂêçÂ≠óÂíåËææÂà∞ÁõÆÁöÑÂú∞ÁöÑÂáÜÁ°Æ‰ø°ÊÅØ</li><li>ÂõΩÂÜÖÂ§ñË¥ßËøê‰ª£ÁêÜ‰ºÅ‰∏öÂÖ±ÂêåÁ°ÆËÆ§Ë¥ßÁâ©ËøêËæì‰ø°ÊÅØÔºå‰ª•ÂèäÂà∞ËææÁõÆÁöÑÂú∞ÁöÑÊó∂Èó¥‰ø°ÊÅØÔºåÂπ∂Â∞ÜÂÖ∑‰Ωì‰ø°ÊÅØ‰º†ÈÄíÁªôÂõΩÂ§ñ‰π∞ÂÆ∂</li></ul></li><li>location / key points<ul><li>ÂçñÊñπÔºåÂá∫Âè£ÂïÜÂú∞ÁÇπ</li><li>Âá∫Âè£ÂçïËØÅÊâãÁª≠</li><li>ËæπÂ¢É/ Êú∫Âú∫/ Á†ÅÂ§¥‰∫§Ë¥ß</li><li>Ë£ÖËøêÊ∏Ø</li><li>ËàπËà∑</li><li>Ëàπ‰∏ä</li><li>Ëàπ‰∏ä</li><li>ËàπËà∑</li><li>Âà∞ËææÂç∏Ë¥ßÊ∏Ø</li><li>ÊåáÂÆöÁõÆÁöÑÂú∞‰∫§Ë¥ß; ËæπÂ¢É/ Êú∫Âú∫/ Á†ÅÂ§¥</li><li>ËøõÂè£ÂçïËØÅÊâãÁª≠</li><li>ÂçñÊñπ/ ËøõÂè£ÂïÜÂú∞ÁÇπ</li></ul></li></ul><h2 id="1-3-Ë¥ß‰ª£‰ºÅ‰∏öÁ≠âÁ∫ß"><a href="#1-3-Ë¥ß‰ª£‰ºÅ‰∏öÁ≠âÁ∫ß" class="headerlink" title="1.3 Ë¥ß‰ª£‰ºÅ‰∏öÁ≠âÁ∫ß"></a>1.3 Ë¥ß‰ª£‰ºÅ‰∏öÁ≠âÁ∫ß</h2><ul><li>‰∏ÄÁ∫ßË¥ß‰ª£‰ºÅ‰∏ö<ul><li>ÈúÄË¶ÅËé∑ÂæóÂõΩÈôÖË¥ß‰ª£ËµÑÊ†ºËØÅ‰π¶</li><li>ÂïÜÂä°ÈÉ®È¢ÅÂèëÁöÑÔºå‰∏ÄÁ∫ßË¥ß‰ª£‰ºÅ‰∏öÊúâÊùÉ‰ªé‰∏≠ÂõΩ‰∏çÂêåÊ∏ØÂè£ËÆ¢Ëà±</li></ul></li><li>Â∞èÂûãË¥ß‰ª£ÂÖ¨Âè∏<ul><li>‰æùÊâò‰∫é‰∏ÄÁ∫ßË¥ß‰ª£‰ºÅ‰∏öÔºåÊù•ËøõË°åËÆ¢Ëà±ÁöÑÂÖ¨Âè∏</li></ul></li></ul><h1 id="2-ÂõΩÈôÖË¥ßËøêË°å‰∏öÂèëÂ±ïÁöÑÂ§ñÈÉ®ÁéØÂ¢É"><a href="#2-ÂõΩÈôÖË¥ßËøêË°å‰∏öÂèëÂ±ïÁöÑÂ§ñÈÉ®ÁéØÂ¢É" class="headerlink" title="2. ÂõΩÈôÖË¥ßËøêË°å‰∏öÂèëÂ±ïÁöÑÂ§ñÈÉ®ÁéØÂ¢É"></a>2. ÂõΩÈôÖË¥ßËøêË°å‰∏öÂèëÂ±ïÁöÑÂ§ñÈÉ®ÁéØÂ¢É</h1><ul><li><p>PESTÂàÜÊûêÊñπÂºè</p><ul><li>Áª¥Â∫¶<ul><li>ÊîøÊ≤ª<ul><li>2010Âπ¥Ë¥ß‰ª£Ê†áÂáÜÂåñÂßîÂëò‰ºö</li><li>2015Âπ¥„ÄäÊé®Âä®ÂÖ±Âª∫‰∏ùÁª∏‰πãË∑ØÁªèÊµéÂ∏¶Âíå21‰∏ñÁ∫™Êµ∑‰∏ä‰∏ùÁª∏‰πãË∑ØÁöÑÊÑøÊôØ‰∏éË°åÂä®„Äã</li><li>2016Âπ¥„ÄäÂÖ≥‰∫éÂä†Âø´ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜÁâ©ÊµÅ‰∏öÂÅ•Â∫∑ÂèëÂ±ïÁöÑÊåáÂØºÊÑèËßÅ„Äã</li><li>„Ää‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÊµ∑ÂïÜÊ≥ï„Äã</li></ul></li><li>ÁªèÊµé</li><li>ÊäÄÊúØ</li><li>Á§æ‰ºöÊñáÂåñ</li></ul></li><li>Â§ñÈÉ®ÁöÑÂèòÂåñÊòØÁªÑÁªáÊó†Ê≥ïÊéßÂà∂ÁöÑÔºåËÑ±Á¶ª‰∫éÁªÑÁªáÂÜÖÈÉ®ÔºåÂç¥ÁéØÁªïÂú®ÁªÑÁªáÂõõÂë®Ôºå‰ªé‰∏çÂêåÊñπÈù¢‰ΩúÁî®Âú®ÁªÑÁªáÂÜÖÈÉ®</li></ul></li><li><p>Ê≥¢Áâπ‰∫îÂäõÁ´û‰∫âÁêÜËÆ∫</p><ul><li>Áª¥Â∫¶<ul><li>Êõø‰ª£ËÄÖ<ul><li>Ë¥ß‰ª£ÁöÑ‰æõÂ∫îÂïÜ</li></ul></li><li>ÂÆ¢Êà∑</li><li>‰æõÂ∫îÂïÜ<ul><li>‰æõÂ∫îÂïÜ Â∞§ÂÖ∂ÊòØËàπËà∂ÂÖ¨Âè∏Ëà™Á©∫ÂÖ¨Âè∏ÊúâÁùÄÊØîËæÉÂº∫ÁöÑËÆÆ‰ª∑ËÉΩÂäõÔºåÂ∞§ÂÖ∂ÂØπ‰∫é‰∏≠Â∞èÂûãË¥ß‰ª£ËÄåË®Ä</li></ul></li><li>ÊΩúÂú®Á´û‰∫âËÄÖ<ul><li>ÊîøÁ≠ñÂ£ÅÂûíÊï¥‰ΩìÂú®Èôç‰Ωé</li><li>‰º†Áªü‰∏öÂä° ‚Äî Êä•ÂÖ≥Êä•Ê£ÄÔºåÁ†ÅÂ§¥Áâ©ÊµÅÔºåÁü≠ÈÄî‰∏ìÁ∫øËøêËæì</li><li>Êñ∞ÂÖ¥‰∏öÂä° ‚Äî ‰æõÂ∫îÈìæÁÆ°ÁêÜÔºåÈùûÂ∏∏ËßÑË¥ßÁâ©ÊâòËøêÔºåÂ§öÂºèËÅîËøê</li></ul></li><li>ÂêåË°å‰∏öÁ´û‰∫âËÄÖ<ul><li>ËàπËà∂ÂÖ¨Âè∏Êóó‰∏ãËá™Â∑±ËÆæÁ´ãÁöÑË¥ß‰ª£Áâ©ÊµÅÂÖ¨Âè∏<ul><li>ÊúâÁõ¥Êé•ÂÆ¢Êà∑Ê∫ê</li><li>Â∫ï‰ª∑Êµ∑ËøêË¥πÂíåËÆ¢Ëà±Ë¥πÂáèÂÖçÁöÑ‰ºòÂäø</li><li>ÂèØ‰ª•ÈÄöËøáËàπÂÖ¨Âè∏ÂÆåÂñÑÁöÑÊµ∑Â§ñÁΩëÁªúÊåáÂÆöÂõΩÂÜÖÁöÑÂá∫Âè£‰æõÂ∫îÂïÜÔºåÂèØ‰ª•Êèê‰æõÊõ¥Â§öÁßçÁöÑË¥∏ÊòìÊñπÂºè<ul><li>Ë¥∏ÊòìÊñπÂºè<ul><li>Exxxx<ul><li>EXW<ul><li>ÂçñÊñπ‰ªÖÂú®Ëá™Â∑±ÁöÑÂú∞ÁÇπ‰∏∫‰π∞ÊàøÂ§áÂ¶•Ë¥ßÁâ©‰∫§‰ªòÔºåÂá∫Â∑•ÂéÇ‰ª•ÂêéÂ∞±Ê≤°ÊúâË¥πÁî®ÂíåÂÆâÂÖ®Ë¥£‰ªª‰∫Ü</li></ul></li></ul></li><li>Fxxx  ‚Äî ÂçñÊñπÈúÄË¶ÅÂ∞ÜË¥ßÁâ©‰∫§Âà∞Âà∂ÂÆöÁöÑÊâøËøê‰∫∫Â§Ñ<ul><li>FCA  Ë¥ß‰∫§ÊâøËøê‰∫∫</li><li>FAS  Ë£ÖËøêÊ∏Ø ËàπËæπ  ‰∫§Ë¥ß ‚Äî Âà∞Á†ÅÂ§¥</li><li>FOB Ë£ÖËøêÊ∏Ø Ëàπ‰∏ä ‰∫§Ë¥ß  ‚Äî Âà∞ËàπËà∑<ul><li>‰ª∑Ê†ºËÆ°ÁÆó  = (‰∫ßÂìÅÂê´Á®éÊàêÊú¨ + Âà©Ê∂¶ + ÂõΩÂÜÖËøêËæìË¥πÁî® - Âá∫Âè£ÈÄÄÁ®é)/ Ê±áÁéá</li><li>ÂçñÊñπÁöÑ‰πâÂä°<ul><li>Â∞ÜÂêàÂêåËßÑÂÆöÁöÑË¥ßÁâ©‰∫§Âà∞‰π∞ÊàøÊâÄÊåáÊ¥æÁöÑËàπ‰∏äÂπ∂ÂèäÊó∂ÈÄöÁü•‰π∞Êñπ</li><li>ÊâøÊãÖË¥ßÁâ©Ë∂äËøáË£ÖËøêÊ∏ØËàπËà∑‰πãÂâçÁöÑ‰∏ÄÂàáÈ£éÈô©</li><li>ÂäûÁêÜË¥ßÁâ©ÁöÑÂá∫Âè£ÊâãÁª≠</li><li>Êèê‰∫§ÂïÜ‰∏öÂèëÁ•®Á≠âÊâÄÈúÄÁöÑÂá≠ËØÅ</li></ul></li><li>‰π∞ÊñπÁöÑ‰πâÂä°<ul><li>ÁßüËàπËÆ¢Ëà±ÔºåÊîØ‰ªòËøêË¥π</li><li>Â∞ÜËàπÂêçÔºåË£ÖË¥ßÂú∞ÁÇπÂíåË¶ÅÊ±Ç‰∫§Ë¥ßÁöÑÊó∂Èó¥ÂèäÊó∂ÈÄöÁü•ÂçñÊñπ</li><li>ÂèóÈ¢ÜË¥ßÁâ©ÔºåÊîØ‰ªòË¥ßÊ¨æ</li><li>ÊâøÊãÖË¥ßÁâ©Ë∂äËøáË£ÖËøêÊ∏ØËàπËà∑‰πãÂêéÁöÑ‰∏ÄÂàáÈ£éÈô©</li><li>ÂäûÁêÜË¥ßÁâ©ÁöÑËøõÂè£ÊâãÁª≠</li></ul></li></ul></li></ul></li><li>Cxxx ‚Äî ÂçñÊñπÈúÄË¶ÅËÆ¢Á´ãËøêËæìÂêàÂêåÔºå‰ΩÜÊòØÂØπ‰∫éË¥ßÁâ©ÊçüÂ§±ÁöÑÈ£éÈô©‰ª•ÂèäË£ÖËàπÂíåÂêØËøê‰πãÂêéÂèëÁîüÁöÑÊÑèÂ§ñÊâÄ‰∫ßÁîüÁöÑÈ¢ùÂ§ñË¥πÁî®ÔºåÂçñÊñπ‰∏çÊâøÊãÖË¥£‰ªª<ul><li>CFR  ÊàêÊú¨+ËøêË¥π<ul><li>CFR = FOB + Êµ∑ËøêË¥π</li></ul></li><li>CIF  ÊàêÊú¨ËøêË¥π‰øùÈô©<ul><li>CIF = FOB + Êµ∑ËøêË¥π + Êµ∑Ëøê‰øùÈô©Ë¥π</li></ul></li><li>CIP  ËøêË¥π/ ‰øùÈô©Ë¥π‰ªòÂà∞ÁõÆÁöÑÂú∞</li></ul></li><li>Dxxx ‚Äî ÂçñÊñπÊâøÊãÖÂ∞ÜË¥ßÁâ©‰∫§Âà∞Âá∫Âè£ÂõΩËæπÂ¢ÉÊàñËÄÖÁõÆÁöÑÂõΩÊâÄÈúÄÁöÑÂÖ®ÈÉ®Ë¥πÁî®ÂíåÈ£éÈô©<ul><li>DAF  Âá∫Âè£ÂõΩËæπÂ¢É‰∫§Ë¥ß</li><li>DES  ÁõÆÁöÑÊ∏ØËàπ‰∏ä‰∫§Ë¥ß</li><li>DEQ  ÁõÆÁöÑÊ∏ØÁ†ÅÂ§¥‰∫§Ë¥ß</li><li>DDU  Êú™ÂÆåÁ®é‰∫§Ë¥ß</li><li>DDP  ÂÆåÁ®éÂêé‰∫§Ë¥ß</li></ul></li><li>FOB</li></ul></li></ul></li></ul></li></ul></li></ul></li></ul></li><li><p>SWOT ÊàòÁï•ÁÆ°ÁêÜÂàÜÊûê</p><ul><li>S - Strength<ul><li>‰ºÅ‰∏öÂÜÖÈÉ®‰ºòÂäø</li></ul></li><li>W - Weakness<ul><li>‰ºÅ‰∏öÈù¢‰∏¥ÁöÑÁ´û‰∫âÂº±Âäø</li></ul></li><li>O - Opportunity<ul><li>ÂèëÂ±ïËøáÁ®ãÂΩì‰∏≠ÁöÑÊúâÂà©Â§ñÈÉ®ÁéØÂ¢É</li></ul></li><li>T  - Threat<ul><li>‰ºÅ‰∏öËá™Ë∫´‰∏öÂä°ÁöÑÂ§ñÈÉ®Â®ÅËÉÅ</li><li>ÂΩìÂ§ñÈÉ®ÁéØÂ¢É‰∏çÂà©‰∫é‰ºÅ‰∏öÁöÑÂèëÂ±ïÔºå‰ºÅ‰∏ö‰∏∫‰∫ÜÈÅøÂÖçÂ§ñÈÉ®ÁéØÂ¢ÉÂ∏¶Êù•ÁöÑÂ®ÅËÉÅÔºåÂ∫îÂΩìÂèäÊó∂Ë∞ÉÊï¥ÁªèËê•ÊàòÁï•</li></ul></li></ul></li></ul><h1 id="3-ÂÜÖÈÉ®ÁéØÂ¢ÉÂàÜÊûê"><a href="#3-ÂÜÖÈÉ®ÁéØÂ¢ÉÂàÜÊûê" class="headerlink" title="3. ÂÜÖÈÉ®ÁéØÂ¢ÉÂàÜÊûê"></a>3. ÂÜÖÈÉ®ÁéØÂ¢ÉÂàÜÊûê</h1><ul><li>‰ª∑ÂÄºÈìæÂàÜÊûêÊ≥ï<ul><li>Â∞ÜÊ¥ªÂä®ÂàÜ‰∏∫Âü∫Á°ÄÊ¥ªÂä®‰ª•ÂèäËæÖÂä©Ê¥ªÂä®‰∏§Â§ßÁ±ª<ul><li>Âü∫Á°ÄÊ¥ªÂä®<ul><li>ÂÜÖÈÉ®Áâ©ÊµÅÊ¥ªÂä®<ul><li>ÂêÑ‰∏™ÈÉ®Èó®ÂíåÁéØËäÇ‰πãÈó¥ÁöÑÂêà‰ΩúÔºåÂ¶Ç‰ΩïËÉΩÁõ¥ËßÇ‰∫ÜËß£Âà∞È°πÁõÆÁöÑËøõÂ±ïÊ≠§Á±ªÈóÆÈ¢ò</li></ul></li><li>Áîü‰∫ßÁªèËê•Ê¥ªÂä®<ul><li>Áîü‰∫ß ÈîÄÂîÆ  ‰æõÂ∫î Ë¥¢Âä°</li></ul></li><li>Â§ñÈÉ®Áâ©ÊµÅÊ¥ªÂä®<ul><li>Ë¥ßÁâ©ÁöÑÂë®ËΩ¨</li><li>Êä•ÂÖ≥ Êä•Ê£Ä Êü•È™å Ê∏ÖÂÖ≥ Áº¥Á®éÁ≠â</li></ul></li><li>ÊúçÂä°ÊÄßÊ¥ªÂä®</li></ul></li><li>ËæÖÂä©Ê¥ªÂä®<ul><li>‰∫∫ÂäõËµÑÊ∫êÁÆ°ÁêÜÊ¥ªÂä®</li><li>ÊîπÂñÑÂü∫Á°ÄËÆæÊñΩÊù°‰ª∂ÁöÑÊ¥ªÂä®</li><li>ÂéüÊùêÊñôÈááË¥≠Ê¥ªÂä®</li><li>Êñ∞‰∫ßÂìÅÁ†îÂèëÊ¥ªÂä®Á≠â</li></ul></li></ul></li><li>Âè™ÊúâÂú®‰∏Ä‰∫õÁâπÂÆöÁéØËäÇÔºåÊâç‰ºöÁúüÁöÑÂéªÂàõÈÄ†‰ª∑ÂÄºÔºåËøô‰∫õÊòØÊàòÁï•ÁéØËäÇÔºåÈúÄË¶ÅÂú®Ê≠§ÊûÑÂª∫ÊàòÁï•‰ºòÂäø</li></ul></li></ul><h1 id="4-Other-Notes"><a href="#4-Other-Notes" class="headerlink" title="4. Other Notes"></a>4. Other Notes</h1><ul><li><p>‰ºÅ‰∏öÊàòÁï•</p><ul><li>Áî®‰∫éÊï¥Âêà‰∏éÈáçÊñ∞‰ºòÂåñÈÖçÁΩÆÁöÑÊé™ÊñΩÂèäÂèØË°åÊÄßÊñπÊ°à</li><li>‰ºÅ‰∏öÁªÑÁªáÁªìÊûÑË¶ÅË∑üÈöè‰ºÅ‰∏öÊàòÁï•ËøõË°åË∞ÉÊï¥</li></ul></li><li><p>Â¶Ç‰ΩïÈÄâÊã©ÂêàÈÄÇÁöÑÁ´û‰∫âÊàòÁï•</p><ul><li>ÂØπÊúâÂê∏ÂºïÂäõÔºåÈ´òÊΩúÂäõÁöÑ‰∫ß‰∏öÁöÑÊ≠£Á°ÆÈÄâÊã©</li><li>Âú®ÈÄâÊã©ÁöÑË°å‰∏öÂΩì‰∏≠Á°ÆÁ´ãËá™Â∑±ÁöÑÁ´û‰∫â‰ºòÂäøÂú∞‰Ωç</li><li>Èô§Ê≠§‰ª•Â§ñËøòÈúÄË¶Å‰ªé‰ºÅ‰∏öÂÜÖÈÉ®ÁéØÂ¢ÉÔºåÁ†îÁ©∂‰ª∑ÂÄºÈìæ</li></ul></li><li><p>‰ºÅ‰∏öÂÜÖÈÉ®ÊÄßÁöÑÊ∑±ÂÖ•Á†îÁ©∂ ‚Äî ‰ºÅ‰∏öÊ†∏ÂøÉËÉΩÂäõ</p><ul><li>ËÆ©‰ºÅ‰∏öÊûÑÊàêÂÖ∂‰ªñ‰ºÅ‰∏öÂπ∂‰∏çÂÖ∑Â§áÁöÑËÉΩÂäõÔºåÂêåÊó∂ËµÑÊ∫êÊó†Ê≥ïÂú®‰∏çÂêåÁöÑ‰ºÅ‰∏ö‰πãÈó¥ËøõË°åÊµÅÈÄö</li><li>‰ºÅ‰∏öÂÜÖÈÉ®ÁöÑËµÑÊ∫êÁöÑÁã¨ÁâπÊÄßÔºåÁõ¥Êé•ÂÖ≥Á≥ªÂà∞‰ºÅ‰∏öÂà©Ê∂¶ÁöÑËé∑Âæó‰ª•ÂèäÁ´û‰∫â‰ºòÂäøÁöÑ‰øùÊåÅ</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>1.<a href="https://www.52by.com/article/2584">https://www.52by.com/article/2584</a><br>2. „ÄäÂ∞èÂûãÂõΩÈôÖË¥ßËøê‰ª£ÁêÜXÂÖ¨Âè∏ÁöÑÂèëÂ±ïÊàòÁï•Á†îÁ©∂„Äã</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢&quot;&gt;&lt;a href=&quot;#ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢&quot; class=&quot;headerlink&quot; title=&quot;ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢&quot;&gt;&lt;/a&gt;ÂõΩÈôÖË¥ßËøê‰ª£ÁêÜË°å‰∏öÂàùÊé¢&lt;/h1&gt;&lt;h1 id=&quot;1-Ë¥ßËøêÂÖ¨Âè∏‰∏öÂä°‰∏éÂ∑•‰ΩúÂÜÖÂÆπ&quot;&gt;&lt;a href=&quot;#1-Ë¥ßËøêÂÖ¨Âè∏‰∏öÂä°
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
      <category term="Ë¥ßËøê‰ª£ÁêÜ" scheme="https://www.llchen60.com/tags/%E8%B4%A7%E8%BF%90%E4%BB%A3%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>System Design Patterns - Quorum</title>
    <link href="https://www.llchen60.com/System-Design-Patterns-Quorum/"/>
    <id>https://www.llchen60.com/System-Design-Patterns-Quorum/</id>
    <published>2021-08-11T04:26:01.000Z</published>
    <updated>2021-08-11T04:26:42.996Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Background"><a href="#1-Background" class="headerlink" title="1. Background"></a>1. Background</h1><p>In distributed system, data is replicated across multiple servers for fault tolerance and high availability.</p><p>Once system decides to maintain multiple copies of data, another problem arises: how to make sure that all replicas are consistent?? </p><h1 id="2-Dive-Deep"><a href="#2-Dive-Deep" class="headerlink" title="2. Dive Deep"></a>2. Dive Deep</h1><h2 id="2-1-Definition"><a href="#2-1-Definition" class="headerlink" title="2.1 Definition"></a>2.1 Definition</h2><ul><li>Quorum<ul><li>Minimum number of servers on which a distributed operation needs to be performed successfully before declaring the operation‚Äôs overall success</li></ul></li></ul><h2 id="2-2-How-it-works"><a href="#2-2-How-it-works" class="headerlink" title="2.2 How it works?"></a>2.2 How it works?</h2><ul><li>Suppose a database is replicated on 5 machines, then quorum refers to the minimum number of machines that perform the same action for a given transaction in order to decide the final operation for that transaction</li><li>So in a set of 5, three machines form the majority quorum, quorum <strong>enforces the consistency requirement</strong> needed for distributed operations</li><li>Quorum Number<ul><li>N / 2 + 1</li></ul></li><li>Quorum is achieved when nodes follow the below protocol R + W &gt; N<ul><li>R  minimum read nodes</li><li>W minimum write nodes</li><li>N  nodes in the quorum group</li></ul></li></ul><h2 id="2-3-Where-is-it-used"><a href="#2-3-Where-is-it-used" class="headerlink" title="2.3 Where is it used?"></a>2.3 Where is it used?</h2><ul><li>Chubby<ul><li>Use paxos for leader election, which use quorum to ensure strong consistency</li></ul></li><li>Cassandra<ul><li>Ensure data consistency, each write request can be configured to be successful only if the data has been written to at least a quorum of replica nodes</li></ul></li><li>Dynamodb<ul><li>Writes to a sloppy quorum of other nodes in the system</li><li>All read/ write operations are performed on the first N healthy nodes from the preference list, which may not always be the first N nodes encountered walking the consistent hashing ring</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Background&quot;&gt;&lt;a href=&quot;#1-Background&quot; class=&quot;headerlink&quot; title=&quot;1. Background&quot;&gt;&lt;/a&gt;1. Background&lt;/h1&gt;&lt;p&gt;In distributed system, data 
      
    
    </summary>
    
    
      <category term="SystemDesign" scheme="https://www.llchen60.com/categories/SystemDesign/"/>
    
    
  </entry>
  
  <entry>
    <title>System Design Patterns - Bloom Filters</title>
    <link href="https://www.llchen60.com/System-Design-Patterns-Bloom-Filters/"/>
    <id>https://www.llchen60.com/System-Design-Patterns-Bloom-Filters/</id>
    <published>2021-08-10T02:33:45.000Z</published>
    <updated>2021-08-10T02:34:11.571Z</updated>
    
    <content type="html"><![CDATA[<h1 id="System-Design-Patterns-Bloom-Filters"><a href="#System-Design-Patterns-Bloom-Filters" class="headerlink" title="System Design Patterns - Bloom Filters"></a>System Design Patterns - Bloom Filters</h1><p>Created: August 8, 2021 10:06 PM<br>Status: Finished<br>Tags: System Design<br>Type: Tech Resource</p><h1 id="1-Background"><a href="#1-Background" class="headerlink" title="1. Background"></a>1. Background</h1><ul><li>Suppose we have a large set of structured data(identified by record IDs) stored in a set of data files, and we want to know which file might contain our required data<ul><li>we don‚Äôt want to read each file, as it‚Äôs slow and we have to read a lot of data from the disk</li></ul></li><li>Solution 1: Build an index on each data file and store it in a separate index file, to map each record ID to its offset in the data file; each index file will be sorted on the record ID. Then we could do a binary search in index file</li><li>Solution 2: We could use Bloom Filters</li></ul><h1 id="2-How-does-Bloom-Filter-work"><a href="#2-How-does-Bloom-Filter-work" class="headerlink" title="2. How does Bloom Filter work?"></a>2. How does Bloom Filter work?</h1><ul><li>The Bloom filter data structure tells whether an element <strong>may be in a set, or definitely is not</strong><ul><li>which means the only possible errors are false positives</li></ul></li><li>How it looks<ul><li>An empty bloom filter is a bit array of m bits, all set to 0</li><li>There are also k different hash functions, each of which maps a set element to one of the m bit positions</li></ul></li><li>Workflow<ul><li>To add an element, feed it to the hash functions to get k bit positions, and set the bits at these positions to 1</li><li>To test if an element is in the set, feed it to the hash functions to get k bit positions<ul><li>if any of the bits at these positions is 0, the element is definitely not in the set</li><li>if all are 1, then the element may be in the set</li></ul></li></ul></li></ul><h1 id="3-When-will-we-use-Bloom-Filter"><a href="#3-When-will-we-use-Bloom-Filter" class="headerlink" title="3. When will we use Bloom Filter?"></a>3. When will we use Bloom Filter?</h1><ul><li>In BigTable, any read operation has to read from all SSTables that make up a tablet<ul><li>if these SSTables are not in memory, the read operation may end up doing many disk accesses</li><li>BigTable uses bloom filters to reduce the number of disk accesses</li><li>Store of BloomFilter could drastically reduces the number of disk seeks, thereby improving read performance</li></ul></li></ul><h1 id="4-How-to-use-Bloom-Filter-in-Java"><a href="#4-How-to-use-Bloom-Filter-in-Java" class="headerlink" title="4. How to use Bloom Filter in Java?"></a>4. How to use Bloom Filter in Java?</h1><ul><li>We could use BloomFilter class from the Guava library to achieve this</li></ul><pre><code class="jsx">BloomFilter&lt;Integer&gt; filter = BloomFilter.create(    Funnels.integerFunnel(),     500,     0.01);</code></pre><ul><li>How to implement from scratch   <a href="https://www.inlighting.org/archives/java-implement-bloom-filter/">https://www.inlighting.org/archives/java-implement-bloom-filter/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;System-Design-Patterns-Bloom-Filters&quot;&gt;&lt;a href=&quot;#System-Design-Patterns-Bloom-Filters&quot; class=&quot;headerlink&quot; title=&quot;System Design Patter
      
    
    </summary>
    
    
      <category term="SystemDesign" scheme="https://www.llchen60.com/categories/SystemDesign/"/>
    
    
  </entry>
  
  <entry>
    <title>RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè</title>
    <link href="https://www.llchen60.com/Redis%E9%9B%86%E5%90%88%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>https://www.llchen60.com/Redis%E9%9B%86%E5%90%88%E7%BB%9F%E8%AE%A1%E6%A8%A1%E5%BC%8F/</id>
    <published>2021-08-08T23:32:13.000Z</published>
    <updated>2021-08-08T23:32:56.696Z</updated>
    
    <content type="html"><![CDATA[<h1 id="RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè"><a href="#RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè" class="headerlink" title="RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè"></a>RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè</h1><h1 id="1-ËÅöÂêàÁªüËÆ°"><a href="#1-ËÅöÂêàÁªüËÆ°" class="headerlink" title="1. ËÅöÂêàÁªüËÆ°"></a>1. ËÅöÂêàÁªüËÆ°</h1><h2 id="1-1-Ê¶ÇÂøµ"><a href="#1-1-Ê¶ÇÂøµ" class="headerlink" title="1.1 Ê¶ÇÂøµ"></a>1.1 Ê¶ÇÂøµ</h2><ul><li>ÁªüËÆ°Â§ö‰∏™ÈõÜÂêàÂÖÉÁ¥†ÁöÑËÅöÂêàÁªìÊûú<ul><li>‰∫§ÈõÜÁªüËÆ° ‚Äî ÁªüËÆ°Â§ö‰∏™ÈõÜÂêàÁöÑÂÖ±ÊúâÂÖÉÁ¥†</li><li>Â∑ÆÈõÜÁªüËÆ° ‚Äî ÁªüËÆ°ÂÖ∂‰∏≠‰∏Ä‰∏™ÈõÜÂêàÁã¨ÊúâÁöÑÂÖÉÁ¥†</li><li>Âπ∂ÈõÜÁªüËÆ° ‚Äî ÁªüËÆ°Â§ö‰∏™ÈõÜÂêàÁöÑÊâÄÊúâÂÖÉÁ¥†</li></ul></li><li>ËÅöÂêàÁªüËÆ°ÂèØ‰ª•‰ΩøÁî®SetÁ±ªÂûãÊù•ÂÅö</li><li>‰ΩÜÊòØSetÁöÑÂ∑ÆÈõÜÔºåÂπ∂ÈõÜÔºå‰∫§ÈõÜÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÊØîËæÉÈ´òÔºåÂú®Êï∞ÊçÆÈáèÊØîËæÉÂ§ßÁöÑÊÉÖÂÜµ‰∏ãÔºåÁõ¥Êé•ÊâßË°åÂèØËÉΩ‰ºöÂØºËá¥RedisÂÆû‰æãÈòªÂ°û„ÄÇ</li><li>ÂèØ‰ª•‰ªé‰∏ª‰ªéÈõÜÁæ§ÂΩì‰∏≠ÈÄâÊã©‰∏Ä‰∏™‰ªéÂ∫ìÔºå‰ΩøÂÖ∂‰∏ìÈó®Ë¥üË¥£ËÅöÂêàËÆ°ÁÆóÔºåÊàñËÄÖÂ∞ÜÊï∞ÊçÆËØªÂèñÂà∞ÂÆ¢Êà∑Á´ØÔºåÂú®ÂÆ¢Êà∑Á´ØÂÆåÊàêËÅöÂêàÁªüËÆ°</li></ul><h2 id="1-2-Ê°à‰æãÂàÜÊûê"><a href="#1-2-Ê°à‰æãÂàÜÊûê" class="headerlink" title="1.2 Ê°à‰æãÂàÜÊûê"></a>1.2 Ê°à‰æãÂàÜÊûê</h2><ul><li>ÁªüËÆ°‰∏Ä‰∏™ÊâãÊú∫AppÁöÑÊØèÂ§©ÁöÑÊñ∞Â¢ûÁî®Êà∑Êï∞ÂíåÁ¨¨‰∫åÂ§©ÁöÑÁïôÂ≠òÁî®Êà∑Êï∞</li><li>Áî®‰∏Ä‰∏™ÈõÜÂêàËÆ∞ÂΩïÊâÄÊúâÁôªÈôÜËøáAppÁöÑÁî®Êà∑Id<ul><li>key ‚Äî user:id</li><li>value ‚Äî setÁ±ªÂûã ËÆ∞ÂΩïÁî®Êà∑id</li></ul></li><li>Âè¶Â§ñ‰∏Ä‰∏™ÈõÜÂêàËÆ∞ÂΩïÊØèÂ§©Áî®Êà∑set<ul><li>key ‚Äî user:id:20210808</li><li>value ‚Äî setÁ±ªÂûã  ËÆ∞ÂΩïÁî®Êà∑id</li></ul></li></ul><pre><code class="jsx">// Â∑ÆÂÄºÁªüËÆ°SUNIONSTORE user:id user:id user:id:20210808// ËÆ°ÁÆóÊñ∞Áî®Êà∑SDIFFSTORE user:new user:id:20210808 user:id // ËÆ°ÁÆóÁïôÂ≠òÁî®Êà∑SINTERSTOPRE user:id:rem user:id:20210808 user:id:20210809</code></pre><h1 id="2-ÊéíÂ∫èÁªüËÆ°"><a href="#2-ÊéíÂ∫èÁªüËÆ°" class="headerlink" title="2. ÊéíÂ∫èÁªüËÆ°"></a>2. ÊéíÂ∫èÁªüËÆ°</h1><h2 id="2-1-Ê¶ÇÂøµ"><a href="#2-1-Ê¶ÇÂøµ" class="headerlink" title="2.1 Ê¶ÇÂøµ"></a>2.1 Ê¶ÇÂøµ</h2><ul><li>ÈúÄË¶ÅËÉΩÂØπËæìÂá∫ËøõË°åÊéíÂ∫èÔºåRedisÂ∏∏Áî®ÁöÑ4‰∏™ÈõÜÂêàÁ±ªÂûãÂΩì‰∏≠ (List, Hash, Set, Sorted Set)Ôºå ListÂíåSorted SetÂ±û‰∫éÊúâÂ∫èÈõÜÂêà</li><li>ListÊåâÁÖßÂÖÉÁ¥†ËøõÂÖ•ListÁöÑÈ°∫Â∫èÊéíÂ∫èÔºåËÄåSorted SetÂèØ‰ª•Ê†πÊçÆÂÖÉÁ¥†ÁöÑÊùÉÈáçÊù•ÊéíÂ∫è</li></ul><h2 id="2-2-Ê°à‰æã"><a href="#2-2-Ê°à‰æã" class="headerlink" title="2.2 Ê°à‰æã"></a>2.2 Ê°à‰æã</h2><ul><li>ÁîµÂïÜÁΩëÁ´ô‰∏äÊèê‰æõÊúÄÊñ∞ËØÑËÆ∫ÂàóË°®ÁöÑÂú∫ÊôØ</li><li>ListÂú®Ëøô‰∏™Âú∫ÊôØÈáåÈù¢ÁöÑÈóÆÈ¢ò<ul><li>Âõ†‰∏∫Ê†πÊçÆ‰ΩçÁΩÆÊéíÂ∫èÔºåÂΩìÊúâÊñ∞ÁöÑËØÑ‰ª∑Âä†ËøõÊù•ÔºåÈÇ£‰πàÂèØËÉΩ‰ºöÊúâ‰∏Ä‰∫õËØÑ‰ª∑‰ºöÂú®‰∏çÂêåÈ°µÈù¢ÈáçÂ§çÂá∫Áé∞</li></ul></li><li>Sorted Set‰∏çÂ≠òÂú®Ëøô‰∏™ÈóÆÈ¢òÔºåÂõ†‰∏∫ÂÆÉÊòØÊ†πÊçÆÂÖÉÁ¥†ÁöÑÂÆûÈôÖÊùÉÈáçÊù•ÊéíÂ∫èÂíåËé∑ÂèñÊï∞ÊçÆÁöÑ<ul><li>Êàë‰ª¨ÂèØ‰ª•ÊåâÁÖßËØÑËÆ∫Êó∂Èó¥ÁöÑÂÖàÂêéÁªôÊØèÊù°ËØÑËÆ∫ËÆæÁΩÆ‰∏Ä‰∏™ÊùÉÈáçÂÄºÔºåÁÑ∂ÂêéÂ∞ÜËØÑËÆ∫‰øùÂ≠òÂà∞Sorted SetÂΩì‰∏≠</li><li>ZRANGEBYSCOREÂëΩ‰ª§Â∞±ÂèØ‰ª•ÊåâÁÖßÊùÉÈáçÊéíÂ∫è‰ª•ÂêéËøîÂõûÂÖÉÁ¥†</li></ul></li></ul><h1 id="3-‰∫åÂÄºÁä∂ÊÄÅÁªüËÆ°"><a href="#3-‰∫åÂÄºÁä∂ÊÄÅÁªüËÆ°" class="headerlink" title="3. ‰∫åÂÄºÁä∂ÊÄÅÁªüËÆ°"></a>3. ‰∫åÂÄºÁä∂ÊÄÅÁªüËÆ°</h1><h2 id="3-1-Ê¶ÇÂøµ"><a href="#3-1-Ê¶ÇÂøµ" class="headerlink" title="3.1 Ê¶ÇÂøµ"></a>3.1 Ê¶ÇÂøµ</h2><ul><li>ÊåáÈõÜÂêàÂÖÉÁ¥†ÁöÑÂèñÂÄºÂè™Êúâ0Âíå1‰∏§Áßç</li><li>ËÆ°ÁÆóÊµ∑Èáè‰∫åÂÄºÁä∂ÊÄÅÊï∞ÊçÆÁöÑÊó∂ÂÄôÔºåbitmapÂèØ‰ª•ÊúâÊïàÂáèÂ∞ëÊâÄÈúÄÁöÑÂÜÖÂ≠òÁ©∫Èó¥</li></ul><h2 id="3-2-Ê°à‰æã"><a href="#3-2-Ê°à‰æã" class="headerlink" title="3.2 Ê°à‰æã"></a>3.2 Ê°à‰æã</h2><ul><li>Á≠æÂà∞ÁªüËÆ°<ul><li>ÊØè‰∏™Áî®Êà∑‰∏ÄÂ§©ÁöÑÁ≠æÂà∞Áî®‰∏Ä‰∏™bit‰ΩçÂ∞±ËÉΩË°®Á§∫</li><li>Âõ†Ê≠§Âπ∂‰∏çÈúÄË¶ÅÈùûÂ∏∏Â§çÊùÇÁöÑÊï∞ÊçÆÁ±ªÂûãÔºå‰ΩøÁî®bitmapÂ∞±ÂèØ‰ª•‰∫Ü</li></ul></li><li>RedisÊèê‰æõ‰∫ÜBitmapÁ±ªÂûã<ul><li>GETBIT</li><li>SETBIT<ul><li>Â∞ÜÊüê‰∏Ä‰ΩçËÆæÁΩÆ‰∏∫1</li></ul></li><li>BITCOUNT<ul><li>Áî®Êù•ÁªüËÆ°ÊâÄÊúâ1ÁöÑ‰∏™Êï∞</li></ul></li></ul></li></ul><pre><code class="jsx">// ËÆ∞ÂΩïÁî®Êà∑8 3 Á≠æÂà∞‰∫ÜSETBIT uid:sign:3000:202008 2 1 // Ê£ÄÊü•ÊòØÂê¶8 3 Á≠æÂà∞‰∫ÜGETBIT uid:sign:3000:202008 2 // ÁªüËÆ°ËØ•Áî®Êà∑8Êúà‰ªΩÁöÑÁ≠æÂà∞Ê¨°Êï∞BITCOUNT uid:sign:3000:202008 </code></pre><ul><li>Â¶Ç‰ΩïÁªüËÆ°‰∏Ä‰∫ø‰∏™Áî®Êà∑ËøûÁª≠10Â§©ÁöÑÁ≠æÂà∞ÊÉÖÂÜµ<ul><li>Â∞ÜÊØèÂ§©Êó•Êúü‰Ωú‰∏∫keyÔºåÊØè‰∏™keyÂØπÂ∫î‰∏Ä‰∏™1‰∫ø‰ΩçÁöÑbitmap  ÊØè‰∏Ä‰∏™bitÂØπÂ∫î‰∏Ä‰∏™Áî®Êà∑ÂΩìÂ§©ÁöÑÁ≠æÂà∞ÊÉÖÂÜµ</li><li>ÂØπ10‰∏™bitmapÂÅö‰∏éÊìç‰Ωú</li><li>ÁÑ∂ÂêéÁî®BITCOUNTÁªüËÆ°‰∏ãÊúÄÁªàÁîüÊàêÁöÑBitmapÂΩì‰∏≠1ÁöÑ‰∏™Êï∞</li></ul></li></ul><h1 id="4-Âü∫Êï∞ÁªüËÆ°"><a href="#4-Âü∫Êï∞ÁªüËÆ°" class="headerlink" title="4. Âü∫Êï∞ÁªüËÆ°"></a>4. Âü∫Êï∞ÁªüËÆ°</h1><h2 id="4-1-Ê¶ÇÂøµ"><a href="#4-1-Ê¶ÇÂøµ" class="headerlink" title="4.1 Ê¶ÇÂøµ"></a>4.1 Ê¶ÇÂøµ</h2><ul><li>Âü∫Êï∞ÁªüËÆ°ÊåáÁªüËÆ°‰∏Ä‰∏™ÈõÜÂêà‰∏≠‰∏çÈáçÂ§çÁöÑÂÖÉÁ¥†ÁöÑ‰∏™Êï∞</li></ul><h2 id="4-2-Ê°à‰æã"><a href="#4-2-Ê°à‰æã" class="headerlink" title="4.2 Ê°à‰æã"></a>4.2 Ê°à‰æã</h2><ul><li>ÁªüËÆ°‰∏Ä‰∏™ÁΩëÈ°µÁöÑUV<ul><li>ÈúÄË¶ÅÂéªÈáçÔºå‰∏Ä‰∏™Áî®Êà∑‰∏ÄÂ§©ÂÜÖÁöÑÂ§öÊ¨°ËÆøÈóÆÂè™ËÉΩÁÆó‰∏ÄÊ¨°</li></ul></li><li>ÂèØ‰ª•‰ΩøÁî®SETÊàñËÄÖHASHÁ±ªÂûãÊù•ËøõË°åËÆ∞ÂΩïÔºå‰ΩÜÊòØ‰ºöÊ∂àËÄóÂæàÂ§ßÁöÑÂÜÖÂ≠òÁ©∫Èó¥</li><li>ÂèØ‰ª•‰ΩøÁî®HyperLogLog<ul><li>Áî®‰∫éÁªüËÆ°Âü∫Êï∞ÁöÑÊï∞ÊçÆÈõÜÂêàÁ±ªÂûã</li><li>‰ºòÂäøÂú®‰∫éÂΩìÈõÜÂêàÂÖÉÁ¥†Êï∞ÈáèÈùûÂ∏∏Â§öÁöÑÊó∂ÂÄôÔºåËÆ°ÁÆóÂü∫Êï∞ÊâÄÈúÄÁöÑÁ©∫Èó¥ÊÄªÊòØÂõ∫ÂÆöÁöÑÔºåËÄå‰∏îËøòÂæàÂ∞è</li><li>Redis‰∏≠ÊØè‰∏™HyperLogLogÂè™ÈúÄË¶Å‰ΩøÁî®12KBÂÜÖÂ≠òÔºåÂ∞±ÂèØ‰ª•ËÆ°ÁÆóÊé•Ëøë2^64‰∏™ÂÖÉÁ¥†ÁöÑÂü∫Êï∞</li></ul></li><li>HyperLogLogÁöÑÁªüËÆ°ËßÑÂàôÊòØÂü∫‰∫éÊ¶ÇÁéáÂÆåÊàêÁöÑÔºåÂõ†Ê≠§ÂÖ∂ÁªôÂá∫ÁöÑÁªüËÆ°ÁªìÊûúÊòØÊúâ‰∏ÄÂÆöËØØÂ∑ÆÁöÑÔºåÊ†áÂáÜËØØÁÆóÁéá‰∏∫0.81% ; Â¶ÇÊûúÂ∫îÁî®Âú∫ÊôØÊòØÂøÖÈ°ªÈùûÂ∏∏Á≤æÁ°ÆÔºåÈÇ£Â∞±ËøòÈúÄË¶Å‰ΩøÁî®SetÊàñËÄÖHashÁ±ªÂûã</li></ul><pre><code class="jsx">PFADD page1:uv  user1 user2 user3 user4 PFCOUNT page1:uv </code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè&quot;&gt;&lt;a href=&quot;#RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè&quot; class=&quot;headerlink&quot; title=&quot;RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè&quot;&gt;&lt;/a&gt;RedisÈõÜÂêàÁªüËÆ°Ê®°Âºè&lt;/h1&gt;&lt;h1 id=&quot;1-ËÅöÂêàÁªüËÆ°&quot;&gt;&lt;a href=&quot;#1-ËÅöÂêàÁªüËÆ°&quot; cla
      
    
    </summary>
    
    
      <category term="Êï∞ÊçÆÂ≠òÂÇ®" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>DynamoDB Architecture (Paper Reading)</title>
    <link href="https://www.llchen60.com/DynamoDB-Architecture-Paper-Reading/"/>
    <id>https://www.llchen60.com/DynamoDB-Architecture-Paper-Reading/</id>
    <published>2021-08-07T20:14:38.000Z</published>
    <updated>2021-08-08T18:51:22.531Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>Designed to be always on</li><li>Dynamo falls within the category of AP systems (available and partition tolerant) and is designed for high availability and partition tolerance at the expense of strong consistency</li></ul><h2 id="1-1-Design-Goals"><a href="#1-1-Design-Goals" class="headerlink" title="1.1 Design Goals"></a>1.1 Design Goals</h2><ul><li>Scalable<ul><li>System need to be highly scalable. We should be able to throw a machine into the system to see proportional improvement</li></ul></li><li>Decentralized<ul><li>To avoid single points of failures and performance bottlenecks, there should not be any central/ leader process</li></ul></li><li>Eventually Consistent<ul><li>Data can be optimistically replicated to become eventually consistent</li></ul></li></ul><h2 id="1-2-Use-cases"><a href="#1-2-Use-cases" class="headerlink" title="1.2 Use cases"></a>1.2 Use cases</h2><ul><li>eventually consistent database</li></ul><h2 id="1-3-System-APIs"><a href="#1-3-System-APIs" class="headerlink" title="1.3 System APIs"></a>1.3 System APIs</h2><ul><li>put(key, context, object)<ul><li>find the nodes where the object associated with the given key should locate</li><li>context is a value that is returned with a get operation and then sent back with the put operation</li><li>context is always stored along with the object</li><li>used like a cookie to verify the validity of the object supplied in the put request</li></ul></li><li>get(key)<ul><li>find the nodes where the object associated with the given key is located</li><li>return a single object or a list of objects with conflicting versions along with a context</li><li>context contains encoded metadata about the object, and <strong>version of the object</strong></li></ul></li></ul><h1 id="2-High-Level-Design"><a href="#2-High-Level-Design" class="headerlink" title="2. High Level Design"></a>2. High Level Design</h1><h2 id="2-1-Data-Distribution"><a href="#2-1-Data-Distribution" class="headerlink" title="2.1 Data Distribution"></a>2.1 Data Distribution</h2><h3 id="2-1-1-What-is-it"><a href="#2-1-1-What-is-it" class="headerlink" title="2.1.1 What is it"></a>2.1.1 What is it</h3><ul><li>Consistent hashing to distribute its data among nodes</li><li>Also make it easy to add/ remove nodes from a dynamo cluster</li></ul><h3 id="2-1-2-Challenge"><a href="#2-1-2-Challenge" class="headerlink" title="2.1.2 Challenge"></a>2.1.2 Challenge</h3><ul><li>how do we know on which node a particular piece of data will be stored?</li><li>when we add/ remove nodes, how do we know what data will be moved from existing nodes to the new nodes?</li><li>how can we minimize data movement when nodes join or leave?</li></ul><h3 id="2-1-3-Consistent-Hashing"><a href="#2-1-3-Consistent-Hashing" class="headerlink" title="2.1.3 Consistent Hashing"></a>2.1.3 Consistent Hashing</h3><ul><li><p>Represents the data managed by a cluster as a ring</p></li><li><p>Each node in the ring is assigned a range of data</p></li><li><p>Token</p><ul><li><p>The start of the range is called a token</p></li><li><p>each node will be assigned with one token</p><p>  <img src="https://i.loli.net/2021/08/08/8jFPMEDNmn4cXaf.png" alt=""></p></li></ul></li><li><p>Process for a put or get request</p><ul><li>DDB performs a MD5 hashing algorithm to the key</li><li>Output determines within which range the data lies ‚Äî‚Üí which node the data will be stored</li></ul></li><li><p>Problems for only use physical nodes</p><ul><li>for adding or removing nodes, it only influence the next node, but it would cause uneven distribution of traffic</li><li>recomputing the tokens causing a significant administrative overhead for a large cluster</li><li>Since each node is assigned one large range, if the data is not evenly distributed, some nodes can become hotspots</li><li>Since each node‚Äôs data is replicated on a fixed number of nodes (discussed later), when we need to rebuild a node, only its replica nodes can provide the data. This puts a lot of pressure on the replica nodes and can lead to service degradation</li></ul></li></ul><h3 id="2-1-4-Virtual-Nodes"><a href="#2-1-4-Virtual-Nodes" class="headerlink" title="2.1.4 Virtual Nodes"></a>2.1.4 Virtual Nodes</h3><p><img src="https://i.loli.net/2021/08/08/YWwxt9eMmToQ3qn.png" alt=""></p><ul><li><p>Hash range is divided into multiple smaller ranges, and each physical node is assigned multiple of these smaller ranges</p></li><li><p>Each of these subranges is called a Vnode</p></li><li><p>Vnodes are randomly distributed across the cluster and are generally non contiguous (‰∏çËøûÁª≠ÁöÑ)</p><p>  <img src="https://i.loli.net/2021/08/08/RVgrPm8T19nbKZB.png" alt=""></p></li><li><p>Benefits of Vnodes</p><ul><li>Help spread the load more evenly across the physical nodes on the cluster by dividing the hash range into smaller subranges<ul><li>speeds up the rebalancing process after adding or removing nodes</li><li>When a new node is added, it receives many Vnodes from the existing nodes to maintain a balanced cluster. Similarly, when a node needs to be rebuilt, instead of getting data from a fixed number of replicas, many nodes participate in the rebuild process.</li></ul></li><li>Vnodes make it easier to maintain a cluster containing heterogeneous machines. This means, with Vnodes, we can assign a high number of ranges to a powerful server and a lower number of ranges to a less powerful server</li><li>Since Vnodes help assign smaller ranges to each physical node, the probability of hotspots is much less than the basic Consistent Hashing scheme which uses one big range per node</li></ul></li></ul><h2 id="2-2-Data-Replication-and-Consistency"><a href="#2-2-Data-Replication-and-Consistency" class="headerlink" title="2.2 Data Replication and Consistency"></a>2.2 Data Replication and Consistency</h2><ul><li>Data is replicated optimistically</li><li>Dynamo provides eventual consistency</li></ul><h3 id="2-2-1-Optimistic-Replication"><a href="#2-2-1-Optimistic-Replication" class="headerlink" title="2.2.1 Optimistic Replication"></a>2.2.1 Optimistic Replication</h3><ul><li><p>To ensure high availability and durability, Dynamo replicates each data item on multiple N nodes in the system where the value N is equivalent to the <strong>replication factor</strong>, also is configured per instance of Dynamo</p></li><li><p>Each key is assigned to a coordinator node, which first stores the data locally and then replicates it to N-1 clockwise successor nodes on the ring</p><ul><li>Thus each node owns the region on the ring between it and its Nth predecessor</li></ul></li><li><p>Replication is done asynchronously and Dynamo provides an eventually consistent model</p></li><li><p>It‚Äôs called optimistic replication, as the replicas are not guaranteed to be identical at all times</p><p>  <img src="https://i.loli.net/2021/08/08/QaHhmPTI6XcYfwu.png" alt=""></p></li><li><p>Preference List</p><ul><li>List of nodes responsible for storing a particular key</li><li>Dynamo is designed so that every node in the system can determine which nodes should be in the list for any specific key</li><li>The list contains more than N nodes to account for failures and skip virtual nodes on the ring so that the list only contains distinct physical nodes</li></ul></li></ul><h2 id="2-3-Handling-Temporary-Failures"><a href="#2-3-Handling-Temporary-Failures" class="headerlink" title="2.3 Handling Temporary Failures"></a>2.3 Handling Temporary Failures</h2><ul><li>To handle temporary failures, dynamo replicates data to a <strong>sloppy quorum</strong> of other nodes in the system instead of a strict majority quorum</li></ul><h3 id="2-3-1-Quorum-Approach"><a href="#2-3-1-Quorum-Approach" class="headerlink" title="2.3.1 Quorum Approach"></a>2.3.1 Quorum Approach</h3><ul><li>Traditional quorum approach<ul><li>any distributed system becomes unavailable during server failures or network partitions and would have reduced availability even under simple failure conditions</li></ul></li><li>Sloppy quorum<ul><li>all read/ write operations are performed on the first N healthy nodes from the preference list. may not always be the first N nodes encountered while moving clockwise on the consistent hashing ring</li></ul></li></ul><h3 id="2-3-2-Hinted-Handoff"><a href="#2-3-2-Hinted-Handoff" class="headerlink" title="2.3.2 Hinted Handoff"></a>2.3.2 Hinted Handoff</h3><ul><li>When a node is unreachable, another node can accept writes on its behalf</li><li>Write is then kept in a local buffer and sent out once the destination node is reachable again</li><li>Problem<ul><li>Sloppy quorum is not a strict majority, the data can and will diverge</li><li>It is possible for two concurrent writes to the same key to be accepted by non-overlapping sets of nodes. This means that multiple conflicting values against the same key can exist in the system, and we can get stale or conflicting data while reading. Dynamo allows this and resolves these conflicts using Vector Clocks.</li></ul></li></ul><h2 id="2-4-Inter-node-communication-and-failure-detection"><a href="#2-4-Inter-node-communication-and-failure-detection" class="headerlink" title="2.4 Inter node communication and failure detection"></a>2.4 Inter node communication and failure detection</h2><ul><li>Use gossip protocol to keep track of the cluster state</li></ul><h3 id="2-4-1-Gossip-Protocol"><a href="#2-4-1-Gossip-Protocol" class="headerlink" title="2.4.1 Gossip Protocol"></a>2.4.1 Gossip Protocol</h3><ul><li><p>Enable each node to keep track of state information about the other nodes in the cluster</p><ul><li>which nodes are reachable</li><li>what key ranges they are responsible for</li></ul></li><li><p>Gossip Protocol</p><ul><li><p>Peer to peer communication mechanism</p></li><li><p>nodes periodically exchange state information about themselves and other nodes they know about</p></li><li><p>each node initiate a gossip round every second with a random node</p><p>  <img src="https://i.loli.net/2021/08/08/hgBPER5e2kuxvMw.png" alt=""></p></li></ul></li><li><p>External discovery through seed nodes</p><ul><li>An administrator joins node A to the ring and then joins node B to the ring. Nodes A and B consider themselves part of the ring, yet neither would be immediately aware of each other. To prevent these logical partitions, Dynamo introduced the concept of seed nodes. Seed nodes are fully functional nodes and can be obtained either from a static configuration or a configuration service. This way, all nodes are aware of seed nodes. Each node communicates with seed nodes through gossip protocol to reconcile membership changes; therefore, logical partitions are highly unlikely.</li></ul></li></ul><h2 id="2-5-Conflict-Resolution-and-Handling-permanent-failures"><a href="#2-5-Conflict-Resolution-and-Handling-permanent-failures" class="headerlink" title="2.5 Conflict Resolution and Handling permanent failures"></a>2.5 Conflict Resolution and Handling permanent failures</h2><h3 id="2-5-1-Clock-Skew"><a href="#2-5-1-Clock-Skew" class="headerlink" title="2.5.1 Clock Skew"></a>2.5.1 Clock Skew</h3><ul><li>Dynamo resolves potential conflicts using below mechanisms<ul><li>use vector clocks to keep track of value history and reconcile divergent histories at read time</li><li>in the background, dynamo use an <strong>anti entropy mechanism</strong> like <strong>Merkle trees</strong> to handle permanent failures</li></ul></li></ul><h3 id="2-5-2-Vector-Clock"><a href="#2-5-2-Vector-Clock" class="headerlink" title="2.5.2 Vector Clock"></a>2.5.2 Vector Clock</h3><ul><li><p>Used to capture causality between different versions of the same object</p></li><li><p>A vector clock is a <code>node, counter</code> pair</p></li><li><p>Each version of every object associate with a vector clock</p><ul><li>one can determine whether two versions of an object are on parallel branches or have a causal ordering by examining vector clocks</li><li>If the counters on the first object‚Äôs clock are less-than-or-equal to all of the nodes in the second clock, then the first is an ancestor of the second and can be forgotten. Otherwise, the two changes are considered to be in conflict and require reconciliation.</li></ul></li><li><p>  <img src="https://i.loli.net/2021/08/08/9fKB418IrMezTun.png" alt=""></p></li><li><p>Issue occur when there are network partition, that same data cannot be shared / communicated via different servers</p></li><li><p>In this case, DynamoDB will return it back and let client reads and reconciles</p></li></ul><h3 id="2-5-3-Conflict-free-replicated-data-types-CRDTs"><a href="#2-5-3-Conflict-free-replicated-data-types-CRDTs" class="headerlink" title="2.5.3 Conflict free replicated data types (CRDTs)"></a>2.5.3 Conflict free replicated data types (CRDTs)</h3><ul><li>we need to model our data in such a way that concurrent changes can be applied to the data in any order and will produce the same end result</li></ul><h2 id="2-6-put-and-get-Operations"><a href="#2-6-put-and-get-Operations" class="headerlink" title="2.6 put() and get() Operations"></a>2.6 put() and get() Operations</h2><h3 id="2-6-1-Strategies-for-choosing-the-coordinator-node"><a href="#2-6-1-Strategies-for-choosing-the-coordinator-node" class="headerlink" title="2.6.1 Strategies for choosing the coordinator node"></a>2.6.1 Strategies for choosing the coordinator node</h3><ul><li><p>Strategies</p><p>  <img src="https://i.loli.net/2021/08/08/MB8qFbQGdwhoZAJ.png" alt=""></p><ul><li>Clients can route their requests through a generic load balancer<ul><li>client is unaware of the dynamo ring<ul><li>helps scalability</li><li>make ddb architecture loosely coupled</li></ul></li><li>it‚Äôs possible node it select is not part of the perference list, this will result in an extra hop</li></ul></li><li>Clients can use a partition aware client library that routes the request to the appropriate coordinator nodes with lower latency<ul><li>helps to achieve lower latency  ‚Äî achieve zero hop</li><li>DDB doesn‚Äôt have much control over the load distribution and request handling</li></ul></li></ul></li></ul><h3 id="2-6-2-Consistency-Protocol"><a href="#2-6-2-Consistency-Protocol" class="headerlink" title="2.6.2 Consistency Protocol"></a>2.6.2 Consistency Protocol</h3><ul><li>R W is the min number of nodes that must participate in a successful read/ write operation</li><li>R + W &gt; N yields a quorun like system</li><li>A Common (N,R,WN, R, WN,R,W) configuration used by Dynamo is (3, 2, 2)</li><li>In general, low values of WWW and RRR increase the risk of inconsistency, as write requests are deemed successful and returned to the clients even if a majority of replicas have not processed them. This also introduces a vulnerability window for durability when a write request is successfully returned to the client even though it has been persisted at only a small number of nodes</li></ul><h3 id="2-6-3-put-process"><a href="#2-6-3-put-process" class="headerlink" title="2.6.3  put() process"></a>2.6.3  <code>put()</code> process</h3><ul><li>the coordinator generates a new data version and vector clock component</li><li>saves new data locally</li><li>sends the write request to N-1 highest ranked healthy nodes from the preference list</li><li>the put() operation is considered successful after receiving W - 1 confirmation</li></ul><h3 id="2-6-4-get-process"><a href="#2-6-4-get-process" class="headerlink" title="2.6.4 get() process"></a>2.6.4 <code>get()</code> process</h3><ul><li>coordinator requests the data version from N - 1 highest ranked healthy nodes from the preference list</li><li>waits until R - 1 replies</li><li>coordinator handles causal data versions through a vector clock</li><li>returns all relevant data versions to the caller</li></ul><h3 id="2-6-5-Request-handling-through-state-machine"><a href="#2-6-5-Request-handling-through-state-machine" class="headerlink" title="2.6.5 Request handling through state machine"></a>2.6.5 Request handling through state machine</h3><ul><li>Each client request results in creating a state machine on the node that received the client request</li><li>A read operation workflow would be:<ul><li>send read requests to the nodes</li><li>wait for the minimum number of required responses</li><li>if too few replies were received within a given time limit, fail the request</li><li>otherwise, gather all the data versions and determine the ones to be returned</li><li>if versioning is enabled, perform syntactic reconciliation and generate an opaque write context that contains the vector clock that subsumes all the remaining versions</li><li>At this point, read response has been returned to the caller</li><li>the state machine waits for a short period to receive any outstanding responces</li><li>if stale versions were returned in any of the responses, the coordinator updates those nodes with the latest version ‚Äî READ REPAIR</li></ul></li></ul><h2 id="2-7-Anti-entropy-Through-Merkle-Trees"><a href="#2-7-Anti-entropy-Through-Merkle-Trees" class="headerlink" title="2.7 Anti-entropy Through Merkle Trees"></a>2.7 Anti-entropy Through Merkle Trees</h2><ul><li>Vector clocks are useful to remove conflicts while serving read requests</li><li>But if a replica falls significantly behind others, it might take a very long time to resolve conflicts using just vector clocks</li></ul><hr><p>‚Äî&gt; we need to quickly compare two copies of a range of data residing on different replicas and figure out exactly which parts are different </p><h3 id="2-7-1-What-are-MerkleTrees"><a href="#2-7-1-What-are-MerkleTrees" class="headerlink" title="2.7.1 What are MerkleTrees?"></a>2.7.1 What are MerkleTrees?</h3><ul><li><p>Dynamo use Merkel Trees to compare replicas of a range</p></li><li><p>A merkle tree is a binary tree of hashes, where each internal node is the hash of its two children, each leaf node is a hash of a portion of the original data</p></li><li><p>Then compare the merkle tree come to be super easy, just compare the root hashes of both trees, if equal, then stop; else, recurse on the left and right children</p></li><li><p>The principal advantage of using a Merkle tree is that each branch of the tree can be checked independently without requiring nodes to download the entire tree or the whole data set. Hence, Merkle trees minimize the amount of data that needs to be transferred for synchronization and reduce the number of disk reads performed during the anti-entropy process.</p></li><li><p>The disadvantage of using Merkle trees is that many key ranges can change when a node joins or leaves, and as a result, the trees need to be recalculated.</p></li></ul><h2 id="2-8-Dynamo-Characteristics"><a href="#2-8-Dynamo-Characteristics" class="headerlink" title="2.8 Dynamo Characteristics"></a>2.8 Dynamo Characteristics</h2><h3 id="2-8-1-Dynamo‚Äôs-Node-Responsibilities"><a href="#2-8-1-Dynamo‚Äôs-Node-Responsibilities" class="headerlink" title="2.8.1 Dynamo‚Äôs Node Responsibilities"></a>2.8.1 Dynamo‚Äôs Node Responsibilities</h3><ul><li>Each node serves three functions:<ul><li>Managing <code>get()</code> and <code>put()</code> requests<ul><li>A node may act as a coordinator and manage all operations for a particular key</li><li>A node also could forward the request to the appropriate node</li></ul></li></ul></li><li>Keep track of membership and detecting failures<ul><li>Every node uses gossip protocol to keep track of other nodes in the system and their associated hash ranges</li></ul></li><li>Local persistent storage<ul><li>Each node is responsible for being either the primary or replica store for keys that hash to a specific range of values</li><li>These pairs are stored within that node using various storage systems depending on application needs</li><li>E.G<ul><li>BerkeleyDB Transactional Data Store</li><li>MySQL</li><li>In memory buffer backed by persistent storage</li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. Overview&quot;&gt;&lt;/a&gt;1. Overview&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Designed to be always on&lt;/li&gt;

      
    
    </summary>
    
    
      <category term="SystemDesign" scheme="https://www.llchen60.com/categories/SystemDesign/"/>
    
    
      <category term="DynamoDB" scheme="https://www.llchen60.com/tags/DynamoDB/"/>
    
  </entry>
  
  <entry>
    <title>Êï∞ÊçÆÂ∫ìÁ¥¢Âºï</title>
    <link href="https://www.llchen60.com/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/"/>
    <id>https://www.llchen60.com/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/</id>
    <published>2021-07-11T04:56:10.000Z</published>
    <updated>2021-07-11T04:56:48.749Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Á¥¢ÂºïÁöÑÂÆûÁé∞ÔºåÂ∫ïÂ±Ç‰∏ÄËà¨‰ºö‰æùËµñ‰∫éÂì™‰∫õÊï∞ÊçÆÁªìÊûÑÔºü</p></blockquote><h1 id="1-‰∏∫‰ªÄ‰πàÈúÄË¶ÅÁ¥¢Âºï"><a href="#1-‰∏∫‰ªÄ‰πàÈúÄË¶ÅÁ¥¢Âºï" class="headerlink" title="1. ‰∏∫‰ªÄ‰πàÈúÄË¶ÅÁ¥¢Âºï"></a>1. ‰∏∫‰ªÄ‰πàÈúÄË¶ÅÁ¥¢Âºï</h1><ul><li>‰∏∫‰∫ÜËÉΩÂ§üÂ∞ΩÂø´ÂæóÂà∞ÊÉ≥Ë¶ÅÁöÑÊï∞ÊçÆ ‚Äî ÊèêÈ´òÊÄßËÉΩ</li><li>ÈÄâÂèñÈ´òÊïàÁöÑÊï∞ÊçÆÁªìÊûÑÔºåÂú®ÈíàÂØπËÆøÈóÆÁâπÊÄßÊúâÊØîËæÉÂ•ΩÁöÑËÆøÈóÆÈÄüÂ∫¶ÁöÑÂêåÊó∂ÔºåÂáèÂ∞ëÁ©∫Èó¥‰∏äÁöÑÂç†Áî®<ul><li>Â¶Ç‰ΩïËäÇÁúÅÂ≠òÂÇ®Á©∫Èó¥</li><li>Â¶Ç‰ΩïÊèêÈ´òÊï∞ÊçÆÂ¢ûÂà†ÊîπÊü•ÁöÑÊâßË°åÊïàÁéá</li></ul></li></ul><h1 id="2-ÂäüËÉΩÊÄßÈúÄÊ±Ç"><a href="#2-ÂäüËÉΩÊÄßÈúÄÊ±Ç" class="headerlink" title="2. ÂäüËÉΩÊÄßÈúÄÊ±Ç"></a>2. ÂäüËÉΩÊÄßÈúÄÊ±Ç</h1><ul><li>Ê†ºÂºèÂåñÊï∞ÊçÆËøòÊòØÈùûÊ†ºÂºèÂåñÊï∞ÊçÆÔºü<ul><li>ÁªìÊûÑÂåñÊï∞ÊçÆ<ul><li>ÊØîÂ¶ÇMySQLÊï∞ÊçÆ</li></ul></li><li>ÈùûÁªìÊûÑÂåñÊï∞ÊçÆ<ul><li>ÊØîÂ¶ÇÊêúÁ¥¢ÂºïÊìéÂΩì‰∏≠ÁöÑÁΩëÈ°µ</li><li>‰∏ÄËà¨ÈúÄË¶ÅËøõË°åÈ¢ÑÂ§ÑÁêÜÔºåÊèêÂèñÂá∫Êü•ËØ¢ÂÖ≥ÈîÆËØçÔºåÂØπÂÖ≥ÈîÆËØçÂª∫Á´ãÁ¥¢Âºï</li></ul></li></ul></li><li>ÈùôÊÄÅÊï∞ÊçÆËøòÊòØÂä®ÊÄÅÊï∞ÊçÆÔºü<ul><li>ÈùôÊÄÅÊï∞ÊçÆ<ul><li>ÊÑèÂë≥ÁùÄÊ≤°ÊúâÂ¢ûÂà†ÊîπÊü•</li><li>Âè™ÈúÄË¶ÅËÄÉËôëÊü•ËØ¢ÊïàÁéáÂç≥ÂèØ</li></ul></li><li>Âä®ÊÄÅÊï∞ÊçÆ<ul><li>ÂΩìÂéüÂßãÊï∞ÊçÆÊõ¥Êñ∞ÁöÑÂêåÊó∂ÔºåÊàë‰ª¨ËøòÈúÄË¶ÅÂä®ÊÄÅÁöÑÊõ¥Êñ∞Á¥¢Âºï</li></ul></li></ul></li><li>Á¥¢ÂºïÂ≠òÂÇ®Âú®ÂÜÖÂ≠òËøòÊòØÁ°¨ÁõòÔºü<ul><li>Â≠òÂÇ®Âú®ÂÜÖÂ≠ò<ul><li>ËÆøÈóÆÈÄüÂ∫¶Âø´</li><li>ÂéüÂßãÊï∞ÊçÆÈáèÂ§ßÁöÑÂâçÊèê‰∏ãÔºåÂØπÂ∫îÁöÑÁ¥¢Âºï‰πü‰ºöÈùûÂ∏∏Â§ß</li><li>Âõ†‰∏∫ÂÜÖÂ≠òÊúâÈôêÔºåÊàë‰ª¨Â∞Ü‰∏çÂæó‰∏çÂ≠òÊîæÂà∞ÂÜÖÂ≠òÂΩì‰∏≠</li></ul></li><li>Â≠òÂÇ®Âú®Á°¨Áõò</li><li>ÈÉ®ÂàÜÂ≠òÂÇ®Âú®ÂÜÖÂ≠òÔºåÈÉ®ÂàÜÂú®Á°¨Áõò</li></ul></li><li>ÂçïÂÄºÊü•ÊâæËøòÊòØÂå∫Èó¥Êü•Êâæ<ul><li>ÂçïÂÄºÊü•Êâæ<ul><li>Êü•ËØ¢ÂÖ≥ÈîÆËØçÁ≠â‰∫éÊüê‰∏™ÂÄºÁöÑÊï∞ÊçÆ</li></ul></li><li>Âå∫Èó¥Êü•Êâæ<ul><li>Êü•ÊâæÂÖ≥ÈîÆËØçÂ§Ñ‰∫éÊüê‰∏™Âå∫Èó¥ÂÄºÁöÑÊï∞ÊçÆ</li></ul></li></ul></li><li>ÂçïÂÖ≥ÈîÆËØçËøòÊòØÂ§öÂÖ≥ÈîÆËØçÁªÑÂêàÁöÑÊü•Êâæ<ul><li>Â§öÂÖ≥ÈîÆËØçÊü•ËØ¢<ul><li>ÂØπ‰∫éÁªìÊûÑÂåñÊï∞ÊçÆÁöÑÔºå<ul><li>ÂÆûÁé∞ÈíàÂØπÂ§ö‰∏™ÂÖ≥ÈîÆËØçÁöÑÁªÑÂêàÂª∫Á´ãÁ¥¢Âºï</li></ul></li><li>ÂØπ‰∫éÈùûÁªìÊûÑÂåñÊï∞ÊçÆÁöÑ<ul><li>Âª∫Á´ãÈíàÂØπÂçï‰∏™ÂÖ≥ÈîÆËØçÁöÑÁ¥¢Âºï</li><li>ÁÑ∂ÂêéÈÄöËøáÈõÜÂêàÊìç‰ΩúÔºåËÆ°ÁÆóÂá∫Êü•ËØ¢ÁªìÊûú</li></ul></li></ul></li></ul></li></ul><h1 id="3-ÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç"><a href="#3-ÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç" class="headerlink" title="3. ÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç"></a>3. ÈùûÂäüËÉΩÊÄßÈúÄÊ±Ç</h1><ul><li>Êó†ËÆ∫Â≠òÊîæÂú®ÂÜÖÂ≠òËøòÊòØÁ£ÅÁõòÂΩì‰∏≠ÔºåÂØπ‰∫éÂ≠òÂÇ®Á©∫Èó¥ÁöÑÊ∂àËÄó‰∏çËÉΩËøáÂ§ß</li><li>Âú®ËÄÉËôëÁ¥¢ÂºïÊü•ËØ¢ÊïàÁéáÁöÑÂêåÊó∂ÔºåËøòË¶ÅËÄÉËôëÁ¥¢ÂºïÁöÑÁª¥Êä§ÊàêÊú¨</li></ul><h1 id="4-ÊûÑÂª∫Á¥¢ÂºïÂ∏∏Áî®ÁöÑÊï∞ÊçÆÁªìÊûÑ"><a href="#4-ÊûÑÂª∫Á¥¢ÂºïÂ∏∏Áî®ÁöÑÊï∞ÊçÆÁªìÊûÑ" class="headerlink" title="4. ÊûÑÂª∫Á¥¢ÂºïÂ∏∏Áî®ÁöÑÊï∞ÊçÆÁªìÊûÑ"></a>4. ÊûÑÂª∫Á¥¢ÂºïÂ∏∏Áî®ÁöÑÊï∞ÊçÆÁªìÊûÑ</h1><ul><li>Êï£ÂàóË°®<ul><li>ÊûÑÂª∫ÂÜÖÂ≠òÁ¥¢Âºï</li><li>Â¶ÇRedis Memcache</li></ul></li><li>Á∫¢ÈªëÊ†ë<ul><li>ÊûÑÂª∫ÂÜÖÂ≠òÁ¥¢Âºï</li><li>ExtÊñá‰ª∂Á≥ªÁªü‰∏≠ÂØπÁ£ÅÁõòÂùóÁöÑÁ¥¢Âºï</li></ul></li><li>B+Ê†ë<ul><li>ÊØîËµ∑Á∫¢ÈªëÊ†ëÔºåÊõ¥ÈÄÇÂêàÂú®Á£ÅÁõòÂΩì‰∏≠ÊûÑÂª∫Á¥¢Âºï</li><li>Â§öÂèâÊ†ëÔºåÊØîËµ∑Á∫¢ÈªëÊ†ëÔºåÈ´òÂ∫¶Êõ¥‰ΩéÔºåIOÊõ¥Â∞ë</li><li>Â§ßÈÉ®ÂàÜÂÖ≥Á≥ªÂûãÊï∞ÊçÆÂ∫ìÁöÑÁ¥¢ÂºïÔºå‰ºö‰ΩøÁî®B+Ê†ëÊù•ÂÆûÁé∞<ul><li>MySQL</li><li>Oracle</li></ul></li></ul></li><li>Ë∑≥Ë°®<ul><li>Redis‰∏≠ÁöÑÊúâÂ∫èÈõÜÂêà</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Á¥¢ÂºïÁöÑÂÆûÁé∞ÔºåÂ∫ïÂ±Ç‰∏ÄËà¨‰ºö‰æùËµñ‰∫éÂì™‰∫õÊï∞ÊçÆÁªìÊûÑÔºü&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;1-‰∏∫‰ªÄ‰πàÈúÄË¶ÅÁ¥¢Âºï&quot;&gt;&lt;a href=&quot;#1-‰∏∫‰ªÄ‰πàÈúÄË¶ÅÁ¥¢Âºï&quot; class=&quot;headerlink&quot; title=&quot;1. ‰∏∫‰ªÄ‰πàÈúÄË¶ÅÁ¥¢Âºï&quot;&gt;&lt;/a&gt;1.
      
    
    </summary>
    
    
      <category term="Êï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ï" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>B+Ê†ë</title>
    <link href="https://www.llchen60.com/B-%E6%A0%91/"/>
    <id>https://www.llchen60.com/B-%E6%A0%91/</id>
    <published>2021-07-11T04:25:25.000Z</published>
    <updated>2021-07-11T04:27:41.539Z</updated>
    
    <content type="html"><![CDATA[<h1 id="B-Ê†ë"><a href="#B-Ê†ë" class="headerlink" title="B+Ê†ë"></a>B+Ê†ë</h1><h1 id="1-‰ªÄ‰πàÊó∂ÂÄô‰ºöÁî®Âà∞Ôºü"><a href="#1-‰ªÄ‰πàÊó∂ÂÄô‰ºöÁî®Âà∞Ôºü" class="headerlink" title="1. ‰ªÄ‰πàÊó∂ÂÄô‰ºöÁî®Âà∞Ôºü"></a>1. ‰ªÄ‰πàÊó∂ÂÄô‰ºöÁî®Âà∞Ôºü</h1><h2 id="1-1-Êï∞ÊçÆÂ∫ìÁ¥¢Âºï"><a href="#1-1-Êï∞ÊçÆÂ∫ìÁ¥¢Âºï" class="headerlink" title="1.1 Êï∞ÊçÆÂ∫ìÁ¥¢Âºï"></a>1.1 Êï∞ÊçÆÂ∫ìÁ¥¢Âºï</h2><p>Â∑•‰Ωú‰∏≠‰∏∫‰∫ÜÂä†Âø´Êï∞ÊçÆÂ∫ì‰∏≠Êï∞ÊçÆÁöÑÊü•ÊâæÈÄüÂ∫¶ÔºåÊàë‰ª¨Â∏∏Áî®ÁöÑÂ§ÑÁêÜÊÄùË∑ØÊòØÂØπË°®‰∏≠Êï∞ÊçÆÂàõÂª∫Á¥¢ÂºïÔºåËÄåÊï∞ÊçÆÂ∫ìÁöÑÁ¥¢ÂºïÂ∫ïÂ±ÇÂ∞±‰ΩøÁî®‰∫ÜB+Ê†ëÁöÑÁªìÊûÑ</p><p>ÂØπ‰∫éÊï∞ÊçÆÂ∫ìÔºåÊàë‰ª¨Â∏åÊúõÈÄöËøáÁ¥¢ÂºïÂÆûÁé∞Êü•ËØ¢Êï∞ÊçÆÁöÑÊïàÁéáÁöÑÊèêÂçáÔºõÂêåÊó∂‰∏çË¶ÅÊ∂àËÄóÂ§™Â§öÁöÑÂÜÖÂ≠òÁ©∫Èó¥„ÄÇËÄåÊï∞ÊçÆÂ∫ìÁ¥¢ÂºïÊü•ÊâæÁöÑËøáÁ®ãÂΩì‰∏≠ÔºåÂÖ∂ÁâπÁÇπÊòØÔºö</p><ul><li>ÈúÄË¶ÅËøõË°åÁõ¥Êé•Êü•Êâæ</li><li>ÈúÄË¶ÅÊîØÊåÅÊåâÁÖß‰∏ÄÂÆöÂå∫Èó¥ÁöÑÂø´ÈÄüÊü•Êâæ</li></ul><h2 id="1-2-Overview"><a href="#1-2-Overview" class="headerlink" title="1.2 Overview"></a>1.2 Overview</h2><ul><li>B + Ê†ëÁâπÂæÅ<ul><li>ÊØè‰∏™ËäÇÁÇπ‰∏≠Â≠êËäÇÁÇπÁöÑ‰∏™Êï∞‰∏çËÉΩË∂ÖËøá mÔºå‰πü‰∏çËÉΩÂ∞è‰∫é m/2Ôºõ</li><li>Ê†πËäÇÁÇπÁöÑÂ≠êËäÇÁÇπ‰∏™Êï∞ÂèØ‰ª•‰∏çË∂ÖËøá m/2ÔºåËøôÊòØ‰∏Ä‰∏™‰æãÂ§ñÔºõ</li><li>m ÂèâÊ†ëÂè™Â≠òÂÇ®Á¥¢ÂºïÔºåÂπ∂‰∏çÁúüÊ≠£Â≠òÂÇ®Êï∞ÊçÆÔºåËøô‰∏™ÊúâÁÇπÂÑøÁ±ª‰ººË∑≥Ë°®Ôºõ</li><li>ÈÄöËøáÈìæË°®Â∞ÜÂè∂Â≠êËäÇÁÇπ‰∏≤ËÅîÂú®‰∏ÄËµ∑ÔºåËøôÊ†∑ÂèØ‰ª•Êñπ‰æøÊåâÂå∫Èó¥Êü•ÊâæÔºõ</li><li>‰∏ÄËà¨ÊÉÖÂÜµ‰∏ãÔºåÊ†πËäÇÁÇπ‰ºöË¢´Â≠òÂÇ®Âú®ÂÜÖÂ≠ò‰∏≠ÔºåÂÖ∂‰ªñËäÇÁÇπÂ≠òÂÇ®Âú®Á£ÅÁõò‰∏≠</li></ul></li><li>BÊ†ë<ul><li>ËäÇÁÇπ‰∏≠Â≠òÂÇ®Êï∞ÊçÆ</li><li>Âè∂Â≠êËäÇÁÇπÂπ∂Ê≤°Êúâ‰ΩøÁî®ÈìæË°®Êù•‰∏≤ËÅî</li><li>ÊòØ‰∏Ä‰∏™ÊØè‰∏™ËäÇÁÇπÁöÑÂ≠êËäÇÁÇπ‰∏™Êï∞‰∏çÂ∞ë‰∫ém/2ÁöÑmÂèâÊ†ë</li></ul></li></ul><h1 id="2-‰∏∫‰ªÄ‰πàÂú®Êï∞ÊçÆÂ∫ìÁ¥¢ÂºïÁöÑÊó∂ÂÄô‰ºö‰ΩøÁî®Âà∞B-Ê†ëÂë¢Ôºü"><a href="#2-‰∏∫‰ªÄ‰πàÂú®Êï∞ÊçÆÂ∫ìÁ¥¢ÂºïÁöÑÊó∂ÂÄô‰ºö‰ΩøÁî®Âà∞B-Ê†ëÂë¢Ôºü" class="headerlink" title="2. ‰∏∫‰ªÄ‰πàÂú®Êï∞ÊçÆÂ∫ìÁ¥¢ÂºïÁöÑÊó∂ÂÄô‰ºö‰ΩøÁî®Âà∞B+Ê†ëÂë¢Ôºü"></a>2. ‰∏∫‰ªÄ‰πàÂú®Êï∞ÊçÆÂ∫ìÁ¥¢ÂºïÁöÑÊó∂ÂÄô‰ºö‰ΩøÁî®Âà∞B+Ê†ëÂë¢Ôºü</h1><h2 id="2-1-‰ΩøÁî®‰∫åÂèâÊü•ÊâæÊ†ëÊù•ÂÆûÁé∞Á¥¢ÂºïÔºü"><a href="#2-1-‰ΩøÁî®‰∫åÂèâÊü•ÊâæÊ†ëÊù•ÂÆûÁé∞Á¥¢ÂºïÔºü" class="headerlink" title="2.1 ‰ΩøÁî®‰∫åÂèâÊü•ÊâæÊ†ëÊù•ÂÆûÁé∞Á¥¢ÂºïÔºü"></a>2.1 ‰ΩøÁî®‰∫åÂèâÊü•ÊâæÊ†ëÊù•ÂÆûÁé∞Á¥¢ÂºïÔºü</h2><ul><li>‰ªé‰∫åÂèâÊü•ÊâæÊ†ëÂºÄÂßãËØ¥Ëµ∑ Êàë‰ª¨ÂèØ‰ª•Êîπ‰∏Ä‰∏ã<ul><li>Ê†ë‰∏≠ÁöÑËäÇÁÇπ‰∏çÂ≠òÂÇ®Êï∞ÊçÆÊú¨Ë∫´ÔºåÂè™‰Ωú‰∏∫Á¥¢Âºï</li><li>ÊØè‰∏™Âè∂Â≠êËäÇÁÇπ‰∏≤Âú®‰∏ÄÊù°ÈìæË°®‰∏ä</li><li>ÈìæË°®ÂΩì‰∏≠ÁöÑÊï∞ÊçÆ‰ªéÂ∞èÂà∞Â§ßÊúâÂ∫è</li></ul></li><li>ÂØπ‰∫éÂå∫Èó¥Êü•ÊâæÁöÑÊîØÊåÅÁ®ãÂ∫¶<ul><li>ÂÖàÂú®Ê†ë‰∏≠ÈÅçÂéÜÔºåÁÑ∂ÂêéÂà∞Âè∂Â≠êËäÇÁÇπ‰ª•ÂêéÂÜçÈ°∫ÁùÄÈìæË°®Êù•ÂæÄÂêéÈÅçÂéÜ</li><li>Áõ¥Âà∞ÈìæË°®ÂΩì‰∏≠ÁöÑÁªìÁÇπÊï∞ÊçÆÂÄºÂ§ß‰∫éÂå∫Èó¥ÁöÑÁªàÊ≠¢ÂÄº‰∏∫Ê≠¢</li></ul></li><li>ÈóÆÈ¢ò<ul><li>Âç†Áî®ÁöÑÂÜÖÂ≠òÁ©∫Èó¥ÈùûÂ∏∏Â§ß<ul><li>Ëß£ÂÜ≥ÊñπÊ°à<ul><li>ÊîæÂà∞Á°¨Áõò‰∏äÔºå‰ΩÜÊòØËÆøÈóÆÈÄüÂ∫¶‰ºöÂèòÊÖ¢ÂæàÂ§ö‰∫Ü</li><li>ÂÜÖÂ≠òËÆøÈóÆÈÄüÂ∫¶Âú®Á∫≥ÁßíÁ∫ßÂà´</li><li>Á°¨ÁõòËÆøÈóÆÈÄüÂ∫¶Âú®ÊØ´ÁßíÁ∫ßÂà´</li></ul></li><li>Ëß£ÂÜ≥ÊñπÊ°àÁöÑÈóÆÈ¢òÂú®‰∫é<ul><li>Á£ÅÁõòIOÊìç‰ΩúÁöÑÊ¨°Êï∞Á≠â‰∫éÊ†ëÁöÑÈ´òÂ∫¶</li><li>Êàë‰ª¨ÈúÄË¶ÅÂ∞ΩÂèØËÉΩÁöÑÂáèÂ∞ëÊ†ëÁöÑÈ´òÂ∫¶Êù•ÂáèÂ∞ëÁ£ÅÁõòIOÁöÑÊ¨°Êï∞</li></ul></li></ul></li></ul></li></ul><h2 id="2-2-‰ΩøÁî®mÂèâÊ†ëÊù•ÂÆûÁé∞"><a href="#2-2-‰ΩøÁî®mÂèâÊ†ëÊù•ÂÆûÁé∞" class="headerlink" title="2.2 ‰ΩøÁî®mÂèâÊ†ëÊù•ÂÆûÁé∞"></a>2.2 ‰ΩøÁî®mÂèâÊ†ëÊù•ÂÆûÁé∞</h2><ul><li>‰ΩøÁî®mÂèâÊ†ëÁöÑÂ•ΩÂ§Ñ<ul><li>ÂáèÂ∞ë‰∫ÜËÆøÈóÆÁ£ÅÁõòÁöÑIOÊ¨°Êï∞</li></ul></li></ul><pre><code class="jsx">/** * ËøôÊòØB+Ê†ëÈùûÂè∂Â≠êËäÇÁÇπÁöÑÂÆö‰πâ„ÄÇ * * ÂÅáËÆækeywords=[3, 5, 8, 10] * 4‰∏™ÈîÆÂÄºÂ∞ÜÊï∞ÊçÆÂàÜ‰∏∫5‰∏™Âå∫Èó¥Ôºö(-INF,3), [3,5), [5,8), [8,10), [10,INF) * 5‰∏™Âå∫Èó¥ÂàÜÂà´ÂØπÂ∫îÔºöchildren[0]...children[4] * * mÂÄºÊòØ‰∫ãÂÖàËÆ°ÁÆóÂæóÂà∞ÁöÑÔºåËÆ°ÁÆóÁöÑ‰æùÊçÆÊòØËÆ©ÊâÄÊúâ‰ø°ÊÅØÁöÑÂ§ßÂ∞èÊ≠£Â•ΩÁ≠â‰∫éÈ°µÁöÑÂ§ßÂ∞èÔºö * PAGE_SIZE = (m-1)*4[keywordssÂ§ßÂ∞è]+m*8[childrenÂ§ßÂ∞è] */public class BPlusTreeNode &#123;  public static int m = 5; // 5ÂèâÊ†ë  public int[] keywords = new int[m-1]; // ÈîÆÂÄºÔºåÁî®Êù•ÂàíÂàÜÊï∞ÊçÆÂå∫Èó¥  public BPlusTreeNode[] children = new BPlusTreeNode[m];//‰øùÂ≠òÂ≠êËäÇÁÇπÊåáÈíà&#125;/** * ËøôÊòØB+Ê†ë‰∏≠Âè∂Â≠êËäÇÁÇπÁöÑÂÆö‰πâ„ÄÇ * * B+Ê†ë‰∏≠ÁöÑÂè∂Â≠êËäÇÁÇπË∑üÂÜÖÈÉ®ËäÇÁÇπÊòØ‰∏ç‰∏ÄÊ†∑ÁöÑ, * Âè∂Â≠êËäÇÁÇπÂ≠òÂÇ®ÁöÑÊòØÂÄºÔºåËÄåÈùûÂå∫Èó¥„ÄÇ * Ëøô‰∏™ÂÆö‰πâÈáåÔºåÊØè‰∏™Âè∂Â≠êËäÇÁÇπÂ≠òÂÇ®3‰∏™Êï∞ÊçÆË°åÁöÑÈîÆÂÄºÂèäÂú∞ÂùÄ‰ø°ÊÅØ„ÄÇ * * kÂÄºÊòØ‰∫ãÂÖàËÆ°ÁÆóÂæóÂà∞ÁöÑÔºåËÆ°ÁÆóÁöÑ‰æùÊçÆÊòØËÆ©ÊâÄÊúâ‰ø°ÊÅØÁöÑÂ§ßÂ∞èÊ≠£Â•ΩÁ≠â‰∫éÈ°µÁöÑÂ§ßÂ∞èÔºö * PAGE_SIZE = k*4[keyw..Â§ßÂ∞è]+k*8[dataAd..Â§ßÂ∞è]+8[prevÂ§ßÂ∞è]+8[nextÂ§ßÂ∞è] */public class BPlusTreeLeafNode &#123;  public static int k = 3;  public int[] keywords = new int[k]; // Êï∞ÊçÆÁöÑÈîÆÂÄº  public long[] dataAddress = new long[k]; // Êï∞ÊçÆÂú∞ÂùÄ  public BPlusTreeLeafNode prev; // Ëøô‰∏™ÁªìÁÇπÂú®ÈìæË°®‰∏≠ÁöÑÂâçÈ©±ÁªìÁÇπ  public BPlusTreeLeafNode next; // Ëøô‰∏™ÁªìÁÇπÂú®ÈìæË°®‰∏≠ÁöÑÂêéÁªßÁªìÁÇπ&#125;</code></pre><ul><li>mÂÄºÁöÑËÆæÂÆö<ul><li>Êìç‰ΩúÁ≥ªÁªüÊòØÊåâÈ°µÊù•ËØªÂèñÊï∞ÊçÆÁöÑÔºå‰∏ÄÈ°µÈÄöÂ∏∏Â§ßÂ∞è‰∏∫4KB</li><li>‰∏ÄÊ¨°‰ºöËØªÂèñ‰∏ÄÈ°µÁöÑÊï∞ÊçÆ</li><li>Â¶ÇÊûúË¶ÅËØªÂèñÁöÑÊï∞ÊçÆÈáèË∂ÖËøá‰∏ÄÈ°µÁöÑÂ§ßÂ∞èÔºåÂ∞±‰ºöËß¶ÂèëÂ§öÊ¨°IOÊìç‰Ωú‰∫Ü</li><li>Âõ†Ê≠§Êàë‰ª¨ÈÄâÂÆömÂ§ßÂ∞èÁöÑÊó∂ÂÄôÂ∞ΩÈáèËÆ©ÊØè‰∏™ËäÇÁÇπÁöÑÂ§ßÂ∞èÁ≠â‰∫é‰∏Ä‰∏™È°µÁöÑÂ§ßÂ∞è</li><li>ËøôÊ†∑ÁöÑËØùËØªÂèñ‰∏Ä‰∏™ËäÇÁÇπÂè™ÈúÄË¶Å‰∏ÄÊ¨°Á£ÅÁõòIOÊìç‰ΩúÂç≥ÂèØ</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/11/148A67p9Y3dre2g.png" alt="B+Ê†ëÊï∞ÊçÆÂ≠òÂÇ®"></p><h2 id="2-3-Á¥¢ÂºïÁöÑÈóÆÈ¢ò-ÂØºËá¥ÂÜôÂÖ•ÊïàÁéá‰∏ãÈôç"><a href="#2-3-Á¥¢ÂºïÁöÑÈóÆÈ¢ò-ÂØºËá¥ÂÜôÂÖ•ÊïàÁéá‰∏ãÈôç" class="headerlink" title="2.3 Á¥¢ÂºïÁöÑÈóÆÈ¢ò - ÂØºËá¥ÂÜôÂÖ•ÊïàÁéá‰∏ãÈôç"></a>2.3 Á¥¢ÂºïÁöÑÈóÆÈ¢ò - ÂØºËá¥ÂÜôÂÖ•ÊïàÁéá‰∏ãÈôç</h2><ul><li>Êï∞ÊçÆÂÜôÂÖ•ËøáÁ®ãÔºå‰ºöÊ∂âÂèäÂà∞Á¥¢ÂºïÁöÑÊõ¥Êñ∞ÔºåËøôÊòØÂØºËá¥Á¥¢ÂºïÂÜôÂÖ•ÂèòÊÖ¢ÁöÑ‰∏ªË¶ÅÂéüÂõ†</li><li>Âú∫ÊôØÊèèËø∞<ul><li>mÂÄºÊòØÊèêÂâçËÆ°ÁÆóÂ•ΩÁöÑ</li><li>ÂêëÊï∞ÊçÆÂ∫ìÂÜôÂÖ•ËøáÁ®ãÂΩì‰∏≠ÔºåÊúâÂèØËÉΩ‰ºö‰ΩøÂæóÁ¥¢ÂºïÂΩì‰∏≠Êüê‰∫õËäÇÁÇπÁöÑÂ≠êËäÇÁÇπÁöÑ‰∏™Êï∞Ë∂ÖËøám</li><li>Ëøô‰∏™ËäÇÁÇπÁöÑÂ§ßÂ∞èË∂ÖËøá‰∏Ä‰∏™È°µÁöÑÂ§ßÂ∞èÔºåÈÇ£‰πàËØªÂèñËøôÊ†∑‰∏Ä‰∏™ËäÇÁÇπÁöÑÊó∂ÂÄôÔºåÂ∞±‰ºöÂØºËá¥Â§öÊ¨°Á£ÅÁõòIOÊìç‰ΩúÔºåËøôÊòØÊàë‰ª¨ÊûÅÂäõÈÅøÂÖçÁöÑ</li></ul></li><li>Ëß£ÂÜ≥ÊñπÊ°à<ul><li>Â∞ÜËøô‰∏™ËäÇÁÇπÂàÜË£ÇÊàê‰∏§‰∏™ËäÇÁÇπ</li><li>Ëøô‰∏™ÈóÆÈ¢ò‰ºöÂêë‰∏ä‰º†ÂØºÔºåÂç≥‰∏äÂ±ÇÁà∂ËäÇÁÇπÁöÑÂ≠êËäÇÁÇπ‰∏™Êï∞ÊúâÂèØËÉΩË∂ÖËøám‰∏™‰∫Ü</li><li>Âõ†Ê≠§Êàë‰ª¨Â∞±ÈúÄË¶ÅÂêë‰∏äÈÄíÂΩíÊù•ÈáçÊûÑËøôÊ£µB+Ê†ë‰∫Ü</li><li>Ê≠£ÊòØÂõ†‰∏∫Êàë‰ª¨ÈúÄË¶Å‰øùËØÅB+Ê†ëÁ¥¢ÂºïÊòØ‰∏Ä‰∏™mÂèâÊ†ëÔºåÊâÄ‰ª•Á¥¢ÂºïÁöÑÂ≠òÂú®‰ºöÂØºËá¥Êï∞ÊçÆÂ∫ìÂÜôÂÖ•ÈÄüÂ∫¶Èôç‰Ωé</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/11/9qAHTSmnlUeVPjb.png" alt="B+Ê†ëÁ¥¢Âºï‰øÆÊîπ"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;B-Ê†ë&quot;&gt;&lt;a href=&quot;#B-Ê†ë&quot; class=&quot;headerlink&quot; title=&quot;B+Ê†ë&quot;&gt;&lt;/a&gt;B+Ê†ë&lt;/h1&gt;&lt;h1 id=&quot;1-‰ªÄ‰πàÊó∂ÂÄô‰ºöÁî®Âà∞Ôºü&quot;&gt;&lt;a href=&quot;#1-‰ªÄ‰πàÊó∂ÂÄô‰ºöÁî®Âà∞Ôºü&quot; class=&quot;headerlink&quot; title=&quot;1
      
    
    </summary>
    
    
      <category term="Êï∞ÊçÆÁªìÊûÑ‰∏éÁÆóÊ≥ï" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
</feed>
