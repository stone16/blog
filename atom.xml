<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Leilei&#39;s Blog | 磊磊的博客</title>
  
  <subtitle>Because it&#39;s there</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.llchen60.com/"/>
  <updated>2021-07-05T19:22:25.605Z</updated>
  <id>https://www.llchen60.com/</id>
  
  <author>
    <name>Leilei Chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis哨兵机制</title>
    <link href="https://www.llchen60.com/Redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6/"/>
    <id>https://www.llchen60.com/Redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6/</id>
    <published>2021-07-06T03:07:59.000Z</published>
    <updated>2021-07-05T19:22:25.605Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis多机数据库-哨兵机制"><a href="#Redis多机数据库-哨兵机制" class="headerlink" title="Redis多机数据库-哨兵机制"></a>Redis多机数据库-哨兵机制</h1><p>主从库的集群模式使得当从库发生故障以后，客户端可以继续向主库或者其他从库发送请求，进行相关的操作；但是如果主库发生了故障，那会直接影响到从库的同步。无论是写中断还是从库无法进行数据同步都是Redis所不能接受的。因此我们需要一些机制，来能够<strong>将一个从库切换为主库</strong>，这就涉及到了Redis的哨兵机制。</p><h1 id="1-哨兵机制的基本流程"><a href="#1-哨兵机制的基本流程" class="headerlink" title="1. 哨兵机制的基本流程"></a>1. 哨兵机制的基本流程</h1><ul><li>哨兵可以理解为一个运行在特殊模式下的<strong>Redis进程</strong>，其在主从库实例运行的同时也在运行</li><li>哨兵主要的三个任务为：<ul><li>监控 — 决策：判断主库是否处于下线状态<ul><li>周期性的ping主库，检测其是否仍然在线运行</li><li>如果从库没有在规定时间内响应哨兵的Ping命令，哨兵就会将其标记为下线状态</li><li>对主库来说同理，在判定主库下线以后会开始一个自动切换主库的流程</li></ul></li><li>选主 — 决策：决定选择哪个从库实例作为主库<ul><li>主库挂了以后，哨兵就需要从很多从库里按照一定的规则选择一个从库实例，将其作为新的主库</li></ul></li><li>通知<ul><li>将新主库的连接信息发给其他从库，让它们执行replicaof命令，与新主库建立连接，并进行数据复制</li><li>哨兵会将新主库的连接信息通知给客户端，让它们将请求操作发到新主库当中</li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2021/01/07/z7o6Kkdfp2IaPsx.png" alt="哨兵机制任务"></p><p>哨兵三大任务</p><h1 id="2-判断主库的下线状态"><a href="#2-判断主库的下线状态" class="headerlink" title="2. 判断主库的下线状态"></a>2. 判断主库的下线状态</h1><h2 id="2-1-哨兵集群使用原因"><a href="#2-1-哨兵集群使用原因" class="headerlink" title="2.1 哨兵集群使用原因"></a>2.1 哨兵集群使用原因</h2><h3 id="2-1-1-为什么需要哨兵集群？"><a href="#2-1-1-为什么需要哨兵集群？" class="headerlink" title="2.1.1 为什么需要哨兵集群？"></a>2.1.1 为什么需要哨兵集群？</h3><ul><li>如果哨兵发生误判，后续的选主和通知操作都会带来额外的计算和通信的开销</li><li>误判通常发生在<ul><li>集群网络压力较大</li><li>网络拥塞</li><li>主库本身压力较大的情况</li></ul></li><li>哨兵机制也是类似的，它通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</li></ul><h3 id="2-1-2-如何使用哨兵集群？"><a href="#2-1-2-如何使用哨兵集群？" class="headerlink" title="2.1.2 如何使用哨兵集群？"></a>2.1.2 如何使用哨兵集群？</h3><ul><li>简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由 Redis 管理员自行设定）。</li></ul><h2 id="2-2-哨兵集群原理-—-基于PubSub机制"><a href="#2-2-哨兵集群原理-—-基于PubSub机制" class="headerlink" title="2.2 哨兵集群原理 — 基于PubSub机制"></a>2.2 哨兵集群原理 — 基于PubSub机制</h2><h3 id="2-2-1-pubsub机制"><a href="#2-2-1-pubsub机制" class="headerlink" title="2.2.1 pubsub机制"></a>2.2.1 pubsub机制</h3><p>哨兵实例之间的相互发现是基于Redis提供的pubsub机制的，<strong>哨兵只要和主库建立起连接</strong>，就可以在主库上发布消息了</p><ul><li>可以选择发布自己的连接信息到主库上</li><li>也可以从主库上订阅消息，获得其他哨兵发布的连接信息</li><li>当多个哨兵实例都在主库上做了发布和订阅操作之后，他们之间就能知道彼此的IP地址和端口</li></ul><h3 id="2-2-2-频道"><a href="#2-2-2-频道" class="headerlink" title="2.2.2 频道"></a>2.2.2 频道</h3><ul><li>Redis通过频道来区分不同应用的消息，对这些消息进行分门别类的管理。频道就是指消息的类别，当消息类别相同时，就会属于同一个频道，否则属于不同的频道。</li><li>主库会构建一个叫做 <code>__sentinel__:hello</code> 的频道，来让各个哨兵互相发现</li><li>只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换</li></ul><p><img src="https://i.loli.net/2021/01/11/LIhj62iuDBbPEve.png" alt="pubsub机制"></p><p>频道订阅机制</p><ul><li>哨兵1 向频道hello发送信息，因为哨兵2 哨兵3 subscribe了hello频道，他们就能从这个频道获取到哨兵1的IP地址和端口号信息</li></ul><h3 id="2-2-3-哨兵和从库的连接沟通"><a href="#2-2-3-哨兵和从库的连接沟通" class="headerlink" title="2.2.3 哨兵和从库的连接沟通"></a>2.2.3 哨兵和从库的连接沟通</h3><ul><li><p>哨兵向主库发出INFO命令</p></li><li><p>主库收到命令后，就会将从库列表返回给哨兵</p></li><li><p>接着哨兵就可以根据从库列表中的信息，和每个从库建立连接，并在这个连接上持续对从库进行监控</p><p>  <img src="https://i.loli.net/2021/01/11/sPTRS1mkhU2lLQn.png" alt="哨兵与从库之间的连接"></p><p>  哨兵和从库的连接</p></li><li><p>哨兵除了上述的和主库之间的连接，获取从库列表，并和从库们建立连接之外，还承担着在发生主库更换以后，将新主库的信息告诉客户端这个任务</p></li></ul><h2 id="2-3-客户端事件通知机制"><a href="#2-3-客户端事件通知机制" class="headerlink" title="2.3 客户端事件通知机制"></a>2.3 客户端事件通知机制</h2><ul><li><p>哨兵是一个运行在特定模式下的Redis实例，只是它不服务请求操作，只是完成监控，选主和通知的任务</p></li><li><p>因此每个哨兵实例也提供pubsub机制，客户端可以从哨兵订阅消息</p><ul><li><p>哨兵提供了很多的消息订阅频道，不同频道包含了主从库切换过程中的不同关键事件</p><p>  <img src="https://i.loli.net/2021/07/06/lBP5xJYieohTZXw.png" alt="哨兵常用的消息订阅频道"></p></li><li><p>客户端可以执行订阅命令，来订阅不同的频道，然后来获取不同的事件信息</p><ul><li>当哨兵将新的主库选出来以后，客户端会看到switch-master事件，事件中会包含新的主库的IP地址还有端口信息</li><li>此时客户端就会使用新主库地址和端口来进行通信了</li></ul></li></ul></li></ul><h1 id="3-如何选定新主库？"><a href="#3-如何选定新主库？" class="headerlink" title="3. 如何选定新主库？"></a>3. 如何选定新主库？</h1><blockquote><p>哨兵筛选新主库的过程称为筛选+打分</p></blockquote><ul><li>筛选 — 按照一定条件筛选，将不符合条件的从库去掉<ul><li>确保从库仍然在线运行</li><li>判断其之前的网络状态 看该从库和主库之间是否经常断联，出现网络相关的问题<ul><li>通过使用down-after-milliseconds属性，这是我们认为的最大主从间的连接超时，如果超过这个时间我们就认为断联了，超过一定次数就认为从库网络状况不好</li></ul></li></ul></li><li>打分 — <strong>只要有得分最高的，那么就在当前轮停止并且认定其为主库</strong><ul><li>从库优先级 — 手动设置的<ul><li>用户可以通过slave-priority配置项，给不同的从库设置不同的优先级<ul><li>譬如：两个从库内存大小不一样，我们就可以手动给内存大的实例设置一个高优先级</li></ul></li></ul></li><li>从库复制进度<ul><li>选择和旧主库<strong>同步最为接近</strong>的那个从库作为主库</li><li>如何判断从库和旧主库的同步进度？<ul><li>主从库之间命令传播机制里面的master_repl_offset 和slave_repl_offset</li><li>看二者的接近程度</li></ul></li></ul></li><li>从库ID号<ul><li>当优先级和复制进度都相同的情况下，ID号最小的从库得分最高，被选为新主库</li></ul></li></ul></li></ul><h1 id="4-由哪个哨兵来执行主从切换？"><a href="#4-由哪个哨兵来执行主从切换？" class="headerlink" title="4. 由哪个哨兵来执行主从切换？"></a>4. 由哪个哨兵来执行主从切换？</h1><ul><li><h2 id="任何一个实例只要自身判断主库主观下线之后，就会给其他势力发送is-master-down-by-addr命令。接着其他实例会根据自己和主库的连接情况，做出Y或N的响应"><a href="#任何一个实例只要自身判断主库主观下线之后，就会给其他势力发送is-master-down-by-addr命令。接着其他实例会根据自己和主库的连接情况，做出Y或N的响应" class="headerlink" title="任何一个实例只要自身判断主库主观下线之后，就会给其他势力发送is-master-down-by-addr命令。接着其他实例会根据自己和主库的连接情况，做出Y或N的响应"></a>任何一个实例只要自身判断主库主观下线之后，就会给其他势力发送is-master-down-by-addr命令。接着其他实例会根据自己和主库的连接情况，做出Y或N的响应</h2><pre><code>  ![哨兵沟通，确定主库是否下线](https://i.loli.net/2021/01/11/HpT5MAdKX9fmo2S.png)  is master down by addr</code></pre><ul><li><p>一个哨兵获得了<strong>仲裁所需的赞成票数后，就可以标记主库为客观下线</strong></p><ul><li>这个所需的赞成票数是通过哨兵配置文件中的quorum配置项设定的</li></ul></li><li><p>当获得了所需赞成票数以后，这个哨兵会再给其他哨兵发送命令，希望由自己来执行主从切换，并让所有其他哨兵进行投票，这个过程称为<strong>Leader选举</strong>。</p></li><li><p>在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：</p><ul><li>第一，拿到半数以上的赞成票；</li><li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。</li></ul><p><img src="https://i.loli.net/2021/01/11/RAaq7KZr2LSUdVx.png" alt="哨兵投票，选举leader"></p><p>票选执行主从切换哨兵的过程</p></li></ul><ol><li>在 T1 时刻，S1 判断主库为“客观下线”，它想成为 Leader，就先给自己投一张赞成票，然后分别向 S2 和 S3 发送命令，表示要成为 Leader。</li><li>在 T2 时刻，S3 判断主库为“客观下线”，它也想成为 Leader，所以也先给自己投一张赞成票，再分别向 S1 和 S2 发送命令，表示要成为 Leader。</li><li>在 T3 时刻，S1 收到了 S3 的 Leader 投票请求。<strong>因为 S1 已经给自己投了一票 Y，所以它不能再给其他哨兵投赞成票了，所以 S1 回复 N 表示不同意</strong>。同时，S2 收到了 T2 时 S3 发送的 Leader 投票请求。因为 S2 之前没有投过票，它会给第一个向它发送投票请求的哨兵回复 Y，给后续再发送投票请求的哨兵回复 N，所以，在 T3 时，S2 回复 S3，同意 S3 成为 Leader。</li><li>在 T4 时刻，S2 才收到 T1 时 S1 发送的投票命令。因为 S2 已经在 T3 时同意了 S3 的投票请求，此时，S2 给 S1 回复 N，表示不同意 S1 成为 Leader。发生这种情况，是因为 S3 和 S2 之间的网络传输正常，而 S1 和 S2 之间的网络传输可能正好拥塞了，导致投票请求传输慢了。</li><li>在 T5 时刻，S1 得到的票数是来自它自己的一票 Y 和来自 S2 的一票 N。而 S3 除了自己的赞成票 Y 以外，还收到了来自 S2 的一票 Y。此时，S3 不仅获得了半数以上的 Leader 赞成票，也达到预设的 quorum 值（quorum 为 2），所以它最终成为了 Leader。接着，S3 会开始执行选主操作，而且在选定新主库后，会给其他从库和客户端通知新主库的信息。</li></ol><ul><li><p>如果 S3 没有拿到 2 票 Y，那么这轮投票就不会产生 Leader。<strong>哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的 2 倍）</strong>，再重新选举。这是因为，哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常网络传播。<strong>如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票</strong>。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。</p><h1 id="5-FAQs"><a href="#5-FAQs" class="headerlink" title="5. FAQs"></a>5. FAQs</h1><h2 id="5-1-哨兵在操作主从切换的过程当中，客户端能否正常进行请求操作？"><a href="#5-1-哨兵在操作主从切换的过程当中，客户端能否正常进行请求操作？" class="headerlink" title="5.1 哨兵在操作主从切换的过程当中，客户端能否正常进行请求操作？"></a>5.1 哨兵在操作主从切换的过程当中，客户端能否正常进行请求操作？</h2></li><li><p>如果客户端使用了读写分离，那么<strong>读请求</strong>可以在从库上正常执行，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间<strong>写请求会失败</strong>，失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间。</p></li><li><p>如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或<strong>写入消息队列中间件</strong>中，等哨兵切换完主从后，再把这些写请求发给新的主库，但这种场景只适合对写入请求返回值不敏感的业务，而且还需要业务层做适配，另外主从切换时间过长，也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这些请求的时间变长。</p></li><li><p>哨兵检测主库多久没有响应就提升从库为新的主库，这个时间是可以配置的（down-after-milliseconds参数）。配置的时间越短，哨兵越敏感，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果配置的时间比较长，哨兵越保守，这种情况可以减少哨兵误判的概率，但是主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多。</p></li><li><p>应用程序不感知服务的中断，还需要哨兵和客户端做些什么？当哨兵完成主从切换后，客户端需要及时感知到主库发生了变更，然后把缓存的写请求写入到新库中，保证后续写请求不会再受到影响，具体做法如下：</p><ul><li>哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端。</li><li>如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。</li><li>所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。</li><li>一般Redis的SDK都提供了通过哨兵拿到实例地址，再访问实例的方式，我们直接使用即可，不需要自己实现这些逻辑。当然，对于只有主从实例的情况，客户端需要和哨兵配合使用，而在分片集群模式下，这些逻辑都可以做在proxy层，这样客户端也不需要关心这些逻辑了，Codis就是这么做的</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1></li></ul><ol><li>极客时间Redis课程</li><li>Redis设计与实现</li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis多机数据库-哨兵机制&quot;&gt;&lt;a href=&quot;#Redis多机数据库-哨兵机制&quot; class=&quot;headerlink&quot; title=&quot;Redis多机数据库-哨兵机制&quot;&gt;&lt;/a&gt;Redis多机数据库-哨兵机制&lt;/h1&gt;&lt;p&gt;主从库的集群模式使得当从库发生故障以
      
    
    </summary>
    
    
      <category term="数据存储" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>Redis Cluster</title>
    <link href="https://www.llchen60.com/Redis-Cluster/"/>
    <id>https://www.llchen60.com/Redis-Cluster/</id>
    <published>2021-07-06T00:08:09.000Z</published>
    <updated>2021-07-09T22:19:57.371Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-Cluster"><a href="#Redis-Cluster" class="headerlink" title="Redis Cluster"></a>Redis Cluster</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>Redis集群是Redis提供的分布式数据库方案，集群通过分片 - sharding来进行数据共享，并提供复制和故障转移功能</li></ul><h1 id="2-节点"><a href="#2-节点" class="headerlink" title="2. 节点"></a>2. 节点</h1><ul><li>概述<ul><li>一个redis集群通常由多个节点 node 组成</li><li>开始的时候每个节点都是相互独立的，相当于各自在自己的集群当中，我们需要将各个独立的节点连接起来，构成一个包含多个节点的集群</li><li><code>CLUSTER MEET &lt;ip&gt; &lt;port&gt;</code> 我们可以用这个指令来连接各个节点<ul><li>以节点A 收到命令，要加节点B为例<ul><li>A和B 握手，确认彼此存在</li><li>A为节点B创建一个clusterNode结构，并添加到自己的clusterState.nodes字典里面</li><li>A根据IP 还有端口，向B发送MEET消息</li><li>节点B 收到信息，为A创建clusterNode结构，并添加到自己的 <code>clustState.nodes</code> 字典里面</li><li>B向A发出PONG消息，让A知道自己成功接收到了</li><li>A向B发出PING消息</li><li>节点B收到，确认A收到了自己的PONG  整个过程结束</li></ul></li></ul></li></ul></li><li>启动节点<ul><li>Redis服务器根据 <code>cluster-enabled</code> 配置选项判断是否开启服务器的集群模式</li></ul></li><li>集群模式和standalone模式的节点区别<ul><li>相同之处<ul><li>单机模式下的功能照旧<ul><li>文件事件处理器</li><li>时间事件处理器</li><li>持久化</li><li>Pubsub</li><li>复制模块</li><li>lua脚本</li></ul></li></ul></li><li>不同点<ul><li>集群模式下的数据会被保存到clusterNode, clusterLink以及clusterState结构里面<ul><li>下面是三个结构的代码实现</li><li>以及一个有三个节点的clusterState结构</li></ul></li></ul></li></ul></li></ul><pre><code class="jsx">struct clusterNode &#123;    mstime_t ctime;    char name[REDIS_CLUSTER_NAMELEN];    // 记录节点角色（主/从); 记录节点目前所处状态(在线/ 下线)    int flags;    // 节点当前配置记录    unit64_t configEpoch;    char ip[REDIS_IP_STR_LEN];    int port;    // 保存连接节点需要的信息    clusterLink *link;    // ....&#125;</code></pre><pre><code class="jsx">typedef struct clusterLink &#123;    mstime_t ctime;    // TCP 套接字描述符    int fd;    // 输出缓冲区，保存等待要发送给其他节点的消息    sds sndbuf;    // 输入缓冲区，保存着从其他节点接收到的消息    sds rcvbuf;    // 与这个连接相关联的节点    struct clusterNode *node;    // ....&#125; clusterLink; </code></pre><pre><code class="jsx">typedef struct clusterState &#123;    clustNode *myself;    unit64_t currentEpoch;    // 集群当前状态    int state;    // 集群中至少处理着一个槽的节点的数量    int size;    // 集群节点名单    dict *nodes;    // ....&#125; clusterState; </code></pre><p><img src="https://i.loli.net/2021/07/06/XxiOA9Qjz763K1Y.png" alt="clusterState示意图"></p><h1 id="3-槽指派"><a href="#3-槽指派" class="headerlink" title="3. 槽指派"></a>3. 槽指派</h1><ul><li>Redis集群通过分片的方式保存数据库当中的键值对<ul><li>整个数据库被分为了16384个slot</li><li>每个键都属于这些槽其中之一</li><li>集群当中的每个节点可以处理0个或者最多16384个槽</li><li>当16383个槽都有节点在处理的时候，集群处在上线状态</li><li>反之，如果有任何一个槽没有得到处理，那么集群就在下线状态</li></ul></li><li>如何指派槽<ul><li><code>CLUSTER ADDSLOTS &lt;slot&gt; [slot...]</code></li></ul></li></ul><h2 id="3-1-如何记录槽指派的信息"><a href="#3-1-如何记录槽指派的信息" class="headerlink" title="3.1 如何记录槽指派的信息"></a>3.1 如何记录槽指派的信息</h2><ul><li><p>clusterNode结构里面有slots属性和numslot属性</p><ul><li><p>slots</p><ul><li><p>bit array</p></li><li><p>根据索引i上的二进制位的值来判断节点是否负责处理槽i</p><p>  <img src="https://i.loli.net/2021/07/06/Zthejck4Xz2bPKl.png" alt="用bit array记录槽指派信息"></p></li></ul></li></ul></li></ul><pre><code class="jsx">struct clusterNode &#123;    // ...    unsigned char slots[16384/8];    int numslots; &#125;</code></pre><h2 id="3-2-如何传播-槽指派的信息"><a href="#3-2-如何传播-槽指派的信息" class="headerlink" title="3.2 如何传播 槽指派的信息"></a>3.2 如何传播 槽指派的信息</h2><ul><li>一个节点除了要记录自己负责处理的槽以外，还要将自己的slots通过消息发送给集群中的其他节点，以此告知其他结点自己目前负责的槽位</li><li>而后槽信息会被存储在clusterState 里面<ul><li>指向的是一个clusterNode结构！</li></ul></li><li>这里对比 <code>clusterState.slots</code> 以及 <code>clusterNode.slots</code> ， 前者记录了所有槽的指派信息，后者记录了当前的clusterNode结构所代表的节点的槽指派信息  一个记录了所有节点，一个记录了部分信息</li></ul><pre><code class="jsx">typedef struct clusterState &#123;    // ...    clusterNode *slots[16384];    // ... &#125;</code></pre><p><img src="https://i.loli.net/2021/07/06/4n1tgixR2NXOHdr.png" alt="槽指派信息的传播"></p><h1 id="4-在集群中执行命令"><a href="#4-在集群中执行命令" class="headerlink" title="4. 在集群中执行命令"></a>4. 在集群中执行命令</h1><h2 id="4-1-发送指令过程"><a href="#4-1-发送指令过程" class="headerlink" title="4.1 发送指令过程"></a>4.1 发送指令过程</h2><ul><li><p>当客户端向节点发送和数据库键有关的命令的时候，接收命令的节点会计算出命令要处理的数据库键属于哪一个槽</p></li><li><p>检查这个槽是否指派给了自己</p><ul><li><p>如果正好指派了，节点直接执行这个命令</p></li><li><p>如果没有，节点向客户端发送一个MOVED错误，指引客户端转向正确的节点，并再次发送之前想要执行的指令</p><p>  <img src="https://i.loli.net/2021/07/06/MamzjpOhCXvwNI4.png" alt="moved执行逻辑"></p><p>  <img src="https://i.loli.net/2021/07/06/3rBPwlGVoITAJn7.png" alt="节点返回MOVED,IP以及端口号"></p><p>  <img src="https://i.loli.net/2021/07/06/zIOFRiGWZutUce9.png" alt="节点转向"></p></li></ul></li></ul><h2 id="4-2-slots-to-keys跳跃表"><a href="#4-2-slots-to-keys跳跃表" class="headerlink" title="4.2 slots_to_keys跳跃表"></a>4.2 slots_to_keys跳跃表</h2><ul><li>当有新的键值对增删的操作时，节点会用clusterState结构中的slots_to_keys跳跃表来保存槽和键之间的关系</li></ul><pre><code class="jsx">typedef struct clusterState &#123;    // ...    zskiplist *slots_to_keys;    // ...&#125; clusterState; </code></pre><h1 id="5-重新分片操作"><a href="#5-重新分片操作" class="headerlink" title="5. 重新分片操作"></a>5. 重新分片操作</h1><h2 id="5-1-重分片流程"><a href="#5-1-重分片流程" class="headerlink" title="5.1 重分片流程"></a>5.1 重分片流程</h2><ul><li><p>将任意数量已经指派给某个节点的槽改为指派给另外一个节点，相关槽所属的键值对也会从源节点被移动到目标节点</p><p>  <img src="https://i.loli.net/2021/07/06/t5wivjMnQuIT2rG.png" alt="重分片"></p></li></ul><h2 id="5-2-ASK错误"><a href="#5-2-ASK错误" class="headerlink" title="5.2 ASK错误"></a>5.2 ASK错误</h2><ul><li>发生了重分片的过程当中，一部分键已经转移到了目标节点，另外一部分还在源节点</li><li>这种情况下，当接收到请求之后<ul><li>源节点首先在自己的数据库里面查找指定的键，如果找到，直接执行</li><li>如果没有找到，源节点会向客户端发送一个ASK，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/06/nD7Ybyk1BHGzOC4.png" alt="ASK判断逻辑"></p><h1 id="6-复制与故障转移"><a href="#6-复制与故障转移" class="headerlink" title="6. 复制与故障转移"></a>6. 复制与故障转移</h1><ul><li><p>Redis集群当中的节点分为主节点还有从节点</p></li><li><p>主节点用于处理槽，而从节点用于复制某个主节点，并在被复制的主节点下线以后，代替下线主节点继续处理命令请求</p></li><li><p>通过 <code>CLUSTER REPLICATE &lt;node_id&gt;</code> 来让接受命令的节点成为从节点，并开始对主节点进行复制</p><ul><li>从节点会在自己的 clusterState.nodes字典里 找到主节点对象的clusterNode结构，并将自己的 <code>clusterState.myself.slaveof</code>指针指向这个结构，以此来记录这个节点正在复制的主节点</li><li>而后修改在 <code>clusterStat.myslef.flags</code>中的属性  关闭原来的REDIS_NODE_MASTER标识，打开REDIS_NODE_SLAVE标识，表示这个节点已经由原来的主节点变成了从节点</li><li>根据 <code>clusterState.myself.slaveof</code>指向的clusterNode结构的IP还有端口号，开始对主节点的复制工作</li></ul></li><li><p>故障检测</p><ul><li>集群中每个节点会定期向其他节点发送PING消息，以此检测对方是否在线</li><li>如果接收PING消息的节点没有在规定时间内，返回PONG消息，那么没发回消息的节点会被标记为probable fail</li><li>集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息<ul><li>在线</li><li>疑似下线状态 PFAIL</li><li>已下线状态 FAIL</li></ul></li><li>主节点会记录各个节点的报告如果半数以上的负责处理槽的主节点都将某个主节点x报告为疑似下线，那么这个主节点会被标记为已下线</li><li>该消息会向集群广播出去</li></ul></li><li><p>故障转移</p><ul><li>在下线的主节点的从节点里面，选出一个从节点<ul><li>通过选举产生</li><li>当从节点发现主节点进入已下线状态的时候，从节点会向集群广播一条 <code>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</code> 消息，要求所有收到这条消息并且有投票权的主节点向这个从节点投票</li><li>如果一个主节点有投票权(负责处理槽) ，且还未投票给其他从节点，那么就会向要求投票的从节点返回一条 <code>CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK</code></li><li>每个参与选举的从节点统计收获到的ACK的数量</li><li>具有投票权的主节点数量为N  那么从节点需要收集到大于等于 N/2 +1 张支持票来获得主节点的支持</li><li>如果没有节点获得大于等于 N/2 +1 张支持票，那么就重新开始选举</li></ul></li><li>被选中的从节点会执行SLAVEOF no one命令，成为新的主节点</li><li>新主节点会撤销所有对已下线的主节点的槽指派，并将这些槽全部指派给自己</li><li>新的主节点向集群广播一条PONG消息，使得集群中的其他结点知道这个节点已经变成了主节点</li></ul></li></ul><h1 id="7-消息"><a href="#7-消息" class="headerlink" title="7. 消息"></a>7. 消息</h1><p>节点发送的消息主要有以下5种： </p><ul><li>MEET<ul><li>要求接受者加入到发送者当前所处的集群当中</li></ul></li><li>PING<ul><li>集群里的每个节点默认每隔一秒从已知节点列表中随机挑选5个结点</li><li>然后对5个当中最长时间没有发送过PING消息的节点发送PING消息</li></ul></li><li>PONG<ul><li>来告知发送者成功收到了MEET或者PING消息</li><li>也可以通过集群广播PONG 来让其他节点刷新对自己的认知</li></ul></li><li>FAIL<ul><li>当主节点A判断另一个主节点B进入FAIL状态了以后</li><li>节点A会向集群广播一条关于节点B FAIL的消息</li><li>所有收到消息的节点会将节点B标记为已下线</li></ul></li><li>PUBLISH<ul><li>当节点接到一个PUBLISH命令的时候，节点会执行，并向集群广播一条PUBLISH消息</li><li>所有接收到的节点都会执行相同的PUBLISH命令</li></ul></li></ul><h1 id="8-Redis-集群扩展与调优"><a href="#8-Redis-集群扩展与调优" class="headerlink" title="8. Redis 集群扩展与调优"></a>8. Redis 集群扩展与调优</h1><blockquote><p>实际案例： 5000万个键值对，每个键值对512B, 如何选择云主机的内存容量？</p></blockquote><ul><li><p>占用的内存空间</p><ul><li>50MM x 512B = 25GB</li></ul></li><li><p>使用32GB主机，但是发现Redis响应有时候会非常慢</p><ul><li>查询latest_fork_usec 指标，发现快到秒级别了</li></ul></li><li><p>Redis持久化机制</p><ul><li>RDB持久化过程当中，Redis会fork子进程来完成</li><li>fork用时和Redis的数据量正相关</li><li>fork在执行时会阻塞主线程<ul><li>数据量越大，fork操作造成的主线程阻塞时间就会越长</li><li>当我们对25GB的数据进行持久化的时候，数据量比较大，后台运行的子进程在fork创建时阻塞了主线程，导致Redis响应变慢</li></ul></li></ul></li><li><p>在上述的例子里面，使用单一redis instance已经不够了，因为我们要通过数据切片来实现</p></li></ul><h2 id="8-1-如何保存更多的数据"><a href="#8-1-如何保存更多的数据" class="headerlink" title="8.1 如何保存更多的数据"></a>8.1 如何保存更多的数据</h2><ul><li>纵向扩展<ul><li>升级单个Redis实例的资源配置<ul><li>增加内存容量</li><li>增加磁盘容量</li><li>使用更高配置的CPU</li></ul></li></ul></li><li>横向扩展<ul><li>横向增加当前Redis实例的个数</li></ul></li></ul><h2 id="8-2-数据切片和实例的对象分布关系"><a href="#8-2-数据切片和实例的对象分布关系" class="headerlink" title="8.2 数据切片和实例的对象分布关系"></a>8.2 数据切片和实例的对象分布关系</h2><ul><li>Redis cluster采用哈希槽来处理数据和实例之间的映射关系<ul><li>一个切片集群有16384个哈希槽</li><li>每个键值都会根据它的key，被映射到一个哈希槽当中</li></ul></li><li>具体映射过程<ul><li>根据键值对的key，按照CRC16算法计算一个16bit的值</li><li>用这个16bit的值对16384取模</li></ul></li><li>reids如何初始化各个实例来分配这些槽的？<ul><li>部署的时候，会用到cluster create命令创建集群</li><li>Redis会在此时将这些槽平均分别在集群实例当中</li></ul></li></ul><h2 id="8-3-客户端如何定位数据的"><a href="#8-3-客户端如何定位数据的" class="headerlink" title="8.3 客户端如何定位数据的"></a>8.3 客户端如何定位数据的</h2><ul><li><p>客户端定位键值对的时候，client library是可以计算出哈希槽是哪个的，但是如何定位到在哪个实例上是个问题</p><ul><li>拿到实例发过来的信息，缓存到本地上</li></ul></li><li><p>最开始</p><ul><li>每个实例都只知道自己被分配了哪些哈希槽的信息，并不知道其他实例拥有的哈希槽信息</li></ul></li><li><p>客户端和集群实例建立连接后</p><ul><li>实例会把哈希槽的分配信息发回给客户端</li><li>各个Redis实例会互相连通，完成哈希槽信息的扩散</li></ul></li><li><p>Redis Cluster的重定向机制</p><ul><li>为什么需要<ul><li>客户端的缓存没有拿到最新的信息<ul><li>集群中实例有新增或者删除</li><li>Redis 重新分配哈希槽</li></ul></li></ul></li><li>如何实现的<ul><li>客户端给一个实例发送读写操作，但是这个实例没有相应的数据</li><li>实例发回一个MOVED响应，包括了新实例的访问地址</li></ul></li></ul></li></ul><p>Redis使用集群方案就是为了解决单个节点数据量大、写入量大产生的性能瓶颈的问题。多个节点组成一个集群，可以提高集群的性能和可靠性，但随之而来的就是集群的管理问题，最核心问题有2个：请求路由、数据迁移（扩容/缩容/数据平衡）。</p><p>1、请求路由：一般都是采用哈希槽的映射关系表找到指定节点，然后在这个节点上操作的方案。</p><p>Redis</p><p>Cluster在每个节点记录完整的映射关系(便于纠正客户端的错误路由请求)，同时也发给客户端让客户端缓存一份，便于客户端直接找到指定节点，客户端与服务端配合完成数据的路由，这需要业务在使用Redis<br> Cluster时，必须升级为集群版的SDK才支持客户端和服务端的协议交互。</p><p>其他Redis集群化方案例如Twemproxy、Codis都是中心化模式（增加Proxy层），客户端通过Proxy对整个集群进行操作，Proxy后面可以挂N多个Redis实例，Proxy层维护了路由的转发逻辑。操作Proxy就像是操作一个普通Redis一样，客户端也不需要更换SDK，而Redis<br> Cluster是把这些路由逻辑做在了SDK中。当然，增加一层Proxy也会带来一定的性能损耗。</p><p>2、数据迁移：当集群节点不足以支撑业务需求时，就需要扩容节点，扩容就意味着节点之间的数据需要做迁移，而迁移过程中是否会影响到业务，这也是判定一个集群方案是否成熟的标准。</p><p>Twemproxy不支持在线扩容，它只解决了请求路由的问题，扩容时需要停机做数据重新分配。而Redis</p><p>Cluster和Codis都做到了在线扩容（不影响业务或对业务的影响非常小），重点就是在数据迁移过程中，客户端对于正在迁移的key进行操作时，集群如何处理？还要保证响应正确的结果？</p><p>Redis</p><p>Cluster和Codis都需要服务端和客户端/Proxy层互相配合，迁移过程中，服务端针对正在迁移的key，需要让客户端或Proxy去新节点访问（重定向），这个过程就是为了保证业务在访问这些key时依旧不受影响，而且可以得到正确的结果。由于重定向的存在，所以这个期间的访问延迟会变大。等迁移完成之后，Redis</p><p>Cluster每个节点会更新路由映射表，同时也会让客户端感知到，更新客户端缓存。Codis会在Proxy层更新路由表，客户端在整个过程中无感知。</p><p>除了访问正确的节点之外，数据迁移过程中还需要解决异常情况（迁移超时、迁移失败）、性能问题（如何让数据迁移更快、bigkey如何处理），这个过程中的细节也很多。</p><p>Redis Cluster的数据迁移是同步的，迁移一个key会同时阻塞源节点和目标节点，迁移过程中会有性能问题。而Codis提供了异步迁移数据的方案，迁移速度更快，对性能影响最小，当然，实现方案也比较复杂。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>极客时间-Redis核心技术与实战</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis-Cluster&quot;&gt;&lt;a href=&quot;#Redis-Cluster&quot; class=&quot;headerlink&quot; title=&quot;Redis Cluster&quot;&gt;&lt;/a&gt;Redis Cluster&lt;/h1&gt;&lt;h1 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Redis多机数据库-数据同步</title>
    <link href="https://www.llchen60.com/Redis%E5%A4%9A%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
    <id>https://www.llchen60.com/Redis%E5%A4%9A%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</id>
    <published>2021-07-05T03:00:14.000Z</published>
    <updated>2021-07-05T03:01:36.094Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis多机数据库-数据同步"><a href="#Redis多机数据库-数据同步" class="headerlink" title="Redis多机数据库-数据同步"></a>Redis多机数据库-数据同步</h1><h1 id="1-Redis的高可靠性"><a href="#1-Redis的高可靠性" class="headerlink" title="1. Redis的高可靠性"></a>1. Redis的高可靠性</h1><p>Redis的高可靠性体现在两个方面：</p><ul><li>数据尽量少丢失<ul><li>AOF</li><li>RDB</li></ul></li><li>服务尽量少中断<ul><li>增加副本冗余量 — 将一份数据同时保存在多个实例上</li></ul></li></ul><h1 id="2-数据同步-—-主从库模式"><a href="#2-数据同步-—-主从库模式" class="headerlink" title="2. 数据同步 — 主从库模式"></a>2. 数据同步 — 主从库模式</h1><ul><li><p>主从库之间采用的是读写分离的方式</p><ul><li><p>读操作</p><ul><li>主库，从库都可以接收</li></ul></li><li><p>写操作</p><ul><li><p>首先到主库执行</p></li><li><p>然后主库将写操作同步给从库</p><p>  <img src="https://i.loli.net/2021/01/04/8wE4dPDgFxqRX6r.png" alt="https://i.loli.net/2021/01/04/8wE4dPDgFxqRX6r.png"></p><p>  主从读写分离</p></li></ul></li></ul></li><li><p>主从库的好处是修改操作都只会在一个库实现</p><ul><li>可以减少加锁，实例间协商这类开销</li></ul></li></ul><h2 id="2-1-主从库之间如何进行第一个同步？"><a href="#2-1-主从库之间如何进行第一个同步？" class="headerlink" title="2.1 主从库之间如何进行第一个同步？"></a>2.1 主从库之间如何进行第一个同步？</h2><ul><li><p>多个Redis实例之间通过replicaof/ slaveof命令形成主库和从库的关系，然后按照三个阶段完成数据的第一次同步：</p><p>  <img src="https://i.loli.net/2021/01/04/KZemoVB6CFjNlJI.png" alt="https://i.loli.net/2021/01/04/KZemoVB6CFjNlJI.png"></p><p>  主从首次同步过程</p></li><li><p>第一阶段</p><ul><li><p>主从库之间建立连接，协商同步</p></li><li><p>为全量复制做准备</p></li><li><p>从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复以后，主从库间就可以开始同步了</p><ul><li><p>从库给主库发送psync命令，表示要进行数据同步</p></li><li><p>主库根据这个命令的参数来启动复制</p><ul><li>psync命令包含主库的runId和复制进度的offset两个参数<ul><li>runID — Redis实例启动的时候自动随机生成的ID，用来唯一标识当前实例<ul><li>runId很关键，比如从服务器断线重连主服务器以后，会发送之前保存的主服务器的运行ID，如果ID一致，说明前后连接的是同一个主服务器，那么就可以继续尝试执行部分的重同步操作</li><li>相反，如果运行ID不同，那么就必须通过RDB完成整个重同步操作</li></ul></li><li>offset 此时设为-1，表示第一次复制</li></ul></li></ul></li><li><p>主库收到psync命令后，使用FULLRESYNC响应命令，包括了主库的runID还有主库目前的复制进度offset，返回给从库</p><ul><li>从库记录下两个参数</li></ul></li><li><p>FULLRESYNC表示第一次复制使用的是全量复制</p></li><li><p>主库与此同时执行BGSAVE命令，在后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令</p><p>  <img src="https://i.loli.net/2021/07/05/Kmw8ZsWuzGki25V.png" alt="主从服务器同步过程"></p></li></ul></li></ul></li><li><p>第二阶段</p><ul><li>主库将所有数据同步给从库</li><li>从库收到数据后，在本地完成数据加载 — 依赖于内存快照生成的RDB文件<ul><li>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。</li><li>从库接收到 RDB 文件后，会先<strong>清空当前数据库</strong>，然后加载 RDB 文件。<ul><li>这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空</li></ul></li></ul></li><li>在做数据同步的过程中，主库不会被阻塞。对于这个过程中接收到的正常请求，写操作会记录在主库的<strong>Replication Buffer</strong>当中</li></ul></li><li><p>第三阶段</p><ul><li>主库会将第二阶段新收到的修改命令，再发给从库</li><li>当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了</li></ul></li></ul><h2 id="2-2-主从级联方式分担全量复制时的主库压力"><a href="#2-2-主从级联方式分担全量复制时的主库压力" class="headerlink" title="2.2 主从级联方式分担全量复制时的主库压力"></a>2.2 主从级联方式分担全量复制时的主库压力</h2><ul><li><p>现状/ 问题</p><ul><li>一次全量复制主库需要完成两个耗时操作<ul><li>生成RDB文件和传输RDB文件</li></ul></li><li>如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。</li><li>传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力</li></ul></li><li><p>解决方案 — 主从从模式</p><ul><li><p>我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。replicaof 所选从库的IP 6379</p><p><img src="https://i.loli.net/2021/01/04/eihQpmN6FJdRxLy.png" alt="https://i.loli.net/2021/01/04/eihQpmN6FJdRxLy.png"></p></li></ul></li></ul><h2 id="2-3-突发情况下-暂时断网-的增量复制"><a href="#2-3-突发情况下-暂时断网-的增量复制" class="headerlink" title="2.3 突发情况下(暂时断网)的增量复制"></a>2.3 突发情况下(暂时断网)的增量复制</h2><ul><li><p>旧版redis在断开重连以后从服务器会向主服务器发出SYNC命令，从头开始进行bootstrap，时间会非常长，非常低效</p></li><li><p>新版本使用PSYNC</p><ul><li>PSYNC具有full resynchronization, partial resynchronization两种模式</li><li>partial resync使得断线重连以后可以通过增量来做复制，而不是用RDB重头开始</li></ul></li><li><p>网络断了以后我们需要一种开销相对合理的复制方式，即增量复制</p><ul><li>将主从库断联期间主库收到的命令，同步给从库</li></ul></li><li><p>增量复制的时候，主从库之间依靠repl_backlog_buffer这个缓冲区来做同步</p></li><li><p>整个过程如下：</p><ul><li><p>当主从库断连后，主库会把断连期间收到的写操作命令，写入 <strong>replication buffer</strong>，同时也会把这些操作命令也写入 <strong>repl_backlog_buffer</strong> 这个缓冲区。</p></li><li><p>repl_backlog_buffer 是一个<strong>环形缓冲区</strong>，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。</p></li><li><p>刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。</p></li><li><p>同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。</p></li><li><p>主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距</p></li><li><p>在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。</p><p><img src="https://i.loli.net/2021/01/04/w3TLhzRgOH2A65d.png" alt="https://i.loli.net/2021/01/04/w3TLhzRgOH2A65d.png"></p></li></ul></li></ul><blockquote><p>因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。</p></blockquote><p>我们要想办法避免这一情况，一般而言，我们可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：<strong>缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小</strong>。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值</p><ul><li>repl_backlog_buffer<ul><li>是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销</li><li>如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量同步，所以repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量同步的概率</li><li>而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer</li></ul></li><li>replication_buffer<ul><li>Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互</li><li>客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的</li><li>Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。</li><li>所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer</li><li>这个buffer需要做大小的限制<ul><li>如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM</li><li>所以Redis提供了<strong>client-output-buffer-limit</strong>参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。</li></ul></li></ul></li></ul><h2 id="2-4-主从全量同步-RDB-vs-AOF"><a href="#2-4-主从全量同步-RDB-vs-AOF" class="headerlink" title="2.4 主从全量同步 RDB vs AOF"></a>2.4 主从全量同步 RDB vs AOF</h2><p>1、RDB文件内容是<strong>经过压缩的二进制数据（不同数据类型数据做了针对性优化）</strong>，文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为<strong>RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可</strong>，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。</p><p>2、假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。</p><h1 id="3-复制过程的具体实现"><a href="#3-复制过程的具体实现" class="headerlink" title="3. 复制过程的具体实现"></a>3. 复制过程的具体实现</h1><ul><li>设置主服务器的地址和端口</li><li>建立套接字连接<ul><li>从服务器根据命令所设置的IP和端口，创建连向主服务器的套接字连接</li><li>如果连接成功，会为这个套接字关联一个专门用于处理复制工作的文件事件处理器</li><li>从服务器这个时候相当于主服务器的客户端</li></ul></li><li>建立完成以后，从PING主<ul><li>检查套接字读写正常</li><li>检查主服务器能否正常处理命令请求</li></ul></li><li>身份验证<ul><li>masterauth</li></ul></li><li>验证成功以后从服务器执行命令  <code>REPLCONF listerning-port &lt;port-numer&gt;</code> 向主服务器发送从服务器的监听端口号</li><li>主服务器接收到以后，会将端口号记录在从服务器所对应的客户端状态的属性当中 <code>slave_listening_port</code></li><li>同步<ul><li>从向主发PSYNC命令，执行同步操作</li></ul></li><li>命令传播</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>极客时间</li><li>redis设计与实现</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis多机数据库-数据同步&quot;&gt;&lt;a href=&quot;#Redis多机数据库-数据同步&quot; class=&quot;headerlink&quot; title=&quot;Redis多机数据库-数据同步&quot;&gt;&lt;/a&gt;Redis多机数据库-数据同步&lt;/h1&gt;&lt;h1 id=&quot;1-Redis的高可靠性&quot;
      
    
    </summary>
    
    
      <category term="数据存储" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>Redis持久化机制-RDB</title>
    <link href="https://www.llchen60.com/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-RDB/"/>
    <id>https://www.llchen60.com/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-RDB/</id>
    <published>2021-07-04T22:17:10.000Z</published>
    <updated>2021-07-04T22:18:28.838Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-AOF数据恢复存在的问题"><a href="#1-AOF数据恢复存在的问题" class="headerlink" title="1. AOF数据恢复存在的问题"></a>1. AOF数据恢复存在的问题</h1><ul><li>AOF方法每次执行记录的是操作命令，需要持久化的数据量不大</li><li>但是也因为记录的是操作命令，而不是实际数据，所以用AOF方法进行故障恢复的时候，需要逐一把操作日志都执行一遍<ul><li>如果操作日志很多，Redis的恢复就会很缓慢，可能影响到正常</li></ul></li></ul><h1 id="2-内存快照Overview"><a href="#2-内存快照Overview" class="headerlink" title="2. 内存快照Overview"></a>2. 内存快照Overview</h1><ul><li>内存快照可以解决上述的问题<ul><li>内存快照指的是记录下内存中的数据在某一时刻的状态</li><li>将某一时刻的状态以文件的形式写到磁盘上 这样即使宕机，快照文件也不会丢失，数据的可靠性也就有了保证</li><li>快照文件称为RDB文件，RDB — Redis DataBase</li></ul></li><li>RDB特征<ul><li>记录的是某一个时刻的数据，并不是操作</li><li>因此在数据恢复的时候，我们可以将RDB文件直接读入内存，很快完成恢复</li></ul></li><li>什么时候会实现RDE的载入？<ul><li>只要Redis服务器在启动的时候检测到RDB文件存在，就会自动载入RDB文件</li><li>如果服务器开启了AOF持久化功能，因为AOF文件更新频率一般比RDB高很多，所以服务器会优先使用AOF文件来还原数据库状态、</li><li>只有当AOF功能处于关闭状态的时候，服务器才会使用RDB文件来还原数据库状态</li></ul></li><li>如何工作的<ul><li>我们可以设置一系列规则，被保存在saveparams里面<ul><li>seconds</li><li>changes</li><li>—&gt; 当在xx秒里 有超过xxx更新数量的时候会触发RDB</li></ul></li><li>dirty计数器<ul><li>记录在上次成功执行了SAVE或者BGSAVE命令之后，服务器对数据库状态进行了多少次修改</li></ul></li><li>lastsave属性<ul><li>UNIX时间戳，记录了上次成功执行的时间</li></ul></li><li>Redis的serverCron函数默认每隔100ms执行一次，来维护服务器<ul><li>其中一项工作就是检查save选项设置的保存条件是否满足</li><li>如果满足就执行BGSAVE命令</li></ul></li></ul></li></ul><h2 id="2-1-给哪些数据做快照？"><a href="#2-1-给哪些数据做快照？" class="headerlink" title="2.1 给哪些数据做快照？"></a>2.1 给哪些数据做快照？</h2><ul><li>Redis的数据都在内存当中，为了提供所有数据的可靠性保证，其执行的是<strong>全量快照</strong><ul><li>即将内存中的所有数据都记录到磁盘当中</li><li>与之一起来的问题就是，当需要对内存的全量数据做快照的时候，将其全部写入磁盘会花费很多时间</li><li>而且全量数据越多，RDB文件就越大，往磁盘上写数据的时间开销就越大</li><li>而Redis的单线程模型决定了我们要尽量避免阻塞主线程的操作</li></ul></li><li>Redis生成RDB文件的命令<ul><li>save<ul><li>在主线程中执行，会导致阻塞</li><li>在服务器进程阻塞期间，服务器不能处理任何命令请求</li></ul></li><li>bgsave<ul><li>创建一个子进程，专门用于写入RDB文件，可以避免对于主线程的阻塞 — 是Redis RDB的文件生成的默认配置</li></ul></li></ul></li></ul><h2 id="2-2-做快照的时候数据是否能够被增删改？"><a href="#2-2-做快照的时候数据是否能够被增删改？" class="headerlink" title="2.2 做快照的时候数据是否能够被增删改？"></a>2.2 做快照的时候数据是否能够被增删改？</h2><ul><li><p>我们需要使系统在进行快照的时候仍然能够接受修改请求，要不然会严重影响系统的执行效率</p></li><li><p>Redis会借助操作系统提供的<strong>写时复制技术 — copy on write</strong>，在执行快照的同时，正常处理写操作</p><ul><li><p>copy on write</p><ul><li><p>copy operation is deferred until the first write,</p></li><li><p>could significantly reduce the resource consumption of unmodified copies, while adding a small overhead to resource-modifying operations</p><p><a href="https://en.wikipedia.org/wiki/Copy-on-write">Copy-on-write</a></p><p><img src="https://i.loli.net/2021/01/03/I8kwNqF41KlezWL.png" alt="Copy On Write的实现"></p><p>Copy on Write实现</p></li></ul></li></ul></li><li><p>例图当中键值对C发生了改变，那么bgsave子进程还会对原键值对C 进行snapshot，然后过程当中的写操作会被写到副本里面</p></li></ul><h2 id="2-3-多久做一次快照？"><a href="#2-3-多久做一次快照？" class="headerlink" title="2.3 多久做一次快照？"></a>2.3 多久做一次快照？</h2><ul><li>尽管bgsave执行时不阻塞主线程，但是频繁的执行全量快照，会带来两方面的开销<ul><li>磁盘带宽压力<ul><li>频繁将全量数据写入磁盘，会给磁盘带来很大的压力</li><li>多个快照竞争有限的磁盘贷款，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环</li></ul></li><li>fork操作的阻塞<ul><li>bgsave子进程需要通过fork操作从主线程创建出来</li><li>fork创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间就越长</li></ul></li></ul></li></ul><h2 id="2-4-RDB文件结构"><a href="#2-4-RDB文件结构" class="headerlink" title="2.4 RDB文件结构"></a>2.4 RDB文件结构</h2><ul><li>一个RDB文件分成以下几个部分<ul><li>REDIS<ul><li>用来检测载入的文件是否为RDB文件</li></ul></li><li>db_version<ul><li>记录RDB文件的版本号</li></ul></li><li>databased<ul><li>包含任意多个数据库，以及每个数据库中的键值对数据</li></ul></li><li>EOF<ul><li>1字节</li><li>标志着RDB文件正文部分的结束</li></ul></li><li>check_sum<ul><li>通过对上面四个部分的内容进行计算得出的</li><li>载入RDB文件的时候，会将载入数据所计算出来的校验和与check_sum所记录的进行对比</li></ul></li></ul></li></ul><h1 id="3-AOF和RDB混用模式"><a href="#3-AOF和RDB混用模式" class="headerlink" title="3. AOF和RDB混用模式"></a>3. AOF和RDB混用模式</h1><ul><li>为什么要混用<ul><li>AOF执行速度会比较慢</li><li>RDB的全量复制频率难以把控，太低，会容易丢失数据；太高，系统开销会很大</li></ul></li><li>如何实现的<ul><li>RDB以一定的频率来执行</li><li>在两次快照之间，使用AOF日志记录这期间所有的命令操作</li></ul></li></ul><p><img src="https://i.loli.net/2021/01/03/C98RNZ7PanDWyUr.png" alt="RDB增量快照的实现"></p><p>AOF &amp; RDB Mix</p><ul><li>如上图所示，到了第二次做全量快照的时候，就可以清空AOF日志，因为所有的操作都已经保存到了第二次的全量快照当中了</li></ul><h1 id="4-实际场景探究"><a href="#4-实际场景探究" class="headerlink" title="4. 实际场景探究"></a>4. 实际场景探究</h1><blockquote><p>我们使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB，我们使用了 RDB 做持久化保证。当时 Redis 的运行负载以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。你觉得，在这个场景下，用 RDB 做持久化有什么风险吗？</p></blockquote><ul><li>内存资源风险<ul><li>Redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和，</li><li>如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。<ul><li>swap 机制<ul><li>将一块磁盘或者一个本地文件当做内存来使用<ul><li>换入<ul><li>当进程再次访问内存的时候，从磁盘读取数据到内存当中</li></ul></li><li>换出<br><a href="https://blog.csdn.net/qq_24436765/article/details/103822548">Linux系统的swap机制_囚牢-峰子的博客-CSDN博客</a><ul><li>将进程暂时不用的内存数据保存到磁盘上，再释放内存给其他进程使用</li><li>当进程再次访问内存的时候，从磁盘读取数据到内存中</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>CPU资源风险<ul><li>虽然子进程在做RDB持久化，但生成RDB快照过程会消耗大量的CPU资源，</li><li>虽然Redis处理处理请求是单线程的，但Redis Server还有其他线程在后台工作，例如AOF每秒刷盘、异步关闭文件描述符这些操作。</li><li>由于机器只有2核CPU，这也就意味着父进程占用了超过一半的CPU资源，此时子进程做RDB持久化，可能会产生CPU竞争，导致的结果就是父进程处理请求延迟增大，子进程生成RDB快照的时间也会变长，整个Redis Server性能下降。</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>极客时间</li><li>Redis设计与实现</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-AOF数据恢复存在的问题&quot;&gt;&lt;a href=&quot;#1-AOF数据恢复存在的问题&quot; class=&quot;headerlink&quot; title=&quot;1. AOF数据恢复存在的问题&quot;&gt;&lt;/a&gt;1. AOF数据恢复存在的问题&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;AOF方法每次执行记录的是操
      
    
    </summary>
    
    
      <category term="数据存储" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>Redis持久化机制-AOF</title>
    <link href="https://www.llchen60.com/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-AOF/"/>
    <id>https://www.llchen60.com/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-AOF/</id>
    <published>2021-07-04T19:02:48.000Z</published>
    <updated>2021-07-04T19:05:05.587Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis持久化机制-AOF"><a href="#Redis持久化机制-AOF" class="headerlink" title="Redis持久化机制-AOF"></a>Redis持久化机制-AOF</h1><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>Redis很大的一个应用场景就是缓存，因为速度很快，通过将后端数据库中的数据存储在内存当中，然后直接从内存中读取数据。</p><p>但是这样做的一个问题，是如果服务器宕机，内存中的数据将会全部丢失掉。对于恢复数据，我们可能的解决方案是：</p><ul><li>从后端数据库访问<ul><li>对数据库的频繁访问会给数据库造成巨大的压力</li><li>会导致应用程序响应速度变慢</li></ul></li><li>理念 - 不从后端数据库读取，实现数据的持久化<ul><li>AOF日志</li><li>RDB快照</li></ul></li></ul><h1 id="2-AOF日志的实现"><a href="#2-AOF日志的实现" class="headerlink" title="2. AOF日志的实现"></a>2. AOF日志的实现</h1><h2 id="2-1-什么是AOF"><a href="#2-1-什么是AOF" class="headerlink" title="2.1 什么是AOF"></a>2.1 什么是AOF</h2><ul><li><p>AOF - Append Only File</p></li><li><p>写后日志</p><ul><li><p>Redis先执行命令，将数据写入内存，然后才记录日志</p><p>  [写后日志]](<a href="https://i.loli.net/2020/12/29/bNUOftoVI19G8Wj.png">https://i.loli.net/2020/12/29/bNUOftoVI19G8Wj.png</a>)</p></li></ul></li></ul><h2 id="2-2-AOF记录了什么"><a href="#2-2-AOF记录了什么" class="headerlink" title="2.2 AOF记录了什么"></a>2.2 AOF记录了什么</h2><ul><li><p>传统数据库日志</p><ul><li>记录修改后的数据</li></ul></li><li><p>AOF</p><ul><li><p>写后日志</p></li><li><p>记录Redis收到的每一条指令，这些命令以文本形式保存</p></li><li><p><strong>AOF记录日志的时候，不会进行语法检查的</strong>！ 因此，如果先记录日志，再做执行的话，日志当中就有可能记录错误的命令，在使用日志恢复数据的时候，就有可能出错</p><ul><li><p>还是对于速度和保证性的tradeoff</p><p><img src="https://i.loli.net/2020/12/29/qn9adxRcv2ZSJiD.png" alt="AOF文件EG"></p><p>AOF日志范例</p></li></ul></li><li><p>写后日志可以避免出现记录错误命令的情况</p></li><li><p>而且因为是在命令执行后才记录日志，所以不会阻塞当前的写操作</p></li></ul></li></ul><h3 id="2-2-1-写后日志的风险"><a href="#2-2-1-写后日志的风险" class="headerlink" title="2.2.1 写后日志的风险"></a>2.2.1 写后日志的风险</h3><ul><li>如果刚执行完一个命令，还没有记录日志就宕机了，那么命令和相应的数据都有丢失的风险。</li><li>AOF虽然避免了对当前命令的阻塞，但是可能会给下一个操作带来阻塞风险<ul><li>因为AOF日志也是在主线程中执行，如果将日志文件写入磁盘的时候，磁盘写压力大，会导致写盘非常慢</li></ul></li></ul><p>解决方案： 需要控制写命令执行完成后AOF日志写回磁盘的时机</p><h2 id="2-3-AOF文件载入与数据还原"><a href="#2-3-AOF文件载入与数据还原" class="headerlink" title="2.3 AOF文件载入与数据还原"></a>2.3 AOF文件载入与数据还原</h2><ul><li>详细步骤<ul><li>创建一个不带网络连接的fake client<ul><li>因为Redis命令只能在客户端的上下文当中来执行</li></ul></li><li>从AOF文件当中分析并读取一条写命令</li><li>使用伪客户端来执行被读出的写命令</li><li>重复执行上述的读取和执行指令，直到处理完毕</li></ul></li></ul><h1 id="3-单点研究"><a href="#3-单点研究" class="headerlink" title="3. 单点研究"></a>3. 单点研究</h1><h2 id="3-1-写回策略"><a href="#3-1-写回策略" class="headerlink" title="3.1 写回策略"></a>3.1 写回策略</h2><ul><li>Redis的服务器进程是一个事件循环，这个循环当中的文件事件负责<ul><li>接收客户端的命令请求</li><li>向客户端发送命令回复</li></ul></li><li>时间事件负责接收客户端的命令请求</li></ul><pre><code class="jsx">def eventLoop():     while true:         // 处理文件事件，可能会有新内容追加到aof_but缓冲区        processFileEvents()        processTimeEvents()        flushAppendOnlyFile()</code></pre><ul><li><p>可用的写回策略 - AOF当中的appendfsync的三个可选值</p><ul><li><p>Always 同步写回</p><ul><li>每个写命令执行完，立刻同步将日志写回磁盘</li></ul></li><li><p>EverySec 每秒写回</p><ul><li>每个写命令执行完，只是先把日志写到<strong>AOF文件的内存缓冲区</strong>，每隔一秒将缓冲区中的内容写入磁盘</li></ul></li><li><p>No 操作系统控制的写回</p><ul><li>每个写命令执行完，只是将日志写到AOF文件的缓冲区，由操作系统决定何时将缓冲区内容写回磁盘</li></ul><p><img src="https://i.loli.net/2020/12/29/RkfhClbVDv5JKzp.png" alt="appendfsync 规定的写回策略"></p><p>写回策略对比</p></li></ul></li><li><p>写回策略的选择 — 根据对于性能和可靠性的要求，来选择选用哪一种写回策略</p><ul><li>想要获得高性能，选用No策略</li><li>想要高可靠性的保证，选用Always策略</li><li>如果允许数据有一点丢失，又希望性能不受太大的影响，选用EverySec策略</li></ul></li></ul><h2 id="3-2-如何处理过大的日志文件-—-AOF重写机制"><a href="#3-2-如何处理过大的日志文件-—-AOF重写机制" class="headerlink" title="3.2 如何处理过大的日志文件 — AOF重写机制"></a>3.2 如何处理过大的日志文件 — AOF重写机制</h2><p>日志过大会产生性能问题，主要在以下三个方面： </p><ol><li><p>文件系统本身对文件大小的限制，无法保存过大的文件 </p></li><li><p>如果文件太大，再向里面追加命令记录，效率会降低 </p></li><li><p>如果发生宕机，AOF中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程会非常缓慢，这就会影响到Redis的正常使用</p></li></ol><h3 id="3-2-1-重写可以优化日志大小的原理"><a href="#3-2-1-重写可以优化日志大小的原理" class="headerlink" title="3.2.1 重写可以优化日志大小的原理"></a>3.2.1 重写可以优化日志大小的原理</h3><ul><li><p>AOF重写机制</p><ul><li><p>重写的时候，根据数据库现状创建一个新的AOF文件</p><ul><li>读取数据库所有的键值对</li><li>针对每一个键值对用一条命令记录它的写入</li><li>需要回复的时候，直接执行这条命令</li></ul></li><li><p>重写可以使得日志文件变小，因为可以压缩多条指令到一条</p><ul><li><p>即AOF日志是用来做恢复的，我不需要记录每一步的中间状态，只要知道最终对应的key的value是多少就好</p><p>  <img src="https://i.loli.net/2020/12/29/R7fgD2tVBvZUk8z.png" alt="AOF重写E.G"></p><p>  重写原理</p></li></ul></li></ul></li></ul><h3 id="3-2-2-重写如何避免阻塞？"><a href="#3-2-2-重写如何避免阻塞？" class="headerlink" title="3.2.2 重写如何避免阻塞？"></a>3.2.2 重写如何避免阻塞？</h3><ul><li><p>AOF日志由主线程写回 — 是在执行了主操作以后，直接call的AOF的方法来进行执行的，而重写过程是由<strong>后台子进程bgrewriteaof</strong>来完成的，是为了避免阻塞主线程，导致数据库性能的下降</p></li><li><p>重写的整个流程</p><ul><li><p>一处拷贝</p><ul><li>每次执行重写的时候，主线程fork到bgrewriteaof子进程</li><li>主线程的内存会被拷贝一份到bgrewriteaof子进程当中，其中会包含数据库的最新数据</li><li>然后该子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志</li></ul></li><li><p>两处日志</p><ul><li><p>主线程当中的AOF日志</p><ul><li>但有新的操作进入，Redis会将该操作写到AOF日志缓冲区</li><li>这样即使宕机，AOF日志的操作仍齐全，可以用来做恢复</li></ul></li><li><p>AOF重写日志</p><ul><li><p>该操作同时也会被写入到重写日志的缓冲区</p></li><li><p>等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以<strong>用新的 AOF 文件替代旧文件</strong>了。</p><p><img src="https://i.loli.net/2020/12/29/6vco3pLJNDBwU52.png" alt="AOF重写缓冲"></p></li></ul></li><li><p>如何解决在AOF重写过程当中数据库新的更新导致的服务器当前的数据库状态和重写后AOF文件所保存的数据库状态不一致的问题？？</p><ul><li>AOF重写缓冲区会在服务器创建了子进程之后开始使用</li><li>当redis服务器执行一个写命令之后，它会同时将其发给AOF缓冲区还有AOF重写缓冲区</li><li>当子进程完成了AOF重写工作之后，会向父进程发出信号，父进程接收到以后，会调用一个信号处理函数，而后：<ul><li>将AOF重写缓冲区中的所有内容写入到新AOF文件里</li><li>对新的AOF文件改名，覆盖现有的AOF文件，完成新旧两个AOF文件的替换</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="3-3-AOF-日志重写过程当中的阻塞风险"><a href="#3-3-AOF-日志重写过程当中的阻塞风险" class="headerlink" title="3.3 AOF 日志重写过程当中的阻塞风险"></a>3.3 AOF 日志重写过程当中的阻塞风险</h2><ul><li>Fork子进程的过程<ul><li>fork并不会一次性拷贝所有内存数据给子进程，采用的是操作系统提供的copy on write机制<ul><li>copy on write机制就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞的问题<ul><li>fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会<strong>把触发的异常的页复制一份</strong>，于是父子进程各自持有独立的一份。</li></ul></li></ul></li><li>fork子进程需要先拷贝进程必要的数据结构<ul><li>拷贝内存页表 — 即虚拟内存和物理内存的映射索引表</li><li>这个拷贝过程会消耗大量的CPU资源，并且拷贝完成之前整个进程是会阻塞的</li><li>阻塞时间取决于整个实例的内存大小<ul><li>实例越大，内存页表也越大，fork阻塞时间就会越久</li></ul></li></ul></li><li>在完成了拷贝内存页表之后，子进程和父进程指向的是相同的内存地址空间<ul><li>这个时候虽然产生了子进程，但是并没有申请和父进程相同的内存大小</li><li>真正的内存分离是<strong>在写发生的时候，这个时候才会真正拷贝内存的数据</strong></li></ul></li></ul></li><li>AOF重写过程中父进程产生写入的过程<ul><li>Fork出的子进程当前状态是指向了和父进程相同的内存地址空间，这个时候子进程就可以执行AOF重写，将内存中的所有数据写入到AOF文件里</li><li>但是同时父进程仍然会有流量写入<ul><li>如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离</li><li>父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险</li><li>如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间</li></ul></li></ul></li></ul><h2 id="3-4-AOF重写日志为什么不共享AOF本身的日志？"><a href="#3-4-AOF重写日志为什么不共享AOF本身的日志？" class="headerlink" title="3.4 AOF重写日志为什么不共享AOF本身的日志？"></a>3.4 AOF重写日志为什么不共享AOF本身的日志？</h2><p>AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可</p><h2 id="3-5-如何触发AOF重写？"><a href="#3-5-如何触发AOF重写？" class="headerlink" title="3.5 如何触发AOF重写？"></a>3.5 如何触发AOF重写？</h2><p>有两个配置项在控制AOF重写的触发时机：</p><ol><li>auto-aof-rewrite-min-size: 表示运行AOF重写时文件的最小大小，默认为64MB</li><li>auto-aof-rewrite-percentage: 这个值的计算方法是：当前AOF文件大小和上一次重写后AOF文件大小的差值，再除以上一次重写后AOF文件大小。也就是当前AOF文件比上一次重写后AOF文件的增量大小，和上一次重写后AOF文件大小的比值。</li></ol><p>AOF文件大小同时超出上面这两个配置项时，会触发AOF重写。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://time.geekbang.org/column/article/271754">https://time.geekbang.org/column/article/271754</a></li><li><a href="https://juejin.cn/post/6844903702373859335">https://juejin.cn/post/6844903702373859335</a> </li><li>Redis设计与实现</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis持久化机制-AOF&quot;&gt;&lt;a href=&quot;#Redis持久化机制-AOF&quot; class=&quot;headerlink&quot; title=&quot;Redis持久化机制-AOF&quot;&gt;&lt;/a&gt;Redis持久化机制-AOF&lt;/h1&gt;&lt;h1 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1
      
    
    </summary>
    
    
      <category term="数据存储" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>Redis IO 模型</title>
    <link href="https://www.llchen60.com/Redis-IO-%E6%A8%A1%E5%9E%8B/"/>
    <id>https://www.llchen60.com/Redis-IO-%E6%A8%A1%E5%9E%8B/</id>
    <published>2021-07-02T18:54:57.000Z</published>
    <updated>2021-07-02T18:59:13.678Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-IO-模型"><a href="#Redis-IO-模型" class="headerlink" title="Redis IO 模型"></a>Redis IO 模型</h1><blockquote><p>为什么单线程的Redis会那么快？</p></blockquote><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>这里的单线程主要指Redis的网络IO和键值对读写是由一个线程来完成的，而Redis的其他功能，比如持久化，异步删除，集群数据同步等，是由额外的线程执行的。</p><h1 id="2-为什么要使用单线程？"><a href="#2-为什么要使用单线程？" class="headerlink" title="2. 为什么要使用单线程？"></a>2. 为什么要使用单线程？</h1><ul><li><p>使用多线程的开销</p><ul><li><p>使用多线程，一定程度上可以增加系统的吞吐率/ 拓展性</p></li><li><p>但是值得注意的是多线程本身有开销，并不是线程增多吞吐率会线性增长的。达到了某个线程数之后，系统吞吐率的增长就会开始迟缓了，有时甚至会出现下降的情况</p><p><img src="https://i.loli.net/2020/12/24/UNVLxyIRokWmjTQ.png" alt="吞吐率Metrics"></p><p>吞吐率随着线程数增长的变化</p></li><li><p>出现这种情况的原因在于</p><ul><li>系统中通常会存在被<strong>多线程同时访问的共享资源</strong> — 比如一个共享的数据结构</li><li>当有多个线程要修改这个共享资源的时候，为了保证共享资源的正确性，就需要有额外的机制进行保证。这会带来额外的开销</li></ul></li></ul></li><li><p>Redis采用单线程就是希望能够避免这种共享资源放锁的情况</p><ul><li>而且CPU往往不是Redis的瓶颈，瓶颈很可能是机器内存或者网络带宽</li></ul></li></ul><h1 id="3-单线程Redis是如何实现低延时的"><a href="#3-单线程Redis是如何实现低延时的" class="headerlink" title="3. 单线程Redis是如何实现低延时的"></a>3. 单线程Redis是如何实现低延时的</h1><ul><li>High Level Takeaway<ul><li>内存上完成操作</li><li>高效的数据结构</li><li>多路复用机制 — 网络IO能够并发处理大量的客户端请求</li></ul></li></ul><h2 id="3-1-基本IO模型和阻塞点"><a href="#3-1-基本IO模型和阻塞点" class="headerlink" title="3.1  基本IO模型和阻塞点"></a>3.1  基本IO模型和阻塞点</h2><p>以前面的SimpleKV为例，为了处理一个Get请求，数据库需要：</p><ol><li>监听客户端请求(bind/ listen)</li><li>和客户端建立连接 (accept)</li><li>从socket中读取请求(recv)</li><li>解析客户端发送请求(parse)</li><li>根据请求类型读取键值数据(get)</li><li>从客户端返回结果，即向socket中写回数据(send)</li></ol><p><img src="https://i.loli.net/2020/12/24/1pFsDaMO452fGkQ.png" alt="处理IO流程"></p><p>Get请求处理示意图</p><p>在上述的整个过程当中，如果Redis监听到客户端请求，但没有成功建立连接的时候，<strong>会阻塞在accept函数上，导致其他的客户端无法建立连接</strong>。这种基本IO模型效率会非常低，因为是阻塞式的，任何一个请求出现了任何一个问题，都会导致其他的请求无法成功完成。</p><h2 id="3-2-非阻塞模式"><a href="#3-2-非阻塞模式" class="headerlink" title="3.2 非阻塞模式"></a>3.2 非阻塞模式</h2><p>Socket网络模型的非阻塞模式体现在不同操作调用后会<strong>返回不同的套接字类型</strong>。socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。</p><p>这样子可以实现非阻塞，值得注意的是我们需要一些机制来监听套接字，有数据到达的时候再通知数据库线程</p><h2 id="3-3-基于多路复用的高性能I-O模型"><a href="#3-3-基于多路复用的高性能I-O模型" class="headerlink" title="3.3  基于多路复用的高性能I/O模型"></a>3.3  基于多路复用的高性能I/O模型</h2><ul><li>是什么<ul><li>指让一个线程能够处理多个IO流</li><li>select epoll机制<ul><li>在内核中，存在多个监听套接字和已连接套接字</li><li>内核会一直监听这些套接字上的连接请求或者数据请求</li></ul></li></ul></li><li>为什么使用I/O多路复用这种技术<ul><li>解决单线程下阻塞操作的问题</li></ul></li><li>如何实现的<ul><li>select epoll方法同时监控多个文件描述符FD的读写情况，当某些FD可读/ 可写的时候，该方法就会返回可读/ 写的FD个数<br><a href="https://cloud.tencent.com/developer/article/1639569">IO多路复用：Redis中经典的Reactor设计模式</a><ul><li>将用户Socket对应的FD注册进epoll，然后epoll告诉那些需要进行读写操作的socket，只处理那些活跃的，有变化的socket FD</li></ul></li></ul></li></ul><p><a href="https://draveness.me/redis-io-multiplexing/">https://draveness.me/redis-io-multiplexing/</a></p><p><a href="https://cloud.tencent.com/developer/article/1639569">https://cloud.tencent.com/developer/article/1639569</a></p><p><a href="https://blog.csdn.net/u014590757/article/details/79860766">https://blog.csdn.net/u014590757/article/details/79860766</a></p><ul><li><p>一个线程处理多个IO流 — select / epoll机制</p><p>  <img src="https://i.loli.net/2020/12/24/QUKfj9ExTgy4tMN.png" alt="select/ epoll机制流程"></p><p>  epoll机制</p><ul><li><p>允许内核中，同时存在多个监听套接字和已连接套接字</p></li><li><p>内核会一直监听这些套接字上的连接请求或数据请求</p></li><li><p>一旦有请求到达，就会交给Redis线程处理</p><p><img src="https://i.loli.net/2020/12/24/4Cp7TQMZ3csAUIm.png" alt="epoll过程"></p><p>多路复用全程</p></li></ul></li><li><p>select/ epoll 一旦检测到FD上有请求到达，就会触发相应的事件</p><ul><li>事件会被放到一个事件队列，Redis单线程对该事件队列不断进行处理</li></ul></li></ul><h2 id="3-3-单线程处理的性能瓶颈"><a href="#3-3-单线程处理的性能瓶颈" class="headerlink" title="3.3 单线程处理的性能瓶颈"></a>3.3 单线程处理的性能瓶颈</h2><p>1、任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：</p><p>a、操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；</p><p>b、使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；</p><p>c、大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；</p><p>d、淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；</p><p>e、AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；</p><p>f、主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；</p><p>2、并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。</p><p>针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。</p><p>针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis-IO-模型&quot;&gt;&lt;a href=&quot;#Redis-IO-模型&quot; class=&quot;headerlink&quot; title=&quot;Redis IO 模型&quot;&gt;&lt;/a&gt;Redis IO 模型&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;为什么单线程的Redis会那么快？&lt;/p&gt;
      
    
    </summary>
    
    
      <category term="数据存储" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="Redis" scheme="https://www.llchen60.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis数据结构</title>
    <link href="https://www.llchen60.com/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <id>https://www.llchen60.com/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</id>
    <published>2021-07-02T18:18:24.000Z</published>
    <updated>2021-07-02T18:57:33.511Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis数据结构"><a href="#Redis数据结构" class="headerlink" title="Redis数据结构"></a>Redis数据结构</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>Redis的快速除了基于内存的原因以外，另外一个是在其数据结构上的操作执行的很快。这里会走一遍Redis的现有数据结构，总结其各自的特点，Redis的数据类型和其底层数据结构的对应关系。</p><p><img src="https://i.loli.net/2021/07/03/L6sH52KacFyROMf.png" alt="Redis数据类型和底层数据结构对应关系"></p><ul><li>Redis底层共有6中基本数据结构，其有着不同的和Redis的数据类型的对应</li><li>List, Hash, Sorted Set, 以及Set都有两种实现结构</li></ul><h1 id="2-键值之间的对应关系如何组织"><a href="#2-键值之间的对应关系如何组织" class="headerlink" title="2. 键值之间的对应关系如何组织"></a>2. 键值之间的对应关系如何组织</h1><h2 id="2-1-全局哈希表"><a href="#2-1-全局哈希表" class="headerlink" title="2.1 全局哈希表"></a>2.1 全局哈希表</h2><ul><li>Redis使用一个哈希表来保存所有的键值对</li><li>一个哈希表由多个哈希桶组成，每个哈希桶保存了键值对数据</li><li>哈希桶当中的entry元素这能够保存的是key和value的指针，分别指向实际的键值</li></ul><p><img src="https://i.loli.net/2021/07/03/tXTca4hIin1zNyH.png" alt="全局哈希表"></p><ul><li>访问流程为<ul><li>计算键的哈希值</li><li>访问到对应的哈希桶</li><li>根据哈希桶来找到key和value的地址</li></ul></li><li>为什么需要哈希桶？<ul><li>因为值的底层实现会是不一样的，这样子哈希桶所占内存空间是整齐且可控的</li><li>然后通过指针来找到在内存当中的具体地址</li><li>这个时候value 是可以分散的放置在内存块当中的</li></ul></li></ul><h2 id="2-2-哈希表的冲突问题"><a href="#2-2-哈希表的冲突问题" class="headerlink" title="2.2 哈希表的冲突问题"></a>2.2 哈希表的冲突问题</h2><ul><li>哈希冲突不可避免，即两个key的哈希值和哈希桶计算对应关系的时候，落到了同一个哈希桶当中了</li><li>解决方式<ul><li>短期解决方案<ul><li>链式哈希<ul><li>同一个哈希桶中多个元素用一个链表来保存，依次用指针连接</li><li>注意新的元素会加到头上</li></ul></li><li>存在的问题<ul><li>当哈希冲突链变得过长，查找速度会退化，无法实现O(1)了</li></ul></li></ul></li><li>中长期解决方案<ul><li>rehash  —→ 增加现有的哈希桶数量<ul><li>是逐渐增多的entry在更多的桶之间分散保存</li></ul></li></ul></li></ul></li></ul><h2 id="2-3-哈希表Rehash策略"><a href="#2-3-哈希表Rehash策略" class="headerlink" title="2.3 哈希表Rehash策略"></a>2.3 哈希表Rehash策略</h2><ul><li><p>整体流程</p><ul><li>首先Redis默认有两个全局哈希表</li><li>当你插入数据的时候，默认使用哈希表1， 此时哈希表2没有被分配空间</li><li>随着数据增多，Redis开始执行rehash<ul><li>给哈希表2分配更大的空间，例如是1的两倍</li><li>将哈希表1中的数据重新映射并拷贝到哈希表2当中<ul><li>这一步会涉及到大量的数据拷贝，会造成Redis线程阻塞</li></ul></li><li>释放哈希表1的空间</li></ul></li><li>另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表</li></ul></li><li><p>渐进式哈希</p><ul><li>是为了解决在做哈希表的复制过程当中，可能造成的线程阻塞问题</li><li>一次处理分成多次，处理请求的时候顺带着更新的哈希表2当中</li><li>rehash的整体流程<ol><li>为 <code>ht[1]</code> 分配空间，让字典同时持有 <code>ht[0]</code> 和 <code>ht[1]</code> 两个哈希表。</li><li>在字典中维持一个索引计数器变量 <code>rehashidx</code> ，并将它的值设置为 <code>0</code> ，表示 rehash 工作正式开始。</li><li>在 rehash 进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将 <code>ht[0]</code> 哈希表在 <code>rehashidx</code> 索引上的所有键值对 rehash 到 <code>ht[1]</code> ，当 rehash 工作完成之后，程序将 <code>rehashidx</code> 属性的值增 <code>1</code></li><li>随着字典操作的不断执行，最终在某个时间点上，<code>ht[0]</code> 的所有键值对都会被 rehash 至 <code>ht[1]</code> ，这时程序将 <code>rehashidx</code> 属性的值设为 <code>1</code> ，表示 rehash 操作已完成。</li></ol></li><li>在渐进式哈希没有完成的时候，会同时所使用 <code>ht[0]</code> 还有 <code>ht[1]</code> 两个哈希表<ul><li>delete find update等操作都会在两个哈希表上进行</li><li>先在 <code>ht[0]</code> 然后再在 <code>ht[1]</code></li><li>而对于添加操作，会一律被保存到 <code>ht[1]</code></li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2021/07/03/pGzqNjfegolP7Lt.png" alt="渐进式哈希的实现"></p><h1 id="3-值的底层实现"><a href="#3-值的底层实现" class="headerlink" title="3. 值的底层实现"></a>3. 值的底层实现</h1><h2 id="3-1-简单动态字符串"><a href="#3-1-简单动态字符串" class="headerlink" title="3.1 简单动态字符串"></a>3.1 简单动态字符串</h2><h3 id="3-1-1-什么是简单动态字符串？"><a href="#3-1-1-什么是简单动态字符串？" class="headerlink" title="3.1.1 什么是简单动态字符串？"></a>3.1.1 什么是简单动态字符串？</h3><ul><li>Simple Dynamic String — SDS</li><li>Redis需要一个可以被修改的字符串值<ul><li>利用SDS来做键值</li><li>也会被用来做缓冲区<ul><li>AOF缓冲区</li><li>客户端状态下的输入缓冲区</li></ul></li></ul></li><li>定义</li></ul><pre><code class="jsx">struct sdshrd &#123;    // 计算buf数组已经使用的字节的数量    int len;    // 记录buf数组未使用的字节的数量    int free;    // 字节数组，用来保存字符串    char buf[];&#125;</code></pre><p><img src="https://i.loli.net/2021/07/03/ALkWVo5jDeX1fyY.png" alt="简单动态字符串的实现"></p><h3 id="3-1-2-为什么需要SDS？"><a href="#3-1-2-为什么需要SDS？" class="headerlink" title="3.1.2 为什么需要SDS？"></a>3.1.2 为什么需要SDS？</h3><ul><li>相比于常规string的优势在于：<ul><li>常数复杂度获取字符串长度<ul><li>有len字段</li><li>设置和更新长度是在API执行过程当中自动完成的</li></ul></li><li>杜绝了缓冲区溢出<ul><li>C字符串不会记录自身长度，容易造成缓冲区溢出—buffer overflow</li><li>可能造成一些数据意外被修改</li><li>而SDS的空间分配策略可以杜绝发生溢出的可能性<ul><li>API会检测free标注的大小</li><li>如果不够，那么就会进行扩展</li></ul></li></ul></li><li>减少了内存重分配次数<ul><li>在C里面如果你做增加或者删除的操作，都会涉及内存重分配</li></ul></li></ul></li><li>空间优化策略<ul><li>空间预分配<ul><li>当需要扩展的时候，程序不仅为SDS分配修改所必须的空间，还会为SDS分配额外的未使用空间</li></ul></li><li>惰性空间释放<ul><li>缩短的时候并不立即使用内存重分配来回收缩短后多出来的字节</li><li>使用free属性将这些字节的数量记录起来，并等待将来使用</li></ul></li></ul></li></ul><h2 id="3-2-双向链表"><a href="#3-2-双向链表" class="headerlink" title="3.2 双向链表"></a>3.2 双向链表</h2><h3 id="3-2-1-概述"><a href="#3-2-1-概述" class="headerlink" title="3.2.1 概述"></a>3.2.1 概述</h3><ul><li>链表<ul><li>可以提供高效的节点重排能力，</li><li>顺序性的节点访问方法</li></ul></li><li>什么时候会被使用<ul><li>当一个列表包含了数量比较多的元素</li><li>列表当中包含的元素都是比较长的字符串</li></ul></li></ul><h3 id="3-2-2-链表和链表节点的实现"><a href="#3-2-2-链表和链表节点的实现" class="headerlink" title="3.2.2 链表和链表节点的实现"></a>3.2.2 链表和链表节点的实现</h3><pre><code class="jsx">typedef struct listNode &#123;    struct listNode *prev;    struct listNode *next;    void *value;&#125;listNode;</code></pre><pre><code class="jsx">typedef struct list &#123;    listNode *head;    listNode *tail;    // 链表包含的节点数量    unsigned long len;    // 节点值复制函数    void *(*dup)(void *ptr);    // 节点值释放函数    void (*free) (void *ptr);    // 节点值对比函数    void (*match)(void *ptr, void *key);&#125;</code></pre><ul><li><p>下方是由一个list结构和多个listNode结构组成的链表</p><p>  <img src="https://i.loli.net/2021/07/03/uJoTHhdLkr4qlAc.png" alt="list + multi listNodes"></p></li></ul><h2 id="3-3-哈希表-字典"><a href="#3-3-哈希表-字典" class="headerlink" title="3.3 哈希表(字典)"></a>3.3 哈希表(字典)</h2><h3 id="3-3-1-什么是字典"><a href="#3-3-1-什么是字典" class="headerlink" title="3.3.1 什么是字典"></a>3.3.1 什么是字典</h3><ul><li>用于保存键值对的数据结构</li><li>Redis自己构建了字典的实现</li><li>哈希表当中可以有多个哈希表节点，而每个哈希表节点就保存了字典当中的一个键值对</li></ul><h3 id="3-3-2-dictht-—-哈希表数组的实现"><a href="#3-3-2-dictht-—-哈希表数组的实现" class="headerlink" title="3.3.2 dictht — 哈希表数组的实现"></a>3.3.2 dictht — 哈希表数组的实现</h3><pre><code class="jsx">typedef struct dictht &#123;    // 哈希表数组    dictEntry **table;    // 哈希表大小    unsigned long size;    // 哈希表大小掩码，用于计算索引值    unsigned long sizemask;    // 已有节点数量    unsigned long used;&#125; dictht;</code></pre><ul><li><p>table是一个数组，数组的每个元素都指向dictEntry结构的指针</p><ul><li>每个dictEntry结构保存着一个键值对</li></ul></li><li><p>size记录哈希表大小</p></li><li><p>used记录目前已有节点的数量</p></li><li><p>sizemask总是等于size - 1</p><ul><li><p>这个属性和哈希值一起决定了一个键应该被放到table数组的哪个索引上面</p><p>  <img src="https://i.loli.net/2021/07/03/3QTOZK1YwX6VyfG.png" alt="dictht + dictEntry"></p></li></ul></li></ul><h3 id="3-3-3-哈希表节点的实现"><a href="#3-3-3-哈希表节点的实现" class="headerlink" title="3.3.3 哈希表节点的实现"></a>3.3.3 哈希表节点的实现</h3><ul><li>而哈希表节点是这么实现的<ul><li>值得注意的是有指向下一个节点的指针，是为了解决键的冲突问题</li></ul></li></ul><pre><code class="jsx">typedef struct dictEntry &#123;    void *key;    union &#123;        void *val;        unit64_tu64;        int64_ts64;    &#125; v;    // 指向下一个哈希表节点    struct dictEntry *next;&#125; dictEntry;</code></pre><h3 id="3-3-4-哈希表整体实现"><a href="#3-3-4-哈希表整体实现" class="headerlink" title="3.3.4 哈希表整体实现"></a>3.3.4 哈希表整体实现</h3><pre><code class="jsx">typedef struct dict &#123;    dictType *type;    void *privatedata;    dictht ht[2];    // rehash索引  当rehash停止了以后，值为-1     in rehashidx;&#125;</code></pre><ul><li>type和privatedata是针对不同类型的键值对，为创建多态字典而设置的</li><li>ht是一个大小为2的数组，都是哈希表<ul><li>一般只用ht[0]的哈希表</li><li>只有在做rehash的时候用ht[1]</li></ul></li><li>rehashidx 记录当前的进度</li><li>hashfunction<ul><li>使用MurmurHash2算法<ul><li>特点<ul><li>即使输入的键是有规律的，算法仍能给出一个很好的随机分布性</li><li>算法的计算速度也非常快</li></ul></li></ul></li></ul></li></ul><h2 id="3-4-跳表"><a href="#3-4-跳表" class="headerlink" title="3.4 跳表"></a>3.4 跳表</h2><h3 id="3-4-1-什么是跳表"><a href="#3-4-1-什么是跳表" class="headerlink" title="3.4.1 什么是跳表"></a>3.4.1 什么是跳表</h3><ul><li>为了解决链表的不足的<ul><li>有序链表只能逐一查找元素，导致操作起来非常缓慢</li></ul></li><li>跳表<ul><li>在链表的基础上增加了多级索引，通过索引位置的跳转，实现数据的快速定位</li><li>是有序集合的底层实现之一</li><li>支持平均O(logN), 最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/03/YgFw2MkjmpSvf7P.png" alt="跳表的实现"></p><h3 id="3-4-2-跳表的实现"><a href="#3-4-2-跳表的实现" class="headerlink" title="3.4.2 跳表的实现"></a>3.4.2 跳表的实现</h3><ul><li><p>由两大部分构成</p><ul><li><p>zskiplist 用来保存跳跃表节点的相关信息</p><ul><li>下图最左侧的方框</li><li>属性包括<ul><li>header — 指向跳跃表的表头节点</li><li>tail — 指向跳跃表的表尾节点</li><li>level — 记录当前跳跃表内，层数最大的那个节点的层数</li><li>length — 记录跳跃表的长度</li></ul></li></ul></li><li><p>zskiplistNode用于表示跳跃表单个节点</p><ul><li><p>属性包括</p><ul><li>level<ul><li>前进指针<ul><li>用于访问其他结点</li></ul></li><li>跨度<ul><li>记录了前进指针所指向节点和当前节点的距离</li><li>累加可以用来记录某个节点在跳表当中的排位</li></ul></li></ul></li><li>backward 后退指针<ul><li>指向位于当前节点的前一个节点</li><li>后退指针在程序从表尾向表头遍历的时候使用</li></ul></li><li>score</li><li>obj 成员对象<ul><li>是一个指针，指向一个字符串对象，</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/03/blB24Gdk5MzXIhH.png" alt="跳表实现"></p></li></ul></li></ul></li></ul><pre><code class="jsx">typedef struct zskiplistNode &#123;    struct zskiplistLevel &#123;        struct zskiplistNode *forward;         unsigned int span;    &#125; level[];    struct zskiplistNode *backward;    double score;    robj *obj;&#125; zskiplistNode;</code></pre><pre><code class="jsx">typedef struct zskiplist &#123;    struct zskiplistNode *header, *tail;    unsigned long length;     int level;&#125;</code></pre><h2 id="3-5-整数数组"><a href="#3-5-整数数组" class="headerlink" title="3.5 整数数组"></a>3.5 整数数组</h2><h3 id="3-5-1-什么是整数数组"><a href="#3-5-1-什么是整数数组" class="headerlink" title="3.5.1 什么是整数数组"></a>3.5.1 什么是整数数组</h3><ul><li>是set的底层实现之一，当一个集合只包含整数值元素，并且这个集合元素数量不多，Redis就会用整数集合作为集合键的底层实现</li></ul><h3 id="3-5-2-整数数组的实现"><a href="#3-5-2-整数数组的实现" class="headerlink" title="3.5.2 整数数组的实现"></a>3.5.2 整数数组的实现</h3><pre><code class="jsx">typedef struct intset &#123;    uinit32_t encoding;    uinit32_t length;  int8_t contents[];&#125;</code></pre><ul><li>encoding<ul><li>记录编码方式<ul><li>INTSET_ENC_INT16</li><li>INTSET_ENC_INT32</li><li>INTSET_ENC_INT64</li></ul></li></ul></li><li>length<ul><li>记录集合包含的元素数量</li></ul></li><li>contents<ul><li>数组，是其底层实现</li><li>整数数组的每个原色都是contents数组的一个item</li><li>各个项在数组中按照值的大小从小到大有序排列，数组中不包含任何重复项</li></ul></li></ul><h3 id="3-5-3-整数数组的升级和降级"><a href="#3-5-3-整数数组的升级和降级" class="headerlink" title="3.5.3 整数数组的升级和降级"></a>3.5.3 整数数组的升级和降级</h3><ul><li>什么时候需要升级？<ul><li>当添加一个新元素，且新元素的类型比整数集合现有的所有元素的类型都要长的时候</li></ul></li><li>如何进行升级<ul><li>根据新元素的类型，扩展整数集合底层数组的空间大小，并且为新元素分配空间</li><li>将底层数组现有所有元素都转换成和新元素相同的类型，并将类型转换后的元素放置到正确的位上</li><li>放置过程需要保证顺序不变</li><li>新元素添加到底层数组当中</li></ul></li><li>整数数组不支持降级！</li></ul><h2 id="3-6-压缩列表"><a href="#3-6-压缩列表" class="headerlink" title="3.6 压缩列表"></a>3.6 压缩列表</h2><h3 id="3-6-1-什么是压缩列表"><a href="#3-6-1-什么是压缩列表" class="headerlink" title="3.6.1 什么是压缩列表"></a>3.6.1 什么是压缩列表</h3><ul><li>类似一个数组<ul><li>每一个元素都对应保存一个数据</li><li>表头有三个字段<ul><li>zlbytes — 列表长度，整个压缩列表占用的字节数</li><li>zltail — 列表尾的偏移量</li><li>zllen — 列表中entry个数</li></ul></li><li>表尾一个字段<ul><li>zlend — 表示列表的结束</li></ul></li></ul></li><li>压缩列表是Redis为了节约内存而开发的，由一系列特殊编码的连续内存块组成的顺序型数据结构<ul><li>一个压缩列表可以包含任意多个节点</li><li>每个节点可以保存一个字节数组或者一个整数值</li><li>比起双端链表来说，更节约内存，而且内存当中连续的保存的方式，能更快的载入到缓存当中</li><li>随着列表对象包含的元素越来越多，使用压缩列表的优势会逐渐消失，对象就会从底层的压缩列表的实现转向双端链表上面</li></ul></li></ul><h3 id="3-6-2-压缩列表的实现"><a href="#3-6-2-压缩列表的实现" class="headerlink" title="3.6.2 压缩列表的实现"></a>3.6.2 压缩列表的实现</h3><ul><li><p>压缩列表节点的构成</p><ul><li><p>previous_entry_length</p><ul><li><p>字节为单位</p></li><li><p>记录压缩列表中前一个节点的长度</p></li><li><p>可以借此通过指针运算，从当前节点的起始地址来计算出前一个节点的起始地址</p></li><li><p>压缩列表的从表尾向表头遍历的操作就是使用这一原理实现的</p><p>  <img src="https://i.loli.net/2021/07/03/743T9ocpMWeksxH.png" alt="压缩列表从尾端向表头的遍历"></p></li></ul></li><li><p>encoding</p><ul><li>记录了节点的content属性所保存的数据类型和长度</li></ul></li><li><p>content</p><ul><li>负责保存节点的值<ul><li>可以使一个字节数组或者一个整数</li></ul></li></ul></li></ul></li></ul><h3 id="3-6-3-压缩列表的连锁更新"><a href="#3-6-3-压缩列表的连锁更新" class="headerlink" title="3.6.3 压缩列表的连锁更新"></a>3.6.3 压缩列表的连锁更新</h3><ul><li>假设一个原先节点长度小于254字节的增长大于了</li><li>那么原先用一个字节保存的previous_entry_length已然无法保存新的数据了，那么就需要对压缩列表执行空间重分配操作</li><li>连锁更新，最坏情况要对压缩列表执行N次空间重分配操作，而每次空间重分配的最坏复杂度为O(N)  所以连锁更新的最坏复杂度为O(N^2)</li><li>连锁更新出现概率比较低，只有在压缩列表当中恰好有多个连续，长度介于250 和253字节之间的节点的时候</li></ul><h2 id="3-7-对象"><a href="#3-7-对象" class="headerlink" title="3.7 对象"></a>3.7 对象</h2><ul><li>用对象来代表Redis对于底层数据结构的上层抽象<ul><li>字符串</li><li>双向链表</li><li>哈希表</li><li>集合</li><li>有序集合</li></ul></li><li>好处<ul><li>针对不同使用场景，为对象设置多种不同的底层数据结构实现，从而优化对象在不同场景下的使用效率</li><li>Redis对象系统实现了基于引用计数技术的内存回收机制</li><li>当程序不再使用某个对象的时候，这个对象所占用的内存就会被自动释放</li></ul></li></ul><h3 id="3-7-1-对象的实现"><a href="#3-7-1-对象的实现" class="headerlink" title="3.7.1 对象的实现"></a>3.7.1 对象的实现</h3><ul><li>键和值都是对象，都由redisObject结构来实现的<ul><li>type  用于记录对象的类型<ul><li>REDIS_STRING</li><li>REDIS_LIST<br>REDIT_HASH</li><li>REDIS_SET</li><li>REDIS_ZSET</li></ul></li><li>encoding 记录对象所使用的编码<ul><li>即对象试用了什么数据结构的底层实现</li></ul></li></ul></li></ul><pre><code class="jsx">typedef struct redisObject &#123;    unsigned type:4;    unsigned encoding:4;    void *ptr;&#125; robj;</code></pre><h3 id="3-7-2-字符串对象"><a href="#3-7-2-字符串对象" class="headerlink" title="3.7.2 字符串对象"></a>3.7.2 字符串对象</h3><ul><li><p>编码可以是</p><ul><li><p>int</p></li><li><p>raw</p><ul><li><p>当保存一个字符串值，且长度大于32字节</p><p>  <img src="https://i.loli.net/2021/07/03/gbGY6fzD3rF7okB.png" alt="字符串对象的raw编码方式"></p></li></ul></li><li><p>embstr</p><ul><li><p>当字符串值的长度小于等于32字节的时候，会用embstr编码方式</p></li><li><p>embstr介绍</p><ul><li><p>专门用于保存短字符串的优化编码方式</p></li><li><p>通过调用一次内存分配函数来分配一块连续空间，依次包含redisObject和sdshdr两个结构</p><p>  <img src="https://i.loli.net/2021/07/03/G6ozCbK1UkYRO4T.png" alt="字符串对象embstr编码方式"></p></li></ul></li></ul></li></ul></li><li><p>编码类型会在需要的时候进行自动的转换</p></li></ul><h3 id="3-7-3-列表对象"><a href="#3-7-3-列表对象" class="headerlink" title="3.7.3 列表对象"></a>3.7.3 列表对象</h3><ul><li><p>列表对象的编码方式是</p><ul><li><p>ziplist — 使用压缩列表来实现</p><p>  <img src="https://i.loli.net/2021/07/03/DHqScpNEFLiCxO7.png" alt="列表对象的压缩列表编码方式"></p></li><li><p>linkedlist — 使用双向链表来实现</p><p>  <img src="https://i.loli.net/2021/07/03/zndxC5jTAhNY7Ek.png" alt="列表对象的双向链表编码方式"></p></li></ul></li><li><p>注意：在上面的示意图当中，StringObject是做了简化的，相当于我在链表或者压缩列表对象里面嵌入了字符串对象，字符串本身是用的embstr编码方式实现的一个redisObject</p></li><li><p>编码转化规则</p><ul><li>使用ziplist的条件<ul><li>列表对象保存的所有字符串元素的长度都小于64字节</li><li>列表对象保存的元素数量小于512个</li></ul></li><li>条件是可以进行改变的，通过改变config paras:<ul><li><code>list-max-ziplist-value</code></li><li><code>list-max-ziplist-entries</code></li></ul></li></ul></li></ul><h3 id="3-7-4-哈希对象"><a href="#3-7-4-哈希对象" class="headerlink" title="3.7.4 哈希对象"></a>3.7.4 哈希对象</h3><ul><li><p>编码方式</p><ul><li><p>ziplist</p><ul><li><p>每当加新的键值对的时候，会将保存了键的压缩列表节点推入到压缩列表表尾，然后再将保存了值的压缩列表节点推入到压缩列表表尾</p><ul><li><p>保存了同一键值对的两个节点总是紧挨在一起</p></li><li><p>值得注意  用ziplist 来实现哈希，查找是无法做到O(1)的，但同时因为值少，所以影响不会很大  <a href="https://blog.csdn.net/zhoucheng05_13/article/details/79864568">https://blog.csdn.net/zhoucheng05_13/article/details/79864568</a></p></li><li><p>保存键的节点在前，保存值的节点在后</p><p>  <img src="https://i.loli.net/2021/07/03/bOavAyDF7u2KjhU.png" alt="哈希对象的压缩列表编码方式"></p></li></ul></li></ul></li><li><p>hashtable</p><p>  <img src="https://i.loli.net/2021/07/03/5AzFotmNTxdLySB.png" alt="哈希对象的hashtable编码方式"></p></li></ul></li><li><p>编码转换条件</p><ul><li>使用ziplist的条件<ul><li>所有键值对键值字符串长度都小于64字节</li><li>键值对数量小于512个</li></ul></li><li>修改阈值方式<ul><li><code>hash-max-ziplist-value</code></li><li><code>hash-max-ziplist-entries</code></li></ul></li></ul></li></ul><h3 id="3-7-5-集合对象"><a href="#3-7-5-集合对象" class="headerlink" title="3.7.5 集合对象"></a>3.7.5 集合对象</h3><ul><li><p>编码方式有</p><ul><li>intset<ul><li>使用整数集合作为底层实现</li></ul></li><li>hashtable<ul><li>使用自定作为底层实现</li></ul></li></ul></li><li><p>编码转换</p><ul><li>使用intset的条件<ul><li>集合对象保存的所有元素都是整数值</li><li>集合对象保存的元素数量不超过512个</li></ul></li></ul></li></ul><h3 id="3-7-6-有序集合对象"><a href="#3-7-6-有序集合对象" class="headerlink" title="3.7.6 有序集合对象"></a>3.7.6 有序集合对象</h3><ul><li><p>编码方式</p><ul><li><p>ziplist</p><ul><li><p>每个集合元素用两个紧挨在一起的压缩列表节点来进行保存</p></li><li><p>第一个结点保存member</p></li><li><p>第二个节点保存score</p><p>  <img src="https://i.loli.net/2021/07/03/1KvRnXyzwk54eLV.png" alt="有序集合对象的压缩列表编码方式"></p></li></ul></li><li><p>skiplist</p><ul><li><p>包括一个字典还有一个跳跃表</p><ul><li>zs1 按照分值从小到大保存了所有集合元素<ul><li>跳跃表节点的object属性保存了元素的成员</li><li>通过跳跃表 就可以对有序集合进行范围性操作了</li></ul></li><li>而字典创建了成员到分值的映射<ul><li>可以实现O(1)复杂度查找给定成员的分值</li></ul></li></ul><pre><code class="jsx">typedef struct zset &#123;  zskiplist *zs1;  dict *dict;&#125; zset;</code></pre><p><img src="https://i.loli.net/2021/07/03/KeBGYXIasS4JL71.png" alt="有序集合的跳表编码方式"></p></li></ul></li></ul></li><li><p>编码转换</p><ul><li>使用ziplist的条件<ul><li>元素数量小于128个</li><li>有序集合保存的元素成员长度小于64字节</li></ul></li></ul></li></ul><h1 id="4-内存和对象的生命周期"><a href="#4-内存和对象的生命周期" class="headerlink" title="4. 内存和对象的生命周期"></a>4. 内存和对象的生命周期</h1><h2 id="4-1-类型检查"><a href="#4-1-类型检查" class="headerlink" title="4.1 类型检查"></a>4.1 类型检查</h2><ul><li><p>有些指令需要底层的特定的数据结构的实现，所以需要进行类型检查</p></li><li><p>通过redisObject结构的type属性来实现</p><p>  <img src="https://i.loli.net/2021/07/03/F45sjTVhqWSaQfH.png" alt="LLEN类型检查逻辑"></p></li></ul><h2 id="4-2-内存回收"><a href="#4-2-内存回收" class="headerlink" title="4.2 内存回收"></a>4.2 内存回收</h2><ul><li>C语言不具备自动内存回收功能，所以Redis在自己的对象系统当中构建了一个引用计数 reference counting技术实现的内存回收机制</li><li>通过这一机制，程序可以通过跟踪对象的引用计数信息，在适当的时候自动释放对象进行内存回收</li><li>引用计数信息变化的方式<ul><li>创建对象，被初始化为1</li><li>当对象被一个新程序使用，+1</li><li>当对象不再被一个程序使用，-1</li><li>当引用计数值变为0，释放内存</li></ul></li></ul><h2 id="4-3-对象共享"><a href="#4-3-对象共享" class="headerlink" title="4.3 对象共享"></a>4.3 对象共享</h2><ul><li><p>highlight！ 只对包含整数值的字符串对象来进行共享，因为其他的类型的对象验证操作的时间复杂度比较高</p></li><li><p>通过引用计数来实现</p></li><li><p>如果键A使用值100，键B也要使用同样的值</p></li><li><p>那么键B的值指针会指向现在有的键A的值对象</p></li><li><p>然后共享的值对象的引用计数+1</p><p>  <img src="https://i.loli.net/2021/07/03/plCK4RXTqOrID8W.png" alt="SDS整数值对象共享"></p></li></ul><h2 id="4-4-对象的空转时长"><a href="#4-4-对象的空转时长" class="headerlink" title="4.4 对象的空转时长"></a>4.4 对象的空转时长</h2><ul><li>redisObject有个lru属性，来记录这个对象上次被访问的timestamp</li><li>如果服务器占用的内存数超过了设定的maxmemory选项，那么空转时间比较长的那部分键就会优先被服务器释放，从而回收内存</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>极客时间 — Redis核心技术与实战</li><li>《Redis设计与实现》</li><li><a href="http://redisbook.com/preview/dict/incremental_rehashing.html">http://redisbook.com/preview/dict/incremental_rehashing.html</a> </li><li><a href="https://blog.csdn.net/zhoucheng05_13/article/details/79864568">https://blog.csdn.net/zhoucheng05_13/article/details/79864568</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis数据结构&quot;&gt;&lt;a href=&quot;#Redis数据结构&quot; class=&quot;headerlink&quot; title=&quot;Redis数据结构&quot;&gt;&lt;/a&gt;Redis数据结构&lt;/h1&gt;&lt;h1 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; cla
      
    
    </summary>
    
    
      <category term="数据存储" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="Redis" scheme="https://www.llchen60.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Redis基本架构</title>
    <link href="https://www.llchen60.com/Redis%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/"/>
    <id>https://www.llchen60.com/Redis%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/</id>
    <published>2021-07-02T00:10:44.000Z</published>
    <updated>2021-07-02T17:28:59.329Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis基本架构"><a href="#Redis基本架构" class="headerlink" title="Redis基本架构"></a>Redis基本架构</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>为什么需要Redis</p><ul><li>key value内存数据库</li><li>支持丰富的数据结构，</li><li>性能非常高，可以支持很高的TPS</li></ul></li><li><p>在使用Redis过程中可能遇到的一些问题</p><ul><li>CPU使用方面的问题<ul><li>数据结构的复杂度</li><li>跨CPU核的访问</li></ul></li><li>内存使用方面<ul><li>主从同步和AOF的内存竞争</li></ul></li><li>存储持久化方面<ul><li>SSD上做快照的性能抖动</li></ul></li><li>网络通信方面<ul><li>多实例时的异常网络丢包</li></ul></li></ul></li><li><p>如何进行学习 — 需要系统化</p><ul><li><p>从应用维度和系统维度进行研究</p></li><li><p>分别看其在以下三个方面的表现</p><ul><li><p>高性能</p><ul><li>线程模型</li><li>数据结构</li><li>持久化</li><li>网络框架</li></ul></li><li><p>高可靠</p><ul><li>主从复制</li><li>哨兵机制</li></ul></li><li><p>高可扩展性</p><ul><li><p>数据分片</p></li><li><p>负载均衡</p><p>  <img src="https://i.loli.net/2020/12/20/vKdkl934yUw7pOe.png" alt="Redis系统"></p></li></ul></li></ul></li></ul></li></ul><h2 id="2-如何构建一个键值数据库"><a href="#2-如何构建一个键值数据库" class="headerlink" title="2. 如何构建一个键值数据库"></a>2. 如何构建一个键值数据库</h2><ul><li>目标<ul><li>创建一个叫做SimpleKV的数据库</li></ul></li><li>几个需要思考的问题<ul><li>问题<ul><li>里面会存什么样的数据 (数据模型)</li><li>需要对数据做什么样的操作 (操作接口)</li></ul></li><li>为什么需要思考这种问题？<ul><li>这影响到你认为这个数据库到底能做什么</li><li>譬如如果支持集合，那么对于存储用户信息的一个关系型数据库，我们也可以将用户Id作为Key，剩余信息作为一个集合存储到我们的键值数据库当中<ul><li>这个点很有意思，可以直接将Redis当成一个数据库来使用</li></ul></li><li>接口的定义确定了我们希望使用这个数据库做什么，是简单的get, put操作，还是说相对复杂的聚合型的操作</li></ul></li></ul></li><li>脉络<ul><li>访问框架</li><li>操作模块<ul><li>内存空间分配 — 分配器</li><li>持久化</li></ul></li><li>索引模块</li></ul></li></ul><hr><h2 id="2-1-可以存哪些数据？"><a href="#2-1-可以存哪些数据？" class="headerlink" title="2.1 可以存哪些数据？"></a>2.1 可以存哪些数据？</h2><ul><li>基本数据类型 Key - Value</li><li>希望Value能够支持复杂类型<ul><li>memcache只支持String</li><li>Redis支持String, HashMap, 列表，集合等<ul><li>值得注意的点是不同的数据结构在实际使用的时候会有在性能，空间效率等方面的差异，从而导致不同的value操作之间也会存在差异</li></ul></li></ul></li></ul><h2 id="2-2-可以对数据做什么操作？"><a href="#2-2-可以对数据做什么操作？" class="headerlink" title="2.2 可以对数据做什么操作？"></a>2.2 可以对数据做什么操作？</h2><ul><li>PUT/ SET<ul><li>新写入或者更新一个KV对</li></ul></li><li>GET<ul><li>根据KEY读取相应的VALUE值</li></ul></li><li>DELETE<ul><li>根据KEY删除整个KV对</li></ul></li><li>SCAN<ul><li>根据一段Key的范围返回相应的value值</li></ul></li><li>Tips<ul><li>当一个键值数据库的value类型多样的时候，也需要包含相应的操作接口的</li></ul></li></ul><h2 id="2-3-数据库存储位置"><a href="#2-3-数据库存储位置" class="headerlink" title="2.3 数据库存储位置"></a>2.3 数据库存储位置</h2><ul><li>可选方案<ul><li>内存<ul><li>读写非常快</li><li>访问速度在百ns级别</li><li>潜在风险是一旦断电，所有的数据都会丢失</li></ul></li><li>外存<ul><li>可以避免数据的丢失，但是受限于磁盘的慢速读写（几个ms）键值数据库的整体性能会被拉低</li></ul></li></ul></li><li>考量的因素<ul><li>主要应用场景<ul><li>缓存场景<ul><li>需要能够快速访问但允许丢失 — 可以采用内存保存键值数据</li><li>memcache 和Redis都属于内存键值数据库</li></ul></li></ul></li></ul></li></ul><h2 id="2-4-数据库基本组件"><a href="#2-4-数据库基本组件" class="headerlink" title="2.4 数据库基本组件"></a>2.4 数据库基本组件</h2><ul><li>一个基本的内部结构需要包括<ul><li>访问框架<ul><li>动态库访问</li><li>网络访问框架</li></ul></li><li>操作模块<ul><li>上述的一系列操作 DELETE/PUT/SCAN etc</li></ul></li><li>索引模块</li><li>存储模块</li></ul></li></ul><p><img src="https://i.loli.net/2020/12/20/ILR4uFc73ZVmevP.png" alt="SimpleKV基本内部架构"></p><p>SimpleKV 内部架构</p><ul><li>采用什么访问模式？— 连接层<ul><li>通过函数库调用的方式供外部应用使用<ul><li>比如图片当中的<code>libsimplekv.so</code> 就是通过动态链接库的形式链接到我们的程序当中，来提供键值存储功能<ul><li>在运行的时候载入的包，而不是像静态库一样在编译的时候就和目标代码进行连接</li><li>这样做可以减少对于空间的浪费，解决了静态库对程序的更新，部署和发布带来的麻烦</li><li><a href="https://www.zhihu.com/question/20484931">https://www.zhihu.com/question/20484931</a></li></ul></li></ul></li><li>通过网络框架以Socket通信的形式对外提供键值对操作<ul><li>系统设计上的问题 — 单线程，多线程还是多个进程来进行交互？<strong>IO模型的选择</strong><ul><li>网络连接的处理</li><li>网络请求的解析</li><li>数据存取的处理</li></ul></li></ul></li></ul></li><li>如何定位键值对的位置？<ul><li>需要依赖于键值数据库的索引模块<ul><li>让键值数据库能够根据key找到相应value的存储位置，进而执行操作<ul><li>索引类型<ul><li>哈希表</li><li>B+树</li><li>字典树</li></ul></li><li>Redis选用的是哈希表，是因为保存在内存中，内存的高性能随机访问特性可以很好地与哈希表O(1)的操作复杂度匹配<ul><li>关于Redis值得注意的是它的value支持多种类型，当我们通过索引找到一个key对应的value后，仍然需要从value的复杂结构中进一步找到我们实际需要的数据</li><li>这个的复杂度取决于具体的数据类型</li><li>Redis采用一些高效索引结构作为某些value类型的底层数据结构，可以为Redis实现高性能访问提供良好的支撑</li></ul></li></ul></li></ul></li></ul></li><li>不同操作的具体逻辑是？<ul><li>对于GET/SCAN 操作而言，根据value的存储位置返回value的值即可</li><li>对于PUT操作，需要为新的键值对分配内存空间<ul><li>—&gt; 如何分配内存空间呢？</li><li>比较重要，当我们的value能支持多种类型的时候，那么如何高效使用内存空间就变得尤为重要了</li></ul></li><li>对于DELETE操作，需要删除键值对，并释放相应的内存空间，这个过程由分配器完成</li></ul></li><li>内存分配器<ul><li>采用内存分配器glibc的malloc和free<ul><li>但是键值对因为通常大小不一，glibc分配器在处理随机大小的内存块分配时表现会不太好。一旦保存的键值对数据规模过大，就可能造成较为严重的内存碎片的问题</li></ul></li></ul></li><li>如何实现重启后快速提供服务？<ul><li>持久化功能<ul><li>采用文件形式，将键值数据通过调用本地文件系统的操作接口保存在磁盘上<ul><li>需要考虑什么时候，什么间隔来做从内存到文件的键值数据的保存工作</li></ul></li><li>也可以每一个键值对都进行持久化<ul><li>坏处是因为每次都要写到磁盘里面，性能会受到很大影响</li><li>好处是能确保所有数据更新都会在磁盘里</li></ul></li><li>可以周期性的将内存中的键值数据保存到文件当中，这样就可以避免频繁写盘操作的性能影响<ul><li>潜在的风险就是数据仍然有可能丢失</li></ul></li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2020/12/20/52Hgk6apwXFtzSU.png" alt="SimpleKV与Redis的比较"></p><p>SimpleKV vs Redis</p><ul><li>SimpleKV和Redis的对比<ul><li>Redis通过网络访问，可以作为一个基础性的网络服务来进行访问</li><li>value类型丰富，就带来了更多的操作接口<ul><li>面向列表的LPush/ LPop</li><li>面向集合的SADD</li></ul></li><li>Redis持久化模块支持日志(AOF)和快照(RDB)两种模式</li><li>Redis支持高可靠集群和高可扩展集群</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.usenix.org/conference/atc17/technical-sessions/presentation/xia">HiKV: A Hybrid Index Key-Value Store for DRAM-NVM Memory Systems</a></li><li>极客时间 - Redis核心技术与实战</li><li><a href="https://www.zhihu.com/question/20484931">https://www.zhihu.com/question/20484931</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis基本架构&quot;&gt;&lt;a href=&quot;#Redis基本架构&quot; class=&quot;headerlink&quot; title=&quot;Redis基本架构&quot;&gt;&lt;/a&gt;Redis基本架构&lt;/h1&gt;&lt;h1 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; cla
      
    
    </summary>
    
    
      <category term="数据存储" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
      <category term="Redis" scheme="https://www.llchen60.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>JVM垃圾回收</title>
    <link href="https://www.llchen60.com/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <id>https://www.llchen60.com/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</id>
    <published>2021-07-01T04:40:35.000Z</published>
    <updated>2021-07-01T04:43:43.866Z</updated>
    
    <content type="html"><![CDATA[<h1 id="JVM垃圾回收"><a href="#JVM垃圾回收" class="headerlink" title="JVM垃圾回收"></a>JVM垃圾回收</h1><ul><li>内存是如何分配和回收的</li><li>哪些垃圾需要回收</li><li>什么时候回收</li><li>如何回收</li></ul><h1 id="1-堆的基本结构"><a href="#1-堆的基本结构" class="headerlink" title="1. 堆的基本结构"></a>1. 堆的基本结构</h1><p><img src="https://i.loli.net/2021/07/01/h3pULFu4rDBA9ei.png" alt="堆的基本结构"></p><ul><li>对象首先在Eden区域分配</li><li>在第一次新生代垃圾回收之后<ul><li>如果对象还存活，就会进入s0或者s1</li><li>对象的年龄还会加1</li><li>当其年龄增加到15岁的时候，就会晋升到老年代</li></ul></li><li>对象晋升到老年代的年龄阈值，可以通过参数 <code>-XX:MaxTenuringThreshold</code> 来进行设置</li><li>每次GC后，Eden区和From区会被清空，然后to和from会替换<ul><li>即新的To就是上次GC的From</li><li>当to区被填满的时候，会将所有对象移动到老年代当中</li></ul></li></ul><h1 id="2-堆的分配策略"><a href="#2-堆的分配策略" class="headerlink" title="2. 堆的分配策略"></a>2. 堆的分配策略</h1><h2 id="2-1-对象优先在eden区分配"><a href="#2-1-对象优先在eden区分配" class="headerlink" title="2.1 对象优先在eden区分配"></a>2.1 对象优先在eden区分配</h2><ul><li>优先在eden区进行分配</li><li>如果eden区已经几乎被分配完了，虚拟机就会发起一次minor GC</li><li>取决于是否survivor区有足够的空间<ul><li>会先放到survivor区</li><li>或者将新生代的对象提前转移到了老年代当中</li><li>如果老年代也空间不够，那就会导致full GC的出现了</li></ul></li></ul><h2 id="2-2-大对象直接进入老年代"><a href="#2-2-大对象直接进入老年代" class="headerlink" title="2.2 大对象直接进入老年代"></a>2.2 大对象直接进入老年代</h2><p>大对象是需要大量连续内存空间的对象，比如字符串，数组等。  为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。</p><ul><li>分配担保机制<ul><li>一个权衡，是把现在正在处理的大对象放到永久代里面</li><li>还是说把现在在eden的一些对象放到永久代当中</li><li><a href="https://cloud.tencent.com/developer/article/1082730" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1082730</a></li></ul></li></ul><h2 id="2-3-长期存活的对象将进入老年代"><a href="#2-3-长期存活的对象将进入老年代" class="headerlink" title="2.3 长期存活的对象将进入老年代"></a>2.3 长期存活的对象将进入老年代</h2><p>如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。</p><p>“Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的 50% 时（默认值是 50%，可以通过 <strong>-XX:TargetSurvivorRatio=percent</strong> 来设置，参见 issue1199 ），取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值”。</p><pre><code class="jsx">uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) { //survivor_capacity是survivor空间的大小 size_t desired_survivor_size = (size_t)((((double)survivor_capacity)*TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; while (age &lt; table_size) {     //sizes数组是每个年龄段对象大小     total += sizes[age];     if (total &gt; desired_survivor_size) {         break;     }     age++; } uint result = age &lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; ...}</code></pre><h1 id="3-如何判断对象的死亡"><a href="#3-如何判断对象的死亡" class="headerlink" title="3. 如何判断对象的死亡"></a>3. 如何判断对象的死亡</h1><h2 id="3-1-判断对象无效的方法"><a href="#3-1-判断对象无效的方法" class="headerlink" title="3.1 判断对象无效的方法"></a>3.1 判断对象无效的方法</h2><h3 id="3-1-1-引用计数法"><a href="#3-1-1-引用计数法" class="headerlink" title="3.1.1 引用计数法"></a>3.1.1 引用计数法</h3><ul><li>给对象添加引用计数器<ul><li>多一个地方引用它，计数器就加1</li><li>当引用失效，计数器就减1</li><li>任何时候计数器为0的对象就是不可能再被使用的</li></ul></li><li>主流的虚拟机并没有使用这个算法，因为很难解决对象之间相互循环引用的问题</li></ul><h3 id="3-1-2-可达性分析算法"><a href="#3-1-2-可达性分析算法" class="headerlink" title="3.1.2 可达性分析算法"></a>3.1.2 可达性分析算法</h3><ul><li>从GC Roots对象作为起点开始向下搜索，节点所走过的路径称为引用链</li><li>当一个对象到GC Roots没有任何引用链相连的话，就证明此对象不可用</li><li>可以作为GC Roots的对象包括<ul><li>虚拟机栈当中引用的对象</li><li>本地方法栈中引用的对象</li><li>方法区中类静态属性引用的对象</li><li>方法区中常量引用的对象</li><li>所有被同步锁持有的对象</li></ul></li></ul><h2 id="3-2-引用的类别"><a href="#3-2-引用的类别" class="headerlink" title="3.2 引用的类别"></a>3.2 引用的类别</h2><h3 id="3-2-1-强引用-StrongReference"><a href="#3-2-1-强引用-StrongReference" class="headerlink" title="3.2.1 强引用  StrongReference"></a>3.2.1 强引用  StrongReference</h3><p>我们当前常使用的基本都属于强引用，如果一个对象具有强引用，那么垃圾回收期绝对不会回收它</p><h3 id="3-2-2-软引用-SoftReference"><a href="#3-2-2-软引用-SoftReference" class="headerlink" title="3.2.2 软引用 SoftReference"></a>3.2.2 软引用 SoftReference</h3><p>如果内存空间足够，GC不会回收</p><p>如果内存空间不足，就会回收这些对象的内存</p><p>软引用可以用来实现内存敏感的高速缓存, 软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 </p><h3 id="3-2-3-弱引用-WeakReference"><a href="#3-2-3-弱引用-WeakReference" class="headerlink" title="3.2.3 弱引用 WeakReference"></a>3.2.3 弱引用 WeakReference</h3><p>弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。</p><h3 id="3-2-4-虚引用-PhantomReference"><a href="#3-2-4-虚引用-PhantomReference" class="headerlink" title="3.2.4 虚引用 PhantomReference"></a>3.2.4 虚引用 PhantomReference</h3><p>“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要用来跟踪对象被垃圾回收的活动。</p><h2 id="3-3-不可达的类是否必须要回收"><a href="#3-3-不可达的类是否必须要回收" class="headerlink" title="3.3 不可达的类是否必须要回收"></a>3.3 不可达的类是否必须要回收</h2><p>要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行<br>finalize 方法。当对象没有覆盖 finalize 方法，或 finalize<br>方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。</p><p>被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。</p><h2 id="3-4-如何判断一个类是无用的类"><a href="#3-4-如何判断一个类是无用的类" class="headerlink" title="3.4 如何判断一个类是无用的类"></a>3.4 如何判断一个类是无用的类</h2><p>类需要同时满足下面 3 个条件才能算是 <strong>“无用的类”</strong> ：</p><ul><li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li><li>加载该类的 <code>ClassLoader</code> 已经被回收。</li><li>该类对应的 <code>java.lang.Class</code> 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li></ul><h1 id="4-垃圾收集算法"><a href="#4-垃圾收集算法" class="headerlink" title="4. 垃圾收集算法"></a>4. 垃圾收集算法</h1><ul><li>标记清除</li><li>标记复制</li><li>标记整理</li><li>分代收集</li></ul><h1 id="5-垃圾收集器"><a href="#5-垃圾收集器" class="headerlink" title="5. 垃圾收集器"></a>5. 垃圾收集器</h1><h2 id="5-1-HotSpot-VM-GC-分类"><a href="#5-1-HotSpot-VM-GC-分类" class="headerlink" title="5.1 HotSpot VM GC 分类"></a>5.1 HotSpot VM GC 分类</h2><ul><li>部分收集 (Partial GC)：<ul><li>新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；</li><li>老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；</li><li>混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。</li></ul></li><li>整堆收集 (Full GC)：收集整个 Java 堆和方法区。</li></ul><h2 id="5-2-Serial-收集器"><a href="#5-2-Serial-收集器" class="headerlink" title="5.2 Serial 收集器"></a>5.2 Serial 收集器</h2><ul><li>串行收集器<ul><li>进行垃圾收集的时候工作线程需要停止</li></ul></li><li>新生代<ul><li>标记复制</li></ul></li><li>老年代<ul><li>标记整理</li></ul></li><li>简单高效，适合在client端运转</li></ul><p><img src="https://i.loli.net/2021/07/01/yoZaLX7NrKgldbM.png" alt="Serial收集器"></p><h2 id="5-3-ParNew收集器"><a href="#5-3-ParNew收集器" class="headerlink" title="5.3 ParNew收集器"></a>5.3 ParNew收集器</h2><ul><li>Serail收集器的多线程版本</li><li>新生代<ul><li>标记复制</li></ul></li><li>老年代<ul><li>标记整理</li></ul></li><li>适合在server模式下</li></ul><p><img src="https://i.loli.net/2021/07/01/plw2YaeWKT9CERc.png" alt="ParNew收集器"></p><h2 id="5-4-Parallel-Scavenge收集器"><a href="#5-4-Parallel-Scavenge收集器" class="headerlink" title="5.4 Parallel Scavenge收集器"></a>5.4 Parallel Scavenge收集器</h2><ul><li>注重对于吞吐量的优化 — 提高CPU的利用率</li><li>吞吐量 —&gt; CPU中用于运行用户代码的时间和CPU总消耗时间的比值</li><li>其提供了很多的参数来实现优化</li><li>新生代<ul><li>标记复制</li></ul></li><li>老年代<ul><li>标记整理</li></ul></li></ul><h2 id="5-5-Serial-Old收集器"><a href="#5-5-Serial-Old收集器" class="headerlink" title="5.5 Serial Old收集器"></a>5.5 Serial Old收集器</h2><ul><li>Serail收集器的老年代版本</li><li>两个用途<ul><li>JDK1.5之前版本和Parallel Scavenge收集器搭配使用</li><li>作为CMS收集器的后备方案</li></ul></li></ul><h2 id="5-6-Parallel-Old收集器"><a href="#5-6-Parallel-Old收集器" class="headerlink" title="5.6 Parallel Old收集器"></a>5.6 Parallel Old收集器</h2><ul><li>Parallel Scavenge的老年版本</li><li>使用多线程和标记整理法</li></ul><h2 id="5-7-CMS收集器"><a href="#5-7-CMS收集器" class="headerlink" title="5.7 CMS收集器"></a>5.7 CMS收集器</h2><ul><li>Concurrent Mark Sweep<ul><li>以获取最短回收停顿时间为目标的收集器</li><li>非常符合注重用户体验的应用</li><li>实现了让垃圾收集线程和用户线程的同时工作</li></ul></li><li>工作步骤<ul><li><strong>初始标记：</strong> 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；</li><li><strong>并发标记：</strong> 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。</li><li><strong>重新标记：</strong> 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短</li><li><strong>并发清除：</strong> 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/01/t5de1FrcE9bOAnf.png" alt="CMS收集器"></p><ul><li>优势<ul><li>并发，低停顿</li></ul></li><li>缺陷<ul><li>对CPU资源敏感</li><li>无法处理浮动垃圾</li><li>标记 清除算法会导致收集结束会产生大量的空间碎片</li></ul></li></ul><h2 id="5-8-G1-收集器"><a href="#5-8-G1-收集器" class="headerlink" title="5.8 G1 收集器"></a>5.8 G1 收集器</h2><ul><li>面向服务器的垃圾收集器，主要针对多核有大容量内存的机器，以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.</li><li>特征<ul><li><strong>并行与并发</strong>：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者<br>CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1<br>收集器仍然可以通过并发的方式让 java 程序继续执行。</li><li><strong>分代收集</strong>：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。</li><li><strong>空间整合</strong>：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。</li><li><strong>可预测的停顿</strong>：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。</li><li>优先列表： 在后台维护一个后台列表，每次根据允许的收集时间，优先选择回收价值最大的region</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6" target="_blank" rel="noopener">JavaGuide</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;JVM垃圾回收&quot;&gt;&lt;a href=&quot;#JVM垃圾回收&quot; class=&quot;headerlink&quot; title=&quot;JVM垃圾回收&quot;&gt;&lt;/a&gt;JVM垃圾回收&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;内存是如何分配和回收的&lt;/li&gt;
&lt;li&gt;哪些垃圾需要回收&lt;/li&gt;
&lt;li&gt;什么时候回
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="JVM" scheme="https://www.llchen60.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot虚拟机 对象声明流程</title>
    <link href="https://www.llchen60.com/HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AF%B9%E8%B1%A1%E5%A3%B0%E6%98%8E%E6%B5%81%E7%A8%8B/"/>
    <id>https://www.llchen60.com/HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AF%B9%E8%B1%A1%E5%A3%B0%E6%98%8E%E6%B5%81%E7%A8%8B/</id>
    <published>2021-06-29T04:45:03.000Z</published>
    <updated>2021-06-29T04:47:15.760Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java虚拟机基本原理"><a href="#Java虚拟机基本原理" class="headerlink" title="Java虚拟机基本原理"></a>Java虚拟机基本原理</h1><h1 id="1-Java-代码运行方式"><a href="#1-Java-代码运行方式" class="headerlink" title="1. Java 代码运行方式"></a>1. Java 代码运行方式</h1><h2 id="1-1-为什么需要虚拟机"><a href="#1-1-为什么需要虚拟机" class="headerlink" title="1.1 为什么需要虚拟机"></a>1.1 为什么需要虚拟机</h2><ul><li>设计一个面向Java语言特性的虚拟机<ul><li>做这个的原因是为了能够在各种机器上来实现对Java的支持</li><li>通过编译器将Java程序转换成该虚拟机所能识别的指令序列，又被称为Java字节码<ul><li>叫做Java字节码的原因是字节码指令的操作码opcode被定义成了一个字节</li></ul></li></ul></li><li>Java的虚拟机是可以由硬件实现的，也可以在各个平台上(Windows/ Linux) 提供软件的实现<ul><li>好处1： 一旦一个程序被转换成了Java字节码，那么便可以在不同平台上的虚拟机里来运行</li><li>好处2： 带来了托管环境，这个托管环境能够代替我们处理一些代码当中冗长而且容易出错的部分<ul><li>自动内存管理</li><li>垃圾回收</li><li>诸如数组越界，动态类型，安全权限等等的动态检测功能</li></ul></li></ul></li></ul><h2 id="1-2-如何运行Java字节码的？"><a href="#1-2-如何运行Java字节码的？" class="headerlink" title="1.2 如何运行Java字节码的？"></a>1.2 如何运行Java字节码的？</h2><ul><li><p>从虚拟机视角来看</p><ul><li><p>首先将其编译成的class文件加载到Java虚拟机当中</p></li><li><p>加载后的Java类会被存放于方法区里 Method Area</p></li><li><p>实际执行的时候，执行方法区的代码</p></li><li><p>空间分配</p><ul><li><p>线程共享的</p><ul><li><p>方法区</p><ul><li>用来存放类似于元数据信息方面的数据<ul><li>类信息</li><li>常量</li><li>静态变量</li><li>编译后代码</li></ul></li><li>JDK 1.8之后，不再有方法区了，元数据会放到本地内存的Metaspace 即元空间里面<ul><li>使用Metaspace的优势<ul><li>元空间大小默认为Unlimited 即只受到系统内存的限制</li><li>因为元数据大小不再由MaxPermSize控制，而由实际的可用空间控制，这样能加载的类就更多了</li></ul></li></ul></li></ul></li><li><p>堆</p><ul><li><p>放置对象实例，数组等</p></li><li><p>和方法区同属于线程共享区域，是线程不安全的</p></li><li><p>堆内存的划分</p><ul><li>年轻代<ul><li>Eden 8<ul><li>当我们new一个对象以后，会放到Eden划分出来的一块作为存储空间的内存当中</li><li>每个线程都会预先申请一块连续空间的内存空间并且规定了对象存放的位置，如果空间不足就再多申请内存空间</li></ul></li><li>Survivor<ul><li>FromPlace 1</li><li>ToPlace 1</li></ul></li></ul></li><li>老年代</li></ul></li><li><p>GC的运行逻辑</p><ul><li><p>Eden空间满了以后，会触发Minor GC</p></li><li><p>存活下来的对象移动到Survivor 0区</p></li><li><p>Survivor 0区满后触发Minor GC，将存活对象移动到Survivor 1区，此时还会将from和to指针交换，保证了一段时间内总有一个survivor区为空，且to所指向的survivor区为空</p></li><li><p>经过多次Minor GC仍存活的对象移动到老年代，一般是15次，因为Hotpot给记录年龄分配到的空间只有4位</p></li><li><p>老年代用来存储长期存活的对象，占满了就会触发Full GC，期间会停止所有线程等待GC的完成 —→ 需要尽量避免这种情况的发生</p></li><li><p>当老年区执行了full GC 还是无法对对象保存，就会产生OOM， 这意味着虚拟机中的堆内存不足</p><ul><li>可能原因<ul><li>设置的堆内存过小</li><li>代码中创建的对象大且多，一直被引用导致GC无法收集他们</li></ul></li></ul><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled.png"></p></li></ul></li></ul></li></ul></li><li><p>线程私有</p><ul><li>程序计数器<ul><li>完成加载工作</li><li>本身是一个指针，指向程序当中下一句需要执行的命令<ul><li>分支，循环，跳转，异常处理，线程恢复等功能都依赖于这个计数器来完成</li></ul></li><li>占用空间非常非常小</li><li>这个内存仅仅代表了当前线程所执行的字节码的行号指示器</li><li>字节码解析器通过改变这个计数器的值来选取下一条需要执行的字节码指令</li></ul></li><li>VM 栈<ul><li>当调用一个Java方法的时候，会在当前线程生成一个栈帧，用来存放局部变量以及字节码的操作数</li><li>栈帧大小是已经计算好了的，栈帧不需要连续分布</li><li>方法执行的内存模型<ul><li>对局部变量，动态链表，方法出口，栈的操作，对象引用进行存储，并且线程独享</li></ul></li><li>如果线程请求的栈的深度大于虚拟机栈的最大深度，就会报StackOverflowError</li><li>JVM是可以动态扩展的，但随着扩展会不断申请内存，当无法申请足够内存的时候就会报OutOfMemoryError</li><li>栈并不存在垃圾回收，因为只要程序运行结束，栈的空间自然会释放的。— 栈的生命周期和所处的线程是一致的</li></ul></li><li>本地方法栈<ul><li>由native修饰的方法</li><li>和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务</li></ul></li></ul></li><li><p>直接内存</p><ul><li>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机定义的内存区域</li><li>是通过基于通道和缓存区的NIO，直接使用Native函数库来分配堆外内存，然后通过一个存储在Java堆当中的DirectByteBuffer对象作为这块内存的引用，进而进行操作</li></ul></li></ul></li></ul></li><li><p>从硬件视角来看</p><ul><li>需要虚拟机将字节码翻译成机器码</li><li>翻译方式<ul><li>解释执行<ul><li>逐条将字节码翻译成机器码并且执行</li><li>优势<ul><li>无需等待编译</li></ul></li></ul></li><li>即时编译 Just In Time Compilation<ul><li>将一个方法中包含的所有字节码编译成机器码以后再执行</li><li>优势<ul><li>实际执行速度会更快</li></ul></li></ul></li></ul></li><li>hotpot的翻译方式<ul><li>先解释执行字节码</li><li>而后将反复执行的热点代码按照方法来作为基本单元进行JIT 即时编译</li></ul></li></ul></li><li><p>走一个代码例子</p></li></ul><pre><code class="jsx">@RequireAllArgConstructorpublic class People {    public String name;    public void sayName() {        System.out.println(&quot;People&#39;s name is: &quot; + name);    }}public class App {    public static void main(String[] args) {        People people = new People(&quot;test&quot;);        people.sayName();    }}</code></pre><ul><li>执行main方法的步骤如下<ul><li>编译好App.java之后得到App.class，执行App.class</li><li>系统会启动一个JVM进程</li><li>从classpath路径当中找到一个名为App.class的二进制文件，将App的类信息加载到运行时数据区的方法区内</li><li>JVM找到App主程序入口，执行main方法</li><li>当要执行new People的时候，发现方法区当中还没有People类的信息，所以JVM马上加载，并将其类的信息放到方法区里面</li><li>JVM在堆当中为一个新的People实例分配内存，然后调用构造函数初始化People实例，这个实例持有指向方法区中的People类的类型信息的引用</li><li>执行people.sayName();时，JVM 根据 people 的引用找到 people 对象，然后根据 people 对象持有的引用定位到方法区中 people 类的类型信息的方法表，获得 sayName() 的字节码地址</li><li>执行sayName()</li></ul></li></ul><h2 id="1-3-Java虚拟机执行效率"><a href="#1-3-Java虚拟机执行效率" class="headerlink" title="1.3 Java虚拟机执行效率"></a>1.3 Java虚拟机执行效率</h2><ul><li>优化方式<ul><li>即时编译<ul><li>底层逻辑 — 二八定律<ul><li>认为20%代码会占据80%的计算资源</li></ul></li><li>编译器类别 — tradeoff 编译时间 vs 执行效率<ul><li>C1<ul><li>Client编译器</li><li>面向对启动性能有要求的客户端GUI程序</li></ul></li><li>C2<ul><li>Server编译器</li><li>面向对峰值性能有要求的服务器端程序</li><li>采用的优化手段相对复杂，因此编译时间较长，但同时生成代码的效率比较高</li></ul></li><li>Graal</li></ul></li></ul></li></ul></li><li>Hotpot对于各种编译器的采用方式<ul><li>分层编译<ul><li>热点方法先被C1 编译</li><li>热点方法里的热点会进一步被C2 编译器编译</li></ul></li><li>会影响应用的正常进行么？<ul><li>即时编译是在额外的编译线程当中进行的</li><li>会根据CPU的数量设置编译线程的数目，并且按照1:2的比例配置给C1 及C2 编译器</li></ul></li></ul></li></ul><h1 id="2-基本类型在虚拟机当中的实现"><a href="#2-基本类型在虚拟机当中的实现" class="headerlink" title="2. 基本类型在虚拟机当中的实现"></a>2. 基本类型在虚拟机当中的实现</h1><ul><li><p>为什么要引入基本类型而不是全都使用对象呢？</p><ul><li>基本类型更靠近底层，在执行效率和内存使用方面都能够提升软件的性能</li></ul></li><li><p>boolean 类型</p><ul><li><p>映射成int类型</p><ul><li><p>true被映射为整数1</p></li><li><p>false被映射为整数0</p><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%201.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%201.png"></p></li></ul></li></ul></li><li><p>Java虚拟机在调用Java方法的时候，会创建出一个栈帧，对于其中的解释栈帧来说，有两个主要组成部分</p><ul><li>局部变量区<ul><li>局部变量</li><li>this指针</li><li>方法接收的参数</li><li>各个基本类型在局部变量区的表现<ul><li>局部变量区等价于一个数组<ul><li>long double需要两个数组单元存储</li><li>其他基本类型和引用类型的值均占用一个数组单元</li></ul></li></ul></li></ul></li><li>字节码的操作数栈</li></ul></li><li><p>存储操作</p><ul><li>如果我们将一个int类型的值放到char short 等里面，相当于做了一次掩码  只会保留低位了</li></ul></li><li><p>加载</p><ul><li>算数运算完全依赖于操作数栈</li><li>堆当中的boolean, byte, char, short 加载到操作数栈当中，而后将栈上的值当成int类型来运算</li></ul></li></ul><h1 id="3-类的加载，链接，初始化过程"><a href="#3-类的加载，链接，初始化过程" class="headerlink" title="3. 类的加载，链接，初始化过程"></a>3. 类的加载，链接，初始化过程</h1><ul><li>首先.java文件会被编译成.class文件，而后我们需要类加载器来处理.class文件，让JVM对其进行处理</li><li>从class文件到内存当中的类，需要经过：<ul><li>加载<ul><li>查找字节流，并且根据此来创建类的过程<ul><li>将class类加载到内存当中</li><li>将静态数据结构转化为方法区当中运行时的数据结构</li><li>在堆当中生成一个代表这个类的java.lang.class对象作为数据访问的入口</li></ul></li><li>借助类加载器来完成查找字节流的过程<ul><li>启动类加载器 — bootstrap class loader<ul><li>负责加载最基础最重要的类，譬如JRE lib目录下Jar包中的类</li><li>由虚拟机参数 -Xbootclasspath指定的类</li></ul></li><li>其他类加载器 — 都是java.lang.ClassLoader的子类<ul><li>需要先由启动类加载器，将其加载至Java虚拟机当中，方能执行类的加载</li><li>E.G<ul><li>扩展类加载器 — 父类是启动类加载器<ul><li>负责加载相对次要、但又通用的类，比如存放在 JRE 的 lib/ext 目录下 jar 包中的类（以及由系统变量 java.ext.dirs 指定的类）</li></ul></li><li>应用类加载器 — 父类是扩展类加载器<ul><li>负责加载应用程序路径下的类<ul><li>例如虚拟机参数 -cp/-classpath, 系统变量java.class.path或者环境变量CLASSPATH所指定的路径</li><li>默认应用程序里包含的类应该由应用类加载器来进行加载</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>双亲委派模型<ul><li>当一个类加载器接收到加载请求时，会先将请求转发给父类加载器</li><li>在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载</li></ul></li><li>类加载器 — 命名空间的作用<ul><li>类的唯一性由类加载器实例和类的全名共同确定</li><li>即使同一串字节流，经由不同的类加载器加载，也会得到不同的类</li></ul></li></ul></li><li>链接<ul><li>将创建的类合并到Java虚拟机当中，并且使其能够执行的过程</li><li>过程<ul><li>验证<ul><li>确保被加载类能够满足Java虚拟机的约束条件</li><li>安全检查</li></ul></li><li>准备<ul><li>为被加载类的静态字段分配内存<ul><li>就是为static变量在方法区当中分配内存空间，设置变量的初始值</li></ul></li><li>也会来构造和其他类层次相关的数据结构，比如说用来实现虚方法的动态绑定的方法表</li></ul></li><li>解析 — 对于字节码符号引用的解析<ul><li>在 class 文件被加载至 Java 虚拟机之前，这个类无法知道其他类及其方法、字段所对应的具体地址，甚至不知道自己方法、字段的地址。</li><li>因此，每当需要引用这些成员时，Java 编译器会生成一个符号引用。在运行阶段，这个符号引用一般都能够无歧义地定位到具体目标上。</li><li>举例来说，对于一个方法调用，编译器会生成一个包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法。</li><li>解析阶段的目的，正是将这些符号引用解析成为实际引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）</li></ul></li></ul></li></ul></li><li>初始化<ul><li>内容<ul><li>为标记为常量值的字段赋值</li><li>执行clinit方法 — Java虚拟机通过加锁确定clinit方法仅仅会被执行一次<ul><li>如果直接赋值的静态字段被 final 所修饰，并且它的类型是基本类型或字符串时，那么该字段便会被 Java 编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成。</li><li>除此之外的直接赋值操作，以及所有静态代码块中的代码，则会被 Java 编译器置于同一方法中，并把它命名为 &lt; clinit &gt;。</li></ul></li></ul></li><li>触发情况<ul><li>当虚拟机启动时，初始化用户指定的主类；</li><li>当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类；</li><li>当遇到调用静态方法的指令时，初始化该静态方法所在的类；</li><li>当遇到访问静态字段的指令时，初始化该静态字段所在的类；</li><li>子类的初始化会触发父类的初始化；</li><li>如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化；</li><li>使用反射 API 对某个类进行反射调用时，初始化这个类；</li><li>当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。</li></ul></li></ul></li><li>卸载<ul><li>GC将无用对象从内存当中卸载掉</li></ul></li></ul></li><li>基本类型是Java虚拟机已经设置好的，而另一大类引用类型，Java将其细分为四种<ul><li>类<ul><li>有对应的字节流 — class文件</li></ul></li><li>接口<ul><li>有对应的字节流 - class文件</li></ul></li><li>数组类<ul><li>由Java虚拟机直接生成</li></ul></li><li>泛型参数</li></ul></li></ul><h1 id="4-JVM执行方法调用"><a href="#4-JVM执行方法调用" class="headerlink" title="4. JVM执行方法调用"></a>4. JVM执行方法调用</h1><h2 id="4-1-重载和重写"><a href="#4-1-重载和重写" class="headerlink" title="4.1 重载和重写"></a>4.1 重载和重写</h2><ul><li>重载<ul><li>同一个类当中方法名称相同，但是方法的参数不相同的情况</li><li>在编译过程当中就可以完成识别，Java编译器根据传入参数的声明类型，来选取重载方法<ul><li>三个阶段<ul><li>不考虑基本类型的自动拆箱装箱，还有可变长参数的情况下选择重载方法</li><li>1阶段没有找到适配的方法，那么就在允许自动拆装箱，但不允许可变长参数的情况下选取重载方法</li><li>2阶段没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法</li></ul></li><li>如果Java编译器在同一个阶段找到了多个适配方法，那么就会选择一个最为贴切的，决定贴切程度的一个关键就是形式参数类型的继承关系<ul><li>会选择那个范围更小的，比如某某的子类这样子</li></ul></li></ul></li></ul></li><li>重写<ul><li>子类定义了和父类非私有方法同名的方法，而且这两个方法的参数类型相同</li><li>如果这两个方法都是静态的，那么子类中的方法隐藏了父类中的方法</li><li>如果都不是静态，也不是私有的，那么子类的方法重写了父类当中的方法</li><li>方法重写 — 允许子类在继承父类部分功能的同时，拥有自己独特的行为</li></ul></li></ul><h2 id="4-2-JVM-静态和动态绑定"><a href="#4-2-JVM-静态和动态绑定" class="headerlink" title="4.2 JVM 静态和动态绑定"></a>4.2 JVM 静态和动态绑定</h2><ul><li>Java虚拟机识别方法<ul><li>类名</li><li>方法名</li><li>方法描述符 — method descriptor<ul><li>由方法的参数类型以及<strong>返回类型</strong>所构成的</li></ul></li></ul></li><li>JVM和Java语言在这里不太一样，同一个类下同样方法名，同样参数，但是不同返回值从JVM角度来说是可以被认为是不同的方法，是可以通过的</li><li>静态绑定<ul><li>在解析的时候便能够识别目标方法的情况</li><li>重载 — 是在编译阶段就完成了的，也可以成为static binding</li></ul></li><li>动态绑定<ul><li>在运行过程当中根据调用者的动态类型来识别目标方法的情况</li><li>重写 — 在JVM当中来做识别，dynamic binding</li></ul></li><li>Java字节码当中和调用相关的指令<ul><li>invokestatic  - 用于调用静态方法</li><li>invokespecial - 用于调用私有实例方法，构造器  以及使用super关键字调用父类的实例方法或者构造器</li><li>invokevirtual  - 用于调用非私有实例方法</li><li>invokeinterface - 用于调用接口方法</li><li>invokedynamic - 用于调用动态方法</li></ul></li></ul><h2 id="4-3-调用指令的符号引用"><a href="#4-3-调用指令的符号引用" class="headerlink" title="4.3 调用指令的符号引用"></a>4.3 调用指令的符号引用</h2><ul><li>在编译过程当中，我们并不知道目标方法的具体内存地址<ul><li>Java编译器会暂时用符号引用来表示该目标方法</li><li>这一符号引用包括目标方法所在的类或接口的名字，以及目标方法的方法名和方法描述符。</li></ul></li></ul><h1 id="5-垃圾回收"><a href="#5-垃圾回收" class="headerlink" title="5. 垃圾回收"></a>5. 垃圾回收</h1><h2 id="5-1-如何判断需要清理一个对象"><a href="#5-1-如何判断需要清理一个对象" class="headerlink" title="5.1 如何判断需要清理一个对象"></a>5.1 如何判断需要清理一个对象</h2><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%202.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%202.png"></p><ul><li>绿色部分是线程拥有的，会随着线程的结束而自动被回收 这里不需要考虑垃圾回收的问题</li><li>橙色部分是共享的，内存分配和回收都是动态的，因此垃圾收集器所关注的都是堆和方法这部分内存</li><li>判断对象存活的方法<ul><li>引用计数器计算<ul><li>给对象添加一个引用计数器，每次引用这个对象的时候计数器加一，引用失效则减一</li><li>计数器等于零的时候就不会再次试用了</li></ul></li><li>可达性分析计算<ul><li>将一系列GC ROOTS作为起始的存活对象集，从这个节点往下搜索</li><li>搜索所走过的路径成为引用链，将能被该集合引用的对象加入到集合当中</li><li>当搜索到一个对象到GC roots没有使用任何引用链的时候，就说明这个对象是不可用的</li></ul></li></ul></li></ul><h2 id="5-2-如何宣告一个对象的结束-死亡"><a href="#5-2-如何宣告一个对象的结束-死亡" class="headerlink" title="5.2 如何宣告一个对象的结束/ 死亡"></a>5.2 如何宣告一个对象的结束/ 死亡</h2><ul><li>finalize()是Object类的一个方法，一个对象的finalize()方法只会被系统自动调用一次，经过finalize()方法逃脱死亡的对象，二次标记的时候会给移出</li><li>整个流程如下<ol><li>如果对象进行可达性分析之后没发现与GC Roots相连的引用链，那它将会第一次标记并且进行一次筛选。判断的条件是决定这个对象是否有必要执行finalize()方法。如果对象有必要执行finalize()方法，则被放入F-Queue队列中。</li><li>GC对F-Queue队列中的对象进行二次标记。如果对象在finalize()方法中重新与引用链上的任何一个对象建立了关联，那么二次标记时则会将它移出“即将回收”集合。如果此时对象还没成功逃脱，那么只能被回收了。</li></ol></li></ul><h2 id="5-3-垃圾回收算法"><a href="#5-3-垃圾回收算法" class="headerlink" title="5.3 垃圾回收算法"></a>5.3 垃圾回收算法</h2><h3 id="5-3-1-标记清除算法"><a href="#5-3-1-标记清除算法" class="headerlink" title="5.3.1 标记清除算法"></a>5.3.1 标记清除算法</h3><ul><li><p>阶段</p><ul><li>标记<ul><li>标记处所有需要回收的对象</li></ul></li><li>清除<ul><li>标记结束以后进行统一的回收</li></ul></li></ul></li><li><p>原理</p><ul><li>将已死亡的对象标记为空闲内存，记录在一个空闲列表当中</li><li>当我们需要new一个对象的时候，内存管理模块会从空闲列表当中寻找空闲的内存来分给新的对象</li></ul></li><li><p>缺陷</p><ul><li><p>会使得内存当中的碎片非常多</p></li><li><p>容易导致当我们需要使用大块的内存的时候，无法分配足够的连续内存</p><p>  <img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%203.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%203.png"></p></li></ul></li></ul><h3 id="5-3-2-复制算法"><a href="#5-3-2-复制算法" class="headerlink" title="5.3.2 复制算法"></a>5.3.2 复制算法</h3><ul><li><p>在标记清除算法的基础上做的优化</p><ul><li>将可用内存按照容量划分成两等分，每次只使用其中一块</li><li>当一块存满了 就将存活的对象复制到另一块上，然后交换指针的内容</li><li>以此解决碎片化的问题</li></ul></li><li><p>缺陷</p><ul><li><p>可用内存减少了！</p><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%204.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%204.png"></p></li></ul></li></ul><h3 id="5-3-3-标记整理算法"><a href="#5-3-3-标记整理算法" class="headerlink" title="5.3.3 标记整理算法"></a>5.3.3 标记整理算法</h3><ul><li>标记了以后会做整理，将所有存活的对象都向内存块一端移动，然后直接清理掉边界以外的内存</li></ul><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%205.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%205.png"></p><h3 id="5-3-4-分代收集算法"><a href="#5-3-4-分代收集算法" class="headerlink" title="5.3.4 分代收集算法"></a>5.3.4 分代收集算法</h3><ul><li>根据对象存活周期的不同将内存划分为几块</li><li>新生代<ul><li>每次垃圾收集都有大批对象死去，少量存活</li><li>所以可以选用复制算法</li></ul></li><li>老年代<ul><li>对象存活率高，没有额外空间对其进行分配和担保</li><li>需要使用标记-清理或者标记整理算法来进行回收</li></ul></li></ul><h2 id="5-4-垃圾收集器"><a href="#5-4-垃圾收集器" class="headerlink" title="5.4 垃圾收集器"></a>5.4 垃圾收集器</h2><ul><li>jdk8 默认收集器是Parallel Scavenge 和 Parallel Old</li><li>jdk9开始，G1收集器成为默认的垃圾收集器</li></ul><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%206.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%206.png"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/[%E5%8A%A0%E9%A4%90]%E5%A4%A7%E7%99%BD%E8%AF%9D%E5%B8%A6%E4%BD%A0%E8%AE%A4%E8%AF%86JVM" target="_blank" rel="noopener">JavaGuide</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Java虚拟机基本原理&quot;&gt;&lt;a href=&quot;#Java虚拟机基本原理&quot; class=&quot;headerlink&quot; title=&quot;Java虚拟机基本原理&quot;&gt;&lt;/a&gt;Java虚拟机基本原理&lt;/h1&gt;&lt;h1 id=&quot;1-Java-代码运行方式&quot;&gt;&lt;a href=&quot;#1-Ja
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
  </entry>
  
  <entry>
    <title>01背包问题</title>
    <link href="https://www.llchen60.com/01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    <id>https://www.llchen60.com/01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/</id>
    <published>2021-06-25T01:20:17.000Z</published>
    <updated>2021-06-25T01:21:30.603Z</updated>
    
    <content type="html"><![CDATA[<h1 id="01背包问题"><a href="#01背包问题" class="headerlink" title="01背包问题"></a>01背包问题</h1><p>Created: Jun 23, 2021 8:02 PM</p><h1 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h1><p>背包问题 即有N件物品，和一个最多能装重量W的背包，第i件物品的重量是weight[i], 得到的价值是value[i], 每件物品只能用一次，求解将哪些物品装入背包里物品价值总和最大。</p><h1 id="2-暴力破解方法"><a href="#2-暴力破解方法" class="headerlink" title="2. 暴力破解方法"></a>2. 暴力破解方法</h1><ul><li>每件物品只有选和不选两种途径，可以使用回溯法搜索出所有的情况，然后取最大的值</li><li>这样写非常慢，因为遍历了每个物品的取和不取的所有情况，时间复杂度为O(2^n)</li></ul><pre><code class="jsx">class Solution {    int result = 0;  int cur = 0;    public maxValue(int[] value, int[] weight, int w) {        backTracking(value, weight, w, 0);        return result;    }    private void backTracking(int[] value, int[] weight, int w, int startIndex) {        if (startIndex &gt; value.length - 1 || w &lt; 0) {            return;        }        for (int i = startIndex; i &lt; value.length; i++) {            cur += value[i];            w -= weight[i];                        result = Math.max(result, cur);            backTracking(value, weight, w, i + 1);            cur -= value[i];            w += weight[i];        }    }}</code></pre><h1 id="3-二维dp数组01背包"><a href="#3-二维dp数组01背包" class="headerlink" title="3. 二维dp数组01背包"></a>3. 二维dp数组01背包</h1><p>因为每一步都是依托于上一步你的物品的取放的选择的，是一个可以用dp来做的类型题目~ </p><p>我们需要做以下几步来思考整个逻辑</p><h2 id="3-1-确定dp数组和下标的含义"><a href="#3-1-确定dp数组和下标的含义" class="headerlink" title="3.1 确定dp数组和下标的含义"></a>3.1 确定dp数组和下标的含义</h2><ul><li>在二维数组里面，我们希望用dp[i][j] 表示我在做了对于前i个产品的选择，在容量为j的时候能够获得的最大的价值</li><li>在这个定义下，那么最终我需要的值就是dp[n][W], 这就是我在做了n个关于这些产品的选取放弃的决定，在满足重量不超过W的限定条件下能取得的最大价值了</li></ul><h2 id="3-2-确定递推公式"><a href="#3-2-确定递推公式" class="headerlink" title="3.2 确定递推公式"></a>3.2 确定递推公式</h2><pre><code class="jsx">// 不选i这件产品，容量为j的值; 还有选了i这件产品，那么i-1件产品的总重量需要满足 j - weight[i], 这个时候再加上i这件产品的价值，  这两个dp数组位置的最大值就是dp[i][j]需要取的值了dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j - weight[i]] + value[i])</code></pre><h2 id="3-3-如何初始化这个数组"><a href="#3-3-如何初始化这个数组" class="headerlink" title="3.3 如何初始化这个数组"></a>3.3 如何初始化这个数组</h2><ul><li>对于第一列  j = 0 意味着现在背包允许的重量为0，所以不管是哪个产品，有的价值都为0</li><li>对于第一行 i = 0, 此时我们只能选择物品0，而且题目中说了只能最多拿一件产品，所以可以将这一行都声明为weight[0]</li></ul><h2 id="3-4-确定遍历顺序"><a href="#3-4-确定遍历顺序" class="headerlink" title="3.4 确定遍历顺序"></a>3.4 确定遍历顺序</h2><p>先遍历物品，再遍历背包重量  其实均可</p><pre><code class="jsx">// weight数组的大小 就是物品个数for(int i = 1; i &lt; weight.size(); i++) { // 遍历物品    for(int j = 0; j &lt;= bagWeight; j++) { // 遍历背包容量        if (j &lt; weight[i]) dp[i][j] = dp[i - 1][j]; // 这个是为了展现dp数组里元素的变化        else dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]);    }}</code></pre><h2 id="3-5-代码"><a href="#3-5-代码" class="headerlink" title="3.5 代码"></a>3.5 代码</h2><pre><code class="jsx">public int WeightBagProblem(int[] weight, int[] value, int bagSize){        int wLen = weight.length, value0 = 0;        //定义dp数组：dp[i][j]表示背包容量为j时，前i个物品能获得的最大价值        int[][] dp = new int[wLen + 1][bagSize + 1];        //初始化：背包容量为0时，能获得的价值都为0        for (int i = 0; i &lt;= wLen; i++){            dp[i][0] = value0;        }        //遍历顺序：先遍历物品，再遍历背包容量        for (int i = 1; i &lt;= wLen; i++){            for (int j = 1; j &lt;= bagSize; j++){                if (j &lt; weight[i - 1]){                    dp[i][j] = dp[i - 1][j];                }else{                    dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - weight[i - 1]] + value[i - 1]);                }            }        }                return dp[wLen][bagSize];    }</code></pre><h1 id="4-数组降维-—-利用滚动数组解决01背包问题"><a href="#4-数组降维-—-利用滚动数组解决01背包问题" class="headerlink" title="4. 数组降维 — 利用滚动数组解决01背包问题"></a>4. 数组降维 — 利用滚动数组解决01背包问题</h1><ul><li>在第三部分当中，我们的递归公式推导出来是：</li></ul><pre><code class="jsx">dp[i][j] = max(dp[i-1][j], dp[i-1][j-weight[i]] + value[i])</code></pre><ul><li>如果在这里 我们将dp[i-1][]那一层的东西拷贝到dp[i]这一层，那么我们是可以使用一个一维数组来解决这个问题的</li></ul><h2 id="4-1-确定dp数组的定义"><a href="#4-1-确定dp数组的定义" class="headerlink" title="4.1 确定dp数组的定义"></a>4.1 确定dp数组的定义</h2><p>在一维dp数组当中, dp[j]表示容量为j的背包所背的物品价值可以最大为dp[j] </p><h2 id="4-2-一维数组递推公式"><a href="#4-2-一维数组递推公式" class="headerlink" title="4.2 一维数组递推公式"></a>4.2 一维数组递推公式</h2><pre><code class="jsx">dp[j] = max(dp[j], dp[j-weight[i]] + value[i])</code></pre><h2 id="4-3-一维数组初始化"><a href="#4-3-一维数组初始化" class="headerlink" title="4.3 一维数组初始化"></a>4.3 一维数组初始化</h2><ul><li>首先确定背包容量为0所背的物品的最大价值也为0</li><li>假设所有产品价值非负，那么我们就不用初始化数组其他位置的值为负无穷了，保持为0即可</li></ul><h2 id="4-4-一维数组遍历顺序"><a href="#4-4-一维数组遍历顺序" class="headerlink" title="4.4 一维数组遍历顺序"></a>4.4 一维数组遍历顺序</h2><pre><code class="jsx">or(int i = 0; i &lt; weight.size(); i++) { // 遍历物品    for(int j = bagWeight; j &gt;= weight[i]; j--) { // 遍历背包容量        dp[j] = max(dp[j], dp[j - weight[i]] + value[i]);    }}</code></pre><ul><li>不能正序遍历，因为正序的话物品会被重复加入很多次<ul><li>因为在遍历后一个的时候实际上已经用了前一个的结果</li><li>譬如<ul><li>dp[1] = dp[1 - weight[0]] + value[0]</li><li>dp[2] = dp[2 - weight[0]] + value[0]</li><li>dp[2] 会用到dp[1] (当weight[0] = 1的时候)  这个时候相当于我们把0号产品用了两次了 这是不能够的</li></ul></li></ul></li></ul><pre><code class="jsx">public static void main(String[] args) {        int[] weight = {1, 3, 4};        int[] value = {15, 20, 30};        int bagWight = 4;        testWeightBagProblem(weight, value, bagWight);    }    public static void testWeightBagProblem(int[] weight, int[] value, int bagWeight){        int wLen = weight.length;        //定义dp数组：dp[j]表示背包容量为j时，能获得的最大价值        int[] dp = new int[bagWeight + 1];        //遍历顺序：先遍历物品，再遍历背包容量        for (int i = 0; i &lt; wLen; i++){            for (int j = bagWeight; j &gt;= weight[i]; j--){                dp[j] = Math.max(dp[j], dp[j - weight[i]] + value[i]);            }        }        //打印dp数组        for (int j = 0; j &lt;= bagWeight; j++){            System.out.print(dp[j] + &quot; &quot;);        }    }</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;01背包问题&quot;&gt;&lt;a href=&quot;#01背包问题&quot; class=&quot;headerlink&quot; title=&quot;01背包问题&quot;&gt;&lt;/a&gt;01背包问题&lt;/h1&gt;&lt;p&gt;Created: Jun 23, 2021 8:02 PM&lt;/p&gt;
&lt;h1 id=&quot;1-问题描述&quot;&gt;&lt;a h
      
    
    </summary>
    
    
      <category term="数据结构与算法" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="01背包" scheme="https://www.llchen60.com/tags/01%E8%83%8C%E5%8C%85/"/>
    
  </entry>
  
  <entry>
    <title>Java虚拟机基本原理</title>
    <link href="https://www.llchen60.com/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"/>
    <id>https://www.llchen60.com/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</id>
    <published>2021-06-23T04:21:43.000Z</published>
    <updated>2021-06-28T00:53:37.453Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Java虚拟机基本原理"><a href="#Java虚拟机基本原理" class="headerlink" title="Java虚拟机基本原理"></a>Java虚拟机基本原理</h1><h1 id="1-Java-代码运行方式"><a href="#1-Java-代码运行方式" class="headerlink" title="1. Java 代码运行方式"></a>1. Java 代码运行方式</h1><h2 id="1-1-为什么需要虚拟机"><a href="#1-1-为什么需要虚拟机" class="headerlink" title="1.1 为什么需要虚拟机"></a>1.1 为什么需要虚拟机</h2><ul><li>设计一个面向Java语言特性的虚拟机<ul><li>做这个的原因是为了能够在各种机器上来实现对Java的支持</li><li>通过编译器将Java程序转换成该虚拟机所能识别的指令序列，又被称为Java字节码<ul><li>叫做Java字节码的原因是字节码指令的操作码opcode被定义成了一个字节</li></ul></li></ul></li><li>Java的虚拟机是可以由硬件实现的，也可以在各个平台上(Windows/ Linux) 提供软件的实现<ul><li>好处1： 一旦一个程序被转换成了Java字节码，那么便可以在不同平台上的虚拟机里来运行</li><li>好处2： 带来了托管环境，这个托管环境能够代替我们处理一些代码当中冗长而且容易出错的部分<ul><li>自动内存管理</li><li>垃圾回收</li><li>诸如数组越界，动态类型，安全权限等等的动态检测功能</li></ul></li></ul></li></ul><h2 id="1-2-如何运行Java字节码的？"><a href="#1-2-如何运行Java字节码的？" class="headerlink" title="1.2 如何运行Java字节码的？"></a>1.2 如何运行Java字节码的？</h2><ul><li><p>从虚拟机视角来看</p><ul><li><p>首先将其编译成的class文件加载到Java虚拟机当中</p></li><li><p>加载后的Java类会被存放于方法区里 Method Area</p></li><li><p>实际执行的时候，执行方法区的代码</p></li><li><p>空间分配</p><ul><li><p>线程共享的</p><ul><li><p>方法区</p><ul><li>用来存放类似于元数据信息方面的数据<ul><li>类信息</li><li>常量</li><li>静态变量</li><li>编译后代码</li></ul></li><li>JDK 1.8之后，不再有方法区了，元数据会放到本地内存的Metaspace 即元空间里面<ul><li>使用Metaspace的优势<ul><li>元空间大小默认为Unlimited 即只受到系统内存的限制</li><li>因为元数据大小不再由MaxPermSize控制，而由实际的可用空间控制，这样能加载的类就更多了</li></ul></li></ul></li></ul></li><li><p>堆</p><ul><li><p>放置对象实例，数组等</p></li><li><p>和方法区同属于线程共享区域，是线程不安全的</p></li><li><p>堆内存的划分</p><ul><li>年轻代<ul><li>Eden 8<ul><li>当我们new一个对象以后，会放到Eden划分出来的一块作为存储空间的内存当中</li><li>每个线程都会预先申请一块连续空间的内存空间并且规定了对象存放的位置，如果空间不足就再多申请内存空间</li></ul></li><li>Survivor<ul><li>FromPlace 1</li><li>ToPlace 1</li></ul></li></ul></li><li>老年代</li></ul></li><li><p>GC的运行逻辑</p><ul><li><p>Eden空间满了以后，会触发Minor GC</p></li><li><p>存活下来的对象移动到Survivor 0区</p></li><li><p>Survivor 0区满后触发Minor GC，将存活对象移动到Survivor 1区，此时还会将from和to指针交换，保证了一段时间内总有一个survivor区为空，且to所指向的survivor区为空</p></li><li><p>经过多次Minor GC仍存活的对象移动到老年代，一般是15次，因为Hotpot给记录年龄分配到的空间只有4位</p></li><li><p>老年代用来存储长期存活的对象，占满了就会触发Full GC，期间会停止所有线程等待GC的完成 —→ 需要尽量避免这种情况的发生</p></li><li><p>当老年区执行了full GC 还是无法对对象保存，就会产生OOM， 这意味着虚拟机中的堆内存不足</p><ul><li>可能原因<ul><li>设置的堆内存过小</li><li>代码中创建的对象大且多，一直被引用导致GC无法收集他们</li></ul></li></ul><p><img src="https://i.loli.net/2021/06/28/q7NYfmdDapVOBU9.png" alt="GC运行逻辑"></p></li></ul></li></ul></li></ul></li><li><p>线程私有</p><ul><li>程序计数器<ul><li>完成加载工作</li><li>本身是一个指针，指向程序当中下一句需要执行的命令<ul><li>分支，循环，跳转，异常处理，线程恢复等功能都依赖于这个计数器来完成</li></ul></li><li>占用空间非常非常小</li><li>这个内存仅仅代表了当前线程所执行的字节码的行号指示器</li><li>字节码解析器通过改变这个计数器的值来选取下一条需要执行的字节码指令</li></ul></li><li>VM 栈<ul><li>当调用一个Java方法的时候，会在当前线程生成一个栈帧，用来存放局部变量以及字节码的操作数</li><li>栈帧大小是已经计算好了的，栈帧不需要连续分布</li><li>方法执行的内存模型<ul><li>对局部变量，动态链表，方法出口，栈的操作，对象引用进行存储，并且线程独享</li></ul></li><li>如果线程请求的栈的深度大于虚拟机栈的最大深度，就会报StackOverflowError</li><li>JVM是可以动态扩展的，但随着扩展会不断申请内存，当无法申请足够内存的时候就会报OutOfMemoryError</li><li>栈并不存在垃圾回收，因为只要程序运行结束，栈的空间自然会释放的。— 栈的生命周期和所处的线程是一致的</li></ul></li><li>本地方法栈<ul><li>由native修饰的方法</li><li>和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务</li></ul></li></ul></li><li><p>直接内存</p><ul><li>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机定义的内存区域</li><li>是通过基于通道和缓存区的NIO，直接使用Native函数库来分配堆外内存，然后通过一个存储在Java堆当中的DirectByteBuffer对象作为这块内存的引用，进而进行操作</li></ul></li></ul></li></ul></li><li><p>从硬件视角来看</p><ul><li>需要虚拟机将字节码翻译成机器码</li><li>翻译方式<ul><li>解释执行<ul><li>逐条将字节码翻译成机器码并且执行</li><li>优势<ul><li>无需等待编译</li></ul></li></ul></li><li>即时编译 Just In Time Compilation<ul><li>将一个方法中包含的所有字节码编译成机器码以后再执行</li><li>优势<ul><li>实际执行速度会更快</li></ul></li></ul></li></ul></li><li>hotpot的翻译方式<ul><li>先解释执行字节码</li><li>而后将反复执行的热点代码按照方法来作为基本单元进行JIT 即时编译</li></ul></li></ul></li><li><p>走一个代码例子</p></li></ul><pre><code class="jsx">@RequireAllArgConstructorpublic class People {    public String name;    public void sayName() {        System.out.println(&quot;People&#39;s name is: &quot; + name);    }}public class App {    public static void main(String[] args) {        People people = new People(&quot;test&quot;);        people.sayName();    }}</code></pre><ul><li>执行main方法的步骤如下<ul><li>编译好App.java之后得到App.class，执行App.class</li><li>系统会启动一个JVM进程</li><li>从classpath路径当中找到一个名为App.class的二进制文件，将App的类信息加载到运行时数据区的方法区内</li><li>JVM找到App主程序入口，执行main方法</li><li>当要执行new People的时候，发现方法区当中还没有People类的信息，所以JVM马上加载，并将其类的信息放到方法区里面</li><li>JVM在堆当中为一个新的People实例分配内存，然后调用构造函数初始化People实例，这个实例持有指向方法区中的People类的类型信息的引用</li><li>执行people.sayName();时，JVM 根据 people 的引用找到 people 对象，然后根据 people 对象持有的引用定位到方法区中 people 类的类型信息的方法表，获得 sayName() 的字节码地址</li><li>执行sayName()</li></ul></li></ul><h2 id="1-3-Java虚拟机执行效率"><a href="#1-3-Java虚拟机执行效率" class="headerlink" title="1.3 Java虚拟机执行效率"></a>1.3 Java虚拟机执行效率</h2><ul><li>优化方式<ul><li>即时编译<ul><li>底层逻辑 — 二八定律<ul><li>认为20%代码会占据80%的计算资源</li></ul></li><li>编译器类别 — tradeoff 编译时间 vs 执行效率<ul><li>C1<ul><li>Client编译器</li><li>面向对启动性能有要求的客户端GUI程序</li></ul></li><li>C2<ul><li>Server编译器</li><li>面向对峰值性能有要求的服务器端程序</li><li>采用的优化手段相对复杂，因此编译时间较长，但同时生成代码的效率比较高</li></ul></li><li>Graal</li></ul></li></ul></li></ul></li><li>Hotpot对于各种编译器的采用方式<ul><li>分层编译<ul><li>热点方法先被C1 编译</li><li>热点方法里的热点会进一步被C2 编译器编译</li></ul></li><li>会影响应用的正常进行么？<ul><li>即时编译是在额外的编译线程当中进行的</li><li>会根据CPU的数量设置编译线程的数目，并且按照1:2的比例配置给C1 及C2 编译器</li></ul></li></ul></li></ul><h1 id="2-基本类型在虚拟机当中的实现"><a href="#2-基本类型在虚拟机当中的实现" class="headerlink" title="2. 基本类型在虚拟机当中的实现"></a>2. 基本类型在虚拟机当中的实现</h1><ul><li><p>为什么要引入基本类型而不是全都使用对象呢？</p><ul><li>基本类型更靠近底层，在执行效率和内存使用方面都能够提升软件的性能</li></ul></li><li><p>boolean 类型</p><ul><li>映射成int类型<ul><li>true被映射为整数1</li><li>false被映射为整数0<br><img src="https://i.loli.net/2021/06/28/k6pXaMj4rUJOFoH.png" alt="基本类型"></li></ul></li></ul></li><li><p>Java虚拟机在调用Java方法的时候，会创建出一个栈帧，对于其中的解释栈帧来说，有两个主要组成部分</p><ul><li>局部变量区<ul><li>局部变量</li><li>this指针</li><li>方法接收的参数</li><li>各个基本类型在局部变量区的表现<ul><li>局部变量区等价于一个数组<ul><li>long double需要两个数组单元存储</li><li>其他基本类型和引用类型的值均占用一个数组单元</li></ul></li></ul></li></ul></li><li>字节码的操作数栈</li></ul></li><li><p>存储操作</p><ul><li>如果我们将一个int类型的值放到char short 等里面，相当于做了一次掩码  只会保留低位了</li></ul></li><li><p>加载</p><ul><li>算数运算完全依赖于操作数栈</li><li>堆当中的boolean, byte, char, short 加载到操作数栈当中，而后将栈上的值当成int类型来运算</li></ul></li></ul><h1 id="3-类的加载，链接，初始化过程"><a href="#3-类的加载，链接，初始化过程" class="headerlink" title="3. 类的加载，链接，初始化过程"></a>3. 类的加载，链接，初始化过程</h1><ul><li>首先.java文件会被编译成.class文件，而后我们需要类加载器来处理.class文件，让JVM对其进行处理</li><li>从class文件到内存当中的类，需要经过：<ul><li>加载<ul><li>查找字节流，并且根据此来创建类的过程<ul><li>将class类加载到内存当中</li><li>将静态数据结构转化为方法区当中运行时的数据结构</li><li>在堆当中生成一个代表这个类的java.lang.class对象作为数据访问的入口</li></ul></li><li>借助类加载器来完成查找字节流的过程<ul><li>启动类加载器 — bootstrap class loader<ul><li>负责加载最基础最重要的类，譬如JRE lib目录下Jar包中的类</li><li>由虚拟机参数 -Xbootclasspath指定的类</li></ul></li><li>其他类加载器 — 都是java.lang.ClassLoader的子类<ul><li>需要先由启动类加载器，将其加载至Java虚拟机当中，方能执行类的加载</li><li>E.G<ul><li>扩展类加载器 — 父类是启动类加载器<ul><li>负责加载相对次要、但又通用的类，比如存放在 JRE 的 lib/ext 目录下 jar 包中的类（以及由系统变量 java.ext.dirs 指定的类）</li></ul></li><li>应用类加载器 — 父类是扩展类加载器<ul><li>负责加载应用程序路径下的类<ul><li>例如虚拟机参数 -cp/-classpath, 系统变量java.class.path或者环境变量CLASSPATH所指定的路径</li><li>默认应用程序里包含的类应该由应用类加载器来进行加载</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>双亲委派模型<ul><li>当一个类加载器接收到加载请求时，会先将请求转发给父类加载器</li><li>在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载</li></ul></li><li>类加载器 — 命名空间的作用<ul><li>类的唯一性由类加载器实例和类的全名共同确定</li><li>即使同一串字节流，经由不同的类加载器加载，也会得到不同的类</li></ul></li></ul></li><li>链接<ul><li>将创建的类合并到Java虚拟机当中，并且使其能够执行的过程</li><li>过程<ul><li>验证<ul><li>确保被加载类能够满足Java虚拟机的约束条件</li><li>安全检查</li></ul></li><li>准备<ul><li>为被加载类的静态字段分配内存<ul><li>就是为static变量在方法区当中分配内存空间，设置变量的初始值</li></ul></li><li>也会来构造和其他类层次相关的数据结构，比如说用来实现虚方法的动态绑定的方法表</li></ul></li><li>解析 — 对于字节码符号引用的解析<ul><li>在 class 文件被加载至 Java 虚拟机之前，这个类无法知道其他类及其方法、字段所对应的具体地址，甚至不知道自己方法、字段的地址。</li><li>因此，每当需要引用这些成员时，Java 编译器会生成一个符号引用。在运行阶段，这个符号引用一般都能够无歧义地定位到具体目标上。</li><li>举例来说，对于一个方法调用，编译器会生成一个包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法。</li><li>解析阶段的目的，正是将这些符号引用解析成为实际引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）</li></ul></li></ul></li></ul></li><li>初始化<ul><li>内容<ul><li>为标记为常量值的字段赋值</li><li>执行clinit方法 — Java虚拟机通过加锁确定clinit方法仅仅会被执行一次<ul><li>如果直接赋值的静态字段被 final 所修饰，并且它的类型是基本类型或字符串时，那么该字段便会被 Java 编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成。</li><li>除此之外的直接赋值操作，以及所有静态代码块中的代码，则会被 Java 编译器置于同一方法中，并把它命名为 &lt; clinit &gt;。</li></ul></li></ul></li><li>触发情况<ul><li>当虚拟机启动时，初始化用户指定的主类；</li><li>当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类；</li><li>当遇到调用静态方法的指令时，初始化该静态方法所在的类；</li><li>当遇到访问静态字段的指令时，初始化该静态字段所在的类；</li><li>子类的初始化会触发父类的初始化；</li><li>如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化；</li><li>使用反射 API 对某个类进行反射调用时，初始化这个类；</li><li>当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。</li></ul></li></ul></li><li>卸载<ul><li>GC将无用对象从内存当中卸载掉</li></ul></li></ul></li><li>基本类型是Java虚拟机已经设置好的，而另一大类引用类型，Java将其细分为四种<ul><li>类<ul><li>有对应的字节流 — class文件</li></ul></li><li>接口<ul><li>有对应的字节流 - class文件</li></ul></li><li>数组类<ul><li>由Java虚拟机直接生成</li></ul></li><li>泛型参数</li></ul></li></ul><h1 id="4-JVM执行方法调用"><a href="#4-JVM执行方法调用" class="headerlink" title="4. JVM执行方法调用"></a>4. JVM执行方法调用</h1><h2 id="4-1-重载和重写"><a href="#4-1-重载和重写" class="headerlink" title="4.1 重载和重写"></a>4.1 重载和重写</h2><ul><li>重载<ul><li>同一个类当中方法名称相同，但是方法的参数不相同的情况</li><li>在编译过程当中就可以完成识别，Java编译器根据传入参数的声明类型，来选取重载方法<ul><li>三个阶段<ul><li>不考虑基本类型的自动拆箱装箱，还有可变长参数的情况下选择重载方法</li><li>1阶段没有找到适配的方法，那么就在允许自动拆装箱，但不允许可变长参数的情况下选取重载方法</li><li>2阶段没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法</li></ul></li><li>如果Java编译器在同一个阶段找到了多个适配方法，那么就会选择一个最为贴切的，决定贴切程度的一个关键就是形式参数类型的继承关系<ul><li>会选择那个范围更小的，比如某某的子类这样子</li></ul></li></ul></li></ul></li><li>重写<ul><li>子类定义了和父类非私有方法同名的方法，而且这两个方法的参数类型相同</li><li>如果这两个方法都是静态的，那么子类中的方法隐藏了父类中的方法</li><li>如果都不是静态，也不是私有的，那么子类的方法重写了父类当中的方法</li><li>方法重写 — 允许子类在继承父类部分功能的同时，拥有自己独特的行为</li></ul></li></ul><h2 id="4-2-JVM-静态和动态绑定"><a href="#4-2-JVM-静态和动态绑定" class="headerlink" title="4.2 JVM 静态和动态绑定"></a>4.2 JVM 静态和动态绑定</h2><ul><li>Java虚拟机识别方法<ul><li>类名</li><li>方法名</li><li>方法描述符 — method descriptor<ul><li>由方法的参数类型以及<strong>返回类型</strong>所构成的</li></ul></li></ul></li><li>JVM和Java语言在这里不太一样，同一个类下同样方法名，同样参数，但是不同返回值从JVM角度来说是可以被认为是不同的方法，是可以通过的</li><li>静态绑定<ul><li>在解析的时候便能够识别目标方法的情况</li><li>重载 — 是在编译阶段就完成了的，也可以成为static binding</li></ul></li><li>动态绑定<ul><li>在运行过程当中根据调用者的动态类型来识别目标方法的情况</li><li>重写 — 在JVM当中来做识别，dynamic binding</li></ul></li><li>Java字节码当中和调用相关的指令<ul><li>invokestatic  - 用于调用静态方法</li><li>invokespecial - 用于调用私有实例方法，构造器  以及使用super关键字调用父类的实例方法或者构造器</li><li>invokevirtual  - 用于调用非私有实例方法</li><li>invokeinterface - 用于调用接口方法</li><li>invokedynamic - 用于调用动态方法</li></ul></li></ul><h2 id="4-3-调用指令的符号引用"><a href="#4-3-调用指令的符号引用" class="headerlink" title="4.3 调用指令的符号引用"></a>4.3 调用指令的符号引用</h2><ul><li>在编译过程当中，我们并不知道目标方法的具体内存地址<ul><li>Java编译器会暂时用符号引用来表示该目标方法</li><li>这一符号引用包括目标方法所在的类或接口的名字，以及目标方法的方法名和方法描述符。</li></ul></li></ul><h1 id="5-垃圾回收"><a href="#5-垃圾回收" class="headerlink" title="5. 垃圾回收"></a>5. 垃圾回收</h1><h2 id="5-1-如何判断需要清理一个对象"><a href="#5-1-如何判断需要清理一个对象" class="headerlink" title="5.1 如何判断需要清理一个对象"></a>5.1 如何判断需要清理一个对象</h2><p><img src="https://i.loli.net/2021/06/28/dtOa3GUh5SkbAVY.png" alt="判断是否需要清理对象的逻辑"></p><ul><li>绿色部分是线程拥有的，会随着线程的结束而自动被回收 这里不需要考虑垃圾回收的问题</li><li>橙色部分是共享的，内存分配和回收都是动态的，因此垃圾收集器所关注的都是堆和方法这部分内存</li><li>判断对象存活的方法<ul><li>引用计数器计算<ul><li>给对象添加一个引用计数器，每次引用这个对象的时候计数器加一，引用失效则减一</li><li>计数器等于零的时候就不会再次试用了</li></ul></li><li>可达性分析计算<ul><li>将一系列GC ROOTS作为起始的存活对象集，从这个节点往下搜索</li><li>搜索所走过的路径成为引用链，将能被该集合引用的对象加入到集合当中</li><li>当搜索到一个对象到GC roots没有使用任何引用链的时候，就说明这个对象是不可用的</li></ul></li></ul></li></ul><h2 id="5-2-如何宣告一个对象的结束-死亡"><a href="#5-2-如何宣告一个对象的结束-死亡" class="headerlink" title="5.2 如何宣告一个对象的结束/ 死亡"></a>5.2 如何宣告一个对象的结束/ 死亡</h2><ul><li>finalize()是Object类的一个方法，一个对象的finalize()方法只会被系统自动调用一次，经过finalize()方法逃脱死亡的对象，二次标记的时候会给移出</li><li>整个流程如下<ol><li>如果对象进行可达性分析之后没发现与GC Roots相连的引用链，那它将会第一次标记并且进行一次筛选。判断的条件是决定这个对象是否有必要执行finalize()方法。如果对象有必要执行finalize()方法，则被放入F-Queue队列中。</li><li>GC对F-Queue队列中的对象进行二次标记。如果对象在finalize()方法中重新与引用链上的任何一个对象建立了关联，那么二次标记时则会将它移出“即将回收”集合。如果此时对象还没成功逃脱，那么只能被回收了。</li></ol></li></ul><h2 id="5-3-垃圾回收算法"><a href="#5-3-垃圾回收算法" class="headerlink" title="5.3 垃圾回收算法"></a>5.3 垃圾回收算法</h2><h3 id="5-3-1-标记清除算法"><a href="#5-3-1-标记清除算法" class="headerlink" title="5.3.1 标记清除算法"></a>5.3.1 标记清除算法</h3><ul><li><p>阶段</p><ul><li>标记<ul><li>标记处所有需要回收的对象</li></ul></li><li>清除<ul><li>标记结束以后进行统一的回收</li></ul></li></ul></li><li><p>原理</p><ul><li>将已死亡的对象标记为空闲内存，记录在一个空闲列表当中</li><li>当我们需要new一个对象的时候，内存管理模块会从空闲列表当中寻找空闲的内存来分给新的对象</li></ul></li><li><p>缺陷</p><ul><li><p>会使得内存当中的碎片非常多</p></li><li><p>容易导致当我们需要使用大块的内存的时候，无法分配足够的连续内存</p><p> <img src="https://i.loli.net/2021/06/28/TkZEf72unqIHLBY.png" alt="标记清除算法"></p></li></ul></li></ul><h3 id="5-3-2-复制算法"><a href="#5-3-2-复制算法" class="headerlink" title="5.3.2 复制算法"></a>5.3.2 复制算法</h3><ul><li><p>在标记清除算法的基础上做的优化</p><ul><li>将可用内存按照容量划分成两等分，每次只使用其中一块</li><li>当一块存满了 就将存活的对象复制到另一块上，然后交换指针的内容</li><li>以此解决碎片化的问题</li></ul></li><li><p>缺陷</p><ul><li><p>可用内存减少了！</p><p><img src="https://i.loli.net/2021/06/28/fQY3p1658zJkIxb.png" alt="复制算法"></p></li></ul></li></ul><h3 id="5-3-3-标记整理算法"><a href="#5-3-3-标记整理算法" class="headerlink" title="5.3.3 标记整理算法"></a>5.3.3 标记整理算法</h3><ul><li>标记了以后会做整理，将所有存活的对象都向内存块一端移动，然后直接清理掉边界以外的内存</li></ul><p><img src="https://i.loli.net/2021/06/28/7CNKE8HvLgVzrPk.png" alt="标记整理算法"></p><h3 id="5-3-4-分代收集算法"><a href="#5-3-4-分代收集算法" class="headerlink" title="5.3.4 分代收集算法"></a>5.3.4 分代收集算法</h3><ul><li>根据对象存活周期的不同将内存划分为几块</li><li>新生代<ul><li>每次垃圾收集都有大批对象死去，少量存活</li><li>所以可以选用复制算法</li></ul></li><li>老年代<ul><li>对象存活率高，没有额外空间对其进行分配和担保</li><li>需要使用标记-清理或者标记整理算法来进行回收</li></ul></li></ul><h2 id="5-4-垃圾收集器"><a href="#5-4-垃圾收集器" class="headerlink" title="5.4 垃圾收集器"></a>5.4 垃圾收集器</h2><ul><li>jdk8 默认收集器是Parallel Scavenge 和 Parallel Old</li><li>jdk9开始，G1收集器成为默认的垃圾收集器</li></ul><p><img src="https://i.loli.net/2021/06/28/hsKHpeEGm4lQydA.png" alt="垃圾收集器列表"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/[%E5%8A%A0%E9%A4%90]%E5%A4%A7%E7%99%BD%E8%AF%9D%E5%B8%A6%E4%BD%A0%E8%AE%A4%E8%AF%86JVM" target="_blank" rel="noopener">JavaGuide</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Java虚拟机基本原理&quot;&gt;&lt;a href=&quot;#Java虚拟机基本原理&quot; class=&quot;headerlink&quot; title=&quot;Java虚拟机基本原理&quot;&gt;&lt;/a&gt;Java虚拟机基本原理&lt;/h1&gt;&lt;h1 id=&quot;1-Java-代码运行方式&quot;&gt;&lt;a href=&quot;#1-Ja
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Java" scheme="https://www.llchen60.com/tags/Java/"/>
    
      <category term="JVM" scheme="https://www.llchen60.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>Log4j 是如何工作的？ </title>
    <link href="https://www.llchen60.com/Log4j-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F/"/>
    <id>https://www.llchen60.com/Log4j-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F/</id>
    <published>2021-04-25T01:15:48.000Z</published>
    <updated>2021-06-28T00:46:40.885Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Log4j-是如何工作的？"><a href="#Log4j-是如何工作的？" class="headerlink" title="Log4j 是如何工作的？"></a>Log4j 是如何工作的？</h1><p>Created: Apr 24, 2021 5:02 PM<br>Tags: backend, tech<br>status: In Progress</p><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>组件化设计的日志系统</li></ul><pre><code>log.info(&quot;User signed in.&quot;); │ │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐ ├──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│ Console  │ │   └──────────┘    └──────────┘    └──────────┘    └──────────┘ │ │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐ ├──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│   File   │ │   └──────────┘    └──────────┘    └──────────┘    └──────────┘ │ │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐ └──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│  Socket  │     └──────────┘    └──────────┘    └──────────┘    └──────────┘</code></pre><ul><li>通过appender将同一条日志输出到不同的目的地</li></ul><h2 id="1-1-Logger组件"><a href="#1-1-Logger组件" class="headerlink" title="1.1 Logger组件"></a>1.1 Logger组件</h2><ul><li>负责产生日志，</li><li>级别<ul><li>DEBUG</li><li>INFO</li><li>WARN</li><li>ERROR</li><li>FATAL</li></ul></li></ul><h2 id="1-2-Appenders-组件"><a href="#1-2-Appenders-组件" class="headerlink" title="1.2 Appenders 组件"></a>1.2 Appenders 组件</h2><ul><li>负责将日志输出到不同的地方<ul><li>控制台 Console</li><li>文件 Files<ul><li>根据天数或者文件大小来产生新的文件</li></ul></li></ul></li></ul><h2 id="1-3-Layout"><a href="#1-3-Layout" class="headerlink" title="1.3 Layout"></a>1.3 Layout</h2><ul><li>完整文档<ul><li><a href="https://logging.apache.org/log4j/2.x/manual/layouts.html" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/manual/layouts.html</a></li></ul></li><li>说明你的日志要以何种格式来进行输出</li></ul><pre><code class="jsx">－X号: X信息输出时左对齐；%p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL,%d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss,SSS}输出类似：2002年10月18日 22：10：28，921%r: 输出自应用启动到输出该log信息耗费的毫秒数%c: 输出日志信息所属的类目，通常就是所在类的全名%t: 输出产生该日志事件的线程名%l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java:10)%x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像java servlets这样的多客户多线程的应用中。%%: 输出一个&quot;%&quot;字符%F: 输出日志消息产生时所在的文件名称%L: 输出代码中的行号%m: 输出代码中指定的消息,产生的日志具体信息%n: 输出一个回车换行符，Windows平台为&quot;/r/n&quot;，Unix平台为&quot;/n&quot;输出日志信息换行</code></pre><h1 id="2-XML-配置文件格式"><a href="#2-XML-配置文件格式" class="headerlink" title="2. XML 配置文件格式"></a>2. XML 配置文件格式</h1><ul><li>通过Filter来过滤哪些需要输出，哪些不需要</li><li>通过Layout来格式化日志信息</li></ul><pre><code class="jsx">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration&gt;    &lt;Properties&gt;        &lt;!-- 定义日志格式 --&gt;        &lt;Property name=&quot;log.pattern&quot;&gt;%d{MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36}%n%msg%n%n&lt;/Property&gt;        &lt;!-- 定义文件名变量 --&gt;        &lt;Property name=&quot;file.err.filename&quot;&gt;log/err.log&lt;/Property&gt;        &lt;Property name=&quot;file.err.pattern&quot;&gt;log/err.%i.log.gz&lt;/Property&gt;    &lt;/Properties&gt;    &lt;!-- 定义Appender，即目的地 --&gt;    &lt;Appenders&gt;        &lt;!-- 定义输出到屏幕 --&gt;        &lt;Console name=&quot;console&quot; target=&quot;SYSTEM_OUT&quot;&gt;            &lt;!-- 日志格式引用上面定义的log.pattern --&gt;            &lt;PatternLayout pattern=&quot;${log.pattern}&quot; /&gt;        &lt;/Console&gt;        &lt;!-- 定义输出到文件,文件名引用上面定义的file.err.filename --&gt;        &lt;RollingFile name=&quot;err&quot; bufferedIO=&quot;true&quot; fileName=&quot;${file.err.filename}&quot; filePattern=&quot;${file.err.pattern}&quot;&gt;            &lt;PatternLayout pattern=&quot;${log.pattern}&quot; /&gt;            &lt;Policies&gt;                &lt;!-- 根据文件大小自动切割日志 --&gt;                &lt;SizeBasedTriggeringPolicy size=&quot;1 MB&quot; /&gt;            &lt;/Policies&gt;            &lt;!-- 保留最近10份 --&gt;            &lt;DefaultRolloverStrategy max=&quot;10&quot; /&gt;        &lt;/RollingFile&gt;    &lt;/Appenders&gt;    &lt;Loggers&gt;        &lt;Root level=&quot;info&quot;&gt;            &lt;!-- 对info级别的日志，输出到console --&gt;            &lt;AppenderRef ref=&quot;console&quot; level=&quot;info&quot; /&gt;            &lt;!-- 对error级别的日志，输出到err，即上面定义的RollingFile --&gt;            &lt;AppenderRef ref=&quot;err&quot; level=&quot;error&quot; /&gt;        &lt;/Root&gt;    &lt;/Loggers&gt;&lt;/Configuration&gt;</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.liaoxuefeng.com/wiki/1252599548343744/1264739436350112" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/1252599548343744/1264739436350112</a> </li><li><a href="https://blog.csdn.net/Mos_wen/article/details/50598967" target="_blank" rel="noopener">https://blog.csdn.net/Mos_wen/article/details/50598967</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Log4j-是如何工作的？&quot;&gt;&lt;a href=&quot;#Log4j-是如何工作的？&quot; class=&quot;headerlink&quot; title=&quot;Log4j 是如何工作的？&quot;&gt;&lt;/a&gt;Log4j 是如何工作的？&lt;/h1&gt;&lt;p&gt;Created: Apr 24, 2021 5:02
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="log" scheme="https://www.llchen60.com/tags/log/"/>
    
      <category term="log4j" scheme="https://www.llchen60.com/tags/log4j/"/>
    
  </entry>
  
  <entry>
    <title>Route53</title>
    <link href="https://www.llchen60.com/Route53/"/>
    <id>https://www.llchen60.com/Route53/</id>
    <published>2021-03-20T20:10:21.000Z</published>
    <updated>2021-03-20T20:11:01.960Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Route-53"><a href="#Route-53" class="headerlink" title="Route 53"></a>Route 53</h1><h1 id="1-How-Route53-works"><a href="#1-How-Route53-works" class="headerlink" title="1. How Route53 works?"></a>1. How Route53 works?</h1><ul><li>Intro<ul><li>DNS webservice</li><li>functionalities<ul><li>domain registration</li><li>DNS routing</li><li>health checking</li></ul></li></ul></li><li>Domain Registration<ul><li>You choose a domain name and confirm that it’s available</li><li>You provide names and contact information for the domain owner and other contacts</li><li>Route 53 automatically makes itself the DNS service for the domain by doing:<ul><li>create a hosted zone that has the same name as your domain</li><li>Assigns a set of <strong>four name servers to the hosted zone</strong>. When someone uses a browser to access your website, such as <a href="http://www.example.com/" target="_blank" rel="noopener">www.example.com</a>, these name servers tell the browser where to find your resources, such as a web server or an Amazon S3 bucket.</li><li>Gets the name servers from the hosted zone and adds them to the domain.</li></ul></li></ul></li></ul><h1 id="2-Concepts"><a href="#2-Concepts" class="headerlink" title="2. Concepts"></a>2. Concepts</h1><ul><li>Hosted Zone<ul><li>A container for records<ul><li>include info about how you want to route traffic for a domain and all of its subdomains</li><li>It has the same name as domain</li><li></li></ul></li></ul></li><li>Records<ul><li>Created in your hosted zone</li><li>For routing traffic to your resources</li><li>Each record includes information about how you want to route traffic for your domain<ul><li>Name</li><li>Type</li><li>Value</li></ul></li></ul></li><li>Name server<ul><li>Route53 will assign a set of 4 name servers to the hosted zone</li><li>name server tell the accessor (browser) where to find your resources</li></ul></li><li>Domain Name System Concepts<ul><li>Alias Record<ul><li>Record you create to route traffic to AWS resources</li></ul></li><li>subdomain<ul><li>A domain name that has one or more labels prepended to the registered domain name. For example, if you register the domain name <a href="http://example.com/" target="_blank" rel="noopener">example.com</a>, then <a href="http://www.example.com/" target="_blank" rel="noopener">www.example.com</a> is a subdomain. If you create the hosted zone <a href="http://accounting.example.com/" target="_blank" rel="noopener">accounting.example.com</a> for the <a href="http://example.com/" target="_blank" rel="noopener">example.com</a> domain, then <a href="http://seattle.accounting.example.com/" target="_blank" rel="noopener">seattle.accounting.example.com</a> is a subdomain.</li></ul></li></ul></li></ul><h1 id="3-Working-with-Hosted-Zones"><a href="#3-Working-with-Hosted-Zones" class="headerlink" title="3. Working with Hosted Zones"></a>3. Working with Hosted Zones</h1><p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-working-with.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-working-with.html</a> </p><h1 id="4-Routing-Traffic-for-subdomains"><a href="#4-Routing-Traffic-for-subdomains" class="headerlink" title="4. Routing Traffic for subdomains"></a>4. Routing Traffic for subdomains</h1><p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-routing-traffic-for-subdomains.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-routing-traffic-for-subdomains.html</a> </p><ul><li>Option 1:<ul><li>Create records in the hosted zone for the doamin</li><li>we could create a record named <a href="http://test.example.com" target="_blank" rel="noopener">test.example.com</a> in the example.com hosted zone</li></ul></li><li>Option 2:<ul><li>Create a hosted zone for the subdomain, and create records in the new hosted zone</li></ul></li></ul><h1 id="5-Routing-Traffic-to-AWS-Resources"><a href="#5-Routing-Traffic-to-AWS-Resources" class="headerlink" title="5. Routing Traffic to AWS Resources"></a>5. Routing Traffic to AWS Resources</h1><p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-aws-resources.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-aws-resources.html</a> </p><ul><li>The logic is to leverage on AWS PrivateLink for cross vpc connection, create the interface endpoint in your service, and build connection between your VPC and Route53</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Route-53&quot;&gt;&lt;a href=&quot;#Route-53&quot; class=&quot;headerlink&quot; title=&quot;Route 53&quot;&gt;&lt;/a&gt;Route 53&lt;/h1&gt;&lt;h1 id=&quot;1-How-Route53-works&quot;&gt;&lt;a href=&quot;#1-How-Rout
      
    
    </summary>
    
    
      <category term="Cloud" scheme="https://www.llchen60.com/categories/Cloud/"/>
    
    
      <category term="DNS" scheme="https://www.llchen60.com/tags/DNS/"/>
    
  </entry>
  
  <entry>
    <title>Elastic Load Balancing </title>
    <link href="https://www.llchen60.com/Elastic-Load-Balancing/"/>
    <id>https://www.llchen60.com/Elastic-Load-Balancing/</id>
    <published>2021-03-09T04:59:23.000Z</published>
    <updated>2021-03-09T05:00:46.137Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Elastic-Load-Balancing"><a href="#Elastic-Load-Balancing" class="headerlink" title="Elastic Load Balancing"></a>Elastic Load Balancing</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>What is ELB?</p><ul><li>ELB distributes your incoming traffic across multiple targets, such as EC2 instances, containers, and IP addresses, in one or more AZs</li><li>It monitors the health of its registered targets, and routes traffic to the healthy targets</li><li>Elastic Load Balancing help scale your load balancer as your incoming traffic change over time — automatically scale to the vast majority of workloads</li></ul></li><li><p>Benefits</p><ul><li>Increase the availability and fault tolerance</li><li>You could configure health checks, thus ELB monitor the health of the compute resources, LB only send requests to the healthy ones</li></ul></li><li><p>How it works</p><ul><li>Listener<ul><li>configure your LB to accept incoming traffic by specifying one or more listeners</li><li>a process that checks for connection requests<ul><li>with a protocol</li><li>port number</li></ul></li></ul></li><li>cross zone load balancing<ul><li>we should enable it cause it could make sure traffic is well distributed</li><li>when client send request, it will first go through route 53, and route 53 will distribute traffic thus each lb node receives 50% of traffic (2 LB nodes in total )</li></ul></li><li>request routing<ul><li>client — amazon dns service — return IP address to client side — client use the ip address to make call to LB</li><li>dns entry specify the TTL to 60 seconds, this ensure that the IP addresses can be remapped quickly in response to changing traffic</li></ul></li></ul></li></ul><h1 id="2-ELB-Types"><a href="#2-ELB-Types" class="headerlink" title="2. ELB Types"></a>2. ELB Types</h1><p><a href="https://aws.amazon.com/elasticloadbalancing/features/#Product_comparisons" target="_blank" rel="noopener">https://aws.amazon.com/elasticloadbalancing/features/#Product_comparisons</a>  </p><h1 id="3-Network-Load-Balancer"><a href="#3-Network-Load-Balancer" class="headerlink" title="3. Network Load Balancer"></a>3. Network Load Balancer</h1><h2 id="3-1-NLB-Overview"><a href="#3-1-NLB-Overview" class="headerlink" title="3.1 NLB Overview"></a>3.1 NLB Overview</h2><ul><li>Similar to ELB overview, NLB has listener<ul><li>a listener checks for connection requests from clients, using the protocol and port number you configure, and then forwards requests to a target group</li></ul></li><li>you can configure your health checks on a per target group basis</li><li>Health checks are performed on all targets registered to a target group that is specified in a listener rule for your load balancer.</li><li>functions at 4th layer of OSI, capable of handling millions of requests per second<ul><li>when receives a connection request, it <strong>selects a target from the target group</strong> for the default rule</li><li>attempts to <strong>open a TCP connection</strong> to the selected target <strong>on the port specified</strong> in the listener configuration</li></ul></li></ul><h2 id="3-2-How-to-create-one-NLB-via-Console"><a href="#3-2-How-to-create-one-NLB-via-Console" class="headerlink" title="3.2 How to create one NLB via Console?"></a>3.2 How to create one NLB via Console?</h2><ul><li>Create a target group<ul><li>set target type, name, protocol, port number, health check method</li></ul></li><li>Configure load balancer and listener<ul><li>Network mapping<ul><li>select the VPC that you used for your EC2 instances</li><li>select AZ and then select public subnet for the AZ</li></ul></li></ul></li></ul><h2 id="3-3-Concepts"><a href="#3-3-Concepts" class="headerlink" title="3.3 Concepts"></a>3.3 Concepts</h2><ul><li>Listener<ul><li>A listener is a process that checks for connection requests, using the protocol and port that you configure. The rules that you define for a listener determine how the load balancer routes requests to the targets in one or more target groups.</li></ul></li><li>Target Groups<ul><li>Each target group is used to route requests to one or more registered targets. When you create a listener, you specify a target group for its default action. Traffic is forwarded to the target group specified in the listener rule. You can create different target groups for different types of requests</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Elastic-Load-Balancing&quot;&gt;&lt;a href=&quot;#Elastic-Load-Balancing&quot; class=&quot;headerlink&quot; title=&quot;Elastic Load Balancing&quot;&gt;&lt;/a&gt;Elastic Load Balanci
      
    
    </summary>
    
    
      <category term="Cloud" scheme="https://www.llchen60.com/categories/Cloud/"/>
    
    
      <category term="Load Balancer" scheme="https://www.llchen60.com/tags/Load-Balancer/"/>
    
  </entry>
  
  <entry>
    <title>VPC General</title>
    <link href="https://www.llchen60.com/VPC-General/"/>
    <id>https://www.llchen60.com/VPC-General/</id>
    <published>2021-03-03T04:42:42.000Z</published>
    <updated>2021-03-03T04:47:10.401Z</updated>
    
    <content type="html"><![CDATA[<h1 id="VPC-General"><a href="#VPC-General" class="headerlink" title="VPC General"></a>VPC General</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>Enable you to launch AWS resources into a virtual network that you’ve defined</li><li>VPC helps you to resemble a traditional network that you’d operate in your own data center</li></ul><h2 id="1-1-Concepts"><a href="#1-1-Concepts" class="headerlink" title="1.1 Concepts"></a>1.1 Concepts</h2><ul><li>VPC</li><li>Subnet<ul><li>A range of IP addresses in the VPC</li></ul></li><li>Route Table<ul><li>A set of rules, called routes, used to determine where network traffic is directed</li></ul></li><li>Internet Gateway<ul><li>A gateway that you attach to your VPC to enable communication between resources in your VPC and the internet</li></ul></li><li>VPC endpoint<ul><li>Enable you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway , NAT device, VPN connection, or AWS Direct Connect Connenction</li></ul></li><li>CIDR block<ul><li>classless inter domain routing</li></ul></li></ul><h1 id="2-How-Amazon-VPC-Work"><a href="#2-How-Amazon-VPC-Work" class="headerlink" title="2. How Amazon VPC Work?"></a>2. How Amazon VPC Work?</h1><h2 id="2-1-VPC-and-Subnets"><a href="#2-1-VPC-and-Subnets" class="headerlink" title="2.1 VPC and Subnets"></a>2.1 VPC and Subnets</h2><ul><li>Use public subnet for resources that must be connected to the internet</li><li>Use private subnet for resources that won’t be connected to the internet</li><li>To protect the AWS resources in each subnet<ul><li>you could use Security groups, network access control lists</li></ul></li></ul><h2 id="2-2-Accessing-the-internet"><a href="#2-2-Accessing-the-internet" class="headerlink" title="2.2 Accessing the internet"></a>2.2 Accessing the internet</h2><ul><li>Both subnets are public, they have both private and public IP address</li><li>They could access internet via Internet gateway</li></ul><p><img src="https://i.loli.net/2021/03/03/zdUi1WXuODGofjK.png" alt="1.png"></p><ul><li>NAT Device vs Internet Gateway<ul><li>When using NAT, it’s another layer of protection, but ultimately, you still need to use Internet Gateway</li><li>NAT  — network address translation device<ul><li>Allow instance in your VPC to instantiate outbound connections to the internet but prevent unsolicited inbound connections from the internet</li><li>It maps multiple private IPv4 addresses to a single public IPv4 address</li><li>A NAT device has an Elastic IP address and is connected to the internet through an internet gateway</li><li>You can connect an instance in a private subnet to the internet through the NAT device, which <strong>routes traffic from the instance to the internet gateway</strong>, and routes any responses to the instance.</li></ul></li></ul></li></ul><h2 id="2-3-Accessing-services-through-AWS-PrivateLink"><a href="#2-3-Accessing-services-through-AWS-PrivateLink" class="headerlink" title="2.3 Accessing services through AWS PrivateLink"></a>2.3 Accessing services through AWS PrivateLink</h2><ul><li><p>AWS PrivateLink enables you to privately connect your VPC to supported AWS services, services hosted by other AWS accounts (VPC endpoint services), and supported AWS Marketplace partner services.</p></li><li><p>To use AWS PrivateLink, create a VPC endpoint for a service in your VPC</p><ul><li><p>this creates an elastic network interface in your subnet with a private IP address that serves as an entry point for the traffic destined to the service</p><p>  <img src="https://i.loli.net/2021/03/03/KdQbqJLR2Or1DnB.png" alt="2.png"></p></li></ul></li></ul><h1 id="3-Getting-Started"><a href="#3-Getting-Started" class="headerlink" title="3. Getting Started"></a>3. Getting Started</h1><ul><li>Create a VPC with a /16 CIDR block<ul><li>has 65,536 private IP addresses</li></ul></li><li>attach an internet gateway to the VPC</li><li>for instances in public subnet, you need to assign an Elastic IP address to the instance</li><li>create a size /24 subnet in the VPC</li><li>create a custom route table, associate it with subnet<ul><li>to flow traffic between the subnet and the internet gateway</li></ul></li></ul><h2 id="3-1-EG-VPC-with-a-single-public-subnet"><a href="#3-1-EG-VPC-with-a-single-public-subnet" class="headerlink" title="3.1 EG - VPC with a single public subnet"></a>3.1 EG - VPC with a single public subnet</h2><h3 id="3-1-1-Basic-Setting"><a href="#3-1-1-Basic-Setting" class="headerlink" title="3.1.1 Basic Setting"></a>3.1.1 Basic Setting</h3><ul><li><p>VPC with/16 CIDR</p></li><li><p>subnet with /24 CIDR</p></li><li><p>internet gateway</p><ul><li>help connect the VPC to the internet and to other AWS services</li></ul></li><li><p>custom route table</p><ul><li><p>enable instances in the subnet to use IPV4 to communicate with other instances in the VPC</p><p><img src="https://i.loli.net/2021/03/03/PulS8ZxvFVXQtcJ.png" alt="3.png"></p></li></ul></li></ul><h3 id="3-1-2-Security"><a href="#3-1-2-Security" class="headerlink" title="3.1.2 Security"></a>3.1.2 Security</h3><ul><li>Security Groups<ul><li>control inbound and outbound traffic for your instances</li></ul></li><li>Network ACLs<ul><li>control inbound and outbound traffic for your subnets</li></ul></li></ul><p>See the recommended Security Group Setting and Network ACLs setting <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario1.html" target="_blank" rel="noopener">here</a> </p><h2 id="3-2-EG-VPC-with-Public-and-Private-subnets-NAT"><a href="#3-2-EG-VPC-with-Public-and-Private-subnets-NAT" class="headerlink" title="3.2 EG - VPC with Public and Private subnets (NAT)"></a>3.2 EG - VPC with Public and Private subnets (NAT)</h2><h3 id="3-2-1-Overview"><a href="#3-2-1-Overview" class="headerlink" title="3.2.1 Overview"></a>3.2.1 Overview</h3><ul><li><p>Scenario</p><ul><li>A public facing web application<ul><li>maintain back end servers that are not publicly accessible</li><li>database server in private subnet while the webserver in a public subnet</li></ul></li></ul></li><li><p>Public subnet vs private subnet</p><ul><li><p>instances in the public subnet can send outbound traffic directly to the internet, whereas the instances in the private subnet can’t</p></li><li><p>the instances in the private subnet can access the Internet by using a network address translation (NAT) gateway that resides in the public subnet</p></li><li><p>The database servers can connect to the Internet for software updates using the NAT gateway, but the Internet cannot establish connections to the database servers</p><p><img src="https://i.loli.net/2021/03/03/cb6tYu79jkWyMOH.png" alt="4.png"></p><h3 id="3-2-2-Security-Setting"><a href="#3-2-2-Security-Setting" class="headerlink" title="3.2.2 Security Setting"></a>3.2.2 Security Setting</h3><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html" target="_blank" rel="noopener">VPC with public and private subnets (NAT)</a></p><h2 id="3-3-Sharing-Public-Subnets-and-Private-Subnets"><a href="#3-3-Sharing-Public-Subnets-and-Private-Subnets" class="headerlink" title="3.3 Sharing Public Subnets and Private Subnets"></a>3.3 Sharing Public Subnets and Private Subnets</h2></li><li><p>still need to leverage on PrivateLinks, VPC Peering, etc.</p><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/example-vpc-share.html" target="_blank" rel="noopener">Example: Sharing public subnets and private subnets</a></p></li><li><p>Consider this scenario where you want an account to be responsible for the infrastructure, including subnets, route tables, gateways, and CIDR ranges and other accounts that are in the same AWS Organization to use the subnets. A VPC owner (Account A) creates the routing infrastructure, including the VPCs, subnets, route tables, gateways, and network ACLs. Account D wants to create public facing applications. Account B and Account C want to create private applications that do not need to connect to the internet and should reside in private subnets. Account A can use AWS Resource Access Manager to create a Resource Share for the subnets and then share the subnets. Account A shares the public subnet with Account D and the private subnet with Account B, and Account C. Account B, Account C, and Account D can create resources in the subnets. Each account can only see the subnets that are shared with them, for example, Account D can only see the public subnet. Each of the accounts can control their resources, including instances, and security groups.</p><p><a href="https://aws.amazon.com/cn/blogs/networking-and-content-delivery/vpc-sharing-a-new-approach-to-multiple-accounts-and-vpc-management/" target="_blank" rel="noopener">VPC sharing: A new approach to multiple accounts and VPC management | Amazon Web Services</a></p><h2 id="3-4-Service-using-AWS-PrivateLink-and-VPC-Peering"><a href="#3-4-Service-using-AWS-PrivateLink-and-VPC-Peering" class="headerlink" title="3.4 Service using AWS PrivateLink and VPC Peering"></a>3.4 Service using AWS PrivateLink and VPC Peering</h2><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-peer-region-example.html" target="_blank" rel="noopener">Examples: Services using AWS PrivateLink and VPC peering</a></p><p><a href="https://www.notion.so/PrivateLinks-e8e5f6802544401299fc3be21b10ed06" target="_blank" rel="noopener">PrivateLinks</a></p></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;VPC-General&quot;&gt;&lt;a href=&quot;#VPC-General&quot; class=&quot;headerlink&quot; title=&quot;VPC General&quot;&gt;&lt;/a&gt;VPC General&lt;/h1&gt;&lt;h1 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overv
      
    
    </summary>
    
    
      <category term="Cloud" scheme="https://www.llchen60.com/categories/Cloud/"/>
    
    
      <category term="VPC" scheme="https://www.llchen60.com/tags/VPC/"/>
    
  </entry>
  
  <entry>
    <title>互联网广告竞价策略</title>
    <link href="https://www.llchen60.com/%E4%BA%92%E8%81%94%E7%BD%91%E5%B9%BF%E5%91%8A%E7%AB%9E%E4%BB%B7%E7%AD%96%E7%95%A5/"/>
    <id>https://www.llchen60.com/%E4%BA%92%E8%81%94%E7%BD%91%E5%B9%BF%E5%91%8A%E7%AB%9E%E4%BB%B7%E7%AD%96%E7%95%A5/</id>
    <published>2021-02-12T19:13:08.000Z</published>
    <updated>2021-02-12T19:14:14.759Z</updated>
    
    <content type="html"><![CDATA[<h1 id="互联网广告竞价策略"><a href="#互联网广告竞价策略" class="headerlink" title="互联网广告竞价策略"></a>互联网广告竞价策略</h1><h1 id="1-传统竞价策略"><a href="#1-传统竞价策略" class="headerlink" title="1. 传统竞价策略"></a>1. 传统竞价策略</h1><h2 id="1-1-英式拍卖-公开增价拍卖OAB"><a href="#1-1-英式拍卖-公开增价拍卖OAB" class="headerlink" title="1.1 英式拍卖/ 公开增价拍卖OAB"></a>1.1 英式拍卖/ 公开增价拍卖OAB</h2><ul><li>OAB<ul><li>Open Ascending Bid</li></ul></li><li>卖家提供物品，在物品拍卖过程中，买家按照竞价阶梯由低至高喊价，出价最高者成为竞买的赢家</li><li>一般会为竞价设定一个终止时间</li></ul><h2 id="1-2-荷兰式拍卖-Sealed-Bid-Auction"><a href="#1-2-荷兰式拍卖-Sealed-Bid-Auction" class="headerlink" title="1.2 荷兰式拍卖 Sealed Bid Auction"></a>1.2 荷兰式拍卖 Sealed Bid Auction</h2><ul><li>竞价由高到低</li><li>递减直到第一个买家应价成交</li></ul><h2 id="1-3-第一价格密封拍卖-FPSB"><a href="#1-3-第一价格密封拍卖-FPSB" class="headerlink" title="1.3 第一价格密封拍卖 FPSB"></a>1.3 第一价格密封拍卖 FPSB</h2><ul><li>FPSB<ul><li>The first price sealed auction</li></ul></li><li>买方将自己的出价写在一个信封里面，众多买方进行投标，同一时间揭晓信封价格，出价最高者竞价成功</li></ul><h2 id="1-4-第二价格密封拍卖-SPSB"><a href="#1-4-第二价格密封拍卖-SPSB" class="headerlink" title="1.4 第二价格密封拍卖 SPSB"></a>1.4 第二价格密封拍卖 SPSB</h2><ul><li>SPSB<ul><li>The Second Price Sealed Auction</li></ul></li><li>买方将自己的出价写在一个信封里面，众多买方进行投标，同一时间揭晓信封价格，呦出价最高的买家获得物品，但他只需要支付<strong>所有投标者中的第二高价</strong></li></ul><h1 id="2-互联网广告竞价策略"><a href="#2-互联网广告竞价策略" class="headerlink" title="2. 互联网广告竞价策略"></a>2. 互联网广告竞价策略</h1><h2 id="2-1-广义第一价格GFP-Generalized-First-Price"><a href="#2-1-广义第一价格GFP-Generalized-First-Price" class="headerlink" title="2.1 广义第一价格GFP - Generalized First Price"></a>2.1 广义第一价格GFP - Generalized First Price</h2><ul><li>出价高者得，需要支付自己提出的报价</li><li>搜索广告竞价往往按照这种形式，缺点是<ul><li>平台方收益不稳定</li><li>竞价效率不高</li></ul></li><li>只考虑到出价没考虑到点击率，</li><li>价格上会因为相互广告商之间的比较，在一定范围内形成波动</li></ul><h2 id="2-2-广义第二价格GSP-Generalized-Second-Price"><a href="#2-2-广义第二价格GSP-Generalized-Second-Price" class="headerlink" title="2.2 广义第二价格GSP - Generalized Second Price"></a>2.2 广义第二价格GSP - Generalized Second Price</h2><ul><li>出价高者得到广告位，需要支付的是第二高者提出的报价加上一个最小值</li><li>不足之处在于不是一种鼓励讲真话的方式，大家有可能都会写一个很大的数字，认为会用到其他人标识的价格，所以整个解不一定是全局最优化的</li><li>这里的排序可以通过广告的出价排序，也可以通过期望收益最大来排序，即CTR x bid</li></ul><h2 id="2-3-VCG-Vickrey-Clarke-Groves"><a href="#2-3-VCG-Vickrey-Clarke-Groves" class="headerlink" title="2.3 VCG - Vickrey Clarke Groves"></a>2.3 VCG - Vickrey Clarke Groves</h2><ul><li>广告主为网民的一次点击支付他对其他广告主造成的效用损失</li><li>但是这种效用损失在实际场景中会非常难以计算</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.geek-share.com/detail/2606975685.html" target="_blank" rel="noopener">https://www.geek-share.com/detail/2606975685.html</a> </li><li><a href="https://www.wandouip.com/t5i229763/" target="_blank" rel="noopener">https://www.wandouip.com/t5i229763/</a></li><li><a href="https://en.wikipedia.org/wiki/Vickrey%E2%80%93Clarke%E2%80%93Groves_auction" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Vickrey–Clarke–Groves_auction</a>  </li><li><a href="https://en.wikipedia.org/wiki/Vickrey%E2%80%93Clarke%E2%80%93Groves_auction" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Vickrey–Clarke–Groves_auction</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;互联网广告竞价策略&quot;&gt;&lt;a href=&quot;#互联网广告竞价策略&quot; class=&quot;headerlink&quot; title=&quot;互联网广告竞价策略&quot;&gt;&lt;/a&gt;互联网广告竞价策略&lt;/h1&gt;&lt;h1 id=&quot;1-传统竞价策略&quot;&gt;&lt;a href=&quot;#1-传统竞价策略&quot; class=&quot;
      
    
    </summary>
    
    
      <category term="Notes" scheme="https://www.llchen60.com/categories/Notes/"/>
    
    
  </entry>
  
  <entry>
    <title>Redis 数据结构使用</title>
    <link href="https://www.llchen60.com/Redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BD%BF%E7%94%A8/"/>
    <id>https://www.llchen60.com/Redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BD%BF%E7%94%A8/</id>
    <published>2021-02-09T04:30:04.000Z</published>
    <updated>2021-03-02T04:46:14.522Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-数据结构使用"><a href="#Redis-数据结构使用" class="headerlink" title="Redis 数据结构使用"></a>Redis 数据结构使用</h1><h1 id="1-String的内存空间消耗问题"><a href="#1-String的内存空间消耗问题" class="headerlink" title="1. String的内存空间消耗问题"></a>1. String的内存空间消耗问题</h1><h2 id="1-1-String在保存数据时内存空间消耗较多"><a href="#1-1-String在保存数据时内存空间消耗较多" class="headerlink" title="1.1 String在保存数据时内存空间消耗较多"></a>1.1 String在保存数据时内存空间消耗较多</h2><ul><li>String类型除了实际记录的数据，还需要额外的内存空间记录数据长度，空间使用等信息，这些信息被称为元数据</li><li>当实际保存的数据比较小的时候，元数据的空间开销就会比较大</li><li>当保存64位有符号整数的时候<ul><li>String类型会将其保存为一个8字节的Long类型整数</li><li>int编码方式</li></ul></li><li>当保存的数据中包含字符的时候<ul><li>String 用简单动态字符串 Simple Dynamic String ， 共有三部分组成<ul><li>buf<ul><li>字节数组，保存实际数据</li><li>为了表示字节数组的结束，会在数组最后加一个\0. 这里会额外占用一个字节的开销</li></ul></li><li>len<ul><li>占四个字节，表示buf的已用长度</li></ul></li><li>alloc<ul><li>占四个字节，表示buf的实际分配长度，一般来说会大于len</li></ul></li></ul></li><li>故而在上述的分析当中，len 和alloc就是元数据，带来了一部分的额外开销</li></ul></li></ul><h2 id="1-2-RedisObject-的结构"><a href="#1-2-RedisObject-的结构" class="headerlink" title="1.2 RedisObject 的结构"></a>1.2 RedisObject 的结构</h2><ul><li><p>Redis本身支持多种数据类型，而不同数据类型都会有一些相同的元数据需要记录</p><ul><li>最后一次访问的时间</li><li>被引用的次数等</li></ul></li><li><p>因此Redis会用一个RedisObject结构体来统一记录这些元数据，同时指向实际数据</p></li><li><p>另外出于节省内存空间的考虑</p><ul><li><p>当保存的是Long类型整数时，RedisObject中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数，节省了指针的空间开销</p></li><li><p>当保存的是字符串数据，并且字符串小于等于44个字节，RedisObject中的元数据，指针的SDS是一块连续的内存区域，来避免内存碎片</p></li><li><p>当保存的数据量大于44字节的时候，SDS的数据量就会变多，Redis就不再把SDS和RedisObject布局在一起了，会给SDS分配独立的空间，并且用指针指向SDS结构</p><p><img src="https://i.loli.net/2021/02/09/JoY9Hi8NqIElBDW.png" alt="Redis Object"></p></li></ul></li><li><p>在计算总共消耗的内存的时候，值得注意的是除了使用RedisObject本身，Redis还维护了一个全局哈希表来保存所有键值对，这个结构体有三个8字节的指针，共24字节。Redis使用的是jemalloc内存分配库，会根据申请的字节数N，找一个比N大，但是最接近N的2的幂次数作为分配的空间，来减少频繁分配的次数</p></li></ul><p><img src="https://i.loli.net/2021/02/09/xO2vECGYoRdl4jB.png" alt="RedisObject Entity"></p><h1 id="2-压缩列表"><a href="#2-压缩列表" class="headerlink" title="2. 压缩列表"></a>2. 压缩列表</h1><ul><li><p>压缩列表的构成</p><p>  <img src="https://i.loli.net/2021/02/18/ALm8GYT2r7cRXqW.png" alt="压缩列表构成"></p><ul><li><p>表头</p><ul><li>zlbytes — 列表长度</li><li>zltail — 列表尾</li><li>zllen — 列表entry个数</li></ul></li><li><p>表尾</p><ul><li>zlend — 列表结束</li></ul></li><li><p>表entry</p><ul><li>是连续的entry<ul><li>因为是挨着来进行放置的，所以不需要再使用额外的指针进行连接，就可以节省指针所占用的空间了</li></ul></li><li>包括以下几部分：<ul><li>prev_len — 前一个entry的长度</li><li>len — 自身长度  4字节</li><li>encoding — 编码方式 1字节</li><li>content — 保存实际数据</li></ul></li></ul></li><li><p>Redis Hash类型底层有两种实现结构</p><ul><li>压缩列表</li><li>哈希表</li></ul></li><li><p>通过阈值确定应该使用哪一种来保存数据</p><ul><li>hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。</li><li>hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。</li></ul></li></ul></li></ul><h1 id="3-集合的使用"><a href="#3-集合的使用" class="headerlink" title="3. 集合的使用"></a>3. 集合的使用</h1><ul><li>使用场景<ul><li>一个key对应一个数据集合<ul><li>比如手机app的用户登录信息 — 一天对应一系列用户ID或者移动设备ID</li><li>电商商品用户评价列表 — 一个商品对应一系列评论</li></ul></li><li>在这样子的场景当中，除了记录信息，我们还需要对集合当中的数据进行统计，而我们选用的数据类型必须能够高效的统计这些数据</li></ul></li></ul><h2 id="3-1-聚合统计"><a href="#3-1-聚合统计" class="headerlink" title="3.1 聚合统计"></a>3.1 聚合统计</h2><ul><li><p>定义</p><ul><li>指统计多个集合元素的聚合结果</li></ul></li><li><p>例子</p><ul><li>统计多个集合的共有元素</li><li>将两个集合相比，统计其中一个集合独有的元素</li><li>统计多个集合的所有元素</li></ul></li><li><p>当你需要对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择。</p></li><li><p>这里有一个潜在的风险。Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。</p><ul><li>你可以从主从集群中选择一个从库，让它专门负责聚合计算</li><li>或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。</li></ul></li></ul><h2 id="3-2-排序统计"><a href="#3-2-排序统计" class="headerlink" title="3.2 排序统计"></a>3.2 排序统计</h2><ul><li>E.G<ul><li>电商网站提供最新评论列表，需要使得集合当中的元素可以按序排列<ul><li>List和Sorted Set属于有序集合</li><li>List按照元素进入List的顺序进行排序，而Sorted Set根据元素的权重来排序</li></ul></li></ul></li><li>使用list来做排序的问题在于是通过元素在List当中的位置来排序，新元素插入会改变原有的顺序，都会顺次后移</li><li>Sorted Set相对应的是根据元素的实际权重来排序和获取数据<ul><li>Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。</li></ul></li></ul><h2 id="3-3-二值状态统计"><a href="#3-3-二值状态统计" class="headerlink" title="3.3 二值状态统计"></a>3.3 二值状态统计</h2><ul><li>集合元素的取值只有0和1两种<ul><li>可以对于数据结构进行优化，使用Bitmap</li><li>Bitmap本身是使用String类型作为底层数据结构来实现的一种统计二值状态的数据类型，可以将其理解为一个bit数组</li></ul></li><li>查看签到情况的基本操作</li></ul><pre><code class="jsx">// 记录8.3 签到SETBIT uid:sign:3000:202008 2 1// 查询8.3是否签到GETBIT uid:sign:3000:202008 2// 统计该用户20年8月份的签到次数BITCOUNT uid:sign:3000:202008</code></pre><ul><li>统计应用当中10天连续签到的用户数量<ul><li>Bitmap支持使用BITOP命令来对多个Bitmap按位做与，或，异或，的操作，操作结果会保存到一个新的bitmap当中</li><li>在统计 1 亿个用户连续 10 天的签到情况时，你可以把每天的日期作为 key，每个 key 对应一个 1 亿位的 Bitmap，每一个 bit 对应一个用户当天的签到情况。接下来，我们对 10 个 Bitmap 做“与”操作，得到的结果也是一个 Bitmap。在这个 Bitmap 中，只有 10 天都签到的用户对应的 bit 位上的值才会是 1。最后，我们可以用 BITCOUNT 统计下 Bitmap 中的 1 的个数，这就是连续签到 10 天的用户总数了。</li></ul></li></ul><h2 id="3-4-基数统计"><a href="#3-4-基数统计" class="headerlink" title="3.4 基数统计"></a>3.4 基数统计</h2><ul><li>统计一个集合中不重复的元素个数 — 统计网页的UV<ul><li>需要去重 — 一个用户一天内的多次访问只能算一次</li><li>使用set 或者hash的话都会需要将不同的id记录下来，最后看整个数据结构内元素的数量，会很大程度上占用内存</li></ul></li><li>HyperLogLog<ul><li>用于统计基数的数据集合<ul><li>当集合元素数量非常多的时候，计算基数所需的空间是固定的，而且比较小</li><li>有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Redis-数据结构使用&quot;&gt;&lt;a href=&quot;#Redis-数据结构使用&quot; class=&quot;headerlink&quot; title=&quot;Redis 数据结构使用&quot;&gt;&lt;/a&gt;Redis 数据结构使用&lt;/h1&gt;&lt;h1 id=&quot;1-String的内存空间消耗问题&quot;&gt;&lt;a hre
      
    
    </summary>
    
    
      <category term="数据存储" scheme="https://www.llchen60.com/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"/>
    
    
  </entry>
  
  <entry>
    <title>lsof/ ulimit/ ps</title>
    <link href="https://www.llchen60.com/lsof-ulimit-ps/"/>
    <id>https://www.llchen60.com/lsof-ulimit-ps/</id>
    <published>2021-01-24T18:15:47.000Z</published>
    <updated>2021-01-24T18:18:34.009Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-lsof"><a href="#1-lsof" class="headerlink" title="1. lsof"></a>1. lsof</h1><h1 id="1-1-File-Descriptor-in-Linux"><a href="#1-1-File-Descriptor-in-Linux" class="headerlink" title="1.1 File Descriptor in Linux"></a>1.1 File Descriptor in Linux</h1><ul><li>Linux consider everything as a file<ul><li>pipes, sockets, directories, devices, etc</li></ul></li></ul><h1 id="1-2-What-does-lsof-do"><a href="#1-2-What-does-lsof-do" class="headerlink" title="1.2 What does lsof do?"></a>1.2 What does lsof do?</h1><ul><li>lsof means — List Open Files</li><li>some columns need to understand<ul><li>FD<ul><li>stands for file descriptor</li><li>possible values<ul><li>cwd — current working directory</li><li>rtd — root directory</li><li>txt — program text</li><li>mem — memory mapped file</li><li>(number)(parameter)<ul><li>r for read acccess</li><li>w for write</li><li>u for both read and write</li></ul></li></ul></li></ul></li><li>TYPE<ul><li>DIR — directory</li><li>REG — Regular file</li><li>CHR — Character special file</li><li>FIFO — First In First Out</li></ul></li></ul></li></ul><pre><code class="jsx">// show long listing of open files, show cols like Command, PID, USER, FD, TYPE# lsof // display the list of all opened file of uder leilei# lsof -u leilei// find process running on specific port# lsof -i TCP:22// list only IPv4 &amp; IPv6 Open Files # lsof -i 4# lsof -i 6// list open files of TCP port ranges from 11 - 1023# lsof -i TCP:1-1023// exclude user with ^# lsof -i -u^leilei// list all network connections # lsof -i// search by PID # lsof -p PID // kill all activities of particular user # kill -9 `lsof -t -u leilei`</code></pre><h1 id="2-ulimit"><a href="#2-ulimit" class="headerlink" title="2. ulimit"></a>2. ulimit</h1><h1 id="2-1-Overview"><a href="#2-1-Overview" class="headerlink" title="2.1 Overview"></a>2.1 Overview</h1><ul><li>Set or report the resource limit of the current user.</li><li>Use with ulimit requires admin access, it only work on systems that allow control through the shell</li><li>Types of resource limitation<ul><li>hard limit<ul><li>define the physical limit that the user can reach</li></ul></li><li>soft limit<ul><li>manageable by the user, its value can go up to the hard limit</li></ul></li></ul></li><li>system resources are defined in a configuration file located at <code>/etc/security/limits.conf</code></li></ul><h1 id="2-2-Common-Commands"><a href="#2-2-Common-Commands" class="headerlink" title="2.2 Common Commands"></a>2.2 Common Commands</h1><pre><code class="jsx">// print all the resource limits for the current user # ulimit -a// check the value of max core file size # ulimit -c // check the max data seg size# ulimit -d// check the max stack size of current user # ulimit -s// check the max number of user processes # ulimit -u// check the max number of threads # ulimit -T // check the size of virtual memory # ulimit -v // check time each process is allowed to run for # ulimit -t // check how many file descriptors a process can have # ulimit -n </code></pre><h1 id="3-ps"><a href="#3-ps" class="headerlink" title="3. ps"></a>3. ps</h1><h1 id="3-1-Overview"><a href="#3-1-Overview" class="headerlink" title="3.1 Overview"></a>3.1 Overview</h1><ul><li><p>Linux is a multi-tasking and multi-user system</p></li><li><p>so it allows multiple processes to operate simultaneously without interfering with each other</p></li><li><p>A process is an executing instance of a program and carry out different tasks within the operating system</p></li><li><p>PS command help us to review information related with the processes on a system</p><ul><li>used to list the currently running processes and their PIDs along with some other information depends on different options</li></ul></li></ul><h1 id="3-2-Some-common-commands"><a href="#3-2-Some-common-commands" class="headerlink" title="3.2 Some common commands"></a>3.2 Some common commands</h1><ul><li>Some common columns you should know what it means<ul><li>PID - the unique process ID</li><li>TTY - terminal type that the user is logged into</li><li>TIME - amount of CPU in minutes and seconds that the process has been running<ul><li>sometimes you see TIME as 00:00:00, merely means the total accumulated CPU utilization time for any process currently is 0</li></ul></li><li>CMD - name of the command that launched the process</li><li>C - the CPU utilization in percentage</li><li>STIME - the start time of the process</li></ul></li></ul><pre><code class="java"># ps PID TTY          TIME CMD12330 pts/0    00:00:00 bash21621 pts/0    00:00:00 ps// view all the running processes # ps -A # ps -e// view all processes associated with the terminal # ps -T // view all the running processes # ps -r // view all the processes owned by you # ps -x // print all the processes within the system # ps -e// More detailed output by using -f option # ps -e -f // Search for a particular process # ps -C systemd</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.geeksforgeeks.org/lsof-command-in-linux-with-examples/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/lsof-command-in-linux-with-examples/</a>  </p><p><a href="https://www.tecmint.com/10-lsof-command-examples-in-linux/" target="_blank" rel="noopener">https://www.tecmint.com/10-lsof-command-examples-in-linux/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-lsof&quot;&gt;&lt;a href=&quot;#1-lsof&quot; class=&quot;headerlink&quot; title=&quot;1. lsof&quot;&gt;&lt;/a&gt;1. lsof&lt;/h1&gt;&lt;h1 id=&quot;1-1-File-Descriptor-in-Linux&quot;&gt;&lt;a href=&quot;#1-1-Fil
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Distributed Locks with the DynamoDB Lock Client </title>
    <link href="https://www.llchen60.com/Distributed-Locks-with-the-DynamoDB-Lock-Client/"/>
    <id>https://www.llchen60.com/Distributed-Locks-with-the-DynamoDB-Lock-Client/</id>
    <published>2021-01-15T03:51:14.000Z</published>
    <updated>2021-01-15T03:53:09.305Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Distributed-Locks-with-the-DynamoDB-Lock-Client"><a href="#Distributed-Locks-with-the-DynamoDB-Lock-Client" class="headerlink" title="Distributed Locks with the DynamoDB Lock Client"></a>Distributed Locks with the DynamoDB Lock Client</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>DynamoDB Lock Client</p><ul><li>enable you to solve distributed computing problems like leader election and distributed locking with client only code and a DDB table</li></ul></li><li><p>Why we need it</p><ul><li>Distributed Locking is complicated<ul><li>you need to <strong>atomically ensure</strong> only one actor is modifying a <strong>stateful resource</strong> at any given time</li></ul></li></ul></li></ul><h1 id="2-Practical-Example"><a href="#2-Practical-Example" class="headerlink" title="2. Practical Example"></a>2. Practical Example</h1><ul><li>Background<ul><li>A retail bank that want to ensure at most one customer service representative change customer details at a time</li><li>solution<ul><li>temporarily lock customer records during an update</li><li>suppose there are bunch different tables to contain all customer information, as the tables are independent, so we cannot just wrap the changes we need in a relational transaction</li><li>we need to lock customer id at a high level</li><li>You’d do so with a locking API action for a certain duration in your application before making any changes.</li></ul></li></ul></li></ul><h2 id="2-1-Locking-Protocol"><a href="#2-1-Locking-Protocol" class="headerlink" title="2.1 Locking Protocol"></a>2.1 Locking Protocol</h2><ul><li>For a new lock, the lock clients store a lock item in the lock table<ul><li>it stores<ul><li>the host name of the owner</li><li>the lease duration in milliseconds</li><li>a UUID unique to the host</li><li>the host system clock time when the lock was initially created</li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2021/01/15/gk6qico4zUw1YXK.png" alt="Whole Workflow"></p><ol><li>Host A acquires a lock on Moe by writing an item to the lock table on the condition that no item keyed at “Moe” exists yet. Host A<br>acquires the lock with a revision version number (RVN) of UUID.</li><li>Host B tries to get a lock on Moe with a RVN UUID.</li><li>Host B checks to see if a lock already exists with a GetItem call.</li><li>In this case, host B finds that host A holds a lock on Moe with a record version number (RVN) of UUID. The same application runs on hosts A and B. That being so, host B<br>expects host A to heartbeat and renew the lock on Moe in less than 10 seconds, if host A intends to keep the lock on Moe. Host A heartbeats once, and uses a conditional update on the lock keyed at Moe to update the RVN of the lock to UUID.</li><li>Host B checks 10 seconds after the first AcquireLock call to see if the RVN in A’s lock on Moe changed with a conditional UpdateItem call and a RVN of UUID.</li><li>Host A successfully updates the lock. Thus, host B finds the new RVN equal to UUID and waited 10 more seconds. Host A died after the first heartbeat, so it never changes the RVN past UUID. When host B calls tries to acquire a lock on Moe for the third time, it finds that the RVN was still UUID, the same RVN retrieved on the second lock attempt.</li><li>In this case, hosts A and B run the same application. Because host B expects host A to heartbeat if host A is healthy and intends to keep the lock, host B considers the lock on Moe expired. Host B’s conditional update to acquire the lock on Moe succeeds, and your application makes progress!</li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://aws.amazon.com/blogs/database/building-distributed-locks-with-the-dynamodb-lock-client/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/database/building-distributed-locks-with-the-dynamodb-lock-client/</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Distributed-Locks-with-the-DynamoDB-Lock-Client&quot;&gt;&lt;a href=&quot;#Distributed-Locks-with-the-DynamoDB-Lock-Client&quot; class=&quot;headerlink&quot; title
      
    
    </summary>
    
    
      <category term="Cloud" scheme="https://www.llchen60.com/categories/Cloud/"/>
    
    
  </entry>
  
</feed>
