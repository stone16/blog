<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Leilei&#39;s Blog | 磊磊的博客</title>
  
  <subtitle>Because it&#39;s there</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.llchen60.com/"/>
  <updated>2020-02-02T23:08:01.245Z</updated>
  <id>https://www.llchen60.com/</id>
  
  <author>
    <name>Leilei Chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>工厂方法模式</title>
    <link href="https://www.llchen60.com/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/"/>
    <id>https://www.llchen60.com/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/</id>
    <published>2020-02-02T23:06:53.000Z</published>
    <updated>2020-02-02T23:08:01.245Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>简单工厂模式虽然简单，但存在一个很严重的问题。当系统中需要引入新产品时，由于静态工厂方法通过所传入参数的不同来创建不同的产品，这必定要修改工厂类的源代码，将违背“开闭原则”，如何实现增加新产品而不影响已有代码？工厂方法模式应运而生，本文将介绍第二种工厂模式——工厂方法模式。</p></blockquote><h1 id="1-日志记录器的设计"><a href="#1-日志记录器的设计" class="headerlink" title="1. 日志记录器的设计"></a>1. 日志记录器的设计</h1><p>Sunny软件公司欲开发一个系统运行日志记录器(Logger)，该记录器可以通过多种途径保存系统的运行日志，如通过文件记录或数据库记录，用户可以通过修改配置文件灵活地更换日志记录方式。在设计各类日志记录器时，Sunny公司的开发人员发现需要对日志记录器进行一些初始化工作，初始化参数的设置过程较为复杂，而且某些参数的设置有严格的先后次序，否则可能会发生记录失败。如何封装记录器的初始化过程并保证多种记录器切换的灵活性是Sunny公司开发人员面临的一个难题。</p><h2 id="1-1-设计要点"><a href="#1-1-设计要点" class="headerlink" title="1.1 设计要点"></a>1.1 设计要点</h2><ol><li>需要封装日志记录器的初始化过程，这些初始化工作较为复杂，例如需要初始化其他相关的类，还有可能需要读取配置文件（例如连接数据库或创建文件），导致代码较长，如果将它们都写在构造函数中，会导致构造函数庞大，不利于代码的修改和维护</li><li>用户可能需要更换日志记录方式，在客户端代码中需要提供一种灵活的方式来选择日志记录器，尽量在不修改源代码的基础上更换或者增加日志记录方式。</li></ol><p><img src="https://i.loli.net/2020/02/03/7ArHEvCctiokB4U.jpg" alt="gc1.jpeg"></p><p>用简单工厂模式来做系统设计，LoggerFactory来创建具体的logger，抽象类logger被几个具体的logger类实现，客户端通过调用LoggerFactory来生成具体的logger对象。</p><pre><code>//日志记录器工厂class LoggerFactory {    //静态工厂方法    public static Logger createLogger(String args) {        if(args.equalsIgnoreCase(&quot;db&quot;)) {            //连接数据库，代码省略            //创建数据库日志记录器对象            Logger logger = new DatabaseLogger();             //初始化数据库日志记录器，代码省略            return logger;        }        else if(args.equalsIgnoreCase(&quot;file&quot;)) {            //创建日志文件            //创建文件日志记录器对象            Logger logger = new FileLogger();             //初始化文件日志记录器，代码省略            return logger;                    }        else {            return null;        }    }}</code></pre><p>通过这种模式，我们将日志记录器的创建和使用分离，客户端只需使用由工厂类创建的日志记录器对象即可。但仍存在一些问题：</p><ol><li>工厂类过于庞大，包含了大量的if…else…代码，导致维护和测试难度增大</li><li>系统扩展不灵活，如果增加新类型的日志记录器，必须修改静态工厂方法的业务逻辑，违反了“开闭原则”。</li></ol><h1 id="2-工厂方法模式概述"><a href="#2-工厂方法模式概述" class="headerlink" title="2. 工厂方法模式概述"></a>2. 工厂方法模式概述</h1><p>简单工厂模式只提供了一个工厂类，该工厂类处于对产品类进行实例化的中心位置，它需要知道每一个产品对象的创建细节，并决定何时实例化哪一个产品类。简单工厂模式最大的缺点是<strong>当有新产品要加入到系统中时，必须修改工厂类，需要在其中加入必要的业务逻辑，这违背了“开闭原则”</strong>。 此外，在简单工厂模式中，所有的产品都由同一个工厂创建，工厂类职责较重，业务逻辑较为复杂，具体产品与工厂类之间的耦合度高，严重影响了系统的灵活性和扩展性，而工厂方法模式则可以很好地解决这一问题。</p><h2 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h2><blockquote><p>工厂方法模式不再提供一个统一的工厂类来创建所有的产品对象，而是针对不同的产品提供不同的工厂，系统提供一个与产品等级结构对应的工厂等级结构。</p></blockquote><blockquote><p>工厂方法模式(Factory Method Pattern)：<strong><em>定义一个用于创建对象的接口，让子类决定将哪一个类实例化</em></strong>。工厂方法模式让一个类的实例化延迟到其子类。工厂方法模式又简称为工厂模式(Factory Pattern)，又可称作虚拟构造器模式(Virtual Constructor Pattern)或多态工厂模式(Polymorphic Factory Pattern)。工厂方法模式是一种类创建型模式。</p></blockquote><p><img src="https://i.loli.net/2020/02/03/lFQLbIy2eUzV8Nu.jpg" alt="gc2.jpeg"></p><h2 id="2-2-组成"><a href="#2-2-组成" class="headerlink" title="2.2 组成"></a>2.2 组成</h2><p>工厂方法模式包含以下几个组成部分：</p><ul><li>Product 抽象产品</li></ul><p>它是定义产品的接口，是工厂方法模式所创建对象的超类型，也就是产品对象的公共父类。</p><ul><li>Concrete Product 具体产品</li></ul><p>它实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，具体工厂和具体产品之间一一对应。</p><ul><li>Factory 抽象工厂</li></ul><p>在抽象工厂类中，声明了工厂方法(Factory Method)，用于返回一个产品。抽象工厂是工厂方法模式的核心，所有创建对象的工厂类都必须实现该接口。</p><ul><li>Concrete Factory 具体工厂</li></ul><p>它是抽象工厂类的子类，实现了抽象工厂中定义的工厂方法，并可由客户端调用，返回一个具体产品类的实例。</p><h2 id="2-3-实现"><a href="#2-3-实现" class="headerlink" title="2.3 实现"></a>2.3 实现</h2><p>抽象工厂，可以使接口，或者是抽象类</p><pre><code>interface Factory {    public Product factoryMethod();}</code></pre><p>抽象工厂声明了工厂方法但是并未实现工厂方法，具体产品对象的创建由其子类负责，客户端针对抽象工厂编程，<strong><em>运行时再指定具体工厂类</em></strong>。不同的具体工厂可以创建不同的具体产品。</p><pre><code>class ConcreteFactory implements Factory {    public Product factoryMethod() {        return new ConcreteProduct();    }}</code></pre><p> 在实际使用时，具体工厂类在实现工厂方法时除了创建具体产品对象之外，还可以负责产品对象的初始化工作以及一些资源和环境配置工作，例如连接数据库、创建文件等。</p><p> 在客户端代码中，只需关注工厂类即可，不同的具体工厂可以创建不同的产品。</p><pre><code> ……Factory factory;factory = new ConcreteFactory(); //可通过配置文件实现Product product;product = factory.factoryMethod();……</code></pre><h2 id="2-4-完整解决方案"><a href="#2-4-完整解决方案" class="headerlink" title="2.4 完整解决方案"></a>2.4 完整解决方案</h2><p><img src="https://i.loli.net/2020/02/03/f6Stw3NPsXAiyC4.jpg" alt="gc3.jpeg"></p><p>Logger是抽象产品， 其子类FileLogger和DatabaseLogger充当具体产品，LoggerFactory接口充当抽象工厂，其子类FileLoggerFactory和DatabaseLoggerFactory充当具体工厂。</p><pre><code>//日志记录器接口：抽象产品interface Logger {    public void writeLog();}//数据库日志记录器：具体产品class DatabaseLogger implements Logger {    public void writeLog() {        System.out.println(&quot;数据库日志记录。&quot;);    }}//文件日志记录器：具体产品class FileLogger implements Logger {    public void writeLog() {        System.out.println(&quot;文件日志记录。&quot;);    }}//日志记录器工厂接口：抽象工厂interface LoggerFactory {    public Logger createLogger();}//数据库日志记录器工厂类：具体工厂class DatabaseLoggerFactory implements LoggerFactory {    public Logger createLogger() {            //连接数据库，代码省略            //创建数据库日志记录器对象            Logger logger = new DatabaseLogger();             //初始化数据库日志记录器，代码省略            return logger;    }    }//文件日志记录器工厂类：具体工厂class FileLoggerFactory implements LoggerFactory {    public Logger createLogger() {            //创建文件日志记录器对象            Logger logger = new FileLogger();             //创建文件，代码省略            return logger;    }    }</code></pre><p>客户端测试代码：</p><pre><code>class Client {    public static void main(String args[]) {        LoggerFactory factory;        Logger logger;        factory = new FileLoggerFactory(); //可引入配置文件实现        logger = factory.createLogger();        logger.writeLog();    }}</code></pre><h2 id="2-5-反射与配置文件"><a href="#2-5-反射与配置文件" class="headerlink" title="2.5 反射与配置文件"></a>2.5 反射与配置文件</h2><p><strong><em>如何在不修改任何客户端代码的基础上更新或增加新的日志记录方式？</em></strong></p><p>在客户端代码中将不再使用new关键字来创建工厂对象，而是将具体工厂类的类名存储在配置文件（如XML文件）中，<strong>通过读取配置文件获取类名字符串</strong>，再使用<strong>Java的反射机制</strong>，根据类名字符串生成对象。在整个实现过程中需要用到两个技术：Java反射机制与配置文件读取。</p><blockquote><p>Java反射机制</p></blockquote><p>是指在程序运行时获取已知名称的类或已有对象的相关信息的一种机制，包括类的方法、属性、父类等信息，还包括实例的创建和实例类型的判断等。在反射中使用最多的类是<strong>Class，Class类的实例表示正在运行的Java应用程序中的类和接口</strong>，其forName(String className)方法可以返回与带有给定字符串名的类或接口相关联的 Class对象，再通过Class对象的newInstance()方法创建此对象所表示的类的一个新实例，即通过一个类名字符串得到类的实例。</p><pre><code>   //通过类名生成实例对象并将其返回   Class c=Class.forName(&quot;String&quot;);   Object obj=c.newInstance();   return obj;</code></pre><p>而后使用XML格式的配置文件config.xml用于存储具体日志记录器工厂类类名：</p><pre><code>&lt;!— config.xml --&gt;&lt;?xml version=&quot;1.0&quot;?&gt;&lt;config&gt;    &lt;className&gt;FileLoggerFactory&lt;/className&gt;&lt;/config&gt;</code></pre><p>然后用一个名为XMLUtil的工具类来获取xml文件定义的类，<strong>并且生成实例对象</strong>。 </p><pre><code>//工具类XMLUtil.javaimport javax.xml.parsers.*;import org.w3c.dom.*;import org.xml.sax.SAXException;import java.io.*;public class XMLUtil {//该方法用于从XML配置文件中提取具体类类名，并返回一个实例对象    public static Object getBean() {        try {            //创建DOM文档对象            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();            DocumentBuilder builder = dFactory.newDocumentBuilder();            Document doc;                                        doc = builder.parse(new File(&quot;config.xml&quot;));             //获取包含类名的文本节点            NodeList nl = doc.getElementsByTagName(&quot;className&quot;);            Node classNode=nl.item(0).getFirstChild();            String cName=classNode.getNodeValue();            //通过类名生成实例对象并将其返回            Class c=Class.forName(cName);              Object obj=c.newInstance();            return obj;        }           catch(Exception e) {               e.printStackTrace();               return null;         }    }}</code></pre><p>而后客户端不需要再使用new关键字来创建具体的工厂类了，可以将具体工厂类的类名存储在XML文件中，再通过XMLUtil类的静态工厂方法getBean()进行对象的实例化</p><pre><code>class Client {    public static void main(String args[]) {        LoggerFactory factory;        Logger logger;        factory = (LoggerFactory)XMLUtil.getBean(); //getBean()的返回类型为Object，需要进行强制类型转换        logger = factory.createLogger();        logger.writeLog();    }}</code></pre><p>引入了Util和XML配置文件之后，如果要增加新的日志记录方式，只需要：</p><ol><li>新的日志记录器需要继承抽象日志记录器Logger</li><li>对应增加一个新的具体日志记录器工厂，继承抽象日志记录器工厂LoggerFactory，并实现其中的工厂方法createLogger()，设置好初始化参数和环境变量，返回具体日志记录器对象；</li><li>修改配置文件config.xml，将新增的具体日志记录器工厂类的类名字符串替换原有工厂类类名字符串</li><li>编译新增的具体日志记录器类和具体日志记录器工厂类，运行客户端测试类即可使用新的日志记录方式，而原有类库代码无须做任何修改，完全符合“开闭原则”。</li></ol><h2 id="2-6-重载的工厂方法"><a href="#2-6-重载的工厂方法" class="headerlink" title="2.6 重载的工厂方法"></a>2.6 重载的工厂方法</h2><p>发现可以通过多种方式来初始化日志记录器，例如可以为各种日志记录器提供默认实现；还可以为数据库日志记录器提供数据库连接字符串，为文件日志记录器提供文件路径；也可以将参数封装在一个Object类型的对象中，通过Object对象将配置参数传入工厂类。此时，可以提供一组重载的工厂方法，以不同的方式对产品对象进行创建。当然，对于同一个具体工厂而言，无论使用哪个工厂方法，创建的产品类型均要相同。</p><p><img src="https://i.loli.net/2020/02/03/l8TdOYBKXeCmqbD.jpg" alt="gc4.jpeg"></p><p>引入重载方法后，抽象工厂LoggerFactory的代码修改如下：</p><pre><code>interface LoggerFactory {    public Logger createLogger();    public Logger createLogger(String args);    public Logger createLogger(Object obj);}</code></pre><p>具体工厂类DatabaseLoggerFactory代码修改如下：</p><pre><code>class DatabaseLoggerFactory implements LoggerFactory {    public Logger createLogger() {            //使用默认方式连接数据库，代码省略            Logger logger = new DatabaseLogger();             //初始化数据库日志记录器，代码省略            return logger;    }    public Logger createLogger(String args) {            //使用参数args作为连接字符串来连接数据库，代码省略            Logger logger = new DatabaseLogger();             //初始化数据库日志记录器，代码省略            return logger;    }        public Logger createLogger(Object obj) {            //使用封装在参数obj中的连接字符串来连接数据库，代码省略            Logger logger = new DatabaseLogger();             //使用封装在参数obj中的数据来初始化数据库日志记录器，代码省略            return logger;    }    }//其他具体工厂类代码省略</code></pre><p>在抽象工厂中定义多个重载的工厂方法，在具体工厂中实现了这些工厂方法，这些方法可以包含不同的业务逻辑，以满足对不同产品对象的需求。</p><h2 id="2-7-工厂方法的隐藏"><a href="#2-7-工厂方法的隐藏" class="headerlink" title="2.7 工厂方法的隐藏"></a>2.7 工厂方法的隐藏</h2><p> 有时候，为了进一步简化客户端的使用，还可以对客户端隐藏工厂方法，此时，在工厂类中将直接调用产品类的业务方法，客户端无须调用工厂方法创建产品，直接通过工厂即可使用所创建的对象中的业务方法。</p><p><img src="gc5.jpeg" alt="gc5.jpeg"></p><p>就是抽象工厂类从接口变成abstract类，并且在这个抽象类里面实现产品类的业务方法。</p><pre><code>//改为抽象类abstract class LoggerFactory {    //在工厂类中直接调用日志记录器类的业务方法writeLog()    public void writeLog() {        Logger logger = this.createLogger();        logger.writeLog();    }    public abstract Logger createLogger();    }</code></pre><p>客户端代码修改成：</p><pre><code>class Client {    public static void main(String args[]) {        LoggerFactory factory;        factory = (LoggerFactory)XMLUtil.getBean();        factory.writeLog(); //直接使用工厂对象来调用产品对象的业务方法    }}</code></pre><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><h2 id="3-1-优势"><a href="#3-1-优势" class="headerlink" title="3.1 优势"></a>3.1 优势</h2><ol><li>工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，<strong>用户只需要关心所需产品对应的工厂，无须关心创建细节，甚至无须知道具体产品类的类名</strong>。</li><li>基于工厂角色和产品角色的<strong>多态性设计</strong>是工厂方法模式的关键。它能够让工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，就正是因为所有的具体工厂类都具有同一抽象父类。</li><li>使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，<strong>而只要添加一个具体工厂和具体产品就可以了</strong>，这样，系统的可扩展性也就变得非常好，完全符合“开闭原则”。</li></ol><h2 id="3-2-劣势"><a href="#3-2-劣势" class="headerlink" title="3.2 劣势"></a>3.2 劣势</h2><ol><li>在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要编译和运行，会给系统带来一些额外的开销。</li><li>由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。</li></ol><h1 id="4-Reference"><a href="#4-Reference" class="headerlink" title="4. Reference"></a>4. Reference</h1><p><a href="https://blog.csdn.net/lovelion/article/details/9306457" target="_blank" rel="noopener">1. CSDN Liuwei</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;简单工厂模式虽然简单，但存在一个很严重的问题。当系统中需要引入新产品时，由于静态工厂方法通过所传入参数的不同来创建不同的产品，这必定要修改工厂类的源代码，将违背“开闭原则”，如何实现增加新产品而不影响已有代码？工厂方法模式应运而生，本文将介绍第二种
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="Design Pattern" scheme="https://www.llchen60.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>如何确定一个服务器的最大连接数</title>
    <link href="https://www.llchen60.com/%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0/"/>
    <id>https://www.llchen60.com/%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0/</id>
    <published>2020-02-02T23:05:38.000Z</published>
    <updated>2020-02-02T23:06:13.499Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-连接数定义"><a href="#1-连接数定义" class="headerlink" title="1. 连接数定义"></a>1. 连接数定义</h1><p>对于给定的一个服务器而言，在任意时刻能够同时处理的最大连接数。</p><h1 id="2-Tips"><a href="#2-Tips" class="headerlink" title="2. Tips"></a>2. Tips</h1><h2 id="2-1-如果超过了会怎么样"><a href="#2-1-如果超过了会怎么样" class="headerlink" title="2.1 如果超过了会怎么样"></a>2.1 如果超过了会怎么样</h2><ul><li>如果使用了Spillover的feature，额外的请求会被放置到队列里</li><li>如果没使用，那么HTTP 503会返回，对于TCP连接，会被重置掉</li></ul><h2 id="2-2-如果得出准确的允许的最大连接数？"><a href="#2-2-如果得出准确的允许的最大连接数？" class="headerlink" title="2.2 如果得出准确的允许的最大连接数？"></a>2.2 如果得出准确的允许的最大连接数？</h2><p>没有办法直接得出，因为运行的代码本身，机器本身都会对结果产生影响的，最好的方式依旧是做测试，即不停更改最大连接数，单独测试一个host在不同连接数的情况下的metrics，譬如延时问题，有没有fatals, etc. 以此来得到针对实际情况的正确地值。</p><h2 id="2-3-General-公式"><a href="#2-3-General-公式" class="headerlink" title="2.3 General 公式"></a>2.3 General 公式</h2><ul><li>需要使用的CPU时间 (local resource)</li><li>远端，网路延时 （remote latency）</li><li>CPU 核心数量</li></ul><p>参考公式</p><pre><code>maxConns = ((local + remote) / local) * cores</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-连接数定义&quot;&gt;&lt;a href=&quot;#1-连接数定义&quot; class=&quot;headerlink&quot; title=&quot;1. 连接数定义&quot;&gt;&lt;/a&gt;1. 连接数定义&lt;/h1&gt;&lt;p&gt;对于给定的一个服务器而言，在任意时刻能够同时处理的最大连接数。&lt;/p&gt;
&lt;h1 id=&quot;2-Ti
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
  </entry>
  
  <entry>
    <title>原型模式</title>
    <link href="https://www.llchen60.com/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"/>
    <id>https://www.llchen60.com/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/</id>
    <published>2020-02-02T23:02:53.000Z</published>
    <updated>2020-02-02T23:05:08.156Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-原型模式概述"><a href="#1-原型模式概述" class="headerlink" title="1. 原型模式概述"></a>1. 原型模式概述</h1><p>原型模式指：通过一个原型对象克隆出多个一模一样的对象。</p><p>在使用原型模式时，首先需要创建一个原型对象，再通过复制这个原型对象来创建更多同类型的对象。</p><blockquote><p>使用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。原型模式时一种对象创建型模式。</p></blockquote><h2 id="1-1-工作原理"><a href="#1-1-工作原理" class="headerlink" title="1.1 工作原理"></a>1.1 工作原理</h2><p>将一个原型对象传给要发动创建的对象，这个要发动创建的对象通过请求原型对象拷贝自己来实现创建过程。</p><p>通过克隆方法所创建的对象是全新的，在内存中有新的地址，对克隆对象所产生的对象进行修改不会对原型对象产生任何影响。</p><h2 id="1-2-包含角色"><a href="#1-2-包含角色" class="headerlink" title="1.2 包含角色"></a>1.2 包含角色</h2><p><img src="https://i.loli.net/2020/02/03/NSa3iLpPcvoCfIq.gif" alt="1.gif"></p><ul><li>Prototype (抽象原型类)</li></ul><p>是声明克隆方法的接口，是所有具体类型类的公共父类。抽象类/ 接口/ 具体实现类</p><ul><li>ConcretePrototype (具体原型类)</li></ul><p>实现了抽象原型类中声明的克隆方法，在克隆方法中返回一个自己的克隆对象</p><ul><li>Client</li></ul><p>让一个原型对象克隆自身，从而创建一个新的对象。客户类针对抽象原型类Prototype编程，因此用户可以根据需要选择具体原型类，扩展性加强了。</p><h1 id="2-原型模式的实现"><a href="#2-原型模式的实现" class="headerlink" title="2. 原型模式的实现"></a>2. 原型模式的实现</h1><h2 id="2-1-通用实现方法"><a href="#2-1-通用实现方法" class="headerlink" title="2.1 通用实现方法"></a>2.1 通用实现方法</h2><pre><code>class ConcretePrototype implements Prototype {    private String attr; //成员属性    public void setAttr(String attr) {        this.attr = attr;    }    public String getAttr() {        return this.attr;    }    public Prototype clone() //克隆方法    {        Prototype prototype = new ConcretePrototype(); //创建新对象        prototype.setAttr(this.attr);        return prototype;    }}</code></pre><h2 id="2-2-Java提供的clone-方法"><a href="#2-2-Java提供的clone-方法" class="headerlink" title="2.2 Java提供的clone()方法"></a>2.2 Java提供的clone()方法</h2><p>所有的Java类都继承自java.lang.Object。事实上，Object提供了clone()方法，可以将一个Java对象复制一份。可以直接使用这个方法来实现克隆的。</p><pre><code>class ConcretePrototype implements Cloneable {    public Prototype clone() {    　　Object object = null;    　　try {    　　　　　object = super.clone();    　　} catch (CloneNotSupportedException exception) {    　　　　　System.err.println(&quot;Not support cloneable&quot;);    　　}    　　return (Prototype )object;    }}</code></pre><p>Java中的clone()满足：</p><ol><li>对于任何对象，都有<code>x.clone() != x</code>，即克隆方法创建了新的对象</li><li>对于任何对象，都有<code>x.clone().getClass() == x.getClass()</code>，即克隆对象与原型对象的类型一样</li><li>派生类需要实现Cloneable接口</li></ol><h1 id="3-原型模式实现工作周报快速创建"><a href="#3-原型模式实现工作周报快速创建" class="headerlink" title="3. 原型模式实现工作周报快速创建"></a>3. 原型模式实现工作周报快速创建</h1><p><img src="https://i.loli.net/2020/02/03/Ci24JYEqs6z8GgX.gif" alt="2.gif"></p><p>快速创建周报结构图</p><p>//工作周报WeeklyLog：具体原型类，考虑到代码的可读性和易理解性，只列出部分与模式相关的核心代码</p><pre><code>class WeeklyLog implements Cloneable{    private String name;    private String date;    private String content;    public  void setName(String name) {        this.name  = name;    }    public  void setDate(String date) {        this.date  = date;    }    public  void setContent(String content) {        this.content  = content;    }    public  String getName() {        return  (this.name);    }    public  String getDate() {        return  (this.date);    }    public  String getContent() {        return  (this.content);    }     //克隆方法clone()，此处使用Java语言提供的克隆机制    public WeeklyLog clone()    {        Object obj = null;        try {        obj = super.clone();        return (WeeklyLog)obj;      } catch(CloneNotSupportedException e) {        System.out.println(&quot;不支持复制！&quot;);        return null;        }    }}</code></pre><p>测试代码:</p><pre><code>class Client{    public  static void main(String args[])    {              WeeklyLog log_previous = new WeeklyLog();  //创建原型对象              log_previous.setName(&quot;张无忌&quot;);              log_previous.setDate(&quot;第12周&quot;);              log_previous.setContent(&quot;这周工作很忙，每天加班！&quot;);              System.out.println(&quot;****周报****&quot;);              System.out.println(&quot;周次：&quot; +  log_previous.getDate());              System.out.println(&quot;姓名：&quot; +  log_previous.getName());              System.out.println(&quot;内容：&quot; +  log_previous.getContent());              System.out.println(&quot;--------------------------------&quot;);              WeeklyLog  log_new;              log_new  = log_previous.clone(); //调用克隆方法创建克隆对象              log_new.setDate(&quot;第13周&quot;);              System.out.println(&quot;****周报****&quot;);              System.out.println(&quot;周次：&quot; + log_new.getDate());              System.out.println(&quot;姓名：&quot; + log_new.getName());              System.out.println(&quot;内容：&quot; + log_new.getContent());       }}</code></pre><h1 id="4-浅克隆与深克隆"><a href="#4-浅克隆与深克隆" class="headerlink" title="4. 浅克隆与深克隆"></a>4. 浅克隆与深克隆</h1><p>在java中，数据类型分为值类型和引用类型，值类型包括int,double, byte, boolean, char等，引用类型包括类，接口，数组等。浅克隆与深克隆的区别在于是否支持引用类型的成员变量的复制。</p><h2 id="4-1-浅克隆"><a href="#4-1-浅克隆" class="headerlink" title="4.1 浅克隆"></a>4.1 浅克隆</h2><p><img src="https://i.loli.net/2020/02/03/xbMHXnZEd3NJlgh.gif" alt="3.gif"><br>浅克隆示意图</p><p>如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象，也就是说二者的成员变量指向了相同的内存地址。<strong><em>在浅克隆中，当对象被复制时只复制它本身和其中包含的值类型的成员变量，而引用类型的成员对象并没有复制</em></strong>。</p><p><img src="https://i.loli.net/2020/02/03/KiLnFxBw2ODJvuI.gif" alt="4.gif"><br>带附件的周报结构图</p><p>附件类代码：</p><pre><code>//附件类class Attachment{    private String name; //附件名    public void setName(String name) {        this.name = name;    }    public String getName() {        return this.name;    }    public void download() {        System.out.println(&quot;下载附件，文件名为&quot; + name);    }}</code></pre><p>工作周报类代码</p><pre><code>//工作周报WeeklyLogclass WeeklyLog implements Cloneable{     //为了简化设计和实现，假设一份工作周报中只有一个附件对象，实际情况中可以包含多个附件，可以通过List等集合对象来实现       private Attachment attachment;       private String name;       private  String date;       private  String content;       public void setAttachment(Attachment  attachment) {              this.attachment = attachment;       }       public  void setName(String name) {              this.name  = name;       }       public  void setDate(String date) {              this.date  = date;       }       public  void setContent(String content) {              this.content  = content;       }       public Attachment  getAttachment(){              return (this.attachment);       }       public  String getName() {              return  (this.name);       }       public  String getDate() {              return  (this.date);       }       public  String getContent() {              return  (this.content);       }     //使用clone()方法实现浅克隆       public WeeklyLog clone()       {              Object obj = null;              try              {                     obj = super.clone();                     return (WeeklyLog)obj;              }              catch(CloneNotSupportedException  e)              {                System.out.println(&quot;不支持复制！&quot;);                     return null;              }       }}</code></pre><p>客户端代码：</p><pre><code>class Client{       public  static void main(String args[])       {              WeeklyLog  log_previous, log_new;              log_previous  = new WeeklyLog(); //创建原型对象              Attachment  attachment = new Attachment(); //创建附件对象              log_previous.setAttachment(attachment);  //将附件添加到周报中              log_new  = log_previous.clone(); //调用克隆方法创建克隆对象              //比较周报              System.out.println(&quot;周报是否相同？ &quot; + (log_previous ==  log_new));              //比较附件              System.out.println(&quot;附件是否相同？ &quot; +  (log_previous.getAttachment() == log_new.getAttachment()));       }}</code></pre><h2 id="4-2-深克隆"><a href="#4-2-深克隆" class="headerlink" title="4.2 深克隆"></a>4.2 深克隆</h2><p>无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象。即深克隆中，除了对象本身被复制外，对象所包含的所有成员变量也将复制。</p><p><img src="https://i.loli.net/2020/02/03/6QblH4gmPvqx2FN.gif" alt="5.gif"><br>深克隆示意图</p><p>如果要实现深克隆，在Java中可以通过序列化Serialization等方式来实现。</p><p>序列化，将对象写到流里，通过序列化的拷贝不仅可以复制对象本身，也可以复制其引用的成员对象。因此通过序列化将对象写到一个流中，再从流里将其读出来，可以实现深克隆。需要注意的是能够实现序列化的对象其类必须实现<strong>Serializable接口</strong>，否则无法实现序列化操作。</p><p><img src="https://i.loli.net/2020/02/03/1vYLodkxTpSJ5q2.gif" alt="6.gif"><br>带附件的周报结构图</p><p>附件类：</p><p>import  java.io.*;</p><p>//附件类</p><pre><code>class  Attachment implements Serializable{       private  String name; //附件名       public  void setName(String name)       {              this.name  = name;       }       public  String getName()       {              return  this.name;       }     public void download()     {            System.out.println(&quot;下载附件，文件名为&quot; + name);     }}</code></pre><p>工作周报类代码实现：</p><pre><code>import  java.io.*;//工作周报类class  WeeklyLog implements Serializable{       private  Attachment attachment;       private  String name;       private  String date;       private  String content;       public  void setAttachment(Attachment attachment) {              this.attachment  = attachment;       }       public  void setName(String name) {              this.name  = name       }       public  void setDate(String date) {              this.date  = date;       }       public  void setContent(String content) {              this.content  = content;       }       public  Attachment getAttachment(){              return  (this.attachment);       }       public  String getName() {              return  (this.name);       }       public  String getDate() {              return  (this.date);       }       public  String getContent() {              return  (this.content);       }   //使用序列化技术实现深克隆       public WeeklyLog deepClone() throws  IOException, ClassNotFoundException, OptionalDataException       {              //将对象写入流中              ByteArrayOutputStream bao=new  ByteArrayOutputStream();              ObjectOutputStream oos=new  ObjectOutputStream(bao);              oos.writeObject(this);              //将对象从流中取出              ByteArrayInputStream bis=new  ByteArrayInputStream(bao.toByteArray());              ObjectInputStream ois=new  ObjectInputStream(bis);              return  (WeeklyLog)ois.readObject();       }}</code></pre><p>客户端代码：</p><pre><code>class Client{       public  static void main(String args[])       {              WeeklyLog  log_previous, log_new = null;              log_previous  = new WeeklyLog(); //创建原型对象              Attachment  attachment = new Attachment(); //创建附件对象              log_previous.setAttachment(attachment);  //将附件添加到周报中              try              {                     log_new =  log_previous.deepClone(); //调用深克隆方法创建克隆对象                                }              catch(Exception e)              {                  System.err.println(&quot;克隆失败！&quot;);              }              //比较周报              System.out.println(&quot;周报是否相同？ &quot; + (log_previous ==  log_new));              //比较附件              System.out.println(&quot;附件是否相同？ &quot; +  (log_previous.getAttachment() == log_new.getAttachment()));       }}</code></pre><blockquote><p>Tips: java中的Cloneable和Serializable接口的代码很简单，都是空接口，也成为标识接口，其中没有任何方法的定义，其作用是告诉JRE这些接口的实现类是否具有某个功能。</p></blockquote><h2 id="4-3-Java中实现深克隆的方法浅析"><a href="#4-3-Java中实现深克隆的方法浅析" class="headerlink" title="4.3 Java中实现深克隆的方法浅析"></a>4.3 Java中实现深克隆的方法浅析</h2><h3 id="4-3-1-Apache-Commons-Lang"><a href="#4-3-1-Apache-Commons-Lang" class="headerlink" title="4.3.1 Apache Commons Lang"></a>4.3.1 Apache Commons Lang</h3><p>SerializationUtils#clone, will perform a deep copy when all classes in the object graph implement the serializable interface. </p><h3 id="4-3-2-Json-Serialization-with-Gson"><a href="#4-3-2-Json-Serialization-with-Gson" class="headerlink" title="4.3.2 Json Serialization with Gson"></a>4.3.2 Json Serialization with Gson</h3><p>No need for Serializable interface</p><pre><code>gson.fromJson(gson.toJson(userA), User.class);</code></pre><h3 id="4-3-3-constructor"><a href="#4-3-3-constructor" class="headerlink" title="4.3.3 constructor"></a>4.3.3 constructor</h3><p>直接handmade, 用constructor生成一个新的想要的对象。</p><h1 id="5-原型管理器"><a href="#5-原型管理器" class="headerlink" title="5. 原型管理器"></a>5. 原型管理器</h1><p>原型管理器(Prototype Manager)是将多个原型对象存储在一个集合中供客户端使用，它是一个专门负责克隆对象的工厂，其中定义了一个集合用于存储原型对象，如果需要某个原型对象的一个克隆，可以通过复制集合中对应的原型对象来获得。在原型管理器中针对抽象原型类进行编程，以便扩展。</p><p><img src="https://i.loli.net/2020/02/03/9UmnSAyI7az4kjl.gif" alt="7.gif"><br>带原型管理器的原型模式图 </p><h2 id="5-1-实例-公文管理器"><a href="#5-1-实例-公文管理器" class="headerlink" title="5.1 实例-公文管理器"></a>5.1 实例-公文管理器</h2><p><img src="https://i.loli.net/2020/02/03/zE3ahLk6lvKfw4J.gif" alt="8.gif"><br>公文管理器结构图</p><p>代码实现： </p><pre><code>import java.util.*;//抽象公文接口，也可定义为抽象类，提供clone()方法的实现，将业务方法声明为抽象方法interface OfficialDocument extends  Cloneable{       public  OfficialDocument clone();       public  void display();}//可行性分析报告(Feasibility Analysis Report)类class FAR implements OfficialDocument{       public  OfficialDocument clone()      {              OfficialDocument  far = null;              try              {                     far  = (OfficialDocument)super.clone();              }              catch(CloneNotSupportedException  e)              {                  System.out.println(&quot;不支持复制！&quot;);              }              return  far;       }       public  void display()       {         System.out.println(&quot;《可行性分析报告》&quot;);       }}//软件需求规格说明书(Software Requirements Specification)类class SRS implements OfficialDocument{       public  OfficialDocument clone()       {              OfficialDocument  srs = null;              try              {                     srs  = (OfficialDocument)super.clone();              }              catch(CloneNotSupportedException  e)              {                 System.out.println(&quot;不支持复制！&quot;);              }              return  srs;       }       public  void display()       {             System.out.println(&quot;《软件需求规格说明书》&quot;);       }}//原型管理器（使用饿汉式单例实现）class  PrototypeManager{       //定义一个Hashtable，用于存储原型对象       private Hashtable ht=new Hashtable();       private static PrototypeManager pm =  new PrototypeManager();       //为Hashtable增加公文对象        private  PrototypeManager()     {              ht.put(&quot;far&quot;,new  FAR());              ht.put(&quot;srs&quot;,new  SRS());                    }     //增加新的公文对象       public void addOfficialDocument(String  key,OfficialDocument doc)       {              ht.put(key,doc);       }       //通过浅克隆获取新的公文对象       public OfficialDocument  getOfficialDocument(String key)       {              return  ((OfficialDocument)ht.get(key)).clone();       }       public static PrototypeManager  getPrototypeManager()       {              return pm;       }}</code></pre><p>客户端代码如下： </p><pre><code>class Client{       public  static void main(String args[])       {              //获取原型管理器对象              PrototypeManager pm =  PrototypeManager.getPrototypeManager();                OfficialDocument  doc1,doc2,doc3,doc4;              doc1  = pm.getOfficialDocument(&quot;far&quot;);              doc1.display();              doc2  = pm.getOfficialDocument(&quot;far&quot;);              doc2.display();              System.out.println(doc1  == doc2);              doc3  = pm.getOfficialDocument(&quot;srs&quot;);              doc3.display();              doc4  = pm.getOfficialDocument(&quot;srs&quot;);              doc4.display();              System.out.println(doc3  == doc4);       }}</code></pre><p> 在PrototypeManager中定义了一个Hashtable类型的集合对象，使用“键值对”来存储原型对象，客户端可以通过Key（如“far”或“srs”）来获取对应原型对象的克隆对象。PrototypeManager类提供了类似工厂方法的getOfficialDocument()方法用于返回一个克隆对象。</p><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h1><h2 id="6-1-优点"><a href="#6-1-优点" class="headerlink" title="6.1 优点"></a>6.1 优点</h2><ol><li>简化对象的创建过程</li><li>客户端可以针对抽象原型类进行编程，具体原型类写在配置文件中</li><li>技工简化的创建结构</li></ol><h2 id="6-2-缺点"><a href="#6-2-缺点" class="headerlink" title="6.2 缺点"></a>6.2 缺点</h2><ol><li>每一个类有自己的克隆方法，且位于一个类的内部，对已有类进行改造的时候，需要修改源代码</li><li>深克隆复杂</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-原型模式概述&quot;&gt;&lt;a href=&quot;#1-原型模式概述&quot; class=&quot;headerlink&quot; title=&quot;1. 原型模式概述&quot;&gt;&lt;/a&gt;1. 原型模式概述&lt;/h1&gt;&lt;p&gt;原型模式指：通过一个原型对象克隆出多个一模一样的对象。&lt;/p&gt;
&lt;p&gt;在使用原型模式时，
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="Design Pattern" scheme="https://www.llchen60.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>单例模式</title>
    <link href="https://www.llchen60.com/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"/>
    <id>https://www.llchen60.com/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</id>
    <published>2020-02-02T23:00:48.000Z</published>
    <updated>2020-02-02T23:01:43.986Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-为什么需要单例模式"><a href="#1-为什么需要单例模式" class="headerlink" title="1. 为什么需要单例模式"></a>1. 为什么需要单例模式</h1><p>windows系统的任务管理器，只能有一个,唯一性的原因：</p><ol><li>如果能弹出多个窗口，且这些窗口的内容完全一致，全都是重复对象，那势必会浪费资源，尤其是任务管理器会需要进入内核态调取各种状态信息，会对性能造成一定的影响。</li><li>而且多个窗口之间需要保持一致性，绝对的同步，相互之间的同步也是资源的浪费。</li></ol><p>现实中的例子，就是为了节约系统资源，有时需要确保系统中某个类只有唯一一个实例，当这个实例创建成功以后，我们无法再创建一个同类型的其他对象，所有的操作都只能基于这个唯一的实例。</p><h1 id="2-单例模式概述"><a href="#2-单例模式概述" class="headerlink" title="2. 单例模式概述"></a>2. 单例模式概述</h1><h2 id="2-1-模拟任务管理类"><a href="#2-1-模拟任务管理类" class="headerlink" title="2.1 模拟任务管理类"></a>2.1 模拟任务管理类</h2><pre><code>class TaskManager{     public TaskManager() {...} //初始化窗口     public void displayProcesses()  {……} //显示进程     public void  displayServices() {……} //显示服务}</code></pre><p>对其进行重构，为了使其是单一实例的，那我们需要禁止类的外部直接使用new来创建对象  —–&gt;  将其构造函数的可见性变为private</p><pre><code>public TaskManager() {...}</code></pre><p>在类内部创建对象，保存这个唯一实例</p><pre><code>private static TaskManager tm = null;public static TaskManager getInstance() {    if (tm == null) {        tm = new TaskManager();    }    return tm;}</code></pre><p><code>getInstance()</code>定义成一个静态方法，这样可以直接通过类名来使用</p><h2 id="2-2-定义"><a href="#2-2-定义" class="headerlink" title="2.2 定义"></a>2.2 定义</h2><blockquote><p>单例模式(Singleton Pattern)：确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式是一种对象创建型模式。</p></blockquote><ol><li>只有一个实例</li><li>必须自行创建这个实例</li><li>必须自行向整个系统提供这个实例</li></ol><p><img src="https://i.loli.net/2020/02/03/vKPVAeCrImYXq1U.gif" alt="s1.gif"></p><h2 id="2-3-负载均衡器的设计与实现"><a href="#2-3-负载均衡器的设计与实现" class="headerlink" title="2.3 负载均衡器的设计与实现"></a>2.3 负载均衡器的设计与实现</h2><p> Sunny软件公司承接了一个服务器负载均衡(Load Balance)软件的开发工作，该软件运行在一台负载均衡服务器上，可以将并发访问和数据流量分发到服务器集群中的多台设备上进行并发处理，提高系统的整体处理能力，缩短响应时间。由于集群中的服务器需要动态删减，且客户端请求需要统一分发，因此需要确保负载均衡器的唯一性，只能有一个负载均衡器来负责服务器的管理和请求的分发，否则将会带来服务器状态的不一致以及请求分配冲突等问题。如何确保负载均衡器的唯一性是该软件成功的关键。</p><p>使用单例模式来设计该负载均衡器： </p><p><img src="https://i.loli.net/2020/02/03/4vJzXqlRCITLUge.gif" alt="s2.gif"></p><pre><code>import java.util.*;//负载均衡器LoadBalancer：单例类，真实环境下该类将非常复杂，包括大量初始化的工作和业务方法，考虑到代码的可读性和易理解性，只列出部分与模式相关的核心代码class LoadBalancer {    //私有静态成员变量，存储唯一实例    private static LoadBalancer instance = null;    //服务器集合    private List serverList = null;    //私有构造函数    private LoadBalancer() {        serverList = new ArrayList();    }    //公有静态成员方法，返回唯一实例    public static LoadBalancer getLoadBalancer() {        if (instance == null) {            instance = new LoadBalancer();        }        return instance;    }    //增加服务器    public void addServer(String server) {        serverList.add(server);    }    //删除服务器    public void removeServer(String server) {        serverList.remove(server);    }    //使用Random类随机获取服务器    public String getServer() {        Random random = new Random();        int i = random.nextInt(serverList.size());        return (String)serverList.get(i);    }}</code></pre><h1 id="3-饿汉式单例模式和懒汉式单例模式"><a href="#3-饿汉式单例模式和懒汉式单例模式" class="headerlink" title="3. 饿汉式单例模式和懒汉式单例模式"></a>3. 饿汉式单例模式和懒汉式单例模式</h1><h2 id="3-1-饿汉式单例模式"><a href="#3-1-饿汉式单例模式" class="headerlink" title="3.1 饿汉式单例模式"></a>3.1 饿汉式单例模式</h2><p><img src="https://i.loli.net/2020/02/03/UAk8topvxWQTwfd.gif" alt="s3.gif"></p><pre><code>class EagerSingleton {     private static final EagerSingleton instance = new EagerSingleton();     private EagerSingleton() { }     public static EagerSingleton getInstance() {        return instance;     }   }</code></pre><p>在类加载的时候，静态变量instance就会被初始化，此时类的私有构造函数会被调用，然后单例类的唯一实例会在这个时候被创建出来。</p><h2 id="3-2-懒汉式单例模式"><a href="#3-2-懒汉式单例模式" class="headerlink" title="3.2 懒汉式单例模式"></a>3.2 懒汉式单例模式</h2><p><img src="https://i.loli.net/2020/02/03/bDLQtESdzF8Ugmq.gif" alt="s4.gif"></p><p>在第一个调用getInstance()方法的时候进行实例化。又叫做延迟加载技术——在需要的时候再加载实例，为了避免多个线程同时调用getInstance()方法，我们需要使用<strong><em>synchronized关键字</em></strong>：</p><pre><code>class LazySingleton {     private static LazySingleton instance = null;     private LazySingleton() { }     synchronized public static LazySingleton getInstance() {         if (instance == null) {            instance = new LazySingleton();         }        return instance;     }}</code></pre><p>这里实际上不需要多整个getInstance()方法要求synchronized， 只需要在new的时候，是不能并发的就可以了:</p><pre><code>public static LazySingleton getInstance() {     if (instance == null) {        synchronized (LazySingleton.class) {            instance = new LazySingleton();         }    }    return instance; }</code></pre><p>还是有可能存在不唯一的状态，即在第一个线程做实例化的时候，第二个线程已经完成了判断，在等待实例化了  所以需要做double check locking：</p><pre><code>class LazySingleton {     // volatile 保证在多线程可以被正确处理    private volatile static LazySingleton instance = null;     private LazySingleton() { }     public static LazySingleton getInstance() {         //第一重判断        if (instance == null) {            //锁定代码块            synchronized (LazySingleton.class) {                //第二重判断                if (instance == null) {                    instance = new LazySingleton(); //创建单例实例                }            }        }        return instance;     }}</code></pre><h1 id="4-Initialization-Demand-Holder-进行单例实现"><a href="#4-Initialization-Demand-Holder-进行单例实现" class="headerlink" title="4. Initialization Demand Holder 进行单例实现"></a>4. Initialization Demand Holder 进行单例实现</h1><p>结合饿汉模式和饱汉模式的优点，新的实例化方式： </p><pre><code>//Initialization on Demand Holderclass Singleton {    private Singleton() {    }    private static class HolderClass {            private final static Singleton instance = new Singleton();    }    public static Singleton getInstance() {        return HolderClass.instance;    }    public static void main(String args[]) {        Singleton s1, s2;             s1 = Singleton.getInstance();        s2 = Singleton.getInstance();        System.out.println(s1==s2);    }}</code></pre><p>在单例类中增加了一个静态内部类，在这个内部类中创建单例对象，再将这个单例对象通过getInstance()给外界使用。通过这种方式，我们实现了延迟加载，也保证了线程安全，不影响系统性能</p><h1 id="5-优缺点分析"><a href="#5-优缺点分析" class="headerlink" title="5. 优缺点分析"></a>5. 优缺点分析</h1><h2 id="5-1-优点"><a href="#5-1-优点" class="headerlink" title="5.1 优点"></a>5.1 优点</h2><ol><li>提供了对唯一实例的访问控制</li><li>因为内存中只存在一个对象，因此可以节约系统资源。尤其是对于一些需要频繁创建和销毁的对象，单例模式可以很大程度上提高系统性能</li></ol><h2 id="5-2-缺点"><a href="#5-2-缺点" class="headerlink" title="5.2 缺点"></a>5.2 缺点</h2><ol><li>扩展困难</li><li>职责相对比较重。因为单例类既充当了工厂角色，提供了工厂方法，同时又充当了产品角色，包含一些业务方法，将产品的创建和产品的本身的功能融合到一起。</li><li>一些语言的垃圾自动回收技术，如果实例化的对象在一段时间内没有被使用，系统会认为它是垃圾，会自动销毁并回收资源。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-为什么需要单例模式&quot;&gt;&lt;a href=&quot;#1-为什么需要单例模式&quot; class=&quot;headerlink&quot; title=&quot;1. 为什么需要单例模式&quot;&gt;&lt;/a&gt;1. 为什么需要单例模式&lt;/h1&gt;&lt;p&gt;windows系统的任务管理器，只能有一个,唯一性的原因：&lt;/p
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="Design Pattern" scheme="https://www.llchen60.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>观察者模式</title>
    <link href="https://www.llchen60.com/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
    <id>https://www.llchen60.com/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/</id>
    <published>2020-02-02T22:59:28.000Z</published>
    <updated>2020-02-02T23:00:13.418Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h1><p>观察者模式旨在描述如下行为：即一个对象的状态或者行为的变化将导致其他对象的状态或者行为也发生变化，他们之间将产生联动。为了更好地描述对象之间这种一对多(一对一)的联动，观察者模式应运而生，其定义了对象之间一种一对多的依赖关系，让一个对象的改变能够影响其他对象。</p><ul><li>Publish/ subscribe</li><li>Model/ View</li><li>Source/ Listener </li></ul><h1 id="2-概述"><a href="#2-概述" class="headerlink" title="2. 概述"></a>2. 概述</h1><p><img src="https://i.loli.net/2020/02/03/M6poTJ5PChWrReB.jpg" alt="fig1.jpg"></p><ul><li>subject<ul><li>被观察的对象</li><li>在subject当中定义了一个观察者的集合</li><li>一个观察目标可以接受任意数量的观察者来观察</li><li>定义了通知方法notify() </li></ul></li><li>concreteSubject <ul><li>具体目标，目标类的子类</li><li>通常包含<strong>经常发生改变的数据</strong>，当其状态发生改变的时候，向它的各个观察者发出通知；同时它还实现了在目标类当中定义的抽象业务逻辑方法。</li></ul></li><li>observer<ul><li>观察者将对观察目标的改变做出反应，观察者一般定义为接口，该接口声明了更新数据的方法update()</li></ul></li><li>concreteObserver<ul><li>在具体观察者中维护一个指向具体目标的对象的引用，存储具体观察者的有关状态。这些状态需要和具体目标的状态保持一致，实现了update()方法。</li></ul></li></ul><pre><code>import java.util.*;abstract class Subject {    //定义一个观察者集合用于存储所有观察者对象    protected ArrayList&lt;Observer&gt; observers= new ArrayList();    //注册方法，用于向观察者集合中增加一个观察者    public void attach(Observer observer) {        observers.add(observer);    }    //注销方法，用于在观察者集合中删除一个观察者    public void detach(Observer observer) {        observers.remove(observer);    }    //声明抽象通知方法    public abstract void notify();}class ConcreteSubject extends Subject {    //实现通知方法    public void notify() {        //遍历观察者集合，调用每一个观察者的响应方法        for(Object obs:observers) {            ((Observer)obs).update();        }    }    }interface Observer {    //声明响应方法    public void update();}class ConcreteObserver implements Observer {    //实现响应方法    public void update() {        //具体响应代码    }}</code></pre><h1 id="3-JDK对观察者模式的支持"><a href="#3-JDK对观察者模式的支持" class="headerlink" title="3. JDK对观察者模式的支持"></a>3. JDK对观察者模式的支持</h1><p><img src="https://i.loli.net/2020/02/03/tv5Zh68AQiSfIXC.jpg" alt="fig2.jpg"></p><ul><li>Observable 类<ul><li>定义了一个List来存储观察者对象</li><li>addObserver(Observer o)</li><li>deleteObserver(Observer o)</li><li>notifyObservers()</li><li>deleteObservers()</li><li>setChanged()</li><li>clearChanged()</li><li>hasChanged()</li><li>countObservers()</li></ul></li></ul><p>Observer接口还有Observable类可以直接作为观察者模式的抽象层，再自定义具体观察者类和具体的观察目标类。</p><h1 id="4-Review"><a href="#4-Review" class="headerlink" title="4. Review"></a>4. Review</h1><ul><li>优点<ul><li>实现表示层和数据逻辑层的分离，定义了稳定的消息更新传递机制，并抽象了更新接口</li><li>在观察目标和观察者之间建立一个抽象的耦合</li><li>观察目标只需要维持一个抽象观察者的集合，无须了解其具体的观察者</li></ul></li><li>缺陷<ul><li>太多观察者，都通知很耗时的</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://blog.csdn.net/lovelion/article/details/7720232" target="_blank" rel="noopener">https://blog.csdn.net/lovelion/article/details/7720232</a></li><li><a href="https://blog.csdn.net/LoveLion/article/details/7720490" target="_blank" rel="noopener">https://blog.csdn.net/LoveLion/article/details/7720490</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-定义&quot;&gt;&lt;a href=&quot;#1-定义&quot; class=&quot;headerlink&quot; title=&quot;1. 定义&quot;&gt;&lt;/a&gt;1. 定义&lt;/h1&gt;&lt;p&gt;观察者模式旨在描述如下行为：即一个对象的状态或者行为的变化将导致其他对象的状态或者行为也发生变化，他们之间将产生联动。为
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="Design Pattern" scheme="https://www.llchen60.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>设计模式概述</title>
    <link href="https://www.llchen60.com/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%A6%82%E8%BF%B0/"/>
    <id>https://www.llchen60.com/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%A6%82%E8%BF%B0/</id>
    <published>2020-02-02T22:58:10.000Z</published>
    <updated>2020-02-02T22:58:46.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-起源"><a href="#1-起源" class="headerlink" title="1. 起源"></a>1. 起源</h1><p>每个模式都描述了一个在我们的环境中不断出现的问题，然后描述了该问题的解决方案的核心，通过这种方式，我们可以无数次重用那些已有的成功的解决方案，无须再重复相同的工作。</p><p>软件模式(Software Patterns)是将模式的一般概念应用于软件开发领域，即软件开发的总体指导思路或参照样板。软件模式并非仅限于设计模式，还包括架构模式、分析模式和过程模式等，<strong><em>实际上，在软件开发生命周期的每一个阶段都存在着一些被认同的模式</em></strong>。</p><h1 id="2-软件模式的基础结构"><a href="#2-软件模式的基础结构" class="headerlink" title="2. 软件模式的基础结构"></a>2. 软件模式的基础结构</h1><ul><li>问题描述</li><li>前提条件</li><li>解法</li><li>效果</li></ul><h1 id="3-设计模式"><a href="#3-设计模式" class="headerlink" title="3. 设计模式"></a>3. 设计模式</h1><blockquote><p>设计模式(Design Pattern)是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让代码更容易被他人理解并且保证代码可靠性。</p></blockquote><p>整个设计模式系列将会分以下几个部分：</p><ol><li><p>概述</p></li><li><p>面向对象设计原则</p><ul><li>单一职责</li><li>开闭原则</li><li>里氏代换</li><li>依赖倒转</li><li>接口隔离</li><li>合成复用</li><li>迪米特</li></ul></li><li><p>创建型模式（描述如何创建对象）</p><ul><li>简单工厂模式</li><li>工厂方法模式</li><li>抽象工厂模式</li><li>单例模式</li><li>原型模式</li><li>建造者模式</li></ul></li><li><p>结构型模式（如何实现类或对象的组合）</p><ul><li>适配器模式</li><li>桥接模式</li><li>组合模式</li><li>装饰模式</li><li>外观模式</li><li>享元模式</li><li>代理模式</li></ul></li><li><p>行为型模式（类或者对象怎样交互以及怎样分配职责）（类是对一类事物的描述，抽象出来的；而对象是具体的描述。类是一群具有相同属性的对象的集合体）</p><ul><li>职责链模式</li><li>命令模式</li><li>解释器模式</li><li>迭代器模式</li><li>中介者模式</li><li>备忘录模式</li><li>观察者模式</li><li>状态模式</li><li>策略模式</li><li>模板方法模式</li><li>访问者模式</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-起源&quot;&gt;&lt;a href=&quot;#1-起源&quot; class=&quot;headerlink&quot; title=&quot;1. 起源&quot;&gt;&lt;/a&gt;1. 起源&lt;/h1&gt;&lt;p&gt;每个模式都描述了一个在我们的环境中不断出现的问题，然后描述了该问题的解决方案的核心，通过这种方式，我们可以无数次重用那些
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="Design Pattern" scheme="https://www.llchen60.com/tags/Design-Pattern/"/>
    
  </entry>
  
  <entry>
    <title>如何设计一个秒杀系统</title>
    <link href="https://www.llchen60.com/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    <id>https://www.llchen60.com/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/</id>
    <published>2020-02-02T22:44:35.000Z</published>
    <updated>2020-02-02T22:51:03.584Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><h2 id="1-1-并发读写"><a href="#1-1-并发读写" class="headerlink" title="1.1 并发读写"></a>1.1 并发读写</h2><p>秒杀要解决的主要问题是：并发读与并发写。</p><p>并发读的优化理念是尽量减少用户到服务端来读数据，或者让他们读更少的数据；并发写的处理原则一样，要求我们在数据库层面独立出一个库，做特殊的处理。</p><p>其次，还需要针对秒杀系统做一些保护，针对意料之外的情况设计兜底方案，以防止最坏的情况发生。</p><h2 id="1-2-API设计原则"><a href="#1-2-API设计原则" class="headerlink" title="1.2 API设计原则"></a>1.2 API设计原则</h2><p>值得注意的地方是：如果想打造并维护一个超大流量并发读写、高性能、高可用的系统，在整个用户请求路径上从浏览器到服务端我们要遵循几个原则，就是保证<strong><em>用户请求的数据尽量少、请求数尽量少、路径尽量短、依赖尽量少，不要有单点</em></strong></p><h2 id="1-3-秒杀架构原则"><a href="#1-3-秒杀架构原则" class="headerlink" title="1.3 秒杀架构原则"></a>1.3 秒杀架构原则</h2><h3 id="1-3-1-高可用"><a href="#1-3-1-高可用" class="headerlink" title="1.3.1 高可用"></a>1.3.1 高可用</h3><p>整个系统架构需要满足高可用性，流量符合预期的时候肯定要稳定，就是超出预期也同样不能掉链子，保证秒杀产品顺利卖出。</p><h3 id="1-3-2-一致性"><a href="#1-3-2-一致性" class="headerlink" title="1.3.2 一致性"></a>1.3.2 一致性</h3><p>数据必须一致，即成交总量必须和设定的数量一致。</p><h3 id="1-3-3-高可用"><a href="#1-3-3-高可用" class="headerlink" title="1.3.3 高可用"></a>1.3.3 高可用</h3><p>系统的性能要足够强，支撑足够大的流量，不仅是服务端要做极致的性能优化，而且在整个请求链路上都要做协同的优化，每个地方都要快一点，整个系统就完美了。</p><p>本文将从这三个原则上来分别进行详细说明。</p><h1 id="2-架构原则"><a href="#2-架构原则" class="headerlink" title="2. 架构原则"></a>2. 架构原则</h1><p>秒杀系统本质上是一个满足大并发、高性能和高可用的分布式系统。</p><h2 id="2-1-数据尽量少"><a href="#2-1-数据尽量少" class="headerlink" title="2.1 数据尽量少"></a>2.1 数据尽量少</h2><p>用户请求的数据能少就少，请求的数据包括上传给系统的数据和系统返回给用户的数据。</p><p>因为这些数据在网络上传输需要时间，其次不管是请求数据还是返回数据都需要服务器处理，而服务器在写网络的时候通常都要做压缩和字符编码，这些都非常消耗CPU，所以减少传输的数据量可以显著减少CPU的使用。</p><p>同样，数据尽量少还要求系统依赖的数据能少就少，包括系统完成某些业务逻辑需要读取和保存的数据，这些数据一般是和后台服务以及数据库打交道的。调用其他服务会涉及数据的序列化和反序列化，这也是CPU的一大杀手，同样也会增加延时。而且数据库本身也很容易成为瓶颈，因此越少和数据库打交道越好。</p><h2 id="2-2-请求数尽量少"><a href="#2-2-请求数尽量少" class="headerlink" title="2.2 请求数尽量少"></a>2.2 请求数尽量少</h2><p>用户请求的页面返回后，浏览器渲染这个页面还要包含其他的额外请求，比如说，这个页面依赖的 CSS/JavaScript、图片，以及 Ajax 请求等等都定义为“额外请求”，这些额外请求应该尽量少。因为浏览器每发出一个请求都多少会有一些消耗，例如建立连接要做三次握手，有的时候有页面依赖或者连接数限制，一些请求（例如 JavaScript）还需要串行加载等。另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析，可能会耗时更久。所以你要记住的是，减少请求数可以显著减少以上这些因素导致的资源消耗。</p><p>例如，减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件，把多个 JavaScript 文件合并成一个文件，在 URL 中用逗号隔开（<code>https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js</code>）。这种方式在服务端仍然是单个文件各自存放，只是服务端会有一个组件解析这个 URL，然后动态把这些文件合并起来一起返回。</p><h2 id="2-3-路径要尽量短"><a href="#2-3-路径要尽量短" class="headerlink" title="2.3 路径要尽量短"></a>2.3 路径要尽量短</h2><p>路径指的是用户发出请求到返回数据这个过程中需要经过的中间节点的数量。</p><p>通常，这些节点可以表示为一个系统或者一个新的 Socket 连接（比如代理服务器只是创建一个新的 Socket 连接来转发请求）。每经过一个节点，一般都会产生一个新的 Socket 连接。</p><p>然而，每增加一个连接都会增加新的不确定性。从概率统计上来说，假如一次请求经过 5 个节点，每个节点的可用性是 99.9% 的话，那么整个请求的可用性是：99.9% 的 5 次方，约等于 99.5%。</p><p>所以缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时（可以减少网络传输耗时）。</p><p>要缩短访问路径可以将多个相互有强依赖的应用合并部署在一起，将远程过程调用变成JVM内部的方法调用。</p><h2 id="2-4-依赖要尽量少"><a href="#2-4-依赖要尽量少" class="headerlink" title="2.4 依赖要尽量少"></a>2.4 依赖要尽量少</h2><p>所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务。 </p><p>举个例子，比如说你要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。</p><p>要减少依赖，我们可以给系统进行分级，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统，以此类推。</p><p>注意，0 级系统要尽量减少对 1 级系统的强依赖，防止重要的系统被不重要的系统拖垮。例如支付系统是 0 级系统，而优惠券是 1 级系统的话，在极端情况下可以把优惠券给降级，防止支付系统被优惠券这个 1 级系统给拖垮。</p><h2 id="2-5-不要有单点"><a href="#2-5-不要有单点" class="headerlink" title="2.5 不要有单点"></a>2.5 不要有单点</h2><p>不能有单点，因为单点意味着没有备份，风险不可控，设计分布式系统的一个最重要的原则就是消除单点。</p><p>如何避免单点？ —-&gt; 避免将服务的状态和机器绑定，即把服务无状态化，这样服务就可以在机器中随意移动了。 </p><p>如何那把服务的状态和机器解耦呢？这里也有很多实现方式。例如把和机器相关的配置动态化，这些参数可以通过配置中心来动态推送，在服务启动时动态拉取下来，我们在这些配置中心设置一些规则来方便地改变这些映射关系。</p><p>应用无状态化是有效避免单点的一种方式，但是像存储服务本身很难无状态化，因为数据要存储在磁盘上，本身就要和机器绑定，那么这种场景一般要通过冗余多个备份的方式来解决单点问题。</p><h1 id="3-不同场景下的不同架构案例"><a href="#3-不同场景下的不同架构案例" class="headerlink" title="3. 不同场景下的不同架构案例"></a>3. 不同场景下的不同架构案例</h1><p>如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面增加一个“定时上架”功能，仅在秒杀开始时才让用户看到购买按钮，当商品的库存卖完了也就结束了。这就是当时第一个版本的秒杀系统实现方式。</p><p>但随着请求量的加大（比如从 1w/s 到了 10w/s 的量级），这个简单的架构很快就遇到了瓶颈，因此需要做架构改造来提升系统性能。这些架构改造包括：</p><ol><li>把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化，例如这个独立出来的系统就减少了店铺装修的功能，减少了页面的复杂度；</li><li>在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；</li><li>将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；</li><li>增加秒杀答题，防止有秒杀器抢单。</li></ol><p>此时秒杀已经成为了一个独立的新系统，另外核心的一些数据放到了缓存当中，其他的关联系统也都以独立集群的方式进行部署。</p><p><img src="https://i.loli.net/2020/02/03/9RJsCGFtgbcyrhZ.jpg" alt="fig1.jpg"></p><p>但是这个架构仍然无法支持超过100w/s的请求量，因此为了进一步提高秒杀系统的性能，又对架构做了进一步的升级，比如：</p><ol><li>对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少；</li><li>在服务端对秒杀商品进行本地缓存，不需要再调用依赖系统的后台服务获取数据，甚至不需要去公共的缓存集群中查询数据，这样不仅可以减少系统调用，而且能够避免压垮公共缓存集群。</li><li>增加系统限流保护，防止最坏的情况发生</li></ol><p>此时整个系统架构变成了这个样子，已经对页面进行了进一步的静态化，秒杀过程当中就不需要刷新整个页面了，只需要向服务端请求很少的动态数据。而且最关键的详情和交易系统都增加了本地缓存，来提前缓存秒杀商品的信息，热点数据库也做了独立部署。</p><p><img src="https://i.loli.net/2020/02/03/46cK3CdURO8Yngp.jpg" alt="fig2.jpg"></p><p>从前面的几次升级来看，其实越到后面需要定制的地方越多，也就是越“不通用”。例如，把秒杀商品缓存在每台机器的内存中，这种方式显然不适合太多的商品同时进行秒杀的情况，因为单机的内存始终有限。所以要取得极致的性能，就要在其他地方（比如，通用性、易用性、成本等方面）有所牺牲。</p><h1 id="4-动静分离的方案"><a href="#4-动静分离的方案" class="headerlink" title="4. 动静分离的方案"></a>4. 动静分离的方案</h1><p>秒杀系统需要让请求效率足够高 - 提高单次请求的效率，减少没必要的请求。</p><h2 id="4-1-何为动静数据"><a href="#4-1-何为动静数据" class="headerlink" title="4.1 何为动静数据"></a>4.1 何为动静数据</h2><p>将用户请求的数据（如HTML）划分为动态数据和静态数据。而动态静态数据的划分，在于看页面中输出的数据是否和URL，浏览者，时间，地域相关，以及是否含有Cookie等私密数据。</p><ol><li>对很多媒体类的网站来说，无论谁来看文章，展示的数据都是一样的，那么哪怕这是个动态页面，它仍然是个典型的静态数据。</li><li>访问淘宝的首页，每个人看到的页面可能都是不一样的，其中包含了很多根据访问者个人信息进行的推荐，这些个性化的数据就称为动态数据。</li></ol><p>这里再强调一下，我们所说的静态数据，不能仅仅理解为传统意义上完全存在磁盘上的 HTML 页面，它也可能是经过 Java 系统产生的页面，但是它输出的页面本身不包含上面所说的那些因素。也就是所谓“动态”还是“静态”，并不是说数据本身是否动静，而是数据中是否含有和访问者相关的个性化数据。</p><p>这样做动静分离的时候，我们就可以对分离出来的静态数据做缓存，有了缓存以后，静态数据的访问效率肯定就提高了。</p><h2 id="4-2-如何对静态数据做缓存？"><a href="#4-2-如何对静态数据做缓存？" class="headerlink" title="4.2 如何对静态数据做缓存？"></a>4.2 如何对静态数据做缓存？</h2><h3 id="4-2-1-距离用户最近"><a href="#4-2-1-距离用户最近" class="headerlink" title="4.2.1 距离用户最近"></a>4.2.1 距离用户最近</h3><p>将静态数据缓存到离用户最近的地方。静态数据就是那些相对不会变化的数据，因此可以做缓存。常见的，我们可以缓存在：</p><ol><li>用户浏览器</li><li>CDN上</li><li>服务端的Cache中</li></ol><h3 id="4-2-2-静态化改造要直接缓存HTTP连接"><a href="#4-2-2-静态化改造要直接缓存HTTP连接" class="headerlink" title="4.2.2 静态化改造要直接缓存HTTP连接"></a>4.2.2 静态化改造要直接缓存HTTP连接</h3><p>系统的静态化改造是直接缓存HTTP连接而不仅仅是数据了。如下图所示，Web代理服务器根据请求URL直接去除对应的HTTP响应头和响应体然后直接返回，这个响应过程连HTTP协议都不用重新组装，甚至连HTTP请求头也不需要解析。</p><p><img src="https://i.loli.net/2020/02/03/ydBbWKCeip8jGm5.jpg" alt="fig3.jpg"></p><h3 id="4-2-3-缓存语言"><a href="#4-2-3-缓存语言" class="headerlink" title="4.2.3 缓存语言"></a>4.2.3 缓存语言</h3><p>不同语言写的cache软件处理缓存数据的效率也各不相同。以Java为例，Java不擅长处理大量连接请求，每个连接消耗的内存会比较多，Servlet容器解析HTTP协议比较慢。所以可以不在Java层做缓存，而是直接在Web服务器层上做，这样就可以屏蔽Java的一些弱点；而相比起来，Web服务器(Nginx, Apache, Varnish)会更加擅长处理大并发的静态文件请求。</p><h2 id="4-3-静态数据处理方案"><a href="#4-3-静态数据处理方案" class="headerlink" title="4.3 静态数据处理方案"></a>4.3 静态数据处理方案</h2><p>以商品详情页为例：</p><h3 id="4-3-1-URL唯一化"><a href="#4-3-1-URL唯一化" class="headerlink" title="4.3.1 URL唯一化"></a>4.3.1 URL唯一化</h3><p>要缓存整个HTTP连接，以URL作为缓存的key</p><h3 id="4-3-2-分离浏览者相关的因素"><a href="#4-3-2-分离浏览者相关的因素" class="headerlink" title="4.3.2 分离浏览者相关的因素"></a>4.3.2 分离浏览者相关的因素</h3><p>分离用户的相关信息，是否登录以及登录身份等等。</p><h3 id="4-3-3-分离时间因素"><a href="#4-3-3-分离时间因素" class="headerlink" title="4.3.3 分离时间因素"></a>4.3.3 分离时间因素</h3><p>服务端输出的是哪也通过动态请求获取</p><h3 id="4-3-4-异步化地域因素"><a href="#4-3-4-异步化地域因素" class="headerlink" title="4.3.4 异步化地域因素"></a>4.3.4 异步化地域因素</h3><p>详情页面上与地域相关的因素做成异步获取的方式</p><h3 id="4-3-5-去掉Cookie"><a href="#4-3-5-去掉Cookie" class="headerlink" title="4.3.5 去掉Cookie"></a>4.3.5 去掉Cookie</h3><p>服务端输出的页面包含的 Cookie 可以通过代码软件来删除，如 Web 服务器 Varnish 可以通过 unset req.http.cookie 命令去掉 Cookie。注意，这里说的去掉 Cookie 并不是用户端收到的页面就不含 Cookie 了，而是说，在缓存的静态数据中不含有 Cookie。</p><h2 id="4-4-动态数据处理方案"><a href="#4-4-动态数据处理方案" class="headerlink" title="4.4 动态数据处理方案"></a>4.4 动态数据处理方案</h2><h3 id="4-4-1-ESI-Edge-Side-Includes"><a href="#4-4-1-ESI-Edge-Side-Includes" class="headerlink" title="4.4.1 ESI (Edge Side Includes)"></a>4.4.1 ESI (Edge Side Includes)</h3><p>在Web代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。对服务端性能有影响，但是用户体验会比较好</p><h3 id="4-4-2-CSI-Client-Side-Include"><a href="#4-4-2-CSI-Client-Side-Include" class="headerlink" title="4.4.2 CSI (Client Side Include)"></a>4.4.2 CSI (Client Side Include)</h3><p>单独发出异步Javascript请求，向服务端获取动态内容。这种方式服务端性能更好，但是用户端可能会有延时，体验会差一些</p><h2 id="4-5-动静分离架构方案"><a href="#4-5-动静分离架构方案" class="headerlink" title="4.5 动静分离架构方案"></a>4.5 动静分离架构方案</h2><h3 id="4-5-1-实体机单机部署"><a href="#4-5-1-实体机单机部署" class="headerlink" title="4.5.1 实体机单机部署"></a>4.5.1 实体机单机部署</h3><p>这种方案是将虚拟机改为实体机，以增大 Cache 的容量，并且采用了一致性 Hash 分组的方式来提升命中率。这里将 Cache 分成若干组，是希望能达到命中率和访问热点的平衡。Hash 分组越少，缓存的命中率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致 Cache 被击穿，所以我们应该适当增加多个相同的分组，来平衡访问热点和命中率的问题。</p><p>Nginx+Cache+Java结构实体机单机部署<br><img src="https://i.loli.net/2020/02/03/m6GuWRPxrk4hvK8.jpg" alt="fig4.jpg"></p><p>这种部署方式有以下几个优点：</p><ol><li>没有网络瓶颈，而且能使用大内存；</li><li>既能提升命中率，又能减少 Gzip 压缩；</li><li>减少 Cache 失效压力，因为采用定时失效方式，例如只缓存 3 秒钟，过期即自动失效。</li></ol><p>这个方案中，虽然把通常只需要虚拟机或者容器运行的 Java 应用换成实体机，优势很明显，它会增加单机的内存容量，但是一定程度上也造成了 CPU 的浪费，因为单个的 Java 进程很难用完整个实体机的 CPU。</p><p>另外就是，一个实体机上部署了 Java 应用又作为 Cache 来使用，这造成了运维上的高复杂度，所以这是一个折中的方案。如果你的公司里，没有更多的系统有类似需求，那么这样做也比较合适，如果你们有多个业务系统都有静态化改造的需求，那还是建议把 Cache 层单独抽出来公用比较合理，如下面的方案 2 所示。</p><h3 id="4-5-2-统一Cache层"><a href="#4-5-2-统一Cache层" class="headerlink" title="4.5.2 统一Cache层"></a>4.5.2 统一Cache层</h3><p>所谓统一 Cache 层，就是将单机的 Cache 统一分离出来，形成一个单独的 Cache 集群。统一 Cache 层是个更理想的可推广方案，该方案的结构图如下：</p><p><img src="https://i.loli.net/2020/02/03/oJjRUqAkN8PVGaM.jpg" alt="fig5.jpg"></p><p>统一Cache层，可以减少运维成本，也方便接入其他静态化系统，还有以下优点：</p><ol><li>单独一个 Cache 层，可以减少多个应用接入时使用 Cache 的成本。这样接入的应用只要维护自己的 Java 系统就好，不需要单独维护 Cache，而只关心如何使用即可。</li><li>统一 Cache 的方案更易于维护，如后面加强监控、配置的自动化，只需要一套解决方案就行，统一起来维护升级也比较方便。</li><li>可以共享内存，最大化利用内存，不同系统之间的内存可以动态切换，从而能够有效应对各种攻击。</li></ol><p>这种方案也会带来一些问题。比如：</p><ol><li>Cache 层内部交换网络成为瓶颈；</li><li>缓存服务器的网卡也会是瓶颈；</li><li>机器少风险较大，挂掉一台就会影响很大一部分缓存数据。</li></ol><p>要解决上面这些问题，可以再对 Cache 做 Hash 分组，即一组 Cache 缓存的内容相同，这样能够避免热点数据过度集中导致新的瓶颈产生。</p><h3 id="4-5-3-使用CDN"><a href="#4-5-3-使用CDN" class="headerlink" title="4.5.3 使用CDN"></a>4.5.3 使用CDN</h3><p>在将整个系统做动静分离后，我们自然会想到更进一步的方案，就是将 Cache 进一步前移到 CDN 上，因为 CDN 离用户最近，效果会更好。</p><p>有几个问题需要解决： </p><ol><li>失效问题</li></ol><p>前面我们也有提到过缓存时效的问题，不知道你有没有理解，我再来解释一下。谈到静态数据时，我说过一个关键词叫“相对不变”，它的言外之意是“可能会变化”。比如一篇文章，现在不变，但如果你发现个错别字，是不是就会变化了？如果你的缓存时效很长，那用户端在很长一段时间内看到的都是错的。所以，这个方案中也是，我们需要保证 CDN 可以在秒级时间内，让分布在全国各地的 Cache 同时失效，这对 CDN 的失效系统要求很高。</p><ol start="2"><li>命中率问题</li></ol><p>Cache 最重要的一个衡量指标就是“高命中率”，不然 Cache 的存在就失去了意义。同样，如果将数据全部放到全国的 CDN 上，必然导致 Cache 分散，而 Cache 分散又会导致访问请求命中同一个 Cache 的可能性降低，那么命中率就成为一个问题。</p><ol start="3"><li>发布更新问题</li></ol><p>如果一个业务系统每周都有日常业务需要发布，那么发布系统必须足够简洁高效，而且你还要考虑有问题时快速回滚和排查问题的简便性。</p><p>从前面的分析来看，将商品详情系统放到全国的所有 CDN 节点上是不太现实的，因为存在失效问题、命中率问题以及系统的发布更新问题。那么是否可以选择若干个节点来尝试实施呢？答案是“可以”，但是这样的节点需要满足几个条件：</p><ol><li>靠近访问量比较集中的地区</li><li>离主站相对较远</li><li>节点到主站间的网络比较好，比较稳定</li><li>节点容量大，不会占用其他CDN太多的资源</li></ol><p>基于上面几个因素，选择 CDN 的二级 Cache 比较合适，因为二级 Cache 数量偏少，容量也更大，让用户的请求先回源的 CDN 的二级 Cache 中，如果没命中再回源站获取数据，部署方式如下图所示：</p><p><img src="https://i.loli.net/2020/02/03/Eu5q7bATK4xFkSW.jpg" alt="fig6.jpg"></p><p>使用 CDN 的二级 Cache 作为缓存，可以达到和当前服务端静态化 Cache 类似的命中率，因为节点数不多，Cache 不是很分散，访问量也比较集中，这样也就解决了命中率问题，同时能够给用户最好的访问体验，是当前比较理想的一种 CDN 化方案。</p><h1 id="5-如何处理热点数据"><a href="#5-如何处理热点数据" class="headerlink" title="5. 如何处理热点数据"></a>5. 如何处理热点数据</h1><p>有一部分数据是会被大量用户访问的热卖商品，这部分商品是需要特殊关注的，因为其会对系统产生一系列的影响。</p><p>首先，热点请求会大量占用服务器处理资源，虽然这个热点可能占总量的很小的一部分，然而却可能抢占90%以上的服务器资源，如果这个热点请求还是没有价值的无效请求，那么对系统资源来说完全是浪费。</p><h2 id="5-1-什么是热点"><a href="#5-1-什么是热点" class="headerlink" title="5.1 什么是热点"></a>5.1 什么是热点</h2><h3 id="5-1-1-热点操作"><a href="#5-1-1-热点操作" class="headerlink" title="5.1.1 热点操作"></a>5.1.1 热点操作</h3><p>例如大量的刷新页面，大量添加购物车，零点大量的下单等。这些操作可以抽象为“读请求”和“写请求”，这两种请求的处理方式大相径庭，读请求的优化空间比较大，而写请求的瓶颈一般都在存储层，优化的思路就是根据CAP理论做平衡。</p><h3 id="5-1-2-热点数据"><a href="#5-1-2-热点数据" class="headerlink" title="5.1.2 热点数据"></a>5.1.2 热点数据</h3><p>热点数据就是用户的热点请求对应的数据，又可以分为静态热点数据和动态热点数据。</p><p>静态热点数据，就是能够提前预测的热点数据。动态热点数据，就是不能被提前预测到的，系统在运行过程中临时产生的热点。</p><h2 id="5-2-发现热点数据"><a href="#5-2-发现热点数据" class="headerlink" title="5.2 发现热点数据"></a>5.2 发现热点数据</h2><h3 id="5-2-1-发现静态热点数据"><a href="#5-2-1-发现静态热点数据" class="headerlink" title="5.2.1 发现静态热点数据"></a>5.2.1 发现静态热点数据</h3><p>如前面讲的，静态热点数据可以通过商业手段，例如强制让卖家通过报名参加的方式提前把热点商品筛选出来，实现方式是通过一个运营系统，把参加活动的商品数据进行打标，然后通过一个后台系统对这些热点商品进行预处理，如提前进行缓存。但是这种通过报名提前筛选的方式也会带来新的问题，即增加卖家的使用成本，而且实时性较差，也不太灵活。</p><p>不过，除了提前报名筛选这种方式，你还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，我们可以认为这些 TOP N 的商品就是热点商品。</p><h3 id="5-2-2-发现动态热点数据"><a href="#5-2-2-发现动态热点数据" class="headerlink" title="5.2.2 发现动态热点数据"></a>5.2.2 发现动态热点数据</h3><p>具体实现</p><ol><li>构建异步系统，用来收集交易链路上各个环节中的中间件产品的热点Key，例如Nginx、缓存、RPC服务框架</li><li>建立一个热点上报和可以按照需求订阅的热点服务的下发规范。因为交易链路上各个系统(包括详情，购物车，交易，优惠，库存等等)会有访问上的时间差，需要将上游已经发现的热点透传给下游系统，提前做好保护。例如，对于大促高峰期，详情系统是最早知道的。</li><li>将上游系统收集的热点数据发送到热点服务台，让下游系统提前知道信息，做热电保护</li></ol><p><img src="https://i.loli.net/2020/02/03/hGd5HWVLaEKAwZS.jpg" alt="fig7.jpg"></p><p>我们通过部署在每台机器上的 Agent 把日志汇总到聚合和分析集群中，然后把符合一定规则的热点数据，通过订阅分发系统再推送到相应的系统中。你可以是把热点数据填充到 Cache 中，或者直接推送到应用服务器的内存中，还可以对这些数据进行拦截，总之下游系统可以订阅这些数据，然后根据自己的需求决定如何处理这些数据。</p><p>Tips:</p><ol><li>热点服务的后台抓取热点数据日志的方式最好采用异步的方式；可以保证通过性，不会影响业务系统和中间件产品的主流程。</li><li>热点服务和中间件自身需要有热电保护模块，每个中间件和应用和需要保护自己</li><li>热点发现需要接近实时，因为只有接近实时才有意义，能及时对下游系统提供保护</li></ol><h2 id="5-3-如何处理热点数据"><a href="#5-3-如何处理热点数据" class="headerlink" title="5.3 如何处理热点数据"></a>5.3 如何处理热点数据</h2><h3 id="5-3-1-优化"><a href="#5-3-1-优化" class="headerlink" title="5.3.1 优化"></a>5.3.1 优化</h3><p>缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。</p><h3 id="5-3-2-限制"><a href="#5-3-2-限制" class="headerlink" title="5.3.2 限制"></a>5.3.2 限制</h3><p>保护机制，比如对商品的ASIN做一致性hash，然后根据hash做分桶，每个分桶处置一个处理队列，通过这种方式将热点商品限制在一个请求队列当中，防止因为某些热点商品占用太多的服务器资源，而使得其他请求始终得不到服务器的处理资源。 </p><h3 id="5-3-3-隔离"><a href="#5-3-3-隔离" class="headerlink" title="5.3.3 隔离"></a>5.3.3 隔离</h3><p>将热点数据隔离出来，针对热点数据可以再做优化</p><ol><li>业务隔离 - 商业逻辑上运行上的隔离</li><li>系统隔离 - 运行时的隔离</li><li>数据隔离 - 单独数据库 Cache集群</li></ol><h1 id="6-流量削峰"><a href="#6-流量削峰" class="headerlink" title="6. 流量削峰"></a>6. 流量削峰</h1><p>秒杀请求在时间上是高度集中于某一特定的时间点的，这样一来会有一个特别高的流量峰值，它对资源的消耗是瞬时的。</p><p>但是对于秒杀这个场景来说，最终能够抢到的商品的人数是固定的，并发读越高，无效请求也就越多了。</p><p>从业务角度上来说，秒杀希望更多的人能够参与进来，更多的人来刷新页面，但是真正开始下单的时候，秒杀请求就不是越多越好了，可以设计一些规则，让并发的请求更多的延缓，甚至我们可以过滤掉一些无效请求。</p><h2 id="6-1-削峰的原因"><a href="#6-1-削峰的原因" class="headerlink" title="6.1 削峰的原因"></a>6.1 削峰的原因</h2><p>我们知道服务器的处理资源是恒定的，你用或者不用它的处理能力都是一样的，所以出现峰值的话，很容易导致忙到处理不过来，闲的时候却又没有什么要处理。但是由于要保证服务质量，我们的很多处理资源只能按照忙的时候来预估，而这会导致资源的一个浪费。</p><p>削峰主要是为了能够让服务端处理变得更加平稳，也为了能够节省服务器的资源成本。从秒杀这个场景来说，就是更多延缓用户请求的发出，以便减少或者过滤掉一些无效请求，遵从请求数要尽量少的原则。</p><h2 id="6-2-无损削峰方式"><a href="#6-2-无损削峰方式" class="headerlink" title="6.2 无损削峰方式"></a>6.2 无损削峰方式</h2><h3 id="6-2-1-排队"><a href="#6-2-1-排队" class="headerlink" title="6.2.1 排队"></a>6.2.1 排队</h3><p>用消息队列缓冲瞬时流量，将同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另外一端平滑地将信息推送出去。</p><p><img src="https://i.loli.net/2020/02/03/dyp5UfOgsSHC3hi.jpg" alt="fig8.jpg"></p><p>但是如果流量峰值持续一段时间，超过了消息队列的处理上限，还是会被压垮的。</p><p>其他常见的排队方式有：</p><ol><li>利用线程池加锁等待</li><li>先进先出、先进后出等常用的内存排队算法的实现</li><li>将请求序列化到文件当中，然后再顺序读文件</li></ol><h3 id="6-2-2-答题"><a href="#6-2-2-答题" class="headerlink" title="6.2.2 答题"></a>6.2.2 答题</h3><p>第一个目的是防止部分买家使用秒杀器在参加秒杀时作弊。2011 年秒杀非常火的时候，秒杀器也比较猖獗，因而没有达到全民参与和营销的目的，所以系统增加了答题来限制秒杀器。增加答题后，下单的时间基本控制在 2s 后，秒杀器的下单比例也大大下降。</p><p>第二个目的其实就是延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰。这个重要的功能就是把峰值的下单请求拉长，从以前的 1s 之内延长到 2s~10s。这样一来，请求峰值基于时间分片了。这个时间的分片对服务端处理并发非常重要，会大大减轻压力。而且，由于请求具有先后顺序，靠后的请求到来时自然也就没有库存了，因此根本到不了最后的下单步骤，所以真正的并发写就非常有限了。这种设计思路目前用得非常普遍，如当年支付宝的“咻一咻”、微信的“摇一摇”都是类似的方式。</p><h3 id="6-2-3-分层过滤"><a href="#6-2-3-分层过滤" class="headerlink" title="6.2.3 分层过滤"></a>6.2.3 分层过滤</h3><p>采用漏斗式的设计</p><p><img src="https://i.loli.net/2020/02/03/GCXLQ2UsIqElavZ.jpg" alt="fig9.jpg"></p><p>假如请求分别经过 CDN、前台读系统（如商品详情系统）、后台系统（如交易系统）和数据库这几层，那么：</p><ul><li>大部分数据和流量在用户浏览器或者 CDN 上获取，这一层可以拦截大部分数据的读取</li><li>经过第二层（即前台系统）时数据（包括强一致性的数据）尽量得走 Cache，过滤一些无效的请求</li><li>再到第三层后台系统，主要做数据的二次检验，对系统做好保护和限流，这样数据量和请求就进一步减少</li><li>最后在数据层完成数据的强一致性校验</li></ul><p>分层过滤的核心思想是：在不同的层次尽可能地过滤掉无效请求，让漏斗最末端的才是有效的请求。而达到这种效果，我们就必须对数据做分层的校验。</p><p>分层校验的基本原则有：</p><ol><li>将动态请求的读数据缓存在Web端，过滤掉无效的数据读</li><li>对读数据不做强一致性校验，减少因为一致性校验产生的瓶颈问题</li><li>对写数据进行基于时间的合理分片，过滤掉过期的失效请求</li><li>对写请求做限流保护，将超出系统承载能力的请求过滤掉</li><li>对写数据进行强一致性校验，只保留最后有效的数据</li></ol><p>分层校验的目的是：在读系统中，尽量减少由于一致性校验带来的系统瓶颈，但是尽量将不影响性能的检查条件提前，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求、营销等价物是否充足等；在写数据系统中，主要对写的数据（如“库存”）做一致性检查，最后在数据库层保证数据的最终准确性（如“库存”不能减为负数）。</p><h1 id="7-影响性能的因素"><a href="#7-影响性能的因素" class="headerlink" title="7. 影响性能的因素"></a>7. 影响性能的因素</h1><h2 id="7-1-性能的定义"><a href="#7-1-性能的定义" class="headerlink" title="7.1 性能的定义"></a>7.1 性能的定义</h2><p>服务设备的不同对于性能的定义也是不一样的，例如CPU主要看主频，磁盘主要看IOPS(Input/ output Operations Per Second, 即每秒进行读写操作的次数)。</p><p>关于秒杀，我们主要讨论系统服务端的性能，一般使用QPS来衡量，还有一个影响和QPS息息相关，即响应时间(Response Time, RT)，可以理解为服务器处理响应的耗时。</p><p>正常情况下响应时间越短，一秒钟处理的请求数就会越多，这在单线程处理的情况下看起来是线性关系，即我们只要把每个请求的响应时间降到最低，那么性能就会最高。而在多线程当中，总QPS = （1000ms/ 响应时间）x 线程数，从这个角度上来看，性能和两个因素相关，一个是一次响应的服务端的耗时，一个是处理请求的线程数。</p><h3 id="7-1-1-响应时间"><a href="#7-1-1-响应时间" class="headerlink" title="7.1.1 响应时间"></a>7.1.1 响应时间</h3><p>对于大部分的Web系统而言，响应时间一般是由CPU执行时间和线程等待时间组成的，即服务器在处理一个请求时，一部分是CPU本身在做运算，还有一部分是各种等待。</p><p>理解了服务器处理请求的逻辑，估计你会说为什么我们不去减少这种等待时间。很遗憾，根据我们实际的测试发现，减少线程等待时间对提升性能的影响没有我们想象得那么大，它并不是线性的提升关系，这点在很多代理服务器（Proxy）上可以做验证。</p><p>如果代理服务器本身没有CPU消耗，我们在每次给代理服务器代理的请求加个延时，即增加响应时间，但是这对代理服务器本身的吞吐量并没有多大的影响，因为代理服务器本身的资源并没有被消耗，可以通过增加代理服务器的处理线程数，来弥补响应时间对代理服务器的 QPS 的影响。</p><p>其实，真正对性能有影响的是 CPU 的执行时间。这也很好理解，因为 CPU 的执行真正消耗了服务器的资源。经过实际的测试，如果减少 CPU 一半的执行时间，就可以增加一倍的 QPS。</p><h3 id="7-1-2-线程数"><a href="#7-1-2-线程数" class="headerlink" title="7.1.2 线程数"></a>7.1.2 线程数</h3><p>并不是线程数越多越好，总QPS就会越大，因为线程本身也消耗资源，会受到其他因素的制约。例如，线程越多系统的线程切换成本就会越高，而且每个线程都会耗费一定的内存。</p><p>默认的配置一般为：</p><blockquote><p>线程数 = 2 x CPU核数 + 1</p></blockquote><p>还有一个根据最佳实践得出来的公式为：</p><blockquote><p>线程数 = [(线程等待时间 + 线程CPU时间) / 线程CPU时间] x CPU数量</p></blockquote><p>因此要提升性能，我们就要减少CPU的执行时间，另外就是要设置一个合理的并发线程数量，通过这两方面来显著提升服务器的性能。</p><h2 id="7-2-如何发现瓶颈"><a href="#7-2-如何发现瓶颈" class="headerlink" title="7.2 如何发现瓶颈"></a>7.2 如何发现瓶颈</h2><p>服务器会出现瓶颈的地方很多，例如CPU， 内存， 磁盘以及网络等可能都会导致瓶颈。另外不同的系统对于瓶颈的关注度不一样，例如对缓存系统来说，制约的是内存，而对存储型的系统来说I/O 更容易出现瓶颈。</p><p>而对于秒杀，瓶颈更容易发生在CPU上。</p><p>那么，如何发现 CPU 的瓶颈呢？其实有很多 CPU 诊断工具可以发现 CPU 的消耗，最常用的就是 JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间，可以发现哪个函数消耗的 CPU 时间最多，以便你有针对性地做优化。</p><p>当然还有一些办法也可以近似地统计 CPU 的耗时，例如通过 jstack 定时地打印调用栈，如果某些函数调用频繁或者耗时较多，那么那些函数就会多次出现在系统调用栈里，这样相当于采样的方式也能够发现耗时较多的函数。</p><p>虽说秒杀系统的瓶颈大部分在 CPU，但这并不表示其他方面就一定不出现瓶颈。例如，如果海量请求涌过来，你的页面又比较大，那么网络就有可能出现瓶颈。</p><p>怎样简单地判断 CPU 是不是瓶颈呢？一个办法就是看当 QPS 达到极限时，你的服务器的 CPU 使用率是不是超过了 95%，如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。</p><h2 id="7-3-如何优化系统"><a href="#7-3-如何优化系统" class="headerlink" title="7.3 如何优化系统"></a>7.3 如何优化系统</h2><p>针对Java来说的：</p><h3 id="7-3-1-减少编码"><a href="#7-3-1-减少编码" class="headerlink" title="7.3.1 减少编码"></a>7.3.1 减少编码</h3><p>Java的编码运行比较慢，在很多场景下，只要涉及字符串的操作都会比较消耗CPU资源，不管是磁盘IO还是网络IO，因为都需要将字符转换成字节，这个转换必须编码。</p><p>每个字符的编码都需要查表，而这种查表的操作非常耗资源，所以减少字符到字节或者相反的转换、减少字符编码会非常有成效。减少编码就可以大大提升性能。</p><p>那么如何才能减少编码呢？例如，网页输出是可以直接进行流输出的，即用 resp.getOutputStream() 函数写数据，把一些静态的数据提前转化成字节，等到真正往外写的时候再直接用 OutputStream() 函数写，就可以减少静态数据的编码转换。</p><h3 id="7-3-2-减少序列化"><a href="#7-3-2-减少序列化" class="headerlink" title="7.3.2 减少序列化"></a>7.3.2 减少序列化</h3><p>序列化也是Java性能的一大天敌，减少Java当中的序列化操作也能大大提升性能。又因为序列化往往是和编码同时发生的，所以减少序列化也就减少了编码。</p><p>序列化大部分是在 RPC 中发生的，因此避免或者减少 RPC 就可以减少序列化，当然当前的序列化协议也已经做了很多优化来提升性能。有一种新的方案，就是可以将多个关联性比较强的应用进行“合并部署”，而减少不同应用之间的 RPC 也可以减少序列化的消耗。</p><p>所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个 Tomcat 容器中，且不能走本机的 Socket，这样才能避免序列化的产生。</p><h3 id="7-3-3-Java-秒杀场景的针对性优化"><a href="#7-3-3-Java-秒杀场景的针对性优化" class="headerlink" title="7.3.3 Java 秒杀场景的针对性优化"></a>7.3.3 Java 秒杀场景的针对性优化</h3><p>Java 和通用的 Web 服务器（如 Nginx 或 Apache 服务器）相比，在处理大并发的 HTTP 请求时要弱一点，所以一般我们都会对大流量的 Web 系统做静态化改造，让大部分请求和数据直接在 Nginx 服务器或者 Web 代理服务器（如 Varnish、Squid 等）上直接返回（这样可以减少数据的序列化与反序列化），而 Java 层只需处理少量数据的动态请求。针对这些请求，我们可以使用以下手段进行优化：</p><ul><li>直接使用 Servlet 处理请求。避免使用传统的 MVC 框架，这样可以绕过一大堆复杂且用处不大的处理逻辑，节省 1ms 时间（具体取决于你对 MVC 框架的依赖程度）。</li><li>直接输出流数据。使用 resp.getOutputStream() 而不是 resp.getWriter() 函数，可以省掉一些不变字符数据的编码，从而提升性能；数据输出时推荐使用 JSON 而不是模板引擎（一般都是解释执行）来输出页面。</li></ul><h3 id="7-3-4-并发读优化"><a href="#7-3-4-并发读优化" class="headerlink" title="7.3.4 并发读优化"></a>7.3.4 并发读优化</h3><p>也许有读者会觉得这个问题很容易解决，无非就是放到 Tair 缓存里面。集中式缓存为了保证命中率一般都会采用一致性 Hash，所以同一个 key 会落到同一台机器上。虽然单台缓存机器也能支撑 30w/s 的请求，但还是远不足以应对像“大秒”这种级别的热点商品。那么，该如何彻底解决单点的瓶颈呢？</p><p>答案是采用应用层的 LocalCache，即在秒杀系统的单机上缓存商品相关的数据。</p><p>那么，又如何缓存（Cache）数据呢？你需要划分成动态数据和静态数据分别进行处理：</p><ul><li>像商品中的“标题”和“描述”这些本身不变的数据，会在秒杀开始之前全量推送到秒杀机器上，并一直缓存到秒杀结束；</li><li>像库存这类动态数据，会采用“被动失效”的方式缓存一定时间（一般是数秒），失效后再去缓存拉取最新的数据。</li></ul><p>还有关于一致性的问题，因为库存是在不断更新的，这就要用到前面介绍的读数据的分层校验原则了，读的场景可以允许一定的脏数据，因为这里的误判只会导致少量原本无库存的下单请求被误认为有库存，可以等到真正写数据时再保证最终的一致性，通过在数据的高可用性和一致性之间的平衡，来解决高并发的数据读取问题。</p><h1 id="8-减库存设计的核心逻辑"><a href="#8-减库存设计的核心逻辑" class="headerlink" title="8. 减库存设计的核心逻辑"></a>8. 减库存设计的核心逻辑</h1><p>不超卖是秒杀系统的前提。减库存到底应该是在下单阶段还是付款阶段呢？ </p><h2 id="8-1-减库存的方式"><a href="#8-1-减库存的方式" class="headerlink" title="8.1 减库存的方式"></a>8.1 减库存的方式</h2><h3 id="8-1-1-下单减库存"><a href="#8-1-1-下单减库存" class="headerlink" title="8.1.1 下单减库存"></a>8.1.1 下单减库存</h3><p>即当买家下单之后，在商品的总库存中减去买家购买的数量。这种方式控制最精确，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的现象。但是有些人下完单以后并不会付款。</p><h3 id="8-1-2-付款减库存"><a href="#8-1-2-付款减库存" class="headerlink" title="8.1.2 付款减库存"></a>8.1.2 付款减库存</h3><p>即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。</p><h3 id="8-1-3-预扣库存"><a href="#8-1-3-预扣库存" class="headerlink" title="8.1.3 预扣库存"></a>8.1.3 预扣库存</h3><p>这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 10 分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。</p><h2 id="8-2-可能存在的问题"><a href="#8-2-可能存在的问题" class="headerlink" title="8.2 可能存在的问题"></a>8.2 可能存在的问题</h2><p>假如我们采用“下单减库存”的方式，即用户下单后就减去库存，正常情况下，买家下单后付款的概率会很高，所以不会有太大问题。但是有一种场景例外，就是当卖家参加某个活动时，此时活动的有效时间是商品的黄金售卖时间，如果有竞争对手通过恶意下单的方式将该卖家的商品全部下单，让这款商品的库存减为零，那么这款商品就不能正常售卖了。要知道，这些恶意下单的人是不会真正付款的，这正是“下单减库存”方式的不足之处。</p><p>既然“下单减库存”可能导致恶意下单，从而影响卖家的商品销售，那么有没有办法解决呢？你可能会想，采用“付款减库存”的方式是不是就可以了？的确可以。但是，“付款减库存”又会导致另外一个问题：库存超卖。</p><p>假如有 100 件商品，就可能出现 300 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。这样一来，就会导致很多买家下单成功但是付不了款，买家的购物体验自然比较差。</p><p>那么，既然“下单减库存”和“付款减库存”都有缺点，我们能否把两者相结合，将两次操作进行前后关联起来，下单时先预扣，在规定时间内不付款再释放库存，即采用“预扣库存”这种方式呢？</p><p>这种方案确实可以在一定程度上缓解上面的问题。但是否就彻底解决了呢？其实没有！针对恶意下单这种情况，虽然把有效的付款时间设置为 10 分钟，但是恶意买家完全可以在 10 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。</p><p>例如，给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买 3 件），以及对重复下单不付款的操作进行次数限制等。</p><p>针对“库存超卖”这种情况，在 10 分钟时间内下单的数量仍然有可能超过库存数量，遇到这种情况我们只能区别对待：对普通的商品下单数量超过库存数量的情况，可以通过补货来解决；但是有些卖家完全不允许库存为负数的情况，那只能在买家付款时提示库存不足。</p><h2 id="8-3-大型秒杀中如何减库存"><a href="#8-3-大型秒杀中如何减库存" class="headerlink" title="8.3 大型秒杀中如何减库存"></a>8.3 大型秒杀中如何减库存</h2><p>对于一般业务系统而言，一般是预扣库存的方案，超出有效付款时间订单就会自动释放。而对于秒杀场景，一般采用下单减库存。</p><p>“下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种解决方案：一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错；再有一种就是使用 CASE WHEN 判断语句，例如这样的 SQL 语句：</p><pre><code>UPDATE item SET inventory = CASE WHEN inventory &gt;= xxx THEN inventory-xxx ELSE inventory END</code></pre><p>秒杀商品和普通商品的减库存还是有些差异的，例如商品数量比较少，交易时间段也比较短，因此这里有一个大胆的假设，即能否把秒杀商品减库存直接放到缓存系统中实现，也就是直接在缓存中减库存或者在一个带有持久化功能的缓存系统（如 Redis）中完成呢？</p><p>如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU 库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。</p><p>由于 MySQL 存储数据的特点，同一数据在数据库里肯定是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁，而并发度越高时等待线程会越多，TPS（Transaction Per Second，即每秒处理的消息数）会下降，响应时间（RT）会上升，数据库的吞吐量就会严重受影响。</p><p>这就可能引发一个问题，就是单个热点商品会影响整个数据库的性能， 导致 0.01% 的商品影响 99.99% 的商品的售卖，这是我们不愿意看到的情况。一个解决思路是遵循前面介绍的原则进行隔离，把热点商品放到单独的热点库中。但是这无疑会带来维护上的麻烦，比如要做热点数据的动态迁移以及单独的数据库等。</p><p>而分离热点商品到单独的数据库还是没有解决并发锁的问题，我们应该怎么办呢？要解决并发锁的问题，有两种办法：</p><ol><li>应用层排队</li></ol><p>按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。</p><ol start="2"><li>数据库排队</li></ol><p>应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。阿里的数据库团队开发了针对这种 MySQL 的 InnoDB 层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。</p><h1 id="9-如何设计兜底方案？"><a href="#9-如何设计兜底方案？" class="headerlink" title="9. 如何设计兜底方案？"></a>9. 如何设计兜底方案？</h1><h2 id="9-1-高可用建设应该从哪里着手？"><a href="#9-1-高可用建设应该从哪里着手？" class="headerlink" title="9.1 高可用建设应该从哪里着手？"></a>9.1 高可用建设应该从哪里着手？</h2><p><img src="https://i.loli.net/2020/02/03/pJX2oIyCGUVY7H5.jpg" alt="fig10.jpg"></p><ol><li>架构阶段 - 考虑系统的可扩展性和容错性，要避免出现单点问题。例如多机房单元化部署，即使某个城市的某个机房出现整体故障，仍然不会影响整体网站的运转。</li><li>编码阶段 - 保证代码的健壮性，例如涉及到远程调用的问题的时候，要设置合理的超时退出机制，防止被其他系统拖垮，也要对调用的返回结果集有预期，防止返回的结果超出程序处理的范围。即对错误异常进行捕获，对无法预料的错误要有默认处理结果。</li><li>测试阶段 - 测试主要是保证测试用例的覆盖度，保证最坏情况发生的时候，我们也有相应的处理流程。</li><li>发布阶段 - 要有紧急的回滚机制</li><li>运行阶段 - 运行态是常态，重要的是对系统的监控要准确及时，发现问题能够准确报警并且报警数据要准确详细，以便于排查问题。</li><li>故障发生 - 及时止损，例如由于程序问题导致商品价格错误，就要及时下架商品或者关闭购买链接，防止造成重大资产损失。</li></ol><p>为什么系统的高可用建设要放到整个生命周期中全面考虑？因为我们在每个环节中都可能犯错，而有些环节犯的错，你在后面是无法弥补的。例如在架构阶段，你没有消除单点问题，那么系统上线后，遇到突发流量把单点给挂了，你就只能干瞪眼，有时候想加机器都加不进去。所以高可用建设是一个系统工程，必须在每个环节都做好。</p><p>那么针对秒杀系统，我们重点介绍在遇到大流量时，应该从哪些方面来保障系统的稳定运行，所以更多的是看如何针对运行阶段进行处理，这就引出了接下来的内容：降级、限流和拒绝服务。</p><h2 id="9-2-降级"><a href="#9-2-降级" class="headerlink" title="9.2 降级"></a>9.2 降级</h2><p>所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务。它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。</p><p>降级方案可以这样设计：当秒杀流量达到 5w/s 时，把成交记录的获取从展示 20 条降级到只展示 5 条。“从 20 改到 5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。</p><p>这里，我给出开关系统的示意图。它分为两部分，一部分是开关控制台，它保存了开关的具体配置信息，以及具体执行开关所对应的机器列表；另一部分是执行下发开关数据的 Agent，主要任务就是保证开关被正确执行，即使系统重启后也会生效。</p><p><img src="https://i.loli.net/2020/02/03/MsuI54DXOFAKU7G.jpg" alt="fig11.jpg"></p><h2 id="9-3-限流"><a href="#9-3-限流" class="headerlink" title="9.3 限流"></a>9.3 限流</h2><p>如果说降级是牺牲了一部分次要的功能和用户的体验效果，那么限流就是更极端的一种保护措施了。限流就是当系统容量达到瓶颈时，我们需要通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施。</p><p>这里，我同样给出了限流系统的示意图。总体来说，限流既可以是在客户端限流，也可以是在服务端限流。此外，限流的实现方式既要支持 URL 以及方法级别的限流，也要支持基于 QPS 和线程的限流。</p><ul><li>客户端限流</li></ul><p>好处可以限制请求的发出，通过减少发出无用请求从而减少对系统的消耗。缺点就是当客户端比较分散时，没法设置合理的限流阈值：如果阈值设的太小，会导致服务端没有达到瓶颈时客户端已经被限制；而如果设的太大，则起不到限制的作用。</p><ul><li>服务端限流</li></ul><p>好处是可以根据服务端的性能设置合理的阈值，而缺点就是被限制的请求都是无效的请求，处理这些无效的请求本身也会消耗服务器资源。</p><p><img src="https://i.loli.net/2020/02/03/zm8P6fRyoUsclSj.jpg" alt="fig12.jpg"></p><p>在限流的实现手段上来讲，基于 QPS 和线程数的限流应用最多，最大 QPS 很容易通过压测提前获取，例如我们的系统最高支持 1w QPS 时，可以设置 8000 来进行限流保护。线程数限流在客户端比较有效，例如在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃。</p><p>限流无疑会影响用户的正常请求，所以必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能 fast fail（快速失败）而拖垮系统。</p><h2 id="9-4-拒绝服务"><a href="#9-4-拒绝服务" class="headerlink" title="9.4 拒绝服务"></a>9.4 拒绝服务</h2><p>当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2*CPU 核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。例如秒杀系统，我们在如下几个环节设计过载保护：</p><p>在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝 HTTP 请求并返回 503 错误码，在 Java 层同样也可以设计过载保护。</p><p>拒绝服务可以说是一种不得已的兜底方案，用以防止最坏情况发生，防止因把服务器压跨而长时间彻底无法提供服务。像这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Overview&quot;&gt;&lt;a href=&quot;#1-Overview&quot; class=&quot;headerlink&quot; title=&quot;1. Overview&quot;&gt;&lt;/a&gt;1. Overview&lt;/h1&gt;&lt;h2 id=&quot;1-1-并发读写&quot;&gt;&lt;a href=&quot;#1-1-并发读写&quot; c
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="秒杀" scheme="https://www.llchen60.com/tags/%E7%A7%92%E6%9D%80/"/>
    
  </entry>
  
  <entry>
    <title>面向对象设计原则</title>
    <link href="https://www.llchen60.com/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"/>
    <id>https://www.llchen60.com/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</id>
    <published>2020-02-02T22:03:01.000Z</published>
    <updated>2020-02-02T22:06:25.685Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>支持可维护性，提高系统的可复用性</p><h1 id="2-设计原则"><a href="#2-设计原则" class="headerlink" title="2.设计原则"></a>2.设计原则</h1><h2 id="2-1-单一职责原则-Single-Responsibility-Principle"><a href="#2-1-单一职责原则-Single-Responsibility-Principle" class="headerlink" title="2.1 单一职责原则 Single Responsibility Principle"></a>2.1 单一职责原则 Single Responsibility Principle</h2><p>一个类只负责一个功能领域中的相应职责，只负责一个功能领域中的相应职责。</p><p>承担的责任越多，那被复用的可能性就越小。多职责意味着是把多个类耦合了起来</p><p><img src="https://i.loli.net/2020/02/03/jKXMsxyiB6z3uac.jpg" alt="单一职责1.jpg"><br>CustomerDataChart类包含了与数据库的连接，查询客户信息和创建显示图标三大方面的功能，应该将其分为三个类，分别进行处理</p><p><img src="https://i.loli.net/2020/02/03/X4Z1TfBRzkMLSNW.jpg" alt="单一职责2.jpg"><br>DBUtil  负责连接数据库<br>CustomerDao 负责操作数据库中的Customer表<br>CustomerDataChart 负责图表的生成的显示</p><h2 id="2-2-开闭原则-Open-Closed-Principle"><a href="#2-2-开闭原则-Open-Closed-Principle" class="headerlink" title="2.2 开闭原则 Open-Closed Principle"></a>2.2 开闭原则 Open-Closed Principle</h2><p>软件实体应对拓展开放，而对修改关闭。<strong><em>软件实体应该尽量在不修改原有代码的情况下进行扩展。</em></strong></p><p>为了满足开闭原则，需要对系统进行抽象化设计！！！为系统定义一个相对稳定的抽象层，而后将不同的实现行为移至具体的实现层中完成。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。</p><p><img src="https://i.loli.net/2020/02/03/6SEFzrxNtTgMPQK.jpg" alt="开闭原则1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/bM73ZsD4UkdJ9QP.jpg" alt="开闭原则2.jpg"></p><p>加一个抽象类，每一种Chart可以extends这个抽象类，然后做具体的实现。在ChartDisplay类中，可以实例化Chart类，调用其display()方法来显示对应的图表。当要改变的时候，加一个实现类，在客户端注入这个对象即可。</p><h2 id="2-3-里氏代换原则-Liskov-Substitution-Principle"><a href="#2-3-里氏代换原则-Liskov-Substitution-Principle" class="headerlink" title="2.3 里氏代换原则 Liskov Substitution Principle"></a>2.3 里氏代换原则 Liskov Substitution Principle</h2><p>所有引用基类对象的地方能够透明地使用其子类的对象</p><p>在软件中，将一个基类的对象替换成其子类对象，程序将不会产生任何错误和异常，反过来则不成立。</p><p>里氏代换原则是实现开闭原则的重要方式之一。由于使用基类对象的地方都可以使用子类，因此<strong><em>在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。</em></strong></p><h3 id="2-3-1-注意事项"><a href="#2-3-1-注意事项" class="headerlink" title="2.3.1 注意事项"></a>2.3.1 注意事项</h3><ol><li>子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。</li><li>我们在运用里氏代换原则时，尽量把父类设计为<strong>抽象类或者接口</strong>，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。</li></ol><p><img src="https://i.loli.net/2020/02/03/OXI4TrtJ1j3gzVa.jpg" alt="里氏原则1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/4PuoLXtib6SQCKH.jpg" alt="里氏原则2.jpg"></p><p>通过增加抽象类，让子类来替换父类的方式来进行编程，增强代码的复用性。</p><h2 id="2-4-依赖倒转原则-Dependence-Inversion-Principle"><a href="#2-4-依赖倒转原则-Dependence-Inversion-Principle" class="headerlink" title="2.4 依赖倒转原则 Dependence Inversion Principle"></a>2.4 依赖倒转原则 Dependence Inversion Principle</h2><p>抽象不应该依赖于细节，细节应该依赖于抽象</p><blockquote><p>针对接口编程，而不是针对实现编程。</p></blockquote><p>在程序代码中传递参数时或者在关联关系中，尽量引用层次高的抽象层类，即，使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。</p><p>为了确保该原则的应用，<strong><em>一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。</em></strong></p><p>在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：</p><ul><li>构造注入</li></ul><p>构造注入是指通过构造函数来传入具体类的对象</p><ul><li>设值注入（Setter注入）</li></ul><p>设值注入是指通过Setter方法来传入具体类的对象</p><ul><li>接口注入</li></ul><p>而接口注入是指通过在接口中声明的业务方法来传入具体类的对象。</p><p><strong>这些方法在定义时使用的是抽象类型，在运行时再传入具体类型的对象，由子类对象来覆盖父类对象。</strong></p><p>加了一个抽象的DataConvertor，面向它来进行编程，然后在Config里面定义到底需要哪一个Convertor的具体实现类</p><p><img src="https://i.loli.net/2020/02/03/n4DwgFpP91Ua2vX.jpg" alt="依赖倒转1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/vq8aUZGpfMWhiAN.jpg" alt="依赖倒转2.jpg"></p><h2 id="2-5-接口隔离原则-Interface-Segragation-Principle"><a href="#2-5-接口隔离原则-Interface-Segragation-Principle" class="headerlink" title="2.5 接口隔离原则 Interface Segragation Principle"></a>2.5 接口隔离原则 Interface Segragation Principle</h2><p>使用多个专门接口，而不使用单一的总接口。即客户端不应该依赖那些它不需要的接口。</p><p><strong><em>每个接口应该承担一种相对独立的角色</em></strong> </p><p>尽量提供窄接口，根据不同的职责分别放在不同的小接口当中</p><p> 在使用接口隔离原则时，我们需要注意控制接口的粒度，接口不能太小，如果太小会导致系统中接口泛滥，不利于维护；接口也不能太大，太大的接口将违背接口隔离原则，灵活性较差，使用起来很不方便。一般而言，接口中仅包含为某一类用户定制的方法即可，不应该强迫客户依赖于那些它们不用的方法。</p><p><img src="https://i.loli.net/2020/02/03/aEnKRgm2THM8L6c.jpg" alt="接口隔离1.jpg"><br><img src="https://i.loli.net/2020/02/03/K1iNF5jB2aGHoVc.jpg" alt="接口隔离2.jpg"></p><h2 id="2-6-合成复用原则-Composite-Reuse-Principle"><a href="#2-6-合成复用原则-Composite-Reuse-Principle" class="headerlink" title="2.6 合成复用原则 Composite Reuse Principle"></a>2.6 合成复用原则 Composite Reuse Principle</h2><p>尽量使用对象组合，而不是继承来达到复用的目的</p><p>在一个新的对象里，通过关联关系（组合关系和聚合关系）来使用一些已有对象，使之成为新对象的一部分。新对象通过委派调用已有对象的方法达到复用功能的目的。</p><blockquote><p>先考虑组合，再考虑继承</p></blockquote><p>组合/聚合可以使系统更加灵活，降低类与类之间的耦合度，一个类的变化对其他类造成的影响相对较少；其次才考虑继承，在使用继承时，需要严格遵循里氏代换原则，有效使用继承会有助于对问题的理解，降低复杂度，而滥用继承反而会增加系统构建和维护的难度以及系统的复杂度，因此需要慎重使用继承复用</p><p>继承复用会破坏系统的封装性，因为继承会将基类的实现细节暴露给子类——&gt; <strong>白箱复用</strong>。如果基类发生改变，子类的实现也必须改变。这样子做没有足够的灵活性。</p><p>组合或者聚合关系是将已有对象纳入到新对象当中，使之成为新对象的一部分。新对象可以调用已有对象的功能，但是具体实现是对其不可见的。合成复用可以在运行时动态进行，新对象可以动态的引用与成员对象类型相同的其他对象。</p><blockquote><p>对于”Has A”关系，使用合成复用，对于”Is A”关系，使用继承</p></blockquote><p><img src="https://i.loli.net/2020/02/03/iQuJD2VyKEzNB8P.jpg" alt="合成复用1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/HUb5O1qjXk7BYKu.jpg" alt="合成复用2.jpg"></p><h2 id="2-7-迪米特法则-Law-of-Demeter"><a href="#2-7-迪米特法则-Law-of-Demeter" class="headerlink" title="2.7 迪米特法则 Law of Demeter"></a>2.7 迪米特法则 Law of Demeter</h2><p>一个软件实体应当尽可能少地与其他实体发生相互作用，这是对软件实体之间通信的限制。</p><p>当其中一个模块发生修改时，会尽量少地影响其他模块，扩展会相对容易。</p><p>只与直接的朋友通信，包括：</p><ol><li>当前对象本身</li><li>以参数形式传入到当前对象方法中的对象</li><li>当前对象的成员对象</li><li>当前对象所创建的对象</li></ol><p>如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。</p><p>！！！ 通过引入中间件来降低整体的耦合度</p><p><img src="https://i.loli.net/2020/02/03/6CxEVeahFjcQ9AN.jpg" alt="迪米特1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/KHX1vnuDbTewQaY.jpg" alt="迪米特2.jpg"></p><h1 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3. Reference"></a>3. Reference</h1><p><a href="https://blog.csdn.net/lovelion/article/details/7536532" target="_blank" rel="noopener">LiuWei’s CSDN</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-概述&quot;&gt;&lt;a href=&quot;#1-概述&quot; class=&quot;headerlink&quot; title=&quot;1. 概述&quot;&gt;&lt;/a&gt;1. 概述&lt;/h1&gt;&lt;p&gt;支持可维护性，提高系统的可复用性&lt;/p&gt;
&lt;h1 id=&quot;2-设计原则&quot;&gt;&lt;a href=&quot;#2-设计原则&quot; class
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/tags/System-Design/"/>
    
  </entry>
  
  <entry>
    <title>混沌工程</title>
    <link href="https://www.llchen60.com/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/"/>
    <id>https://www.llchen60.com/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/</id>
    <published>2020-02-02T22:01:23.000Z</published>
    <updated>2020-02-02T22:02:05.692Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-微服务架构的挑战"><a href="#1-微服务架构的挑战" class="headerlink" title="1. 微服务架构的挑战"></a>1. 微服务架构的挑战</h1><p>当前的趋势就是微服务架构，将原有系统拆分为更加灵活、有业务边界、上下文、松散耦合、可独立部署的服务来应对快速变化的消费市场。</p><p>通常情况下，对于复杂业务或遗留系统，我们可以通过领域驱动设计(DDD:Domain-Driven Design)有效的解决限界上下文划分、服务边界定义以及组织结构调整等问题。除了这些，我们的开发团队还面临着其他的挑战：复杂的分布式系统、数据一致性、容错设计、限流设计、舱壁设计等问题。那么如此复杂的系统如何来保证系统“质量”呢？</p><p>长久以来，“测试金字塔”都是敏捷开发团队保证项目交付质量的守则，而“测试金字塔”也确实从不同的维度涵盖了方法调用、业务逻辑、用户行为等方面。</p><p>End2End test -&gt; API test -&gt; Unit test</p><p>除此以外，我们可以利用契约测试来保证调用方与提供方的一致性，然而七月测试只能覆盖到业务逻辑的维度，需要更深入的了解微服务特性以期更好的开发与改造。</p><p>譬如微服务系统的客户端负载均衡、微服务容错保护、API服务网关、分布式链路跟踪就无法被契约测试测试。</p><p>既然我们没有办法避免灾难的发生，最好的办法就是“探索系统故障边界，验证系统灾难恢复能力”。以往的“机房”时代的一些故障演练一般通过断网、断电模拟单点故障，来测试系统的恢复能力，而新型的分布式服务时代消除了单点故障，但也引入了更多复杂的问题，我们需要可靠性更强、容错性和扩容性更高的系统。一种解决方案就是，我们需要一种有策略的、有方法的实践方案对系统进行一定程度的“随机破坏”，通过让系统”感染“，来提升系统的”免疫力“。</p><h1 id="2-混沌工程"><a href="#2-混沌工程" class="headerlink" title="2. 混沌工程"></a>2. 混沌工程</h1><p>混沌工程是一种可试验的、基于系统的方法来处理大规模分布式系统中的混乱问题。通过不断试验，了解系统的实际能承受的韧性边界并建立信心，通过不同的试验方法和目的，观察分布式系统的行为和反应。一句话——以试验的方法尽早揭露系统弱点。</p><p>混沌工程类似于“故障演练”，不局限于测试，而更像是工程实践。为什么这么说，通常的测试用例会有“期望结果”和“实际结果”，通过将两个结果比较，或者对用户行为的预期，来判断测试通过或失败。而混沌试验类似于”<strong>探索性测试</strong>“，试验本身没有明确是输入和预期结果，通过对系统和服务的干预，来观察系统的”反应“。我们将混沌工程原则融入在试验过程中：在生产环境小规模模拟系统故障并定期自动化执行试验，通过试验结果与正常结果进行比对，观察系统”边界“。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://insights.thoughtworks.cn/microservice-architecture-chaotic-engineering/#utm_source=rss&amp;utm_medium=rss" target="_blank" rel="noopener">https://insights.thoughtworks.cn/microservice-architecture-chaotic-engineering/#utm_source=rss&amp;utm_medium=rss</a>   </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-微服务架构的挑战&quot;&gt;&lt;a href=&quot;#1-微服务架构的挑战&quot; class=&quot;headerlink&quot; title=&quot;1. 微服务架构的挑战&quot;&gt;&lt;/a&gt;1. 微服务架构的挑战&lt;/h1&gt;&lt;p&gt;当前的趋势就是微服务架构，将原有系统拆分为更加灵活、有业务边界、上下文、
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/tags/BackEnd/"/>
    
      <category term="混沌工程" scheme="https://www.llchen60.com/tags/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>IOC容器和Dependency Injection模式</title>
    <link href="https://www.llchen60.com/IOC%E5%AE%B9%E5%99%A8%E5%92%8CDependency-Injection%E6%A8%A1%E5%BC%8F/"/>
    <id>https://www.llchen60.com/IOC%E5%AE%B9%E5%99%A8%E5%92%8CDependency-Injection%E6%A8%A1%E5%BC%8F/</id>
    <published>2020-02-02T21:59:46.000Z</published>
    <updated>2020-02-02T22:00:54.797Z</updated>
    
    <content type="html"><![CDATA[<p>Martin Fowler的文章，在文中深入探索控制反转的的工作原理，给它一个更能描述其特点的名字——”依赖注入”（Dependency Injection），并将其与”服务定位器”（Service Locator）模式作一个比较。探讨了异同。最最重要的，也是每个程序员都应该注意的是：应该将服务的配置和应用程序内部对服务的使用分离开。这也是控制反转以及服务定位器一直在做的。</p><h1 id="1-问题"><a href="#1-问题" class="headerlink" title="1. 问题"></a>1. 问题</h1><p>J2EE开发者常遇到的一个问题就是<strong><em>如何组装不同的程序元素</em></strong>：如果web控制器体系结构和数据库接口是由不同的团队所开发的，彼此几乎一无所知，你应该如何让它们配合工作？很多框架尝试过解决这个问题，有几个框架索性朝这个方向发展，提供了更通用的”组装各层组件”的方案。这样的框架通常被称为”轻量级容器”，PicoContainer和Spring都在此列中。</p><h2 id="2-实例"><a href="#2-实例" class="headerlink" title="2.实例"></a>2.实例</h2><p>有一个提供一份电影清单的组件，清单上列出有一位特定导演执导的影片</p><pre><code>class MovieLister...public Movie[] moviesDirectedBy(String arg){    List allMovies = finder.findAll();    for (Iterator it = allMovies.iterator(); it.hasNext();)    {        Movie movie = (Movie) it.next();        if (!movie.getDirector().equals(arg))        {            it.remove();        }    }    return (Movie[]) allMovies.toArray(new Movie[allMovies.size()]);}</code></pre><p>这个功能的实现极其简单：moviesDirectedBy方法首先请求finder（影片搜寻者）对象（我们稍后会谈到这个对象）返回后者所知道的所有影片，然后遍历finder对象返回的清单，并返回其中由特定的某个导演执导的影片。非常简单，不过不必担心，这只是整个例子的脚手架罢了。<strong><em>我们真正想要考察的是finder对象，或者说，如何将MovieLister对象与特定的finder对象连接起来</em></strong>。为什么我们对这个问题特别感兴趣？因为<strong><em>我希望上面这个漂亮的moviesDirectedBy方法完全不依赖于影片的实际存储方式。</em></strong>所以，这个方法只能引用一个finder对象，而finder对象则必须知道如何对findAll 方法作出回应。为了帮助读者更清楚地理解，我给finder定义了一个接口：</p><pre><code>public interface MovieFinder{    List findAll();}</code></pre><p>现在，两个对象之间没有什么耦合关系。但是，当我要实际寻找影片时，就必须涉及到MovieFinder的某个具体子类。在这里，<em>我把涉及具体子类的代码放在MovieLister类的构造函数中</em>。</p><pre><code>class MovieLister...private MovieFinder finder;public MovieLister(){    finder = new ColonDelimitedMovieFinder(&quot;movies1.txt&quot;);}</code></pre><p>这个实现类的名字就说明：我将要从一个逗号分隔的文本文件中获得影片列表。你不必操心具体的实现细节，只要设想这样一个实现类就可以了。如果这个类只由我自己使用，一切都没问题。但是，如果我的朋友叹服于这个精彩的功能，也想使用我的程序，那又会怎么样呢？如果他们也把影片清单保存在一个逗号分隔的文本文件中，并且也把这个文件命名为” movie1.txt “，那么一切还是没问题。如果他们只是给这个文件改改名，我也可以从一个配置文件获得文件名，这也很容易。<strong>但是，如果他们用完全不同的方式——例如SQL 数据库、XML 文件、web service，或者另一种格式的文本文件——来存储影片清单呢？</strong>在这种情况下，我们需要用另一个类来获取数据。由于已经定义了MovieFinder接口，我可以不用修改moviesDirectedBy方法。但是，我<strong><em>仍然需要通过某种途径获得合适的MovieFinder实现类的实例</em></strong>。</p><p><img src="https://i.loli.net/2020/02/03/B2Nf9MX6VIL4oKP.gif" alt="figure1.gif"></p><p>MovieLister类既依赖于MovieFinder接口，也依赖于具体的实现类。我们当然希望MovieLister类只依赖于接口，但我们要如何获得一个MovieFinder子类的实例呢？</p><p>在Patterns of Enterprise Application Architecture一书中，我们把这种情况称为<strong>插件（plugin）</strong>：MovieFinder的实现类<strong>不是在编译期连入程序之中的</strong>，因为我并不知道我的朋友会使用哪个实现类。我们希望MovieLister类能够与MovieFinder的任何实现类配合工作，并且允许<strong>在运行期插入具体的实现类</strong>，插入动作完全脱离我（原作者）的控制。这里的问题就是：<strong>如何设计这个连接过程，使MovieLister类在不知道实现类细节的前提下与其实例协同工作。</strong></p><p>将这个例子推而广之，在一个真实的系统中，我们可能有数十个服务和组件。在任何时候，我们总可以对使用组件的情形加以抽象，<strong>通过接口与具体的组件交流</strong>（如果组件并没有设计一个接口，也可以通过适配器与之交流）。但是，如果我们希望以不同的方式部署这个系统，就需要用插件机制来处理服务之间的交互过程，这样我们才可能在不同的部署方案中使用不同的实现。所以，现在的核心问题就是：<strong>如何将这些插件组合成一个应用程序？这正是新生的轻量级容器所面临的主要问题，而它们解决这个问题的手段无一例外地是控制反转（Inversion of Control）模式</strong>。</p><h1 id="3-控制反转"><a href="#3-控制反转" class="headerlink" title="3. 控制反转"></a>3. 控制反转</h1><p>几位轻量级容器的作者曾骄傲地对我说：这些容器非常有用，因为它们实现了控制反转。这样的说辞让我深感迷惑：控制反转是框架所共有的特征，如果仅仅因为使用了控制反转就认为这些轻量级容器与众不同，就好象在说我的轿车是与众不同的，因为它有四个轮子。</p><p>问题的关键在于：它们反转了哪方面的控制？我第一次接触到的控制反转针对的是用户界面的主控权。早期的用户界面是完全由应用程序来控制的，你预先设计一系列命令，例如输入姓名、输入地址等，应用程序逐条输出提示信息，并取回用户的响应。而在图形用户界面环境下，UI框架将负责执行一个主循环，你的应用程序只需为屏幕的各个区域提供事件处理函数即可。在这里，程序的主控权发生了反转：从应用程序移到了框架。对于这些新生的容器，它们反转的是如何定位插件的具体实现。在前面那个简单的例子中，MovieLister类负责定位MovieFinder的具体实现——它直接实例化后者的一个子类。这样一来，MovieFinder也就不成其为一个插件了，因为它并不是在运行期插入应用程序中的。而这些轻量级容器则使用了更为灵活的办法，<strong>只要插件遵循一定的规则，一个独立的组装模块就能够将插件的具体实现注射到应用程序中。</strong>因此，我想我们需要给这个模式起一个更能说明其特点的名字——”控制反转”这个名字太泛了，常常让人有些迷惑。与多位IoC 爱好者讨论之后，我们决定将这个模式叫做”依赖注入”（Dependency Injection）。</p><p>下面，我将开始介绍Dependency Injection模式的几种不同形式。不过，在此之前，我要首先指出：要消除应用程序对插件实现的依赖，依赖注入并不是唯一的选择，你也可以用ServiceLocator模式获得同样的效果。介绍完Dependency Injection模式之后，我也会谈到ServiceLocator 模式。</p><h2 id="3-1-依赖注入的几种形式"><a href="#3-1-依赖注入的几种形式" class="headerlink" title="3.1 依赖注入的几种形式"></a>3.1 依赖注入的几种形式</h2><p>Dependency Injection模式的基本思想是：用一个单独的对象（装配器）来获得MovieFinder的一个合适的实现，并将其实例赋给MovieLister类的一个字段。这样一来，我们就得到了图2所示的依赖图：</p><p><img src="https://i.loli.net/2020/02/03/wySa8WINcA2Xp49.gif" alt="figure2.gif"></p><h3 id="3-1-1-构造函数注入"><a href="#3-1-1-构造函数注入" class="headerlink" title="3.1.1 构造函数注入"></a>3.1.1 构造函数注入</h3><p>这里使用PicoContainer，一个轻量级容器来完成依赖注入。</p><p>PicoContainer通过构造函数来判断如何将MovieFinder实例注入MovieLister 类。因此，MovieLister类必须声明一个构造函数，并在其中包含所有需要注入的元素：</p><pre><code>class MovieLister...    public MovieLister(MovieFinder finder)    {        this.finder = finder;    }</code></pre><p>MovieFinder实例本身也将由PicoContainer来管理，因此文本文件的名字也可以由容器注入：</p><pre><code>class ColonMovieFinder...    public ColonMovieFinder(String filename)    {        this.filename = filename;    }</code></pre><p>随后，需要告诉PicoContainer：各个接口分别与哪个实现类关联、将哪个字符串注入MovieFinder组件。</p><pre><code>private MutablePicoContainer configureContainer(){    MutablePicoContainer pico = new DefaultPicoContainer();    Parameter[] finderParams = {newConstantParameter(&quot;movies1.txt&quot;)};    pico.registerComponentImplementation(MovieFinder.class,ColonMovieFinder.class, finderParams);    pico.registerComponentImplementation(MovieLister.class);    return pico;}</code></pre><p>这段配置代码通常位于另一个类。对于我们这个例子，使用我的MovieLister 类的朋友需要在自己的设置类中编写合适的配置代码。当然，还可以将这些配置信息放在一个单独的配置文件中，这也是一种常见的做法。你可以编写一个类来读取配置文件，然后对容器进行合适的设置。尽管PicoContainer本身并不包含这项功能，但另一个与它关系紧密的项目NanoContainer提供了一些包装，允许开发者使用XML配置文件保存配置信息。NanoContainer能够解析XML文件，并对底下的PicoContainer进行配置。这个项目的哲学观念就是：将配置文件的格式与底下的配置机制分离开。</p><pre><code>public void testWithPico(){    MutablePicoContainer pico = configureContainer();    MovieLister lister = (MovieLister)pico.getComponentInstance(MovieLister.class);    Movie[] movies = lister.moviesDirectedBy(&quot;Sergio Leone&quot;);    assertEquals(&quot;Once Upon a Time in the West&quot;,movies[0].getTitle());}</code></pre><h3 id="3-1-2-设值方法注入"><a href="#3-1-2-设值方法注入" class="headerlink" title="3.1.2 设值方法注入"></a>3.1.2 设值方法注入</h3><p>Spring 框架是一个用途广泛的企业级Java 开发框架，其中包括了针对事务、持久化框架、web应用开发和JDBC等常用功能的抽象。和PicoContainer一样，它也同时支持构造函数注入和设值方法注入，但该项目的开发者更推荐使用设值方法注入——恰好适合这个例子。为了让MovieLister类接受注入，我需要为它定义一个设值方法，该方法接受类型为MovieFinder的参数：</p><pre><code>class MovieLister...private MovieFinder finder;public void setFinder(MovieFinder finder){    this.finder = finder;}</code></pre><p>类似地，在MovieFinder的实现类中，我也定义了一个设值方法，接受类型为String 的参数：</p><pre><code>class ColonMovieFinder...    public void setFilename(String filename)    {        this.filename = filename;    }</code></pre><p>第三步是设定配置文件。Spring 支持多种配置方式，你可以通过XML 文件进行配置，也可以直接在代码中配置。不过，XML 文件是比较理想的配置方式。</p><pre><code>&lt;beans&gt;    &lt;bean id=&quot;MovieLister&quot; class=&quot;spring.MovieLister&quot;&gt;        &lt;property name=&quot;finder&quot;&gt;            &lt;ref local=&quot;MovieFinder&quot;/&gt;        &lt;/property&gt;    &lt;/bean&gt;    &lt;bean id=&quot;MovieFinder&quot; class=&quot;spring.ColonMovieFinder&quot;&gt;        &lt;property name=&quot;filename&quot;&gt;            &lt;value&gt;movies1.txt&lt;/value&gt;        &lt;/property&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>测试代码：</p><pre><code>public void testWithSpring() throws Exception{    ApplicationContext ctx = newFileSystemXmlApplicationContext(&quot;spring.xml&quot;);    MovieLister lister = (MovieLister) ctx.getBean(&quot;MovieLister&quot;);    Movie[] movies = lister.moviesDirectedBy(&quot;Sergio Leone&quot;);    assertEquals(&quot;Once Upon a Time in the West&quot;,movies[0].getTitle());}</code></pre><h3 id="3-1-3-接口注入"><a href="#3-1-3-接口注入" class="headerlink" title="3.1.3 接口注入"></a>3.1.3 接口注入</h3><p>除了前面两种注入技术，还可以在接口中定义需要注入的信息，并通过接口完成注入。Avalon框架就使用了类似的技术。在这里，我首先用简单的范例代码说明它的用法，后面还会有更深入的讨论。首先，我需要定义一个接口，<strong>组件的注入将通过这个接口进行</strong>。在本例中，这个接口的用途是将一个MovieFinder实例注入继承了该接口的对象。</p><pre><code>public interface InjectFinder{    void injectFinder(MovieFinder finder);}</code></pre><p>这个接口应该由提供MovieFinder接口的人一并提供。任何想要使用MovieFinder实例的类（例如MovieLister类）都必须实现这个接口。</p><pre><code>class MovieLister implements InjectFinder...    public void injectFinder(MovieFinder finder)    {        this.finder = finder;    }</code></pre><p>然后，我使用类似的方法将文件名注入MovieFinder的实现类：</p><pre><code>public interface InjectFilename{    void injectFilename (String filename);}class ColonMovieFinder implements MovieFinder, InjectFilename...    public void injectFilename(String filename)    {        this.filename = filename;    }</code></pre><p>现在，还需要用一些配置代码将所有的组件实现装配起来。简单起见，我直接在代码中完成配置，并将配置好的MovieLister 对象保存在名为lister的字段中：</p><pre><code>class IfaceTester...    private MovieLister lister;    private void configureLister()    {        ColonMovieFinder finder = new ColonMovieFinder();        finder.injectFilename(&quot;movies1.txt&quot;);        lister = new MovieLister();        lister.injectFinder(finder);    }</code></pre><p>测试代码：</p><pre><code>class IfaceTester...public void testIface(){    configureLister();    Movie[] movies = lister.moviesDirectedBy(&quot;Sergio Leone&quot;);    assertEquals(&quot;Once Upon a Time in the West&quot;,movies[0].getTitle());}</code></pre><h2 id="3-2-构造函数注入-vs-设值方法注入"><a href="#3-2-构造函数注入-vs-设值方法注入" class="headerlink" title="3.2 构造函数注入 vs. 设值方法注入"></a>3.2 构造函数注入 vs. 设值方法注入</h2><p>在组合服务时，你总得遵循一定的约定，才可能将所有东西拼装起来。<strong>依赖注入的优点主要在于：它只需要非常简单的约定——至少对于构造函数注入和设值方法注入来说是这样</strong>。相比于这两者，接口注入的侵略性要强得多，比起Service Locator模式的优势也不那么明显。所以，如果你想要提供一个组件给多个使用者，构造函数注入和设值方法注入看起来很有吸引力。你不必在组件中加入什么希奇古怪的东西，注入器可以相当轻松地把所有东西配置起来。</p><p>设值函数注入和构造函数注入之间的选择相当有趣，因为它折射出面向对象编程的一些更普遍的问题：应该在哪里填充对象的字段，构造函数还是设值方法？</p><p>一直以来，我首选的做法是尽量在构造阶段就创建完整、合法的对象——也就是说，在构造函数中填充对象字段。这样做的好处可以追溯到Kent Beck在Smalltalk Best Practice Patterns一书中介绍的两个模式：Constructor Method和Constructor Parameter Method。带有参数的构造函数可以明确地告诉你如何创建一个合法的对象。如果创建合法对象的方式不止一种，你还可以提供多个构造函数，以说明不同的组合方式。</p><p>构造函数初始化的另一个好处是：你可以隐藏任何不可变的字段——只要不为它提供设值方法就行了。我认为这很重要：如果某个字段是不应该被改变的，没有针对该字段的设值方法就很清楚地说明了这一点。如果你通过设值方法完成初始化，暴露出来的设值方法很可能成为你心头永远的痛。（实际上，在这种时候我更愿意回避通常的设值方法约定，而是使用诸如initFoo之类的方法名，以表明该方法只应该在对象创建之初调用。）</p><p>不过，世事总有例外。如果参数太多，构造函数会显得凌乱不堪，特别是对于不支持关键字参数的语言更是如此。的确，如果构造函数参数列表太长，通常标志着对象太过繁忙，理应将其拆分成几个对象，但有些时候也确实需要那么多的参数。如果有不止一种的方式可以构造一个合法的对象，也很难通过构造函数描述这一信息，因为构造函数之间只能通过参数的个数和类型加以区分。这就是Factory Method模式适用的场合了，工厂方法<strong>可以借助多个私有构造函数和设值方法的组合来完成自己的任务</strong>。经典Factory Method模式的问题在于：它们往往以静态方法的形式出现，你无法在接口中声明它们。你可以创建一个工厂类，但那又变成另一个服务实体了。工厂服务是一种不错的技巧，但你仍然需要以某种方式实例化这个工厂对象，问题仍然没有解决。</p><p>如果要传入的参数是像字符串这样的简单类型，构造函数注入也会带来一些麻烦。使用设值方法注入时，你可以在每个设值方法的名字中说明参数的用途；而使用构造函数注入时，你只能靠参数的位置来决定每个参数的作用，而记住参数的正确位置显然要困难得多。</p><p>如果对象有多个构造函数，对象之间又存在继承关系，事情就会变得特别讨厌。为了让所有东西都正确地初始化，你必须将对子类构造函数的调用转发给超类的构造函数，然后处理自己的参数。这可能造成构造函数规模的进一步膨胀。</p><p>尽管有这些缺陷，但我仍然建议你首先考虑构造函数注入。不过，一旦前面提到的问题真的成了问题，你就应该准备转为使用设值方法注入。</p><h2 id="3-3-代码配置-vs-配置文件"><a href="#3-3-代码配置-vs-配置文件" class="headerlink" title="3.3 代码配置 vs 配置文件"></a>3.3 代码配置 vs 配置文件</h2><p>另一个问题相对独立，但也经常与其他问题牵涉在一起：如何配置服务的组装，通过配置文件还是直接编码组装？对于大多数需要在多处部署的应用程序来说，一个单独的配置文件会更合适。配置文件几乎都是XML 文件，XML 也的确很适合这一用途。不过，有些时候直接在程序代码中实现装配会更简单。譬如一个简单的应用程序，也没有很多部署上的变化，这时用几句代码来配置就比XML 文件要清晰得多。</p><p>与之相对的，有时应用程序的组装非常复杂，涉及大量的条件步骤。一旦编程语言中的配置逻辑开始变得复杂，你就应该用一种合适的语言来描述配置信息，使程序逻辑变得更清晰。然后，<strong>你可以编写一个构造器（builder）类来完成装配工作</strong>。如果使用构造器的情景不止一种，你可以提供多个构造器类，然后通过一个简单的配置文件在它们之间选择。</p><p>我常常发现，人们太急于定义配置文件。编程语言通常会提供简捷而强大的配置管理机制，现代编程语言也可以将程序编译成小的模块，并将其插入大型系统中。如果编译过程会很费力，脚本语言也可以在这方面提供帮助。通常认为，配置文件不应该用编程语言来编写，因为它们需要能够被不懂编程的系统管理人员编辑。但是，这种情况出现的几率有多大呢？我们真的希望不懂编程的系统管理人员来改变一个复杂的服务器端应用程序的事务隔离等级吗？只有在非常简单的时候，非编程语言的配置文件才有最好的效果。如果配置信息开始变得复杂，就应该考虑选择一种合适的编程语言来编写配置文件。</p><p>在Java 世界里，我们听到了来自配置文件的不和谐音——每个组件都有它自己的配置文件，而且格式还各不相同。如果你要使用一打这样的组件，你就得维护一打的配置文件，那会很快让你烦死。</p><p>在这里，我的建议是：始终提供一种标准的配置方式，使程序员能够通过同一个编程接口轻松地完成配置工作。至于其他的配置文件，仅仅把它们当作一种可选的功能。借助这个编程接口，开发者可以轻松地管理配置文件。如果你编写了一个组件，则可以由组件的使用者来选择如何管理配置信息：使用你的编程接口、直接操作配置文件格式，或者定义他们自己的配置文件格式，并将其与你的编程接口相结合。</p><h2 id="3-4-分离配置和使用"><a href="#3-4-分离配置和使用" class="headerlink" title="3.4 分离配置和使用"></a>3.4 分离配置和使用</h2><p>所有这一切的关键在于：<strong><em>服务的配置应该与使用分开</em></strong>。实际上，这是一个基本的设计原则——分离接口与实现。在面向对象程序里，我们在一个地方用条件逻辑来决定具体实例化哪一个类，以后的条件分支都由多态来实现，而不是继续重复前面的条件逻辑，这就是分离接口与实现的原则。</p><p>如果对于一段代码而言，接口与实现的分离还只是有用的话，那么当你需要使用外部元素（例如组件和服务）时，它就是生死攸关的大事。这里的第一个问题是：你是否希望将选择具体实现类的决策推迟到部署阶段。如果是，那么你需要使用插入技术。使用了插入技术之后，插件的装配原则上是与应用程序的其余部分分开的，这样你就可以轻松地针对不同的部署替换不同的配置。这种配置机制可以通过服务定位器来实现（Service Locator模式），也可以借助依赖注入直接完成（Dependency Injection 模式）。</p><h1 id="4-结论与思考"><a href="#4-结论与思考" class="headerlink" title="4. 结论与思考"></a>4. 结论与思考</h1><p>在时下流行的轻量级容器都使用了一个共同的模式来组装应用程序所需的服务，我把这个模式称为Dependency Injection，它可以有效地替代Service Locator模式。在开发应用程序时，两者不相上下，但我认为Service Locator模式略有优势，因为它的行为方式更为直观。但是，如果你开发的组件要交给多个应用程序去使用，那么Dependency Injection模式会是更好的选择。</p><p>如果你决定使用Dependency Injection模式，这里还有几种不同的风格可供选择。我建议你首先考虑构造函数注入；如果遇到了某些特定的问题，再改用设值方法注入。如果你要选择一个容器，在其之上进行开发，我建议你选择同时支持这两种注入方式的容器。</p><p>Service Locator 模式和Dependency Injection 模式之间的选择并是最重要的，更重要的是：应该将服务的配置和应用程序内部对服务的使用分离开。</p><p><a href="https://martinfowler.com/articles/injection.html" target="_blank" rel="noopener">1.[Inversion of Control Containers and the Dependency Injection pattern]</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Martin Fowler的文章，在文中深入探索控制反转的的工作原理，给它一个更能描述其特点的名字——”依赖注入”（Dependency Injection），并将其与”服务定位器”（Service Locator）模式作一个比较。探讨了异同。最最重要的，也是每个程序员都应
      
    
    </summary>
    
    
      <category term="BackEnd" scheme="https://www.llchen60.com/categories/BackEnd/"/>
    
    
      <category term="Java" scheme="https://www.llchen60.com/tags/Java/"/>
    
      <category term="BackEnd" scheme="https://www.llchen60.com/tags/BackEnd/"/>
    
      <category term="IOC" scheme="https://www.llchen60.com/tags/IOC/"/>
    
      <category term="Dependency Injection" scheme="https://www.llchen60.com/tags/Dependency-Injection/"/>
    
  </entry>
  
  <entry>
    <title>UML - Class Diagram</title>
    <link href="https://www.llchen60.com/UML-Class-Diagram/"/>
    <id>https://www.llchen60.com/UML-Class-Diagram/</id>
    <published>2020-02-02T21:57:47.000Z</published>
    <updated>2020-02-02T21:58:37.744Z</updated>
    
    <content type="html"><![CDATA[<p>Alright, some basic knowledge collecting from wiki, uml tutorial websites. Merely regrad this blog as a reference, when you creating/ reading some class disgram, you might wanna look at the blog for better understanding. </p><h1 id="1-Visibility"><a href="#1-Visibility" class="headerlink" title="1. Visibility"></a>1. Visibility</h1><ul><li>+ public </li><li>- private </li><li># protected </li><li>~ package </li></ul><h1 id="2-Relationships"><a href="#2-Relationships" class="headerlink" title="2. Relationships"></a>2. Relationships</h1><p>Types of logical connections found on class and object diagrams. </p><p><img src="https://i.loli.net/2020/02/03/EHNIMsw3hv142yd.png" alt="fig1.png"></p><h2 id="2-1-Dependency"><a href="#2-1-Dependency" class="headerlink" title="2.1 Dependency"></a>2.1 Dependency</h2><p>A sementic connection between dependent and independent model elements. </p><h2 id="2-2-Association"><a href="#2-2-Association" class="headerlink" title="2.2 Association"></a>2.2 Association</h2><p>A binary association </p><h2 id="2-3-Aggregation"><a href="#2-3-Aggregation" class="headerlink" title="2.3 Aggregation"></a>2.3 Aggregation</h2><p>Has a assocation relationship </p><h2 id="2-4-Compostion"><a href="#2-4-Compostion" class="headerlink" title="2.4 Compostion"></a>2.4 Compostion</h2><p>Has a, and without parent, child will not exist </p><h2 id="2-5-Inheritance"><a href="#2-5-Inheritance" class="headerlink" title="2.5 Inheritance"></a>2.5 Inheritance</h2><h2 id="2-6-Realization-Implementation"><a href="#2-6-Realization-Implementation" class="headerlink" title="2.6 Realization/ Implementation"></a>2.6 Realization/ Implementation</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/Class_diagram" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Class_diagram</a></li><li><a href="https://design-patterns.readthedocs.io/zh_CN/latest/read_uml.html" target="_blank" rel="noopener">https://design-patterns.readthedocs.io/zh_CN/latest/read_uml.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Alright, some basic knowledge collecting from wiki, uml tutorial websites. Merely regrad this blog as a reference, when you creating/ rea
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/tags/System-Design/"/>
    
      <category term="UML" scheme="https://www.llchen60.com/tags/UML/"/>
    
  </entry>
  
  <entry>
    <title>Event Storming</title>
    <link href="https://www.llchen60.com/Event-Storming/"/>
    <id>https://www.llchen60.com/Event-Storming/</id>
    <published>2020-02-02T21:56:24.000Z</published>
    <updated>2020-02-02T21:57:04.636Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-什么是事件风暴？"><a href="#1-什么是事件风暴？" class="headerlink" title="1. 什么是事件风暴？"></a>1. 什么是事件风暴？</h1><p>通过便签而不是代码来理解你的整个系统，并不断革新你的商业逻辑和需求。</p><p>构建一个能够对事件及时作出反应的系统</p><p>事件风暴是一种组织架构的方法，他是在讨论事件在你的组织里的流动，并将其用一种易于理解的方式模型化。</p><p>实质上想做的事情是通过交流，能够更加迅速的了解到在这个简单事情的背后都发生了什么，了解到数据/信息究竟是如何在多个系统间进行流动的。</p><p>想达到的目标就是通过便签纸在白板上展现出在每个步骤当中想要做的事情，这样能更好的理解商业需求，不需要太过于关注技术细节。</p><h1 id="2-关键的几个概念"><a href="#2-关键的几个概念" class="headerlink" title="2. 关键的几个概念"></a>2. 关键的几个概念</h1><h2 id="2-1-Events-and-Reactions"><a href="#2-1-Events-and-Reactions" class="headerlink" title="2.1 Events and Reactions"></a>2.1 Events and Reactions</h2><p>可以简化为因果关系，或者说是起因及其影响。重要的事件会在系统当中引发一些影响，我们需要理解为什么这些反应会发生，以及其是怎么样发生的。</p><h2 id="2-2-事件流"><a href="#2-2-事件流" class="headerlink" title="2.2 事件流"></a>2.2 事件流</h2><p>单独的事件没有什么太大的影响，我们需要考虑的是事件流，即事件在一段时间内的变化。我们要做的实际上就是使用便签纸，从左到右，按照时间顺序，记录下事件的发生。当我们有了这样的一个线性的事件流以后，下一步是去思考事件是因何而发生的。</p><h2 id="2-3-Reactions"><a href="#2-3-Reactions" class="headerlink" title="2.3 Reactions"></a>2.3 Reactions</h2><p>反馈是在其他事件发生以后发生的事件。 – this happens whenever that happens. </p><h2 id="2-4-Policy"><a href="#2-4-Policy" class="headerlink" title="2.4 Policy"></a>2.4 Policy</h2><p>Policy是指事件和其反馈的整体流动。我们称其为policy 是因为这个流动捕捉到了核心的商业逻辑和规则。</p><h2 id="2-5-Commands"><a href="#2-5-Commands" class="headerlink" title="2.5 Commands"></a>2.5 Commands</h2><p>来代表用户的某些行为，这些行为可以触发某些事件的发生，或者说这些行为本身很有可能就是某些事件，而这些事件会触发某些reaction，然后再度触发事件，一以贯之。</p><h1 id="3-背后逻辑"><a href="#3-背后逻辑" class="headerlink" title="3. 背后逻辑"></a>3. 背后逻辑</h1><p>个人感觉这不仅仅是应用在技术架构和模型上，任何商业上的事务，想要明晰商业逻辑，都可以用这一套逻辑链条来进行分析。核心就是用户行为，事件，平台/app 对事件作出的反应，三者形成一个可以循环往复的圈，不停带来新的行为和新的反馈。这是行为环，还有利益环，即每个角色在这整个过程当中交换了什么，获得了什么。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://ziobrando.blogspot.com/2013/11/introducing-event-storming.html" target="_blank" rel="noopener">https://ziobrando.blogspot.com/2013/11/introducing-event-storming.html</a></li><li><a href="https://blog.redelastic.com/corporate-arts-crafts-modelling-reactive-systems-with-event-storming-73c6236f5dd7" target="_blank" rel="noopener">https://blog.redelastic.com/corporate-arts-crafts-modelling-reactive-systems-with-event-storming-73c6236f5dd7</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-什么是事件风暴？&quot;&gt;&lt;a href=&quot;#1-什么是事件风暴？&quot; class=&quot;headerlink&quot; title=&quot;1. 什么是事件风暴？&quot;&gt;&lt;/a&gt;1. 什么是事件风暴？&lt;/h1&gt;&lt;p&gt;通过便签而不是代码来理解你的整个系统，并不断革新你的商业逻辑和需求。&lt;/
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="DDD" scheme="https://www.llchen60.com/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>DDD-领域驱动设计</title>
    <link href="https://www.llchen60.com/DDD-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"/>
    <id>https://www.llchen60.com/DDD-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/</id>
    <published>2020-02-02T16:04:32.000Z</published>
    <updated>2020-02-02T16:08:01.593Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><h2 id="1-1-什么是领域驱动设计"><a href="#1-1-什么是领域驱动设计" class="headerlink" title="1.1 什么是领域驱动设计"></a>1.1 什么是领域驱动设计</h2><p>、】=op90q`</p><blockquote><p>DDD是面向对象的一套方言，提供了一种基于业务领域的对象划分和分类方法，其最大的价值就在于对于软件开发过程全生命周期使用语言的统一。</p></blockquote><h2 id="1-2-常用名词"><a href="#1-2-常用名词" class="headerlink" title="1.2 常用名词"></a>1.2 常用名词</h2><ul><li>Controller </li><li>Service </li><li>Repository </li><li>Entity </li></ul><h2 id="1-3-为什么使用DDD"><a href="#1-3-为什么使用DDD" class="headerlink" title="1.3 为什么使用DDD?"></a>1.3 为什么使用DDD?</h2><p>我们在使用面向对象语言来解决实际问题的时候，知道所有东西都是对象，但我们并没有明确的关于对象应当如何组织和划分的规范。</p><p>作为技术人员，我们习惯于从技术角度来出发进行思考，出现了用<strong>技术语言</strong>定义对象的习惯，例如DAO(Data Access Objects), DTO(Data Transfer Object)这类对象及其体现出来的划分方式。</p><p>但是我们日常工作当中很多时间需要做大量的业务语言和技术语言的相互翻译。DDD - Domain Driven Design 就是想解决这样的相互翻译的问题，希望能通过一套面向对象的分类方法，从领域触发，实现软件开发过程当中各个角色和环境的统一语言(Ubiquitous Language).例如使用Repository（仓库）替代数据访问对象（DAO），就更能让业务和技术同时理解这个对象的作用了。</p><p>DDD分为战术和战略两部分，恰好可以用在微服务的划分当中。我们需要利用DDD的战略部分，划分问题域，来合理对微服务进行划分。</p><h1 id="2-事件风暴-EventStorming"><a href="#2-事件风暴-EventStorming" class="headerlink" title="2. 事件风暴 EventStorming"></a>2. 事件风暴 EventStorming</h1><blockquote><p>是一套独立的通过协作基于事件还原系统全貌，从而快速分析复杂业务领域，完成领域建模的方法。</p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://insights.thoughtworks.cn/ddd-eventstorming-zhongtai/#utm_source=rss&amp;utm_medium=rss" target="_blank" rel="noopener">https://insights.thoughtworks.cn/ddd-eventstorming-zhongtai/#utm_source=rss&amp;utm_medium=rss</a></li><li><a href="https://www.eventstorming.com/#services" target="_blank" rel="noopener">https://www.eventstorming.com/#services</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-Intro&quot;&gt;&lt;a href=&quot;#1-Intro&quot; class=&quot;headerlink&quot; title=&quot;1. Intro&quot;&gt;&lt;/a&gt;1. Intro&lt;/h1&gt;&lt;h2 id=&quot;1-1-什么是领域驱动设计&quot;&gt;&lt;a href=&quot;#1-1-什么是领域驱动设计&quot; cla
      
    
    </summary>
    
    
      <category term="System Design" scheme="https://www.llchen60.com/categories/System-Design/"/>
    
    
      <category term="DDD" scheme="https://www.llchen60.com/tags/DDD/"/>
    
  </entry>
  
  <entry>
    <title>网络协议(十一)-用双十一理顺起来的网络协议</title>
    <link href="https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%8D%81%E4%B8%80-%E7%94%A8%E5%8F%8C%E5%8D%81%E4%B8%80%E7%90%86%E9%A1%BA%E8%B5%B7%E6%9D%A5%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"/>
    <id>https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%8D%81%E4%B8%80-%E7%94%A8%E5%8F%8C%E5%8D%81%E4%B8%80%E7%90%86%E9%A1%BA%E8%B5%B7%E6%9D%A5%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/</id>
    <published>2020-02-02T05:58:42.000Z</published>
    <updated>2020-02-02T06:07:29.953Z</updated>
    
    <content type="html"><![CDATA[<p>本文会尽可能详细描述双十一的技术栈，希望对大家能有所裨益。</p><p>整个过程会分为十个阶段，接下来也会分别从这十个方面进行讲述： </p><ul><li>部署高可用高并发的电商平台</li><li>广播全网</li><li>域名解析</li></ul><h1 id="1-部署高可用高并发的电商平台"><a href="#1-部署高可用高并发的电商平台" class="headerlink" title="1. 部署高可用高并发的电商平台"></a>1. 部署高可用高并发的电商平台</h1><p><img src="https://i.loli.net/2020/02/02/6AuPT1RQZilKpcB.jpg" alt="fig1.jpg"></p><ul><li>主站点</li><li>多机房，多Available zone </li><li>数据中心，一个AZ<ul><li>汇聚交换机 <ul><li>机柜<ul><li>接入交换机 </li><li>服务器</li></ul></li></ul></li></ul></li></ul><p>这些服务器上部署的都是计算节点，每台上面都有Open vSwitch创建的虚拟交换机，将来在这台机器上创建的虚拟机，都会连到Open vSwitch上。</p><p><img src="https://i.loli.net/2020/02/02/JCiMoL1DwbGcqQB.jpg" alt="fig2.jpg"></p><ul><li>创建VPC</li><li>指定IP段<ul><li>这样以后部署的所有应用都会在这个虚拟网络当中，使用你分配的这个IP段</li><li>即使同一台物理机，不同的VPC也不会相通</li><li>多个可用区，为每个可用区分配Subnet<ul><li>在两个可用区里面网段不同的时候，就可以配置路由策略，访问另一个可用区</li></ul></li></ul></li><li>创建数据库持久化层<ul><li>云平台给每个Subnet的数据库实例分配一个域名，在创建的时候，需要指定可用区和Subnet，这样创建出来的数据库实例可以通过这个Subnet的私网IP进行访问。 </li><li>各个可用区都要有数据库，主从数据库，云平台会提供数据库同步工具，将应用写入的主数据同步给备数据库集群</li></ul></li><li>创建缓存集群<ul><li>每个可用区，Subnet有一套</li><li>缓存的数据写在内存中</li><li>因为较高的读写性能要求，一般不需要跨可用区读写</li></ul></li><li>写的程序们…<ul><li>相互关系<ul><li>之间通过RPC相互调用</li><li>需要到注册中心去进行注册</li><li>网络通信是虚拟机和虚拟机之间的</li><li>不同的可用区之间，通过核心交换机连在一起，核心交换机之外是边界路由器。</li></ul></li><li>基础服务层</li><li>组合服务层</li><li>Controller层</li><li>Nginx层<ul><li>负载均衡也是云平台提供的 PaaS 服务，也是属于某个 VPC 的，部署在虚拟机里面的，但是负载均衡有个外网的 IP，这个外网的 IP 地址就是在网关节点的外网网口上的。在网关节点上，会有 NAT 规则，将外网 IP 地址转换为 VPC 里面的私网 IP 地址，通过这些私网 IP 地址访问到虚拟机上的负载均衡节点，然后通过负载均衡节点转发到 API 网关的节点。 </li></ul></li><li>API网关<ul><li>网关节点的外网网口是带公网IP地址的，里面有一个虚拟网关转发模块，还会有一个OVS，将私网IP地址放到VXLAN隧道里面，转发到虚拟机上，从而实现外网和虚拟机网络之间的互通。</li></ul></li><li>智能DNS<ul><li>对于不同地区和不同运营商的用户，保证访问速度</li></ul></li><li>CDN与边缘节点<ul><li>存储静态资源到对象存储里</li><li>通过CDN下发到边缘节点</li></ul></li></ul></li></ul><h1 id="2-广播给全网"><a href="#2-广播给全网" class="headerlink" title="2. 广播给全网"></a>2. 广播给全网</h1><p><img src="https://i.loli.net/2020/02/02/padlBADogKVHhGI.jpg" alt="fig3.jpg"></p><p>外网IP是放在虚拟网关的外网网口上的，通过BGP路由协议让全世界知道。</p><p>BGP路由协议 Border Gateway Protocol， 去中心化自治路由协议，通过维护IP路由表来实现自治系统之间的可达性，属于矢量路由协议</p><p>每个可用区都有自己的汇聚交换机，每个Region也有自己的核心交换区域。</p><p>在核心交换外面是安全设备，然后是边界路由器。边界路由器会和多个运营商连接，从而每个运营商都能够访问到这个网站。边界路由器可以通过BGP协议，将自己的数据中心里面的外网IP向外广播。</p><h1 id="3-域名解析地址"><a href="#3-域名解析地址" class="headerlink" title="3. 域名解析地址"></a>3. 域名解析地址</h1><p><img src="https://i.loli.net/2020/02/02/HoziVPFMukRL9wa.jpg" alt="fig4.jpg"></p><p>客户的手机开机以后，在附近寻找基站 eNodeB，发送请求，申请上网。基站将请求发给 MME，MME 对手机进行认证和鉴权，还会请求 HSS 看有没有钱，看看是在哪里上网。</p><p>当 MME 通过了手机的认证之后，开始建立隧道，建设的数据通路分两段路，其实是两个隧道。一段是从 eNodeB 到 SGW，第二段是从 SGW 到 PGW，在 PGW 之外，就是互联网。</p><p>PGW 会为手机分配一个 IP 地址，手机上网都是带着这个 IP 地址的。当在手机上面打开一个 App 的时候，首先要做的事情就是解析这个网站的域名。</p><p>在手机运营商所在的互联网区域里，有一个本地的 DNS，手机会向这个 DNS 请求解析 DNS。当这个 DNS 本地有缓存，则直接返回；如果没有缓存，本地 DNS 才需要递归地从根 DNS 服务器，查到.com 的顶级域名服务器，最终查到权威 DNS 服务器。</p><p>如果配置了DNS和全局负载均衡，在权威DNS服务中，我们可以通过配置CNAME的方式，起一个别名，然后告诉本地 DNS 服务器，让它请求 GSLB 解析这个域名，GSLB 就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。</p><p>GSLB 通过查看请求它的本地 DNS 服务器所在的运营商和地址，就知道用户所在的运营商和地址，然后将距离用户位置比较近的 Region 里面，三个负载均衡 SLB 的公网 IP 地址，返回给本地 DNS 服务器。本地 DNS 解析器将结果缓存后，返回给客户端。</p><p>对于手机 App 来说，可以绕过刚才的传统 DNS 解析机制，直接只要 HTTPDNS 服务，通过直接调用 HTTPDNS 服务器，得到这三个 SLB 的公网 IP 地址。</p><h1 id="4-购物前浏览的过程-静态资源CDN"><a href="#4-购物前浏览的过程-静态资源CDN" class="headerlink" title="4. 购物前浏览的过程 - 静态资源CDN"></a>4. 购物前浏览的过程 - 静态资源CDN</h1><p><img src="https://i.loli.net/2020/02/02/HmRsg9l7X1yzF4q.jpg" alt="fig5.jpg"></p><p>DNS -&gt; CDN -&gt; Cloud </p><p>我们部署电商应用的时候，一般会将静态资源保存在两个地方： </p><ul><li>接入层nginx后面的varnish缓存里</li><li>对于比较大，不常更新的静态图片，会保存在对象存储里面</li></ul><p>这两个地方的静态资源都会配置CDN，将资源下发到边缘节点。</p><p>配置了CDN之后，权威DNS服务器上，会为<strong>静态资源设置一个CNAME别名</strong>，指向另外一个域名，cdn.com，返回给本地的DNS服务器。当本地 DNS 服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的时候就不是原来的权威 DNS 服务器了，而是cdn.com的权威DNS服务器，这是CDN自己的。</p><p>在这个服务器上，还是会设置一个 CNAME，指向另外一个域名，也即 CDN 网络的全局负载均衡器。</p><p>本地 DNS 服务器去请求 CDN 的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，将 IP 返回给客户端，客户端去访问这个边缘节点，下载资源。缓存服务器响应用户请求，将用户所需内容传送到用户终端。</p><p><strong><em>如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器，将内容拉到本地</em></strong></p><h1 id="5-下单过程，双方建立连接"><a href="#5-下单过程，双方建立连接" class="headerlink" title="5. 下单过程，双方建立连接"></a>5. 下单过程，双方建立连接</h1><p>对于下单，网站会提供RESTful的下单接口，这种操作有很强的私密性，因此需要通过HTTPS协议进行请求。</p><p><img src="https://i.loli.net/2020/02/02/ENjJD3su5RIHdAk.jpg" alt="fig6.jpg"></p><p>建立TCP连接的行为是在手机的APP和负载均衡器SLB之间发生的。</p><p>对于TCP连接来讲，需要通过三次握手建立连接，为了维护这个连接，双方都需要在TCP层维护一个连接的状态机。</p><p>一开始，客户端和服务端都处于 CLOSED 状态。服务端先是主动监听某个端口，处于 LISTEN 状态。然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。</p><p>客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态。这是因为，它一发一收成功了。服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它的一发一收也成功了。</p><p>TCP层连接建立完毕之后，接下来是在HTTPS层建立连接，在HTTPS的交换过程中，TCP层始终处于ESTABLISHED状态。</p><p>对于 HTTPS，客户端会发送 Client Hello 消息到服务器，用明文传输 TLS 版本信息、加密套件候选列表、压缩算法候选列表等信息。另外，还会有一个随机数，在协商对称密钥的时候使用。</p><p>然后，服务器会返回 Server Hello 消息，告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等。这也有一个随机数，用于后续的密钥协商。</p><p>然后，服务器会给你一个服务器端的证书，然后说：“Server Hello Done，我这里就这些信息了。”</p><p>客户端当然不相信这个证书，于是从自己信任的 CA 仓库中，拿 CA 的证书里面的公钥去解密电商网站的证书。如果能够成功，则说明电商网站是可信的。这个过程中，你可能会不断往上追溯 CA、CA 的 CA、CA 的 CA 的 CA，反正直到一个授信的 CA，就可以了。</p><p>证书验证完毕之后，觉得这个服务端是可信的，于是客户端计算产生随机数字 Pre-master，发送 Client Key Exchange，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。</p><p>接下来，无论是客户端还是服务器，都有了三个随机数，分别是：自己的、对端的，以及刚生成的 Pre-Master 随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。</p><p>有了对称密钥，客户端就可以说：“Change Cipher Spec，咱们以后都采用协商的通信密钥和加密算法进行加密通信了。”</p><p>然后客户端发送一个 Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。</p><p>同样，服务器也可以发送 Change Cipher Spec，说：“没问题，咱们以后都采用协商的通信密钥和加密算法进行加密通信了”，并且也发送 Encrypted Handshake Message 的消息试试。</p><p>当双方握手结束之后，就可以通过对称密钥进行加密传输了。</p><h1 id="6-发送下单请求的网络包"><a href="#6-发送下单请求的网络包" class="headerlink" title="6. 发送下单请求的网络包"></a>6. 发送下单请求的网络包</h1><p>客户端和服务端之间建立连接之后，接下来就是发送下单请求的网络包了。</p><p>在用户层发送的是 HTTP 的网络包，因为服务端提供的是 RESTful API，因而 HTTP 层发送的就是一个请求。</p><pre><code>POST /purchaseOrder HTTP/1.1Host: www.llchen60.comContent-Type: application/json; charset=utf-8Content-Length: nnn{ &quot;order&quot;: {  &quot;date&quot;: &quot;2018-07-01&quot;,  &quot;className&quot;: &quot; 趣谈网络协议 &quot;,  &quot;Author&quot;: &quot; leilei &quot; }}</code></pre><p>HTTP报文分为三个部分</p><ul><li>请求行<ul><li><a href="http://www.llchen60.com/purchaseOrder">www.llchen60.com/purchaseOrder</a></li></ul></li><li>请求首部<ul><li>key value的形式， 通过冒号分隔 </li></ul></li><li>请求的正文实体</li></ul><p>HTTP请求的报文格式搞好了以后，浏览器会将其交给传输层，交给的方式是用socket进行程序设计。</p><p>HTTP协议是基于TCP协议的，所以使用面向连接的方式发送请求，通过Stream二进制流的方式传给对方。到了TCP层，它会把二进制流变成一个报文段发送给服务器。</p><p>在 TCP 头里面，会有源端口号和目标端口号，<strong>目标端口号一般是服务端监听的端口号</strong>，源端口号在手机端，往往是随机分配一个端口号。这个端口号在客户端和服务端用于区分请求和返回，发给那个应用。</p><p>在 IP 头里面，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址）。当一个手机上线的时候，PGW 会给这个手机分配一个 IP 地址，这就是源地址，而目标地址则是云平台的负载均衡器的外网 IP 地址。</p><p>在 IP 层，客户端需要查看目标地址和自己是否是在同一个局域网，计算是否是同一个网段，往往需要通过 CIDR 子网掩码来计算。</p><p>对于这个下单场景，目标 IP 和源 IP 不会在同一个网段，因而需要发送到默认的网关。一般通过 DHCP 分配 IP 地址的时候，同时配置默认网关的 IP 地址。</p><p>但是客户端不会直接使用默认网关的 IP 地址，而是发送 ARP 协议，来获取网关的 MAC 地址，然后将网关 MAC 作为目标 MAC，自己的 MAC 作为源 MAC，放入 MAC 头，发送出去。</p><p>完整的网络包如下所示： </p><p><img src="https://i.loli.net/2020/02/02/MfVQxW1XCzjuLN7.jpg" alt="fig7.jpg"></p><h1 id="7-流控拥塞与重传"><a href="#7-流控拥塞与重传" class="headerlink" title="7. 流控拥塞与重传"></a>7. 流控拥塞与重传</h1><p>对于手机来讲，默认的网关在 PGW 上。在移动网络里面，从手机到 SGW，到 PGW 是有一条隧道的。在这条隧道里面，会将上面的这个包作为隧道的乘客协议放在里面，外面 SGW 和 PGW 在核心网机房的 IP 地址。网络包直到 PGW（PGW 是隧道的另一端）才将里面的包解出来，转发到外部网络。</p><p>从手机发送出来的网络包的结构如下：</p><ul><li>源MAC地址</li><li>目标MAC地址： 网关PGW上面的隧道端点的MAC</li><li>源IP： UE的IP地址</li><li>目标IP： SLB的公网IP地址</li></ul><p>进入隧道之后，要封装外层的网络地址，因而网络包的格式为：</p><ul><li>外层源MAC： E-NodeB的MAC</li><li>外层目标MAC： SGW的MAC</li><li>外层源IP： E-NodeB的IP</li><li>外层目标IP： SGW的IP</li><li>内层源 MAC：手机也即 UE 的 MAC</li><li>内层目标 MAC：网关 PGW 上面的隧道端点的 MAC</li><li>内层源 IP：UE 的 IP 地址</li><li>内层目标 IP：SLB 的公网 IP 地址</li></ul><p>当隧道在 SGW 的时候，切换了一个隧道，会从 SGW 到 PGW 的隧道，因而网络包的格式为：</p><ul><li>外层源 MAC：SGW 的 MAC</li><li>外层目标 MAC：PGW 的 MAC</li><li>外层源 IP：SGW 的 IP</li><li>外层目标 IP：PGW 的 IP</li><li>内层源 MAC：手机也即 UE 的 MAC</li><li>内层目标 MAC：网关 PGW 上面的隧道端点的 MAC</li><li>内层源 IP：UE 的 IP 地址</li><li>内层目标 IP：SLB 的公网 IP 地址</li></ul><p>在 PGW 的隧道端点将包解出来，转发出去的时候，一般在 PGW 出外部网络的路由器上，会部署 NAT 服务，将手机的 IP 地址转换为公网 IP 地址，当请求返回的时候，再 NAT 回来。因而在PGW之后，网络包格式为： </p><ul><li>源 MAC：PGW 出口的 MAC；</li><li>目标 MAC：NAT 网关的 MAC；</li><li>源 IP：UE 的 IP 地址；</li><li>目标 IP：SLB 的公网 IP 地址。</li></ul><p>在NAT网关，网络包的格式变成： </p><ul><li>源 MAC：NAT 网关的 MAC</li><li>目标 MAC：A2 路由器的 MAC</li><li>源 IP：UE 的公网 IP 地址</li><li>目标 IP：SLB 的公网 IP 地址</li></ul><p><img src="https://i.loli.net/2020/02/02/GMPYBduQXoiTgcW.jpg" alt="fig8.jpg"></p><p>出了 NAT 网关，就从核心网到达了互联网。在网络世界，每一个运营商的网络成为自治系统 AS。每个自治系统都有边界路由器，通过它和外面的世界建立联系。</p><p>如何从出口的运营商到达云平台的边界路由器？在路由器之间需要通过 BGP 协议实现，BGP 又分为两类，eBGP 和 iBGP。自治系统之间、边界路由器之间使用 eBGP 广播路由。内部网络也需要访问其他的自治系统。</p><p>边界路由器如何将 BGP 学习到的路由导入到内部网络呢？通过运行 iBGP，使内部的路由器能够找到到达外网目的地最好的边界路由器。</p><p>网站的 SLB 的公网 IP 地址早已经通过云平台的边界路由器，让全网都知道了。于是这个下单的网络包选择的下一跳是 A2，也即将 A2 的 MAC 地址放在目标 MAC 地址中。</p><p>到达 A2 之后，从路由表中找到下一跳是路由器 C1，于是将目标 MAC 换成 C1 的 MAC 地址。到达 C1 之后，找到下一跳是 C2，将目标 MAC 地址设置为 C2 的 MAC。到达 C2 后，找到下一跳是云平台的边界路由器，于是将目标 MAC 设置为边界路由器的 MAC 地址。</p><p>你会发现，这一路，都是只换 MAC，不换目标 IP 地址。这就是所谓下一跳的概念。在云平台的边界路由器，会将下单的包转发进来，经过核心交换，汇聚交换，到达外网网关节点上的 SLB 的公网 IP 地址。</p><p>我们可以看到，手机到 SLB 的公网 IP，是一个端到端的连接，连接的过程发送了很多包。所有这些包，无论是 TCP 三次握手，还是 HTTPS 的密钥交换，都是要走如此复杂的过程到达 SLB 的，当然每个包走的路径不一定一致。</p><p>网络包走在这个复杂的道路上，很可能一不小心就丢了，怎么办？这就需要借助 TCP 的机制重新发送。</p><p>既然 TCP 要对包进行重传，就需要维护 Sequence Number，看哪些包到了，哪些没到，哪些需要重传，传输的速度应该控制到多少，这就是TCP的滑动窗口协议。</p><p><img src="https://i.loli.net/2020/02/02/uKBpG8RZn5lHeEU.jpg" alt="fig9.jpg"></p><p>整个 TCP 的发送，一开始会协商一个 Sequence Number，从这个 Sequence Number 开始，每个包都有编号。滑动窗口将接收方的网络包分成四个部分：</p><ul><li>已经接收，已经 ACK，已经交给应用层的包</li><li>已经接收，已经 ACK，未发送给应用层</li><li>已经接收，尚未发送 ACK</li><li>未接收，尚有空闲的缓存区域</li></ul><p>对于 TCP 层来讲，每一个包都有 ACK。ACK 需要从 SLB 回复到手机端，将上面的那个过程反向来一遍，当然路径不一定一致，可见 ACK 也不是那么轻松的事情。</p><p>如果发送方超过一定的时间没有收到 ACK，就会重新发送。只有 TCP 层 ACK 过的包，才会发给应用层，并且只会发送一份，对于下单的场景，应用层是 HTTP 层。</p><p>你可能会问了，TCP 老是重复发送，会不会导致一个单下了两遍？是否要求服务端实现幂等？从 TCP 的机制来看，是不会的。只有收不到 ACK 的包才会重复发，发到接收端，在窗口里面只保存一份，所以在同一个 TCP 连接中，不用担心重传导致二次下单。</p><p>但是 TCP 连接会因为某种原因断了，例如手机信号不好，这个时候手机把所有的动作重新做一遍，建立一个新的 TCP 连接，在 HTTP 层调用两次 RESTful API。这个时候可能会导致两遍下单的情况，因而 RESTful API 需要实现幂等。</p><p>当 ACK 过的包发给应用层之后，TCP 层的缓存就空了出来，这会导致上面图中的大三角，也即接收方能够容纳的总缓存，整体顺时针滑动。小的三角形，也即接收方告知发送方的窗口总大小，也即还没有完全确认收到的缓存大小，如果把这些填满了，就不能再发了，因为没确认收到，所以一个都不能扔。</p><h1 id="8-从数据中心进网关，公网NAT成私网"><a href="#8-从数据中心进网关，公网NAT成私网" class="headerlink" title="8. 从数据中心进网关，公网NAT成私网"></a>8. 从数据中心进网关，公网NAT成私网</h1><p>包从手机端到了SLB公网IP所在的公网网口，由于匹配上了MAC地址和IP地址，因而将网络包收了起来。</p><p><img src="https://i.loli.net/2020/02/02/I4NUqCcgnXFZ5TQ.jpg" alt="fig10.jpg"></p><p>在虚拟网关节点的外网网口上，会有一个 NAT 规则，将公网 IP 地址转换为 VPC 里面的私网 IP 地址，这个私网 IP 地址就是 SLB 的 HAProxy 所在的虚拟机的私网 IP 地址。</p><p>当然为了承载比较大的吞吐量，虚拟网关节点会有多个，物理网络会将流量分发到不同的虚拟网关节点。同样 HAProxy 也会是一个大的集群，虚拟网关会选择某个负载均衡节点，将某个请求分发给它，负载均衡之后是 Controller 层，也是部署在虚拟机里面的。</p><p>当网络包里面的目标 IP 变成私有 IP 地址之后，虚拟路由会查找路由规则，将网络包从下方的私网网口发出来。这个时候包的格式为：</p><ul><li>源 MAC：网关 MAC；</li><li>目标 MAC：HAProxy 虚拟机的 MAC；</li><li>源 IP：UE 的公网 IP；</li><li>目标 IP：HAProxy 虚拟机的私网 IP。</li></ul><h1 id="9-进入隧道，RPC远程调用下单"><a href="#9-进入隧道，RPC远程调用下单" class="headerlink" title="9. 进入隧道，RPC远程调用下单"></a>9. 进入隧道，RPC远程调用下单</h1><p>在虚拟路由节点上，也会有 OVS，将网络包封装在 VXLAN 隧道里面，VXLAN ID 就是给你的租户创建 VPC 的时候分配的。包的格式为：</p><ul><li>外层源 MAC：网关物理机 MAC；</li><li>外层目标 MAC：物理机 A 的 MAC；</li><li>外层源 IP：网关物理机 IP；</li><li>外层目标 IP：物理机 A 的 IP；</li><li>内层源 MAC：网关 MAC；</li><li>内层目标 MAC：HAProxy 虚拟机的 MAC；</li><li>内层源 IP：UE 的公网 IP；</li><li>内层目标 IP：HAProxy 虚拟机的私网 IP。</li></ul><p>在物理机 A 上，OVS 会将包从 VXLAN 隧道里面解出来，发给 HAProxy 所在的虚拟机。HAProxy 所在的虚拟机发现 MAC 地址匹配，目标 IP 地址匹配，就根据 TCP 端口，将包发给 HAProxy 进程，因为 HAProxy 是在监听这个 TCP 端口的。因而 HAProxy 就是这个 TCP 连接的服务端，客户端是手机。对于 TCP 的连接状态、滑动窗口等，都是在 HAProxy 上维护的。</p><p>在这里 HAProxy 是一个四层负载均衡，也即它只解析到 TCP 层，里面的 HTTP 协议它不关心，就将请求转发给后端的多个 Controller 层的一个。</p><p>HAProxy 发出去的网络包就认为 HAProxy 是客户端了，看不到手机端了。网络包格式如下：</p><ul><li>源 MAC：HAProxy 所在虚拟机的 MAC；</li><li>目标 MAC：Controller 层所在虚拟机的 MAC；</li><li>源 IP：HAProxy 所在虚拟机的私网 IP；</li><li>目标 IP：Controller 层所在虚拟机的私网 IP。</li></ul><p>这个包发出去之后，会被物理机上的OVS放入VXLAN隧道里面，网络包格式为;</p><ul><li>外层源 MAC：物理机 A 的 MAC；</li><li>外层目标 MAC：物理机 B 的 MAC；</li><li>外层源 IP：物理机 A 的 IP；</li><li>外层目标 IP：物理机 B 的 IP；</li><li>内层源 MAC：HAProxy 所在虚拟机的 MAC；</li><li>内层目标 MAC：Controller 层所在虚拟机的 MAC；</li><li>内层源 IP：HAProxy 所在虚拟机的私网 IP；</li><li>内层目标 IP：Controller 层所在虚拟机的私网 IP。</li></ul><p>在物理机 B 上，OVS 会将包从 VXLAN 隧道里面解出来，发给 Controller 层所在的虚拟机。Controller 层所在的虚拟机发现 MAC 地址匹配，目标 IP 地址匹配，就根据 TCP 端口，将包发给 Controller 层的进程，因为它在监听这个 TCP 端口。</p><p>在 HAProxy 和 Controller 层之间，维护一个 TCP 的连接。</p><p>Controller 层收到包之后，它是关心 HTTP 里面是什么的，于是解开 HTTP 的包，发现是一个 POST 请求，内容是下单购买一个课程。</p><h1 id="10-下单扣减库存，数据入库返回成功"><a href="#10-下单扣减库存，数据入库返回成功" class="headerlink" title="10. 下单扣减库存，数据入库返回成功"></a>10. 下单扣减库存，数据入库返回成功</h1><p>一般在组合服务层会有专门管理下单的服务，Controller层会通过RPC调用这个组合服务层。</p><p>假设我们使用的是 Dubbo，则 Controller 层需要读取注册中心，将下单服务的进程列表拿出来，选出一个来调用。Dubbo 中默认的 RPC 协议是 Hessian2。Hessian2 将下单的远程调用序列化为二进制进行传输。</p><p>Netty 是一个非阻塞的基于事件的网络传输框架。Controller 层和下单服务之间，使用了 Netty 的网络传输框架。有了 Netty，就不用自己编写复杂的异步 Socket 程序了。Netty 使用的方式，就是IO多路复用。</p><p>Netty 还是工作在 Socket 这一层的，发送的网络包还是基于 TCP 的。在 TCP 的下层，还是需要封装上 IP 头和 MAC 头。如果跨物理机通信，还是需要封装的外层的 VXLAN 隧道里面。当然底层的这些封装，Netty 都不感知，它只要做好它的异步通信即可。</p><p>在 Netty 的服务端，也即下单服务中，收到请求后，先用 Hessian2 的格式进行解压缩。然后将请求分发到线程中进行处理，在线程中，会调用下单的业务逻辑。</p><p>下单的业务逻辑比较复杂，往往要调用基础服务层里面的库存服务、优惠券服务等，将多个服务调用完毕，才算下单成功。下单服务调用库存服务和优惠券服务，也是通过 Dubbo 的框架，通过注册中心拿到库存服务和优惠券服务的列表，然后选一个调用。</p><p>调用的时候，统一使用 Hessian2 进行序列化，使用 Netty 进行传输，底层如果跨物理机，仍然需要通过 VXLAN 的封装和解封装。</p><p>咱们以库存为例子的时候，讲述过幂等的接口实现的问题。因为如果扣减库存，仅仅是谁调用谁减一。这样存在的问题是，如果扣减库存因为一次调用失败，而多次调用，这里指的不是 TCP 多次重试，而是应用层调用的多次重试，就会存在库存扣减多次的情况。</p><p>这里常用的方法是，使用乐观锁（Compare and Set，简称 CAS）。CAS 要考虑三个方面，当前的库存数、预期原来的库存数和版本，以及新的库存数。在操作之前，查询出原来的库存数和版本，真正扣减库存的时候，判断如果当前库存的值与预期原值和版本相匹配，则将库存值更新为新值，否则不做任何操作。</p><p>这是一种基于状态而非基于动作的设计，符合 RESTful 的架构设计原则。这样的设计有利于高并发场景。当多个线程尝试使用 CAS 同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</p><p>最终，当下单更新到分布式数据库当中之后，整个下单过程结束。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本文会尽可能详细描述双十一的技术栈，希望对大家能有所裨益。&lt;/p&gt;
&lt;p&gt;整个过程会分为十个阶段，接下来也会分别从这十个方面进行讲述： &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;部署高可用高并发的电商平台&lt;/li&gt;
&lt;li&gt;广播全网&lt;/li&gt;
&lt;li&gt;域名解析&lt;/li&gt;
&lt;/ul&gt;
&lt;h
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
      <category term="Network" scheme="https://www.llchen60.com/tags/Network/"/>
    
      <category term="Distributed System" scheme="https://www.llchen60.com/tags/Distributed-System/"/>
    
  </entry>
  
  <entry>
    <title>网络协议(十) - RPC, SOAP, RESTful</title>
    <link href="https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%8D%81-RPC-SOAP-RESTful/"/>
    <id>https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%8D%81-RPC-SOAP-RESTful/</id>
    <published>2020-02-02T05:53:34.000Z</published>
    <updated>2020-02-02T06:06:58.017Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-RPC协议综述"><a href="#1-RPC协议综述" class="headerlink" title="1. RPC协议综述"></a>1. RPC协议综述</h1><p><img src="https://i.loli.net/2020/02/02/jrVzNFexLaUElXY.jpg" alt="fig1.jpg"></p><p>我们需要研究的是在网络打通以后，服务之间是如何互相调用的呢？</p><p>实质上是调用方和被调用方之间建立一个TCP或者UDP连接，来进行通信的。</p><p><img src="https://i.loli.net/2020/02/02/sWc8My2XSKHukzv.jpg" alt="fig2.jpg"></p><p>但是实际过程会非常复杂，假设一个场景，即客户端调用一个加法函数，将两个整数相加返回他们的和。放在远程调用上，因为要牵扯到网络，就要牵扯到Socket编程.</p><h2 id="1-1-实现远程调用的问题"><a href="#1-1-实现远程调用的问题" class="headerlink" title="1.1 实现远程调用的问题"></a>1.1 实现远程调用的问题</h2><ol><li>如何规定远程调用的语法？ </li></ol><p>如何表示加减，如何表示整数间的和小数间的？ </p><ol start="2"><li>如何传递参数？ </li></ol><p>参数和操作符的传递顺序；TCP流如何区分各个参数</p><ol start="3"><li>如何表示数据？</li></ol><p>对于长度不一定的类，结构体，怎么给空间来传递？<br>Big Endian 和Little Endian，采用的方式不一样的问题。</p><ol start="4"><li>如何知道一个服务端都实现了哪些远程调用？从哪个端口可以访问到？</li></ol><p>假设服务端实现了多个远程调用，每个可能实现在不同的进程当中，监听的端口也不一样，而且由于服务端都是自己实现的，不可能使用一个大家都公认的端口，而且有可能多个进程部署在同一台机器上，大家就需要抢占端口，为了防止冲突，往往使用随机端口，那客户端如何找到这些监听的端口呢？</p><ol start="5"><li>发生了错误、重传、丢包、性能等问题怎么办？ </li></ol><p>本地调用没有这个问题，但是一旦到网络上，这些问题都需要处理，因为网络是不可靠的，虽然在同一个连接中，我们还可通过 TCP 协议保证丢包、重传的问题，但是如果服务器崩溃了又重启，当前连接断开了，TCP 就保证不了了，需要应用自己进行重新调用，重新传输会不会同样的操作做两遍，远程调用性能会不会受影响呢？</p><h2 id="1-2-协议约定问题"><a href="#1-2-协议约定问题" class="headerlink" title="1.2 协议约定问题"></a>1.2 协议约定问题</h2><p>上述的各种问题是需要服务端和客户端协商来解决的，Jay Nelson写了一篇论文，<a href="http://www.cs.cmu.edu/~dga/15-712/F07/papers/birrell842.pdf" target="_blank" rel="noopener">Implementing Remote Procedure Calls</a> 定义了RPC的标准。</p><p><img src="https://i.loli.net/2020/02/02/KJDQzCel3fSuvTy.jpg" alt="fig3.jpg"></p><h3 id="1-2-1-客户端发起远程调用"><a href="#1-2-1-客户端发起远程调用" class="headerlink" title="1.2.1 客户端发起远程调用"></a>1.2.1 客户端发起远程调用</h3><p>通过本地调用本地调用方的Stub，负责将调用的接口、方法和参数，通过约定的协议规范进行编码，并通过本地的RPCRuntime进行传输，将调用网络包发送到服务器上。</p><h3 id="1-2-2-服务器端处理请求"><a href="#1-2-2-服务器端处理请求" class="headerlink" title="1.2.2 服务器端处理请求"></a>1.2.2 服务器端处理请求</h3><p>服务器端的RPCRuntime收到请求以后，交给提供方Stub进行解码，然后调用服务端的方法，服务端执行方法，返回结果，提供方Stub将返回结果编码后，发送给客户端，客户端的RPCRuntime收到结果，发给调用方Stub解码得到结果，返回给客户端。</p><h3 id="1-2-3-分析"><a href="#1-2-3-分析" class="headerlink" title="1.2.3 分析"></a>1.2.3 分析</h3><p>这里面分了三个层次，对于客户端和服务端，都像是本地调用一样，专注于业务逻辑的处理就可以了。对于Stub层，主要处理双方约定好的语法、语义、封装、解封装。对于RPCRuntime，主要处理高性能的传输，以及网络的错误和异常。</p><h2 id="1-3-RPC调用细节"><a href="#1-3-RPC调用细节" class="headerlink" title="1.3 RPC调用细节"></a>1.3 RPC调用细节</h2><p>最早的RPC是在NFS协议中使用的。NFS(Network File System)就是网络文件系统。要使NFS成功运行，要启动两个服务端，一个是MountID，用来挂载文件路径；一个是nfsd，用来读写文件。NFS可以在本地mount一个远程的目录到本地的一个目录，从而本地的用户在这个目录里面读写的时候，实际上操作的是远程另一台机器上的文件。</p><p><img src="https://i.loli.net/2020/02/02/lQ6Cbu58OWX7vTE.jpg" alt="fig4.jpg"></p><p>XDR(External Data Representation，外部数据表示法)是一个标准的数据压缩格式，可以表示基本的数据类型，也可以表示结构体。</p><p><img src="https://i.loli.net/2020/02/02/XTKIjcPuGNeiYt7.jpg" alt="fig5.jpg"></p><p>在RPC的调用中，所有的数据类型都要封装成类似的格式。而且RPC的调用和结果的返回，也有严格的格式。</p><ul><li>XID 唯一标识一对请求和回复。请求为 0，回复为 1。</li><li>RPC 有版本号，两端要匹配 RPC 协议的版本号。如果不匹配，就会返回 Deny，原因就是 RPC_MISMATCH。</li><li>程序有编号。如果服务端找不到这个程序，就会返回 PROG_UNAVAIL。</li><li>程序有版本号。如果程序的版本号不匹配，就会返回 PROG_MISMATCH。</li><li>一个程序可以有多个方法，方法也有编号，如果找不到方法，就会返回 PROC_UNAVAIL。</li><li>调用需要认证鉴权，如果不通过，则 Deny。</li><li>对于参数列表，如果参数无法解析，则返回GARBAGE_ARGS</li></ul><p><img src="https://i.loli.net/2020/02/02/oqLCI6nlrb9HpFZ.jpg" alt="fig6.jpg"></p><p>因此为了可以成功调用RPC，在客户端和服务端实现RPC的时候，首先要定义一个双方都认可的程序、版本、方法、参数等。</p><p><img src="https://i.loli.net/2020/02/02/FplZqHnDdILKmkw.jpg" alt="fig7.jpg"></p><p>如果还是上面的加法，则双方约定为一个协议定义文件，同理如果是 NFS、mount 和读写，也会有类似的定义。</p><p>有了协议定义文件，ONC RPC 会提供一个工具，根据这个文件生成客户端和服务器端的 Stub 程序。</p><p><img src="https://i.loli.net/2020/02/02/tjTU6N2nwdbEpZz.jpg" alt="fig8.jpg"></p><p>最下层的是XDR文件，用于编码和解码参数。这个文件是客户端和服务端共享的，因为只有双方一致才能成功通信。</p><p>在客户端，会调用 clnt_create 创建一个连接，然后调用 add_1，这是一个 Stub 函数，感觉是在调用本地一样。其实是这个函数发起了一个 RPC 调用，通过调用 clnt_call 来调用 ONC RPC 的类库，来真正发送请求。</p><p>当然服务端也有一个 Stub 程序，监听客户端的请求，当调用到达的时候，判断如果是 add，则调用真正的服务端逻辑，也即将两个数加起来。</p><p>服务端将结果返回服务端的 Stub，这个 Stub 程序发送结果给客户端，客户端的 Stub 程序正在等待结果，当结果到达客户端 Stub，就将结果返回给客户端的应用程序，从而完成整个调用过程。</p><h2 id="1-4-传输问题"><a href="#1-4-传输问题" class="headerlink" title="1.4 传输问题"></a>1.4 传输问题</h2><p>传输问题主要解决错误，重传，丢包，性能的问题，这些不是Stub来解决的，而是由One RPC类库来实现。</p><p><img src="https://i.loli.net/2020/02/02/FKCS6taMrDpizqv.jpg" alt="fig9.jpg"></p><p>在这个类库中，为了解决传输问题，对于每一个客户端，都会创建一个传输管理层，而每一次RPC调用，都会是一个任务，在传输管理层会有队列机制、拥塞控制机制等等。</p><p>由于在网络传输的时候，经常需要等待，因而同步的方式往往效率比较低，因而也就有 Socket 的异步模型。为了能够异步处理，对于远程调用的处理，往往是通过状态机来实现的。只有当满足某个状态的时候，才进行下一步，如果不满足状态，不是在那里等，而是将资源留出来，用来处理其他的 RPC 调用。</p><p><img src="https://i.loli.net/2020/02/02/rJ7AGCRfNMSVtHc.jpg" alt="fig10.jpg"></p><p>首先，进入起始状态，查看 RPC 的传输层队列中有没有空闲的位置，可以处理新的 RPC 任务。如果没有，说明太忙了，或直接结束或重试。如果申请成功，就可以分配内存，获取服务的端口号，然后连接服务器。</p><p>连接的过程要有一段时间，因而要等待连接的结果，会有连接失败，或直接结束或重试。如果连接成功，则开始发送 RPC 请求，然后等待获取 RPC 结果，这个过程也需要一定的时间；如果发送出错，可以重新发送；如果连接断了，可以重新连接；如果超时，可以重新传输；如果获取到结果，就可以解码，正常结束。</p><h2 id="1-5-服务发现问题"><a href="#1-5-服务发现问题" class="headerlink" title="1.5 服务发现问题"></a>1.5 服务发现问题</h2><p>如何找到RPC服务端的随机端口，在Onc RPC中，服务发现是通过portmapper实现的</p><p><img src="https://i.loli.net/2020/02/02/5BRPnap1Z9GcfkK.jpg" alt="fig11.jpg"></p><p>portmapper 会启动在一个众所周知的端口上，RPC 程序由于是用户自己写的，会监听在一个随机端口上，但是 RPC 程序启动的时候，会向 portmapper 注册。客户端要访问 RPC 服务端这个程序的时候，首先查询 portmapper，获取 RPC 服务端程序的随机端口，然后向这个随机端口建立连接，开始 RPC 调用。从图中可以看出，mount 命令的 RPC 调用，就是这样实现的。</p><h1 id="2-基于XML的SOAP协议"><a href="#2-基于XML的SOAP协议" class="headerlink" title="2. 基于XML的SOAP协议"></a>2. 基于XML的SOAP协议</h1><p>上述的ONC RPC协议还存在一些问题： </p><ol><li>需要双方的压缩格式完全一致</li><li>协议修改不灵活</li><li>版本问题</li></ol><p>即还是很难在客户端和服务端之间进行开发。</p><h2 id="2-1-XML-amp-SOAP"><a href="#2-1-XML-amp-SOAP" class="headerlink" title="2.1 XML &amp; SOAP"></a>2.1 XML &amp; SOAP</h2><p>要让所有不同的人都能看懂我们的信息，那么我们就需要用<strong>文本类</strong>的方式进行传输，无论哪个客户端获得这个文本，都能够知道它的意义。</p><h2 id="2-2-传输协议问题"><a href="#2-2-传输协议问题" class="headerlink" title="2.2 传输协议问题"></a>2.2 传输协议问题</h2><p>基于XML的最著名的通信协议就是SOAP了(Simple Object Access Protocol)-简单对象访问协议。使用XML编写简单的请求和回复消息，并用HTTP协议进行传输。</p><p>SOAP将请求和回复放在一个信封里，就像传递邮件一样，有抬头与正文的区别。</p><pre><code>POST /purchaseOrder HTTP/1.1Host: www.baidu.comContent-Type: application/soap+xml; charset=utf-8Content-Length: nnn&lt;?xml version=&quot;1.0&quot;?&gt;&lt;soap:Envelope xmlns:soap=&quot;http://www.w3.org/2001/12/soap-envelope&quot;soap:encodingStyle=&quot;http://www.w3.org/2001/12/soap-encoding&quot;&gt;    &lt;soap:Header&gt;        &lt;m:Trans xmlns:m=&quot;http://www.w3schools.com/transaction/&quot;          soap:mustUnderstand=&quot;1&quot;&gt;1234        &lt;/m:Trans&gt;    &lt;/soap:Header&gt;    &lt;soap:Body xmlns:m=&quot;http://www.baidu.com/perchaseOrder&quot;&gt;        &lt;m:purchaseOrder&quot;&gt;            &lt;order&gt;                &lt;date&gt;2018-07-01&lt;/date&gt;                &lt;className&gt; RPC &amp; SOAP &lt;/className&gt;                &lt;Author&gt; LLCHEN &lt;/Author&gt;            &lt;/order&gt;        &lt;/m:purchaseOrder&gt;    &lt;/soap:Body&gt;&lt;/soap:Envelope&gt;</code></pre><p>这个请求使用POST方法，发送一个格式为<code>application/soap + xml</code>的XML正文给<a href="http://www.baidu.com，从而下一个单，这个订单封装在SOAP的信封里。" target="_blank" rel="noopener">www.baidu.com，从而下一个单，这个订单封装在SOAP的信封里。</a></p><h2 id="2-3-协议约定问题"><a href="#2-3-协议约定问题" class="headerlink" title="2.3 协议约定问题"></a>2.3 协议约定问题</h2><p>因为服务开发出来是给陌生人用的，就像上面下单的那个 XML 文件，对于客户端来说，它如何知道应该拼装成上面的格式呢？这就需要对于服务进行描述，因为调用的人不认识你，所以没办法找到你，问你的服务应该如何调用。</p><p>当然你可以写文档，然后放在官方网站上，但是你的文档不一定更新得那么及时，而且你也写的文档也不一定那么严谨，所以常常会有调试不成功的情况。因而，我们需要一种相对比较严谨的<strong>Web服务描述语言， WSDL(Web Service Description Languages)</strong></p><p>在这个文件里，要定义一个类型的order，与上面的XML对应起来。</p><pre><code> &lt;wsdl:types&gt;  &lt;xsd:schema targetNamespace=&quot;http://www.example.org/geektime&quot;&gt;   &lt;xsd:complexType name=&quot;order&quot;&gt;    &lt;xsd:element name=&quot;date&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:element&gt;&lt;xsd:element name=&quot;className&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:element&gt;&lt;xsd:element name=&quot;Author&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:element&gt;    &lt;xsd:element name=&quot;price&quot; type=&quot;xsd:int&quot;&gt;&lt;/xsd:element&gt;   &lt;/xsd:complexType&gt;  &lt;/xsd:schema&gt; &lt;/wsdl:types&gt;</code></pre><p>定义一个message结构</p><pre><code> &lt;wsdl:message name=&quot;purchase&quot;&gt;  &lt;wsdl:part name=&quot;purchaseOrder&quot; element=&quot;tns:order&quot;&gt;&lt;/wsdl:part&gt; &lt;/wsdl:message&gt;</code></pre><p>暴露一个端口</p><pre><code> &lt;wsdl:portType name=&quot;PurchaseOrderService&quot;&gt;  &lt;wsdl:operation name=&quot;purchase&quot;&gt;   &lt;wsdl:input message=&quot;tns:purchase&quot;&gt;&lt;/wsdl:input&gt;   &lt;wsdl:output message=&quot;......&quot;&gt;&lt;/wsdl:output&gt;  &lt;/wsdl:operation&gt; &lt;/wsdl:portType&gt;</code></pre><p>编写一个binding，将上面定义的信息绑定到SOAP请求的body里面</p><pre><code> &lt;wsdl:binding name=&quot;purchaseOrderServiceSOAP&quot; type=&quot;tns:PurchaseOrderService&quot;&gt;  &lt;soap:binding style=&quot;rpc&quot;   transport=&quot;http://schemas.xmlsoap.org/soap/http&quot; /&gt;  &lt;wsdl:operation name=&quot;purchase&quot;&gt;   &lt;wsdl:input&gt;    &lt;soap:body use=&quot;literal&quot; /&gt;   &lt;/wsdl:input&gt;   &lt;wsdl:output&gt;    &lt;soap:body use=&quot;literal&quot; /&gt;   &lt;/wsdl:output&gt;  &lt;/wsdl:operation&gt; &lt;/wsdl:binding&gt;</code></pre><p>对应的Service：</p><pre><code> &lt;wsdl:service name=&quot;PurchaseOrderServiceImplService&quot;&gt;  &lt;wsdl:port binding=&quot;tns:purchaseOrderServiceSOAP&quot; name=&quot;PurchaseOrderServiceImplPort&quot;&gt;   &lt;soap:address location=&quot;http://www.geektime.com:8080/purchaseOrder&quot; /&gt;  &lt;/wsdl:port&gt; &lt;/wsdl:service&gt;</code></pre><h2 id="2-4-服务发现问题"><a href="#2-4-服务发现问题" class="headerlink" title="2.4 服务发现问题"></a>2.4 服务发现问题</h2><p>采用UDDI协议(Universal Description, Discovery, and Integration),即统一描述、发现和继承协议。它其实是一个注册中心，服务提供方可以将上面的 WSDL 描述文件，发布到这个注册中心，注册完毕后，服务使用方可以查找到服务的描述，封装为本地的客户端进行调用。</p><h1 id="3-基于JSON的RESTful接口协议"><a href="#3-基于JSON的RESTful接口协议" class="headerlink" title="3. 基于JSON的RESTful接口协议"></a>3. 基于JSON的RESTful接口协议</h1><h2 id="3-1-RESTful"><a href="#3-1-RESTful" class="headerlink" title="3.1 RESTful"></a>3.1 RESTful</h2><p>然而 RESTful 可不仅仅是指 API，而是一种架构风格，全称 Representational State Transfer，表述性状态转移</p><h2 id="3-2-协议约定问题"><a href="#3-2-协议约定问题" class="headerlink" title="3.2 协议约定问题"></a>3.2 协议约定问题</h2><p>和 SOAP 不一样，REST 不是一种严格规定的标准，它其实是一种设计风格。如果按这种风格进行设计，RESTful 接口和 SOAP 接口都能做到，只不过后面的架构是 REST 倡导的，而 SOAP 相对比较关注前面的接口。</p><p>然而本地调用和远程跨网络调用毕竟不一样，这里的不一样还不仅仅是因为有网络而导致的客户端和服务端的分离，从而带来的网络性能问题。更重要的问题是，客户端和服务端谁来维护状态。所谓的状态就是对某个数据当前处理到什么程度了。</p><p>当有了 RPC 之后，我们本来期望对上层透明，就像上一节说的“远在天边，尽在眼前”。于是使用 RPC 的时候，对于状态的问题也没有太多的考虑。上面的例子都是在 RPC 场景下，由服务端来维护状态，很多 SOAP 接口设计的时候，也常常按这种模式。这种模式原来没有问题，是因为客户端和服务端之间的比例没有失衡。因为一般不会同时有太多的客户端同时连上来，所以 NFS 还能把每个客户端的状态都记住。</p><p>但是互联网场景下，客户端和服务端就彻底失衡了。你可以想象“双十一”，多少人同时来购物，作为服务端，它能记得过来吗？当然不可能，只好多个服务端同时提供服务，大家分担一下。但是这就存在一个问题，服务端怎么把自己记住的客户端状态告诉另一个服务端呢？或者说，你让我给你分担工作，你也要把工作的前因后果给我说清楚啊！</p><p>因此应该是服务端只记录资源的状态，而客户端自己维护自己的状态，比如已经访问到哪个目录了，哪一页等等这类信息。</p><p>当客户端维护了自己的状态的时候，就不需要这样调用服务端了。通过这种让客户端记录自己的状态的方式，我们可以实现服务端的无状态化，就可以让服务端来横向扩展了。</p><p>所谓的无状态，其实是服务端维护资源的状态，客户端维护会话的状态。对于服务端来讲，只有资源的状态改变了，客户端才调用 POST、PUT、DELETE 方法来找我；如果资源的状态没变，只是客户端的状态变了，就不用告诉我了，对于我来说都是统一的 GET。</p><p>虽然这只改进了 GET，但是已经带来了很大的进步。因为对于互联网应用，大多数是读多写少的。<strong>而且只要服务端的资源状态不变，就给了我们缓存的可能。例如可以将状态缓存到接入层，甚至缓存到 CDN 的边缘节点，这都是资源状态不变的好处</strong>。</p><p>按照这种思路，对于API的设计，就慢慢变成了以资源为核心，而不是以过程为核心了。也就是说服务端只需要客户端告诉它你需要什么资源就好了，具体的过程和动作就不需要知道了。</p><p>还是文件目录的例子。客户端应该访问哪个绝对路径，而非一个动作，我就要进入某个路径。再如，库存的调用，应该查看当前的库存数目，然后减去购买的数量，得到结果的库存数。这个时候应该设置为目标库存数（但是当前库存数要匹配），而非告知减去多少库存。</p><p>这种 API 的设计需要实现幂等，因为网络不稳定，就会经常出错，因而需要重试，但是一旦重试，就会存在幂等的问题，也就是同一个调用，多次调用的结果应该一样，不能一次支付调用，因为调用三次变成了支付三次。不能进入 cd a，做了三次，就变成了 cd a/a/a。也不能扣减库存，调用了三次，就扣减三次库存。</p><p>当然按照这种设计模式，无论 RESTful API 还是 SOAP API 都可以将架构实现成无状态的，面向资源的、幂等的、横向扩展的、可缓存的。</p><p>但SOAP的XML正文可以放任何动作，而RESTful基本描述的就是资源的状态，没法描述动作，能发出的动作只有CRUD。</p><h2 id="3-3-服务发现问题"><a href="#3-3-服务发现问题" class="headerlink" title="3.3 服务发现问题"></a>3.3 服务发现问题</h2><p>有个著名的基于 RESTful API 的跨系统调用框架叫 Spring  Cloud。在 Spring  Cloud 中有一个组件叫 Eureka。传说，阿基米德在洗澡时发现浮力原理，高兴得来不及穿上裤子，跑到街上大喊：“Eureka（我找到了）！”所以 Eureka 是用来实现注册中心的，负责维护注册的服务列表。</p><p>服务分服务提供方，它向 Eureka 做服务注册、续约和下线等操作，注册的主要数据包括服务名、机器 IP、端口号、域名等等。</p><p>另外一方是服务消费方，向 Eureka 获取服务提供方的注册信息。为了实现负载均衡和容错，服务提供方可以注册多个。</p><p>当消费方要调用服务的时候，会从注册中心读出多个服务来，那怎么调用呢？当然是 RESTful 方式了。</p><p>Spring Cloud 提供一个 RestTemplate 工具，用于将请求对象转换为 JSON，并发起 Rest 调用，RestTemplate 的调用也是分 POST、PUT、GET、  DELETE 的，当结果返回的时候，根据返回的 JSON 解析成对象。</p><h1 id="4-二进制类RPC协议"><a href="#4-二进制类RPC协议" class="headerlink" title="4. 二进制类RPC协议"></a>4. 二进制类RPC协议</h1><p>接入层设计，在CDN, DNS当中，对于静态资源或者动态资源静态化的部分都可以做缓存。但是对于下单，支付等交易场景，还是需要调用API。</p><p>对于微服务的架构，API需要一个API网关统一进行管理。实现方式有：用Nginx或者OpenResty结合Lua脚本。在Spring Cloud当中，用组件Zuul也可以。</p><h2 id="4-1-数据中心内部是如何调用的？"><a href="#4-1-数据中心内部是如何调用的？" class="headerlink" title="4.1 数据中心内部是如何调用的？"></a>4.1 数据中心内部是如何调用的？</h2><p>API网关用来管理API，但是API的实现一般在Controller层进行实现，这一层对外提供API。因为是面向大规模互联网应用的，所以主流还是使用RESTful API。</p><p><img src="https://i.loli.net/2020/02/02/r5w7jdebPcLEDty.jpg" alt="fig12.jpg"></p><p>非常棒的分层图:</p><ol><li>客户端进入的请求首先会进入负载均衡系统-nginx</li><li>静态资源先到Varnish找</li><li>动态资源去Redis找</li><li>2，3是负责整个页面的渲染</li><li>对于API调用，会到Controller层去解决，这里主要是处理各种业务逻辑的</li><li>Controller层下方会有细化的基础服务层</li><li>缓存层</li><li>持久化层（分布式数据库+搜索引擎）</li></ol><p>在Controller之内，就是互联网应用的业务逻辑实现了。业务逻辑的实现最好是无状态的，从而可以横向扩展，但是资源的状态还是需要服务端来维护的。资源的状态不应该维护在业务逻辑层，而是在最底层的持久化层，一般会使用分布式数据库和Elastic Search.</p><p>这些服务端的状态，例如订单、库存、商品等，都是重中之重，都需要持久化到硬盘上，数据不能丢，但是由于硬盘读写性能差，因而持久化层往往吞吐量不能达到互联网应用要求的吞吐量，因而前面要有一层缓存层，使用 Redis 或者 memcached 将请求拦截一道，不能让所有的请求都进入数据库“中军大营”。</p><p>缓存和持久化层之上一般是<strong>基础服务层</strong>，这里面提供一些原子化的接口。例如，对于用户、商品、订单、库存的增删查改，将缓存和数据库对再上层的业务逻辑屏蔽一道。有了这一层，上层业务逻辑看到的都是接口，而不会调用数据库和缓存。因而对于缓存层的扩容，数据库的分库分表，所有的改变，都截止到这一层，这样有利于将来对于缓存和数据库的运维。</p><p>再上面就是<strong>组合层</strong>。因为基础服务层只是提供简单的接口，实现简单的业务逻辑，而复杂的业务逻辑，比如下单，要扣优惠券，扣减库存等，就要在组合服务层实现。</p><p>这样，Controller 层、组合服务层、基础服务层就会相互调用，这个调用是在数据中心内部的，量也会比较大，还是使用 RPC 的机制实现的。</p><p>由于服务比较多，需要一个单独的注册中心来做服务发现。服务提供方会将自己提供哪些服务注册到注册中心中去，同时服务消费方订阅这个服务，从而可以对这个服务进行调用。</p><p>调用的时候有一个问题，这里的 RPC 调用，应该用二进制还是文本类？其实文本的最大问题是，占用字节数目比较多。比如数字 123，其实本来二进制 8 位就够了，但是如果变成文本，就成了字符串 123。如果是 UTF-8 编码的话，就是三个字节；如果是 UTF-16，就是六个字节。同样的信息，要多费好多的空间，传输起来也更加占带宽，时延也高。因而对于数据中心内部的相互调用，很多公司选型的时候，还是希望采用更加省空间和带宽的二进制的方案。</p><h2 id="4-2-Dubbo服务化框架二进制的RPC方式"><a href="#4-2-Dubbo服务化框架二进制的RPC方式" class="headerlink" title="4.2 Dubbo服务化框架二进制的RPC方式"></a>4.2 Dubbo服务化框架二进制的RPC方式</h2><p><img src="https://i.loli.net/2020/02/02/fX8e25rG6xkBpq4.jpg" alt="fig13.jpg"></p><p>Dubbo 会在客户端的本地启动一个 Proxy，其实就是客户端的 Stub，对于远程的调用都通过这个 Stub 进行封装。</p><p>接下来，Dubbo 会从注册中心获取服务端的列表，根据路由规则和负载均衡规则，在多个服务端中选择一个最合适的服务端进行调用。</p><p>调用服务端的时候，首先要进行编码和序列化，形成 Dubbo 头和序列化的方法和参数。将编码好的数据，交给网络客户端进行发送，网络服务端收到消息后，进行解码。然后将任务分发给某个线程进行处理，在线程中会调用服务端的代码逻辑，然后返回结果。</p><h2 id="4-3-如何解决协议约定问题？"><a href="#4-3-如何解决协议约定问题？" class="headerlink" title="4.3 如何解决协议约定问题？"></a>4.3 如何解决协议约定问题？</h2><p>Dubbo 中默认的 RPC 协议是 Hessian2。为了保证传输的效率，Hessian2 将远程调用序列化为二进制进行传输，并且可以进行一定的压缩。这个时候你可能会疑惑，同为二进制的序列化协议，Hessian2 和前面的二进制的 RPC 有什么区别呢？Hessian2 是解决了一些问题的。例如，原来要定义一个协议文件，然后通过这个文件生成客户端和服务端的 Stub，才能进行相互调用，这样使得修改就会不方便。Hessian2 不需要定义这个协议文件，而是自描述的。什么是自描述呢？</p><p>所谓自描述就是，关于调用哪个函数，参数是什么，另一方不需要拿到某个协议文件、拿到二进制，靠它本身根据 Hessian2 的规则，就能解析出来。</p><h2 id="4-4-如何解决RPC传输问题？"><a href="#4-4-如何解决RPC传输问题？" class="headerlink" title="4.4 如何解决RPC传输问题？"></a>4.4 如何解决RPC传输问题？</h2><p>Dubbo使用了Netty的网络传输框架。</p><p>Netty是一个非阻塞的基于事件的网络传输框架，在服务端启动的时候，会监听一个端口，并注册以下事件：</p><ul><li>连接事件 - 当收到客户端的连接事件时，会调用void connected(Channel channel)方法</li><li>当<strong>可写事件</strong>触发时，会调用void sent(Channel channel, Object message)，服务端向客户端返回响应数据</li><li>当<strong>可读事件</strong>触发时，会调用 void received(Channel channel, Object message) ，服务端在收到客户端的请求数据。</li><li>当<strong>发生异常</strong>时，会调用 void caught(Channel channel, Throwable exception)。</li></ul><p>当事件触发之后，服务端在这些函数中的逻辑，可以选择<strong>直接在这个函数里面进行操作，还是将请求分发到线程池</strong>去处理。一般异步的数据读写都需要另外的线程池参与，在线程池中会<strong>调用真正的服务端业务代码逻辑</strong>，返回结果</p><p>到这里，我们说了数据中心里面的相互调用。为了高性能，大家都愿意用二进制，但是为什么后期 Spring Cloud 又兴起了呢？这是因为，并发量越来越大，已经到了微服务的阶段。同原来的 SOA 不同，微服务粒度更细，模块之间的关系更加复杂。</p><p>在上面的架构中，如果使用二进制的方式进行序列化，虽然不用协议文件来生成 Stub，但是对于接口的定义，以及传的对象 DTO，<strong>还是需要共享 JAR</strong>。因为只有客户端和服务端都有这个 JAR，才能成功地序列化和反序列化。</p><p>但当关系复杂的时候，JAR 的依赖也变得异常复杂，难以维护，而且如果在 DTO 里加一个字段，双方的 JAR 没有匹配好，也会导致序列化不成功，而且还有可能循环依赖。这个时候，一般有两种选择。</p><ol><li>建立严格的项目管理流程</li></ol><ul><li>不允许循环调用，不允许跨层调用，只准上层调用下层，不允许下层调用上层。</li><li>接口要保持兼容性，不兼容的接口新添加而非改原来的，当接口通过监控，发现不用的时候，再下掉。</li><li>升级的时候，先升级服务提供端，再升级服务消费端。</li></ul><ol start="2"><li>改用RESTful方式</li></ol><ul><li>使用 Spring Cloud，消费端和提供端不用共享 JAR，各声明各的，只要能变成 JSON 就行，而且 JSON 也是比较灵活的。</li><li>使用 RESTful 的方式，性能会降低，所以需要通过横向扩展来抵消单机的性能损耗。</li></ul><h1 id="5-跨语言类RPC协议"><a href="#5-跨语言类RPC协议" class="headerlink" title="5. 跨语言类RPC协议"></a>5. 跨语言类RPC协议</h1><p>通过学习，我们知道，二进制的传输性能好，文本类的传输性能差一些；二进制的难以跨语言，文本类的可以跨语言；要写协议文件的严谨一些，不写协议文件的灵活一些。虽然都有服务发现机制，有的可以进行服务治理，有的则没有。</p><p>RPC从最初的客户端服务器的模式，最终演化到微服务。对于RPC框架的要求也开始逐渐变多，要求如下： </p><ol><li>传输性能很重要，因为服务之间的调用太过频繁，还是二进制的越快越好</li><li>跨语言很重要，因为服务多了，什么语言写成的都有，而且不同的场景适宜用不同的语言，不能一个语言走到底。</li><li>最好既严谨又灵活，添加一个字段不需要重新编译和发布程序</li><li>最好既有服务发现，也有服务治理，就像Dubbo和Spring Cloud这样子。</li></ol><h2 id="5-1-gRPC协议"><a href="#5-1-gRPC协议" class="headerlink" title="5.1 gRPC协议"></a>5.1 gRPC协议</h2><p>二进制传输，并且可以跨语言传输。因为语言不同，还压缩过了，所以双方必须搞一个协议约定文件，规定好双方沟通的专业术语，这样来让整个沟通更加顺畅。</p><p>对于 GRPC 来讲，二进制序列化协议是 Protocol Buffers。首先，需要定义一个协议文件.proto。</p><pre><code>syntax = “proto3”;package com.llchen60.grpcoption java_package = “com.llchen60.grpc”;message Order {  required string date = 1;  required string classname = 2;  required string author = 3;  required int price = 4;}message OrderResponse {  required string message = 1;}service PurchaseOrder {  rpc Purchase (Order) returns (OrderResponse) {}}</code></pre><p>在这个协议文件中，我们首先指定使用 proto3 的语法，然后我们使用** Protocol Buffers 的语法<strong>，定义两个消息的类型，一个是发出去的参数，一个是返回的结果。里面的每一个字段，例如 date、classname、author、price 都有</strong>唯一的一个数字标识**，这样在压缩的时候，就不用传输字段名称了，只传输这个数字标识就行了，能节省很多空间。</p><p>最后定义一个Service，里面会有一个RPC调用的声明，无论使用什么语言，都有相应的工具生成客户端和服务端的Stub程序，这样客户端就可以像调用本地一样，调用远程的服务了。</p><h2 id="5-2-协议约定问题"><a href="#5-2-协议约定问题" class="headerlink" title="5.2 协议约定问题"></a>5.2 协议约定问题</h2><p>Protocol Buffers，是一个有着很高的压缩效率的序列化协议。对于 int 类型 32 位的，一般都需要 4 个 Byte 进行存储。在 Protocol Buffers 中，使用的是变长整数的形式。对于每一个 Byte 的 8 位，最高位都有特殊的含义。如果该位为 1，表示这个数字没完，后续的 Byte 也属于这个数字；如果该位为 0，则这个数字到此结束。其他的 7 个 Bit 才是用来表示数字的内容。因此，小于 128 的数字都可以用一个 Byte 表示；大于 128 的数字，比如 130，会用两个字节来表示。对于每一个字段，使用的是 TLV（Tag，Length，Value）的存储办法。其中 Tag = (field_num &lt;&lt; 3) | wire_type。field_num 就是在 proto 文件中，给每个字段指定唯一的数字标识，而 wire_type 用于标识后面的数据类型。</p><p><img src="https://i.loli.net/2020/02/02/Rvy2MsuzKemHNb6.jpg" alt="fig14.jpg"></p><p>在灵活性方面，这种基于协议文件的二进制压缩协议往往存在更新不方便的问题。例如，客户端和服务器因为需求的改变需要添加或者删除字段。这一点上，Protocol Buffers考虑了兼容性，在上面的协议文件当中，每一个字段都有修饰符，比如：</p><ul><li>required </li><li>optional </li><li>repeated </li></ul><p>如果我们想修改协议文件，对于赋给某个标签的数字，例如 string author=3，这个就不要改变了，改变了就不认了；也不要添加或者删除 required 字段，因为解析的时候，发现没有这个字段就会报错。对于 optional 和 repeated 字段，可以删除，也可以添加。这就给了客户端和服务端升级的可能性。</p><h2 id="5-3-网络传输问题"><a href="#5-3-网络传输问题" class="headerlink" title="5.3 网络传输问题"></a>5.3 网络传输问题</h2><p>假设是Java技术栈，那么gRPC的客户端和服务器之间通过Netty Channel作为数据通道，每个请求都被封装成HTTP2.0的Stream当中。</p><p>Netty是一个搞笑的基于异步IO的网络传输框架，</p><p>HTTP2.0还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。</p><p>通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。</p><p><img src="https://i.loli.net/2020/02/02/bqVPBtkcZwWL5A4.jpg" alt="fig15.jpg"></p><p>由于基于HTTP2.0，gRPC和其他的RPC不同，可以定义四种服务方法。</p><h3 id="5-3-1-单向RPC"><a href="#5-3-1-单向RPC" class="headerlink" title="5.3.1 单向RPC"></a>5.3.1 单向RPC</h3><p>客户端发送一个请求给服务端，从服务端获取一个应答，就像普通的一次函数调用一样。</p><pre><code>rpc SayHello(HelloRequest) returns (HelloResponse){}</code></pre><h3 id="5-3-2-服务端流式RPC"><a href="#5-3-2-服务端流式RPC" class="headerlink" title="5.3.2 服务端流式RPC"></a>5.3.2 服务端流式RPC</h3><p>服务端返回的不是一个结果，而是一批。客户端发送一个请求给服务端，可获取一个数据流用来读取一系列信息。客户端从返回的数据流里一直读取，直到没有更多的消息为止。</p><pre><code>rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse){}</code></pre><h3 id="5-3-3-客户端流式RPC"><a href="#5-3-3-客户端流式RPC" class="headerlink" title="5.3.3 客户端流式RPC"></a>5.3.3 客户端流式RPC</h3><p>客户端的请求不是一个，而是一批，客户端用提供的一个数据流写入并发送一系列消息给服务端。一旦客户端完成消息写入，就等待服务端读取这些消息并返回应答。</p><pre><code>rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) {}</code></pre><h3 id="5-3-4-双向流式RPC"><a href="#5-3-4-双向流式RPC" class="headerlink" title="5.3.4 双向流式RPC"></a>5.3.4 双向流式RPC</h3><p>即两边都可以分别通过一个读写数据流来发送一系列消息。这两个数据流操作是<strong>相互独立</strong>的，所以客户端和服务端<strong>能按其希望的任意顺序读写</strong>，服务端可以在写应答前等待所有的客户端消息，或者它可以先读一个消息再写一个消息，或者读写相结合的其他方式。每个数据流里消息的顺序会被保持。</p><pre><code>rpc BidiHello(stream HelloRequest) returns (stream HelloResponse){}</code></pre><p>如果基于 HTTP  2.0，客户端和服务器之间的交互方式要丰富得多，不仅可以单方向远程调用，还可以实现当服务端状态改变的时候，主动通知客户端。</p><h2 id="5-4-服务发现与治理问题"><a href="#5-4-服务发现与治理问题" class="headerlink" title="5.4 服务发现与治理问题"></a>5.4 服务发现与治理问题</h2><p>gRPC本身没有提供服务发现的机制，需要借助其他的组件，发现要访问的服务端，在多个服务端之间进行容错和负载均衡。</p><p>这个地方的重点问题在于如何发现服务端，并根据服务端的变化，动态修改负载均衡器的配置。</p><h3 id="5-4-1-Envoy配置"><a href="#5-4-1-Envoy配置" class="headerlink" title="5.4.1 Envoy配置"></a>5.4.1 Envoy配置</h3><p>在这里我们介绍一种对于 GRPC 支持比较好的负载均衡器 Envoy。其实 Envoy 不仅仅是负载均衡器，它还是一个高性能的 C++ 写的 Proxy 转发器，可以配置非常灵活的转发规则。</p><p>这些规则可以是静态的，放在配置文件中的，在启动的时候加载。要想重新加载，一般需要重新启动，但是 Envoy 支持热加载和热重启，这在一定程度上缓解了这个问题。</p><p>当然，最好的方式是将规则设置为动态的，放在统一的地方维护。这个统一的地方在 Envoy 眼中被称为服务发现（Discovery Service），过一段时间去这里拿一下配置，就修改了转发策略。</p><p>无论是静态的，还是动态的，在配置里面往往会配置四个东西： </p><ol><li>listener: Envoy既然是Proxy，专门做转发，就得监听一个端口，接入请求，然后才能根据策略转发，这个监听的端口就称为listener.</li><li>endpoint: 是目标的IP地址和端口。这个是proxy最终将请求转发到的地方。</li><li>cluster: 一个cluster是具有完全相同行为的多个endpoint，即如果有三个服务端在运行，就会有三个IP和端口，但是部署的是完全相同的三个服务，它们组成了一个cluster，从cluster到endpoint的过程称为负载均衡，可以轮询。</li><li>route: 有时候多个cluster具有类似的功能，但是是不同的版本，可以通过route规则，选择将请求路由到某一个版本号当中，就到了对应的cluster里面。</li></ol><p>如果是静态的，则将后端的服务端的 IP 地址拿到，然后放在配置文件里面就可以了。</p><p>如果是动态的，就需要配置一个服务发现中心，这个服务发现中心要实现 Envoy 的 API，Envoy 可以主动去服务发现中心拉取转发策略。</p><p><img src="https://i.loli.net/2020/02/02/TFIJXoGlNMCh1Ec.jpg" alt="fig16.jpg"></p><p>看来，Envoy 进程和服务发现中心之间要经常相互通信，互相推送数据，所以 Envoy 在控制面和服务发现中心沟通的时候，就可以使用 GRPC，也就天然具备在用户面支撑 GRPC 的能力。</p><h3 id="5-4-2-Envoy-功能"><a href="#5-4-2-Envoy-功能" class="headerlink" title="5.4.2 Envoy 功能"></a>5.4.2 Envoy 功能</h3><ul><li>配置路由策略</li></ul><p>例如后端的服务有两个版本，可以通过配置 Envoy 的 route，来设置两个版本之间，也即两个 cluster 之间的 route 规则，一个占 99% 的流量，一个占 1% 的流量。</p><ul><li>负载均衡策略</li></ul><p>对于一个 cluster 下的多个endpoint，可以配置负载均衡机制和健康检查机制，当服务端新增了一个，或者挂了一个，都能够及时配置 Envoy，进行负载均衡。</p><p><img src="https://i.loli.net/2020/02/02/E7Qrsp6q2tySUK5.jpg" alt="fig17.jpg"></p><p>所有这些节点的变化都会上传到注册中心，所有这些策略都可以通过注册中心进行下发，所以，更严格的意义上讲，注册中心可以称为注册治理中心。</p><p>Envoy 这么牛，是不是能够将服务之间的相互调用全部由它代理？如果这样，服务也不用像 Dubbo，或者 Spring Cloud 一样，自己感知到注册中心，自己注册，自己治理，对应用干预比较大。</p><p>如果我们的应用能够意识不到服务治理的存在，就是直接进行 GRPC 的调用就可以了。</p><p>这就是未来服务治理的趋势<strong><em>Service Mesh</em></strong>，即应用之间的相互调用全部由Envoy进行代理，服务之间的治理也被Envoy进行代理，完全将服务治理抽象出来，到平台层解决。</p><p><img src="https://i.loli.net/2020/02/02/8naO9kR1dh3K4Cj.jpg" alt="fig18.jpg"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-RPC协议综述&quot;&gt;&lt;a href=&quot;#1-RPC协议综述&quot; class=&quot;headerlink&quot; title=&quot;1. RPC协议综述&quot;&gt;&lt;/a&gt;1. RPC协议综述&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2020/02/02/
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
      <category term="RESTFul" scheme="https://www.llchen60.com/tags/RESTFul/"/>
    
      <category term="RPC" scheme="https://www.llchen60.com/tags/RPC/"/>
    
      <category term="SOAP" scheme="https://www.llchen60.com/tags/SOAP/"/>
    
  </entry>
  
  <entry>
    <title>网络协议(九)-云</title>
    <link href="https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B9%9D-%E4%BA%91/"/>
    <id>https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B9%9D-%E4%BA%91/</id>
    <published>2020-02-02T03:52:09.000Z</published>
    <updated>2020-02-02T06:06:58.014Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-虚拟网卡"><a href="#1-虚拟网卡" class="headerlink" title="1. 虚拟网卡"></a>1. 虚拟网卡</h1><p>数据中心的维护非常复杂麻烦，主要体现在采购，运维，规格，复用等方面。为了解决这个问题，我们发明了虚拟机，并基于它产生了云计算技术。</p><h2 id="1-1-物理机到虚拟机"><a href="#1-1-物理机到虚拟机" class="headerlink" title="1.1 物理机到虚拟机"></a>1.1 物理机到虚拟机</h2><p>软件模拟硬件的方式，数据中心里面用的是qumu-kvm，能让你在一台巨大的物理机里面，掏出一台台小机器。这套软件就能解决上面的问题：一点就能创建，一点就能销毁。想多大就有多大，每次创建的系统都还是新的。</p><p>其实做的事情就和OS做的事情一样，让虚拟机觉得自己在使用独立的设备，占有所有的内存，CPU，网络，硬盘。</p><p>实质上是多个虚拟机轮流使用物理CPU，内存也是使用虚拟内存映射的方式，最终映射到物理内存上。硬盘在一块大的文件系统上创建一个N个G的文件，作为虚拟机的硬盘。</p><h2 id="1-2-虚拟网卡的原理-如何将虚拟机的网络和物理机的网络连接起来？"><a href="#1-2-虚拟网卡的原理-如何将虚拟机的网络和物理机的网络连接起来？" class="headerlink" title="1.2 虚拟网卡的原理 - 如何将虚拟机的网络和物理机的网络连接起来？"></a>1.2 虚拟网卡的原理 - 如何将虚拟机的网络和物理机的网络连接起来？</h2><p><img src="https://i.loli.net/2020/02/02/PkNpQgShKDFRtyx.jpg" alt="fig1.jpg"></p><p>虚拟机是物理机上跑着的一个软件，这个软件可以像其他应用打开文件一样，打开一个称谓TUN/TAP的Char Dev(字符设备文件)。打开了这个字符设备文件之后，在物理机上就能看到一张虚拟TAP网卡。</p><p>虚拟机会打开这个文件，然后在自己的虚拟的身上(hhhh)虚拟出一张网卡，让虚拟机里的应用觉得它们真的有一张网卡。然后，所有的网络包都往这里发。</p><p>当然，网络包会到虚拟化软件这里。它会将网络包转换成为<strong>文件</strong>流，写入字符设备，就像写一个文件一样。内核中 TUN/TAP 字符设备驱动会收到这个写入的文件流，交给 TUN/TAP 的虚拟网卡驱动。这个驱动将文件流再次转成网络包，交给 TCP/IP 协议栈，最终从虚拟 TAP 网卡发出来，成为标准的网络包。这样数据就能从虚拟机里面最终发送到虚拟机的外面。</p><h2 id="1-3-虚拟网卡的连接"><a href="#1-3-虚拟网卡的连接" class="headerlink" title="1.3 虚拟网卡的连接"></a>1.3 虚拟网卡的连接</h2><h3 id="1-3-1-云计算中的网络问题"><a href="#1-3-1-云计算中的网络问题" class="headerlink" title="1.3.1 云计算中的网络问题"></a>1.3.1 云计算中的网络问题</h3><ul><li>共享： 尽管每个虚拟机都会有一个或者多个虚拟网卡，但是物理机可能只有有限的网卡。这么多虚拟网卡如何共享同一个出口？ </li><li>隔离： 安全隔离-同一个机器上的两个虚拟机属于两个用户，怎么保证相互之间不会被窃听？  流量隔离-同一个机器上的两个虚拟机，一个占用大量带宽，另外一个还能上网么？ </li><li>互通： 同一个机器两个虚拟机，同一用户，如何通信？ 不同物理机上两个虚拟机，属于同一个用户的话，这两个如何相互通信？ </li><li>灵活： 虚拟机会经常有创建，删除的操作，或者所有配置的迁移搬运，需要能够进行灵活配置。</li></ul><h3 id="1-3-2-共享与互通的问题"><a href="#1-3-2-共享与互通的问题" class="headerlink" title="1.3.2 共享与互通的问题"></a>1.3.2 共享与互通的问题</h3><ul><li>一台物理机上有多个虚拟机，多个虚拟网卡，这些虚拟网卡如何连接在一起，进行相互访问，并且能够访问外网的呢？ </li></ul><h4 id="1-3-2-1-网桥"><a href="#1-3-2-1-网桥" class="headerlink" title="1.3.2.1 网桥"></a>1.3.2.1 网桥</h4><p>物理机上应该有一个虚拟的交换机，通过创建虚拟的网桥  <code>brctl addbr br0</code> 将几个虚拟机的虚拟网卡都连接到虚拟网桥brctl addif br0 tap0上，这样讲两个虚拟机配置相同的子网网段，两台虚拟机就能够相互通信了。</p><p><img src="https://i.loli.net/2020/02/02/f9AW6sK2tF4qNMO.jpg" alt="fig2.jpg"></p><p>要让几台虚拟机都能访问外网，可以采用桥接的方式，形成以下的结构：</p><p><img src="https://i.loli.net/2020/02/02/WA1KMhrXbvt4ke9.jpg" alt="fig3.jpg"></p><p>这个时候如果你去看你的IP地址，会发现你的虚拟机的地址和你的笔记本电脑和你旁边的人的网段是一致的。因为网桥将这几个都连接起来了。在数据中心里面，采取的也是类似的技术，只不过都是 Linux，在每台机器上都创建网桥 br0，虚拟机的网卡都连到 br0 上，物理网卡也连到br0上，所有的br0都通过物理网卡出来连接到物理交换机上。</p><p><img src="https://i.loli.net/2020/02/02/HyPYxt9M5Ob2gJd.jpg" alt="fig4.jpg"><br><img src="https://i.loli.net/2020/02/02/nkVRqf7bU1YtDPi.jpg" alt="fig9.jpg"></p><p>你还记得吗？在一个二层网络里面，最大的问题是广播。一个数据中心的物理机已经很多了，广播已经非常严重，需要通过 VLAN 进行划分。如果使用了虚拟机，假设一台物理机里面创建 10 台虚拟机，全部在一个二层网络里面，那广播就会很严重，所以除非是你的桌面虚拟机或者数据中心规模非常小，才可以使用这种相对简单的方式。</p><h4 id="1-3-2-2-NAT"><a href="#1-3-2-2-NAT" class="headerlink" title="1.3.2.2 NAT"></a>1.3.2.2 NAT</h4><p><img src="https://i.loli.net/2020/02/02/rnV3TutSEp9Z72B.jpg" alt="fig5.jpg"></p><p>在这种方式下，你登录到虚拟机里面查看 IP 地址，会发现虚拟机的网络是虚拟机的，物理机的网络是物理机的，两个不相同。虚拟机要想访问物理机的时候，需要将地址 NAT 成为物理机的地址。</p><p>除此之外，它还会在你的笔记本电脑里内置一个 DHCP 服务器，为笔记本电脑上的虚拟机动态分配 IP 地址。因为虚拟机的网络自成体系，需要进行 IP 管理。为什么桥接方式不需要呢？因为桥接将网络打平了，虚拟机的 IP 地址应该由物理网络的 DHCP 服务器分配。</p><p><img src="https://i.loli.net/2020/02/02/9PSTLm8MdbO6f3v.jpg" alt="fig6.jpg"></p><p>虚拟机是你的电脑，路由器和 DHCP Server 相当于家用路由器或者寝室长的电脑，物理网卡相当于你们宿舍的外网网口，用于访问互联网。所有电脑都通过内网网口连接到一个网桥 br0 上，虚拟机要想访问互联网，需要通过 br0 连到路由器上，然后通过路由器将请求 NAT 成为物理网络的地址，转发到物理网络。</p><p>如果是你自己登录到物理机上做个简单配置，你可以简化一下。例如将虚拟机所在网络的网关的地址直接配置到 br0 上，不用 DHCP Server，手动配置每台虚拟机的 IP 地址，通过命令 iptables -t nat -A POSTROUTING -o ethX -j MASQUERADE，直接在物理网卡 ethX 上进行 NAT，所有从这个网卡出去的包都 NAT 成这个网卡的地址。通过设置 net.ipv4.ip_forward = 1，开启物理机的转发功能，直接做路由器，而不用单独的路由器，这样虚拟机就能直接上网了。</p><p><img src="https://i.loli.net/2020/02/02/6nB4Z2ekyQMivqP.jpg" alt="fig7.jpg"></p><h2 id="1-3-3-隔离问题"><a href="#1-3-3-隔离问题" class="headerlink" title="1.3.3 隔离问题"></a>1.3.3 隔离问题</h2><p>如果一台机器上的两个虚拟机不属于同一个用户，怎么办呢？好在 brctl 创建的网桥也是支持 VLAN 功能的，可以设置两个虚拟机的 tag，这样在这个虚拟网桥上，两个虚拟机是不互通的。</p><p>但是如何跨物理机互通，并且实现 VLAN 的隔离呢？由于 brctl 创建的网桥上面的 tag 是没办法在网桥之外的范围内起作用的，于是我们需要寻找其他的方式。</p><p>有一个命令<code>vconfig</code>，可以基于物理网卡eth0创建带VLAN的虚拟网卡，所有从这个虚拟网卡出去的包，都带这个VLAN，如果这样跨物理机的互通和隔离就可以通过这个网卡来实现了。</p><p><img src="https://i.loli.net/2020/02/02/HtvwWh5iqmpDfze.jpg" alt="fig8.jpg"></p><p>首先为每个用户分配不同的 VLAN，例如有一个用户 VLAN 10，一个用户 VLAN 20。在一台物理机上，基于物理网卡，为每个用户用 vconfig 创建一个带 VLAN 的网卡。不同的用户使用不同的虚拟网桥，带 VLAN 的虚拟网卡也连接到虚拟网桥上。</p><p>这样是否能保证两个用户的隔离性呢？不同的用户由于网桥不通，不能相互通信，一旦出了网桥，由于 VLAN 不同，也不会将包转发到另一个网桥上。另外，出了物理机，也是带着 VLAN ID 的。只要物理交换机也是支持 VLAN 的，到达另一台物理机的时候，VLAN ID 依然在，它只会将包转发给相同 VLAN 的网卡和网桥，所以跨物理机，不同的 VLAN 也不会相互通信。</p><p>使用 brctl 创建出来的网桥功能是简单的，基于 VLAN 的虚拟网卡也能实现简单的隔离。但是这都不是大规模云平台能够满足的，一个是 VLAN 的隔离，数目太少。前面我们学过，VLAN ID 只有 4096 个，明显不够用。另外一点是这个配置不够灵活。谁和谁通，谁和谁不通，流量的隔离也没有实现，还有大量改进的空间。</p><h1 id="2-云中网络Qos"><a href="#2-云中网络Qos" class="headerlink" title="2. 云中网络Qos"></a>2. 云中网络Qos</h1><p>流量控制技术，来实现Quality of Service,从而保障大多数人的服务质量</p><p><img src="https://i.loli.net/2020/02/02/joSwOU5tpml7a6n.jpg" alt="fig10.jpg"></p><p>我们能控制的只有出方向，通过Shaping，将出的流量控制成自己想要的模样。而进入的方向无法控制，只能通过Policy将包丢弃。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-虚拟网卡&quot;&gt;&lt;a href=&quot;#1-虚拟网卡&quot; class=&quot;headerlink&quot; title=&quot;1. 虚拟网卡&quot;&gt;&lt;/a&gt;1. 虚拟网卡&lt;/h1&gt;&lt;p&gt;数据中心的维护非常复杂麻烦，主要体现在采购，运维，规格，复用等方面。为了解决这个问题，我们发明了虚拟机，
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
      <category term="Cloud" scheme="https://www.llchen60.com/tags/Cloud/"/>
    
  </entry>
  
  <entry>
    <title>网络协议(八)-数据中心, VPN, 移动网络</title>
    <link href="https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AB-%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83-VPN-%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C/"/>
    <id>https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AB-%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83-VPN-%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C/</id>
    <published>2020-02-02T03:44:17.000Z</published>
    <updated>2020-02-02T06:06:58.015Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-数据中心"><a href="#1-数据中心" class="headerlink" title="1. 数据中心"></a>1. 数据中心</h1><p>数据中心里都是服务器，放在机架上(Rack)。数据中心的出口和入口也是路由器，多个边界路由器使其可用性更高。</p><p>为了高可用性，数据中心的边界路由器会连接多个运营商网络。</p><p>对于各个机架上的服务器，需要用交换机进行连接，TOR(Top of Rack)。</p><p><img src="https://i.loli.net/2020/02/02/PudyE2nb3oJ8ARr.jpg" alt="fig1.jpg"></p><p>当一个机架放不下的时候，就需要多个机架，并使用交换机将多个机架连接起来。这些交换机称为汇聚层交换机。</p><p>数据中心的服务器需要有至少两个网卡，保证可用性。对网卡要进行网卡绑定的操作。</p><p>这就需要服务器和交换机都支持一种协议，LACP, Link Aggregation Control Protocol。互相通信，将多个网卡聚合成一个网卡，多个网线聚合成一个网线，在网线之间可以进行负载均衡，也可以为高可用作准备。</p><p><img src="https://i.loli.net/2020/02/02/81kG3HRJU4KfYWE.jpg" alt="fig2.jpg"></p><p>交换机有一种技术叫作堆叠，将多个交换机形成一个逻辑的交换机，服务器通过多根线分配连到多个接入层交换机上，而接入层交换机多根线分别连接到多个交换机上，并且通过堆叠的私有协议，形成双活的连接方式。</p><p><img src="https://i.loli.net/2020/02/02/8nGwLsV6ziAWIgP.jpg" alt="fig3.jpg"></p><p>汇聚层将大量的节点相互连接在一起，形成了一个集群。在这个集群里面，服务器之间通过二层互通，这个区域成为一个POD(Point of Delivery)， 又称为可用区(Available Zone). </p><p>当节点数目再多的时候，一个可用区放不下，需要将多个可用区连在一起，连接多个可用区的交换机称为核心交换机。</p><p><img src="https://i.loli.net/2020/02/02/GcgNHiBLT9OUey1.jpg" alt="fig4.jpg"></p><p><img src="https://i.loli.net/2020/02/02/G2qbpI8MNBdTCVr.jpg" alt="fig5.jpg"></p><h1 id="2-VPN"><a href="#2-VPN" class="headerlink" title="2. VPN"></a>2. VPN</h1><p><img src="https://i.loli.net/2020/02/02/qwKnYlM3y4saCHr.jpg" alt="fig6.jpg"></p><p>VPN(Virtual Private Network)， 虚拟专用网，就是利用开放的公众网络，建立专用数据传输通道，将远程的分支机构、移动办公人员连接起来。</p><h2 id="2-1-VPN是如何工作的"><a href="#2-1-VPN是如何工作的" class="headerlink" title="2.1 VPN是如何工作的"></a>2.1 VPN是如何工作的</h2><p>VPN通过隧道技术在公众网络上仿真一条点到点的专线，是通过一种协议来传输另外一种协议的技术：这里面涉及三种协议：乘客协议、隧道协议、承载协议。</p><p>以IPsec协议为例说明</p><p><img src="https://i.loli.net/2020/02/02/3rCDzlsnipXjH8A.jpg" alt="fig7.jpg"></p><p>IPsec VPN, 是基于IP协议的安全隧道协议，为了保证在公网上信息的安全，因而采取了一定的机制保证安全性。</p><h2 id="2-2-VPN-采取的保证安全的机制"><a href="#2-2-VPN-采取的保证安全的机制" class="headerlink" title="2.2 VPN 采取的保证安全的机制"></a>2.2 VPN 采取的保证安全的机制</h2><ol><li>私密性</li></ol><p>通过加密把数据从明文编程无法读懂的密文，从而确保数据的私密性。采用对称加密， 因为VPN一旦建立，是需要传输大量数据的。</p><p>存在加密密钥如何传输的问题，这里需要用到因特网密钥交换协议(IKE, Internet Key Exchange)。</p><ol start="2"><li>完整性</li></ol><p>数据没有被非法篡改，通过对数据进行hash运算，产生类似于指纹的数据摘要，以保证数据的完整性</p><ol start="3"><li>真实性</li></ol><p>数据确实是由特定的对端发出，通过身份认证可以保证数据的真实性。</p><ol start="4"><li>保证对方真实的方式</li></ol><ul><li>预共享秘钥</li><li>数字签名验证</li></ul><h2 id="2-3-IPsec-VPN协议"><a href="#2-3-IPsec-VPN协议" class="headerlink" title="2.3 IPsec VPN协议"></a>2.3 IPsec VPN协议</h2><p><img src="https://i.loli.net/2020/02/02/PXUnhNDlZmbHi6L.jpg" alt="fig8.jpg"></p><p>在这个协议族里面，有两种协议，区别在于封装网络 包的格式不一样。</p><ul><li>AH(Authentication Header)，只能进行数据摘要，不能实现数据加密</li><li>ESP(Encapsulating Security Payload), 能够进行数据加密和数据摘要</li></ul><p>在这个协议族里，有加密算法和摘要算法。包含了两大组件，一个用于VPN的双方要进行对称密钥交换的IKE组件，另一个是VPN的双方要对连接进行维护的SA(Security Association) 组件。</p><h2 id="2-4-IPsec-VPN-建立过程"><a href="#2-4-IPsec-VPN-建立过程" class="headerlink" title="2.4 IPsec VPN 建立过程"></a>2.4 IPsec VPN 建立过程</h2><h3 id="2-4-1-建立IKE自己的SA-Security-Association"><a href="#2-4-1-建立IKE自己的SA-Security-Association" class="headerlink" title="2.4.1 建立IKE自己的SA(Security Association)"></a>2.4.1 建立IKE自己的SA(Security Association)</h3><p>用来维护一个通过身份认证和安全保护的通道，为第二个阶段提供服务。通过DH(Diffie-Hellman)算法计算出一个对称密钥K。</p><p>DH算法很巧妙。客户端和服务端约定两个公开的质数p和q，然后客户端随机产生一个数a作为自己的私钥，服务端随机产生一个b作为自己的私钥，客户端可以根据p q a计算出公钥A，服务端根据p，q，b计算出公钥B，然后双方交换公钥A和B。</p><p>至此客户端和服务e端可以根据已有信息，各自独立算出相同的结果K，就是对称密钥。但是这个过程当中，对称密钥从来没有在通道上传输过，只传输了生成密钥的材料。截获的人根本无法算出到底是生成了什么数字。</p><p><img src="https://i.loli.net/2020/02/02/mowAje5ZFLitCfJ.jpg" alt="fig9.jpg"></p><h3 id="2-4-2-建立IPsec-SA"><a href="#2-4-2-建立IPsec-SA" class="headerlink" title="2.4.2 建立IPsec SA"></a>2.4.2 建立IPsec SA</h3><p>在这个SA里面，双方会生成一个随机的对称密钥M，由K加密传给对方，然后使用M进行双方接下来通信的数据。对称密钥M是有过期时间的，会过一段时间，重新生成一次，从而防止被破解。</p><p>IPsec SA 里面有以下内容：</p><ul><li>SPI(Security Parameter Index),用于标识不同的连接</li><li>双方商量好的加密算法，哈希算法和封装算法</li><li>生存周期，超过这个周期，就要重新生成一个IPsec SA，重新生成对称密钥</li></ul><p><img src="https://i.loli.net/2020/02/02/RfP8cp4zw9KT27G.jpg" alt="fig10.jpg"></p><p>当IPsec建立好，接下来就可以开始打包封装传输了。</p><p><img src="https://i.loli.net/2020/02/02/NlPSm6hzrvQxAcj.jpg" alt="fig11.jpg"></p><p>左面是原始的 IP 包，在 IP 头里面，会指定上一层的协议为 TCP。ESP 要对 IP 包进行封装，因而 IP 头里面的上一层协议为 ESP。在 ESP 的正文里面，ESP 的头部有双方商讨好的 SPI，以及这次传输的序列号。</p><p>接下来全部是加密的内容。可以通过对称密钥进行解密，解密后在正文的最后，指明了里面的协议是什么。如果是 IP，则需要先解析 IP 头，然后解析 TCP 头，这是从隧道出来后解封装的过程。</p><p>有了 IPsec VPN 之后，客户端发送的明文的 IP 包，都会被加上 ESP 头和 IP 头，在公网上传输，由于加密，可以保证不被窃取，到了对端后，去掉 ESP 的头，进行解密。</p><p><img src="https://i.loli.net/2020/02/02/muPYyMVGEKWLFz6.jpg" alt="fig12.jpg"></p><p>这种点对点的基于 IP 的 VPN，能满足互通的要求，但是速度往往比较慢，这是由底层 IP 协议的特性决定的。IP 不是面向连接的，是尽力而为的协议，每个 IP 包自由选择路径，到每一个路由器，都自己去找下一跳，丢了就丢了，是靠上一层 TCP 的重发来保证可靠性。</p><p><img src="https://i.loli.net/2020/02/02/TSRuA7tq8eLphHZ.jpg" alt="fig13.jpg"></p><p>因为 IP 网络从设计的时候，就认为是不可靠的，所以即使同一个连接，也可能选择不同的道路，这样的好处是，一条道路崩溃的时候，总有其他的路可以走。当然，带来的代价就是，不断的路由查找，效率比较差。</p><p>和 IP 对应的另一种技术称为 ATM。这种协议和 IP 协议的不同在于，它是面向连接的。你可以说 TCP 也是面向连接的啊。这两个不同，ATM 和 IP 是一个层次的，和 TCP 不是一个层次的。</p><p>另外，TCP 所谓的面向连接，是不停地重试来保证成功，其实下层的 IP 还是不面向连接的，丢了就丢了。ATM 是传输之前先建立一个连接，形成一个虚拟的通路，一旦连接建立了，所有的包都按照相同的路径走，不会分头行事。</p><p><img src="https://i.loli.net/2020/02/02/u36xtoN72KkBGQZ.jpg" alt="fig14.jpg"></p><p>ATM的好处是不需要每次都查路由表了，虚拟路径已经建立，打上了标签，后续的包跟着走就可以了；但是一旦虚拟路径上的某个路由器坏了，那么这个连接就断了.</p><h2 id="2-4-3-多协议标签交换-MPLS-Multi-Protocol-Label-Switching"><a href="#2-4-3-多协议标签交换-MPLS-Multi-Protocol-Label-Switching" class="headerlink" title="2.4.3 多协议标签交换(MPLS, Multi-Protocol Label Switching)"></a>2.4.3 多协议标签交换(MPLS, Multi-Protocol Label Switching)</h2><p>这种协议可以结合IP和ATM协议的优点，其结构是在原始的IP头之外，多了MPLS的头，里面可以打标签。</p><p><img src="https://i.loli.net/2020/02/02/WxC8o6wYshu1bSJ.jpg" alt="fig15.jpg"></p><p>在 MPLS 头里面，首先是标签值占 20 位，接着是 3 位实验位，再接下来是 1 位栈底标志位，表示当前标签是否位于栈底了。这样就允许多个标签被编码到同一个数据包中，形成标签栈。最后是 8 位 TTL 存活时间字段，如果标签数据包的出发 TTL 值为 0，那么该数据包在网络中的生命期被认为已经过期了。</p><p>有了标签，还需要设备认这个标签，并且能够根据这个标签转发，这种能够转发标签的路由器称为标签交换路由器(LSR, Label Switching Router).</p><p>这种路由器会有两个表格，一个是传统的FIB，路由表，另外一个就是LFIB，标签转发表。有着这两个表，就既可以进行普通的路由转发，也可以进行基于标签的转发。</p><p><img src="https://i.loli.net/2020/02/02/p2WM8XwjtuLRxNn.jpg" alt="fig16.jpg"></p><p>有了标签转发表，转发的过程如图所示，不需要每次都进行普通路由的查找了。</p><p>这里我们区分 MPLS 区域和非 MPLS 区域。在 MPLS 区域中间，使用标签进行转发，非 MPLS 区域，使用普通路由转发，在边缘节点上，需要有能力将对于普通路由的转发，变成对于标签的转发。</p><p>例如图中要访问 114.1.1.1，在边界上查找普通路由，发现马上要进入 MPLS 区域了，进去了对应标签 1，于是在 IP 头外面加一个标签 1，在区域里面，标签 1 要变成标签 3，标签 3 到达出口边缘，将标签去掉，按照路由发出。</p><p>这样一个通过标签转化而建立的路径称为LSP，标签交换路径。在一条LSP上，沿数据包传送的方向，相邻的LSR分别叫做上游LSR(upstream LSR), 和下游LSR(downstream LSR).</p><p>MPLS有个动态生成标签的协议, LDP(Label Distribution Protocol)。 其实 LDP 与 IP 帮派中的路由协议十分相像，通过 LSR 的交互，互相告知去哪里应该打哪个标签，称为标签分发，往往是从下游开始的。</p><p><img src="https://i.loli.net/2020/02/02/dVlJvoAQfKLSwsb.jpg" alt="fig17.jpg"></p><p>如果有一个边缘节点发现自己的路由表中出现了新的目的地址，它就要给别人说，我能到达一条新的路径了。</p><p>如果此边缘节点存在上游 LSR，并且尚有可供分配的标签，则该节点为新的路径分配标签，并向上游发出标签映射消息，其中包含分配的标签等信息。</p><p>收到标签映射消息的 LSR 记录相应的标签映射信息，在其标签转发表中增加相应的条目。此 LSR 为它的上游 LSR 分配标签，并继续向上游 LSR 发送标签映射消息。</p><p>当入口 LSR 收到标签映射消息时，在标签转发表中增加相应的条目。这时，就完成了 LSP 的建立。有了标签，转发轻松多了，但是这个和 VPN 什么关系呢？</p><p>可以想象，如果我们 VPN 通道里面包的转发，都是通过标签的方式进行，效率就会高很多。所以要想个办法把 MPLS 应用于 VPN。</p><p><img src="https://i.loli.net/2020/02/02/9F5D3xSad7PzhYw.jpg" alt="fig18.jpg"></p><p>在MPLS VPN中，网络中的路由器分成以下几类：</p><ul><li>PE (Provider Edge): 运营商网络与客户网络相连的边缘网络设备</li><li>CE (Customer Edge): 客户网络与PE相连接的边缘设备</li><li>P (Provider): 指运营商网络中除了PE以外的其他运营商网络设备</li></ul><p>为什么要这样分呢？因为我们发现，在运营商网络里面，也即 P Router 之间，使用标签是没有问题的，因为都在运营商的管控之下，对于网段，路由都可以自己控制。但是一旦客户要接入这个网络，就复杂得多。</p><p>首先是客户地址重复的问题。客户所使用的大多数都是私网的地址 (192.168.X.X;10.X.X.X;172.X.X.X)，而且很多情况下都会与其它的客户重复。</p><p>比如，机构 A 和机构 B 都使用了 192.168.101.0/24 网段的地址，这就发生了地址空间重叠（Overlapping Address Spaces）。</p><p>首先困惑的是 BGP 协议，既然 VPN 将两个数据中心连起来，应该看起来像一个数据中心一样，那么如何到达另一端需要通过 BGP 将路由广播过去，传统 BGP 无法正确处理地址空间重叠的 VPN 的路由。</p><p>假设机构 A 和机构 B 都使用了 192.168.101.0/24 网段的地址，并各自发布了一条去往此网段的路由，BGP 将只会选择其中一条路由，从而导致去往另一个 VPN 的路由丢失。</p><p>所以 PE 路由器之间使用特殊的 MP-BGP 来发布 VPN 路由，在相互沟通的消息中，在一般 32 位 IPv4 的地址之前加上一个客户标示的区分符用于客户地址的区分，这种称为 VPN-IPv4 地址族，这样 PE 路由器会收到如下的消息，机构 A 的 192.168.101.0/24 应该往这面走，机构 B 的 192.168.101.0/24 则应该去另外一个方向。</p><p>另外一个困惑是路由表，当两个客户的IP包到达PE的时候，PE就困惑了，因为网段是重复的。如何区分哪些路由是属于哪些客户 VPN 内的？如何保证 VPN 业务路由与普通路由不相互干扰？</p><p>在 PE 上，可以通过 VRF（VPN Routing&amp;Forwarding Instance）建立每个客户一个路由表，与其它 VPN 客户路由和普通路由相互区分。可以理解为专属于客户的小路由器。</p><p>远端 PE 通过 MP-BGP 协议把业务路由放到近端 PE，近端 PE 根据不同的客户选择出相关客户的业务路由放到相应的 VRF 路由表中。</p><p>VPN报文转发采用两层标签的方式：</p><ul><li>第一层（外层）标签在骨干网内部进行交换，指示从 PE 到对端 PE 的一条 LSP。VPN 报文利用这层标签，可以沿 LSP 到达对端 PE；</li><li>第二层（内层）标签在从对端 PE 到达 CE 时使用，在 PE 上，通过查找 VRF 表项，指示报文应被送到哪个 VPN 用户，或者更具体一些，到达哪一个 CE。这样，对端 PE 根据内层标签可以找到转发报文的接口。</li></ul><p><img src="https://i.loli.net/2020/02/02/fTPFVvbBgOxsqE5.jpg" alt="fig19.jpg"></p><p>举例说明MPLS VPN的包发送过程</p><ol><li>机构 A 和机构 B 都发出一个目的地址为 192.168.101.0/24 的 IP 报文，分别由各自的 CE 将报文发送至 PE。</li><li>PE 会根据报文到达的接口及目的地址查找 VPN 实例表项 VRF，匹配后将报文转发出去，同时打上内层和外层两个标签。假设通过 MP-BGP 配置的路由，两个报文在骨干网走相同的路径。</li><li>MPLS 网络利用报文的外层标签，将报文传送到出口 PE，报文在到达出口 PE 2 前一跳时已经被剥离外层标签，仅含内层标签。</li><li>出口 PE 根据内层标签和目的地址查找 VPN 实例表项 VRF，确定报文的出接口，将报文转发至各自的 CE。</li><li>CE 根据正常的 IP 转发过程将报文传送到目的地。</li></ol><h1 id="3-移动网络"><a href="#3-移动网络" class="headerlink" title="3. 移动网络"></a>3. 移动网络</h1><p>研究下手机上网的场景：</p><h2 id="3-1-2G网络"><a href="#3-1-2G网络" class="headerlink" title="3.1 2G网络"></a>3.1 2G网络</h2><p>2G时代上网不是使用的IP网络，而是电话网络，走模拟信号，叫做公共交换电话网(PSTN, Public Switched Telephone Network)</p><p>手机通过收发无线信号来通信，成为Mobile Station， 简称MS，需要嵌入SIM。手机是客户端，而无线信号的服务端，就是基站子系统(BBS, Base Station SubsystemBSS).</p><blockquote><p>无论无线通信如何无线，最终还要连接到有线网络里。</p></blockquote><p>因而，基站子系统分两部分，一部分对外提供无线通信，叫作基站收发信台（BTS，Base Transceiver Station），另一部分对内连接有线网络，叫作基站控制器（BSC，Base Station Controller）。基站收发信台通过无线收到数据后，转发给基站控制器。</p><p>这部分属于无线的部分，统称为无线接入网（RAN，Radio Access Network）。</p><p>基站控制器通过有线网络，连接到提供手机业务的运营商的数据中心，这部分称为核心网（CN，Core Network）。核心网还没有真的进入互联网，这部分还是主要提供手机业务，是手机业务的有线部分。</p><p>首先接待基站来的数据的是移动业务交换中心（MSC，Mobile Service Switching Center），它是进入核心网的入口，但是它不会让你直接连接到互联网上。</p><p>因为在让你的手机真正进入互联网之前，提供手机业务的运营商，需要认证是不是合法的手机接入。别你自己造了一张手机卡，就连接上来。鉴权中心（AUC，Authentication Center）和设备识别寄存器（EIR，Equipment Identity Register）主要是负责安全性的。</p><p>另外，需要看你是本地的号，还是外地的号，这个牵扯到计费的问题，异地收费还是很贵的。访问位置寄存器（VLR，Visit Location Register）是看你目前在的地方，归属位置寄存器（HLR，Home Location Register）是看你的号码归属地。</p><p>当你的手机卡既合法又有钱的时候，才允许你上网，这个时候需要一个网关，连接核心网和真正的互联网。网关移动交换中心（GMSC ，Gateway Mobile Switching Center）就是干这个的，然后是真正的互连网。在 2G 时代，还是电话网络 PSTN。</p><p>数据中心里的这些模块统称为网络子系统(NSS, Network and Switching Subsystem)</p><p><img src="https://i.loli.net/2020/02/02/SOJQsF8LxMjBkia.jpg" alt="fig20.jpg"></p><p>2G时代的上网，有几个核心点：</p><ul><li>手机通过无线信号连接基站；</li><li>基站一面朝前接无线，一面朝后接核心网；</li><li>核心网一面朝前接到基站请求，一是判断你是否合法，二是判断你是不是本地号，还有没有钱，一面通过网关连接电话网络。</li></ul><h2 id="3-2-2-5G网络"><a href="#3-2-2-5G网络" class="headerlink" title="3.2 2.5G网络"></a>3.2 2.5G网络</h2><p>后来从 2G 到了 2.5G，也即在原来电路交换的基础上，加入了分组交换业务，支持 Packet 的转发，从而支持 IP 网络。</p><p>在上述网络的基础上，基站一面朝前接无线，一面朝后接核心网。在朝后的组件中，多了一个分组控制单元（PCU，Packet Control Unit），用以提供分组交换通道。</p><p>在核心网里面，有个朝前的接待员（SGSN，Service GPRS Supported Node）和朝后连接 IP 网络的网关型 GPRS 支持节点（GGSN，Gateway GPRS Supported Node）。</p><p><img src="https://i.loli.net/2020/02/02/6G2FysU1h7YvZNr.jpg" alt="fig21.jpg"></p><h2 id="3-3-3G网络"><a href="#3-3-3G网络" class="headerlink" title="3.3 3G网络"></a>3.3 3G网络</h2><p>到了 3G 时代，主要是无线通信技术有了改进，大大增加了无线的带宽。</p><p>以 W-CDMA 为例，理论最高 2M 的下行速度，因而基站改变了，一面朝外的是 Node  B，一面朝内连接核心网的是无线网络控制器（RNC，Radio Network Controller）。核心网以及连接的 IP 网络没有什么变化。</p><p><img src="https://i.loli.net/2020/02/02/3oOgzejCiLG86Sk.jpg" alt="fig22.jpg"></p><h2 id="3-4-4G网络"><a href="#3-4-4G网络" class="headerlink" title="3.4 4G网络"></a>3.4 4G网络</h2><p><img src="https://i.loli.net/2020/02/02/vAWC6fOwgQmSa37.jpg" alt="fig30.jpg"></p><p>4G网络的协议相对复杂了很多：</p><p><img src="https://i.loli.net/2020/02/02/pJBhu8y2LR6FSrV.jpg" alt="fig23.jpg"></p><h3 id="3-4-1-控制面协议"><a href="#3-4-1-控制面协议" class="headerlink" title="3.4.1 控制面协议"></a>3.4.1 控制面协议</h3><p>其中虚线部分是控制面的协议。当一个手机想上网的时候，先要连接 eNodeB，并通过 S1-MME 接口，请求 MME 对这个手机进行认证和鉴权。S1-MME 协议栈如下图所示。</p><p><img src="https://i.loli.net/2020/02/02/LCZHKxFuf1tJbBd.jpg" alt="fig24.jpg"></p><p>UE是手机，eNodeB朝前对接无线网络，朝后对接核心网络，在控制面对接的是MME。</p><p>eNode与MME之间的连接是靠IP网络，而在IP层上，是用的SCTP。这是面向连接的传输层的协议，更适合移动网络。继承了TCP较为完善的拥塞控制，并改进了TCP的不足之处。</p><p>SCTP特点是多宿主，引入了联合的概念，将多个接口、多条路径放到一个association当中，当检测到一条路径失效时，协议就会从另外一条路径来发送通信数据。应用程序甚至不必知道发生了故障和恢复，从而提供更高的可用性和可靠性。</p><p>SCTP还可以将一个联合分成多个流。一个联合中的所有流都是独立的，但均与这个联合相关。每个流都给定了一个流编号，被编码到SCTP报文当中，通过联合在网络上传送。在TCP的机制当中，由于强制顺序，导致前一个不到达，后一个就得等待，SCTP的多个流不会相互阻塞。</p><p>SCP还可以进行四次握手，防止 SYN 攻击。在 TCP 中是三次握手，当服务端收到客户的 SYN 之后，返回一个 SYN-ACK 之前，就建立数据结构，并记录下状态，等待客户端发送 ACK 的 ACK。当恶意客户端使用虚假的源地址来伪造大量 SYN 报文时，服务端需要分配大量的资源，最终耗尽资源，无法处理新的请求。</p><p>SCTP 可以通过四次握手引入 Cookie 的概念，来有效地防止这种攻击的产生。在 SCTP 中，客户机使用一个 INIT 报文发起一个连接。服务器使用一个 INIT-ACK 报文进行响应，其中就包括了 Cookie。然后客户端就使用一个 COOKIE-ECHO 报文进行响应，其中包含了服务器所发送的 Cookie。这个时候，服务器为这个连接分配资源，并通过向客户机发送一个 COOKIE-ACK 报文对其进行响应。</p><p>SCTP还可以对信息进行分帧。TCP是面向流的，即发送的数据没头没尾，没有明显的界限。这对于发送数据没有什么大问题，但是对于发送一个个消息类型的数据，就不太方便了。有可能客户端写入10个字节，再写入20个。服务端不是按照10-20来读的，而是先25个字节，再读入5个字节，需要业务层去组合成消息。</p><p>SCTP借鉴了UDP的机制，在数据传输中提供了消息分帧功能。当一端对一个套接字执行写操作时，可确保对等端读出的数据大小与此相同。 </p><p>SCTP在断开连接的时候是三次挥手。在TCP里面，断开连接是四次挥手，云溪另一端处于半关闭的状态。SCTP选择放弃这种状态，当一端关闭自己的套接字的时候，对等的两端全部需要关闭，将来任何一端都不允许再进行数据的移动了。</p><p>当 MME 通过认证鉴权，同意这个手机上网的时候，需要建立一个数据面的数据通路。建立通路的过程还是控制面的事情，因而使用的是控制面的协议 GTP-C。</p><p>建设的数据通路分两段路，其实是两个隧道。一段是从 eNodeB 到 SGW，这个数据通路由 MME 通过 S1-MME 协议告诉 eNodeB，它是隧道的一端，通过 S11 告诉 SGW，它是隧道的另一端。第二端是从 SGW 到 PGW，SGW 通过 S11 协议知道自己是其中一端，并主动通过 S5 协议，告诉 PGW 它是隧道的另一端。</p><p>GTP-C协议是基于UDP的，如果看GTP的头，可以看到里面有隧道的ID还有序列号。 </p><p><img src="https://i.loli.net/2020/02/02/wHfyhS7pLVe1RQl.jpg" alt="fig25.jpg"></p><h3 id="3-4-2-数据面协议"><a href="#3-4-2-数据面协议" class="headerlink" title="3.4.2 数据面协议"></a>3.4.2 数据面协议</h3><p>当两个隧道都打通，接在一起的时候，PGW 会给手机分配一个 IP 地址，这个 IP 地址是隧道内部的 IP 地址，可以类比为 IPsec 协议里面的 IP 地址。这个 IP 地址是归手机运营商管理的。然后，手机可以使用这个 IP 地址，连接 eNodeB，从 eNodeB 经过 S1-U 协议，通过第一段隧道到达 SGW，再从 SGW 经过 S8 协议，通过第二段隧道到达 PGW，然后通过 PGW 连接到互联网。</p><p>数据面的协议通过GTP-U, 如图所示：</p><p><img src="https://i.loli.net/2020/02/02/4eWXgcECuIbB3qk.jpg" alt="fig26.jpg"></p><p>手机每发出一个包，都由GTP-U隧道协议封装起来：</p><p><img src="https://i.loli.net/2020/02/02/WIgOKsLhw7tRpX8.jpg" alt="fig27.jpg"></p><p>和 IPsec 协议很类似，分为乘客协议、隧道协议、承载协议。其中乘客协议是手机发出来的包，IP 是手机的 IP，隧道协议里面有隧道 ID，不同的手机上线会建立不同的隧道，因而需要隧道 ID 来标识。承载协议的 IP 地址是 SGW 和 PGW 的 IP 地址。</p><h3 id="3-4-3-手机上网流程"><a href="#3-4-3-手机上网流程" class="headerlink" title="3.4.3 手机上网流程"></a>3.4.3 手机上网流程</h3><p>Attach:</p><p><img src="https://i.loli.net/2020/02/02/hwtE7aFNjqgSOCu.jpg" alt="fig28.jpg"></p><ol><li>手机开机以后，在附近寻找基站 eNodeB，找到后给 eNodeB 发送 Attach Request，说“我来啦，我要上网”。</li><li>eNodeB 将请求发给 MME，说“有个手机要上网”。</li><li>MME 去请求手机，一是认证，二是鉴权，还会请求 HSS 看看有没有钱，看看是在哪里上网。</li><li>当 MME 通过了手机的认证之后，开始分配隧道，先告诉 SGW，说要创建一个会话（Create Session）。在这里面，会给 SGW 分配一个隧道 ID  t1，并且请求 SGW 给自己也分配一个隧道 ID。</li><li>SGW 转头向 PGW 请求建立一个会话，为 PGW 的控制面分配一个隧道 ID  t2，也给 PGW 的数据面分配一个隧道 ID  t3，并且请求 PGW 给自己的控制面和数据面分配隧道 ID。</li><li>PGW 回复 SGW 说“创建会话成功”，使用自己的控制面隧道 ID t2，回复里面携带着给 SGW 控制面分配的隧道 ID  t4 和控制面的隧道 ID  t5，至此 SGW 和 PGW 直接的隧道建设完成。双方请求对方，都要带着对方给自己分配的隧道 ID，从而标志是这个手机的请求。</li><li>接下来 SGW 回复 MME 说“创建会话成功”，使用自己的隧道 ID  t1 访问 MME，回复里面有给 MME 分配隧道 ID  t6，也有 SGW 给 eNodeB 分配的隧道 ID  t7。</li><li>当 MME 发现后面的隧道都建设成功之后，就告诉 eNodeB，“后面的隧道已经建设完毕，SGW 给你分配的隧道 ID 是 t7，你可以开始连上来了，但是你也要给 SGW 分配一个隧道 ID”。</li><li>eNodeB 告诉 MME 自己给 SGW 分配一个隧道，ID 为 t8。</li><li>MME 将 eNodeB 给 SGW 分配的隧道 ID  t8 告知 SGW，从而前面的隧道也建设完毕。</li></ol><h3 id="3-4-4-异地上网问题"><a href="#3-4-4-异地上网问题" class="headerlink" title="3.4.4 异地上网问题"></a>3.4.4 异地上网问题</h3><p>为什么要分 SGW 和 PGW 呢，一个 GW 不可以吗？SGW 是你本地的运营商的设备，而 PGW 是你所属的运营商的设备。如果你在巴塞罗那，一下飞机，手机开机，周围搜寻到的肯定是巴塞罗那的 eNodeB。通过 MME 去查寻国内运营商的 HSS，看你是否合法，是否还有钱。如果允许上网，你的手机和巴塞罗那的 SGW 会建立一个隧道，然后巴塞罗那的 SGW 和国内运营商的 PGW 建立一个隧道，然后通过国内运营商的 PGW 上网。</p><p><img src="https://i.loli.net/2020/02/02/baY14UCmQ6ZkjOs.jpg" alt="fig29.jpg"></p><p>这样判断你是否能上网的在国内运营商的 HSS，控制你上网策略的是国内运营商的 PCRF，给手机分配的 IP 地址也是国内运营商的 PGW 负责的，给手机分配的 IP 地址也是国内运营商里统计的。运营商由于是在 PGW 里面统计的，这样你的上网流量全部通过国内运营商即可，只不过巴塞罗那运营商也要和国内运营商进行流量结算。</p><p>由于你的上网策略是由国内运营商在 PCRF 中控制的，因而你还是上不了脸书。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-数据中心&quot;&gt;&lt;a href=&quot;#1-数据中心&quot; class=&quot;headerlink&quot; title=&quot;1. 数据中心&quot;&gt;&lt;/a&gt;1. 数据中心&lt;/h1&gt;&lt;p&gt;数据中心里都是服务器，放在机架上(Rack)。数据中心的出口和入口也是路由器，多个边界路由器使其可用性更
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
      <category term="Data Center" scheme="https://www.llchen60.com/tags/Data-Center/"/>
    
      <category term="VPN" scheme="https://www.llchen60.com/tags/VPN/"/>
    
  </entry>
  
  <entry>
    <title>网络协议(七)-流媒体协议(网络直播当中的视频压缩与传播问题)</title>
    <link href="https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%83-%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE-%E7%BD%91%E7%BB%9C%E7%9B%B4%E6%92%AD%E5%BD%93%E4%B8%AD%E7%9A%84%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E4%B8%8E%E4%BC%A0%E6%92%AD%E9%97%AE%E9%A2%98/"/>
    <id>https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%83-%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE-%E7%BD%91%E7%BB%9C%E7%9B%B4%E6%92%AD%E5%BD%93%E4%B8%AD%E7%9A%84%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E4%B8%8E%E4%BC%A0%E6%92%AD%E9%97%AE%E9%A2%98/</id>
    <published>2020-02-02T03:38:44.000Z</published>
    <updated>2020-02-02T06:06:58.013Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-视频压缩"><a href="#1-视频压缩" class="headerlink" title="1. 视频压缩"></a>1. 视频压缩</h1><p>网络直播,视频压缩是一个很关键的技术，因为假设每一张图片大小为1024 * 768，每个像素由RGB组成，其中每个占8位，共24位。那么每秒钟的视频大小为：</p><p>30帧 x 1024 x 768 x 24 = 70,778,880 Bytes<br>如果一分钟的视频，就已经是4个G了。</p><p>解决的方式是编码，通过对图片的压缩，使播放的时候画面看起来仍然足够精美。</p><h2 id="1-1-视频和图片压缩过程特征"><a href="#1-1-视频和图片压缩过程特征" class="headerlink" title="1.1 视频和图片压缩过程特征"></a>1.1 视频和图片压缩过程特征</h2><h3 id="1-1-1-空间冗余"><a href="#1-1-1-空间冗余" class="headerlink" title="1.1.1 空间冗余"></a>1.1.1 空间冗余</h3><p>图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，没必要每个像素都完整地保存，可以隔几个保存一个，中间的用算法计算出来。</p><h3 id="1-1-2-时间冗余"><a href="#1-1-2-时间冗余" class="headerlink" title="1.1.2 时间冗余"></a>1.1.2 时间冗余</h3><p>视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。</p><h3 id="1-1-3-视觉冗余"><a href="#1-1-3-视觉冗余" class="headerlink" title="1.1.3 视觉冗余"></a>1.1.3 视觉冗余</h3><p>人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数据。</p><h3 id="1-1-4-编码冗余"><a href="#1-1-4-编码冗余" class="headerlink" title="1.1.4 编码冗余"></a>1.1.4 编码冗余</h3><p>不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多</p><p>整个压缩过程如下图所示：</p><p><img src="https://i.loli.net/2020/02/02/s1dCD9uOXyP7t4E.jpg" alt="fig1.jpg"></p><h2 id="1-2-视频编码的两大种类-流派"><a href="#1-2-视频编码的两大种类-流派" class="headerlink" title="1.2 视频编码的两大种类/ 流派"></a>1.2 视频编码的两大种类/ 流派</h2><h3 id="1-2-1-ITU-International-Telecommunications-Union"><a href="#1-2-1-ITU-International-Telecommunications-Union" class="headerlink" title="1.2.1 ITU International Telecommunications Union"></a>1.2.1 ITU International Telecommunications Union</h3><p>VCEG(Video Conding Experts Group),视频编码，侧重于传输</p><h3 id="1-2-2-ISO-International-Standards-Organization"><a href="#1-2-2-ISO-International-Standards-Organization" class="headerlink" title="1.2.2 ISO International Standards Organization"></a>1.2.2 ISO International Standards Organization</h3><p>MPEG(Moving Picture Experts Group)，视频存储</p><h2 id="1-2-网络直播"><a href="#1-2-网络直播" class="headerlink" title="1.2 网络直播"></a>1.2 网络直播</h2><p>网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络包，从而得到里面的视频流。</p><p>服务端接到视频流以后，对视频流进行转码，保证用各种客户端都能看到直播。</p><p>如果有非常多的观众，同时看一个视频直播，都从一个服务器上拉流，压力太大了，因而需要一个视频的分发网络，将视频预先加载到就近的边缘节点，来降低服务器的压力。</p><p><img src="https://i.loli.net/2020/02/02/CqdINFefH17Pvph.jpg" alt="fig2.jpg"></p><h2 id="1-3-视频图片压缩过程详解"><a href="#1-3-视频图片压缩过程详解" class="headerlink" title="1.3 视频图片压缩过程详解"></a>1.3 视频图片压缩过程详解</h2><h3 id="1-3-1-编码"><a href="#1-3-1-编码" class="headerlink" title="1.3.1 编码"></a>1.3.1 编码</h3><p>会将视频序列分为三种帧，来分别进行压缩行为：</p><ul><li>I 帧</li></ul><p>也称关键帧。里面是完整的图片，只需要本帧数据，就可以完成解码。</p><ul><li>P 帧</li></ul><p>前向预测编码帧。P 帧表示的是这一帧跟之前的一个关键帧（或 P 帧）的差别，解码时需要用之前缓存的画面，叠加上和本帧定义的差别，生成最终画面。</p><ul><li>B 帧</li></ul><p>双向预测内插编码帧。B 帧记录的是本帧与前后帧的差别。要解码 B 帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的数据与本帧数据的叠加，取得最终的画面。</p><p>可以看出，I 帧最完整，B 帧压缩率最高，而压缩后帧的序列，应该是在 IBBP 的间隔出现的。这就是通过时序进行编码</p><p><img src="https://i.loli.net/2020/02/02/yS8dkhIKF5Xaf3w.jpg" alt="fig3.jpg"></p><p>在一帧中，分成多个片，每个片中分成多个宏块，每个宏块分成多个子块，这样将一张大的图分解成一个个小块，可以方便进行空间上的编码。</p><p>帧 -&gt; 片 -&gt; 宏块 -&gt; 子块</p><p>编码后的整个序列是要压缩为一个二进制流在网络上传播的，因此需要分割成一个个网络提取单元(NALU, network abstraction layer unit). </p><p><img src="https://i.loli.net/2020/02/02/dMZ329Vrgj6ynex.jpg" alt="fig4.jpg"></p><p>每一个 NALU 首先是一个起始标识符，用于标识 NALU 之间的间隔；然后是 NALU 的头，里面主要配置了 NALU 的类型；最终 Payload 里面是 NALU 承载的数据。</p><p>在 NALU 头里面，主要的内容是类型NAL Type.</p><ul><li>0x07 表示 SPS，是序列参数集， 包括一个图像序列的所有信息，如图像尺寸、视频格式等。</li><li>0x08 表示 PPS，是图像参数集，包括一个图像的所有分片的所有相关信息，包括图像类型、序列号等。</li><li>在传输视频流之前，必须要传输这两类参数，不然无法解码。为了保证容错性，每一个 I 帧前面，都会传一遍这两个参数集合。</li></ul><p>如果 NALU Header 里面的表示类型是 SPS 或者 PPS，则 Payload 中就是真正的参数集的内容。</p><p>如果类型是帧，则 Payload 中才是正的视频数据，当然也是一帧一帧存放的，前面说了，一帧的内容还是挺多的，因而每一个 NALU 里面保存的是一片。对于每一片，到底是 I 帧，还是 P 帧，还是 B 帧，在片结构里面也有个 Header，这里面有个类型，然后是片的内容。</p><p><strong>一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，在每一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列</strong></p><h3 id="1-3-2-推流"><a href="#1-3-2-推流" class="headerlink" title="1.3.2 推流"></a>1.3.2 推流</h3><p>需要将这个二进制流打包成网络包进行发送，一般使用RTMP协议。</p><p>RTMP协议是基于TCP的，因此肯定需要双方建立一个TCP的连接。在有TCP的连接的基础上，还需要建立一个RTMP的连接，即在程序当中，需要调用RTMP类库的Connect函数显示创建一个连接。</p><p>RTMP需要单独一个连接的原因在于：双方需要互相知道版本号，时间戳(看时间戳的差值)</p><p>未来沟通这些事情，需要发送六条消息：客户端发送 C0、C1、  C2，服务器发送 S0、  S1、  S2。首先，客户端发送 C0 表示自己的版本号，不必等对方的回复，然后发送 C1 表示自己的时间戳。服务器只有在收到 C0 的时候，才能返回 S0，表明自己的版本号，如果版本不匹配，可以断开连接。<br>服务器发送完 S0 后，也不用等什么，就直接发送自己的时间戳 S1。客户端收到 S1 的时候，发一个知道了对方时间戳的 ACK  C2。同理服务器收到 C1 的时候，发一个知道了对方时间戳的 ACK  S2。<br>握手完成。</p><p><img src="https://i.loli.net/2020/02/02/4DgIibdfYF9xmPl.jpg" alt="fig5.jpg"></p><p>握手之后，双方需要互相传递一些控制信息，比如Chunk块的大小，窗口大小等。真正传输数据的时候，还是需要创建一个流Stream，然后通过这个Stream来推流publish。 </p><p>推流的过程，就是将NALU放在message里面发送，称为RTMP Packet包。格式如下图所示：</p><p><img src="https://i.loli.net/2020/02/02/id8BeJZkDrVbpQX.jpg" alt="fig6.jpg"></p><p>发送的时候，去掉 NALU 的起始标识符。因为这部分对于 RTMP 协议来讲没有用。接下来，将 SPS 和 PPS 参数集封装成一个 RTMP 包发送，然后发送一个个片的 NALU。</p><p>RTMP 在收发数据的时候并不是以 Message 为单位的，而是把 Message 拆分成 Chunk 发送，而且必须在一个 Chunk 发送完成之后，才能开始发送下一个 Chunk。每个 Chunk 中都带有 Message  ID，表示属于哪个 Message，接收端也会按照这个 ID 将 Chunk 组装成 Message。</p><p>前面连接的时候，设置的 Chunk 块大小就是指这个 Chunk。将大的消息变为小的块再发送，可以在低带宽的情况下，减少网络拥塞。</p><p>举一个分块的例子：</p><p>假设一个视频的消息长度为 307，但是 Chunk 大小约定为 128，于是会拆分为三个 Chunk。</p><p>第一个 Chunk 的 Type＝0，表示 Chunk 头是完整的；头里面 Timestamp 为 1000，总长度 Length 为 307，类型为 9，是个视频，Stream  ID 为 12346，正文部分承担 128 个字节的 Data。</p><p>第二个 Chunk 也要发送 128 个字节，Chunk 头由于和第一个 Chunk 一样，因此采用 Chunk Type＝3，表示头一样就不再发送了。</p><p>第三个 Chunk 要发送的 Data 的长度为 307-128-128=51 个字节，还是采用 Type＝3。</p><p><img src="https://i.loli.net/2020/02/02/TvqDHjO9eQ8bcBo.jpg" alt="fig7.jpg"></p><p>这样数据就能源源不断到达流媒体服务器</p><p><img src="https://i.loli.net/2020/02/02/7gvWiSIFkPX64Oe.jpg" alt="fig8.jpg"></p><p>这个时候，大量观看直播的观众就可以通过 RTMP 协议从流媒体服务器上拉取，但是这么多的用户量，都去同一个地方拉取，服务器压力会很大，而且用户分布在全国甚至全球，如果都去统一的一个地方下载，也会时延比较长，需要有分发网络。</p><p>分发网络分为中心和边缘两层。边缘层服务器部署在全国各地及横跨各大运营商里，和用户距离很近。中心层是流媒体服务集群，负责内容的转发。智能负载均衡系统，根据用户的地理位置信息，就近选择边缘服务器，为用户提供推 / 拉流服务。中心层也负责转码服务，例如，把 RTMP 协议的码流转换为 HLS 码流。</p><p><img src="https://i.loli.net/2020/02/02/tcimUEH6WRv8wsA.jpg" alt="fig9.jpg"></p><h3 id="1-3-3-拉流"><a href="#1-3-3-拉流" class="headerlink" title="1.3.3 拉流"></a>1.3.3 拉流</h3><p>观众的客户端通过RTMP拉流的过程：</p><p><img src="https://i.loli.net/2020/02/02/9Br2WsplhnkzvjK.jpg" alt="fig10.jpg"></p><h1 id="2-P2P"><a href="#2-P2P" class="headerlink" title="2. P2P"></a>2. P2P</h1><h2 id="2-1-传输大文件的现有方式"><a href="#2-1-传输大文件的现有方式" class="headerlink" title="2.1 传输大文件的现有方式"></a>2.1 传输大文件的现有方式</h2><h3 id="2-1-1-HTTP方式"><a href="#2-1-1-HTTP方式" class="headerlink" title="2.1.1 HTTP方式"></a>2.1.1 HTTP方式</h3><p>最简单的是通过HTTP进行下载，但是通过浏览器下载速度非常慢。</p><h3 id="2-1-2-FTP方式"><a href="#2-1-2-FTP方式" class="headerlink" title="2.1.2 FTP方式"></a>2.1.2 FTP方式</h3><p>还可以通过FTP，即文件传输协议，FTP通过两个TCP连接来传输一个文件。</p><ul><li>控制连接</li></ul><p>服务器以被动的方式，打开用于FTP的端口21，客户端则主动发起连接。该连接将命令从客户端传给服务器，并传回服务器的应答。</p><ul><li>数据连接</li></ul><p>每当一个文件在客户端与服务器之间传输时，就创建一个数据连接</p><p>FTP有两种工作模式</p><ul><li>主动模式 PORT</li></ul><p>客户端随机打开一个大于1024的端口N，向服务器的命令端口21发起连接，同时开放N+1端口监听，并向服务器发出 prot N+1的命令，由服务器从自己的数据端口20主动连接到客户端指定的数据端口N+1 </p><ul><li>被动模式 PASV</li></ul><p>当开启一个FTP连接时，客户端打开两个任意的本地端口N（仍然需要大于1024）和N+1.第一个端口连接服务器的21端口，提交PASV命令。然后，服务器会开启一个任意的端口P（大于1024），返回”227 entering passive mode”信息，其中有FTP服务器开放的用来进行数据传输的端口。客户端收到信息获取端口号以后，会通过N+1号端口连接服务器的端口P，然后在两个端口之间进行数据传输。</p><h2 id="2-2-P2P概念"><a href="#2-2-P2P概念" class="headerlink" title="2.2 P2P概念"></a>2.2 P2P概念</h2><p>首先无论是HTTP的方式还是FTP的方式，都难以解决单一服务器的带宽压力的问题，因为它们使用的都是传统的客户端服务器方式。P2P是指peer-to-peer。资源开始并不集中地存储在某些设备上，而是分散地存储在多台设备上。</p><p>想要下载一个文件的时候，需要得到那些已经存在了文件的peer，并和这些peer之间建立点对点的连接，而不需要到中心服务器上，就可以就近下载文件。同时在做下载和上传。</p><h2 id="2-3-种子-torrent-文件"><a href="#2-3-种子-torrent-文件" class="headerlink" title="2.3 种子(.torrent) 文件"></a>2.3 种子(.torrent) 文件</h2><p>需要知道哪些peer有这些文件，因此需要用到种子，就是我们熟悉的.torrent文件。由两部分组成：分别是announce(tracker URL) 和文件信息</p><h3 id="2-3-1-文件信息"><a href="#2-3-1-文件信息" class="headerlink" title="2.3.1 文件信息"></a>2.3.1 文件信息</h3><ul><li>info区</li></ul><p>指定该中西有几个文件、文件有多长、目录结构，以及目录和文件的名字。</p><ul><li>name字段</li></ul><p>指定顶层目录的名字</p><ul><li>每个段的大小</li></ul><p>BitTorrent协议把一个文件分成很多小段，然后分段下载。</p><ul><li>段哈希值</li></ul><p>将整个种子种，每个段的SHA-1哈希值拼在一起。</p><h3 id="2-3-2-下载过程"><a href="#2-3-2-下载过程" class="headerlink" title="2.3.2 下载过程"></a>2.3.2 下载过程</h3><p>下载时，BT 客户端首先解析.torrent 文件，得到 tracker 地址，然后连接 tracker 服务器。tracker 服务器回应下载者的请求，将其他下载者（包括发布者）的 IP 提供给下载者。下载者再连接其他下载者，根据.torrent 文件，两者分别对方告知自己已经有的块，然后交换对方没有的数据。此时不需要其他服务器参与，并分散了单个线路上的数据流量，因此减轻了服务器的负担。</p><p>下载者每得到一个块，需要算出下载块的 Hash 验证码，并与.torrent 文件中的对比。如果一样，则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容的准确性问题。</p><p>从这个过程也可以看出，这种方式特别依赖 tracker。tracker 需要收集下载者信息的服务器，并将此信息提供给其他下载者，使下载者们相互连接起来，传输数据。虽然下载的过程是非中心化的，但是加入这个 P2P 网络的时候，都需要借助 tracker 中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源。</p><p>所以，这种工作方式有一个弊端，一旦 tracker 服务器出现故障或者线路遭到屏蔽，BT 工具就无法正常工作了。</p><h2 id="2-4-去中心化网络-Distributed-Hash-Table"><a href="#2-4-去中心化网络-Distributed-Hash-Table" class="headerlink" title="2.4 去中心化网络(Distributed Hash Table)"></a>2.4 去中心化网络(Distributed Hash Table)</h2><p>每个加入这个DHT网络的人都要负责存储这个网络里的资源信息和其它成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。</p><h3 id="2-4-1-Kademlia-协议"><a href="#2-4-1-Kademlia-协议" class="headerlink" title="2.4.1 Kademlia 协议"></a>2.4.1 Kademlia 协议</h3><p>任何一个BitTorrent启动之后，都有两个角色：一个是peer，监听一个TCP端口，用来上传和下载文件；另一个角色DHT node，监听一个UDP端口，通过这个角色，这个节点就可以加入到一个DHT网络当中。</p><p><img src="https://i.loli.net/2020/02/02/573ksTWaqClEcJo.jpg" alt="fig11.jpg"></p><p>在 DHT 网络里面，每一个 DHT node 都有一个 ID。这个 ID 是一个很长的串。每个 DHT node 都有责任掌握一些知识，也就是文件索引，即它应该知道某些文件时保存在哪些节点上的，这些信息就足够了，而它自己本身不一定就是保存这个文件的节点。</p><h3 id="2-4-2-哈希值"><a href="#2-4-2-哈希值" class="headerlink" title="2.4.2 哈希值"></a>2.4.2 哈希值</h3><p>每个文件可以计算出一个哈希值，而DHT node的ID是和哈希值相同长度的串。</p><p>DHT 算法是这样规定的：如果一个文件计算出一个哈希值，则和这个哈希值一样的那个 DHT node，就有责任知道从哪里下载这个文件，即便它自己没保存这个文件。</p><p>当然不一定这么巧，总能找到和哈希值一模一样的，有可能一模一样的 DHT node 也下线了，所以 DHT 算法还规定：除了一模一样的那个 DHT node 应该知道，ID 和这个哈希值非常接近的 N 个 DHT node 也应该知道。</p><p>什么叫和哈希值接近呢？例如只修改了最后一位，就很接近；修改了倒数 2 位，也不远；修改了倒数 3 位，也可以接受。总之，凑齐了规定的 N 这个数就行。</p><p>在这种模式下，种子.torrent 文件里面就不再是 tracker 的地址了，而是一个 list 的 node 的地址，而所有这些 node 都是已经在 DHT 网络里面的。当然随着时间的推移，很可能有退出的，有下线的，但是我们假设，不会所有的都联系不上，总有一个能联系上。</p><p>node new 只要在种子里面找到一个 DHT node，就加入了网络。</p><p>node new 会计算文件 1 的哈希值，并根据这个哈希值了解到，和这个哈希值匹配，或者很接近的 node 上知道如何下载这个文件，例如计算出来的哈希值就是 node C。</p><p>但是 node new 不知道怎么联系上 node C，因为种子里面的 node 列表里面很可能没有 node C，但是它可以问，DHT 网络特别像一个社交网络，node new 只有去它能联系上的 node 问，你们知道不知道 node C 的联系方式呀？</p><p>在 DHT 网络中，每个 node 都保存了一定的联系方式，但是肯定没有 node 的所有联系方式。DHT 网络中，节点之间通过互相通信，也会交流联系方式，也会删除联系方式。</p><p>在 node C 上，告诉 node new，下载文件 1，要去 B、D、 F，于是 node new 选择和 node B 进行 peer 连接，开始下载，它一旦开始下载，自己本地也有文件 1 了，于是 node new 告诉 node C 以及和 node C 的 ID 很像的那些节点，我也有文件 1 了，可以加入那个文件拥有者列表了。</p><p>但是你会发现 node new 上没有文件索引，但是根据哈希算法，一定会有某些文件的哈希值是和 node new 的 ID 匹配上的。在 DHT 网络中，会有节点告诉它，你既然加入了咱们这个网络，你也有责任知道某些文件的下载地址。</p><h1 id="3-DNS"><a href="#3-DNS" class="headerlink" title="3. DNS"></a>3. DNS</h1><h2 id="3-1-DNS服务器"><a href="#3-1-DNS服务器" class="headerlink" title="3.1 DNS服务器"></a>3.1 DNS服务器</h2><p>DNS服务器很重要，根据名称来查找对应的IP地址的协议。DNS服务器，一定要设置成高可用、高并发和分布式的。</p><p><img src="https://i.loli.net/2020/02/02/7nKk5iPVNmQRdot.jpg" alt="fig12.jpg"></p><ul><li>根DNS服务器：返回顶级域DNS服务器的IP地址</li><li>顶级域DNS服务器：返回权威DNS服务器的IP地址</li><li>权威DNS服务器：返回相应主机的IP地址</li></ul><h2 id="3-2-DNS解析流程"><a href="#3-2-DNS解析流程" class="headerlink" title="3.2 DNS解析流程"></a>3.2 DNS解析流程</h2><p><img src="https://i.loli.net/2020/02/02/oRQapO7AxS3jKqt.jpg" alt="fig13.jpg"></p><ol><li>电脑客户端会发出一个 DNS 请求，问 <a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 的 IP 是啥啊，并发给本地域名服务器 (本地 DNS)。那本地域名服务器 (本地 DNS) 是什么呢？如果是通过 DHCP 配置，本地 DNS 由你的网络服务商（ISP），如电信、移动等自动分配，它通常就在你网络服务商的某个机房。</li><li>本地 DNS 收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应 IP 地址的大表格。如果能找到 <a href="http://www.163.com，它直接就返回" target="_blank" rel="noopener">www.163.com，它直接就返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大，能告诉我 <a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 的 IP 地址吗？”根域名服务器是最高层次的，全球共有 13 套。它不直接用于域名解析，但能指明一条道路。</li><li>根 DNS 收到来自本地 DNS 的请求，发现后缀是 .com，说：“哦，<a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 啊，这个域名是由.com 区域管理，我给你它的顶级域名服务器的地址，你去问问它吧。”</li><li>本地 DNS 转向问顶级域名服务器：“老二，你能告诉我 <a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 的 IP 地址吗？”顶级域名服务器就是大名鼎鼎的比如 .com、.net、 .org 这些一级域名，它负责管理二级域名，比如 163.com，所以它能提供一条更清晰的方向。</li><li>顶级域名服务器说：“我给你负责 <a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到。”</li><li>本地 DNS 转向问权威 DNS 服务器：“您好，<a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 对应的 IP 是啥呀？”163.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</li><li>权限 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</li><li>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。</li></ol><h2 id="3-3-DNS-负载均衡"><a href="#3-3-DNS-负载均衡" class="headerlink" title="3.3 DNS 负载均衡"></a>3.3 DNS 负载均衡</h2><p>DNS通过名称映射为IP地址的时候，并不会都映射到同一个IP地址，会根据距离选择最近的。</p><h3 id="3-3-1-DNS内部负载均衡"><a href="#3-3-1-DNS内部负载均衡" class="headerlink" title="3.3.1 DNS内部负载均衡"></a>3.3.1 DNS内部负载均衡</h3><p>例如，一个应用要访问数据库，在这个应用里面应该配置这个数据库的 IP 地址，还是应该配置这个数据库的域名呢？显然应该配置域名，因为一旦这个数据库，因为某种原因，换到了另外一台机器上，而如果有多个应用都配置了这台数据库的话，一换 IP 地址，就需要将这些应用全部修改一遍。但是如果配置了域名，则只要在 DNS 服务器里，将域名映射为新的 IP 地址，这个工作就完成了，大大简化了运维。</p><p>都尽量用域名进行配置，然后就可以在DNS层面上对其进行限制，比如轮询不同的IP地址，达到负载均衡的目的。</p><h3 id="3-3-2-全局负载均衡"><a href="#3-3-2-全局负载均衡" class="headerlink" title="3.3.2 全局负载均衡"></a>3.3.2 全局负载均衡</h3><p>为了保证我们的应用高可用，往往会部署在多个机房，每个地方都会有自己的 IP 地址。当用户访问某个域名的时候，这个 IP 地址可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要在 DNS 服务器里面，将这个数据中心对应的 IP 地址删除，就可以实现一定的高可用。</p><h3 id="3-3-3-DNS访问数据中心中对象存储上的静态资源"><a href="#3-3-3-DNS访问数据中心中对象存储上的静态资源" class="headerlink" title="3.3.3 DNS访问数据中心中对象存储上的静态资源"></a>3.3.3 DNS访问数据中心中对象存储上的静态资源</h3><p>我们通过 DNS 访问数据中心中对象存储上的静态资源为例，看一看整个过程。</p><p>假设全国有多个数据中心，托管在多个运营商，每个数据中心三个可用区（Available Zone）。对象存储通过跨可用区部署，实现高可用性。在每个数据中心中，都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器（Proxy-server）。</p><p><img src="https://i.loli.net/2020/02/02/ZJqxP9mMeatDEjo.jpg" alt="fig14.jpg"></p><ol><li>当一个客户端要访问 object.yourcompany.com 的时候，需要将域名转换为 IP 地址进行访问，所以它要请求本地 DNS 解析器。</li><li>本地 DNS 解析器先查看看本地的缓存是否有这个记录。如果有则直接使用，因为上面的过程太复杂了，如果每次都要递归解析，就太麻烦了。</li><li>如果本地无缓存，则需要请求本地的 DNS 服务器。</li><li>本地的 DNS 服务器一般部署在你的数据中心或者你所在的运营商的网络中，本地 DNS 服务器也需要看本地是否有缓存，如果有则返回，因为它也不想把上面的递归过程再走一遍。</li><li>至 7. 如果本地没有，本地 DNS 才需要递归地从根 DNS 服务器，查到.com 的顶级域名服务器，最终查到 yourcompany.com 的权威 DNS 服务器，给本地 DNS 服务器，权威 DNS 服务器按说会返回真实要访问的 IP 地址。</li></ol><p>对于不需要进行全局负载均衡的简单应用来讲，权威DNS服务器就可以直接将域名解析为一个或者多个IP地址，然后客户端可以通过多个IP地址进行简单的轮询，实现简单的负载均衡。</p><p>但是对于复杂的应用，尤其是跨地域运营商的大型应用，需要专门的设备或者服务器来做这件事情，这就是全局负载均衡器。(GSLB, Global Server Load Balance)</p><p>在 yourcompany.com 的 DNS 服务器中，一般是通过配置 CNAME 的方式，给 object.yourcompany.com 起一个别名，例如 object.vip.yourcomany.com，然后告诉本地 DNS 服务器，让它请求 GSLB 解析这个域名，GSLB 就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。</p><ol><li>第一层 GSLB，通过查看请求它的本地 DNS 服务器所在的运营商，就知道用户所在的运营商。假设是移动，通过 CNAME 的方式，通过另一个别名 object.yd.yourcompany.com，告诉本地 DNS 服务器去请求第二层的 GSLB。</li><li>第二层 GSLB，通过查看请求它的本地 DNS 服务器所在的地址，就知道用户所在的地理位置，然后将距离用户位置比较近的 Region 里面，六个内部负载均衡的地址返回给本地DNS服务器</li><li>本地DNS服务器将结果返回给本地DNS解析器</li><li>本地DNS解析器将结果缓存后，返回给客户端</li><li>客户端开始访问属于相同运营商的距离较近的 Region 1 中的对象存储，当然客户端得到了六个 IP 地址，它可以通过负载均衡的方式，随机或者轮询选择一个可用区进行访问。对象存储一般会有三个备份，从而可以实现对存储读写的负载均衡。</li></ol><h2 id="3-4-DNS功能"><a href="#3-4-DNS功能" class="headerlink" title="3.4 DNS功能"></a>3.4 DNS功能</h2><ol><li>根据名称找具体地址</li><li>针对多个地址做负载均衡</li></ol><p>在多个地址中选择一个距离你近的地方访问。</p><h2 id="3-5-传统DNS的问题"><a href="#3-5-传统DNS的问题" class="headerlink" title="3.5 传统DNS的问题"></a>3.5 传统DNS的问题</h2><h3 id="3-5-1-域名缓存问题"><a href="#3-5-1-域名缓存问题" class="headerlink" title="3.5.1 域名缓存问题"></a>3.5.1 域名缓存问题</h3><p>DNS会对域名做缓存，在访问过一次以后会把结果缓存到本地，当其他人来问的时候，直接就返回这个缓存数据。某些运营商会将静态页面缓存到本运营商的服务器内，这样用户请求的时候，就不用跨运营商进行访问了。既加快了速度，也减少了运营商之间流量计算的成本。 在做域名解析的时候，<strong>不会将用户导向真正的网址，而是指向这个缓存的服务器。</strong></p><p>还有就是本地的缓存往往会使全局负载失败，因为上次进行缓存的时候，缓存中的地址不一定是这次访问离客户最近的地方。</p><h3 id="3-5-2-域名转发问题"><a href="#3-5-2-域名转发问题" class="headerlink" title="3.5.2 域名转发问题"></a>3.5.2 域名转发问题</h3><p>运营商可能不是直接和DNS服务器交流的，可能用转发给了其他的做解析，自己只是外包了出去。</p><h3 id="3-5-3-出口NAT问题"><a href="#3-5-3-出口NAT问题" class="headerlink" title="3.5.3 出口NAT问题"></a>3.5.3 出口NAT问题</h3><p>网络地址转换，使得从网关出去的包都换成了新的IP地址，当请求返回的时候，在这个网关，再将IP地址转换回去。但一旦做了网络地址转换，权威DNS服务器就没法通过这个地址来判断客户到底来自哪个运营商，极有可能误判运营商，导致跨运营商的访问</p><h3 id="3-5-4-域名更新问题"><a href="#3-5-4-域名更新问题" class="headerlink" title="3.5.4 域名更新问题"></a>3.5.4 域名更新问题</h3><p>本地 DNS 服务器是由不同地区、不同运营商独立部署的。对域名解析缓存的处理上，实现策略也有区别，有的会偷懒，忽略域名解析结果的 TTL 时间限制，在权威 DNS 服务器解析变更的时候，解析结果在全网生效的周期非常漫长。但是有的时候，在 DNS 的切换中，场景对生效时间要求比较高。</p><p>例如双机房部署的时候，跨机房的负载均衡和容灾多使用 DNS 来做。当一个机房出问题之后，需要修改权威 DNS，将域名指向新的 IP 地址，但是如果更新太慢，那很多用户都会出现访问异常。</p><h2 id="3-6-HTTPDNS"><a href="#3-6-HTTPDNS" class="headerlink" title="3.6 HTTPDNS"></a>3.6 HTTPDNS</h2><p>HTTPDNS就是不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商。当客户端需要DNS解析的时候，直接通过HTTP协议进行请求这个服务器集群，得到就近的地址。大部分应用在手机中，在手机端嵌入支持HTTPDNS的客户端SDK来进行使用。 </p><h1 id="4-CDN"><a href="#4-CDN" class="headerlink" title="4. CDN"></a>4. CDN</h1><p>当一个用户想访问一个网址的时候，指定这个网站的域名，DNS就会将这个域名解析为地址，然后用户请求这个地址，返回一个网页。</p><p>但是还有很多可以优化的地方： </p><p>借鉴快递的就近配送的原则/思路，在数据中心里部署几台机器，形成一个缓存的集群来缓存部分数据。 </p><p>这些分布在各个地方的各个数据中心的节点，称为边缘节点。</p><p>由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中，这样就会在边缘节点之上。有区域节点，规模就要更大，缓存的数据会更多，命中的概率也就更大。在区域节点之上是中心节点，规模更大，缓存数据更多。如果还不命中，就只好回源网站访问了。</p><p><img src="https://i.loli.net/2020/02/02/71hNwRIfryiuJHb.jpg" alt="fig15.jpg"></p><p>在没有CDN的情况下，用户向浏览器输入 <a href="http://www.web.com" target="_blank" rel="noopener">www.web.com</a> 这个域名，客户端访问本地 DNS 服务器的时候，如果本地 DNS 服务器有缓存，则返回网站的地址；如果没有，递归查询到网站的权威 DNS 服务器，这个权威 DNS 服务器是负责 web.com 的，它会返回网站的 IP 地址。本地 DNS 服务器缓存下 IP 地址，将 IP 地址返回，然后客户端直接访问这个 IP 地址，就访问到了这个网站。</p><p>当CDN存在的时候，在web.com这个权威DNS服务器上，会设置一个CNAME别名，指向另一个域名 <a href="http://www.web.cdn.com,并返回给本地DNS服务器。" target="_blank" rel="noopener">www.web.cdn.com,并返回给本地DNS服务器。</a></p><p><img src="https://i.loli.net/2020/02/02/KPOFwGSbZcgsqr9.jpg" alt="fig16.jpg"></p><p>当本地 DNS 服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是 web.com 的权威 DNS 服务器了，而是 web.cdn.com 的权威 DNS 服务器，这是 CDN 自己的权威 DNS 服务器。在这个服务器上，还是会设置一个 CNAME，指向另外一个域名，也即 CDN 网络的全局负载均衡器。接下来，本地 DNS 服务器去请求 CDN 的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：</p><ol><li>根据用户 IP 地址，判断哪一台服务器距用户最近；</li><li>用户所处的运营商；</li><li>根据用户所请求的 URL 中携带的内容名称，判断哪一台服务器上有用户所需的内容；</li><li>查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。</li></ol><p>基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的 IP 地址。</p><p>本地 DNS 服务器缓存这个 IP 地址，然后将 IP 返回给客户端，客户端去访问这个边缘节点，下载资源。缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。</p><h2 id="4-1-CDN缓存的内容"><a href="#4-1-CDN缓存的内容" class="headerlink" title="4.1 CDN缓存的内容"></a>4.1 CDN缓存的内容</h2><p><img src="https://i.loli.net/2020/02/02/1dZ6rmyNulOwSbY.jpg" alt="fig17.jpg"></p><p>会保存静态页面，图片等，因为这些东西变化的可能性不高。</p><p>在进入数据中心的时候，我们希望通过最外层接入层的缓存，将大部分静态资源的访问拦在边缘。而CDN则更进一步，将这些静态资源缓存到离用户更近的数据中心外。越接近客户，访问性能越好，时延越低。</p><p>静态资源中，流媒体也大量使用了CDN技术。CDN支持流媒体协议，例如前面讲过的 RTMP 协议。在很多情况下，这相当于一个代理，从上一级缓存读取内容，转发给用户。由于流媒体往往是连续的，因而可以进行预先缓存的策略，也可以预先推送到用户的客户端。</p><p>对于静态页面来讲，内容的分发往往采取拉取的方式，即未命中的时候，向上一级进行拉取，但流媒体数据量很大，如果出现回源，压力会比较大，因此往往采取主动推送的模式，将热点数据主动推送到边缘节点。</p><p>对于流媒体来讲，很多CDN还提供预处理服务，即在文件分发之前，经过一定的处理。例如将视频转换为不同的码流，以适应不同的网络带宽的用户需求；再比如对视频进行分片，降低存储压力，也使得客户端可以选择使用不同的码率加载不同的分片。</p><h2 id="4-2-防盗链问题"><a href="#4-2-防盗链问题" class="headerlink" title="4.2 防盗链问题"></a>4.2 防盗链问题</h2><p>对于流媒体来说，防盗链很重要，即视频都有版权的，只能在自己的网站里播才可以的。</p><h3 id="4-2-1-refer机制"><a href="#4-2-1-refer机制" class="headerlink" title="4.2.1 refer机制"></a>4.2.1 refer机制</h3><p>HTTP头的refer字段，告诉服务器这个请求从哪里来的，服务器基于此可以获得一些信息用于处理。如果referer的信息不是来自本站，就阻止访问或者调到其它链接当中。</p><h3 id="4-2-2-时间戳防盗链"><a href="#4-2-2-时间戳防盗链" class="headerlink" title="4.2.2 时间戳防盗链"></a>4.2.2 时间戳防盗链</h3><p>使用 CDN 的管理员可以在配置界面上，和 CDN 厂商约定一个加密字符串。客户端取出当前的时间戳，要访问的资源及其路径，连同加密字符串进行签名算法得到一个字符串，然后生成一个下载链接，带上这个签名字符串和截止时间戳去访问 CDN。在 CDN 服务端，根据取出过期时间，和当前 CDN 节点时间进行比较，确认请求是否过期。然后 CDN 服务端有了资源及路径，时间戳，以及约定的加密字符串，根据相同的签名算法计算签名，如果匹配则一致，访问合法，才会将资源返回给客户。</p><h2 id="4-3-动态CDN"><a href="#4-3-动态CDN" class="headerlink" title="4.3 动态CDN"></a>4.3 动态CDN</h2><h3 id="4-3-1-边缘计算模式"><a href="#4-3-1-边缘计算模式" class="headerlink" title="4.3.1 边缘计算模式"></a>4.3.1 边缘计算模式</h3><p>既然数据时动态生成的，那数据的逻辑计算和存储也应当相应的放在边缘节点。其中定时从源数据哪里同步存储的数据，然后再边缘进行计算得到结果。 </p><h3 id="4-3-2-路径优化模式"><a href="#4-3-2-路径优化模式" class="headerlink" title="4.3.2 路径优化模式"></a>4.3.2 路径优化模式</h3><p>数据不是在边缘计算生成的，而是在源站生成的，数据的下发则可以通过CDN网络，对路径进行优化。因为CDN节点较多，能够找到离源站很近的边缘节点，也能找到离用户很近的边缘节点。中间的链路完全由CDN规划，选择一个更加可靠的路径，使用类似专线的方式进行访问。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-视频压缩&quot;&gt;&lt;a href=&quot;#1-视频压缩&quot; class=&quot;headerlink&quot; title=&quot;1. 视频压缩&quot;&gt;&lt;/a&gt;1. 视频压缩&lt;/h1&gt;&lt;p&gt;网络直播,视频压缩是一个很关键的技术，因为假设每一张图片大小为1024 * 768，每个像素由RGB组成
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
      <category term="Network" scheme="https://www.llchen60.com/tags/Network/"/>
    
      <category term="CDN" scheme="https://www.llchen60.com/tags/CDN/"/>
    
      <category term="流媒体协议" scheme="https://www.llchen60.com/tags/%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE/"/>
    
      <category term="P2P" scheme="https://www.llchen60.com/tags/P2P/"/>
    
      <category term="DNS" scheme="https://www.llchen60.com/tags/DNS/"/>
    
  </entry>
  
  <entry>
    <title>网络协议(六)-应用层</title>
    <link href="https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AD-%E5%BA%94%E7%94%A8%E5%B1%82/"/>
    <id>https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AD-%E5%BA%94%E7%94%A8%E5%B1%82/</id>
    <published>2020-02-02T01:42:56.000Z</published>
    <updated>2020-02-02T06:06:58.016Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-HTTP协议"><a href="#1-HTTP协议" class="headerlink" title="1. HTTP协议"></a>1. HTTP协议</h1><p>以输入一个网址<a href="http://www.google.com为例。这是一个URL，称为统一资源定位符。HTTP是一个协议，www.google.com是一个域名，表示互联网上的一个位置。因为有规范，浏览器才知道如何统一进行处理。" target="_blank" rel="noopener">http://www.google.com为例。这是一个URL，称为统一资源定位符。HTTP是一个协议，www.google.com是一个域名，表示互联网上的一个位置。因为有规范，浏览器才知道如何统一进行处理。</a></p><h2 id="1-1-HTTP请求的准备"><a href="#1-1-HTTP请求的准备" class="headerlink" title="1.1 HTTP请求的准备"></a>1.1 HTTP请求的准备</h2><p>浏览器会将域名发送给DNS服务器，将其解析为IP地址。而后因为HTTP是基于TCP协议的，所以需要先通过三次握手来建立TCP连接。目前使用的HTTP协议大多数是1.1版本的，在1.1的协议当中，默认开启了Keep-alive，这意味着建立的TCP连接可以在多次请求中复用。</p><h2 id="1-2-HTTP请求的构建"><a href="#1-2-HTTP请求的构建" class="headerlink" title="1.2 HTTP请求的构建"></a>1.2 HTTP请求的构建</h2><p>连接建立以后，浏览器就要发送HTTP请求。</p><p>请求的格式如下图所示：</p><p><img src="https://i.loli.net/2020/02/02/9UN4fDEwdcCV8qZ.jpg" alt="fig1.jpg"></p><p>HTTP的请求分为三部分，分别为请求行，请求的首部，请求的正文实体。</p><h3 id="1-2-1-请求行"><a href="#1-2-1-请求行" class="headerlink" title="1.2.1 请求行"></a>1.2.1 请求行</h3><p>方法 + sp + URL + sp + 版本 + cr + If</p><p>在请求行中，URL就是<code>http://www.google.com</code>, 版本是HTTP1.1。</p><p>方法有几个类型：</p><ol><li>GET</li></ol><p>GET就是去服务器获取一些资源。对于访问网页来讲，要获取的往往是一个页面，也会有很多其他的格式，比如返回一个JSON字符串等等。返回的状态是由服务器的实现来决定的。</p><ol start="2"><li>POST</li></ol><p>主动告诉服务端一些信息，而非获取。一般是将这些信息放在正文当中。</p><ol start="3"><li>PUT</li></ol><p>向指定资源位置上传最新的内容，但是HTTP的服务器往往不允许上传文件，所以PUT和POST就都变成了要传给服务器东西的方法。POST往往是用来创建一个资源的，而PUT往往是用来修改一个资源的。</p><ol start="4"><li>DELETE</li></ol><p>用来删除资源的。</p><h3 id="1-2-2-首部字段"><a href="#1-2-2-首部字段" class="headerlink" title="1.2.2 首部字段"></a>1.2.2 首部字段</h3><p>首部字段首先是key value，通过冒号分隔。这里往往保存了一些非常重要的字段，比如：</p><ul><li>Accept-Charset： 这里表示客户端可以接受的字符集，防止传过来的是另外的字符集，从而导致出现乱码。</li><li>Content-Type: 正文的格式。例如如果正文是JSON，那这里我们就应该将其设为JSON。</li><li>缓存</li></ul><p>为什么要使用缓存呢？因为一个大的页面会有很多的东西。图片和大段的介绍内容往往是不会太经常发生变化的，因此我们每次更新页面的时候，不应该刷新整个页面，完全的从服务器重新获取一遍数据，应该做局部的刷新的。</p><p>对于这种高并发场景下的系统，在真正的业务逻辑之前，都会有一个<strong>接入层</strong>，将这些静态资源的请求拦在最外面。架构图如下所示：</p><p><img src="https://i.loli.net/2020/02/02/7BHNARp3Lg8Yuav.jpg" alt="fig2.jpg"></p><p>基本上是客户端和DNS还有CDN相连，再联系负载均衡模块 - nginx。将资源划分为动态资源和静态资源，对于静态资源，使用Varnish缓存层；对于动态资源，使用Redis，Varnish和Redis都和Tomcat应用集群相连，这意味着如果无法从缓存中拿到数据，那就访问服务器，调取数据。</p><p>在HTTP头里面，Cache-control是用来控制缓存的，当客户端发送的请求中包含max-age指令时，如果判定缓存层中资源的缓存时间数值比指定时间的数值小，那么客户端可以接受缓存的资源；当指定max-age值为0，那么缓存层通常需要将请求转发给应用集群。</p><ul><li>If-Modified-Since</li></ul><p>如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回”304 Not Modified”的响应，那客户端就不用下载了，也会节省带宽。</p><p>到目前为止，我们有了HTTP请求的报文格式，接下来，浏览器会通过Socket将其交给传输层。</p><h3 id="1-2-3-HTTP请求的发送"><a href="#1-2-3-HTTP请求的发送" class="headerlink" title="1.2.3 HTTP请求的发送"></a>1.2.3 HTTP请求的发送</h3><p>HTTP协议是基于TCP协议的。使用面向连接的方式发送请求，通过stream二进制流的方式传给对方。到了TCP层，它会把二进制流变成一个报文段发送给服务器。</p><p>在发送每一个报文段的时候，都需要对方回应一个ACK，来保证报文可靠地到达对方。如果没有回应，那么TCP这一层会重新传输，直到可以到达。</p><p>TCP 层发送每一个报文的时候，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址），将这两个信息放到 IP 头里面，交给 IP 层进行传输。</p><p>IP 层需要查看目标地址和自己是否是在同一个局域网。如果是，就发送 ARP 协议来请求这个目标地址对应的 MAC 地址，然后将源 MAC 和目标 MAC 放入 MAC 头，发送出去即可；如果不在同一个局域网，就需要发送到网关，还要需要发送 ARP 协议，来获取网关的 MAC 地址，然后将源 MAC 和网关 MAC 放入 MAC 头，发送出去。</p><p>网关收到包发现 MAC 符合，取出目标 IP 地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的 MAC 地址，将包发给下一跳路由器。这样路由器一跳一跳终于到达目标的局域网。这个时候，最后一跳的路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送 ARP，获得这个目标地址的 MAC 地址，将包发出去。</p><p>目标的机器发现 MAC 地址符合，就将包收起来；发现 IP 地址符合，根据 IP 头中协议项，知道自己上一层是 TCP 协议，于是解析 TCP 的头，里面有序列号，需要看一看这个序列包是不是我要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。</p><p>TCP 头里面还有端口号，HTTP 的服务器正在监听这个端口号。于是，目标机器自然知道是 HTTP 服务器这个进程想要这个包，于是将包发给 HTTP 服务器。HTTP 服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。</p><h3 id="1-2-4-HTTP返回的构建"><a href="#1-2-4-HTTP返回的构建" class="headerlink" title="1.2.4 HTTP返回的构建"></a>1.2.4 HTTP返回的构建</h3><p>基于HTTP/1.1的返回报文：</p><p><img src="https://i.loli.net/2020/02/02/2nmbaI9hzYTKUr1.jpg" alt="fig3.jpg"></p><p>状态码会返回HTTP请求的结果。</p><p>而后是返回首部的key value。 </p><ul><li>Retry-After表示告诉客户端应该在多长时间以后再次尝试一下。</li><li>Content-Type: 表示返回的是HTML，还是JSON。</li></ul><p>构造好了返回的HTTP报文，接下来就是把这个报文发送出去。交给Socket去发送，交给TCP层，让TCP层将返回的HTML分成一个个小段，并且保证每个段都可靠到达。这些段加上TCP头后会交给IP层，然后将刚才的发送过程反方向来一遍。两次的逻辑基本相同，一直到达客户端。</p><p>客户端发现 MAC 地址符合、IP 地址符合，于是就会交给 TCP 层。根据序列号看是不是自己要的报文段，如果是，则会根据 TCP 头中的端口号，发给相应的进程。这个进程就是浏览器，浏览器作为客户端也在监听某个端口。</p><p>当浏览器拿到了 HTTP 的报文。发现返回“200”，一切正常，于是就从正文中将 HTML 拿出来。HTML 是一个标准的网页格式。浏览器只要根据这个格式，展示出一个绚丽多彩的网页。</p><p>这是一个正常的HTTP请求和返回的完整过程。</p><h2 id="1-3-HTTP-2-0"><a href="#1-3-HTTP-2-0" class="headerlink" title="1.3 HTTP 2.0"></a>1.3 HTTP 2.0</h2><p>HTTP 1.1 在应用层以纯文本的形式进行通信。每次通信都要带完整的 HTTP 的头，而且不考虑 pipeline 模式的话，每次的过程总是像上面描述的那样一去一回。这样在实时性、并发性上都存在问题。</p><p>为了解决这些问题，HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key  value 在两端建立一个索引表，对相同的头只发送索引表中的索引。</p><p>另外，HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。</p><p>HTTP 2.0 还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有Header帧，用于传输Header内容，并且会开启一个新的流。再就是Data帧，用来传输正文实体。多个帧属于同一个流。</p><p>通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。</p><p>我们来举一个例子。假设我们的一个页面要发送三个独立的请求，一个获取 css，一个获取 js，一个获取图片 jpg。如果使用 HTTP 1.1 就是串行的，但是如果使用 HTTP 2.0，就可以在一个连接里，客户端和服务端都可以同时发送多个请求或回应，而且不用按照顺序一对一对应。</p><p><img src="https://i.loli.net/2020/02/02/eyvpNZfrz3ClsnT.jpg" alt="fig4.jpg"></p><p>HTTP2.0实际上是将三个请求变成三个流，将数据分成帧，乱序发送到一个TCP连接当中。</p><p><img src="https://i.loli.net/2020/02/02/ymohztOPXklU84f.jpg" alt="fig5.jpg"></p><p>HTTP 2.0 成功解决了 HTTP 1.1 的队首阻塞问题，同时，也不需要通过 HTTP 1.x 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应；减少了 TCP 连接数对服务器性能的影响，同时将页面的多个数据 css、js、 jpg 等通过一个数据链接进行传输，能够加快页面组件的传输速度。</p><p>HTTP2.0虽然大大增加了并发性，但是还存在问题，因为HTTP2.0还是基于TCP协议的，TCP协议在处理包时是有严格顺序的。当其中一个数据包遇到问题，TCP连接需要等待这个包完成重传之后才能继续进行。因此Google引入QUIC协议来加速整个过程。</p><h2 id="1-4-QUIC协议"><a href="#1-4-QUIC协议" class="headerlink" title="1.4 QUIC协议"></a>1.4 QUIC协议</h2><p>从TCP切换到了UDP！</p><h3 id="1-4-1-自定义连接机制"><a href="#1-4-1-自定义连接机制" class="headerlink" title="1.4.1 自定义连接机制"></a>1.4.1 自定义连接机制</h3><p>我们都知道，一条 TCP 连接是由四元组标识的，分别是源 IP、源端口、目的 IP、目的端口。一旦一个元素发生变化时，就需要断开重连，重新连接。在移动互联情况下，当手机信号不稳定或者在 WIFI 和 移动网络切换时，都会导致重连，从而进行再次的三次握手，导致一定的时延。</p><p>这在 TCP 是没有办法的，但是基于 UDP，就可以在 QUIC 自己的逻辑里面维护连接的机制，不再以四元组标识，而是以一个 64 位的随机数作为 ID 来标识，而且 UDP 是无连接的，所以当 IP 或者端口变化的时候，只要 ID 不变，就不需要重新建立连接。</p><h3 id="1-4-2-自定义重传机制"><a href="#1-4-2-自定义重传机制" class="headerlink" title="1.4.2 自定义重传机制"></a>1.4.2 自定义重传机制</h3><p>TCP使用序号和应答机制来解决顺序问题和丢包问题。任何一个序号的包发过去，都要在一定的时间内得到应答，否则一旦超时，就会重发这个序号的包。那怎么样才算超时呢？通过使用自适应重传算法，通过采样往返时间RTT不断调整。</p><p>其实，在 TCP 里面超时的采样存在不准确的问题。例如，发送一个包，序号为 100，发现没有返回，于是再发送一个 100，过一阵返回一个 ACK101。这个时候客户端知道这个包肯定收到了，但是往返时间是多少呢？是 ACK 到达的时间减去后一个 100 发送的时间，还是减去前一个 100 发送的时间呢？事实是，第一种算法把时间算短了，第二种算法把时间算长了。</p><p>QUIC 也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。例如，发送一个包，序号是 100，发现没有返回；再次发送的时候，序号就是 101 了；如果返回的 ACK  100，就是对第一个包的响应。如果返回 ACK  101 就是对第二个包的响应，RTT 计算相对准确。</p><p>但是这里有一个问题，就是怎么知道包 100 和包 101 发送的是同样的内容呢？QUIC 定义了一个 offset 概念。QUIC 既然是面向连接的，也就像 TCP 一样，是一个数据流，发送的数据在这个数据流里面有个偏移量 offset，可以通过 offset 查看数据发送到了哪里，这样只要这个 offset 的包没有来，就要重发；如果来了，按照 offset 拼接，还是能够拼成一个流。</p><p><img src="https://i.loli.net/2020/02/02/p2nxwzvTsV1toX9.jpg" alt="fig6.jpg"></p><h3 id="1-4-3-无阻塞的多路复用"><a href="#1-4-3-无阻塞的多路复用" class="headerlink" title="1.4.3 无阻塞的多路复用"></a>1.4.3 无阻塞的多路复用</h3><p>有了自定义的连接和重传机制，我们就可以解决HTTP2.0的多路复用问题。同 HTTP 2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。但是，QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖。这样，假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。</p><h3 id="1-4-4-自定义流量控制"><a href="#1-4-4-自定义流量控制" class="headerlink" title="1.4.4 自定义流量控制"></a>1.4.4 自定义流量控制</h3><p>TCP的流量控制是通过滑动窗口协议。QUIC的流量控制是通过window_update，来告诉对方它可以接收的字节数。但是QUIC的窗口是适应自己的多路复用机制的，可以在一个连接中的每一个stream控制窗口大小。</p><p>在 TCP 协议中，接收端的窗口的起始点是下一个要接收并且 ACK 的包，即便后来的包都到了，放在缓存里面，窗口也不能右移，因为 TCP 的 ACK 机制是基于序列号的累计应答，一旦 ACK 了一个系列号，就说明前面的都到了，所以只要前面的没到，后面的到了也不能 ACK，就会导致后面的到了，也有可能超时重传，浪费带宽。</p><p>QUIC 的 ACK 是基于 offset 的，每个 offset 的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空挡会等待到来或者重发即可，而窗口的起始位置为当前收到的最大 offset，从这个 offset 到当前的 stream 所能容纳的最大缓存，是真正的窗口大小。显然，这样更加准确。</p><p><img src="https://i.loli.net/2020/02/02/k4weK82tcO7yfuq.jpg" alt="fig7.jpg"></p><h1 id="2-HTTPS-协议"><a href="#2-HTTPS-协议" class="headerlink" title="2.HTTPS 协议"></a>2.HTTPS 协议</h1><p>HTTPS协议的适用场景：我们可以用HTTP协议来看新闻，但是放到下单支付的应用场景中会存在很多的风险。如果适用HTTP，假设点外卖支付，网络包被截获了，于是在服务器回复你之前，黑客假装是外卖网站，然后给你回复一个假消息让你发送银行卡号和密码。</p><p>为了解决在这种应用场景下的安全问题，需要进行加密，分为对称加密和非对称加密两种：</p><h2 id="2-1-加密方式"><a href="#2-1-加密方式" class="headerlink" title="2.1 加密方式"></a>2.1 加密方式</h2><h3 id="2-1-1-对称加密"><a href="#2-1-1-对称加密" class="headerlink" title="2.1.1 对称加密"></a>2.1.1 对称加密</h3><p>在对称加密算法中，加密和解密使用的密钥是相同的。也就是说，加密和解密使用的是同一个密钥。因此，对称加密算法要保证安全性的话，密钥要做好保密。只能让使用的人知道，不能对外公开。</p><p>在上述场景当中的问题变成了：如何让用户和银行之间进行交流，来传递公钥，对称加密下这种交流非常的困难。</p><h3 id="2-1-2-非对称加密"><a href="#2-1-2-非对称加密" class="headerlink" title="2.1.2 非对称加密"></a>2.1.2 非对称加密</h3><p>在非对称加密算法中，加密使用的密钥和解密使用的密钥是不相同的。一把是作为公开的公钥，另一把是作为谁都不能给的私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。</p><p>依旧以上述为例，非对称加密的私钥放在银行网站上，不在互联网上传播，这样就可以保证私钥的私密性；银行网站传播对应私钥的公钥。</p><p>这样，客户端给外卖网站发送的时候，用外卖网站的公钥加密。而外卖网站给客户端发送消息的时候，使用客户端的公钥。这样就算有黑客企图模拟客户端获取一些信息，或者半路截获回复信息，但是由于它没有私钥，这些信息它还是打不开。</p><p>非对称加密的另一个问题是如何将公钥给对方： </p><ol><li>放在一个公网的地址上，供下载使用</li><li>在建立连接的时候，传给对方</li></ol><p>需要权威部门的认证来证明我的公钥是官方的，需要证书。证书里面包含公钥还有证书的所有者。注意权威部门是分层级的，通过层层授信背书的方式，来保证非对称加密模式的正常运转。</p><h2 id="2-2-HTTPS的工作模式"><a href="#2-2-HTTPS的工作模式" class="headerlink" title="2.2 HTTPS的工作模式"></a>2.2 HTTPS的工作模式</h2><p>利用非对称加密来传输对称加密的密钥，而真正的双方大数据量的通信都是通过对称加密来进行的。 </p><p><img src="https://i.loli.net/2020/02/02/9o2gqFN1pmkKSte.jpg" alt="fig8.jpg"></p><p>当你登录一个外卖网站的时候，由于是 HTTPS，客户端会发送 Client Hello 消息到服务器，以明文传输 TLS 版本信息、加密套件候选列表、压缩算法候选列表等信息。另外，还会有一个随机数，在协商对称密钥的时候使用。</p><p>然后，外卖网站返回 Server Hello 消息, 告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等，还有一个随机数，用于后续的密钥协商。</p><p>然后，外卖网站会给你一个服务器端的证书，然后说：“Server Hello Done，我这里就这些信息了。”</p><p>你当然不相信这个证书，于是你从自己信任的 CA 仓库中，拿 CA 的证书里面的公钥去解密外卖网站的证书。如果能够成功，则说明外卖网站是可信的。这个过程中，你可能会不断往上追溯 CA、CA 的 CA、CA 的 CA 的 CA，反正直到一个授信的 CA，就可以了。</p><p>证书验证完毕之后，觉得这个外卖网站可信，于是客户端计算产生随机数字 Pre-master，发送 Client Key Exchange，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。</p><p>此时无论是客户端还是服务器都有三个随机数：自己的，对端的，以及刚生成的Pre-Master随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。</p><p>客户端Change Cipher Spec, 开始采用协商的通信密钥和加密算法进行加密通信了。然后发送一个 Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。</p><h1 id="3-RTMP协议"><a href="#3-RTMP协议" class="headerlink" title="3. RTMP协议"></a>3. RTMP协议</h1><p>Real Time Messaging </p><p>RTMP协议是应用层协议，是要靠底层可靠的传输层协议（通常是TCP）来保证信息传输的可靠性的。在基于传输层协议的链接建立完成后，RTMP协议也要客户端和服务器通过“握手”来建立基于传输层链接之上的RTMP Connection链接，在Connection链接上会传输一些控制信息，如SetChunkSize,SetACKWindowSize。其中CreateStream命令会创建一个Stream链接，用于传输具体的音视频数据和控制这些信息传输的命令信息。RTMP协议传输时会对数据做自己的格式化，这种格式的消息我们称之为RTMP Message，而实际传输的时候为了更好地实现多路复用、分包和信息的公平性，发送端会把Message划分为带有Message ID的Chunk，每个Chunk可能是一个单独的Message，也可能是Message的一部分，在接受端会根据chunk中包含的data的长度，message id和message的长度把chunk还原成完整的Message，从而实现信息的收发。</p><p>详细应用见<a href="https://www.llchen60.com/2019/01/06/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%83-%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE-%E7%BD%91%E7%BB%9C%E7%9B%B4%E6%92%AD%E5%BD%93%E4%B8%AD%E7%9A%84%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E4%B8%8E%E4%BC%A0%E6%92%AD%E9%97%AE%E9%A2%98/">网络协议-七-流媒体协议-网络直播当中的视频压缩与传播问题</a></p><h1 id="4-HTTP的历史"><a href="#4-HTTP的历史" class="headerlink" title="4. HTTP的历史"></a>4. HTTP的历史</h1><h2 id="4-1-HTTP-0-9-1-0"><a href="#4-1-HTTP-0-9-1-0" class="headerlink" title="4.1 HTTP 0.9/ 1.0"></a>4.1 HTTP 0.9/ 1.0</h2><ul><li>0.9协议十分简单<ul><li>不支持请求头</li><li>只支持GET方法</li></ul></li><li>1.0 扩展了0.9<ul><li>请求中加入了HTTP版本号</li><li>有Header，不管是request还是response都有header<ul><li>将元数据和业务数据解耦，也可以成为业务逻辑和控制逻辑的分离 </li></ul></li><li>增加了HTTP status code标识相关的状态码</li><li>content-type可以传输其它文件了</li><li>缺点是<ul><li>每请求一个资源就要新建一个TCP连接，而且是串行请求的</li></ul></li></ul></li></ul><h2 id="4-2-HTTP-1-1"><a href="#4-2-HTTP-1-1" class="headerlink" title="4.2 HTTP/1.1"></a>4.2 HTTP/1.1</h2><p>主要目的在于解决HTTP1.0的网络性能问题，以及：</p><ul><li>增加<code>keepalive</code>来让HTTP重用TCP连接，重用TCP连接可以省去每次建立连接时需要的TCP三次握手的开销 – 又名 HTTP长连接 - HTTP Persistent Connection </li><li>支持pipeline网络传输<ul><li>只要第一个请求发出，不用等到拿到响应就可以发出第二个请求了</li></ul></li><li>支持 Chunked Responses 在response的时候不必说明Context-length。这样客户端就直到收到服务端的EOF标识才可以断连接了。</li><li>增加了cache control机制</li><li>协议头增加了language, encoding, type等等，让客户端可以跟服务器端进行更多的协商</li><li>加了<code>Host</code> 头，这样子服务器就可以直到你要请求的网站了</li></ul><h2 id="4-3-HTTP-2"><a href="#4-3-HTTP-2" class="headerlink" title="4.3 HTTP/2"></a>4.3 HTTP/2</h2><p>HTTP/1.1虽然说可以重用TCP连接，但是请求依旧串行的，需要保证其顺序。然而，大量的网页请求中都是些资源类的东西，如果我们能并行这类请求，那就会大大增加网络吞吐量和性能。</p><p>另外1.1是以文本的方式来传输数据，然后做zip压缩减少网络带宽，但是这样做就会消耗前端和后端的CPU了。HTTP/2就是为了解决上述的性能问题的。</p><ul><li>二进制协议，增加数据传输的效率</li><li>可以在一个TCP连接中并发请求多个HTTP请求</li><li>压缩头，如果同时发送多个请求，他们的头是一样的或者是类似的，那么协议就会帮助你消除重复的部分</li><li>允许服务端在客户端放cache，又叫做服务端push。也就是说，你没有请求的东西，我服务端可以先送给你放在本地的缓存当中。</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://coolshell.cn/articles/19840.html" target="_blank" rel="noopener">https://coolshell.cn/articles/19840.html</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-HTTP协议&quot;&gt;&lt;a href=&quot;#1-HTTP协议&quot; class=&quot;headerlink&quot; title=&quot;1. HTTP协议&quot;&gt;&lt;/a&gt;1. HTTP协议&lt;/h1&gt;&lt;p&gt;以输入一个网址&lt;a href=&quot;http://www.google.com为例。这是一个
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
      <category term="HTTP" scheme="https://www.llchen60.com/tags/HTTP/"/>
    
      <category term="Network" scheme="https://www.llchen60.com/tags/Network/"/>
    
      <category term="HTTP 2.0" scheme="https://www.llchen60.com/tags/HTTP-2-0/"/>
    
      <category term="QUIC" scheme="https://www.llchen60.com/tags/QUIC/"/>
    
      <category term="HTTPS" scheme="https://www.llchen60.com/tags/HTTPS/"/>
    
  </entry>
  
  <entry>
    <title>网络协议(五)-传输层</title>
    <link href="https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%BA%94-%E4%BC%A0%E8%BE%93%E5%B1%82/"/>
    <id>https://www.llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%BA%94-%E4%BC%A0%E8%BE%93%E5%B1%82/</id>
    <published>2020-02-02T00:50:39.000Z</published>
    <updated>2020-02-02T06:06:58.015Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-UDP协议"><a href="#1-UDP协议" class="headerlink" title="1. UDP协议"></a>1. UDP协议</h1><h2 id="1-1-UDP和TCP协议的区别"><a href="#1-1-UDP和TCP协议的区别" class="headerlink" title="1.1 UDP和TCP协议的区别"></a>1.1 UDP和TCP协议的区别</h2><table><thead><tr><th>类型</th><th>是否面向连接</th><th>传输可靠性</th><th>传输形式</th><th>传输效率</th><th>所需资源</th><th>应用场景</th><th>首部字节</th></tr></thead><tbody><tr><td>TCP</td><td>面向连接</td><td>可靠</td><td>字节流</td><td>慢</td><td>多</td><td>要求通信数据可靠（文件传输）</td><td>20-60</td></tr><tr><td>UDP</td><td>无连接</td><td>不可靠</td><td>数据报文段</td><td>快</td><td>少</td><td>要求通信速度高（视频直播）</td><td>8字节</td></tr></tbody></table><p>TCP是面向连接的，UDP无连接。</p><p>面向连接指，在互通之前，先建立连接，比如TCP三次握手，而UDP不会。建立连接是为了在客户端和服务端维护连接，而建立一定的数据结构来保证所谓的面向连接的特性。</p><p>TCP提供可靠支付，UDP不保证不丢失，不保证按顺序到达</p><p>TCP面向字节流，发送的时候发一个流。这是靠TCP自身的状态维护做的事情。</p><p>UDP继承了IP包的特性，不保证不丢失，不保证按顺序到达。</p><p>TCP具有拥塞控制，意识到丢包或者网络环境不好，会调整整个发送的速度的。UDP不做调整。</p><p>TCP有状态服务，精确记录了发送了没有，接收了没有，以及该接收哪一个了这样的信息。</p><p>如果MAC层定义了本地局域网的传输行为，IP层定义了整个网络端到端的传输行为，这两层基本定义了：网络传输是以包为单位的；二层叫帧，网络层叫包，传输层叫段。包单独传输，自行选段，在不同的设备封装解封装，不保证到达。 </p><h2 id="1-2-UDP-包头"><a href="#1-2-UDP-包头" class="headerlink" title="1.2 UDP 包头"></a>1.2 UDP 包头</h2><p>接收的机器通过看IP头里面的8位协议位来确定数据到底是通过TCP还是UDP来传的。</p><p>无论应用程序写的是用TCP传数据还是UDP传数据，都要监听一个端口。正是这个端口用来区分应用程序，无论是TCP还是UDP都有端口号，根据端口号来将数据交给相应的应用程序。</p><p><img src="https://i.loli.net/2020/02/02/KRSsZMkCaTFN8Vt.jpg" alt="fig1.jpg"></p><h2 id="1-3-UDP-使用场景"><a href="#1-3-UDP-使用场景" class="headerlink" title="1.3 UDP 使用场景"></a>1.3 UDP 使用场景</h2><ol><li><p>需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用</p><p>DHCP 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 又没事，过一会儿还有机会。我们讲过 PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的 TFTP，这个也是基于 UDP 协议的。在还没有操作系统的时候，客户端拥有的资源很少，不适合维护一个复杂的状态机，而是因为是内网，一般也没啥问题。</p><ol start="2"><li>不需要一对一沟通，建立连接，而是可以广播的应用</li></ol></li></ol><p>UDP 的不面向连接的功能，可以使得可以承载广播或者多播的协议。DHCP 就是一种广播的形式，就是基于 UDP 协议的，而广播包的格式前面说过了。</p><p>对于多播，我们在讲 IP 地址的时候，讲过一个 D 类地址，也即组播地址，使用这个地址，可以将包组播给一批机器。当一台机器上的某个进程想监听某个组播地址的时候，需要发送 IGMP 包，所在网络的路由器就能收到这个包，知道有个机器上有个进程在监听这个组播地址。当路由器收到这个组播地址的时候，会将包转发给这台机器，这样就实现了跨路由器的组播。</p><ol start="3"><li>需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候</li></ol><p>同理，UDP 简单、处理速度快，不像 TCP 那样，操这么多的心，各种重传啊，保证顺序啊，前面的不收到，后面的没法处理啊。不然等这些事情做完了，时延早就上去了。而 TCP 在网络不好出现丢包的时候，拥塞控制策略会主动的退缩，降低发送速度，这就相当于本来环境就差，还自断臂膀，用户本来就卡，这下更卡了。</p><p>当前很多应用都是要求低时延的，它们可不想用 TCP 如此复杂的机制，而是想根据自己的场景，实现自己的可靠和连接保证。例如，如果应用自己觉得，有的包丢了就丢了，没必要重传了，就可以算了，有的比较重要，则应用自己重传，而不依赖于 TCP。有的前面的包没到，后面的包到了，那就先给客户展示后面的嘛，干嘛非得等到齐了呢？如果网络不好，丢了包，那不能退缩啊，要尽快传啊，速度不能降下来啊，要挤占带宽，抢在客户失去耐心之前到达。</p><h2 id="1-4-UDP的应用实例"><a href="#1-4-UDP的应用实例" class="headerlink" title="1.4 UDP的应用实例"></a>1.4 UDP的应用实例</h2><h3 id="1-4-1-网页或者APP的访问"><a href="#1-4-1-网页或者APP的访问" class="headerlink" title="1.4.1 网页或者APP的访问"></a>1.4.1 网页或者APP的访问</h3><p>原来访问网页和手机 APP 都是基于 HTTP 协议的。HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的目前主流的移动互联网来讲，建立一次连接需要的时间会比较长，然而既然是移动中，TCP 可能还会断了重连，也是很耗时的。而且目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，<strong>但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。</strong></p><p>而QUIC (Quick UDP Internet Connections)是谷歌提出的一种基于UDP改进的通信协议，QUIC 在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制，是应用层“城会玩”的代表。这一节主要是讲 UDP，QUIC 我们放到应用层去讲。</p><h3 id="1-4-2-流媒体的协议"><a href="#1-4-2-流媒体的协议" class="headerlink" title="1.4.2 流媒体的协议"></a>1.4.2 流媒体的协议</h3><p>现在直播比较火，直播协议多使用 RTMP，这个协议我们后面的章节也会讲，而这个 RTMP 协议也是基于 TCP 的。TCP 的严格顺序传输要保证前一个收到了，下一个才能确认，如果前一个收不到，下一个就算包已经收到了，在缓存里面，也需要等着。对于直播来讲，这显然是不合适的，因为老的视频帧丢了其实也就丢了，就算再传过来用户也不在意了，他们要看新的了，如果老是没来就等着，卡顿了，新的也看不了，那就会丢失客户，所以直播，实时性比较比较重要，宁可丢包，也不要卡顿的。</p><p>另外，对于丢包，其实对于视频播放来讲，有的包可以丢，有的包不能丢，因为视频的连续帧里面，有的帧重要，有的不重要，如果必须要丢包，隔几个帧丢一个，其实看视频的人不会感知，但是如果连续丢帧，就会感知了，因而在网络不好的情况下，应用希望选择性的丢帧。</p><p>还有就是当网络不好的时候，TCP 协议会主动降低发送速度，这对本来当时就卡的看视频来讲是要命的，应该应用层马上重传，而不是主动让步。因而，很多直播应用，都基于 UDP 实现了自己的视频传输协议。</p><h3 id="1-4-3-实时游戏"><a href="#1-4-3-实时游戏" class="headerlink" title="1.4.3 实时游戏"></a>1.4.3 实时游戏</h3><p>游戏有一个特点，就是实时性比较高。快一秒你干掉别人，慢一秒你被别人爆头，所以很多职业玩家会买非常专业的鼠标和键盘，争分夺秒。</p><p>因而，实时游戏中客户端和服务端要建立长连接，来保证实时传输。但是游戏玩家很多，服务器却不多。由于维护 TCP 连接需要在内核维护一些数据结构，因而一台机器能够支撑的 TCP 连接数目是有限的，然后 UDP 由于是没有连接的，在异步 IO 机制引入之前，常常是应对海量客户端连接的策略。</p><p>另外还是 TCP 的强顺序问题，对战的游戏，对网络的要求很简单，玩家通过客户端发送给服务器鼠标和键盘行走的位置，服务器会处理每个用户发送过来的所有场景，处理完再返回给客户端，客户端解析响应，渲染最新的场景展示给玩家。</p><p>如果出现一个数据包丢失，所有事情都需要停下来等待这个数据包重发。客户端会出现等待接收数据，然而玩家并不关心过期的数据，激战中卡 1 秒，等能动了都已经死了。游戏对实时要求较为严格的情况下，采用自定义的可靠 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。</p><h3 id="1-4-4-物联网"><a href="#1-4-4-物联网" class="headerlink" title="1.4.4 物联网"></a>1.4.4 物联网</h3><p>一方面，物联网领域终端资源少，很可能只是个内存非常小的嵌入式系统，而维护 TCP 协议代价太大；另一方面，物联网对实时性要求也很高，而 TCP 还是因为上面的那些原因导致时延大。Google 旗下的 Nest 建立 Thread Group，推出了物联网通信协议 Thread，就是基于 UDP 协议的。</p><h3 id="1-4-5-移动通信领域"><a href="#1-4-5-移动通信领域" class="headerlink" title="1.4.5 移动通信领域"></a>1.4.5 移动通信领域</h3><p>4G网络中移动流量上网的数据面对的协议GTP-U就是基于UDP的。</p><h1 id="2-TCP协议"><a href="#2-TCP协议" class="headerlink" title="2. TCP协议"></a>2. TCP协议</h1><p>更倾向于网络环境是恶劣的，丢包，乱序，重传，拥塞都是常有的事情，很有可能送达不了，所以要从算法层面来保证可靠性。</p><h1 id="2-1-TCP包头格式"><a href="#2-1-TCP包头格式" class="headerlink" title="2.1 TCP包头格式"></a>2.1 TCP包头格式</h1><p><img src="https://i.loli.net/2020/02/02/C5bnKw2gUVLj9Ap.jpg" alt="fig2.jpg"></p><ul><li>源端口号-16</li><li>目的端口号-16</li></ul><p>源端口号和目标端口号，来确定从哪发送，要发送到哪里去。</p><ul><li>序号-32</li></ul><p>给包编序号，解决包的乱序问题</p><ul><li>确认序号-32</li></ul><p>发出去的包要有确认，来确认对方收到了。如果没有收到就需要重发，直到送达为止</p><ul><li>首部长度-4</li><li>保留位-6</li></ul><p>下述的状态位的存在是因为TCP是面向连接的，双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</p><ul><li>URG</li><li>ACK</li></ul><p>回复</p><ul><li>PSH</li><li>RST</li></ul><p>重新连接</p><ul><li>SYN</li></ul><p>发起一个连接</p><ul><li>FIN</li></ul><p>结束连接</p><ul><li>窗口大小-16</li></ul><p>TCP要做流量控制，通信双方各声明一个窗口，标识自己当前的处理能力，保持接收和处理的速度适宜。</p><ul><li>校验和-16</li><li>紧急指针-16</li><li>选项</li><li>数据</li></ul><h2 id="2-2-TCP三次握手"><a href="#2-2-TCP三次握手" class="headerlink" title="2.2 TCP三次握手"></a>2.2 TCP三次握手</h2><p>客户端–发送带有 SYN 标志的数据包–一次握手–服务端<br>服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端<br>传回SYN的原因，确保就是传过来的那个信息</p><p>客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端</p><p>第一次握手：Client 什么都不能确认；Server 确认了对方发送正常<br>第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常<br>第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常</p><p>三次握手除了建立双方的连接以外，还要解决TCP包的序号问题。每个连接都要有不同的序号，这个序号队列的起始序号是随着时间变化的，这样子可以避免有一个包到的有一点晚的问题。</p><p>我们在做设计的时候，会开启keepalive机制，即使没有真实的数据包，也会有探活包来保证连接的保持。</p><p><img src="https://i.loli.net/2020/02/02/n3gk8OYMdvoNHVI.jpg" alt="fig3.jpg"></p><p>一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。</p><h2 id="2-3-TCP四次挥手"><a href="#2-3-TCP四次挥手" class="headerlink" title="2.3 TCP四次挥手"></a>2.3 TCP四次挥手</h2><p>以下是四次挥手的状态时序图</p><p><img src="https://i.loli.net/2020/02/02/hLMrV2E5fA67nsw.jpg" alt="fig4.jpg"></p><p>断开的时候，我们可以看到，当 A 说“不玩了”，就进入 FIN_WAIT_1 的状态，B 收到“A 不玩”的消息后，发送知道了，就进入 CLOSE_WAIT 的状态。</p><p>A 收到“B 说知道了”，就进入 FIN_WAIT_2 的状态，如果这个时候 B 直接跑路，则 A 将永远在这个状态。TCP 协议里面并没有对这个状态的处理，但是 Linux 有，可以调整 tcp_fin_timeout 这个参数，设置一个超时时间。</p><p>如果 B 没有跑路，发送了“B 也不玩了”的请求到达 A 时，A 发送“知道 B 也不玩了”的 ACK 后，从 FIN_WAIT_2 状态结束，按说 A 可以跑路了，但是最后的这个 ACK 万一 B 收不到呢？则 B 会重新发一个“B 不玩了”，这个时候 A 已经跑路了的话，B 就再也收不到 ACK 了，因而 TCP 协议要求 A 最后等待一段时间 TIME_WAIT，这个时间要足够长，长到如果 B 没收到 ACK 的话，“B 说不玩了”会重发的，A 会重新发一个 ACK 并且足够时间到达 B。</p><p>A 直接跑路还有一个问题是，A 的端口就直接空出来了，但是 B 不知道，B 原来发过的很多包很可能还在路上，如果 A 的端口被一个新的应用占用了，这个新的应用会收到上个连接中 B 发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来 B 发送的所有的包都死翘翘，再空出端口来。</p><p>等待的时间设为 2MSL，MSL是Maximum Segment Lifetime, 报文最大生存时间。，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟和 2 分钟等。</p><h2 id="2-4-TCP状态机"><a href="#2-4-TCP状态机" class="headerlink" title="2.4 TCP状态机"></a>2.4 TCP状态机</h2><p><img src="https://i.loli.net/2020/02/02/uEPq9i54UK2Ya8m.jpg" alt="fig5.jpg"></p><h2 id="2-5-重传策略"><a href="#2-5-重传策略" class="headerlink" title="2.5 重传策略"></a>2.5 重传策略</h2><p>TCP传输的时候，每一个包都有一个ID。在建立连接的时候，会商定起始的ID是什么，然后按照ID一个个发送。为了保证不丢包，对于发送的包都要进行应答，但这个应答并不是一个一个来的，而是会应答某个之前的ID，表示都收到了，这种模式称为<strong><em>累计确认</em></strong> 或者<strong><em>累计应答</em></strong>。</p><h3 id="2-5-1-发送端缓存结构"><a href="#2-5-1-发送端缓存结构" class="headerlink" title="2.5.1 发送端缓存结构"></a>2.5.1 发送端缓存结构</h3><p>为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分。</p><p>第一部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。</p><p>第二部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。</p><p>第三部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。</p><p>第四部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。</p><p>区分第三第四部分的原因是为了进行流量控制 - 窗口大小。在TCP里，接收端会给发送端报一个窗口的大小，叫做Advertised Window. 这个窗口的大小应该等于上面的第二部分加上第三部分，超过了这个大小的接收端没法接收。</p><p>因此发送端需要保持以下的数据结构：</p><p><img src="https://i.loli.net/2020/02/02/TbYHfF2AS8XNKoR.jpg" alt="fig6.jpg"></p><ul><li>LastByteAcked：第一部分和第二部分的分界线</li><li>LastByteSent：第二部分和第三部分的分界线</li><li>LastByteAcked + AdvertisedWindow：第三部分和第四部分的分界线</li></ul><h3 id="2-5-2-接收端缓存结构"><a href="#2-5-2-接收端缓存结构" class="headerlink" title="2.5.2 接收端缓存结构"></a>2.5.2 接收端缓存结构</h3><p>第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的。</p><p>第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。</p><p>第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。</p><p><img src="https://i.loli.net/2020/02/02/gnSOQJytzlDp2EF.jpg" alt="fig7.jpg"></p><ul><li>MaxRcvBuffer：最大缓存的量；</li><li>LastByteRead 之后是已经接收了，但是还没被应用层读取的；</li><li>NextByteExpected 是第一部分和第二部分的分界线。</li></ul><p>第二部分的窗口有多大呢？</p><p>NextByteExpected 和 LastByteRead 的差其实是还没被应用层读取的部分占用掉的 MaxRcvBuffer 的量，我们定义为 A。AdvertisedWindow 其实是 MaxRcvBuffer 减去 A。也就是：AdvertisedWindow=MaxRcvBuffer-((NextByteExpected-1)-LastByteRead)。那第二部分和第三部分的分界线在哪里呢？NextByteExpected 加 AdvertisedWindow 就是第二部分和第三部分的分界线，其实也就是 LastByteRead 加上 MaxRcvBuffer。其中第二部分里面，由于受到的包可能不是顺序的，会出现空挡，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。</p><h3 id="2-5-3-顺序问题和丢包问题"><a href="#2-5-3-顺序问题和丢包问题" class="headerlink" title="2.5.3 顺序问题和丢包问题"></a>2.5.3 顺序问题和丢包问题</h3><p><strong>超时重试</strong>： 对于每一个发送了但是没有ACK的包，都设定一个定时器，超过了一定时间就重新尝试。这是时间不宜太短，时间必须大于往返时间RTT(Round trip time)，否则会引起不必要的重传。</p><p>估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为<strong><em>自适应重传算法</em></strong></p><p><strong>超时间隔加倍</strong>：每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</p><p><strong>快速重传机制</strong>：有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的 ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。</p><p>另外一种方式成为<strong>Selective Acknowledgment(SACK)</strong>, ）。这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方。例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了。</p><h3 id="2-5-4-流量控制问题"><a href="#2-5-4-流量控制问题" class="headerlink" title="2.5.4 流量控制问题"></a>2.5.4 流量控制问题</h3><p>在对于包的确认中，会携带一个窗口的大小。</p><p>我们先假设窗口不变的情况，窗口始终为 9。4 的确认来的时候，会右移一个，这个时候第 13 个包也可以发送了。</p><p><img src="https://i.loli.net/2020/02/02/hNHO7CLUzQqfwmt.jpg" alt="fig8.jpg"></p><p>这个时候，假设发送端发送过猛，会将第三部分的 10、11、12、13 全部发送完毕，之后就停止发送了，未发送可发送部分为 0。</p><p><img src="https://i.loli.net/2020/02/02/XaQ4KcUZe7vCNPn.jpg" alt="fig9.jpg"></p><p>当对于包 5 的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第 14 个包才可以发送。</p><p><img src="https://i.loli.net/2020/02/02/v3BKa6imlSHhXRd.jpg" alt="fig10.jpg"></p><p>如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送。</p><p>我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包 6 确认后，窗口大小就不能再是 9 了，就要缩小一个变为 8。</p><p><img src="https://i.loli.net/2020/02/02/Sdia3Akts1cKGnD.jpg" alt="fig11.jpg"></p><p>这个新的窗口 8 通过 6 的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从 9 改成了 8。</p><p><img src="https://i.loli.net/2020/02/02/MpGW7ZkgRBuwQxq.jpg" alt="fig12.jpg"></p><p>如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。</p><p><img src="https://i.loli.net/2020/02/02/oI1u3nGxDOyfe4q.jpg" alt="fig13.jpg"></p><p>当这个窗口通过包 14 的确认到达发送端的时候，发送端的窗口也调整为 0，停止发送。</p><p><img src="https://i.loli.net/2020/02/02/lqjmcvphQ6wZoNU.jpg" alt="fig14.jpg"></p><p>如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。</p><h3 id="2-5-5-拥塞控制"><a href="#2-5-5-拥塞控制" class="headerlink" title="2.5.5 拥塞控制"></a>2.5.5 拥塞控制</h3><p>通过控制窗口的大小来控制，拥塞窗口是防止将网络塞满。类比水管： 水管里面的水量 = 水管粗细 x 水管长度。 同理，网络通道的容量 = 带宽 x 往返延迟。如果我们设置发送窗口，使得发送但未确认的包为通道的容量，就能够撑满整个管道。</p><p><img src="https://i.loli.net/2020/02/02/WLgk5KJ8i4vMOlP.jpg" alt="fig15.jpg"></p><p>如图所示，假设往返时间为 8s，去 4s，回 4s，每秒发送一个包，每个包 1024byte。已经过去了 8s，则 8 个包都发出去了，其中前 4 个包已经到达接收端，但是 ACK 还没有返回，不能算发送成功。5-8 后四个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为 8 个包，正好等于带宽，也即每秒发送 1 个包，乘以来回时间 8s。</p><p>如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？</p><p>我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费 1s，所以到达另一端需要耗费 4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。</p><p>这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s 肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。</p><p>于是 TCP 的拥塞控制主要来避免两种现象，包丢失以及超时重传。一旦发生了这种现象，就说明发送速度太快了，TCP采用慢启动来避免发送速度太快的现象。</p><p>一条 TCP 连接开始，cwnd 设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd 加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认 cwnd 加一，两个确认 cwnd 加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认 cwnd 加一，四个确认 cwnd 加四，于是一次能够发送八个。可以看出这是呈指数性增长的。</p><p>在增长到ssthresh值-65535字节的时候，会减速变成线性增长。</p><p>每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加 1/8，八个确认一共 cwnd 增加 1，于是一次能够发送九个，变成了线性增长。</p><p>采用快速重传算法解决丢包问题，当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。</p><p>但是TCP的拥塞控制存在问题：</p><ol><li>丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。</li><li>TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实 TCP 只要填满管道就可以了，不应该接着填，直到连缓存也填满。</li></ol><p>为了解决这个问题，就有了TCP BBR拥塞算法，企图找到一个平衡点，通过不断加快发送速度，将管道填满，但是不填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以达到高带宽和低时延的平衡。</p><p><img src="https://i.loli.net/2020/02/02/ApmJWIycxjXfNaq.jpg" alt="fig16.jpg"></p><h1 id="3-套接字Socket"><a href="#3-套接字Socket" class="headerlink" title="3. 套接字Socket"></a>3. 套接字Socket</h1><p>Socket编程是基于TCP和UDP协议的。Socket编程进行的是端到端的通信，往往意识不到中间经过了多少局域网、路由器，因而能够设置的参数是在端到端协议智商的网络层和传输层上。</p><p>网络层： 指定是IPV4(AF_INET)还是IPV6(AF_INET6). </p><p>传输层： 指定是TCP(SOCK_STREAM)还是UDP(SOCK_DGRAM)。</p><h2 id="3-1-基于TCP协议的Socket程序函数调用过程"><a href="#3-1-基于TCP协议的Socket程序函数调用过程" class="headerlink" title="3.1 基于TCP协议的Socket程序函数调用过程"></a>3.1 基于TCP协议的Socket程序函数调用过程</h2><p>首先是两端要创建Socket，这之后<br>TCP 的服务端要先监听一个端口，一般是先调用 bind 函数，给这个 Socket 赋予一个 IP 地址和端口。为什么需要端口呢？要知道，你写的是一个应用程序，当一个网络包来的时候，内核要通过 TCP 头里面的这个端口，来找到你这个应用程序，把包给你。为什么要 IP 地址呢？有时候，一台机器会有多个网卡，也就会有多个 IP 地址，你可以选择监听所有的网卡，也可以选择监听一个网卡，这样，只有发给这个网卡的包，才会给你。</p><p>当服务端有了 IP 和端口号，就可以调用 listen 函数进行监听。在 TCP 的状态图里面，有一个 listen 状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。</p><p>在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于 established 状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于 syn_rcvd 的状态。</p><p>接下来，服务端调用Accept函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。 </p><p>在服务端等待的时候，客户端可以通过 connect 函数发起连接。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的 accept 就会返回另一个 Socket。注意**监听的socket和真正用来传数据的Socket是两个，一个叫做监听Socket，一个叫做已连接Socket。 </p><p>连接建立成功之后，双方开始通过read和write函数来读写数据，就像往一个文件流里面写东西一样。</p><p>下图是基于TCP协议的Socket程序函数调用过程。</p><p><img src="https://i.loli.net/2020/02/02/tLb6hp47lYN3yZu.jpg" alt="fig17.jpg"></p><p>说 TCP 的 Socket 就是一个文件流，是非常准确的。因为，Socket 在 Linux 中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。</p><p>在内核中，Socket 是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构 task_struct，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。</p><p>这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个 inode，只不过 Socket 对应的 inode 不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。</p><p>在这个结构里面，主要是两个队列，一个是发送队列，一个是接收队列。在这两个队列里面保存的是一个缓存sk_buff.这个缓存里面能够看到完整的包的结构。</p><p><img src="https://i.loli.net/2020/02/02/Ag5IO6YfPbZ3SUQ.jpg" alt="fig18.jpg"></p><h2 id="3-2-基于UDP协议的Socket程序函数调用过程"><a href="#3-2-基于UDP协议的Socket程序函数调用过程" class="headerlink" title="3.2 基于UDP协议的Socket程序函数调用过程"></a>3.2 基于UDP协议的Socket程序函数调用过程</h2><p>和TCP协议的Socket编程相比，不同在于UDP是无连接的，不需要三次握手，也不需要调用listen和connect，但是UDP的交互仍然需要IP和端口号，因此也需要bind。UDP是没有维护连接状态的，因为不需要每对连接建立一组socket，而是只要有一个socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都需要调用sendto和recvfrom，都可以传入IP地址和端口。</p><p><img src="https://i.loli.net/2020/02/02/5XzPcB4R9Mrpf1b.jpg" alt="fig19.jpg"></p><h2 id="3-3-服务器最大连接数"><a href="#3-3-服务器最大连接数" class="headerlink" title="3.3 服务器最大连接数"></a>3.3 服务器最大连接数</h2><pre><code>{本机 IP, 本机端口, 对端 IP, 对端端口}</code></pre><p>服务器通常固定在某个本地端口上监听，等待客户端的连接请求。因此，服务端端 TCP 连接四元组中只有对端 IP, 也就是客户端的 IP 和对端的端口，也即客户端的端口是可变的，因此，最大 TCP 连接数 = 客户端 IP 数×客户端端口数。对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。</p><p>当然，服务端最大并发 TCP 连接数远不能达到理论上限。首先主要是文件描述符的限制，，按照上面的原理，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目；另一个限制是内存，按照上面的数据结构，每个TCP连接都要占用一定的内存，操作系统是有限的。</p><p>因此需要寻找方法去降低每个项目消耗的资源数目</p><h3 id="3-3-1-多进程方式"><a href="#3-3-1-多进程方式" class="headerlink" title="3.3.1 多进程方式"></a>3.3.1 多进程方式</h3><p>这就相当于你是一个代理，在那里监听来的请求。一旦建立了一个连接，就会有一个已连接 Socket，这时候你可以创建一个子进程，然后将基于已连接 Socket 的交互交给这个新的子进程来做。就像来了一个新的项目，但是项目不一定是你自己做，可以再注册一家子公司，招点人，然后把项目转包给这家子公司做，以后对接就交给这家子公司了，你又可以去接新的项目了。</p><p>在linux中使用fork来做的。</p><p><img src="https://i.loli.net/2020/02/02/9MOWKfI7kzEdD6V.jpg" alt="fig20.jpg"></p><p>因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得。</p><p>接下来，子进程就可以通过这个已连接 Socket 和客户端进行互通了，当通信完毕之后，就可以退出进程，那父进程如何知道子进程干完了项目，要退出呢？还记得 fork 返回的时候，如果是整数就是父进程吗？这个整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出。</p><h3 id="3-3-2-多线程方式"><a href="#3-3-2-多线程方式" class="headerlink" title="3.3.2 多线程方式"></a>3.3.2 多线程方式</h3><p>相当于不成立子公司了，而是在公司里成立新的项目组。在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一个引用而已。</p><p><img src="https://i.loli.net/2020/02/02/a8SoUfLwyzp5Ze3.jpg" alt="fig21.jpg"></p><p>上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程。一台机器无法创建很多进程或者线程。有个C10k. ，它的意思是一台机器要维护 1 万个连接，就要创建 1 万个进程或者线程，那么操作系统是无法承受的。如果维持 1 亿用户在线需要 10 万台服务器，成本也太高了。</p><h3 id="3-3-3-IO多路复用，一个线程维护多个Socket"><a href="#3-3-3-IO多路复用，一个线程维护多个Socket" class="headerlink" title="3.3.3 IO多路复用，一个线程维护多个Socket"></a>3.3.3 IO多路复用，一个线程维护多个Socket</h3><p>即一个线程维护多个Socket。 由于 Socket 是文件描述符，因而某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，这就是项目进度墙。，然后调用 select 函数来监听文件描述符集合是否有变化。一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。。</p><h3 id="3-3-4-IO多路复用，subscribe-publish模式"><a href="#3-3-4-IO多路复用，subscribe-publish模式" class="headerlink" title="3.3.4 IO多路复用，subscribe/publish模式"></a>3.3.4 IO多路复用，subscribe/publish模式</h3><p>上面 select 函数还是有问题的，因为每次 Socket 所在的文件描述符集合中有 Socket 发生变化的时候，都需要通过轮询的方式，也就是需要将全部项目都过一遍的方式来查看进度，这大大影响了一个项目组能够支撑的最大的项目数量。因而使用 select，能够同时盯的项目数量由 FD_SETSIZE 限制。</p><p>如果改成事件通知的方式，情况就会好很多，项目组不需要通过轮询挨个盯着这些项目，而是当项目进度发生变化的时候，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。</p><p>能完成这件事情的函数叫 epoll，它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发送变化的时候，就会主动通知。</p><p><img src="https://i.loli.net/2020/02/02/MqYfXpClu6AGvQs.jpg" alt="fig22.jpg"></p><p>如图所示，假设进程打开了 Socket m, n, x 等多个文件描述符，现在需要通过 epoll 来监听是否这些 Socket 都有事件发生。其中 epoll_create 创建一个 epoll 对象，也是一个文件，也对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，在红黑树里，要保存这个 epoll 要监听的所有 Socket。</p><p>当 epoll_ctl 添加一个 Socket 的时候，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 来了一个事件的时候，可以从这个列表中得到 epoll 对象，并调用 call  back 通知它。</p><p>这种通知方式使得监听的 Socket 数据增加的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-UDP协议&quot;&gt;&lt;a href=&quot;#1-UDP协议&quot; class=&quot;headerlink&quot; title=&quot;1. UDP协议&quot;&gt;&lt;/a&gt;1. UDP协议&lt;/h1&gt;&lt;h2 id=&quot;1-1-UDP和TCP协议的区别&quot;&gt;&lt;a href=&quot;#1-1-UDP和TCP协议的区
      
    
    </summary>
    
    
      <category term="Web" scheme="https://www.llchen60.com/categories/Web/"/>
    
    
      <category term="Network" scheme="https://www.llchen60.com/tags/Network/"/>
    
      <category term="UDP" scheme="https://www.llchen60.com/tags/UDP/"/>
    
      <category term="TCP" scheme="https://www.llchen60.com/tags/TCP/"/>
    
      <category term="Socket" scheme="https://www.llchen60.com/tags/Socket/"/>
    
  </entry>
  
</feed>
