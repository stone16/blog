<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Developing on AWS Note.9 Step Functions, ElasticCache</title>
      <link href="/Developing-on-AWS-Note-9-Step-Functions-ElasticCache/"/>
      <url>/Developing-on-AWS-Note-9-Step-Functions-ElasticCache/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Understanding-the-need-for-step-functions"><a href="#1-Understanding-the-need-for-step-functions" class="headerlink" title="1. Understanding the need for step functions"></a>1. Understanding the need for step functions</h1><ul><li><p>Step functions make it easy to coordinate components of distributed applications and microservices by using visual workflows. </p></li><li><p>Microservices are processes that communicate with each other over a network to complete a larger goal. </p></li><li><p>Applications built as a collections of microservices are more resilient and easier to scale. </p></li><li><p>Have cases that we begin to have more functions and they continue to grow</p></li><li><p>Need a mechanism to scale out, easily handle errors and timeouts, easily build and operate</p></li></ul><h1 id="2-Intro-to-AWS-Step-Functions"><a href="#2-Intro-to-AWS-Step-Functions" class="headerlink" title="2. Intro to AWS Step Functions"></a>2. Intro to AWS Step Functions</h1><ul><li>define a workflow called a state machine made up of states</li><li>each order is an execution through this state machine </li><li>each execution starts with an input and the states transform it</li><li>step functions keep track of the state of each execution </li><li>actually, it’s a web service that enables you to coordinate the components of distributed applications and microservices using visual workflows.</li><li>provides a reliable way to coordinate components and step through the functions of your application. </li><li>automatically triggers and tracks each step, and retries when there are errors</li><li>lifecycle<ul><li>define workflow as a series of steps and transitions between each step, also known as a state machine</li><li>step functions ingests your JSON template and turns it into a real-time graphical view , help you make sense of your state machine’s current state</li></ul></li><li>benefits <ul><li>productivity<ul><li>build applications quickly  </li></ul></li><li>agility<ul><li>scale and recover reliably </li></ul></li><li>resilience <ul><li>evolve applications easily </li></ul></li></ul></li><li>Terminology<ul><li>state machine - workflow template<ul><li>an object that has a set number of operating conditions that depend on its previous condition to determine output </li><li>AWS step functions allows you to create and automate state machines within the AWS env<ul><li>with the use of a JSON-based Amazon State Language</li><li>a collection states, that can to work (task states), determine which states to transition to next (Choicestates), stop an execution with an error</li></ul></li><li>state common features<ul><li>each state must have a type field indicating what type of state it is</li><li>each state can have an optinal comment field to hold a human readable comment about, or description of, the state</li><li>Each state (except a Succeed or Fail state) requires a Next field or, alternatively, can become a terminal state by specifying an End field.</li></ul></li><li>state types<ul><li>task </li><li>choise - adds branching logic</li><li>parallel </li><li>wait</li><li>fail</li><li>succeed </li><li>pass</li></ul></li></ul></li><li>execution - specific workflow based on template</li><li>task - lambda function or activity <ul><li>An activity consists of program code or a task that waits for <strong>an operator to perform</strong> an action or to provide input. You can host activities on Amazon EC2, on Amazon ECS, or even on mobile devices. Activities poll Step Functions using the <strong>GetActivityTask</strong> and <strong>SendTaskSuccess</strong>, <strong>SendTaskFailure</strong>, and <strong>SendTaskHeartbeat</strong> API actions. Activities represent workers (processes or threads), implemented and hosted by you, that perform a specific task.</li><li>A Lambda function is a cloud-native task that runs on AWS Lambda. You can write Lambda functions in a variety of programming languages, using the AWS Management Console or by uploading code to Lambda. Lambda functions execute a function using AWS Lambda. To specify a Lambda function, use the ARN of the Lambda function in the Resource field </li></ul></li><li>activity - handle for external compute</li><li>task token - ID for instance of activity </li><li>heartbeat - ping from task indicating that it is still running </li><li>failure </li><li>success </li></ul></li></ul><h1 id="3-Caching-for-scalibility"><a href="#3-Caching-for-scalibility" class="headerlink" title="3. Caching for scalibility"></a>3. Caching for scalibility</h1><h2 id="3-1-Caching-Overview"><a href="#3-1-Caching-Overview" class="headerlink" title="3.1 Caching Overview"></a>3.1 Caching Overview</h2><ul><li>Benefits<ul><li>Provides high throughput, low latency access to commonly accessed application data, <strong>by storing the data in memory</strong></li><li>imrpove the speed </li><li>reduce the response latency </li><li>the following types of information or applications can benefit from caching:<ul><li>results of database queries</li><li>results of intensive calculations</li><li>results of remote API calls </li></ul></li></ul></li></ul><ul><li>when to consider caching your data<ul><li>data that requires a slow and expensive query to acquire </li><li>relatively static and frequently accessed data </li><li>information that can afford to be stale for some time</li><li>data should be relatively static and frequently accessed</li><li>Cache data should always be considered and treated as stale</li></ul></li></ul><h2 id="3-2-Caching-Strategy"><a href="#3-2-Caching-Strategy" class="headerlink" title="3.2 Caching Strategy"></a>3.2 Caching Strategy</h2><h1 id="4-Amazon-ElastiCache"><a href="#4-Amazon-ElastiCache" class="headerlink" title="4. Amazon ElastiCache"></a>4. Amazon ElastiCache</h1><ul><li>a webservice that makes it easy to deploy, operate and scale an in-memory cache in the cloud</li><li>ElastiCache improves the performance of web applications by allowing you to retrieve information from fast, managed, in-memory caches, instead of relying entirely on slower disk-based databases </li><li>ElastiCache supports<ul><li>Memcached</li><li>Redis</li></ul></li></ul><h2 id="4-1-Memcached-vs-Redis"><a href="#4-1-Memcached-vs-Redis" class="headerlink" title="4.1 Memcached vs Redis"></a>4.1 Memcached vs Redis</h2><ul><li>Memcached<ul><li>multithreading </li><li>low maintenance </li><li>easy horizontal scalability with auto discovery </li><li>single AZ </li><li>lack persistence<ul><li>if you terminate node or scale it down, you lose the data stored in that cache memory  </li></ul></li></ul></li><li>Redis<ul><li>single thread </li><li>support for data structures <ul><li>strings</li><li>hashes</li><li>lists</li><li>sets</li><li>sorted sets with range queries</li><li>bitmaps</li><li>hypolog</li><li>geospatial indexes with radius queries</li></ul></li><li>persistence </li><li>atomic operations </li><li>pub/ sub messaging</li><li>read replicas/ failover</li><li>cluster mode/ sharded clusters</li><li>multiple AZ </li></ul></li></ul><h2 id="4-2-Terminology"><a href="#4-2-Terminology" class="headerlink" title="4.2 Terminology"></a>4.2 Terminology</h2><ul><li>node<ul><li>smallest building block of an ElastiCache deployment </li></ul></li><li>cluster<ul><li>a logical grouping of one or more nodes</li></ul></li><li>replication group<ul><li>a collection of Redis clusters</li><li>with one primary read-write cluster and up to five secondary, read only clusters, which are called read replicas. </li><li>each read replica maintains a copy of the data from the primary cluster</li><li>asynchronous replication mechanisms are used to keep the read-replicas synchronized with the primary cluster </li><li>applications can <strong>read from any cluster in the replication group</strong> </li><li>applications can write only to the primary cluster</li><li>read replicas enhance scalability and guard against data loss </li></ul></li></ul><h2 id="4-3-Cache-hit-amp-Cache-Miss-Scenarios"><a href="#4-3-Cache-hit-amp-Cache-Miss-Scenarios" class="headerlink" title="4.3 Cache hit &amp; Cache Miss Scenarios"></a>4.3 Cache hit &amp; Cache Miss Scenarios</h2><ul><li>cache hit occurs when the cache contains the information required</li><li>cache miss occurs when the cache does not contain the information requested</li><li>ElastiCache caches data as key-value pairs.</li><li>An application can retrieve a value corresponding to a specific key. </li><li>An application can store an item in cache by specifying a key, value, and an expiration time(TTL). </li></ul><h2 id="4-4-Cache-strategies"><a href="#4-4-Cache-strategies" class="headerlink" title="4.4 Cache strategies"></a>4.4 Cache strategies</h2><ul><li>Lazy loading<ul><li>Whenever your application requests data, it first makes the request to the ElastiCache cache. </li><li>If the data exists in the cache and is current, ElastiCache returns the data to your application. </li><li>If the data does not exist in the cache, or the data in the cache has expired, your application requests the data from your data store which returns the data to your application. </li><li>Your application then writes the data received from the store to the cache so it can be more quickly retrieved next time it is requested.</li><li>Lazy Loading is a caching strategy that loads data into the cache only when necessary. </li><li>Avoid filling up the cache with unnecessary data</li><li>advantages<ul><li>Only requested data is cached. Since most data is never requested, lazy loading avoids filling up the cache with data that isn’t requested.</li><li>Node failures are not fatal. </li><li>When a node fails and is replaced by a new, empty node the application continues to function, though with increased latency. As requests are made to the new node each cache miss results in a query of the database and adding the data copy to the cache so that subsequent requests are retrieved from the cache.</li></ul></li><li>disadvantages<ul><li>a cache miss penalty, each cache miss results in 3 trips<ul><li>initial request for data from the cache</li><li>query of the database for the data</li><li>write the data to the cache </li></ul></li><li>may receive stale data because another application may have updated the data in the database behind the scenes. </li></ul></li></ul></li><li>write through <ul><li>this strategy adds data or updates data in the cache whenever data is written to the database </li><li>advantages<ul><li>data in the cache is never stale, always current</li></ul></li><li>disadvantages<ul><li>write penalty, involve two trips<ul><li>a write to cache, and a write to the database</li><li>missing data: When a new node is created to scale up or to replace a failed node, the node does not contain all data. Data continues to be missing until it is added or updated in the database. In this scenario, you might choose to use a lazy caching approach to repopulate the cache</li><li>Unused data: Since most data is never read, there can be a lot of data in the cluster that is never read.</li><li>Cache churn: The cache may be updated often if certain records are updated repeatedly.</li></ul></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Step Functions </tag>
            
            <tag> ElasticCache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.8 SQS, SNS</title>
      <link href="/Developing-on-AWS-Note-8-SQS-SNS/"/>
      <url>/Developing-on-AWS-Note-8-SQS-SNS/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Why-use-a-queuing-service"><a href="#1-Why-use-a-queuing-service" class="headerlink" title="1. Why use a queuing service?"></a>1. Why use a queuing service?</h1><p>Consider a scenario where an application produces messages that must be processed by a consumer downstream. The producer needs to know how to connect to the consumer. If the consumer fails for some reason, then messages may be lost. If new consumer instances are launched to recover from failure or to keep up with an increased workload, the producer needs to be explicitly made aware of the new consumer instances. In this scenario, the producer is tightly coupled with the consumers and the coupling is prone to brittleness.</p><p>In this way, there will be a strong interdependency between teh consumer and the producer, which is a <strong>tightly coupled system</strong>. which is not fault tolerant, if any one component in our system fails, the entire system will fail. </p><ul><li>Having a queue service decouples the producer from the consumer.<ul><li>queue is a temprary repositiory for messages that are awaiting processing. </li><li>acts as a buffer between the component producing data and the component receiving the data for processing. </li><li>A queue supports multiple producers and consumers interacting with the same queue. </li><li>A single queue can be used <strong>simultaneously</strong> by many distributed application components, with no need for those components to coordinate with each other to share the queue. A queue delivers each message at least once.</li><li>In this way, a producer can put messages on the queue regardless if they are being read by the consumer or not. </li></ul></li></ul><h1 id="2-Developing-with-Amazon-Simple-Queue-Service-Amazon-SQS"><a href="#2-Developing-with-Amazon-Simple-Queue-Service-Amazon-SQS" class="headerlink" title="2. Developing with Amazon Simple Queue Service (Amazon SQS)"></a>2. Developing with Amazon Simple Queue Service (Amazon SQS)</h1><h2 id="2-1-Types"><a href="#2-1-Types" class="headerlink" title="2.1 Types"></a>2.1 Types</h2><ul><li>Standard queues<ul><li>message ordering is not guranteed</li><li>message may be duplicated </li><li>maximum throughput </li></ul></li><li>FIFO queue<ul><li>message ordering is preserved</li><li>message only receive once</li><li>limited throughput (300 transactions per second)</li></ul></li></ul><h2 id="2-2-Used-to-solve-tightly-linked-systems"><a href="#2-2-Used-to-solve-tightly-linked-systems" class="headerlink" title="2.2 Used to solve tightly linked systems"></a>2.2 Used to solve tightly linked systems</h2><ul><li>problem to be solved<ul><li>An example of image processing: the sequential operations of uploading, storing, and encoding the image, creating a thumbnail, and copyrighting are tightly linked to each other. This tight linkage complicates the recovery operations when there has been a failure.</li></ul></li><li>queuing chain pattern<ul><li>Achieve loose coupling of systems by using queues between systems and exchanging messages that transfer jobs</li><li>This enables asynchronous linking of systems.</li><li>lets you increase the number of virtual servers that receive and process the messages in parallel. </li><li>If there is no image to process, you can configure auto scaling to terminate the servers that are in excess.</li></ul></li></ul><h2 id="2-3-Operations"><a href="#2-3-Operations" class="headerlink" title="2.3 Operations"></a>2.3 Operations</h2><h3 id="2-3-1-Client"><a href="#2-3-1-Client" class="headerlink" title="2.3.1 Client"></a>2.3.1 Client</h3><ul><li><p>sendMessage </p><ul><li>send message to a specific queue</li><li>max size: 256 KB </li><li>parameters of a sendMessage operation<ul><li>QueueUrl: specify the url of the queue that the message should be sent to</li><li>MessageBody: specify the message to send </li><li>DelaySeconds: specify the number of seconds to delay a specific message. Messages will become available for processing after the delay time is finished. </li><li>MessageAttributes <ul><li>specify structured metadata about the message<ul><li>timestamp</li><li>signature</li><li>geospatial data</li></ul></li></ul></li></ul></li></ul></li><li><p>receiveMessage</p><ul><li>specify short polling or long polling </li><li>When requesting to get a message from the queue, <strong>you cannot specify which message to get</strong>. You simply specify the maximum number of messages you want to get (up to 10), and Amazon SQS returns up to that maximum number.</li><li>parameters <ul><li>WaitTimeSeconds</li><li>MaxNumberOfMessages</li><li>VisibilityTimeout<ul><li>period of time that a message is invisible to the rest of your application after an application component gets it from the queue.</li><li>prevents multiple components from processing the same message </li><li>during the visibility time, the component that received the message usually processes it and then delete it from the queue. </li><li>this prevents multiple components from processing the same message </li></ul></li></ul></li><li>polling types<ul><li>short polling<ul><li>Amazon SQS samples a subset of the servers (based on a weighted random distribution) and returns messages from only the sampled servers</li><li>if you keep retrieving from your queues, SQS samples all the servers, and you will eventually receive all of your messages. </li><li>occurs when the WaitTimeSeconds parameter of a ReceiveMessage call is set to 0 or the queue attribute ReceiveMessageWaitTimeSeconds is 0</li></ul></li><li>long polling<ul><li>better and preferred way to retrieve messages </li><li>if your application has a single thread polling multiple queues, switching from short polling to long polling will likely not work, because the single thread will wait for the long poll timeout on any empty queues, delaying the processing of any queues which may contain messages. </li><li>Amazon SQS long polling doesn’t return a response until a message arrives in the queue or the long poll times out </li><li>inexpensive </li><li>unless the connection time out, the response to the ReceiveMessage request will contain at least one of the available messages. </li><li>Reduce the cost of using Amazon SQS by reducing the number of empty responsed and false empty responses. </li></ul></li></ul></li></ul></li></ul><ul><li>deleteMessage<ul><li>When you receive the message, you <strong>must delete it from the queue</strong> to acknowledge that you processed the message and no longer need it. </li><li>You specify which message to delete by providing the <strong>receipt handle</strong> that Amazon SQS returned when you received the message.</li></ul></li><li>deleteMessageBatch</li><li>PuregeQueue<ul><li>delete all the messages in an AmazonSQS queue without deleting the queue itself.  </li></ul></li></ul><h3 id="2-3-2-Basic-Queue-Operations"><a href="#2-3-2-Basic-Queue-Operations" class="headerlink" title="2.3.2 Basic Queue Operations"></a>2.3.2 Basic Queue Operations</h3><ul><li>CreateQueue <ul><li>attributes<ul><li>delaySeconds<ul><li>the delivery of all messages in the queue will be delayed </li><li>default 0, maximum 15 min</li></ul></li><li>maximumMessageSize<ul><li>the limit of how many bytes a message can contain before Amazon SQS rejects it </li><li>max 256 KB</li></ul></li><li>messageRetentionPeriod<ul><li>seconds SQS retains a message </li></ul></li><li>ReceiveMessageWaitTimeSeconds<ul><li>time for which a ReceiveMessage call will wait for a message to arrive </li><li>max configurable wait time is 20 seconds </li><li>default 0</li></ul></li><li>VisibilityTimeout<ul><li>period of time that a message is invisbile to the rest of your application  </li></ul></li></ul></li></ul></li><li>SetQueueAttributes</li><li>GetQueueAttributes</li><li>GetQueueUrl</li><li>ListQueues</li><li>DeleteQueue</li></ul><h2 id="2-4-Message-Lifecycle"><a href="#2-4-Message-Lifecycle" class="headerlink" title="2.4 Message Lifecycle"></a>2.4 Message Lifecycle</h2><ul><li>Immediately after a message is received, it <strong>remains in the queue</strong>. To prevent other consumers from processing the message again, Amazon SQS sets a visibility timeout, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. </li><li>The default visibility timeout for a message is 30 seconds. The maximum is 12 hours.</li><li>Or consumer could send a separate request which acknowledges that you no longer need the message because you have successfully received and processed it </li><li>Maximum message retention period<ul><li>SQS automatically deletes messages that have been in a queue for more than maximum message retension period</li><li>default is 4 days </li><li>can be set from 60 seconds to 14 days </li></ul></li></ul><h2 id="2-5-Queue-and-Message-Identifiers"><a href="#2-5-Queue-and-Message-Identifiers" class="headerlink" title="2.5 Queue and Message Identifiers"></a>2.5 Queue and Message Identifiers</h2><ul><li>Queue URL <ul><li>when creating a new queue, must provide a queue name that is unique within the scope of all your queues. </li><li>AWS assgin each queue an identifier called a <strong>queue URL</strong>, which includes the queue name and other components that Amazon SQS determines. </li></ul></li><li>Message ID<ul><li>For each message, Amazon SQS returns a system-assigned message ID in the SendMessage response. </li></ul></li><li>Receipt Handle<ul><li>Each time you receive a message from a queue, you receive a receipt handle for that message. </li><li>The handle is assoiciated with the act of receiving the message, not with the message itself. </li><li>To delete a message, you need the message’s receipt handle instead of the message ID. </li></ul></li></ul><h2 id="2-6-Dead-letter-queues"><a href="#2-6-Dead-letter-queues" class="headerlink" title="2.6 Dead letter queues"></a>2.6 Dead letter queues</h2><ul><li>A queue of messages that were not able to be processed </li><li>Use dead-letter queues with standard queues.</li><li>Dead letter queues help you troubleshoot incorrect message transmission operations </li></ul><h2 id="2-7-Sharing-a-Queue"><a href="#2-7-Sharing-a-Queue" class="headerlink" title="2.7 Sharing a Queue"></a>2.7 Sharing a Queue</h2><ul><li>Shared queues<ul><li>Queue can be shared with other AWS accounts</li><li>Queue can be shared anonymously </li><li>A permission gives access to another person to use your queue in some particular way</li><li>A policy is the actual document that contains the permissions you granted </li></ul></li></ul><h2 id="2-8-Use-cases"><a href="#2-8-Use-cases" class="headerlink" title="2.8 Use cases"></a>2.8 Use cases</h2><ul><li>Work queues<ul><li>decouple components of a distributed application that may not all process the same amount of work simultaneourly </li></ul></li><li>Buffer and batch operations<ul><li>add scalability and reliability to your architecture and smooth out temporary volume spikes without losing messages or increasing latency </li></ul></li><li>request offloading<ul><li>move slow operations off of interactive request paths by enqueuing the request</li></ul></li><li>Auto scaling<ul><li>Use queue to help determine the load on an application, and when combined with auto sclaing, you can sclae the numebr of Amazon Ec3 intances out or in, depending on the volumne of traffic </li></ul></li><li>fan out<ul><li>combine SQS with SNS to send identical copies of a message to multiple queues in parallel for simultaneous processing  </li></ul></li></ul><h1 id="3-Amazon-Simple-Notification-Service"><a href="#3-Amazon-Simple-Notification-Service" class="headerlink" title="3. Amazon Simple Notification Service"></a>3. Amazon Simple Notification Service</h1><h2 id="3-1-Introduction"><a href="#3-1-Introduction" class="headerlink" title="3.1 Introduction"></a>3.1 Introduction</h2><ul><li>A web service that makes it easy to set up, operate and send notifications from the cloud.</li><li>Follow the publish-subscribe messaging paradigm, with notifications being delivered to clients using a push mechanism that eliminates the need to periodically check or poll for new information and updates </li><li>When using Amazon SNS, you (as the owner) create a <strong>topic</strong> and <strong>control access to it by defining policies</strong> that determine which publishers and subscribers can communicate with the topic. </li><li>A publisher sends messages to topics they have created or to topics they have permission to publish to. </li><li>Instead of including a specific destination address in each message, a publisher sends a message to the topic. </li><li>Amazon SNS matches the topic to a list of subscribers who have subscribed to that topic and delivers the message to each of those subscribers. </li><li>Each topic has a <strong>unique name</strong> that identifies the Amazon SNS endpoint for <strong>publishers to post messages and subscribers to register for notifications</strong>. Subscribers receive all messages published to the topics that they subscribe to, and all subscribers to a topic receive the same messages.</li><li>Subscriber<ul><li>Web servers </li><li>email addresses</li><li>amazon sqs queues</li><li>aws lambda</li></ul></li><li>topic <ul><li>an access point for allowing recipients to dynamically subscribe for identical copies of the same notification </li></ul></li></ul><h2 id="3-2-Use-case-Fan-out"><a href="#3-2-Use-case-Fan-out" class="headerlink" title="3.2 Use case: Fan out"></a>3.2 Use case: Fan out</h2><ul><li>An Amazon SNS message is sent to a topic and then replicated and pushed to multiple Amazon SQS queues, HTTP endpoints, or email addresses. </li><li>Allow for parallel asynchronous processing</li><li>All subscribers get identical information </li></ul><h2 id="3-3-Operations"><a href="#3-3-Operations" class="headerlink" title="3.3 Operations"></a>3.3 Operations</h2><ul><li>CreateTopic<ul><li>Input: Topic name </li><li>Output: ARN of topic </li><li>creates a topic to which notifications can be published </li><li>action is idempotent, so if the requester already owns a topic with the specified name, that topic’s ARN is returned without creating a new topic </li></ul></li><li>Subscribe<ul><li>Input<ul><li>subscriber’s endpoint</li><li>protocol </li><li>ARN of topic </li></ul></li><li>prepare to subscribe an endpoint by sending the endpoint a confirmation message</li><li>to actually create a subscription, the endpoint owner must call the confirmSubscription action with the token from the confirmation message. </li><li>The ConfirmSubscription request verify an endpoint owner’s intent to receive messages by validating the token sent to the endpoint by an earlier Subscribe action. </li><li>If the token is valid, the action creates a new subscription and returns its ARN </li></ul></li><li>DeleteTopic <ul><li>Input<ul><li>ARN of topic  </li></ul></li><li>Deleting a topic might prevent some messages previously sent to the topic being delivered to subscribers</li><li>Action is idempotent, will not result in an error if the topic doesn’t exist</li></ul></li><li>Publish <ul><li>Input <ul><li>Message</li><li>Messsage attributes</li><li>Message structure : json</li><li>subject </li><li>ARN of topic </li></ul></li><li>output <ul><li>message ID </li></ul></li><li>Sends a message to all of a topic’s subscribed endpoints.</li><li>When a messageId is returned, the message has been saved and Amazon SNS will attempt to deliver it to the topic’s subscribers shortly. </li><li>The format of the outgoing message to each subscribed endpoint depends on the notification protocol selected.</li></ul></li></ul><h2 id="3-4-Best-practices"><a href="#3-4-Best-practices" class="headerlink" title="3.4 Best practices"></a>3.4 Best practices</h2><h3 id="3-4-1-Characteristics-of-Amazon-SNS"><a href="#3-4-1-Characteristics-of-Amazon-SNS" class="headerlink" title="3.4.1 Characteristics of Amazon SNS"></a>3.4.1 Characteristics of Amazon SNS</h3><ul><li>Each notification message contains a single published message</li><li>Message order is not guaranteed</li><li>A message cannot be deleted after it has been published </li><li>Amazon SNS delivery policy can be used to control retries in case of message delivery failure</li><li>Message can contain up to 256 kb of text data</li></ul><h3 id="3-4-2-Manage-Access-to-Amazon-SNS"><a href="#3-4-2-Manage-Access-to-Amazon-SNS" class="headerlink" title="3.4.2 Manage Access to Amazon SNS"></a>3.4.2 Manage Access to Amazon SNS</h3><ul><li>which endpoints</li><li>who can publish notifications</li><li>who can subscribe to notifications</li></ul><h3 id="3-4-3-SQS-vs-SNS"><a href="#3-4-3-SQS-vs-SNS" class="headerlink" title="3.4.3 SQS vs SNS"></a>3.4.3 SQS vs SNS</h3><ul><li>both messaging services within AWS</li><li>SNS<ul><li>allow applications to send time-critical messages to multiple subscribers through a push mechanism</li><li>eliminate the need to periodically check or poll for updates </li></ul></li><li>SQS <ul><li>message queue service used by distributed applications to exchange messages through a polling model, and it can be used to decouple sending and receiving components. </li><li>provides flexibility for distributed components of applications to send and receive messages without requiring each component to be concurrently available</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> SQS </tag>
            
            <tag> SNS </tag>
            
            <tag> Notification Service </tag>
            
            <tag> Queue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.7 API Gateway</title>
      <link href="/Developing-on-AWS-Note-7-API-Gateway/"/>
      <url>/Developing-on-AWS-Note-7-API-Gateway/</url>
      
        <content type="html"><![CDATA[<h1 id="1-What-is-Amazon-API-Gateway"><a href="#1-What-is-Amazon-API-Gateway" class="headerlink" title="1. What is Amazon API Gateway?"></a>1. What is Amazon API Gateway?</h1><h2 id="1-1-Functionalities"><a href="#1-1-Functionalities" class="headerlink" title="1.1 Functionalities"></a>1.1 Functionalities</h2><ul><li>enables developers to create, publish, maintain, monitor and secure APIs</li><li>allow you to connect your applications to AWS services and other public or private websites</li><li>provides consistent RESTFUL APIs for mobile and web applications to access AWS services and other resources hosted outside of AWS</li><li>Handles all the tasks involved in <strong>accepting and processing</strong> up to hundreds of thousands of concurrent API calls, including <strong>traffic management, authorization and access control, monitoring and API version management</strong></li></ul><h2 id="1-2-Use-cases"><a href="#1-2-Use-cases" class="headerlink" title="1.2 Use cases"></a>1.2 Use cases</h2><ul><li><p>Create a unified API frontend for multiple microservices</p></li><li><p>DDoS protection and throttling for backend </p></li><li><p>Authenticate and authorize requests to a backend</p></li><li><p>Throttle, meter, and monetize API usage by third party developers </p></li><li><p>message transformation and validation</p><ul><li><strong>models</strong> can be created to define a schema for reqeust/ response messages</li><li>A <strong>Mapping Template</strong> can then be used to transform data from one model to another</li><li>request/ response payload and header can be validated against the model</li><li>message transformation and mapping can be done using API Gateway</li><li>customers will often map request messages to a canonical format for downstream applications using API Gateway.  –&gt; <strong>transform a response body from the backend data format to the frontend data format</strong></li></ul></li><li><p>Expose backend resources</p><ul><li>allow you to create an API that acts as a front door for applications to access data, business logic or functionality from your backend service</li><li>expose<ul><li>HTTP endpoints</li><li>AWS services</li><li>AWS Lambda functions</li></ul></li></ul></li><li><p>Increase API performance : Cache</p><ul><li>eploy APIs to Regional or Edge-optimized endpoints to bring them closer to their clients. Cache API responses to the API Gateway response cache.</li><li>You can also enable API caching in Amazon API Gateway to cache your endpoint’s response. </li><li>With caching, you can reduce the number of calls made to your endpoint and also improve the latency of the requests to your API. When you enable caching for a stage, API Gateway caches responses from your endpoint for a specified time-to-live (TTL) period, in seconds. </li><li>API Gateway then responds to the request by looking up the endpoint response from the cache instead of making a request to your endpoint</li></ul></li><li><p>Control Access to APIs</p><ul><li>method level throttling </li><li>client usage throttling and quota limits sepcified in a usage plan </li><li>help prevent one customer from consuming all of your backend system’s capacity</li></ul></li><li><p>Secure API method invocations</p><ul><li>creating a resource policy <ul><li>a JSON policy document that you attach to an API to control whether a specified principal(IAM user or role) can invoke the API </li><li>You can use a resource policy to enable users from a different AWS account to securely access your API or to allow the API to be invoked only from specified source IP address ranges or Classless Inter-Domain Routing (CIDR) blocks.</li></ul></li><li>Creating IAM permission policy, can protect: <ul><li>the creation, deployment, and management of an API</li><li>the invocation of the methods in the API and refresh of its cache</li></ul></li><li>Creating a Private API endpoint that can only be accessed by a VPC client</li><li>Integrating with Amazon Cognito or Lambda authorizers to authenticate and authorize clients before accessing backend resources</li><li>Resource policy and IAM permission capabilities offer flexible and robust access controls that can be applied to an entire API set or individual methods. <h1 id="2-Best-practices"><a href="#2-Best-practices" class="headerlink" title="2. Best practices"></a>2. Best practices</h1></li></ul></li></ul><h2 id="2-1-Developing-an-API"><a href="#2-1-Developing-an-API" class="headerlink" title="2.1 Developing an API"></a>2.1 Developing an API</h2><ul><li>WHen API client requests come from the same region where the API is deployed, choose a regional API endpoint type</li><li>Test invking the API before deploying it</li><li>Use HTTP 500 error code for error handling </li><li>Cache only GET methods </li></ul><h1 id="3-Serverless-Application-Model-SAM"><a href="#3-Serverless-Application-Model-SAM" class="headerlink" title="3. Serverless Application Model (SAM)"></a>3. Serverless Application Model (SAM)</h1><p>Template driven development model for defining serverless apps</p><ul><li>supports <ul><li>Lambda</li><li>API Gateway</li><li>DynamoDB table</li><li>Any resource that AWS CloudFormation supports </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Gateway </tag>
            
            <tag> RESTFul </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.6 AWS Serverless platform, Lambda</title>
      <link href="/Developing-on-AWS-Note-6-AWS-Serverless-platform-Lambda/"/>
      <url>/Developing-on-AWS-Note-6-AWS-Serverless-platform-Lambda/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Serverless-Computing"><a href="#1-Serverless-Computing" class="headerlink" title="1. Serverless Computing"></a>1. Serverless Computing</h1><h2 id="1-1-Benefits"><a href="#1-1-Benefits" class="headerlink" title="1.1 Benefits"></a>1.1 Benefits</h2><ul><li>with serverless deployment and operation, only need to<ul><li>build and deploy apps</li><li>monitor and maintain apps</li></ul></li><li>no need to provision, scale and manage any servers </li></ul><h2 id="1-2-Use-cases"><a href="#1-2-Use-cases" class="headerlink" title="1.2 Use cases"></a>1.2 Use cases</h2><ul><li>web applications <ul><li>automatically scale up and down </li><li>run in a highly available configuration across multiple data centers </li></ul></li><li>backends<ul><li>build serverless backends using AWS lambda to handle web, mobile, internet of Things(IoT), and 3rd party APR requests </li></ul></li><li>mobile backends</li><li>data processing <ul><li>execute code in response to triggers <ul><li>changes in data </li><li>shifts in system state</li><li>actions by users</li></ul></li></ul></li></ul><h1 id="2-AWS-serverless-Platform"><a href="#2-AWS-serverless-Platform" class="headerlink" title="2. AWS serverless Platform"></a>2. AWS serverless Platform</h1><ul><li>Compute<ul><li>AWS lambda</li><li>AWS Fargate</li></ul></li><li>API Proxy<ul><li>Amazon API Gateway</li><li>AWS AppSync</li></ul></li><li>Storage<ul><li>Amazon S3</li></ul></li><li>Database<ul><li>Amazon DynamoDB</li><li>Amazon Aurora</li></ul></li><li>Interprocess Messaging<ul><li>Amazon SNS</li><li>Amazon SQS</li></ul></li><li>Orchetration<ul><li>AWS Step Functions </li></ul></li><li>Analytics<ul><li>Amazon Kinesis</li><li>Amazon Athena</li></ul></li><li>Developer Tools<ul><li>Frameworks</li><li>SDKs</li><li>Libraries</li></ul></li></ul><p>Serverless applications don’t require provisioning, maintaining, and administering servers for backend components such as compute, databases, storage, stream processing, message queueing, and more. You also no longer need to worry about ensuring application fault tolerance and availability.</p><h1 id="3-AWS-Lambda"><a href="#3-AWS-Lambda" class="headerlink" title="3. AWS Lambda"></a>3. AWS Lambda</h1><h2 id="3-1-What-is-AWS-Lambda"><a href="#3-1-What-is-AWS-Lambda" class="headerlink" title="3.1 What is AWS Lambda?"></a>3.1 What is AWS Lambda?</h2><ul><li>Compute service that enables you to run code without provisioning or managing servers. </li><li>Pay only for the compute time you consume </li><li>Run code for virtually any type of application or backend service, all with zero administration. </li><li>can set up code to automatically trigger from other AWS services or call it directly from any web or mobile app</li></ul><h2 id="3-2-Concepts"><a href="#3-2-Concepts" class="headerlink" title="3.2 Concepts"></a>3.2 Concepts</h2><ul><li>Event source - what triggers the call<ul><li>Used to pass in event data to the handler </li><li>java/C# supports simple data types and stream input/ output</li><li>includes all of the data and metadata Lambda needs</li></ul></li><li>Context object<ul><li>provides handler runtime information </li><li>interact with Lambda execution environment </li><li>contain<ul><li>AWS requestId - Used to track specific invocations of a Lambda function</li><li>Remaining time - The amount of time in milliseconds that remain before your function timeout occurs</li><li>logging - Each language runtime provides the ability to stream log statements to Amazon CloudWatch Logs.</li></ul></li></ul></li><li>Language choice</li><li>Execution environment - permissions and resources</li><li>Runtime <ul><li>a program that runs a lambda function’s handler method when the function is invoked</li><li>can include a runtime in your function’s deployment package in the form of an executable file named bootstrap</li><li>responsible for running the function’s setup code</li><li>read the handler name</li><li>read invocation events from the runtime API</li><li>runtime passes the event data to the function handler, and posts response from the handler back to Lambda</li></ul></li><li>handler function<ul><li>When a Lambda function is invoked, code execution begins at what is called the handler. The handler is a specific code method (Java, C#) or function (Node.js, Python) that you’ve created and included in your package. </li></ul></li></ul><h2 id="3-3-Using-Lambda"><a href="#3-3-Using-Lambda" class="headerlink" title="3.3 Using Lambda"></a>3.3 Using Lambda</h2><ul><li>Bring own code <ul><li>bring own libraries</li><li>custom runtimes </li></ul></li><li>Simple resource model <ul><li>CPU and network allocated proportionately</li></ul></li><li>Flexible Use<ul><li>Synchronous/ Asynchronous</li><li>Integrated with other AWS services</li></ul></li><li>Flexible Authorization<ul><li>securely grant access to resources and VPCs </li><li>Fine grained control for invoking your functions </li></ul></li></ul><h2 id="3-4-How-it-works"><a href="#3-4-How-it-works" class="headerlink" title="3.4 How it works"></a>3.4 How it works</h2><p>Function can be invoked by</p><ul><li>push model<ul><li>event based invocation </li><li>event sources invoke your Lambda function </li><li>e.g<ul><li>S3, SNS, Cognito, Echo </li></ul></li></ul></li><li>request-response invocation <ul><li>causes Lambda to execute the function <strong>synchronously</strong> and returns the response immediately to the calling application. This invocation type is available for custom applications</li></ul></li><li>pull event model<ul><li>Lambda polls the event source and invokes function when it detects an event</li><li>E.G<ul><li>DynamoDB, SQS, Kinesis </li></ul></li></ul></li></ul><h2 id="3-5-Develop-and-deploy-workflow"><a href="#3-5-Develop-and-deploy-workflow" class="headerlink" title="3.5 Develop and deploy workflow"></a>3.5 Develop and deploy workflow</h2><ul><li>create a lambda handler class in code</li><li>create lambda function </li><li>allow Lambda to assume an IAM role</li><li>upload the code</li><li>invoke the AWS Lambda Function </li><li>Monitor function </li></ul><h2 id="3-6-Lambda-Layers"><a href="#3-6-Lambda-Layers" class="headerlink" title="3.6 Lambda Layers"></a>3.6 Lambda Layers</h2><ul><li><p>Centrally manage code and data that is shared across multiple functions</p><ul><li>reduce size of deployments</li><li>speed up deployment </li><li>Limits<ul><li>5 layers</li><li>250 MB</li></ul></li></ul></li><li><p>Layer</p><ul><li>ZIP archive that contain libraries, a custom runtime, or other dependencies</li><li>with layers, you can use libraries in your function without needing to include them in deployment package</li><li>extracted to the /opt directory in the function execution env </li><li>use AWS Serverless Application Model (AWS SAM) to manage layers and your function’s layer configuration</li></ul></li></ul><h2 id="3-7-Best-practices"><a href="#3-7-Best-practices" class="headerlink" title="3.7 Best practices"></a>3.7 Best practices</h2><ul><li>Function Code<ul><li>Separate the Lambda handler (entry point) from your core logic <ul><li>can make a more unit-testable function </li></ul></li><li>take advantage of Execution Context reuse<ul><li>make sure any externalized configuration or dependencies that your code retrieves are stored and referenced locally after initial execution</li><li>Limit the re-initialization of variables/objects on every invocation. Instead use static initialization/constructor, global/static variables and singletons. Keep alive and reuse connections (HTTP, database, etc.) that were established during a previous invocation.</li></ul></li><li>use environment variables</li><li>control the dependencies in your function’s deployment package</li><li>minimize the complexity of your dependencies <ul><li>Prefer simpler Java dependency injection frameworks like Dagger or Guice, over more complex ones like Spring Framework</li></ul></li><li>avoid using recursive code </li><li>share common dependencies with layers</li></ul></li><li>Function Configuration<ul><li>performance testing your Lambda function for memory<ul><li>crucial part in ensuring you pick the optimum memory size configuration</li><li>Any increase in memory size triggers an equivalent increase in CPU available to your function. </li><li>The memory usage for your function is determined per-invoke and can be viewed in AWS CloudWatch logs.</li></ul></li><li>Load test Lambda Function<ul><li>Determine an optimum timeout value</li><li>Important to analyze how long your function runs so that you can better determine any problems with a dependency service that may increase the concurrency of the function beyond what you expect</li><li>This is especially important when your Lambda function makes network calls to resources that may not handle Lambda’s scaling.</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Lambda </tag>
            
            <tag> Serverless </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.5 DynamoDB</title>
      <link href="/Developing-on-AWS-Note-5-DynamoDB/"/>
      <url>/Developing-on-AWS-Note-5-DynamoDB/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AWS-Database-Options"><a href="#1-AWS-Database-Options" class="headerlink" title="1. AWS Database Options"></a>1. AWS Database Options</h1><h2 id="1-1-SQL-vs-NoSQL-database"><a href="#1-1-SQL-vs-NoSQL-database" class="headerlink" title="1.1 SQL vs NoSQL database"></a>1.1 SQL vs NoSQL database</h2><table><thead><tr><th>Attr</th><th>SQL</th><th>NoSQL</th></tr></thead><tbody><tr><td>Data Storage</td><td>rows and columns</td><td>key-value, document, wide-column, graph</td></tr><tr><td>Schemas</td><td>fixed</td><td>dynamic</td></tr><tr><td>Querying</td><td>Using SQL</td><td>Focused on collection of documents</td></tr><tr><td>Scalability</td><td>Vertical</td><td>Horizontal</td></tr><tr><td>Transactions</td><td>Supported</td><td>Support varies</td></tr><tr><td>Consistency</td><td>Strong</td><td>Eventual and strong</td></tr></tbody></table><ul><li>Relational Database supports vertical scaling which means that a single server must be made more powerful </li><li>Relational Database support ACID transactions<ul><li>atomicity</li><li>consistency</li><li>isolation </li><li>durability</li></ul></li><li>Relational databases automatically support strong data consistency due to ACID properties of transactions.</li></ul><h2 id="1-2-AWS-database-Options"><a href="#1-2-AWS-database-Options" class="headerlink" title="1.2 AWS database Options"></a>1.2 AWS database Options</h2><table><thead><tr><th>Type</th><th>SQL</th><th>NoSQL</th></tr></thead><tbody><tr><td>Transactional Databses</td><td>Amazon RDS</td><td>Amazon DynamoDB</td></tr><tr><td>Data Analytics/ Relationshiups</td><td>Amazon Redshift</td><td>Amazon Neptune</td></tr><tr><td>In-memory Data Store and Cache</td><td></td><td>Amazon ElastiCache</td></tr></tbody></table><ul><li>Amazon Relational Database Service(RDS): provides relational database services in the cloud with support for the following db engines: <ul><li>AMazon Aurora</li><li>PostgreSQL</li><li>MySQL</li><li>MariaDB</li><li>Oracle</li><li>Microsoft SQL server </li></ul></li><li>Amazon Redshift: fast, fully managed data warehouse<ul><li>includes Redshift Spectrum, allowing you to directly run SQL queries against exabytes of unstructured data in Amazon S3. </li></ul></li><li>Amazon DynamoDB: NoSQL db that supports both document and key-value store models </li><li>Amazon Neptune: fully managed graph databse service<ul><li>fully manged graoh databse service </li><li>purpose-built, high-performance <strong>graph database engine</strong> optimized for storing billions of <strong>relationships</strong> and querying the graph with milliseconds latency.</li><li>A graph database is ideal when you need to create relationships between data and quickly query these relationships. </li><li>This type of requirement is challenging to satisfy using a relational database because you would need multiple tables with multiple foreign keys. </li><li>In addition, SQL queries to navigate this data would require nested queries and complex joins that could quickly become complex and inefficient as your data size grows over time. </li><li>Neptune uses graph structures such as nodes (data entities), edges (relationships), and properties to represent and store data. </li><li>The relationships are stored as first order citizens of the data model. </li><li>This allows data in nodes to be directly linked, dramatically improving the performance of queries that navigate relationships in the data.</li></ul></li><li>Amazon ElastiCache: <strong>in-memory data cache</strong> that supports a fully managed Redis or Memcached engine<ul><li>easier to deploy, operate, and scale an in-memory data store or cache in the cloud. </li><li>improve the performance of web applications by allowing you to retrieve information from fast, managed, in memory caches</li><li>provides <ul><li>redis</li><li>memcached</li></ul></li></ul></li></ul><h1 id="2-DynamoDB"><a href="#2-DynamoDB" class="headerlink" title="2. DynamoDB"></a>2. DynamoDB</h1><h2 id="2-1-Intro"><a href="#2-1-Intro" class="headerlink" title="2.1 Intro"></a>2.1 Intro</h2><p>Amazon DynamoDB is a fast and flexible non-relational database service for all applications that need consistent, <strong>single-digit millisecond latency</strong> at any scale. It is a fully managed cloud database and supports both document and key-value store models.</p><h2 id="2-2-Components"><a href="#2-2-Components" class="headerlink" title="2.2 Components"></a>2.2 Components</h2><ul><li>Table <ul><li>data is stored in tables </li><li>contain<ul><li>item with attributes </li></ul></li></ul></li><li>Partition<ul><li>ddb can divide a table’s items into multiple partitions based on the primary key value. </li><li>an allocation of storage for a table</li><li>backed by SSDs and automatically replicated across multiple Availability Zones within an AWS region</li><li>partition key (hashkey), ddb use this to do partition </li></ul></li><li>sort key (range key) A sort key can be defined to store all of the items with the same partition key value <strong>physically close together and order them by sort key value in the partition</strong>. It represents a one-to-many relationship based on the partition key and enables querying on the sort key attribute.</li><li>Primary key - uniquely identify an Item<ul><li>types<ul><li>partition primary key</li><li>partition and sort primary key</li></ul></li></ul></li><li>item (400 KB at most)<ul><li>collection of attributes </li><li>not cosntrained by a predefined schema</li><li>items in a table can have different types of attributes </li></ul></li><li>attribute<ul><li>name</li><li>data type<ul><li>scalar<ul><li>number, string, binary, boolean, null</li></ul></li><li>multi-valued types <ul><li>string set</li><li>number set</li><li>binary set</li></ul></li><li>Document types<ul><li>List</li><li>Map</li></ul></li></ul></li><li>value</li></ul></li><li>Read/ Write Consistency<ul><li>Read<ul><li>eventually consistent</li><li>strongly consistent: return most up-to-date data</li><li>transactional: provides ACID consistency</li></ul></li><li>write<ul><li>standard</li><li>transactional </li></ul></li></ul></li><li>Read/ write Throughput<ul><li>RCU: number of strongly consistent reads per second of items up to <strong>4KB</strong> in size </li><li>WCU: number of <strong>1KB</strong> writes per second</li></ul></li><li>Secondary Indexes<ul><li>allow you to query data based on non-primary key attributes</li><li>contain<ul><li>alternate key attributes</li><li>primary key attributes</li><li>optinal subset of other attributes from the base table </li></ul></li><li>type<ul><li>GSI<ul><li>queries on this index can span all the data in a table, across all partitions</li><li>can have different partition key and sort key from original table</li><li>key values do not to be unique</li><li>can be deleted </li><li>supports eventually consistent only </li><li>its own provisioned WCU and RCU</li><li>*<em>queries only return attributes that are projected into the index *</em></li></ul></li><li>LSI<ul><li>index is located on the same table partition</li><li>sort key can be any scalar attribute </li><li>cannot be deleted </li><li>support eventually consitent and strong consistent </li><li>use table’s read and write capacity units</li></ul></li></ul></li></ul></li><li>Streams<ul><li>Ordered flow of information about changes to a table </li><li>contains changes to items in a single table </li><li>When you make an update to a table, DynamoDB first <strong>persists the data durably</strong> to the table. </li><li>It then asynchronously updates the corresponding stream with information about the changes made. </li><li>The asynchronous update is made to the stream with <strong>sub-second latency</strong>. </li><li>The update to the stream does not affect the write throughput of the table</li><li><strong>stricly in the order</strong> </li><li>each change contains exactly one stream record, available for 24 hours</li><li>streams scale by splitting data across shards </li><li>shards in detail<ul><li>A shard is created per partition in your DynamoDB table. If a partition split is required due to too many items in the same partition, the shard gets split into children as well.</li><li>DynamoDB Streams captures a time-ordered sequence of item-level modifications in your DynamoDB table. This time-ordered sequence is preserved at a per shard level. In other words, the order within a shard is established based on the order in which items were created, updated or deleted. </li></ul></li><li>configuration<ul><li>StreamEnabled: specify whether a stream is enabled or disabled </li><li>StreamViewType: specify the information that will be written to the stream whenever data in the table is modified<ul><li>KEYS_ONLY: only the key attributes </li><li>NEW_IMAGE: entire item, as it appears after modified</li><li>OLD_IMAGE: entire item, as it appears before modified</li><li>NEW_AND_OLD_IMAGES: both the new and old images of the item</li></ul></li></ul></li><li>when a stream is created, DDB assigns an ARN(Amazon Resource Name) that can be used to retrieve information about a stream. </li></ul></li><li>Global table<ul><li>A collection of one or more DynamoDB tables, all ownd by a single AWS account, identified as replica tables </li><li>A replica table (or replica, for short) is a single DynamoDB table that functions as a part of a global table. Each replica stores the same set of data items.</li><li>data replication<ul><li>Any changes made to any item in any replica table will be replicated to all of the other replicas within the same global table. </li><li>propagate within seconds </li></ul></li><li>concurrent updates <ul><li>all replicas agree on the latest update, and converge toward a state in which they all have identical data</li></ul></li><li>Read Consistency <ul><li>An application can read and write data to any replica table. </li><li>If your application only uses eventually consistent reads, and only issues reads against one AWS region, then it will work without any modification. </li><li>However, if your application requires strongly consistent reads, then it must perform all of its strongly consistent reads and writes in the same region. DynamoDB does not support strongly consistent reads across AWS regions; </li><li>therefore, if you write to one region and read from another region, the read response might include stale data that doesn’t reflect the results of recently-completed writes in the other region. </li></ul></li></ul></li><li>Backup and Restore<ul><li>on-demand backup and restore capabilities </li><li>all backups in DDB work without consuming any provisioned throughput on the table </li><li>point-in-time recovery can restore the table to any point in time during last 35 days</li></ul></li></ul><h2 id="2-3-APIs-and-operations"><a href="#2-3-APIs-and-operations" class="headerlink" title="2.3 APIs and operations"></a>2.3 APIs and operations</h2><h3 id="2-3-1-Control-operations"><a href="#2-3-1-Control-operations" class="headerlink" title="2.3.1 Control operations"></a>2.3.1 Control operations</h3><p>Create and manage DynamoDB tables. Let you work with indexes, streams, and other objects that are dependent on tables. </p><h3 id="2-3-2-Data-operations"><a href="#2-3-2-Data-operations" class="headerlink" title="2.3.2 Data operations"></a>2.3.2 Data operations</h3><p>Perform CRUD actions on data in a table. Also let you read data from a secondary index. </p><ul><li>PutItem<ul><li>create a new item or replace an existing item </li></ul></li><li>GetItem<ul><li>reads an item from a table</li></ul></li><li>UpdateItem<ul><li>edit an existing item’s attributes, or adds a new item to the table</li><li>can perform a conditional update on an existing item </li><li>can only bring some attributes instead of all comparing with putItem</li></ul></li><li>deleteItem<ul><li>can delete an item in a table using its primary key  </li></ul></li></ul><h3 id="2-3-3-Stream-operations"><a href="#2-3-3-Stream-operations" class="headerlink" title="2.3.3 Stream operations"></a>2.3.3 Stream operations</h3><p>Enable or disable a stream on a table, and allow access to the data modification records contained in a stream. </p><h3 id="2-3-4-Object-persistence-Model"><a href="#2-3-4-Object-persistence-Model" class="headerlink" title="2.3.4 Object persistence Model"></a>2.3.4 Object persistence Model</h3><ul><li>Allow you to persist client-side objects in DynamoDB<ul><li>supports the mapping of objects to tables</li></ul></li><li>Provides higher-level programming interfaces to:<ul><li>connect to DynamoDB</li><li>perform CRUD operations</li><li>execute queries</li></ul></li></ul><h3 id="2-3-5-Batch-Operations"><a href="#2-3-5-Batch-Operations" class="headerlink" title="2.3.5 Batch Operations"></a>2.3.5 Batch Operations</h3><ul><li>BatchGetItem<ul><li>Read up to 16MB of data consisting of up to 100 items from multiple tables</li></ul></li><li>BatchWriteItem<ul><li>write up to 16MB of data consisting of up to 25 put or delete requests in multiple tables </li></ul></li><li>retry <ul><li>if one request in a batch fails, the entire operation does not fail</li><li>retry with failed keys and data returned </li></ul></li></ul><h3 id="2-3-6-Transactional-Operations"><a href="#2-3-6-Transactional-Operations" class="headerlink" title="2.3.6 Transactional Operations"></a>2.3.6 Transactional Operations</h3><ul><li>TransactWriteItems<ul><li>contains a write set </li><li>includes one or more PutItem, updateItem, and DeleteItem operations across</li></ul></li><li>TransactGetItems<ul><li>contains a read set </li><li>includes one or more getItem operations across multiple tables</li></ul></li></ul><h2 id="2-4-On-demand-mode"><a href="#2-4-On-demand-mode" class="headerlink" title="2.4 On-demand mode"></a>2.4 On-demand mode</h2><p>Amazon DynamoDB on-demand is a flexible billing option capable of serving thousands of requests per second without capacity planning. DynamoDB on-demand offers pay-per-request pricing for read and write requests so that you pay only for what you use. </p><h2 id="2-5-Query-and-Scan"><a href="#2-5-Query-and-Scan" class="headerlink" title="2.5 Query and Scan"></a>2.5 Query and Scan</h2><ul><li>Query <ul><li>reads from a table or secondary index only the items that match the primary key specified in the key condition expression.  </li><li>parameters<ul><li>tableName</li><li>KeyContditionExpression<ul><li>must specify partition key name and value</li></ul></li><li>ProjectExpression </li><li>ConsistentRead</li><li>FilterExpression<ul><li>a string that contains conditions that DDB applies after the query operation, but before the data is returned to you </li><li>all other records are discarded </li></ul></li></ul></li></ul></li><li>Scan <ul><li>reads all items from the table or index </li><li>parameters <ul><li>tableName</li><li>ProjectionExpression <ul><li>a string that identify one or more attributes to retrieve from the table </li></ul></li><li>consistentRead</li><li>filterExpression </li></ul></li></ul></li></ul><h2 id="2-6-Best-Practices"><a href="#2-6-Best-Practices" class="headerlink" title="2.6 Best Practices"></a>2.6 Best Practices</h2><ul><li>Uniform workloads</li><li>One-To-Many tables<ul><li>If your table has items that store a large number of values in an attribute of set type, such as string set or number set, consider removing the set attribute from the table and splitting it as separate items in another table.</li><li>If you frequently access large items in a table but do not use the large attribute values, consider storing frequently accessed smaller attributes in a separate table</li></ul></li><li>Optimistic Locking with Version Number <ul><li>Use optimistic locking with a version number to make sure that an item has not changed since the last time you read it. </li><li>Maintain a version number to check that the item has not been updated between the last read and update </li></ul></li></ul><h2 id="2-7-DynamoDB-Accelerator-DAX"><a href="#2-7-DynamoDB-Accelerator-DAX" class="headerlink" title="2.7 DynamoDB Accelerator (DAX)"></a>2.7 DynamoDB Accelerator (DAX)</h2><ul><li>deliver fast response times for accessing eventually consistent data </li><li>DAX is a DynamoDB compatible caching service that enables you to benefit from fast in memory performance for demanding applications. It addresses three core scenarios: <ul><li>reduce the response times of eventually consistent read workloads by an order of magnitude, from single-digit milliseconds to microsends</li><li>reduce operational and application complexity by providing a managed service that is API-compatible with Amazon DynamoDB</li><li>DAX provides increased throughput and potential operational cost savings by reducing the need to over-provision read capacity units</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> NoSQL </tag>
            
            <tag> DynamoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.4 Storage Options, S3 in detail</title>
      <link href="/Developing-on-AWS-Note-4-Storage-Options-S3-in-detail/"/>
      <url>/Developing-on-AWS-Note-4-Storage-Options-S3-in-detail/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AWS-Storage-Options"><a href="#1-AWS-Storage-Options" class="headerlink" title="1. AWS Storage Options"></a>1. AWS Storage Options</h1><ul><li>Amazon S3<ul><li>Scalable, highly durable object storage in the cloud</li></ul></li><li>Amazon Glacier<ul><li>Low-cost, highly durable <strong>archive</strong> storage in the cloud</li></ul></li><li>Amazon EFS<ul><li>Scalable network file storage for Amazon EC2 instances</li><li>network file system that can grow to petabytes </li><li>allows massively parallel access from EC2 instances to your data within a region</li><li>designed to <strong>meet the performance needs of big data and analytics</strong></li></ul></li><li>Amazon EBS<ul><li>Network attached volumes that provide durable block-level storage for Amazon EC2 instances </li></ul></li><li>AWS storage gateway<ul><li>change to hybrid later </li><li>connects an on-premises software appliance with cloud-based storage to provide seamless and secure storage integration between an organization’s on-premises IT environment and the AWS storage infrastructure like Amazon S3, Amazon Glacier and EBS.</li></ul></li></ul><h1 id="2-Amazon-S3"><a href="#2-Amazon-S3" class="headerlink" title="2. Amazon S3"></a>2. Amazon S3</h1><p>Amazon Simple Storage Service provides develipers with <strong>high secure, durable, and scalable object storage</strong>. </p><h2 id="2-1-Use-cases"><a href="#2-1-Use-cases" class="headerlink" title="2.1 Use cases"></a>2.1 Use cases</h2><ul><li>storage solution <ul><li>content storage and distribution</li></ul></li><li>backup</li><li>archiving </li><li>big data analytics</li><li>static web site hosting</li><li>disaster recovery <ul><li>cross region replication(CRR) automatically replicates every S3 object to a destination bucket located in a different AWS Region. </li></ul></li></ul><h2 id="2-2-Components"><a href="#2-2-Components" class="headerlink" title="2.2 Components"></a>2.2 Components</h2><ul><li>bucket<ul><li>global unique</li><li>use only lower case letters, numbers and hyphens</li><li>associated with a region<ul><li>choose region by considering<ul><li>latency</li><li>cost</li><li>regulatory requirements </li></ul></li></ul></li></ul></li><li>Object<ul><li>S3 refers to files as objects </li><li>you can store any number of objects inside bucket</li><li>each object is <strong>identified by a unique key</strong></li><li>object metadata</li><li>version<ul><li>each object has a version ID if you enable this feature</li><li>Object locking supported on versioned buckets<ul><li>use object lock to prevent data from being changed, overwritten, or deleted </li></ul></li></ul></li><li>URLs for S3 Objects<ul><li>Path style URL<ul><li><code>http://&lt;region-specific endpoint&gt;/&lt;bucket name&gt;/&lt;object name&gt;</code></li></ul></li><li>virtual hosted-style URL<ul><li><code>http://&lt;bucket name&gt;.s3.amazonaws.com/&lt;object key&gt;</code> </li></ul></li></ul></li></ul></li><li>Key<ul><li>unique identifier for each object in an S3 bucket </li></ul></li><li>Object Url<ul><li>specify region, bucket name, object name(key)</li></ul></li></ul><h2 id="2-3-Operations"><a href="#2-3-Operations" class="headerlink" title="2.3 Operations"></a>2.3 Operations</h2><h3 id="2-3-1-put"><a href="#2-3-1-put" class="headerlink" title="2.3.1 put"></a>2.3.1 put</h3><ul><li>upload object</li><li>copy object <ul><li>create copies of an object </li><li>rename obejcts by creating a copy and deleting the original object </li><li>move objects across S3 locations </li><li>update object metadata </li></ul></li><li>limits<ul><li>5 GB at most in a single PUT operation </li><li>recommened: use multipart upload if size &gt; 100MB<ul><li>Multipart upload allows you to upload a single object as a set of parts. </li><li>You can upload each part separately. </li><li>If one of the parts fails to upload, you can retransmit that particular part without retransmitting the remaining parts. After all the parts of your object are uploaded to the server, you must send a complete multipart upload request that indicates that multipart upload has been completed. </li><li>Amazon S3 then assembles these parts and creates the complete object. </li><li>Amazon S3 retains all parts on the server until you complete or abort the upload.</li><li>You can upload parts in parallel to improve throughput, recover quickly from network issues, pause and resume object uploads </li></ul></li></ul></li></ul><h3 id="2-3-2-Get"><a href="#2-3-2-Get" class="headerlink" title="2.3.2 Get"></a>2.3.2 Get</h3><ul><li>retrieve a complete object in a single GET request </li><li>You can also retrieve an object in parts by specifying the range of bytes needed. This is useful in scenarios where network connectivity is poor or your application can or must process only subsets of object data.</li></ul><h3 id="2-3-3-Select"><a href="#2-3-3-Select" class="headerlink" title="2.3.3 Select"></a>2.3.3 Select</h3><ul><li>Select content from Object instead of retrieving Object </li><li>filter of content handled at S3 service level <ul><li>works by providing the ability to retrieve a subset of data from an object in Amazon S3 using simple SQL expressions </li><li>simply change API from get to select </li></ul></li></ul><h3 id="2-3-4-Delete"><a href="#2-3-4-Delete" class="headerlink" title="2.3.4 Delete"></a>2.3.4 Delete</h3><ul><li>can delete a single object or delete multiple objects in a single delete request <ul><li>versioning disabled <ul><li>can permanently delete an object by specifying the key that you want to delete</li></ul></li><li>versioning enabled <ul><li>can permanently delete an object by invoking a delete request with a key and version ID</li><li>must delete each individual version to completely remove an object </li></ul></li></ul></li></ul><h3 id="2-3-5-Listing-Keys"><a href="#2-3-5-Listing-Keys" class="headerlink" title="2.3.5 Listing Keys"></a>2.3.5 Listing Keys</h3><ul><li>There is no hierarchy of objects in S3 buckets. You can use prefixes in key names to group similar items. </li><li>You can use delimiters (any string such as / or _) in key names to organize your keys and create a logical hierarchy</li></ul><h2 id="2-4-Features"><a href="#2-4-Features" class="headerlink" title="2.4 Features"></a>2.4 Features</h2><h3 id="2-4-1-Pre-Signed-URLs"><a href="#2-4-1-Pre-Signed-URLs" class="headerlink" title="2.4.1 Pre-Signed URLs"></a>2.4.1 Pre-Signed URLs</h3><ul><li>Provide access to PUT/ GET objects without opening permissions to do anything else </li><li>Use permissions of the user who creates the URL</li><li>Provide security credentials, a bucket name, an object key, HTTP method and expiration date and time </li><li>onlu valid until expiration time </li></ul><h3 id="2-4-2-Date-Encryption"><a href="#2-4-2-Date-Encryption" class="headerlink" title="2.4.2 Date Encryption"></a>2.4.2 Date Encryption</h3><ul><li>Securing data in transit <ul><li>SSL-encrypted endpoints with HTTPS</li><li>client-side encryption - via SDKs</li><li>server-side encryption<ul><li>S3 encrypts your data at the object level  </li></ul></li></ul></li><li>Securing data at rest on server<ul><li>Amazon S3 managed keys (SSE-S3)</li><li>AWS KMS-managed keys (SSE-KMS)</li><li>Customer-provided keys (SSE-C)</li></ul></li></ul><h3 id="2-4-3-Corss-Origin-Resource-Sharing-CORS"><a href="#2-4-3-Corss-Origin-Resource-Sharing-CORS" class="headerlink" title="2.4.3 Corss Origin Resource Sharing (CORS)"></a>2.4.3 Corss Origin Resource Sharing (CORS)</h3><ul><li>defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.</li></ul><h2 id="2-5-Best-practices"><a href="#2-5-Best-practices" class="headerlink" title="2.5 Best practices"></a>2.5 Best practices</h2><ul><li>Avoid unnecessary requests <ul><li>handle noSuchBucket errors instead of checking for existence of fixed buckets </li><li>set the object metadata before uploading an object </li><li>avoid using the copy operation to update metadata</li><li>cache bucket and key names if your application design allows it </li></ul></li><li>Network latency<ul><li>choose the bucket region closest to latency-sensitive customers </li><li>consider compressing data stored in Amazon S3 to reduce the size of data transferred and storage used</li><li>use a CDN to distribute content </li></ul></li><li>Data integrity<ul><li>ensure the data has not been corrupted in transit</li><li>check MD5 checksum of the object retrieved from the GET and PUT operation <ul><li>AWS SDK automatically specifies MD5 checksum in a PUT operation. Amazon S3 recalculates MD5 checksum and compares it with the specified value. </li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> S3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.3  - CloudWatch, CloudTrail, server-design for fail</title>
      <link href="/Developing-on-AWS-Note-3-CloudWatch-CloudTrail-server-design-for-fail/"/>
      <url>/Developing-on-AWS-Note-3-CloudWatch-CloudTrail-server-design-for-fail/</url>
      
        <content type="html"><![CDATA[<h1 id="1-CloudWatch"><a href="#1-CloudWatch" class="headerlink" title="1. CloudWatch"></a>1. CloudWatch</h1><h2 id="Why-use-Amazon-CloudWatch"><a href="#Why-use-Amazon-CloudWatch" class="headerlink" title="Why use Amazon CloudWatch?"></a>Why use Amazon CloudWatch?</h2><p>Need it to: </p><ul><li>monitor CPU, memory, disk I/O, network  -&gt; metrics</li><li>react to application log events and availability -&gt; logs/ event</li><li>automatically scale ec2 instance fleet -&gt; logs/ event</li><li>view operational status and identify issues -&gt; alarms, dashboard </li></ul><p>Actually, we could use Amazon CloudWatch to gain <strong>system-wide visibility</strong> into <strong>resource utilization</strong>, <strong>application performance</strong>, and <strong>operational health</strong>. You can use these insights to react and keep your application running smoothly. Amazon CloudWatch monitors your AWS Cloud resources and your cloud-powered applications. It tracks the metrics so that you can visualize and review them. You can also set alarms that will fire when a metric goes beyond a limit that you specified. CloudWatch gives you visibility into resource utilization, application performance, and operational health.</p><h1 id="2-CloudTrail"><a href="#2-CloudTrail" class="headerlink" title="2. CloudTrail"></a>2. CloudTrail</h1><p>CloudTrail is integrated with several AWS services. </p><ul><li>EC2</li><li>VPC</li><li>S3</li><li>EBS</li><li>DDB</li><li>RDS</li><li>Redshift</li><li>CloudFormation </li><li>IAM</li><li>…etc. </li></ul><p>AWS CloudTrail is an AWS service that generates logs of calls to the AWS API. AWS CloudTrail can <strong>record all activity</strong> against the services it monitors. Here are questions that you can answer using CloudTrail logs: <strong>who, when, what, which, where</strong>? While the coverage is extensive, not all services are covered in CloudTrail logs. You can use the AWS API <strong>call history produced by CloudTrail to track changes to AWS resources</strong>, including creation, modification, and deletion of AWS resources such as Amazon EC2 instances, Amazon VPC security groups, and Amazon EBS volumes.</p><p>You can use the CloudTrail console to view the last 90 days of recorded API activity and events in an AWS region. You can also download a file with that info, or a subset of info based on the filter and time range you choose</p><h1 id="3-Best-practices-of-developing-cloud-apps"><a href="#3-Best-practices-of-developing-cloud-apps" class="headerlink" title="3. Best practices of developing cloud apps"></a>3. Best practices of developing cloud apps</h1><ul><li>consider designing applications that are <strong>loosely coupled</strong>. <ul><li>think of your application as a consumer and provider of services </li><li>design and develop app as <strong>granular components</strong> that can be delivered and scaled independently. </li></ul></li><li>Architect for resilience; <ul><li>Set up your servers to scale automatically based on the number of users concurrently visiting your application.</li><li>Autoscaling would enable your application to handle a surge in volumn during a sale or propmotion and go back to normal </li><li>set up a <strong>cluster of nodes</strong> such that when one node fails, another node automatically picks up all the traffic. </li><li>Consider setting up <strong>read replicas for your database</strong>. </li></ul></li><li>design for failure<ul><li>In case of service failure, your application may log the failure and retry at a later time.</li><li>If the service is slow to respond, your application could retry by using an exponential backoff algorithm: retry after increasing amounts of time between attempts.<ul><li>This approach attempts to <strong>reach the service without overwhelming it</strong> with repeated requests and potentially aggravating the latency issue. </li></ul></li></ul></li><li>log metrics and monitor performance </li><li>implement a strong DevOps model<ul><li>Operationalize the development and deployment process for your application</li><li>Develop a <strong>modular, automated, and continuous build</strong> process. </li><li>Ensure <strong>consistency</strong> in the development, staging, and production environments. Set up scripts or use robust tools to consistently configure your environments.</li></ul></li><li>implement security in every layer <ul><li>infrastructure</li><li>application</li><li>data at transit and at rest </li><li>user authentication and authorization</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> CloudWatch </tag>
            
            <tag> CloudTrail </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.2  - IAM</title>
      <link href="/Developing-on-AWS-Note-2-IAM/"/>
      <url>/Developing-on-AWS-Note-2-IAM/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Why-need-IAM"><a href="#1-Why-need-IAM" class="headerlink" title="1. Why need IAM?"></a>1. Why need IAM?</h1><p>IAM: AWS Identity and Access Management</p><ul><li><p>web service that helps you securely control access to AWS resources for your users. </p></li><li><p>You use IAM to control <strong>who</strong> can use your AWS resources (<strong>authentication</strong>) and <strong>what resources</strong> they can use and in what ways (<strong>authorization</strong>).</p></li><li><p>To set up your dev env to wrok with the AWS SDK. </p><ul><li>Need an AWS acount and AWS credentials </li><li>Use an IAM user to provide access credentials to <strong><em>increase the security of your AWS account</em></strong>. </li></ul></li><li><p>grant least privilege - <strong>grant only permissions required to perform a task</strong></p></li></ul><h1 id="2-Concepts"><a href="#2-Concepts" class="headerlink" title="2. Concepts"></a>2. Concepts</h1><p><img src="https://i.loli.net/2020/01/29/TbyX6r1jtKR2VuJ.png" alt="fig1.png"></p><ul><li>User<ul><li>we can set up a user account for every developer in organization </li><li>each user has credentials that they <strong>must</strong> use to access AWS services. </li></ul></li><li>groups </li><li>roles <ul><li>trusted entities </li><li>A role has policies granting access to specific services and operations </li><li>create role like developer, and associate it with each developer user account</li><li>developer role can be configured with policies that control which services and operations that role has access to </li><li>a role does not have standard long-term credentials(pwd or access keys) associated with it</li></ul></li><li>Policy<ul><li>contain permissions which specify which actions an entity can perform and on which resources </li><li>a JSON document that defines effect, actions, resources, and optional conditions for what API calls an entity can invoke </li><li>Type<ul><li>Managed policy<ul><li>standablon policies that you can attach to multiplke users, groups and roles </li><li>reusability </li><li>central change management </li><li>version</li><li>rollback </li></ul></li><li>Inline policy<ul><li>embedded in a principal entity like a user, group, or role. </li><li>you can use the same policy across multiple entities, but those entities are not sharing the policy </li></ul></li></ul></li></ul></li><li>Resources <ul><li>The user, role, group, and policy objects that are stored in IAM</li><li>you can add, edit, and remove resources from IAM</li></ul></li><li>Identities <ul><li>The IAM resource objects that are used to identify and group. These include users, groups, and roles.</li></ul></li><li>Entities<ul><li>The IAM resource objects that AWS uses for authentication</li><li>includes users and roles </li></ul></li><li>Principles<ul><li>a person or application that uses an entity to sign in and make requests </li></ul></li><li>Authentication<ul><li>As a principal, you must be authenticated (signed in to AWS) using an IAM entity to send a request to AWS.</li><li>Must provide your access key and secret key when accessing by CLI</li></ul></li><li>Authorization <ul><li>Must be authorized to complete request </li><li>AWS uses values from the request context to check for policies that apply to the request. </li></ul></li></ul><h1 id="3-Features"><a href="#3-Features" class="headerlink" title="3. Features"></a>3. Features</h1><ul><li>management<ul><li>user, role, federated users </li></ul></li><li>Shared access to your AWS account </li><li>Granular permissions <ul><li>grant different permissions to different people for different resources</li></ul></li><li>secire access tp AWS respirces for applications that run on Amazon EC2 </li><li>multi factor authentication </li><li>eventually consistent </li><li>identity based permissions<ul><li>attached to the IAM user and indicate what the user is permitted to do.</li><li>attached to a resource and indicate what a specified user (or group of users) is permitted to do with it. <strong>Amazon S3, Amazon Simple Queue Service (Amazon SQS), Amazon Simple Notification Service (Amazon SNS), and AWS OpsWorks are the only services that support resource-based permissions</strong>.</li></ul></li><li>resource based permissions</li><li>IAM Evaluation logic (In order)<ul><li>By default, all requests are denied. (In general, requests made using the account/root credentials for resources in the account are always allowed.)</li><li>An explicit allow overrides this default.</li><li>An explicit deny overrides any allows</li></ul></li></ul><h1 id="4-IAM-best-practice"><a href="#4-IAM-best-practice" class="headerlink" title="4. IAM best practice"></a>4. IAM best practice</h1><ul><li>IAM policies are specified with JSON-formatted text.</li><li>Policies are used to control access permissions for AWS APIs and other AWS resources. </li><li>They are not used for operating system permissions or application permissions. For those, use LDAP or Active Directory/Active Directory Federation Services (AD FS).</li><li>When you create IAM policies, follow the standard security advice of granting least privilege; <ul><li>i.e., grant only the permissions required to perform a task. </li><li>Determine what users need to do, and then craft policies for them that let the users perform only those tasks. </li><li>Similarly, create policies for individual resources that identify precisely who is allowed to access the resource, and allow only the minimal permissions for those users. </li></ul></li></ul><h1 id="5-Amazon-Shared-Responsibility-Model"><a href="#5-Amazon-Shared-Responsibility-Model" class="headerlink" title="5. Amazon Shared Responsibility Model"></a>5. Amazon Shared Responsibility Model</h1><p>Customer and AWS table the responsibility together: </p><ul><li>customer<ul><li>responsible for what you implement using AWS and for the applications you connect to AWS</li></ul></li><li>AWS<ul><li>goes from the ground up to the hypervisor. </li><li>secure the hardware, software, facilities, and networks that run all of our products and services. Customers are responsible for securely configuring the services they sign up for and anything they put on those services. </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Identity and Access Management </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.1  - AWS Models, EC2, ELB, autoScaling</title>
      <link href="/Developing-on-AWS-Note-1-AWS-Models-EC2-ELB-autoScaling/"/>
      <url>/Developing-on-AWS-Note-1-AWS-Models-EC2-ELB-autoScaling/</url>
      
        <content type="html"><![CDATA[<h1 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h1><p>We use SDKs to interract with Application Programing Interface(API), and then connect to all AWS services. </p><h1 id="1-Cloud-computing-definition"><a href="#1-Cloud-computing-definition" class="headerlink" title="1.  Cloud computing definition"></a>1.  Cloud computing definition</h1><ul><li>enable you to stop thinking of your infrastructure as hardware, and instead think of it and use it as software. </li></ul><h1 id="2-Models-of-Cloud-Computing"><a href="#2-Models-of-Cloud-Computing" class="headerlink" title="2. Models of Cloud Computing"></a>2. Models of Cloud Computing</h1><ul><li><p>IaaS (Infrastructure as a Service)</p><ul><li>basic buiding blocks for Cloud IT <ul><li>Networking features </li><li>Computers </li><li>Data storage space </li></ul></li><li>PaaS (Platform as a Service)<ul><li>enables you to run applications without the need to manage underlying infrastructure(hardware and operating systems)</li></ul></li><li>SaaS (Software as a Service)<ul><li>A complete product that is run and managed by the service provider<h1 id="3-AWS-Service-Stack"><a href="#3-AWS-Service-Stack" class="headerlink" title="3. AWS Service Stack"></a>3. AWS Service Stack</h1></li></ul></li></ul></li><li><p>Infrastructure </p><ul><li>Regions </li><li>Availability Zones </li><li>Edge Locations </li></ul></li><li><p>Foundation Services </p><ul><li>Compute<ul><li>virtual instances </li><li>auto scaling </li><li>load balancing </li></ul></li><li>networking </li><li>storage <ul><li>object </li><li>block </li><li>archive </li></ul></li></ul></li><li><p>Platform Services </p><ul><li>Compute<ul><li>AWS Lambda</li><li>AWS Elastic Beanstalk </li><li>Amazon ECS</li><li>Amazon EKS </li></ul></li><li>database<ul><li>relational </li><li>No SQL </li><li>Caching </li><li>Products <ul><li>DynamoDB</li><li>RDS - relational database service </li><li>Elastic Cache </li><li>Redshift - data warehouse, for analysis and migration </li></ul></li></ul></li><li>Analytics <ul><li>Cluster computing </li><li>real time </li><li>data warehouse </li><li>data workflows </li><li>Products <ul><li>EMR - managed hadoop framework </li><li>Kinesis </li><li>CloudSearch </li><li>ElasticSearch </li></ul></li></ul></li><li>App services <ul><li>Queuing </li><li>Orchestration </li><li>App streaming </li><li>Transcoding </li><li>Email </li><li>Search </li><li>Products <ul><li>SQS </li><li>SNS </li><li>SES </li><li>Amazon Step Functions </li></ul></li></ul></li><li>Deployment and management <ul><li>containers </li><li>Dev/ ops tools </li><li>resource templates </li><li>usage tracking </li><li>monitoring and logs </li><li>products <ul><li>CodeCommit </li><li>CodeDeploy </li><li>CodePipeline </li><li>CodeBuild </li><li>X-Ray </li></ul></li></ul></li><li>Mobile Services <ul><li>identity </li><li>sync </li><li>mobile analytics </li><li>notifications </li><li>products <ul><li>Cognito </li><li>Pinpoint </li><li>API gateway </li></ul></li></ul></li></ul></li><li><p>Applications </p><ul><li>Virtual Desktops </li><li>Collaboration and Sharing </li></ul></li></ul><h1 id="4-Compute-services"><a href="#4-Compute-services" class="headerlink" title="4. Compute services"></a>4. Compute services</h1><h2 id="4-1-EC2"><a href="#4-1-EC2" class="headerlink" title="4.1 EC2"></a>4.1 EC2</h2><ul><li>Computers in the cloud. </li><li>Can create images of your servers at any time with a few clicks or simple API call. </li><li>different instance type for different use cases:<ul><li>low traffic websites </li><li>small database </li><li>high performance web services </li><li>high performance databases </li><li>distributed memory caches </li><li>data warehousing </li><li>log or data-processing applications </li><li>3D visualizations </li><li>Machine learning </li></ul></li><li>Pricing <ul><li>on demand </li><li>reserved instances </li><li>spot instances </li></ul></li></ul><h2 id="4-2-ELB-Elastic-Load-Balancing"><a href="#4-2-ELB-Elastic-Load-Balancing" class="headerlink" title="4.2 ELB - Elastic Load Balancing"></a>4.2 ELB - Elastic Load Balancing</h2><ul><li><p>distribute traffic across multiple EC2 instances, in multiple Availability Zones </p></li><li><p>Support health checks to detect unhealthy Amazon EC2 instances </p><ul><li>To discover the availability of instances, a ELB periodically sends pings, attempts connections or sends requests to test the EC2 instances.  </li></ul></li><li><p>Supports the routing and load balancing of traffic to Amazon EC2 instances. </p></li><li><p>when the LB determins that an instance is unhealthy, it stops routing requests to that instance. </p></li><li><p>sticky sessions</p><ul><li>enables the load balancer to bind a user’s session to a <strong>specific server instance</strong>. </li></ul></li><li><p>we should get rid of sticky sessions since: </p><ul><li>limit application’s scalability </li><li>lead to unequal load across servers </li><li>affect end-user response time since a single user’s load isn’t even spread across servers. </li></ul></li><li><p>Instead of using sticky sessions: cache </p><ul><li>manage user sessions by<ul><li>store locally to the node responding to the HTTP request </li><li>designate a layer which can store those sessions in a scalable and robust manner. </li></ul></li><li>Duration based session stickiness<ul><li>LB uses a special LB generated cookie to rack the application instance for each request. <strong>When the load balancer reveives a request, it first checks to see whether this cookie is present in the request</strong>.  If so, the reqeust is sent to the application instance specified in the cookie. If not, the LB chooses an application instance based on the existing load balancing algo. <strong>A cookie is inserted into the response for binding subsequent requests from the same user to that application instance</strong>. The stickiness policy configuration defines a cookie expiration, which establishes the duration of validity for each cookie. Cookie will be automatically updated after its duration expires. </li></ul></li><li>Application base session stickiness <ul><li>LB uses a <strong>special cookie</strong> to associate the session with the original server that handled the reqeust. But follows the lifetime of the application-generated cookie corresponding to the cookie name specified in the policy configuration. </li><li>The LB only inserts a new stickiness cookie if the application response includes a new application cookie. </li><li>The load balancer stickiness cookie does not update with each request. If the application cookie is explicitly removed or expires, the session stops being sticky until a new application cookie is issued.</li><li>Application often store session data in memory, but this approach does not scale well</li></ul></li></ul></li><li><p>Methods available to manage session data without sticky sessions include: </p><ul><li>using ElasticCache to store session data </li><li>using Amazon DynamoDB to store session data </li></ul></li></ul><h2 id="4-3-Auto-Scaling"><a href="#4-3-Auto-Scaling" class="headerlink" title="4.3 Auto Scaling"></a>4.3 Auto Scaling</h2><p>Auto Scaling helps you ensure that you have the correct number of EC2 instances available to handle the load for your application. Auto Scaling is particularly well-suited for applications that experience hourly, daily, or weekly variability in usage.</p><h1 id="5-Exceptions-and-Errors-handle"><a href="#5-Exceptions-and-Errors-handle" class="headerlink" title="5. Exceptions and Errors handle"></a>5. Exceptions and Errors handle</h1><ul><li>400 series: handle error in application </li><li>500 series: retry operations </li></ul><p>Java SDK throes the following unchecked(runtime) exceptions when error occur:</p><ul><li>AmazonServiceException<ul><li>indicates that the reqeust was correctly transmitted to the service, but for some reason, the service was not able to process it, and returned an error response instead. </li></ul></li><li>AmazonClientException <ul><li>indicates that a problem occured inside the hava client code <ul><li>try to send a request to AWS </li><li>try to parse a response from AWS </li></ul></li></ul></li><li>IllegalArgumentException <ul><li>throw if you pass an illegal argument when performing an operation on a service  </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> EC2 </tag>
            
            <tag> ELB </tag>
            
            <tag> AutoScaling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么要合并HTTP请求?</title>
      <link href="/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%90%88%E5%B9%B6HTTP%E8%AF%B7%E6%B1%82/"/>
      <url>/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%90%88%E5%B9%B6HTTP%E8%AF%B7%E6%B1%82/</url>
      
        <content type="html"><![CDATA[<p>思考路径：<br>为什么要实现batch call? -&gt; 减少网络中的传输损耗 -&gt; 如何减少的? -&gt; 通过合并HTTP请求 -&gt; 合并HTTP请求是如何减少网络损耗的？ </p><p>本文将解决这个问题。一起看看单个请求携载大量信息和多个请求携载小量信息对于整个时间的影响。</p><h1 id="1-Client发出请求"><a href="#1-Client发出请求" class="headerlink" title="1. Client发出请求"></a>1. Client发出请求</h1><h2 id="1-1-HTTP-1-1"><a href="#1-1-HTTP-1-1" class="headerlink" title="1.1 HTTP 1.1"></a>1.1 HTTP 1.1</h2><p>可以保持长连接，但是每个不同的请求之间，client要向server发一个请求头</p><p>请求无法并行执行的，在一个连接里面</p><p>假设如果不合并的话需要建立N个连接，那么合并就可以省去(N-1)*RTT的时间，RTT指网络延迟（在传输介质中传输所用的时间，即从报文开始进入网络到它开始离开网络之间的时间）。</p><h2 id="1-2-TCP丢包问题"><a href="#1-2-TCP丢包问题" class="headerlink" title="1.2 TCP丢包问题"></a>1.2 TCP丢包问题</h2><p>慢启动，拥塞控制窗口</p><p>TCP报文乱序到达，合并后的文件可以允许队首丢包以后在队中补上来，但是分开资源的时候，前一个资源未加载完成后面的资源是不能加载的，会有更严重的队首阻塞问题，丢包率会严重影响Keep alive情况下多个文件的传输速率。</p><h2 id="1-3-浏览器线程数限制"><a href="#1-3-浏览器线程数限制" class="headerlink" title="1.3 浏览器线程数限制"></a>1.3 浏览器线程数限制</h2><p>多为2-6个线程，会在每个连接上串行发送若干个请求。TCP连接太多，会给服务器造成很大的压力的。</p><h2 id="1-4-DNS缓存问题"><a href="#1-4-DNS缓存问题" class="headerlink" title="1.4 DNS缓存问题"></a>1.4 DNS缓存问题</h2><p> 每次请求都需要找DNS缓存，多个请求就需要查找多次，而且缓存有可能被无故清空</p><h1 id="2-服务器处理请求"><a href="#2-服务器处理请求" class="headerlink" title="2. 服务器处理请求"></a>2. 服务器处理请求</h1><p>每个请求需要使用一个连接，建立一个线程，分配一部分CPU, 对于CPU而言，是种负担，尤其是一般来说建立了连接以后，哪怕发回了请求，这个连接还会保持一段时间才会timeout。这种时候，维持连接是对服务器资源的一种巨大的浪费。</p><h1 id="3-HTTP-2-0"><a href="#3-HTTP-2-0" class="headerlink" title="3. HTTP 2.0"></a>3. HTTP 2.0</h1><p>上面描述的所有都是基于HTTP/1.1的一些特性，或者说弊端，有长连接但是无法并行处理请求，TCP的慢启动和拥塞控制，队首阻塞问题都给整个性能带来很多弊端，因此我们有了HTTP2.0来做针对性的改进。很有意思的东西，直接看图： </p><ul><li><p>HTTP/1.1 network的请求图<br><img src="https://i.loli.net/2020/01/29/JPaxGAR2lrnKh6b.png" alt="http1-waterfall.png"></p></li><li><p>HTTP/2 network的请求图<br><img src="https://i.loli.net/2020/01/29/C64pmQAVzZrtyus.png" alt="http2-waterfall.png"></p></li></ul><p>就是这么酷炫，HTTP/2多了很多特性来解决HTTP/1.1的很多问题</p><h2 id="3-1-Fully-multiplexed"><a href="#3-1-Fully-multiplexed" class="headerlink" title="3.1 Fully multiplexed"></a>3.1 Fully multiplexed</h2><p>解决了队首阻塞的问题。对于同一个TCP连接，现在可以发送多个请求，接收多个回应了！在HTTP/1.1里面，如果在一个连接里上一个请求发生了丢包，那么后面的所有请求都必须等第一个请求补上包，收到回应以后才能继续执行。而在HTTP/2里面，可以直接并行处理。</p><h2 id="3-2-Header-Compression"><a href="#3-2-Header-Compression" class="headerlink" title="3.2 Header Compression"></a>3.2 Header Compression</h2><p>所有的HTTP request和response都有header，但是header里很可能包含缓存信息，导致他的大小会迅速增大的。但是在一个连接里大部分请求的请求头其实携带的信息都很类似，所以HTTP/2使用了索引表，存储了第一次出现的请求的请求头，然后后面的类似的请求只需要携带这个索引的数字就好了。头部压缩平均减少了30%的头部大小，加快了整体的网络中传输的速度。</p><p>这两点是和本文关系最大的，有了这两点，实质上合并HTTP请求的好处在HTTP/2的协议下，已经基本上消失了。合并不合并请求，更多的是看业务上的需求，后端的一些配置。</p><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><p>It’s a trade-off. 其实最重要的是看你传输什么东西，因为合并HTTP请求实质上是减少了网络延时，但是如果你在服务器上处理的时间远远大于网络延时的时间的时候，那么合并HTTP请求并不会给你带来很多性能上的提升。而且大数据量的传输一定会降低浏览器的cache hit rate,对于缓存的利用率会降低很多。但是对于HTTP请求携带的数据量比较少的情况，合并请求带来的性能提升会是显而易见的。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.zhihu.com/question/34689035" target="_blank" rel="noopener">1. 网络延迟</a></p><p><a href="https://www.zhihu.com/question/34401250" target="_blank" rel="noopener">2.知乎:合并HTTP请求是否真的有意义？</a></p><p><a href="https://deliciousbrains.com/performance-best-practices-http2/" target="_blank" rel="noopener">3. HTTP/2 Intro</a></p><p><a href="https://www.tutorialdocs.com/article/merge-parallel-http-request.html" target="_blank" rel="noopener">4. Merge parallel htto requests</a></p>]]></content>
      
      
      <categories>
          
          <category> Network </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> Network </tag>
            
            <tag> HTTP </tag>
            
            <tag> Batch Processing </tag>
            
            <tag> Web Development </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java-Synchronized方法</title>
      <link href="/Java-Synchronized%E6%96%B9%E6%B3%95/"/>
      <url>/Java-Synchronized%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="1-synchronized-type"><a href="#1-synchronized-type" class="headerlink" title="1. synchronized type"></a>1. synchronized type</h1><ol><li>Synchronized methods</li><li>Synchronized statements </li></ol><h1 id="2-Synchronized-Methods"><a href="#2-Synchronized-Methods" class="headerlink" title="2. Synchronized Methods"></a>2. Synchronized Methods</h1><p>修饰实例方法，作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁。修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁。 </p><h2 id="2-1-不可插入"><a href="#2-1-不可插入" class="headerlink" title="2.1 不可插入"></a>2.1 不可插入</h2><p>It is not possible for two invocations of synchronized methods on the same object to interleave. When one thread is executing a synchronized method for an object, all other threads that invoke synchronized methods for the same object block (suspend execution) until the first thread is done with the object.</p><p>当一个方法是同步的时候，当前线程在执行时，其他线程都会停止运行，直到线程完成工作，下一个线程继续执行。</p><h2 id="2-2-自动传递状态"><a href="#2-2-自动传递状态" class="headerlink" title="2.2 自动传递状态"></a>2.2 自动传递状态</h2><p>when a synchronized method exits, it automatically establishes a happens-before relationship with any subsequent invocation of a synchronized method for the same object. This guarantees that changes to the state of the object are visible to all threads.</p><p>保证状态可见，上个线程对对象的操作结果会作为输入给下一个线程来使用。 </p><h1 id="3-Synchronized-Statements"><a href="#3-Synchronized-Statements" class="headerlink" title="3. Synchronized Statements"></a>3. Synchronized Statements</h1><p>修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。</p><p>Synchronized statements must specify the object that provides the intrinsic lock. </p><pre><code>public void addName(String name) {    synchronized(this) {        lastName = name;        nameCount++;    }    nameList.add(name);}</code></pre><p>这里lastname 和namecount都要改变，是同步的。但要注意在声明里不可以调用其他对象的方法。</p><h1 id="4-底层实现原理"><a href="#4-底层实现原理" class="headerlink" title="4. 底层实现原理"></a>4. 底层实现原理</h1><p>可以锁代码块，也可以锁方法。如果锁的是类的实例对象，那么就是锁这个。如果锁的是类对象，那么尽管new多个实例对象，他们仍然属于同一个类，依然会被锁住，即线程之间保证同步关系。</p><p><code>synchronized</code> 同步语句块的实现使用的是 <code>monitorenter</code> 和 <code>monitorexit</code> 指令，其中 <code>monitorenter</code> 指令指向同步代码块的开始位置，<code>monitorexit</code> 指令则指明同步代码块的结束位置。</p><p>当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。</p><p>最开始的Synchronized是调用OS的mutex lock，要完成context switch ，映射到原生操作系统里，从用户态转到内核态。现在从JVM层面做了大量的优化，减少了锁开销。</p><h1 id="5-synchronized-优化"><a href="#5-synchronized-优化" class="headerlink" title="5. synchronized 优化"></a>5. synchronized 优化</h1><p>synchronized是互斥的，我们需要找方法加快中间过程，比如传统的零售交钱排队，找零到扫码付费的转变。这里介绍轻量级锁，偏向锁。</p><h2 id="5-1-CAS操作"><a href="#5-1-CAS操作" class="headerlink" title="5.1 CAS操作"></a>5.1 CAS操作</h2><p>使用锁的时候，线程获取锁是一种悲观锁，即认为每一次执行临界区的代码都会产生冲突，所以当前线程获取锁的时候同时会堵塞其他线程获取锁。而CAS是一种乐观锁策略，<strong>假设所有线程访问共享资源的时候不会出现冲突</strong>。出现了冲突以后采取CAS(compare and swap) 策略，用来比较交换，看线程之间是否出现了冲突。</p><h3 id="5-1-1-操作过程"><a href="#5-1-1-操作过程" class="headerlink" title="5.1.1 操作过程"></a>5.1.1 操作过程</h3><p>CAS比较交换的过程可以通俗的理解为CAS(V,O,N)，包含三个值分别为：V 内存地址存放的实际值；O 预期的值（旧值）；N 更新的新值。当V和O相同时，也就是说旧值和内存中实际的值相同表明该值没有被其他线程更改过，即该旧值O就是目前来说最新的值了，自然而然可以将新值N赋值给V。反之，V和O不相同，表明该值已经被其他线程改过了则该旧值O不是最新版本的值了，所以不能将新值N赋给V，返回V即可。当多个线程使用CAS操作一个变量是，只有一个线程会成功，并成功更新，其余会失败。失败的线程会重新尝试，当然也可以选择挂起线程。</p><p>It compares the contents of a memory location with a given value and, only if they are the same, modifies the contents of that memory location to a new given value. This is done as a single atomic operation. The atomicity guarantees that the new value is calculated based on up-to-date information; if the value had been updated by another thread in the meantime, the write would fail.</p><p>非阻塞同步。</p><h3 id="5-1-2-存在的问题"><a href="#5-1-2-存在的问题" class="headerlink" title="5.1.2 存在的问题"></a>5.1.2 存在的问题</h3><ol><li>ABA问题</li></ol><p>发生了变化，但又变了回去。（加上序号来解决）</p><ol start="2"><li>自旋时间过长</li><li>只能保证一个共享变量的原子操作</li></ol><h2 id="5-2-对象头"><a href="#5-2-对象头" class="headerlink" title="5.2 对象头"></a>5.2 对象头</h2><p>对象的锁 -&gt;  对象的标记，存在java对象的对象头里面。存放有</p><ol><li>锁状态<ul><li>无锁状态</li><li>偏向锁状态</li><li>轻量级锁状态</li><li>重量级锁状态</li></ul></li><li>对象的hashcode</li><li>对象分代年龄</li><li>是否是偏向锁</li><li>锁标志位</li></ol><blockquote><p>Tips: 级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</p></blockquote><h2 id="5-3-偏向锁"><a href="#5-3-偏向锁" class="headerlink" title="5.3 偏向锁"></a>5.3 偏向锁</h2><p>大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。</p><p>当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程</p><p>偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。</p><h2 id="5-4-轻量级锁"><a href="#5-4-轻量级锁" class="headerlink" title="5.4 轻量级锁"></a>5.4 轻量级锁</h2><p>线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。</p><p>轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。</p><h2 id="5-5-比较"><a href="#5-5-比较" class="headerlink" title="5.5 比较"></a>5.5 比较</h2><p><img src="https://i.loli.net/2020/01/29/meDvzPd6g24ITU9.png" alt="锁比较.png"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://en.wikipedia.org/wiki/Compare-and-swap" target="_blank" rel="noopener">1. Wiki: Compare and swap</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Concurrency </tag>
            
            <tag> Synchronized </tag>
            
            <tag> Lock </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Volatile关键字</title>
      <link href="/Volatile%E5%85%B3%E9%94%AE%E5%AD%97/"/>
      <url>/Volatile%E5%85%B3%E9%94%AE%E5%AD%97/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Synchronized-vs-volatile"><a href="#1-Synchronized-vs-volatile" class="headerlink" title="1. Synchronized vs volatile"></a>1. Synchronized vs volatile</h1><p>synchronized是阻塞式同步，在线程竞争激烈的情况下会升级为重量级锁。而volatile是java虚拟机提供的最轻量级的同步机制。而针对volatile修饰的变量给java虚拟机特殊的约定，线程对volatile变量的修改会立刻被其他线程所感知，即不会出现数据脏读的现象，从而保证数据的“可见性”。</p><p><strong>被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象。</strong></p><h1 id="2-实现原理"><a href="#2-实现原理" class="headerlink" title="2. 实现原理"></a>2. 实现原理</h1><p>生成汇编代码时会在Volatile修饰的共享变量进行写操作的时候多出lock前缀的指令：<strong>该指令会将当前处理器缓存行的数据写会系统内存；这个写回内存的操作会使得其他CPU里缓存了该内存地址的数据无效</strong></p><p>为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到<strong>内部缓存（L1，L2或其他</strong>）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现<strong>缓存一致性协</strong>议，<strong>每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。</strong>因此，经过分析我们可以得出如下结论：</p><ol><li>lock前缀的指令会引起处理器缓存写回内存</li><li>一个处理器的缓存回写到内存会导致其他处理器的缓存失效</li><li>当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获得当前最新值</li></ol><h1 id="3-volatile的happen-before关系"><a href="#3-volatile的happen-before关系" class="headerlink" title="3. volatile的happen before关系"></a>3. volatile的happen before关系</h1><p>写后读，线程A改本地内存的变量，同步到主内存，线程B的本地内存废弃，到主内存中拿到更新的数据。</p><h1 id="4-volatile的内存语义实现"><a href="#4-volatile的内存语义实现" class="headerlink" title="4. volatile的内存语义实现"></a>4. volatile的内存语义实现</h1><p>为了性能优化，JMM在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序，那如果想阻止重排序要怎么办了？答案是可以添加内存屏障。</p><p>内存屏障类型： </p><p><img src="https://i.loli.net/2020/01/29/kIQaATpeCf56nxs.png" alt="内存屏障.png"></p><p><img src="https://i.loli.net/2020/01/29/RKDH1XxFAJeQVjY.png" alt="重排序.png"></p><p>“NO”表示禁止重排序。为了实现volatile内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM采取了保守策略：</p><ol><li>在每个volatile写操作的前面插入一个StoreStore屏障；</li><li>在每个volatile写操作的后面插入一个StoreLoad屏障；</li><li>在每个volatile读操作的后面插入一个LoadLoad屏障；</li><li>在每个volatile读操作的后面插入一个LoadStore屏障。</li></ol><p><img src="https://i.loli.net/2020/01/29/8JCkKYZg2NfMzP5.png" alt="volatile内存屏障.png"><br><img src="https://i.loli.net/2020/01/29/uY9qUvorMLK5a1V.png" alt="volatile读插入内存屏障示意图.png"></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BackEnd </tag>
            
            <tag> Java </tag>
            
            <tag> Concurrency </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java并发图谱</title>
      <link href="/Java%E5%B9%B6%E5%8F%91%E5%9B%BE%E8%B0%B1/"/>
      <url>/Java%E5%B9%B6%E5%8F%91%E5%9B%BE%E8%B0%B1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>在网上看到的描述Java并发的非常棒的知识图谱，分享/标注一波。</p></blockquote><p>包含： </p><ol><li>并发理论</li><li>并发关键字</li><li>Lock体系</li><li>并发容器</li></ol><p><img src="https://i.loli.net/2020/01/29/neDuY6XEaA2FsV9.png" alt="java-concurrency.png"></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BackEnd </tag>
            
            <tag> Java </tag>
            
            <tag> Concurrency </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浏览器输入url以后都发生了什么</title>
      <link href="/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E4%BB%A5%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/"/>
      <url>/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E4%BB%A5%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/</url>
      
        <content type="html"><![CDATA[<p>从输入一个网址开始，都调用了哪些服务，经历了哪些步骤，深度解析。以输入<a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a> 为例。</p><h1 id="1-Client端"><a href="#1-Client端" class="headerlink" title="1. Client端"></a>1. Client端</h1><p>一般来说，这里的Client指用户，即browser浏览器。这里我们以输入google.com为例。</p><h2 id="1-1-输入提示"><a href="#1-1-输入提示" class="headerlink" title="1.1 输入提示"></a>1.1 输入提示</h2><p>浏览器会根据历史访问，书签等信息给出输入建议。</p><p>还会根据默认搜索引擎的搜索记录，去匹配最近的搜索记录。</p><h2 id="1-2-url解析"><a href="#1-2-url解析" class="headerlink" title="1.2 url解析"></a>1.2 url解析</h2><p>如果是不合法的地址，会转给默认的搜索引擎,例如如果你正在使用chrome，可以在url输入框输入你想要搜索的内容，然后搜索引擎会根据关键字进行搜索。</p><p>HSTS列表 安全策略机制，强行使用https</p><h2 id="1-3-DNS解析"><a href="#1-3-DNS解析" class="headerlink" title="1.3 DNS解析"></a>1.3 DNS解析</h2><p>域名通过DNS转化为ip地址，这个转化主要是为了人机交互的友好型。没有人喜欢记一堆数字来访问一个网站。DNS做的事情就是把你输入的<a href="http://www.google.com翻译成计算机可以理解的IP地址，类似于192.188.1.1这种样子。" target="_blank" rel="noopener">www.google.com翻译成计算机可以理解的IP地址，类似于192.188.1.1这种样子。</a></p><h3 id="1-3-1查询过程"><a href="#1-3-1查询过程" class="headerlink" title="1.3.1查询过程"></a>1.3.1查询过程</h3><p>在解析的过程中，浏览器会由近及远寻找是否有缓存信息，即存没存从域名到地址的映射，整个查询过程分为如下几步，值得注意的是一旦查询到，就会立刻返回，不会再继续执行下去了。</p><ol><li>查看浏览器内部缓存</li></ol><p>浏览器内会会存有在一段时间内你曾经访问过的网站的域名地址的映射。</p><ol start="2"><li>系统缓存</li></ol><p>操作系统的缓存。浏览器会发出system call， 去询问操作系统是否存有相应的映射。</p><ol start="3"><li>路由器缓存， ISP缓存</li></ol><p>查询路由器的缓存。如果在路由器缓存中没有找到映射，就会去ISP(Internet Service Provider)处去寻找</p><ol start="4"><li><p>本地DNS服务器</p></li><li><p>域名服务器  根域服务器  -&gt; 顶级域名服务器</p></li></ol><p>寻找方式类似于一个树状结构，从最底层的子叶开始向上遍历，不停向更高级的域名服务器发出请求。这个过程会不停发送携带有请求和IP地址的数据包，会经过在client和server之间的多个网路设备直到其到达正确的DNS服务器。</p><h1 id="2-网络"><a href="#2-网络" class="headerlink" title="2 网络"></a>2 网络</h1><p>找到了正确的IP地址以后就要开始建立连接了，建立连接的过程一般会使用TCP协议，通过三次握手建立连接。</p><h2 id="2-1-TCP连接"><a href="#2-1-TCP连接" class="headerlink" title="2.1 TCP连接"></a>2.1 TCP连接</h2><p>会用TCP，建立连接。并在Client和Server之间传递数据包。</p><h3 id="2-1-1-IP封装-socket"><a href="#2-1-1-IP封装-socket" class="headerlink" title="2.1.1 IP封装  socket"></a>2.1.1 IP封装  socket</h3><h3 id="2-1-2-TCP-三次握手"><a href="#2-1-2-TCP-三次握手" class="headerlink" title="2.1.2 TCP 三次握手"></a>2.1.2 TCP 三次握手</h3><ol><li>Client 发出建立连接的请求。数据包携带有<code>SYN</code>。</li><li>如果Server有开放的端口，可以接受并建立连接，那么server会返回<code>SYN</code> + <code>ACK</code>, 告诉Client我可以接受你的请求。</li><li>Client收到Server的回应，发送<code>ACK</code>给Server。 连接建立。</li></ol><p>给一个知乎连接，<a href="https://www.zhihu.com/question/24853633" target="_blank" rel="noopener">为什么是三次握手，不是两次或者四次？</a>  非常有意思的例子。</p><h3 id="2-1-3-TCP-四次挥手"><a href="#2-1-3-TCP-四次挥手" class="headerlink" title="2.1.3 TCP 四次挥手"></a>2.1.3 TCP 四次挥手</h3><ol><li>Client发起中断请求，发送<code>FIN</code>到server</li><li>Server收到请求，可能数据还没有发完。这个时候不会关闭socket，而是回复<code>ACK</code>，告诉Client知道了</li><li>Client进入<code>Fin_Wait</code>状态，继续等待Server端的<code>FIN</code>报文。Server端发送完毕后，会向Client发送<code>FIN</code></li><li>Client收到后就回复<code>ACK</code>，并关闭连接</li></ol><h1 id="3-Server"><a href="#3-Server" class="headerlink" title="3 Server"></a>3 Server</h1><p>这里主要描述TCP连接建立和断开之间发生的一些事情。</p><p>TCP/IP是个协议组，是网络层和传输层的协议。Client首先建立一条与服务器的TCP连接（上文中的三次握手）。而后Client发送HTTP请求，这里为了获得页面，会发送一个GET请求给服务器。请求会包含浏览器ID，用户数据头，连接头（包含额外信息，比如是否需要保持TCP连接等），从cookie获取的数据等。</p><p>Server收到Client的Request，会将请求传递给Request Handler，去处理请求（从数据库查找数据，处理数据，构建Response）。构建完毕后会返回一个Response。值得注意的是这个Response里会含有状态信息： </p><ul><li>1xx informational message only  —— 包含信息</li><li>2xx success of some kind  ——成功信息</li><li>3xx redirects the client to another URL  ——将Client转到其他URL</li><li>4xx indicates an error on the client’s part  ——Client端错误 </li><li>5xx indicates an error on the server’s part  ——Server端错误</li></ul><h1 id="4-页面渲染"><a href="#4-页面渲染" class="headerlink" title="4 页面渲染"></a>4 页面渲染</h1><p>浏览器根据Resonse返回数据，渲染出DOM树，将返回的数据呈现在页面上。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://github.com/sunyongjian/blog/issues/34" target="_blank" rel="noopener">https://github.com/sunyongjian/blog/issues/34</a></p>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> Browser </tag>
            
            <tag> CDN </tag>
            
            <tag> network </tag>
            
            <tag> TCP/ IP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React初探</title>
      <link href="/React%E5%88%9D%E6%8E%A2/"/>
      <url>/React%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<p>初探React,很喜欢Component这种方式，很大程度提高了复用性，如果抛除C/S的区别，感觉有点像mason，毕竟刚刚弃掉mason的坑，很有意思的React。</p><h1 id="1-Hello-World"><a href="#1-Hello-World" class="headerlink" title="1. Hello World"></a>1. Hello World</h1><p>React.Component   A component takes in parameters, called props and returns a hierarchy of views to display via the render method. </p><p>To collect data from multiple children, or to have two child components communicate with each other, you need to declare the shared state in their parent component instead. <strong>The parent component can pass the state back down to the children by using props; this keeps the child components in sync with each other and with the parent component.</strong> </p><pre><code>ReactDOM.render(    &lt;h1&gt;Hello, world!&lt;/h1&gt;,    document.getElementById(&apos;root&apos;));</code></pre><h1 id="2-JSX"><a href="#2-JSX" class="headerlink" title="2. JSX"></a>2. JSX</h1><p>jsx, 一种JavaScript的语法扩展。用来声明React当中的元素。可以任意在<strong>大括号{}</strong>里面使用<strong>JS表达式</strong>.</p><h2 id="2-1-JS表达式"><a href="#2-1-JS表达式" class="headerlink" title="2.1 JS表达式"></a>2.1 JS表达式</h2><blockquote><p>Any valid unit of code that resolves to a value. </p></blockquote><h3 id="2-1-1-分类"><a href="#2-1-1-分类" class="headerlink" title="2.1.1 分类"></a>2.1.1 分类</h3><ul><li><p>Arithmetic</p></li><li><p>String </p></li><li><p>Logical</p></li><li><p>Primary Expressions</p></li></ul><p>Basic keywords and general expressions in JS.</p><ol><li><p>this: refer to the current object.</p></li><li><p>grouping operator() : controls the precedence of evaluation in expressions. </p></li><li><p>new: to create an instance of a user-defined object type </p></li><li><p>super: call functions on an object’s parent.</p></li><li><p>spread operator: allow an expression to be expanded in places where multiple arguments or multiple elements are expected. </p><pre><code> function f(x, y, z) { }var args = [0, 1, 2];f(...args);</code></pre></li></ol><ul><li>Left hand side expressions</li></ul><h2 id="2-2-JSX-属性"><a href="#2-2-JSX-属性" class="headerlink" title="2.2 JSX 属性"></a>2.2 JSX 属性</h2><p>编译之后，会被转化为普通的JS对象。这意味着可以在if 或者for语句里使用JSX，将其赋值给变量，当做参数传入或者作为返回值都可以。</p><pre><code>// 使用引号定义以字符串为值得属性const element = &lt;div tabIndex=&quot;0&quot;&gt;&lt;/div&gt;;// 使用大括号来定义以js表达式为值得属性const element = &lt;img src={user.avatarUrl}&gt;&lt;/img&gt;;</code></pre><p>JSX代表Objects, Babel转译器会把JSX转换成一个名为React.createEliment()的方法来调用</p><h2 id="2-3-嵌套与防注入攻击"><a href="#2-3-嵌套与防注入攻击" class="headerlink" title="2.3 嵌套与防注入攻击"></a>2.3 嵌套与防注入攻击</h2><pre><code>const element = (  &lt;div&gt;    &lt;h1&gt;Hello!&lt;/h1&gt;    &lt;h2&gt;Good to see you here.&lt;/h2&gt;  &lt;/div&gt;);React DOM在渲染之前会过滤所有传入的值，可以确保应用不会被注入攻击，因为所有内容渲染之前都已经被转化为了字符串，有效防止XSS。 </code></pre><h1 id="3-元素渲染"><a href="#3-元素渲染" class="headerlink" title="3. 元素渲染"></a>3. 元素渲染</h1><p>React中的元素实际上是普通的对象，React DOM可以确保浏览器DOM的数据内容与React元素保持一致。<br>寻找React 根节点，渲染在根节点上</p><pre><code>const element = &lt;h1&gt;Hello, world&lt;/h1&gt;;ReactDOM.render(element, document.getElementById(&apos;root&apos;));</code></pre><h2 id="3-1-更新元素渲染"><a href="#3-1-更新元素渲染" class="headerlink" title="3.1 更新元素渲染"></a>3.1 更新元素渲染</h2><p>React 元素都是immutable的，更新界面的方式就是创建一个新的元素，然后将其传入<code>ReactDOM.render()</code> </p><p>React DOM 会比较元素的内容的先后的不同，而在渲染过程中只会更新改变了的部分。</p><h1 id="4-组件-amp-props"><a href="#4-组件-amp-props" class="headerlink" title="4. 组件 &amp; props"></a>4. 组件 &amp; props</h1><p>组件将UI切分成一些独立的，可复用的部件，这样就可以专注于构建每一个单独的部件。概念上像<strong>函数</strong>一样，可以接受任意的输入值(props)，并返回一个在页面上展示的React元素。</p><h2 id="4-1-函数定义组件"><a href="#4-1-函数定义组件" class="headerlink" title="4.1 函数定义组件"></a>4.1 函数定义组件</h2><pre><code>function Welcome(props) {    return &lt;h1&gt;Hello, {props.name}&lt;/h1&gt;;}</code></pre><h2 id="4-2-ES6-class-定义组件"><a href="#4-2-ES6-class-定义组件" class="headerlink" title="4.2 ES6 class 定义组件"></a>4.2 ES6 class 定义组件</h2><pre><code>class Welcome extends React.Component {    render() {        return &lt;h1&gt;Hello, {this.props.name}&lt;/h1&gt;    }}</code></pre><h2 id="4-3-组件渲染"><a href="#4-3-组件渲染" class="headerlink" title="4.3 组件渲染"></a>4.3 组件渲染</h2><pre><code>// React 元素可以使用户自定义的组件const element = &lt;Welcome name=&quot;Sara&quot; /&gt;;</code></pre><p><strong>当React遇到的元素是用户自定义的组件，它会将JSX属性作为单个对象传递给该组件，这个对象被称为”props”</strong></p><blockquote><p>组件名称必须大写</p></blockquote><h2 id="4-4-组合组件"><a href="#4-4-组合组件" class="headerlink" title="4.4 组合组件"></a>4.4 组合组件</h2><p>组件可以在它的输出中引用其他组件，这样我们就可以用同一组件来抽象出任意层次的细节。</p><blockquote><p>一个新的React应用程序的顶部是一个App组件。但是，如果要将React集成到现有应用程序中，则可以从下而上使用像Button这样的小组件作为开始，并逐渐运用到视图层的顶部。</p></blockquote><blockquote><p>组件的返回值只能有一个根元素。这也是我们要用一个<div>来包裹所有<Welcome />元素的原因。</p></blockquote><h2 id="4-5-提取组件"><a href="#4-5-提取组件" class="headerlink" title="4.5 提取组件"></a>4.5 提取组件</h2><p>分割组件，</p><h2 id="4-6-Props的只读性"><a href="#4-6-Props的只读性" class="headerlink" title="4.6 Props的只读性"></a>4.6 Props的只读性</h2><p>所有的React组件必须像纯函数那样使用它们的props</p><h1 id="5-State-amp-生命周期"><a href="#5-State-amp-生命周期" class="headerlink" title="5. State &amp; 生命周期"></a>5. State &amp; 生命周期</h1><p>更新UI的方法： <code>ReactDOM.render()</code></p><p>还可以通过更新状态来更新UI，<strong>状态是私有的，完全受控于当前组件</strong></p><h2 id="5-1-将函数转换为类"><a href="#5-1-将函数转换为类" class="headerlink" title="5.1 将函数转换为类"></a>5.1 将函数转换为类</h2><p>定义为类的组件有状态这个特性，还有生命周期钩子。</p><p>函数转换为类的步骤： </p><ol><li>创建一个名称扩展为<code>React.Component</code>的类</li><li>创建一个<code>render()</code>空方法</li><li>将函数体移动到render()方法中</li><li>在render()方法中，使用this.props替换props</li><li>删除剩余的空函数声明</li></ol><h2 id="5-2-为类添加局部状态"><a href="#5-2-为类添加局部状态" class="headerlink" title="5.2 为类添加局部状态"></a>5.2 为类添加局部状态</h2><pre><code>Class Clock extends React.Component {    constructor(props) {        super(props);        this.state = {date: new Date()};    }    render() {        return (            &lt;div&gt;                &lt;h1&gt;Hello, world!&lt;/h1&gt;                &lt;h2&gt;It is {this.state.date.toLocaleTimeString()}.&lt;/h2&gt;            &lt;/div&gt;        );    }}ReactDOM.render(    &lt;Clock/&gt;    document.getElementById(&apos;root&apos;));</code></pre><h2 id="5-3-添加生命周期方法到类中"><a href="#5-3-添加生命周期方法到类中" class="headerlink" title="5.3 添加生命周期方法到类中"></a>5.3 添加生命周期方法到类中</h2><p>当组件第一次加载到DOM中时，生成定时器，挂载</p><pre><code>componentDidMount() {}</code></pre><p>当Clock生成的这个DOM被移除时，清除定时器，卸载</p><pre><code>componentWillUnmount() {}</code></pre><p>一个完整的Clock的例子： </p><pre><code>class Clock extends React.Component {    constructor(props) {        super(props);        this.state = {date: new Date()};    }    // 3. Called when Clock&apos;s output is injected into DOM     componentDidMount() {        this.timerID = setInterval(            () =&gt; this.tick(),                1000        );    }    componentWillUnmount() {        clearInterval(this.timerID);    }    // 4. when setState() is being called, render() is called     tick() {        this.setState({            date: new Date()        });    }    // 2. Call render(), react know what need to be shown on screen. Update DOM     render() {        return (          &lt;div&gt;            &lt;h1&gt;Hello, world!&lt;/h1&gt;            &lt;h2&gt;It is {this.state.date.toLocaleTimeString()}.&lt;/h2&gt;          &lt;/div&gt;        );    }}ReactDOM.render(// 1. call Clock&apos;s constructor  &lt;Clock /&gt;,  document.getElementById(&apos;root&apos;));</code></pre><h2 id="5-4-如何使用状态"><a href="#5-4-如何使用状态" class="headerlink" title="5.4 如何使用状态"></a>5.4 如何使用状态</h2><ol><li><p>不要直接更新状态</p><p> use: this.setState({comment: ‘hi’});</p></li></ol><blockquote><p>构造函数是唯一能够初始化this.state的地方</p></blockquote><ol start="2"><li>状态更新可能是异步的</li></ol><p>React可以将多个<code>setState()</code>调用合并成一个来提高性能</p><pre><code>// Wrongthis.setState({  counter: this.state.counter + this.props.increment,});// Correctthis.setState((prevState, props) =&gt; ({  counter: prevState.counter + props.increment}));// Correctthis.setState(function(prevState, props) {  return {    counter: prevState.counter + props.increment  };});</code></pre><ol start="3"><li>当调用<code>setState()</code>的时候，React会将你提供的对象合并到当前状态。可以只提供state的一部分。</li></ol><h2 id="5-5-数据流动方向：-自顶向下"><a href="#5-5-数据流动方向：-自顶向下" class="headerlink" title="5.5 数据流动方向： 自顶向下"></a>5.5 数据流动方向： 自顶向下</h2><p>父组件或子组件都不知道某个组件是否有状态，组件可以选择将其状态作为属性传递给其子组件。</p><h1 id="6-事件处理"><a href="#6-事件处理" class="headerlink" title="6. 事件处理"></a>6. 事件处理</h1><p>React事件绑定属性的命名采用驼峰式写法</p><p>采用jsx的语法你需要传入一个函数作为事件处理函数，而不是一个字符串。</p><pre><code>&lt;button onClick={activateLasers}&gt;    Activate Lasers&lt;/button&gt;</code></pre><h2 id="6-1-Toggle"><a href="#6-1-Toggle" class="headerlink" title="6.1 Toggle"></a>6.1 Toggle</h2><pre><code>class Toggle extends React.Component {    constructor(props) {    super(props);    this.state = {isToggleOn: true};    // This binding is necessary to make `this` work in the callback    this.handleClick = this.handleClick.bind(this);    }    handleClick() {        this.setState(prevState =&gt; ({            isToggleOn: !prevState.isToggleOn        }));    }    render() {        return (        // &lt;button onClick={(e) =&gt; this.handleClick(e)}&gt;         // 问题L每次渲染的时候都会创建一个不同的回调函数            &lt;button onClick={this.handleClick}&gt;                {this.state.isToggleOn ? &apos;ON&apos; : &apos;OFF&apos;}            &lt;/button&gt;        );    }}ReactDOM.render(    &lt;Toggle /&gt;,    document.getElementById(&apos;root&apos;));</code></pre><p>必须谨慎对待JSX回调函数中的this，类的方法默认不会绑定this的。如果你忘记绑定 <code>this.handleClick</code> 并把它传入 <code>onClick</code>, 当你调用这个函数的时候 <code>this</code> 的值会是 <code>undefined</code>。</p><h2 id="6-2-Todolist"><a href="#6-2-Todolist" class="headerlink" title="6.2 Todolist"></a>6.2 Todolist</h2><pre><code>class TodoApp extends React.Component {    constructor(props) {        super(props);        this.state = { items: [], text: &apos;&apos; };        this.handleChange = this.handleChange.bind(this);        this.handleSubmit = this.handleSubmit.bind(this);    }    render() {        return (            &lt;div&gt;                &lt;h3&gt;TODO&lt;/h3&gt;                &lt;TodoList items={this.state.items} /&gt;                &lt;form onSubmit={this.handleSubmit}&gt;                  &lt;input                    onChange={this.handleChange}                    value={this.state.text}                  /&gt;                  &lt;button&gt;                    Add #{this.state.items.length + 1}                  &lt;/button&gt;                &lt;/form&gt;            &lt;/div&gt;        );    }    handleChange(e) {        this.setState({ text: e.target.value });    }    handleSubmit(e) {        e.preventDefault();        if (!this.state.text.length) {            return;        }        const newItem = {            text: this.state.text,            id: Date.now()        };        this.setState(prevState =&gt; ({            items: prevState.items.concat(newItem),            text: &apos;&apos;        }));    }}class TodoList extends React.Component {    render() {        return (            &lt;ul&gt;                {this.props.items.map(item =&gt; (                  &lt;li key={item.id}&gt;{item.text}&lt;/li&gt;                ))}            &lt;/ul&gt;        );    }}ReactDOM.render(&lt;TodoApp /&gt;, mountNode);</code></pre><h2 id="6-3-向事件处理程序传递参数"><a href="#6-3-向事件处理程序传递参数" class="headerlink" title="6.3 向事件处理程序传递参数"></a>6.3 向事件处理程序传递参数</h2><pre><code>&lt;button onClick={(e) =&gt; this.deleteRow(id, e)}&gt;Delete Row&lt;/button&gt;&lt;button onClick={this.deleteRow.bind(this, id)}&gt;Delete Row&lt;/button&gt;</code></pre><p>参数 e 作为 React 事件对象将会被作为第二个参数进行传递。通过箭头函数的方式，事件对象必须显式的进行传递，但是通过 bind 的方式，事件对象以及更多的参数将会被隐式的进行传递。</p><h2 id="6-4-bind-向监听函数传参，-事件对象e需要放在最后"><a href="#6-4-bind-向监听函数传参，-事件对象e需要放在最后" class="headerlink" title="6.4 bind 向监听函数传参， 事件对象e需要放在最后"></a>6.4 bind 向监听函数传参， 事件对象e需要放在最后</h2><pre><code>class Popper extends React.Component{    constructor(){        super();        this.state = {name:&apos;Hello world!&apos;};    }    preventPop(name, e){    //事件对象e要放在最后        e.preventDefault();        alert(name);    }    render(){        return (            &lt;div&gt;                &lt;p&gt;hello&lt;/p&gt;                {/* Pass params via bind() method. */}                &lt;a href=&quot;https://reactjs.org&quot; onClick={this.preventPop.bind(this,this.state.name)}&gt;Click&lt;/a&gt;            &lt;/div&gt;        );    }}</code></pre><h1 id="7-条件渲染"><a href="#7-条件渲染" class="headerlink" title="7. 条件渲染"></a>7. 条件渲染</h1><p>可以创建不同的组件来封装各种你需要的行为。然后根据应用的状态变化只渲染其中的一部分。(if)</p><pre><code>function Greeting(props) {    const isLoggedIn = props.isLoggedIn;    if (isLoggedIn) {        return &lt;UserGreeting /&gt;;    }    return &lt;GuestGreeting /&gt;;}ReactDOM.render(  // Try changing to isLoggedIn={true}:  &lt;Greeting isLoggedIn={false} /&gt;,  document.getElementById(&apos;root&apos;));</code></pre><h2 id="7-1-与运算符-amp-amp"><a href="#7-1-与运算符-amp-amp" class="headerlink" title="7.1 与运算符 &amp;&amp;"></a>7.1 与运算符 &amp;&amp;</h2><pre><code>function Mailbox(props) {    const unreadMessages = props.unreadMessages;    return (        &lt;div&gt;          &lt;h1&gt;Hello!&lt;/h1&gt;          {unreadMessages.length &gt; 0 &amp;&amp;            &lt;h2&gt;              You have {unreadMessages.length} unread messages.            &lt;/h2&gt;          }        &lt;/div&gt;    );}const messages = [&apos;React&apos;, &apos;Re: React&apos;, &apos;Re:Re: React&apos;];ReactDOM.render(  &lt;Mailbox unreadMessages={messages} /&gt;,  document.getElementById(&apos;root&apos;));</code></pre><p><strong>在 JavaScript 中，true &amp;&amp; expression 总是返回 expression，而 false &amp;&amp; expression 总是返回 false。</strong></p><h2 id="7-2-阻止组件渲染"><a href="#7-2-阻止组件渲染" class="headerlink" title="7.2 阻止组件渲染"></a>7.2 阻止组件渲染</h2><pre><code>function WarningBanner(props) {    if (!props.warn) {        return null;    }    return (        &lt;div className=&quot;warning&quot;&gt;            Warning!        &lt;/div&gt;    );}class Page extends React.Component {    constructor(props) {        super(props);        this.state = {showWarning: true}        this.handleToggleClick = this.handleToggleClick.bind(this);    }    handleToggleClick() {        this.setState(prevState =&gt; ({            showWarning: !prevState.showWarning        }));    }    render() {        return (            &lt;div&gt;                &lt;WarningBanner warn={this.state.showWarning} /&gt;                &lt;button onClick={this.handleToggleClick}&gt;                {this.state.showWarning ? &apos;Hide&apos; : &apos;Show&apos;}                &lt;/button&gt;            &lt;/div&gt;        );    }}ReactDOM.render(  &lt;Page /&gt;,  document.getElementById(&apos;root&apos;));</code></pre><h1 id="8-列表-amp-Keys"><a href="#8-列表-amp-Keys" class="headerlink" title="8. 列表 &amp; Keys"></a>8. 列表 &amp; Keys</h1><h2 id="8-1-渲染多个组件"><a href="#8-1-渲染多个组件" class="headerlink" title="8.1 渲染多个组件"></a>8.1 渲染多个组件</h2><pre><code>const numbers = [1, 2, 3, 4, 5];const listItems = numbers.map(    (number) =&gt; &lt;li&gt;{number}&lt;/li&gt;);ReactDOM.render(    &lt;ul&gt;{listItems}&lt;/ul&gt;    documnet.getElementById(&apos;root&apos;));</code></pre><h2 id="8-2-基础列表组件"><a href="#8-2-基础列表组件" class="headerlink" title="8.2 基础列表组件"></a>8.2 基础列表组件</h2><pre><code>function NumberList(props) {    const numbers = props.numbers;    const listItems = numbers.map((number) =&gt;        &lt;li key={number.toString()}&gt;            {number}        &lt;/li&gt;    );    return (        &lt;ul&gt;{listItems}&lt;/ul&gt;    );}const numbers = [1, 2, 3, 4, 5];ReactDOM.render(  &lt;NumberList numbers={numbers} /&gt;,  document.getElementById(&apos;root&apos;));</code></pre><h2 id="8-3-Keys"><a href="#8-3-Keys" class="headerlink" title="8.3 Keys"></a>8.3 Keys</h2><p>Keys可以在DOM中的某些元素被增加或删除的时候帮助React识别哪些元素发生了变化。最好是该元素在列表中拥有的独一无二的字符串。使用来自数据的id作为元素的key</p><p>元素的key只有在它和它的兄弟节点对比时才有意义。</p><h1 id="9-表单"><a href="#9-表单" class="headerlink" title="9.表单"></a>9.表单</h1><p>HTML 表单元素与React中其他DOM元素有所不同，因为表单元素本来就保留一些内部状态了。会构造一个处理提交表单并可访问用户输入表单数据的函数。标准方法是使用受控组件。</p><h2 id="9-1-受控组件"><a href="#9-1-受控组件" class="headerlink" title="9.1 受控组件"></a>9.1 受控组件</h2><p>在HTML当中，像<code>&lt;input&gt;,&lt;textarea&gt;, 和 &lt;select&gt;</code>这类表单元素会维持自身状态，并根据用户输入进行更新。但在React中，可变的状态通常保存在组件的状态属性中，并且只能用 setState() 方法进行更新。</p><pre><code>class NameForm extends React.Component {    constructor(props) {        super(props);        this.state = {value: &apos;&apos;};        this.handleChange = this.handleChange.bind(this);        this.handleSubmit = this.handleSubmit.bind(this);    }    handleChange(event) {        this.setState({value: event.target.value});    }    handleSubmit(event) {        alert(&apos;A name was submitted: &apos; + this.state.value);        event.preventDefault();    }    render() {        return (            &lt;form onSubmit={this.handleSubmit}&gt;                &lt;label&gt;                  Name:                  &lt;input type=&quot;text&quot; value={this.state.value} onChange={this.handleChange} /&gt;                &lt;/label&gt;                &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;            &lt;/form&gt;        );    }}</code></pre><h2 id="9-2-textarea标签"><a href="#9-2-textarea标签" class="headerlink" title="9.2 textarea标签"></a>9.2 textarea标签</h2><pre><code>class EssayForm extends React.Component {    constructor(props) {        super(props);        this.state = {          value: &apos;Please write an essay about your favorite DOM element.&apos;        };        this.handleChange = this.handleChange.bind(this);        this.handleSubmit = this.handleSubmit.bind(this);    }    handleChange(event) {        this.setState({value: event.target.value});    }    handleSubmit(event) {        alert(&apos;An essay was submitted: &apos; + this.state.value);        event.preventDefault();    }    render() {        return (            &lt;form onSubmit={this.handleSubmit}&gt;                &lt;label&gt;                Name:                &lt;textarea value={this.state.value} onChange={this.handleChange} /&gt;                &lt;/label&gt;                &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;            &lt;/form&gt;        );    }}</code></pre><h2 id="9-3-select标签"><a href="#9-3-select标签" class="headerlink" title="9.3 select标签"></a>9.3 select标签</h2><p>React中，不适用selected属性表明选中项，而是在根select标签上用value属性来表示选中项。这在受控组件中更方便，因为只需要在一个地方更新组件。</p><pre><code>class FlavorForm extends React.Component {    constructor(props) {    super(props);    this.state = {value: &apos;coconut&apos;};    this.handleChange = this.handleChange.bind(this);    this.handleSubmit = this.handleSubmit.bind(this);}handleChange(event) {    this.setState({value: event.target.value});}handleSubmit(event) {    alert(&apos;Your favorite flavor is: &apos; + this.state.value);    event.preventDefault();}    render() {        return (            &lt;form onSubmit={this.handleSubmit}&gt;                &lt;label&gt;                    Pick your favorite La Croix flavor:                    &lt;select value={this.state.value} onChange={this.handleChange}&gt;                    &lt;option value=&quot;grapefruit&quot;&gt;Grapefruit&lt;/option&gt;                    &lt;option value=&quot;lime&quot;&gt;Lime&lt;/option&gt;                    &lt;option value=&quot;coconut&quot;&gt;Coconut&lt;/option&gt;                    &lt;option value=&quot;mango&quot;&gt;Mango&lt;/option&gt;                    &lt;/select&gt;                &lt;/label&gt;                &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;            &lt;/form&gt;        );    }}</code></pre><h2 id="9-4-多个输入的解决方法"><a href="#9-4-多个输入的解决方法" class="headerlink" title="9.4 多个输入的解决方法"></a>9.4 多个输入的解决方法</h2><p>通过给每个元素添加一个name属性，来让处理函数根据event.target.name的值来选择做什么</p><pre><code>class Reservation extends React.Component {    constructor(props) {        super(props);        this.state = {            isGoing: true,            numberOfGuests: 2        };        this.handleInputChange = this.handleInputChange.bind(this);    }    handleInputChange(event) {        const target = event.target;        const value = target.type === &apos;checkbox&apos; ? target.checked : target.value;        const name = target.name;        this.setState({            [name]: value        });    }    render() {        return (            &lt;form&gt;                &lt;label&gt;                    Is going:                    &lt;input                        name=&quot;isGoing&quot;                        type=&quot;checkbox&quot;                        checked={this.state.isGoing}                        onChange={this.handleInputChange} /&gt;                &lt;/label&gt;                &lt;br /&gt;                &lt;label&gt;                    Number of guests:                    &lt;input                        name=&quot;numberOfGuests&quot;                        type=&quot;number&quot;                        value={this.state.numberOfGuests}                        onChange={this.handleInputChange} /&gt;                &lt;/label&gt;            &lt;/form&gt;        );    }}</code></pre><h1 id="10-状态提升"><a href="#10-状态提升" class="headerlink" title="10. 状态提升"></a>10. 状态提升</h1><h2 id="10-1-摄氏度华氏度的例子"><a href="#10-1-摄氏度华氏度的例子" class="headerlink" title="10.1 摄氏度华氏度的例子"></a>10.1 摄氏度华氏度的例子</h2><p>状态分享是通过将state数据提升至离需要这些数据的组件最近的父组件来完成的</p><pre><code>class Calculator extends React.Component {    constructor(props) {        super(props);        this.handleCelsiusChange = this.handleCelsiusChange.bind(this);        this.handleFahrenheitChange = this.handleFahrenheitChange.bind(this);        this.state = {temperature: &apos;&apos;, scale: &apos;c&apos;};    }    handleCelsiusChange(temperature) {        this.setState({scale: &apos;c&apos;, temperature});    }    handleFahrenheitChange(temperature) {        this.setState({scale: &apos;f&apos;, temperature});    }    render() {        const scale = this.state.scale;        const temperature = this.state.temperature;        const celsius = scale === &apos;f&apos; ? tryConvert(temperature, toCelsius) : temperature;        const fahrenheit = scale === &apos;c&apos; ? tryConvert(temperature, toFahrenheit) : temperature;        return (          &lt;div&gt;            &lt;TemperatureInput              scale=&quot;c&quot;              temperature={celsius}              onTemperatureChange={this.handleCelsiusChange} /&gt;            &lt;TemperatureInput              scale=&quot;f&quot;              temperature={fahrenheit}              onTemperatureChange={this.handleFahrenheitChange} /&gt;            &lt;BoilingVerdict              celsius={parseFloat(celsius)} /&gt;          &lt;/div&gt;        );    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二战时间线</title>
      <link href="/%E4%BA%8C%E6%88%98%E6%97%B6%E9%97%B4%E7%BA%BF/"/>
      <url>/%E4%BA%8C%E6%88%98%E6%97%B6%E9%97%B4%E7%BA%BF/</url>
      
        <content type="html"><![CDATA[<!--toc--><blockquote><p>对二战很感兴趣，依旧在不断了解中。未了解前完全没想到在不到80年前，我们这个世界因为战争在短短十多年间死去了7000万人。中间有太多的泯灭人性，亦有很多人性的光辉。不知道列宁格勒，如今的圣彼得堡的居民，在两年半的被围城中是如何活下来的，每个人，都真的是挺直了腰背，这一刻，尊严比命重要。有太多的细节可以探寻，也有很多微妙的节点，好多次盟军的胜利是因为一些不期而遇的变化，小人物的选择，天气的突然放晴。每每读到这种时候，心里总会长舒一口气，庆幸啊。（PS: 有部美剧，就特地开了脑洞，讲二战轴心国胜利以后的世界的样子… 一个真的敢拍，一个真的敢播，hhh ）Anyway，铭记历史~ </p></blockquote><h1 id="时间线（欧洲战场-and-太平洋战场）"><a href="#时间线（欧洲战场-and-太平洋战场）" class="headerlink" title="时间线（欧洲战场 and 太平洋战场）"></a>时间线（欧洲战场 and 太平洋战场）</h1><p>二战整个过程，德国东征波兰，北伐北欧、西吞法国、南并巴尔干，在欧洲大陆上大杀四方，无人可挡。但到了第二阶段，苏联以强大的力量阻遏了德国的闪电攻势，而年底日本对美国的偷袭更将可怕的敌人拉入了战争。在第三阶段，同盟国在太平洋战场、北非战场、东线战场相继赢得转折点性质的胜利。在第四阶段，扫清了北非的盟军开始进攻西欧大陆，苏联在东面的战场大举反攻。到第五阶段，轴心国崩溃，德国、日本相继投降（意大利早在上一阶段就已投降），战争结束。</p><h2 id="1939-1940"><a href="#1939-1940" class="headerlink" title="1939 - 1940"></a>1939 - 1940</h2><ul><li>1939.9 </li></ul><p>德国进攻波兰，闪电战，波兰迅速崩溃。波兰盟友英法向德国宣战，却没有采取大规模行动，形成了西线无战事的奇怪的战争。与德国签订有《德苏互不侵犯条约》的苏联更是趁机从东面入侵了波兰，一个月，战争结束，波兰被德苏两国瓜分。</p><ul><li>1930.11</li></ul><p>苏联入侵芬兰，在芬兰人的抵抗下，苏联损失惨重。两方面原因，芬兰人英勇抵抗，苏联在大清洗中洗掉了大量的优秀军官。最终苏联惨胜，签订《莫斯科和平协定》。</p><ul><li>1940.5 </li></ul><p>德国德国兵锋西指，几天内就攻陷了荷兰和比利时，驻守在<strong><em>马其诺防线</em></strong>北侧的英军、法军北上迎击，这落入了曼施坦因的圈套，德军出其不意地从<strong>阿登山区</strong>突入，“闪击战之父”古德里安率领坦克部队果断前进，切入到盟军侧背，形成围歼之势。盟军被迫在敦刻尔克乘英国的大小船只撤退到英国，这就是代号为“发电机行动”的敦刻尔克大撤退。无力抵抗的法国在德军的继续进攻下被迫投降，一部分国土被德国和意大利占领，另一部分国土则由贝当的“维希法国”管理。戴高乐在伦敦发表演说，不承认维希法国的合法性，组织自由法国继续抗争。几乎与此同时，苏联吞并了位于波罗的海的三个国家——爱沙尼亚、拉脱维亚和立陶宛。</p><ul><li>1940.8</li></ul><p>攻占法国后，希特勒开始着眼于英国，制定了“海狮计划”准备登陆英国。为了争夺登陆作战的制空权，德国空军从8月份开始对英国的空中攻势，英国军民在丘吉尔的领导下奋勇抵抗 —— 不列颠空战。1941年不列颠空战中，英国取得了最终胜利。</p><ul><li>1940.9</li></ul><p>利比亚的意大利军队入侵埃及，而后被英军击败并在12月反推至利比亚。10月，意大利入侵希腊，却迅速失败反而被希腊军队反推到阿尔巴尼亚。德国被迫卷入战争，入侵南斯拉夫和希腊。经过一系列战役后，巴尔干半岛上的战争最终以轴心国的胜利结束，整个巴尔干半岛都落入了轴心国的掌控之内。希特勒在次年又将隆美尔派往北非营救意大利。隆美尔取得了一系列胜利，赢得了“沙漠之狐”的美誉。轴心国在地中海、北非战场取得了一定进展，但德军因此推迟了入侵苏联的时间，希特勒后来为之懊恼不已。</p><h2 id="1941"><a href="#1941" class="headerlink" title="1941"></a>1941</h2><ul><li>1941.6</li></ul><p>德国巴巴罗萨行动，三路大军入侵苏联。北方集团军群攻占波罗的海三国，保卫列宁格勒，列宁格勒保卫战开始。中央集团军攻克斯摩棱斯克，直指莫斯科。南方军团在基辅大胜苏军，完成了历史上最大规模的歼灭战。</p><ul><li>1941.7</li></ul><p>英美冻结日本的资产，美国对日本实施了石油禁运政策，釜底抽薪之策啊。</p><ul><li>1941.12</li></ul><p>日本在太平洋上对英美发起了进攻。山本五十六偷袭珍珠港（12.7），美国从孤立主义转向参战。美国总统罗斯福对日本宣战，半年内日军依旧在太平洋战场占据优势。德军潜艇部队在邓尼茨的指挥下，运用狼群战术，对盟军航运船只造成了巨大的伤害。 </p><h2 id="1942"><a href="#1942" class="headerlink" title="1942"></a>1942</h2><ul><li>1942.5 </li></ul><p>太平洋珊瑚海，日军对抗盟军航母，日军航母祥凤号被击沉，翔鹤号受到重创，瑞鹤号飞机损耗严重。美军航母列星顿号沉没，约克城号受伤。这是日本在太平洋战场上的扩张势头第一次受到阻遏，盟军保住了美国到澳大利亚间的交通线。</p><ul><li>1942.6 </li></ul><p>中途岛海战爆发。酷炫的圈套和反圈套作战，最终日军四艘航母全沉没了。此战后，日军在太平洋战场上的优势不复存在。</p><ul><li>1942.5-6</li></ul><p>北非战场，“沙漠之狐”隆美尔率领轴心国军队在加查拉战役中战胜了奥金莱克指挥的盟军，盟军向东退守阿拉曼防线。7月，隆美尔进攻阿拉曼防线，奥金莱克率军抵抗，两军打成了消耗战。8月，奥金莱克的指挥职务被蒙哥马利取代。10月，第二次阿拉曼战役打响，在拥有制空权和后勤方面的优势条件下，蒙哥马利击败了隆美尔，一路追到了突尼斯。</p><ul><li>1942.7</li></ul><p>斯大林格勒战役打响，德军攻入了斯大林格勒，但是与苏军展开巷战，遭到英勇抵抗。11月，天王星计划，完成了反包围。德军在整个战争过程中第一个大规模失败，被俘90，000余人。转折点，盟军进入战略反攻阶段。</p><h2 id="1943"><a href="#1943" class="headerlink" title="1943"></a>1943</h2><ul><li>1942.11 </li></ul><p>北非火炬行动，在阿尔及利亚和摩洛哥登陆后，向突尼斯的轴心国军队进攻。到1943年5月，在实力雄厚的盟军的两面夹击之下，轴心国的部队完全失败，除了一部分逃走外，全部向盟军投降。至此盟军取得了在北非战场上的全面胜利，他们可以把目光投向地中海对面的意大利了。</p><ul><li>1943.7 </li></ul><p>盟军进攻西西里岛，取得胜利。</p><p>东线，德军元帅曼施坦因对阵苏军元帅朱可夫。曼施坦因想用钳形攻势攻击突出的库尔斯克地区，却被朱可夫抵挡住。战争发展成了历史上规模最大的坦克大会战，苏联人的损失比德国更大，但他们能承受这些。最后，由于盟军在西西里岛的入侵，希特勒急需从东线抽调兵力，曼施坦因被迫撤退。从此苏联人开始大规模收复失地，德国人节节败退。</p><ul><li>1943.9</li></ul><p>盟军入侵意大利本土，墨索里尼下台，意大利政府投降。</p><ul><li>1943.11</li></ul><p>开罗会议 - 英美中</p><p>德黑兰会议 - 苏美英  商讨进攻轴心国的战略和战后的安排</p><h1 id="1944-1945"><a href="#1944-1945" class="headerlink" title="1944 - 1945"></a>1944 - 1945</h1><ul><li>1944.1 </li></ul><p>长达两年四个月的列宁格勒围城战终于结束了。苏联法功十次斯大林突进。到年底，收回了全部领土，更控制了东欧大部分国家。</p><ul><li>1944.6</li></ul><p>盟军霸王行动，诺曼底登陆，三百万士兵横渡英吉利海峡。巴顿将军率部横扫法兰西。8月，法国解放。</p><ul><li>1944.12</li></ul><p>12月，德国进行最后的挣扎，在阿登地区向盟军发动攻势，莫德尔成功地在布莱德利的防线上打出了一个“突出部”，所以这场战役被称为突出部战役。德军将小股盟军包围在巴斯托尼。在守军即将崩溃的时候，天气放晴，盟军的空军优势得以发挥，他们对德军进行了猛烈的轰炸，并将物资空投到巴斯托尼。巴顿的援军迅速北上，德军大势已去。希特勒终于同意了莫德尔的撤军请求，他的孤注一掷失败了。</p><ul><li>1945.2 </li></ul><p>雅尔塔会议 —— 苏美英</p><ul><li>1945.4</li></ul><p>朱可夫率领苏军攻占柏林，占领国会大厦，希特勒自杀。</p><p>太平洋战场，盟军在麦克阿瑟的率领下，用蛙跳式跃岛战术。冲绳岛作战。</p><ul><li>1945.7 </li></ul><p>波茨坦会议 —— 苏美英，商讨战后欧洲问题及对日本作战的问题</p><ul><li>1945.8 </li></ul><p>广岛长崎原子弹</p><p>苏联红军攻进中国东北，击溃关东军。</p><p>日本宣布接收《波茨坦公告》公告，无条件投降。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
            <tag> world war </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读懂财报</title>
      <link href="/%E8%AF%BB%E6%87%82%E8%B4%A2%E6%8A%A5/"/>
      <url>/%E8%AF%BB%E6%87%82%E8%B4%A2%E6%8A%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="1-资产负债表"><a href="#1-资产负债表" class="headerlink" title="1 资产负债表"></a>1 资产负债表</h1><h2 id="1-1-资产负债表-分类"><a href="#1-1-资产负债表-分类" class="headerlink" title="1.1 资产负债表 分类"></a>1.1 资产负债表 分类</h2><p>企业需要做三张报表，分别是</p><ul><li>资产负债表</li><li>利润表</li><li>现金流</li></ul><h2 id="1-2-财务报表是用来做什么的？"><a href="#1-2-财务报表是用来做什么的？" class="headerlink" title="1.2 财务报表是用来做什么的？"></a>1.2 财务报表是用来做什么的？</h2><p>企业从事的经营活动的种类有：</p><ul><li>经营活动</li></ul><p>比如一个企业需要生产产品、销售产品、回收货款等等</p><ul><li>投资活动</li></ul><p>如果一个企业想要到一个新的地区去开展业务，想进入一个新的业务领域，或者想设计生产一个新的产品</p><ul><li>融资活动</li></ul><p>在经营和投资的过程中，当缺钱了的时候，需要去银行借钱，或者找别人来投资自己</p><p>可以这样子说，企业一辈子只做这三件事，经营，投资以及融资。在这整个过程中，无论其处在什么发展阶段，其日常经济活动都可以抽象成这样一个过程，从现金开始，转了一圈再搞到现金的过程。</p><h2 id="1-3-资产负债表详解"><a href="#1-3-资产负债表详解" class="headerlink" title="1.3 资产负债表详解"></a>1.3 资产负债表详解</h2><p>分为如下几个部分： </p><ul><li>资产 - 流动资产</li><li>资产 - 非流动资产</li><li>负债 - 流动负债</li><li>负债 - 非流动负债</li><li>股东权益</li></ul><h3 id="1-3-1-流动资产"><a href="#1-3-1-流动资产" class="headerlink" title="1.3.1 流动资产"></a>1.3.1 流动资产</h3><ul><li>货币资金</li></ul><p>放在银行里面或者放在公司里面的钱。包括库存现金，银行贷款，和其他货币资金三个项目的期末余额。</p><ul><li>应收账款</li></ul><p>销售产品的时候，发生的卖掉产品但是收不到钱的情况。<br>即需要核算的企业因为销售商品、提供劳务等经营活动应收取的款项。</p><ul><li>其他应收款</li></ul><p>企业除了存出保证金（租房子时交付的未来将退回的保证金、押金等）、买入返售的金融资产、应收票据、应收账款、预付账款、应收股利、应收利息、应收代位追偿款、应收分保账款、应收分包合同准备金、长期应收款等以外的其他各种应收及暂付款项。</p><ul><li>预付账款</li></ul><p>基本发生在货品很紧缺，带了一种向卖方收款的权利。预付账款也是一种资产。</p><ul><li>存货</li></ul><p>生产产品所需的原材料，生产出来的产成品，以及尚且处在生产过程中的没有完成的在产品</p><ul><li>待摊费用</li></ul><p>资产 vs 费用。 如果这笔钱可以换来对将来有用的东西，就是资产。如果画完就完了，就是费用。</p><p>各项流动资产在资产负债表中是按照<strong>各自转换为现金的速度</strong>来排序的。</p><h3 id="1-3-2-非流动资产"><a href="#1-3-2-非流动资产" class="headerlink" title="1.3.2 非流动资产"></a>1.3.2 非流动资产</h3><p>返回现金的时间长度，无法在一个循环内完成的。</p><ul><li>长期投资</li></ul><p>指不满足短期投资条件的投资，即不准备在一年或长于一年的经营周期之内转变为现金的投资。可以分为长期股票投资，长期债券投资，其他长期投资</p><ul><li>固定资产</li></ul><p>指同时具有以下特征的有形资产： （1）为生产商品、提供劳务、出租或经营管理而持有的； （2）使用寿命超过了一个会计年度</p><ul><li>无形资产</li></ul><p>专利权，版权等，还有土地使用权</p><p>指企业拥有或者控制的没有实物形态的可辨认的非货币性的资产。包括专利权、非专利技术、商标权、著作权、土地使用权等。</p><h3 id="1-3-3-资产-gt-企业"><a href="#1-3-3-资产-gt-企业" class="headerlink" title="1.3.3 资产 -&gt; 企业"></a>1.3.3 资产 -&gt; 企业</h3><p> 固定资产多，应收账款多，可能是有经营压力的传统企业</p><p> 生物资产，指有生命的动物和植物，生物资产分为消耗性生物资产，生产性生物资产和公益性生物资产。</p><p> 资产的结构会告诉你这家公司是什么样子的。 </p><h3 id="1-3-4-资产如何计价？"><a href="#1-3-4-资产如何计价？" class="headerlink" title="1.3.4 资产如何计价？"></a>1.3.4 资产如何计价？</h3><p> 会计们会用原来购买的资产价格当做这个资产的价值。</p><blockquote><p>历史成本</p></blockquote><blockquote><p>资产在其取得时为其所支付的现金或现金等价物的金额。负债在正常经营活动中为交换而收到或为偿付将要支付的现金或现金等价物的金额。</p></blockquote><blockquote><p>Bug: 历史成本无法体现出资产的变化。故解决方案为： 如果资产价值减小了，就把减值记下来。因为资产计价体系是一个历史成本的体系，一定要在历史成本的基础上扣除这个资产的减值。 </p></blockquote><ul><li>历史成本的含义</li></ul><ol><li>只有花了的钱才能记在账上。</li><li>在历史成本的计价体系下，增加资产价值的唯一途径是发生一个新的交易。</li></ol><h3 id="1-3-5-负债"><a href="#1-3-5-负债" class="headerlink" title="1.3.5 负债"></a>1.3.5 负债</h3><blockquote><p>负债：由于过去的交易或事务所引起的公司企业的现有债务，这种债务需要企业在将来以转移资产或提供劳务加以清偿，从而引起未来经济利益的流出。<br>其他：是为了简化，欠员工的工资，因为是月底发钱； 欠税务局的钱。这些都是流动负债。非流动负债： 应付债券。</p></blockquote><blockquote><p>应付债券：企业为了筹集资金而对外发行的期限在一年以上的长期借款性质的书面证明，约定在一定期限内还本付息的一种书面承诺。</p></blockquote><h3 id="1-3-6-股东权益"><a href="#1-3-6-股东权益" class="headerlink" title="1.3.6 股东权益"></a>1.3.6 股东权益</h3><blockquote><p>股东权益： 公司总资产中扣除负债剩余的部分，也成为净资产，反映了公司的自有资本。</p></blockquote><blockquote><p>股本： 股本金额相当于公司的注册资本。股本的总额体现了这个公司对外承担法律责任的上限。股本的组成则确定了多个股东之间的权利义务关系。</p></blockquote><blockquote><p>资本公积： 企业收到的投资者的超出其在企业注册资本所占份额，以及直接计入所有者权益的利得和损失等。</p></blockquote><blockquote><p>股东权益 + 负债 = 资产</p></blockquote><p>注意资产负债表是一个时间点的概念，是状态，不是过程。</p><h1 id="2-利润表"><a href="#2-利润表" class="headerlink" title="2. 利润表"></a>2. 利润表</h1><p>资产负债表： 可以看到投入的本金是否得到保障。利润表，则能得知投入的本金有没有赚钱。</p><p>毛利 = 营业收入 - 营业成本</p><h2 id="2-1-税种"><a href="#2-1-税种" class="headerlink" title="2.1 税种"></a>2.1 税种</h2><ul><li>营业税</li></ul><p>国家对工商营利事业按照营业额征收的税</p><ul><li>营业税金及附加</li></ul><p>企业经营活动应负担的相关税费，包括营业税、消费税、城市维护建设税、资源税、教育费附加等。不是所得税，是流转税，只要是有业务的企业就得缴纳流转税。</p><ul><li>常见的流转税： 营业税（价内税） + 增值税（价外税）</li><li>价内税： 税金包含在商品价值或价格之内</li><li>价外税： 税款不包括在价格内</li><li>增值税： 一种销售税，是消费者承担的税费，属于累退税，是基于商品或服务的增值而增税的一种间接税</li></ul><h2 id="2-2-其他项目"><a href="#2-2-其他项目" class="headerlink" title="2.2 其他项目"></a>2.2 其他项目</h2><ul><li>补贴收入<br>中国特色： 政府为一些企业提供的补贴。</li></ul><h2 id="2-3-利润表的分析"><a href="#2-3-利润表的分析" class="headerlink" title="2.3 利润表的分析"></a>2.3 利润表的分析</h2><p>告诉了是否赚钱，在哪些方面赚钱的基本信息。同时因为将可持续的和不可持续的营业收入分开，就可以帮助企业推断出自己未来一段时间以内的收益。</p>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reading </tag>
            
            <tag> finance </tag>
            
            <tag> stock </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
