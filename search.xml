<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>DynamoDB Architecture (Paper Reading)</title>
      <link href="/DynamoDB-Architecture-Paper-Reading/"/>
      <url>/DynamoDB-Architecture-Paper-Reading/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>Designed to be always on</li><li>Dynamo falls within the category of AP systems (available and partition tolerant) and is designed for high availability and partition tolerance at the expense of strong consistency</li></ul><h2 id="1-1-Design-Goals"><a href="#1-1-Design-Goals" class="headerlink" title="1.1 Design Goals"></a>1.1 Design Goals</h2><ul><li>Scalable<ul><li>System need to be highly scalable. We should be able to throw a machine into the system to see proportional improvement</li></ul></li><li>Decentralized<ul><li>To avoid single points of failures and performance bottlenecks, there should not be any central/ leader process</li></ul></li><li>Eventually Consistent<ul><li>Data can be optimistically replicated to become eventually consistent</li></ul></li></ul><h2 id="1-2-Use-cases"><a href="#1-2-Use-cases" class="headerlink" title="1.2 Use cases"></a>1.2 Use cases</h2><ul><li>eventually consistent database</li></ul><h2 id="1-3-System-APIs"><a href="#1-3-System-APIs" class="headerlink" title="1.3 System APIs"></a>1.3 System APIs</h2><ul><li>put(key, context, object)<ul><li>find the nodes where the object associated with the given key should locate</li><li>context is a value that is returned with a get operation and then sent back with the put operation</li><li>context is always stored along with the object</li><li>used like a cookie to verify the validity of the object supplied in the put request</li></ul></li><li>get(key)<ul><li>find the nodes where the object associated with the given key is located</li><li>return a single object or a list of objects with conflicting versions along with a context</li><li>context contains encoded metadata about the object, and <strong>version of the object</strong></li></ul></li></ul><h1 id="2-High-Level-Design"><a href="#2-High-Level-Design" class="headerlink" title="2. High Level Design"></a>2. High Level Design</h1><h2 id="2-1-Data-Distribution"><a href="#2-1-Data-Distribution" class="headerlink" title="2.1 Data Distribution"></a>2.1 Data Distribution</h2><h3 id="2-1-1-What-is-it"><a href="#2-1-1-What-is-it" class="headerlink" title="2.1.1 What is it"></a>2.1.1 What is it</h3><ul><li>Consistent hashing to distribute its data among nodes</li><li>Also make it easy to add/ remove nodes from a dynamo cluster</li></ul><h3 id="2-1-2-Challenge"><a href="#2-1-2-Challenge" class="headerlink" title="2.1.2 Challenge"></a>2.1.2 Challenge</h3><ul><li>how do we know on which node a particular piece of data will be stored?</li><li>when we add/ remove nodes, how do we know what data will be moved from existing nodes to the new nodes?</li><li>how can we minimize data movement when nodes join or leave?</li></ul><h3 id="2-1-3-Consistent-Hashing"><a href="#2-1-3-Consistent-Hashing" class="headerlink" title="2.1.3 Consistent Hashing"></a>2.1.3 Consistent Hashing</h3><ul><li><p>Represents the data managed by a cluster as a ring</p></li><li><p>Each node in the ring is assigned a range of data</p></li><li><p>Token</p><ul><li><p>The start of the range is called a token</p></li><li><p>each node will be assigned with one token</p><p>  <img src="https://i.loli.net/2021/08/08/8jFPMEDNmn4cXaf.png" alt=""></p></li></ul></li><li><p>Process for a put or get request</p><ul><li>DDB performs a MD5 hashing algorithm to the key</li><li>Output determines within which range the data lies —→ which node the data will be stored</li></ul></li><li><p>Problems for only use physical nodes</p><ul><li>for adding or removing nodes, it only influence the next node, but it would cause uneven distribution of traffic</li><li>recomputing the tokens causing a significant administrative overhead for a large cluster</li><li>Since each node is assigned one large range, if the data is not evenly distributed, some nodes can become hotspots</li><li>Since each node’s data is replicated on a fixed number of nodes (discussed later), when we need to rebuild a node, only its replica nodes can provide the data. This puts a lot of pressure on the replica nodes and can lead to service degradation</li></ul></li></ul><h3 id="2-1-4-Virtual-Nodes"><a href="#2-1-4-Virtual-Nodes" class="headerlink" title="2.1.4 Virtual Nodes"></a>2.1.4 Virtual Nodes</h3><p><img src="https://i.loli.net/2021/08/08/YWwxt9eMmToQ3qn.png" alt=""></p><ul><li><p>Hash range is divided into multiple smaller ranges, and each physical node is assigned multiple of these smaller ranges</p></li><li><p>Each of these subranges is called a Vnode</p></li><li><p>Vnodes are randomly distributed across the cluster and are generally non contiguous (不连续的)</p><p>  <img src="https://i.loli.net/2021/08/08/RVgrPm8T19nbKZB.png" alt=""></p></li><li><p>Benefits of Vnodes</p><ul><li>Help spread the load more evenly across the physical nodes on the cluster by dividing the hash range into smaller subranges<ul><li>speeds up the rebalancing process after adding or removing nodes</li><li>When a new node is added, it receives many Vnodes from the existing nodes to maintain a balanced cluster. Similarly, when a node needs to be rebuilt, instead of getting data from a fixed number of replicas, many nodes participate in the rebuild process.</li></ul></li><li>Vnodes make it easier to maintain a cluster containing heterogeneous machines. This means, with Vnodes, we can assign a high number of ranges to a powerful server and a lower number of ranges to a less powerful server</li><li>Since Vnodes help assign smaller ranges to each physical node, the probability of hotspots is much less than the basic Consistent Hashing scheme which uses one big range per node</li></ul></li></ul><h2 id="2-2-Data-Replication-and-Consistency"><a href="#2-2-Data-Replication-and-Consistency" class="headerlink" title="2.2 Data Replication and Consistency"></a>2.2 Data Replication and Consistency</h2><ul><li>Data is replicated optimistically</li><li>Dynamo provides eventual consistency</li></ul><h3 id="2-2-1-Optimistic-Replication"><a href="#2-2-1-Optimistic-Replication" class="headerlink" title="2.2.1 Optimistic Replication"></a>2.2.1 Optimistic Replication</h3><ul><li><p>To ensure high availability and durability, Dynamo replicates each data item on multiple N nodes in the system where the value N is equivalent to the <strong>replication factor</strong>, also is configured per instance of Dynamo</p></li><li><p>Each key is assigned to a coordinator node, which first stores the data locally and then replicates it to N-1 clockwise successor nodes on the ring</p><ul><li>Thus each node owns the region on the ring between it and its Nth predecessor</li></ul></li><li><p>Replication is done asynchronously and Dynamo provides an eventually consistent model</p></li><li><p>It’s called optimistic replication, as the replicas are not guaranteed to be identical at all times</p><p>  <img src="https://i.loli.net/2021/08/08/QaHhmPTI6XcYfwu.png" alt=""></p></li><li><p>Preference List</p><ul><li>List of nodes responsible for storing a particular key</li><li>Dynamo is designed so that every node in the system can determine which nodes should be in the list for any specific key</li><li>The list contains more than N nodes to account for failures and skip virtual nodes on the ring so that the list only contains distinct physical nodes</li></ul></li></ul><h2 id="2-3-Handling-Temporary-Failures"><a href="#2-3-Handling-Temporary-Failures" class="headerlink" title="2.3 Handling Temporary Failures"></a>2.3 Handling Temporary Failures</h2><ul><li>To handle temporary failures, dynamo replicates data to a <strong>sloppy quorum</strong> of other nodes in the system instead of a strict majority quorum</li></ul><h3 id="2-3-1-Quorum-Approach"><a href="#2-3-1-Quorum-Approach" class="headerlink" title="2.3.1 Quorum Approach"></a>2.3.1 Quorum Approach</h3><ul><li>Traditional quorum approach<ul><li>any distributed system becomes unavailable during server failures or network partitions and would have reduced availability even under simple failure conditions</li></ul></li><li>Sloppy quorum<ul><li>all read/ write operations are performed on the first N healthy nodes from the preference list. may not always be the first N nodes encountered while moving clockwise on the consistent hashing ring</li></ul></li></ul><h3 id="2-3-2-Hinted-Handoff"><a href="#2-3-2-Hinted-Handoff" class="headerlink" title="2.3.2 Hinted Handoff"></a>2.3.2 Hinted Handoff</h3><ul><li>When a node is unreachable, another node can accept writes on its behalf</li><li>Write is then kept in a local buffer and sent out once the destination node is reachable again</li><li>Problem<ul><li>Sloppy quorum is not a strict majority, the data can and will diverge</li><li>It is possible for two concurrent writes to the same key to be accepted by non-overlapping sets of nodes. This means that multiple conflicting values against the same key can exist in the system, and we can get stale or conflicting data while reading. Dynamo allows this and resolves these conflicts using Vector Clocks.</li></ul></li></ul><h2 id="2-4-Inter-node-communication-and-failure-detection"><a href="#2-4-Inter-node-communication-and-failure-detection" class="headerlink" title="2.4 Inter node communication and failure detection"></a>2.4 Inter node communication and failure detection</h2><ul><li>Use gossip protocol to keep track of the cluster state</li></ul><h3 id="2-4-1-Gossip-Protocol"><a href="#2-4-1-Gossip-Protocol" class="headerlink" title="2.4.1 Gossip Protocol"></a>2.4.1 Gossip Protocol</h3><ul><li><p>Enable each node to keep track of state information about the other nodes in the cluster</p><ul><li>which nodes are reachable</li><li>what key ranges they are responsible for</li></ul></li><li><p>Gossip Protocol</p><ul><li><p>Peer to peer communication mechanism</p></li><li><p>nodes periodically exchange state information about themselves and other nodes they know about</p></li><li><p>each node initiate a gossip round every second with a random node</p><p>  <img src="https://i.loli.net/2021/08/08/hgBPER5e2kuxvMw.png" alt=""></p></li></ul></li><li><p>External discovery through seed nodes</p><ul><li>An administrator joins node A to the ring and then joins node B to the ring. Nodes A and B consider themselves part of the ring, yet neither would be immediately aware of each other. To prevent these logical partitions, Dynamo introduced the concept of seed nodes. Seed nodes are fully functional nodes and can be obtained either from a static configuration or a configuration service. This way, all nodes are aware of seed nodes. Each node communicates with seed nodes through gossip protocol to reconcile membership changes; therefore, logical partitions are highly unlikely.</li></ul></li></ul><h2 id="2-5-Conflict-Resolution-and-Handling-permanent-failures"><a href="#2-5-Conflict-Resolution-and-Handling-permanent-failures" class="headerlink" title="2.5 Conflict Resolution and Handling permanent failures"></a>2.5 Conflict Resolution and Handling permanent failures</h2><h3 id="2-5-1-Clock-Skew"><a href="#2-5-1-Clock-Skew" class="headerlink" title="2.5.1 Clock Skew"></a>2.5.1 Clock Skew</h3><ul><li>Dynamo resolves potential conflicts using below mechanisms<ul><li>use vector clocks to keep track of value history and reconcile divergent histories at read time</li><li>in the background, dynamo use an <strong>anti entropy mechanism</strong> like <strong>Merkle trees</strong> to handle permanent failures</li></ul></li></ul><h3 id="2-5-2-Vector-Clock"><a href="#2-5-2-Vector-Clock" class="headerlink" title="2.5.2 Vector Clock"></a>2.5.2 Vector Clock</h3><ul><li><p>Used to capture causality between different versions of the same object</p></li><li><p>A vector clock is a <code>node, counter</code> pair</p></li><li><p>Each version of every object associate with a vector clock</p><ul><li>one can determine whether two versions of an object are on parallel branches or have a causal ordering by examining vector clocks</li><li>If the counters on the first object’s clock are less-than-or-equal to all of the nodes in the second clock, then the first is an ancestor of the second and can be forgotten. Otherwise, the two changes are considered to be in conflict and require reconciliation.</li></ul></li><li><p>  <img src="https://i.loli.net/2021/08/08/9fKB418IrMezTun.png" alt=""></p></li><li><p>Issue occur when there are network partition, that same data cannot be shared / communicated via different servers</p></li><li><p>In this case, DynamoDB will return it back and let client reads and reconciles</p></li></ul><h3 id="2-5-3-Conflict-free-replicated-data-types-CRDTs"><a href="#2-5-3-Conflict-free-replicated-data-types-CRDTs" class="headerlink" title="2.5.3 Conflict free replicated data types (CRDTs)"></a>2.5.3 Conflict free replicated data types (CRDTs)</h3><ul><li>we need to model our data in such a way that concurrent changes can be applied to the data in any order and will produce the same end result</li></ul><h2 id="2-6-put-and-get-Operations"><a href="#2-6-put-and-get-Operations" class="headerlink" title="2.6 put() and get() Operations"></a>2.6 put() and get() Operations</h2><h3 id="2-6-1-Strategies-for-choosing-the-coordinator-node"><a href="#2-6-1-Strategies-for-choosing-the-coordinator-node" class="headerlink" title="2.6.1 Strategies for choosing the coordinator node"></a>2.6.1 Strategies for choosing the coordinator node</h3><ul><li><p>Strategies</p><p>  <img src="https://i.loli.net/2021/08/08/MB8qFbQGdwhoZAJ.png" alt=""></p><ul><li>Clients can route their requests through a generic load balancer<ul><li>client is unaware of the dynamo ring<ul><li>helps scalability</li><li>make ddb architecture loosely coupled</li></ul></li><li>it’s possible node it select is not part of the perference list, this will result in an extra hop</li></ul></li><li>Clients can use a partition aware client library that routes the request to the appropriate coordinator nodes with lower latency<ul><li>helps to achieve lower latency  — achieve zero hop</li><li>DDB doesn’t have much control over the load distribution and request handling</li></ul></li></ul></li></ul><h3 id="2-6-2-Consistency-Protocol"><a href="#2-6-2-Consistency-Protocol" class="headerlink" title="2.6.2 Consistency Protocol"></a>2.6.2 Consistency Protocol</h3><ul><li>R W is the min number of nodes that must participate in a successful read/ write operation</li><li>R + W &gt; N yields a quorun like system</li><li>A Common (N,R,WN, R, WN,R,W) configuration used by Dynamo is (3, 2, 2)</li><li>In general, low values of WWW and RRR increase the risk of inconsistency, as write requests are deemed successful and returned to the clients even if a majority of replicas have not processed them. This also introduces a vulnerability window for durability when a write request is successfully returned to the client even though it has been persisted at only a small number of nodes</li></ul><h3 id="2-6-3-put-process"><a href="#2-6-3-put-process" class="headerlink" title="2.6.3  put() process"></a>2.6.3  <code>put()</code> process</h3><ul><li>the coordinator generates a new data version and vector clock component</li><li>saves new data locally</li><li>sends the write request to N-1 highest ranked healthy nodes from the preference list</li><li>the put() operation is considered successful after receiving W - 1 confirmation</li></ul><h3 id="2-6-4-get-process"><a href="#2-6-4-get-process" class="headerlink" title="2.6.4 get() process"></a>2.6.4 <code>get()</code> process</h3><ul><li>coordinator requests the data version from N - 1 highest ranked healthy nodes from the preference list</li><li>waits until R - 1 replies</li><li>coordinator handles causal data versions through a vector clock</li><li>returns all relevant data versions to the caller</li></ul><h3 id="2-6-5-Request-handling-through-state-machine"><a href="#2-6-5-Request-handling-through-state-machine" class="headerlink" title="2.6.5 Request handling through state machine"></a>2.6.5 Request handling through state machine</h3><ul><li>Each client request results in creating a state machine on the node that received the client request</li><li>A read operation workflow would be:<ul><li>send read requests to the nodes</li><li>wait for the minimum number of required responses</li><li>if too few replies were received within a given time limit, fail the request</li><li>otherwise, gather all the data versions and determine the ones to be returned</li><li>if versioning is enabled, perform syntactic reconciliation and generate an opaque write context that contains the vector clock that subsumes all the remaining versions</li><li>At this point, read response has been returned to the caller</li><li>the state machine waits for a short period to receive any outstanding responces</li><li>if stale versions were returned in any of the responses, the coordinator updates those nodes with the latest version — READ REPAIR</li></ul></li></ul><h2 id="2-7-Anti-entropy-Through-Merkle-Trees"><a href="#2-7-Anti-entropy-Through-Merkle-Trees" class="headerlink" title="2.7 Anti-entropy Through Merkle Trees"></a>2.7 Anti-entropy Through Merkle Trees</h2><ul><li>Vector clocks are useful to remove conflicts while serving read requests</li><li>But if a replica falls significantly behind others, it might take a very long time to resolve conflicts using just vector clocks</li></ul><hr><p>—&gt; we need to quickly compare two copies of a range of data residing on different replicas and figure out exactly which parts are different </p><h3 id="2-7-1-What-are-MerkleTrees"><a href="#2-7-1-What-are-MerkleTrees" class="headerlink" title="2.7.1 What are MerkleTrees?"></a>2.7.1 What are MerkleTrees?</h3><ul><li><p>Dynamo use Merkel Trees to compare replicas of a range</p></li><li><p>A merkle tree is a binary tree of hashes, where each internal node is the hash of its two children, each leaf node is a hash of a portion of the original data</p></li><li><p>Then compare the merkle tree come to be super easy, just compare the root hashes of both trees, if equal, then stop; else, recurse on the left and right children</p></li><li><p>The principal advantage of using a Merkle tree is that each branch of the tree can be checked independently without requiring nodes to download the entire tree or the whole data set. Hence, Merkle trees minimize the amount of data that needs to be transferred for synchronization and reduce the number of disk reads performed during the anti-entropy process.</p></li><li><p>The disadvantage of using Merkle trees is that many key ranges can change when a node joins or leaves, and as a result, the trees need to be recalculated.</p></li></ul><h2 id="2-8-Dynamo-Characteristics"><a href="#2-8-Dynamo-Characteristics" class="headerlink" title="2.8 Dynamo Characteristics"></a>2.8 Dynamo Characteristics</h2><h3 id="2-8-1-Dynamo’s-Node-Responsibilities"><a href="#2-8-1-Dynamo’s-Node-Responsibilities" class="headerlink" title="2.8.1 Dynamo’s Node Responsibilities"></a>2.8.1 Dynamo’s Node Responsibilities</h3><ul><li>Each node serves three functions:<ul><li>Managing <code>get()</code> and <code>put()</code> requests<ul><li>A node may act as a coordinator and manage all operations for a particular key</li><li>A node also could forward the request to the appropriate node</li></ul></li></ul></li><li>Keep track of membership and detecting failures<ul><li>Every node uses gossip protocol to keep track of other nodes in the system and their associated hash ranges</li></ul></li><li>Local persistent storage<ul><li>Each node is responsible for being either the primary or replica store for keys that hash to a specific range of values</li><li>These pairs are stored within that node using various storage systems depending on application needs</li><li>E.G<ul><li>BerkeleyDB Transactional Data Store</li><li>MySQL</li><li>In memory buffer backed by persistent storage</li></ul></li></ul></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>数据库索引</title>
      <link href="/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/"/>
      <url>/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<blockquote><p>索引的实现，底层一般会依赖于哪些数据结构？</p></blockquote><h1 id="1-为什么需要索引"><a href="#1-为什么需要索引" class="headerlink" title="1. 为什么需要索引"></a>1. 为什么需要索引</h1><ul><li>为了能够尽快得到想要的数据 — 提高性能</li><li>选取高效的数据结构，在针对访问特性有比较好的访问速度的同时，减少空间上的占用<ul><li>如何节省存储空间</li><li>如何提高数据增删改查的执行效率</li></ul></li></ul><h1 id="2-功能性需求"><a href="#2-功能性需求" class="headerlink" title="2. 功能性需求"></a>2. 功能性需求</h1><ul><li>格式化数据还是非格式化数据？<ul><li>结构化数据<ul><li>比如MySQL数据</li></ul></li><li>非结构化数据<ul><li>比如搜索引擎当中的网页</li><li>一般需要进行预处理，提取出查询关键词，对关键词建立索引</li></ul></li></ul></li><li>静态数据还是动态数据？<ul><li>静态数据<ul><li>意味着没有增删改查</li><li>只需要考虑查询效率即可</li></ul></li><li>动态数据<ul><li>当原始数据更新的同时，我们还需要动态的更新索引</li></ul></li></ul></li><li>索引存储在内存还是硬盘？<ul><li>存储在内存<ul><li>访问速度快</li><li>原始数据量大的前提下，对应的索引也会非常大</li><li>因为内存有限，我们将不得不存放到内存当中</li></ul></li><li>存储在硬盘</li><li>部分存储在内存，部分在硬盘</li></ul></li><li>单值查找还是区间查找<ul><li>单值查找<ul><li>查询关键词等于某个值的数据</li></ul></li><li>区间查找<ul><li>查找关键词处于某个区间值的数据</li></ul></li></ul></li><li>单关键词还是多关键词组合的查找<ul><li>多关键词查询<ul><li>对于结构化数据的，<ul><li>实现针对多个关键词的组合建立索引</li></ul></li><li>对于非结构化数据的<ul><li>建立针对单个关键词的索引</li><li>然后通过集合操作，计算出查询结果</li></ul></li></ul></li></ul></li></ul><h1 id="3-非功能性需求"><a href="#3-非功能性需求" class="headerlink" title="3. 非功能性需求"></a>3. 非功能性需求</h1><ul><li>无论存放在内存还是磁盘当中，对于存储空间的消耗不能过大</li><li>在考虑索引查询效率的同时，还要考虑索引的维护成本</li></ul><h1 id="4-构建索引常用的数据结构"><a href="#4-构建索引常用的数据结构" class="headerlink" title="4. 构建索引常用的数据结构"></a>4. 构建索引常用的数据结构</h1><ul><li>散列表<ul><li>构建内存索引</li><li>如Redis Memcache</li></ul></li><li>红黑树<ul><li>构建内存索引</li><li>Ext文件系统中对磁盘块的索引</li></ul></li><li>B+树<ul><li>比起红黑树，更适合在磁盘当中构建索引</li><li>多叉树，比起红黑树，高度更低，IO更少</li><li>大部分关系型数据库的索引，会使用B+树来实现<ul><li>MySQL</li><li>Oracle</li></ul></li></ul></li><li>跳表<ul><li>Redis中的有序集合</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>B+树</title>
      <link href="/B-%E6%A0%91/"/>
      <url>/B-%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h1><h1 id="1-什么时候会用到？"><a href="#1-什么时候会用到？" class="headerlink" title="1. 什么时候会用到？"></a>1. 什么时候会用到？</h1><h2 id="1-1-数据库索引"><a href="#1-1-数据库索引" class="headerlink" title="1.1 数据库索引"></a>1.1 数据库索引</h2><p>工作中为了加快数据库中数据的查找速度，我们常用的处理思路是对表中数据创建索引，而数据库的索引底层就使用了B+树的结构</p><p>对于数据库，我们希望通过索引实现查询数据的效率的提升；同时不要消耗太多的内存空间。而数据库索引查找的过程当中，其特点是：</p><ul><li>需要进行直接查找</li><li>需要支持按照一定区间的快速查找</li></ul><h2 id="1-2-Overview"><a href="#1-2-Overview" class="headerlink" title="1.2 Overview"></a>1.2 Overview</h2><ul><li>B + 树特征<ul><li>每个节点中子节点的个数不能超过 m，也不能小于 m/2；</li><li>根节点的子节点个数可以不超过 m/2，这是一个例外；</li><li>m 叉树只存储索引，并不真正存储数据，这个有点儿类似跳表；</li><li>通过链表将叶子节点串联在一起，这样可以方便按区间查找；</li><li>一般情况下，根节点会被存储在内存中，其他节点存储在磁盘中</li></ul></li><li>B树<ul><li>节点中存储数据</li><li>叶子节点并没有使用链表来串联</li><li>是一个每个节点的子节点个数不少于m/2的m叉树</li></ul></li></ul><h1 id="2-为什么在数据库索引的时候会使用到B-树呢？"><a href="#2-为什么在数据库索引的时候会使用到B-树呢？" class="headerlink" title="2. 为什么在数据库索引的时候会使用到B+树呢？"></a>2. 为什么在数据库索引的时候会使用到B+树呢？</h1><h2 id="2-1-使用二叉查找树来实现索引？"><a href="#2-1-使用二叉查找树来实现索引？" class="headerlink" title="2.1 使用二叉查找树来实现索引？"></a>2.1 使用二叉查找树来实现索引？</h2><ul><li>从二叉查找树开始说起 我们可以改一下<ul><li>树中的节点不存储数据本身，只作为索引</li><li>每个叶子节点串在一条链表上</li><li>链表当中的数据从小到大有序</li></ul></li><li>对于区间查找的支持程度<ul><li>先在树中遍历，然后到叶子节点以后再顺着链表来往后遍历</li><li>直到链表当中的结点数据值大于区间的终止值为止</li></ul></li><li>问题<ul><li>占用的内存空间非常大<ul><li>解决方案<ul><li>放到硬盘上，但是访问速度会变慢很多了</li><li>内存访问速度在纳秒级别</li><li>硬盘访问速度在毫秒级别</li></ul></li><li>解决方案的问题在于<ul><li>磁盘IO操作的次数等于树的高度</li><li>我们需要尽可能的减少树的高度来减少磁盘IO的次数</li></ul></li></ul></li></ul></li></ul><h2 id="2-2-使用m叉树来实现"><a href="#2-2-使用m叉树来实现" class="headerlink" title="2.2 使用m叉树来实现"></a>2.2 使用m叉树来实现</h2><ul><li>使用m叉树的好处<ul><li>减少了访问磁盘的IO次数</li></ul></li></ul><pre><code class="jsx">/** * 这是B+树非叶子节点的定义。 * * 假设keywords=[3, 5, 8, 10] * 4个键值将数据分为5个区间：(-INF,3), [3,5), [5,8), [8,10), [10,INF) * 5个区间分别对应：children[0]...children[4] * * m值是事先计算得到的，计算的依据是让所有信息的大小正好等于页的大小： * PAGE_SIZE = (m-1)*4[keywordss大小]+m*8[children大小] */public class BPlusTreeNode &#123;  public static int m = 5; // 5叉树  public int[] keywords = new int[m-1]; // 键值，用来划分数据区间  public BPlusTreeNode[] children = new BPlusTreeNode[m];//保存子节点指针&#125;/** * 这是B+树中叶子节点的定义。 * * B+树中的叶子节点跟内部节点是不一样的, * 叶子节点存储的是值，而非区间。 * 这个定义里，每个叶子节点存储3个数据行的键值及地址信息。 * * k值是事先计算得到的，计算的依据是让所有信息的大小正好等于页的大小： * PAGE_SIZE = k*4[keyw..大小]+k*8[dataAd..大小]+8[prev大小]+8[next大小] */public class BPlusTreeLeafNode &#123;  public static int k = 3;  public int[] keywords = new int[k]; // 数据的键值  public long[] dataAddress = new long[k]; // 数据地址  public BPlusTreeLeafNode prev; // 这个结点在链表中的前驱结点  public BPlusTreeLeafNode next; // 这个结点在链表中的后继结点&#125;</code></pre><ul><li>m值的设定<ul><li>操作系统是按页来读取数据的，一页通常大小为4KB</li><li>一次会读取一页的数据</li><li>如果要读取的数据量超过一页的大小，就会触发多次IO操作了</li><li>因此我们选定m大小的时候尽量让每个节点的大小等于一个页的大小</li><li>这样的话读取一个节点只需要一次磁盘IO操作即可</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/11/148A67p9Y3dre2g.png" alt="B+树数据存储"></p><h2 id="2-3-索引的问题-导致写入效率下降"><a href="#2-3-索引的问题-导致写入效率下降" class="headerlink" title="2.3 索引的问题 - 导致写入效率下降"></a>2.3 索引的问题 - 导致写入效率下降</h2><ul><li>数据写入过程，会涉及到索引的更新，这是导致索引写入变慢的主要原因</li><li>场景描述<ul><li>m值是提前计算好的</li><li>向数据库写入过程当中，有可能会使得索引当中某些节点的子节点的个数超过m</li><li>这个节点的大小超过一个页的大小，那么读取这样一个节点的时候，就会导致多次磁盘IO操作，这是我们极力避免的</li></ul></li><li>解决方案<ul><li>将这个节点分裂成两个节点</li><li>这个问题会向上传导，即上层父节点的子节点个数有可能超过m个了</li><li>因此我们就需要向上递归来重构这棵B+树了</li><li>正是因为我们需要保证B+树索引是一个m叉树，所以索引的存在会导致数据库写入速度降低</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/11/9qAHTSmnlUeVPjb.png" alt="B+树索引修改"></p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis哨兵机制</title>
      <link href="/Redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6/"/>
      <url>/Redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis多机数据库-哨兵机制"><a href="#Redis多机数据库-哨兵机制" class="headerlink" title="Redis多机数据库-哨兵机制"></a>Redis多机数据库-哨兵机制</h1><p>主从库的集群模式使得当从库发生故障以后，客户端可以继续向主库或者其他从库发送请求，进行相关的操作；但是如果主库发生了故障，那会直接影响到从库的同步。无论是写中断还是从库无法进行数据同步都是Redis所不能接受的。因此我们需要一些机制，来能够<strong>将一个从库切换为主库</strong>，这就涉及到了Redis的哨兵机制。</p><h1 id="1-哨兵机制的基本流程"><a href="#1-哨兵机制的基本流程" class="headerlink" title="1. 哨兵机制的基本流程"></a>1. 哨兵机制的基本流程</h1><ul><li>哨兵可以理解为一个运行在特殊模式下的<strong>Redis进程</strong>，其在主从库实例运行的同时也在运行</li><li>哨兵主要的三个任务为：<ul><li>监控 — 决策：判断主库是否处于下线状态<ul><li>周期性的ping主库，检测其是否仍然在线运行</li><li>如果从库没有在规定时间内响应哨兵的Ping命令，哨兵就会将其标记为下线状态</li><li>对主库来说同理，在判定主库下线以后会开始一个自动切换主库的流程</li></ul></li><li>选主 — 决策：决定选择哪个从库实例作为主库<ul><li>主库挂了以后，哨兵就需要从很多从库里按照一定的规则选择一个从库实例，将其作为新的主库</li></ul></li><li>通知<ul><li>将新主库的连接信息发给其他从库，让它们执行replicaof命令，与新主库建立连接，并进行数据复制</li><li>哨兵会将新主库的连接信息通知给客户端，让它们将请求操作发到新主库当中</li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2021/01/07/z7o6Kkdfp2IaPsx.png" alt="哨兵机制任务"></p><p>哨兵三大任务</p><h1 id="2-判断主库的下线状态"><a href="#2-判断主库的下线状态" class="headerlink" title="2. 判断主库的下线状态"></a>2. 判断主库的下线状态</h1><h2 id="2-1-哨兵集群使用原因"><a href="#2-1-哨兵集群使用原因" class="headerlink" title="2.1 哨兵集群使用原因"></a>2.1 哨兵集群使用原因</h2><h3 id="2-1-1-为什么需要哨兵集群？"><a href="#2-1-1-为什么需要哨兵集群？" class="headerlink" title="2.1.1 为什么需要哨兵集群？"></a>2.1.1 为什么需要哨兵集群？</h3><ul><li>如果哨兵发生误判，后续的选主和通知操作都会带来额外的计算和通信的开销</li><li>误判通常发生在<ul><li>集群网络压力较大</li><li>网络拥塞</li><li>主库本身压力较大的情况</li></ul></li><li>哨兵机制也是类似的，它通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</li></ul><h3 id="2-1-2-如何使用哨兵集群？"><a href="#2-1-2-如何使用哨兵集群？" class="headerlink" title="2.1.2 如何使用哨兵集群？"></a>2.1.2 如何使用哨兵集群？</h3><ul><li>简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由 Redis 管理员自行设定）。</li></ul><h2 id="2-2-哨兵集群原理-—-基于PubSub机制"><a href="#2-2-哨兵集群原理-—-基于PubSub机制" class="headerlink" title="2.2 哨兵集群原理 — 基于PubSub机制"></a>2.2 哨兵集群原理 — 基于PubSub机制</h2><h3 id="2-2-1-pubsub机制"><a href="#2-2-1-pubsub机制" class="headerlink" title="2.2.1 pubsub机制"></a>2.2.1 pubsub机制</h3><p>哨兵实例之间的相互发现是基于Redis提供的pubsub机制的，<strong>哨兵只要和主库建立起连接</strong>，就可以在主库上发布消息了</p><ul><li>可以选择发布自己的连接信息到主库上</li><li>也可以从主库上订阅消息，获得其他哨兵发布的连接信息</li><li>当多个哨兵实例都在主库上做了发布和订阅操作之后，他们之间就能知道彼此的IP地址和端口</li></ul><h3 id="2-2-2-频道"><a href="#2-2-2-频道" class="headerlink" title="2.2.2 频道"></a>2.2.2 频道</h3><ul><li>Redis通过频道来区分不同应用的消息，对这些消息进行分门别类的管理。频道就是指消息的类别，当消息类别相同时，就会属于同一个频道，否则属于不同的频道。</li><li>主库会构建一个叫做 <code>__sentinel__:hello</code> 的频道，来让各个哨兵互相发现</li><li>只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换</li></ul><p><img src="https://i.loli.net/2021/01/11/LIhj62iuDBbPEve.png" alt="pubsub机制"></p><p>频道订阅机制</p><ul><li>哨兵1 向频道hello发送信息，因为哨兵2 哨兵3 subscribe了hello频道，他们就能从这个频道获取到哨兵1的IP地址和端口号信息</li></ul><h3 id="2-2-3-哨兵和从库的连接沟通"><a href="#2-2-3-哨兵和从库的连接沟通" class="headerlink" title="2.2.3 哨兵和从库的连接沟通"></a>2.2.3 哨兵和从库的连接沟通</h3><ul><li><p>哨兵向主库发出INFO命令</p></li><li><p>主库收到命令后，就会将从库列表返回给哨兵</p></li><li><p>接着哨兵就可以根据从库列表中的信息，和每个从库建立连接，并在这个连接上持续对从库进行监控</p><p>  <img src="https://i.loli.net/2021/01/11/sPTRS1mkhU2lLQn.png" alt="哨兵与从库之间的连接"></p><p>  哨兵和从库的连接</p></li><li><p>哨兵除了上述的和主库之间的连接，获取从库列表，并和从库们建立连接之外，还承担着在发生主库更换以后，将新主库的信息告诉客户端这个任务</p></li></ul><h2 id="2-3-客户端事件通知机制"><a href="#2-3-客户端事件通知机制" class="headerlink" title="2.3 客户端事件通知机制"></a>2.3 客户端事件通知机制</h2><ul><li><p>哨兵是一个运行在特定模式下的Redis实例，只是它不服务请求操作，只是完成监控，选主和通知的任务</p></li><li><p>因此每个哨兵实例也提供pubsub机制，客户端可以从哨兵订阅消息</p><ul><li><p>哨兵提供了很多的消息订阅频道，不同频道包含了主从库切换过程中的不同关键事件</p><p>  <img src="https://i.loli.net/2021/07/06/lBP5xJYieohTZXw.png" alt="哨兵常用的消息订阅频道"></p></li><li><p>客户端可以执行订阅命令，来订阅不同的频道，然后来获取不同的事件信息</p><ul><li>当哨兵将新的主库选出来以后，客户端会看到switch-master事件，事件中会包含新的主库的IP地址还有端口信息</li><li>此时客户端就会使用新主库地址和端口来进行通信了</li></ul></li></ul></li></ul><h1 id="3-如何选定新主库？"><a href="#3-如何选定新主库？" class="headerlink" title="3. 如何选定新主库？"></a>3. 如何选定新主库？</h1><blockquote><p>哨兵筛选新主库的过程称为筛选+打分</p></blockquote><ul><li>筛选 — 按照一定条件筛选，将不符合条件的从库去掉<ul><li>确保从库仍然在线运行</li><li>判断其之前的网络状态 看该从库和主库之间是否经常断联，出现网络相关的问题<ul><li>通过使用down-after-milliseconds属性，这是我们认为的最大主从间的连接超时，如果超过这个时间我们就认为断联了，超过一定次数就认为从库网络状况不好</li></ul></li></ul></li><li>打分 — <strong>只要有得分最高的，那么就在当前轮停止并且认定其为主库</strong><ul><li>从库优先级 — 手动设置的<ul><li>用户可以通过slave-priority配置项，给不同的从库设置不同的优先级<ul><li>譬如：两个从库内存大小不一样，我们就可以手动给内存大的实例设置一个高优先级</li></ul></li></ul></li><li>从库复制进度<ul><li>选择和旧主库<strong>同步最为接近</strong>的那个从库作为主库</li><li>如何判断从库和旧主库的同步进度？<ul><li>主从库之间命令传播机制里面的master_repl_offset 和slave_repl_offset</li><li>看二者的接近程度</li></ul></li></ul></li><li>从库ID号<ul><li>当优先级和复制进度都相同的情况下，ID号最小的从库得分最高，被选为新主库</li></ul></li></ul></li></ul><h1 id="4-由哪个哨兵来执行主从切换？"><a href="#4-由哪个哨兵来执行主从切换？" class="headerlink" title="4. 由哪个哨兵来执行主从切换？"></a>4. 由哪个哨兵来执行主从切换？</h1><ul><li><h2 id="任何一个实例只要自身判断主库主观下线之后，就会给其他势力发送is-master-down-by-addr命令。接着其他实例会根据自己和主库的连接情况，做出Y或N的响应"><a href="#任何一个实例只要自身判断主库主观下线之后，就会给其他势力发送is-master-down-by-addr命令。接着其他实例会根据自己和主库的连接情况，做出Y或N的响应" class="headerlink" title="任何一个实例只要自身判断主库主观下线之后，就会给其他势力发送is-master-down-by-addr命令。接着其他实例会根据自己和主库的连接情况，做出Y或N的响应"></a>任何一个实例只要自身判断主库主观下线之后，就会给其他势力发送is-master-down-by-addr命令。接着其他实例会根据自己和主库的连接情况，做出Y或N的响应</h2><pre><code>  ![哨兵沟通，确定主库是否下线](https://i.loli.net/2021/01/11/HpT5MAdKX9fmo2S.png)  is master down by addr</code></pre><ul><li><p>一个哨兵获得了<strong>仲裁所需的赞成票数后，就可以标记主库为客观下线</strong></p><ul><li>这个所需的赞成票数是通过哨兵配置文件中的quorum配置项设定的</li></ul></li><li><p>当获得了所需赞成票数以后，这个哨兵会再给其他哨兵发送命令，希望由自己来执行主从切换，并让所有其他哨兵进行投票，这个过程称为<strong>Leader选举</strong>。</p></li><li><p>在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：</p><ul><li>第一，拿到半数以上的赞成票；</li><li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。</li></ul><p><img src="https://i.loli.net/2021/01/11/RAaq7KZr2LSUdVx.png" alt="哨兵投票，选举leader"></p><p>票选执行主从切换哨兵的过程</p></li></ul><ol><li>在 T1 时刻，S1 判断主库为“客观下线”，它想成为 Leader，就先给自己投一张赞成票，然后分别向 S2 和 S3 发送命令，表示要成为 Leader。</li><li>在 T2 时刻，S3 判断主库为“客观下线”，它也想成为 Leader，所以也先给自己投一张赞成票，再分别向 S1 和 S2 发送命令，表示要成为 Leader。</li><li>在 T3 时刻，S1 收到了 S3 的 Leader 投票请求。<strong>因为 S1 已经给自己投了一票 Y，所以它不能再给其他哨兵投赞成票了，所以 S1 回复 N 表示不同意</strong>。同时，S2 收到了 T2 时 S3 发送的 Leader 投票请求。因为 S2 之前没有投过票，它会给第一个向它发送投票请求的哨兵回复 Y，给后续再发送投票请求的哨兵回复 N，所以，在 T3 时，S2 回复 S3，同意 S3 成为 Leader。</li><li>在 T4 时刻，S2 才收到 T1 时 S1 发送的投票命令。因为 S2 已经在 T3 时同意了 S3 的投票请求，此时，S2 给 S1 回复 N，表示不同意 S1 成为 Leader。发生这种情况，是因为 S3 和 S2 之间的网络传输正常，而 S1 和 S2 之间的网络传输可能正好拥塞了，导致投票请求传输慢了。</li><li>在 T5 时刻，S1 得到的票数是来自它自己的一票 Y 和来自 S2 的一票 N。而 S3 除了自己的赞成票 Y 以外，还收到了来自 S2 的一票 Y。此时，S3 不仅获得了半数以上的 Leader 赞成票，也达到预设的 quorum 值（quorum 为 2），所以它最终成为了 Leader。接着，S3 会开始执行选主操作，而且在选定新主库后，会给其他从库和客户端通知新主库的信息。</li></ol><ul><li><p>如果 S3 没有拿到 2 票 Y，那么这轮投票就不会产生 Leader。<strong>哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的 2 倍）</strong>，再重新选举。这是因为，哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常网络传播。<strong>如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票</strong>。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。</p><h1 id="5-FAQs"><a href="#5-FAQs" class="headerlink" title="5. FAQs"></a>5. FAQs</h1><h2 id="5-1-哨兵在操作主从切换的过程当中，客户端能否正常进行请求操作？"><a href="#5-1-哨兵在操作主从切换的过程当中，客户端能否正常进行请求操作？" class="headerlink" title="5.1 哨兵在操作主从切换的过程当中，客户端能否正常进行请求操作？"></a>5.1 哨兵在操作主从切换的过程当中，客户端能否正常进行请求操作？</h2></li><li><p>如果客户端使用了读写分离，那么<strong>读请求</strong>可以在从库上正常执行，不会受到影响。但是由于此时主库已经挂了，而且哨兵还没有选出新的主库，所以在这期间<strong>写请求会失败</strong>，失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库 的时间。</p></li><li><p>如果不想让业务感知到异常，客户端只能把写失败的请求先缓存起来或<strong>写入消息队列中间件</strong>中，等哨兵切换完主从后，再把这些写请求发给新的主库，但这种场景只适合对写入请求返回值不敏感的业务，而且还需要业务层做适配，另外主从切换时间过长，也会导致客户端或消息队列中间件缓存写请求过多，切换完成之后重放这些请求的时间变长。</p></li><li><p>哨兵检测主库多久没有响应就提升从库为新的主库，这个时间是可以配置的（down-after-milliseconds参数）。配置的时间越短，哨兵越敏感，哨兵集群认为主库在短时间内连不上就会发起主从切换，这种配置很可能因为网络拥塞但主库正常而发生不必要的切换，当然，当主库真正故障时，因为切换得及时，对业务的影响最小。如果配置的时间比较长，哨兵越保守，这种情况可以减少哨兵误判的概率，但是主库故障发生时，业务写失败的时间也会比较久，缓存写请求数据量越多。</p></li><li><p>应用程序不感知服务的中断，还需要哨兵和客户端做些什么？当哨兵完成主从切换后，客户端需要及时感知到主库发生了变更，然后把缓存的写请求写入到新库中，保证后续写请求不会再受到影响，具体做法如下：</p><ul><li>哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端。</li><li>如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持主动去获取最新主从的地址进行访问。</li><li>所以，客户端需要访问主从库时，不能直接写死主从库的地址了，而是需要从哨兵集群中获取最新的地址（sentinel get-master-addr-by-name命令），这样当实例异常时，哨兵切换后或者客户端断开重连，都可以从哨兵集群中拿到最新的实例地址。</li><li>一般Redis的SDK都提供了通过哨兵拿到实例地址，再访问实例的方式，我们直接使用即可，不需要自己实现这些逻辑。当然，对于只有主从实例的情况，客户端需要和哨兵配合使用，而在分片集群模式下，这些逻辑都可以做在proxy层，这样客户端也不需要关心这些逻辑了，Codis就是这么做的</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1></li></ul><ol><li>极客时间Redis课程</li><li>Redis设计与实现</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis Cluster</title>
      <link href="/Redis-Cluster/"/>
      <url>/Redis-Cluster/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis-Cluster"><a href="#Redis-Cluster" class="headerlink" title="Redis Cluster"></a>Redis Cluster</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>Redis集群是Redis提供的分布式数据库方案，集群通过分片 - sharding来进行数据共享，并提供复制和故障转移功能</li></ul><h1 id="2-节点"><a href="#2-节点" class="headerlink" title="2. 节点"></a>2. 节点</h1><ul><li>概述<ul><li>一个redis集群通常由多个节点 node 组成</li><li>开始的时候每个节点都是相互独立的，相当于各自在自己的集群当中，我们需要将各个独立的节点连接起来，构成一个包含多个节点的集群</li><li><code>CLUSTER MEET &lt;ip&gt; &lt;port&gt;</code> 我们可以用这个指令来连接各个节点<ul><li>以节点A 收到命令，要加节点B为例<ul><li>A和B 握手，确认彼此存在</li><li>A为节点B创建一个clusterNode结构，并添加到自己的clusterState.nodes字典里面</li><li>A根据IP 还有端口，向B发送MEET消息</li><li>节点B 收到信息，为A创建clusterNode结构，并添加到自己的 <code>clustState.nodes</code> 字典里面</li><li>B向A发出PONG消息，让A知道自己成功接收到了</li><li>A向B发出PING消息</li><li>节点B收到，确认A收到了自己的PONG  整个过程结束</li></ul></li></ul></li></ul></li><li>启动节点<ul><li>Redis服务器根据 <code>cluster-enabled</code> 配置选项判断是否开启服务器的集群模式</li></ul></li><li>集群模式和standalone模式的节点区别<ul><li>相同之处<ul><li>单机模式下的功能照旧<ul><li>文件事件处理器</li><li>时间事件处理器</li><li>持久化</li><li>Pubsub</li><li>复制模块</li><li>lua脚本</li></ul></li></ul></li><li>不同点<ul><li>集群模式下的数据会被保存到clusterNode, clusterLink以及clusterState结构里面<ul><li>下面是三个结构的代码实现</li><li>以及一个有三个节点的clusterState结构</li></ul></li></ul></li></ul></li></ul><pre><code class="jsx">struct clusterNode &#123;    mstime_t ctime;    char name[REDIS_CLUSTER_NAMELEN];    // 记录节点角色（主/从); 记录节点目前所处状态(在线/ 下线)    int flags;    // 节点当前配置记录    unit64_t configEpoch;    char ip[REDIS_IP_STR_LEN];    int port;    // 保存连接节点需要的信息    clusterLink *link;    // ....&#125;</code></pre><pre><code class="jsx">typedef struct clusterLink &#123;    mstime_t ctime;    // TCP 套接字描述符    int fd;    // 输出缓冲区，保存等待要发送给其他节点的消息    sds sndbuf;    // 输入缓冲区，保存着从其他节点接收到的消息    sds rcvbuf;    // 与这个连接相关联的节点    struct clusterNode *node;    // ....&#125; clusterLink; </code></pre><pre><code class="jsx">typedef struct clusterState &#123;    clustNode *myself;    unit64_t currentEpoch;    // 集群当前状态    int state;    // 集群中至少处理着一个槽的节点的数量    int size;    // 集群节点名单    dict *nodes;    // ....&#125; clusterState; </code></pre><p><img src="https://i.loli.net/2021/07/06/XxiOA9Qjz763K1Y.png" alt="clusterState示意图"></p><h1 id="3-槽指派"><a href="#3-槽指派" class="headerlink" title="3. 槽指派"></a>3. 槽指派</h1><ul><li>Redis集群通过分片的方式保存数据库当中的键值对<ul><li>整个数据库被分为了16384个slot</li><li>每个键都属于这些槽其中之一</li><li>集群当中的每个节点可以处理0个或者最多16384个槽</li><li>当16383个槽都有节点在处理的时候，集群处在上线状态</li><li>反之，如果有任何一个槽没有得到处理，那么集群就在下线状态</li></ul></li><li>如何指派槽<ul><li><code>CLUSTER ADDSLOTS &lt;slot&gt; [slot...]</code></li></ul></li></ul><h2 id="3-1-如何记录槽指派的信息"><a href="#3-1-如何记录槽指派的信息" class="headerlink" title="3.1 如何记录槽指派的信息"></a>3.1 如何记录槽指派的信息</h2><ul><li><p>clusterNode结构里面有slots属性和numslot属性</p><ul><li><p>slots</p><ul><li><p>bit array</p></li><li><p>根据索引i上的二进制位的值来判断节点是否负责处理槽i</p><p>  <img src="https://i.loli.net/2021/07/06/Zthejck4Xz2bPKl.png" alt="用bit array记录槽指派信息"></p></li></ul></li></ul></li></ul><pre><code class="jsx">struct clusterNode &#123;    // ...    unsigned char slots[16384/8];    int numslots; &#125;</code></pre><h2 id="3-2-如何传播-槽指派的信息"><a href="#3-2-如何传播-槽指派的信息" class="headerlink" title="3.2 如何传播 槽指派的信息"></a>3.2 如何传播 槽指派的信息</h2><ul><li>一个节点除了要记录自己负责处理的槽以外，还要将自己的slots通过消息发送给集群中的其他节点，以此告知其他结点自己目前负责的槽位</li><li>而后槽信息会被存储在clusterState 里面<ul><li>指向的是一个clusterNode结构！</li></ul></li><li>这里对比 <code>clusterState.slots</code> 以及 <code>clusterNode.slots</code> ， 前者记录了所有槽的指派信息，后者记录了当前的clusterNode结构所代表的节点的槽指派信息  一个记录了所有节点，一个记录了部分信息</li></ul><pre><code class="jsx">typedef struct clusterState &#123;    // ...    clusterNode *slots[16384];    // ... &#125;</code></pre><p><img src="https://i.loli.net/2021/07/06/4n1tgixR2NXOHdr.png" alt="槽指派信息的传播"></p><h1 id="4-在集群中执行命令"><a href="#4-在集群中执行命令" class="headerlink" title="4. 在集群中执行命令"></a>4. 在集群中执行命令</h1><h2 id="4-1-发送指令过程"><a href="#4-1-发送指令过程" class="headerlink" title="4.1 发送指令过程"></a>4.1 发送指令过程</h2><ul><li><p>当客户端向节点发送和数据库键有关的命令的时候，接收命令的节点会计算出命令要处理的数据库键属于哪一个槽</p></li><li><p>检查这个槽是否指派给了自己</p><ul><li><p>如果正好指派了，节点直接执行这个命令</p></li><li><p>如果没有，节点向客户端发送一个MOVED错误，指引客户端转向正确的节点，并再次发送之前想要执行的指令</p><p>  <img src="https://i.loli.net/2021/07/06/MamzjpOhCXvwNI4.png" alt="moved执行逻辑"></p><p>  <img src="https://i.loli.net/2021/07/06/3rBPwlGVoITAJn7.png" alt="节点返回MOVED,IP以及端口号"></p><p>  <img src="https://i.loli.net/2021/07/06/zIOFRiGWZutUce9.png" alt="节点转向"></p></li></ul></li></ul><h2 id="4-2-slots-to-keys跳跃表"><a href="#4-2-slots-to-keys跳跃表" class="headerlink" title="4.2 slots_to_keys跳跃表"></a>4.2 slots_to_keys跳跃表</h2><ul><li>当有新的键值对增删的操作时，节点会用clusterState结构中的slots_to_keys跳跃表来保存槽和键之间的关系</li></ul><pre><code class="jsx">typedef struct clusterState &#123;    // ...    zskiplist *slots_to_keys;    // ...&#125; clusterState; </code></pre><h1 id="5-重新分片操作"><a href="#5-重新分片操作" class="headerlink" title="5. 重新分片操作"></a>5. 重新分片操作</h1><h2 id="5-1-重分片流程"><a href="#5-1-重分片流程" class="headerlink" title="5.1 重分片流程"></a>5.1 重分片流程</h2><ul><li><p>将任意数量已经指派给某个节点的槽改为指派给另外一个节点，相关槽所属的键值对也会从源节点被移动到目标节点</p><p>  <img src="https://i.loli.net/2021/07/06/t5wivjMnQuIT2rG.png" alt="重分片"></p></li></ul><h2 id="5-2-ASK错误"><a href="#5-2-ASK错误" class="headerlink" title="5.2 ASK错误"></a>5.2 ASK错误</h2><ul><li>发生了重分片的过程当中，一部分键已经转移到了目标节点，另外一部分还在源节点</li><li>这种情况下，当接收到请求之后<ul><li>源节点首先在自己的数据库里面查找指定的键，如果找到，直接执行</li><li>如果没有找到，源节点会向客户端发送一个ASK，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/06/nD7Ybyk1BHGzOC4.png" alt="ASK判断逻辑"></p><h1 id="6-复制与故障转移"><a href="#6-复制与故障转移" class="headerlink" title="6. 复制与故障转移"></a>6. 复制与故障转移</h1><ul><li><p>Redis集群当中的节点分为主节点还有从节点</p></li><li><p>主节点用于处理槽，而从节点用于复制某个主节点，并在被复制的主节点下线以后，代替下线主节点继续处理命令请求</p></li><li><p>通过 <code>CLUSTER REPLICATE &lt;node_id&gt;</code> 来让接受命令的节点成为从节点，并开始对主节点进行复制</p><ul><li>从节点会在自己的 clusterState.nodes字典里 找到主节点对象的clusterNode结构，并将自己的 <code>clusterState.myself.slaveof</code>指针指向这个结构，以此来记录这个节点正在复制的主节点</li><li>而后修改在 <code>clusterStat.myslef.flags</code>中的属性  关闭原来的REDIS_NODE_MASTER标识，打开REDIS_NODE_SLAVE标识，表示这个节点已经由原来的主节点变成了从节点</li><li>根据 <code>clusterState.myself.slaveof</code>指向的clusterNode结构的IP还有端口号，开始对主节点的复制工作</li></ul></li><li><p>故障检测</p><ul><li>集群中每个节点会定期向其他节点发送PING消息，以此检测对方是否在线</li><li>如果接收PING消息的节点没有在规定时间内，返回PONG消息，那么没发回消息的节点会被标记为probable fail</li><li>集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息<ul><li>在线</li><li>疑似下线状态 PFAIL</li><li>已下线状态 FAIL</li></ul></li><li>主节点会记录各个节点的报告如果半数以上的负责处理槽的主节点都将某个主节点x报告为疑似下线，那么这个主节点会被标记为已下线</li><li>该消息会向集群广播出去</li></ul></li><li><p>故障转移</p><ul><li>在下线的主节点的从节点里面，选出一个从节点<ul><li>通过选举产生</li><li>当从节点发现主节点进入已下线状态的时候，从节点会向集群广播一条 <code>CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST</code> 消息，要求所有收到这条消息并且有投票权的主节点向这个从节点投票</li><li>如果一个主节点有投票权(负责处理槽) ，且还未投票给其他从节点，那么就会向要求投票的从节点返回一条 <code>CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK</code></li><li>每个参与选举的从节点统计收获到的ACK的数量</li><li>具有投票权的主节点数量为N  那么从节点需要收集到大于等于 N/2 +1 张支持票来获得主节点的支持</li><li>如果没有节点获得大于等于 N/2 +1 张支持票，那么就重新开始选举</li></ul></li><li>被选中的从节点会执行SLAVEOF no one命令，成为新的主节点</li><li>新主节点会撤销所有对已下线的主节点的槽指派，并将这些槽全部指派给自己</li><li>新的主节点向集群广播一条PONG消息，使得集群中的其他结点知道这个节点已经变成了主节点</li></ul></li></ul><h1 id="7-消息"><a href="#7-消息" class="headerlink" title="7. 消息"></a>7. 消息</h1><p>节点发送的消息主要有以下5种： </p><ul><li>MEET<ul><li>要求接受者加入到发送者当前所处的集群当中</li></ul></li><li>PING<ul><li>集群里的每个节点默认每隔一秒从已知节点列表中随机挑选5个结点</li><li>然后对5个当中最长时间没有发送过PING消息的节点发送PING消息</li></ul></li><li>PONG<ul><li>来告知发送者成功收到了MEET或者PING消息</li><li>也可以通过集群广播PONG 来让其他节点刷新对自己的认知</li></ul></li><li>FAIL<ul><li>当主节点A判断另一个主节点B进入FAIL状态了以后</li><li>节点A会向集群广播一条关于节点B FAIL的消息</li><li>所有收到消息的节点会将节点B标记为已下线</li></ul></li><li>PUBLISH<ul><li>当节点接到一个PUBLISH命令的时候，节点会执行，并向集群广播一条PUBLISH消息</li><li>所有接收到的节点都会执行相同的PUBLISH命令</li></ul></li></ul><h1 id="8-Redis-集群扩展与调优"><a href="#8-Redis-集群扩展与调优" class="headerlink" title="8. Redis 集群扩展与调优"></a>8. Redis 集群扩展与调优</h1><blockquote><p>实际案例： 5000万个键值对，每个键值对512B, 如何选择云主机的内存容量？</p></blockquote><ul><li><p>占用的内存空间</p><ul><li>50MM x 512B = 25GB</li></ul></li><li><p>使用32GB主机，但是发现Redis响应有时候会非常慢</p><ul><li>查询latest_fork_usec 指标，发现快到秒级别了</li></ul></li><li><p>Redis持久化机制</p><ul><li>RDB持久化过程当中，Redis会fork子进程来完成</li><li>fork用时和Redis的数据量正相关</li><li>fork在执行时会阻塞主线程<ul><li>数据量越大，fork操作造成的主线程阻塞时间就会越长</li><li>当我们对25GB的数据进行持久化的时候，数据量比较大，后台运行的子进程在fork创建时阻塞了主线程，导致Redis响应变慢</li></ul></li></ul></li><li><p>在上述的例子里面，使用单一redis instance已经不够了，因为我们要通过数据切片来实现</p></li></ul><h2 id="8-1-如何保存更多的数据"><a href="#8-1-如何保存更多的数据" class="headerlink" title="8.1 如何保存更多的数据"></a>8.1 如何保存更多的数据</h2><ul><li>纵向扩展<ul><li>升级单个Redis实例的资源配置<ul><li>增加内存容量</li><li>增加磁盘容量</li><li>使用更高配置的CPU</li></ul></li></ul></li><li>横向扩展<ul><li>横向增加当前Redis实例的个数</li></ul></li></ul><h2 id="8-2-数据切片和实例的对象分布关系"><a href="#8-2-数据切片和实例的对象分布关系" class="headerlink" title="8.2 数据切片和实例的对象分布关系"></a>8.2 数据切片和实例的对象分布关系</h2><ul><li>Redis cluster采用哈希槽来处理数据和实例之间的映射关系<ul><li>一个切片集群有16384个哈希槽</li><li>每个键值都会根据它的key，被映射到一个哈希槽当中</li></ul></li><li>具体映射过程<ul><li>根据键值对的key，按照CRC16算法计算一个16bit的值</li><li>用这个16bit的值对16384取模</li></ul></li><li>reids如何初始化各个实例来分配这些槽的？<ul><li>部署的时候，会用到cluster create命令创建集群</li><li>Redis会在此时将这些槽平均分别在集群实例当中</li></ul></li></ul><h2 id="8-3-客户端如何定位数据的"><a href="#8-3-客户端如何定位数据的" class="headerlink" title="8.3 客户端如何定位数据的"></a>8.3 客户端如何定位数据的</h2><ul><li><p>客户端定位键值对的时候，client library是可以计算出哈希槽是哪个的，但是如何定位到在哪个实例上是个问题</p><ul><li>拿到实例发过来的信息，缓存到本地上</li></ul></li><li><p>最开始</p><ul><li>每个实例都只知道自己被分配了哪些哈希槽的信息，并不知道其他实例拥有的哈希槽信息</li></ul></li><li><p>客户端和集群实例建立连接后</p><ul><li>实例会把哈希槽的分配信息发回给客户端</li><li>各个Redis实例会互相连通，完成哈希槽信息的扩散</li></ul></li><li><p>Redis Cluster的重定向机制</p><ul><li>为什么需要<ul><li>客户端的缓存没有拿到最新的信息<ul><li>集群中实例有新增或者删除</li><li>Redis 重新分配哈希槽</li></ul></li></ul></li><li>如何实现的<ul><li>客户端给一个实例发送读写操作，但是这个实例没有相应的数据</li><li>实例发回一个MOVED响应，包括了新实例的访问地址</li></ul></li></ul></li></ul><p>Redis使用集群方案就是为了解决单个节点数据量大、写入量大产生的性能瓶颈的问题。多个节点组成一个集群，可以提高集群的性能和可靠性，但随之而来的就是集群的管理问题，最核心问题有2个：请求路由、数据迁移（扩容/缩容/数据平衡）。</p><p>1、请求路由：一般都是采用哈希槽的映射关系表找到指定节点，然后在这个节点上操作的方案。</p><p>Redis</p><p>Cluster在每个节点记录完整的映射关系(便于纠正客户端的错误路由请求)，同时也发给客户端让客户端缓存一份，便于客户端直接找到指定节点，客户端与服务端配合完成数据的路由，这需要业务在使用Redis<br> Cluster时，必须升级为集群版的SDK才支持客户端和服务端的协议交互。</p><p>其他Redis集群化方案例如Twemproxy、Codis都是中心化模式（增加Proxy层），客户端通过Proxy对整个集群进行操作，Proxy后面可以挂N多个Redis实例，Proxy层维护了路由的转发逻辑。操作Proxy就像是操作一个普通Redis一样，客户端也不需要更换SDK，而Redis<br> Cluster是把这些路由逻辑做在了SDK中。当然，增加一层Proxy也会带来一定的性能损耗。</p><p>2、数据迁移：当集群节点不足以支撑业务需求时，就需要扩容节点，扩容就意味着节点之间的数据需要做迁移，而迁移过程中是否会影响到业务，这也是判定一个集群方案是否成熟的标准。</p><p>Twemproxy不支持在线扩容，它只解决了请求路由的问题，扩容时需要停机做数据重新分配。而Redis</p><p>Cluster和Codis都做到了在线扩容（不影响业务或对业务的影响非常小），重点就是在数据迁移过程中，客户端对于正在迁移的key进行操作时，集群如何处理？还要保证响应正确的结果？</p><p>Redis</p><p>Cluster和Codis都需要服务端和客户端/Proxy层互相配合，迁移过程中，服务端针对正在迁移的key，需要让客户端或Proxy去新节点访问（重定向），这个过程就是为了保证业务在访问这些key时依旧不受影响，而且可以得到正确的结果。由于重定向的存在，所以这个期间的访问延迟会变大。等迁移完成之后，Redis</p><p>Cluster每个节点会更新路由映射表，同时也会让客户端感知到，更新客户端缓存。Codis会在Proxy层更新路由表，客户端在整个过程中无感知。</p><p>除了访问正确的节点之外，数据迁移过程中还需要解决异常情况（迁移超时、迁移失败）、性能问题（如何让数据迁移更快、bigkey如何处理），这个过程中的细节也很多。</p><p>Redis Cluster的数据迁移是同步的，迁移一个key会同时阻塞源节点和目标节点，迁移过程中会有性能问题。而Codis提供了异步迁移数据的方案，迁移速度更快，对性能影响最小，当然，实现方案也比较复杂。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>极客时间-Redis核心技术与实战</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis多机数据库-数据同步</title>
      <link href="/Redis%E5%A4%9A%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
      <url>/Redis%E5%A4%9A%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93-%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis多机数据库-数据同步"><a href="#Redis多机数据库-数据同步" class="headerlink" title="Redis多机数据库-数据同步"></a>Redis多机数据库-数据同步</h1><h1 id="1-Redis的高可靠性"><a href="#1-Redis的高可靠性" class="headerlink" title="1. Redis的高可靠性"></a>1. Redis的高可靠性</h1><p>Redis的高可靠性体现在两个方面：</p><ul><li>数据尽量少丢失<ul><li>AOF</li><li>RDB</li></ul></li><li>服务尽量少中断<ul><li>增加副本冗余量 — 将一份数据同时保存在多个实例上</li></ul></li></ul><h1 id="2-数据同步-—-主从库模式"><a href="#2-数据同步-—-主从库模式" class="headerlink" title="2. 数据同步 — 主从库模式"></a>2. 数据同步 — 主从库模式</h1><ul><li><p>主从库之间采用的是读写分离的方式</p><ul><li><p>读操作</p><ul><li>主库，从库都可以接收</li></ul></li><li><p>写操作</p><ul><li><p>首先到主库执行</p></li><li><p>然后主库将写操作同步给从库</p><p>  <img src="https://i.loli.net/2021/01/04/8wE4dPDgFxqRX6r.png" alt="https://i.loli.net/2021/01/04/8wE4dPDgFxqRX6r.png"></p><p>  主从读写分离</p></li></ul></li></ul></li><li><p>主从库的好处是修改操作都只会在一个库实现</p><ul><li>可以减少加锁，实例间协商这类开销</li></ul></li></ul><h2 id="2-1-主从库之间如何进行第一个同步？"><a href="#2-1-主从库之间如何进行第一个同步？" class="headerlink" title="2.1 主从库之间如何进行第一个同步？"></a>2.1 主从库之间如何进行第一个同步？</h2><ul><li><p>多个Redis实例之间通过replicaof/ slaveof命令形成主库和从库的关系，然后按照三个阶段完成数据的第一次同步：</p><p>  <img src="https://i.loli.net/2021/01/04/KZemoVB6CFjNlJI.png" alt="https://i.loli.net/2021/01/04/KZemoVB6CFjNlJI.png"></p><p>  主从首次同步过程</p></li><li><p>第一阶段</p><ul><li><p>主从库之间建立连接，协商同步</p></li><li><p>为全量复制做准备</p></li><li><p>从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复以后，主从库间就可以开始同步了</p><ul><li><p>从库给主库发送psync命令，表示要进行数据同步</p></li><li><p>主库根据这个命令的参数来启动复制</p><ul><li>psync命令包含主库的runId和复制进度的offset两个参数<ul><li>runID — Redis实例启动的时候自动随机生成的ID，用来唯一标识当前实例<ul><li>runId很关键，比如从服务器断线重连主服务器以后，会发送之前保存的主服务器的运行ID，如果ID一致，说明前后连接的是同一个主服务器，那么就可以继续尝试执行部分的重同步操作</li><li>相反，如果运行ID不同，那么就必须通过RDB完成整个重同步操作</li></ul></li><li>offset 此时设为-1，表示第一次复制</li></ul></li></ul></li><li><p>主库收到psync命令后，使用FULLRESYNC响应命令，包括了主库的runID还有主库目前的复制进度offset，返回给从库</p><ul><li>从库记录下两个参数</li></ul></li><li><p>FULLRESYNC表示第一次复制使用的是全量复制</p></li><li><p>主库与此同时执行BGSAVE命令，在后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令</p><p>  <img src="https://i.loli.net/2021/07/05/Kmw8ZsWuzGki25V.png" alt="主从服务器同步过程"></p></li></ul></li></ul></li><li><p>第二阶段</p><ul><li>主库将所有数据同步给从库</li><li>从库收到数据后，在本地完成数据加载 — 依赖于内存快照生成的RDB文件<ul><li>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。</li><li>从库接收到 RDB 文件后，会先<strong>清空当前数据库</strong>，然后加载 RDB 文件。<ul><li>这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空</li></ul></li></ul></li><li>在做数据同步的过程中，主库不会被阻塞。对于这个过程中接收到的正常请求，写操作会记录在主库的<strong>Replication Buffer</strong>当中</li></ul></li><li><p>第三阶段</p><ul><li>主库会将第二阶段新收到的修改命令，再发给从库</li><li>当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了</li></ul></li></ul><h2 id="2-2-主从级联方式分担全量复制时的主库压力"><a href="#2-2-主从级联方式分担全量复制时的主库压力" class="headerlink" title="2.2 主从级联方式分担全量复制时的主库压力"></a>2.2 主从级联方式分担全量复制时的主库压力</h2><ul><li><p>现状/ 问题</p><ul><li>一次全量复制主库需要完成两个耗时操作<ul><li>生成RDB文件和传输RDB文件</li></ul></li><li>如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。</li><li>传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力</li></ul></li><li><p>解决方案 — 主从从模式</p><ul><li><p>我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。replicaof 所选从库的IP 6379</p><p><img src="https://i.loli.net/2021/01/04/eihQpmN6FJdRxLy.png" alt="https://i.loli.net/2021/01/04/eihQpmN6FJdRxLy.png"></p></li></ul></li></ul><h2 id="2-3-突发情况下-暂时断网-的增量复制"><a href="#2-3-突发情况下-暂时断网-的增量复制" class="headerlink" title="2.3 突发情况下(暂时断网)的增量复制"></a>2.3 突发情况下(暂时断网)的增量复制</h2><ul><li><p>旧版redis在断开重连以后从服务器会向主服务器发出SYNC命令，从头开始进行bootstrap，时间会非常长，非常低效</p></li><li><p>新版本使用PSYNC</p><ul><li>PSYNC具有full resynchronization, partial resynchronization两种模式</li><li>partial resync使得断线重连以后可以通过增量来做复制，而不是用RDB重头开始</li></ul></li><li><p>网络断了以后我们需要一种开销相对合理的复制方式，即增量复制</p><ul><li>将主从库断联期间主库收到的命令，同步给从库</li></ul></li><li><p>增量复制的时候，主从库之间依靠repl_backlog_buffer这个缓冲区来做同步</p></li><li><p>整个过程如下：</p><ul><li><p>当主从库断连后，主库会把断连期间收到的写操作命令，写入 <strong>replication buffer</strong>，同时也会把这些操作命令也写入 <strong>repl_backlog_buffer</strong> 这个缓冲区。</p></li><li><p>repl_backlog_buffer 是一个<strong>环形缓冲区</strong>，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。</p></li><li><p>刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。</p></li><li><p>同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。</p></li><li><p>主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距</p></li><li><p>在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。</p><p><img src="https://i.loli.net/2021/01/04/w3TLhzRgOH2A65d.png" alt="https://i.loli.net/2021/01/04/w3TLhzRgOH2A65d.png"></p></li></ul></li></ul><blockquote><p>因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。</p></blockquote><p>我们要想办法避免这一情况，一般而言，我们可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：<strong>缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小</strong>。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值</p><ul><li>repl_backlog_buffer<ul><li>是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销</li><li>如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量同步，所以repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量同步的概率</li><li>而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer</li></ul></li><li>replication_buffer<ul><li>Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互</li><li>客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的</li><li>Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。</li><li>所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer</li><li>这个buffer需要做大小的限制<ul><li>如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM</li><li>所以Redis提供了<strong>client-output-buffer-limit</strong>参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。</li></ul></li></ul></li></ul><h2 id="2-4-主从全量同步-RDB-vs-AOF"><a href="#2-4-主从全量同步-RDB-vs-AOF" class="headerlink" title="2.4 主从全量同步 RDB vs AOF"></a>2.4 主从全量同步 RDB vs AOF</h2><p>1、RDB文件内容是<strong>经过压缩的二进制数据（不同数据类型数据做了针对性优化）</strong>，文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为<strong>RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可</strong>，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。</p><p>2、假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。</p><h1 id="3-复制过程的具体实现"><a href="#3-复制过程的具体实现" class="headerlink" title="3. 复制过程的具体实现"></a>3. 复制过程的具体实现</h1><ul><li>设置主服务器的地址和端口</li><li>建立套接字连接<ul><li>从服务器根据命令所设置的IP和端口，创建连向主服务器的套接字连接</li><li>如果连接成功，会为这个套接字关联一个专门用于处理复制工作的文件事件处理器</li><li>从服务器这个时候相当于主服务器的客户端</li></ul></li><li>建立完成以后，从PING主<ul><li>检查套接字读写正常</li><li>检查主服务器能否正常处理命令请求</li></ul></li><li>身份验证<ul><li>masterauth</li></ul></li><li>验证成功以后从服务器执行命令  <code>REPLCONF listerning-port &lt;port-numer&gt;</code> 向主服务器发送从服务器的监听端口号</li><li>主服务器接收到以后，会将端口号记录在从服务器所对应的客户端状态的属性当中 <code>slave_listening_port</code></li><li>同步<ul><li>从向主发PSYNC命令，执行同步操作</li></ul></li><li>命令传播</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>极客时间</li><li>redis设计与实现</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis持久化机制-RDB</title>
      <link href="/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-RDB/"/>
      <url>/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-RDB/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AOF数据恢复存在的问题"><a href="#1-AOF数据恢复存在的问题" class="headerlink" title="1. AOF数据恢复存在的问题"></a>1. AOF数据恢复存在的问题</h1><ul><li>AOF方法每次执行记录的是操作命令，需要持久化的数据量不大</li><li>但是也因为记录的是操作命令，而不是实际数据，所以用AOF方法进行故障恢复的时候，需要逐一把操作日志都执行一遍<ul><li>如果操作日志很多，Redis的恢复就会很缓慢，可能影响到正常</li></ul></li></ul><h1 id="2-内存快照Overview"><a href="#2-内存快照Overview" class="headerlink" title="2. 内存快照Overview"></a>2. 内存快照Overview</h1><ul><li>内存快照可以解决上述的问题<ul><li>内存快照指的是记录下内存中的数据在某一时刻的状态</li><li>将某一时刻的状态以文件的形式写到磁盘上 这样即使宕机，快照文件也不会丢失，数据的可靠性也就有了保证</li><li>快照文件称为RDB文件，RDB — Redis DataBase</li></ul></li><li>RDB特征<ul><li>记录的是某一个时刻的数据，并不是操作</li><li>因此在数据恢复的时候，我们可以将RDB文件直接读入内存，很快完成恢复</li></ul></li><li>什么时候会实现RDE的载入？<ul><li>只要Redis服务器在启动的时候检测到RDB文件存在，就会自动载入RDB文件</li><li>如果服务器开启了AOF持久化功能，因为AOF文件更新频率一般比RDB高很多，所以服务器会优先使用AOF文件来还原数据库状态、</li><li>只有当AOF功能处于关闭状态的时候，服务器才会使用RDB文件来还原数据库状态</li></ul></li><li>如何工作的<ul><li>我们可以设置一系列规则，被保存在saveparams里面<ul><li>seconds</li><li>changes</li><li>—&gt; 当在xx秒里 有超过xxx更新数量的时候会触发RDB</li></ul></li><li>dirty计数器<ul><li>记录在上次成功执行了SAVE或者BGSAVE命令之后，服务器对数据库状态进行了多少次修改</li></ul></li><li>lastsave属性<ul><li>UNIX时间戳，记录了上次成功执行的时间</li></ul></li><li>Redis的serverCron函数默认每隔100ms执行一次，来维护服务器<ul><li>其中一项工作就是检查save选项设置的保存条件是否满足</li><li>如果满足就执行BGSAVE命令</li></ul></li></ul></li></ul><h2 id="2-1-给哪些数据做快照？"><a href="#2-1-给哪些数据做快照？" class="headerlink" title="2.1 给哪些数据做快照？"></a>2.1 给哪些数据做快照？</h2><ul><li>Redis的数据都在内存当中，为了提供所有数据的可靠性保证，其执行的是<strong>全量快照</strong><ul><li>即将内存中的所有数据都记录到磁盘当中</li><li>与之一起来的问题就是，当需要对内存的全量数据做快照的时候，将其全部写入磁盘会花费很多时间</li><li>而且全量数据越多，RDB文件就越大，往磁盘上写数据的时间开销就越大</li><li>而Redis的单线程模型决定了我们要尽量避免阻塞主线程的操作</li></ul></li><li>Redis生成RDB文件的命令<ul><li>save<ul><li>在主线程中执行，会导致阻塞</li><li>在服务器进程阻塞期间，服务器不能处理任何命令请求</li></ul></li><li>bgsave<ul><li>创建一个子进程，专门用于写入RDB文件，可以避免对于主线程的阻塞 — 是Redis RDB的文件生成的默认配置</li></ul></li></ul></li></ul><h2 id="2-2-做快照的时候数据是否能够被增删改？"><a href="#2-2-做快照的时候数据是否能够被增删改？" class="headerlink" title="2.2 做快照的时候数据是否能够被增删改？"></a>2.2 做快照的时候数据是否能够被增删改？</h2><ul><li><p>我们需要使系统在进行快照的时候仍然能够接受修改请求，要不然会严重影响系统的执行效率</p></li><li><p>Redis会借助操作系统提供的<strong>写时复制技术 — copy on write</strong>，在执行快照的同时，正常处理写操作</p><ul><li><p>copy on write</p><ul><li><p>copy operation is deferred until the first write,</p></li><li><p>could significantly reduce the resource consumption of unmodified copies, while adding a small overhead to resource-modifying operations</p><p><a href="https://en.wikipedia.org/wiki/Copy-on-write">Copy-on-write</a></p><p><img src="https://i.loli.net/2021/01/03/I8kwNqF41KlezWL.png" alt="Copy On Write的实现"></p><p>Copy on Write实现</p></li></ul></li></ul></li><li><p>例图当中键值对C发生了改变，那么bgsave子进程还会对原键值对C 进行snapshot，然后过程当中的写操作会被写到副本里面</p></li></ul><h2 id="2-3-多久做一次快照？"><a href="#2-3-多久做一次快照？" class="headerlink" title="2.3 多久做一次快照？"></a>2.3 多久做一次快照？</h2><ul><li>尽管bgsave执行时不阻塞主线程，但是频繁的执行全量快照，会带来两方面的开销<ul><li>磁盘带宽压力<ul><li>频繁将全量数据写入磁盘，会给磁盘带来很大的压力</li><li>多个快照竞争有限的磁盘贷款，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环</li></ul></li><li>fork操作的阻塞<ul><li>bgsave子进程需要通过fork操作从主线程创建出来</li><li>fork创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间就越长</li></ul></li></ul></li></ul><h2 id="2-4-RDB文件结构"><a href="#2-4-RDB文件结构" class="headerlink" title="2.4 RDB文件结构"></a>2.4 RDB文件结构</h2><ul><li>一个RDB文件分成以下几个部分<ul><li>REDIS<ul><li>用来检测载入的文件是否为RDB文件</li></ul></li><li>db_version<ul><li>记录RDB文件的版本号</li></ul></li><li>databased<ul><li>包含任意多个数据库，以及每个数据库中的键值对数据</li></ul></li><li>EOF<ul><li>1字节</li><li>标志着RDB文件正文部分的结束</li></ul></li><li>check_sum<ul><li>通过对上面四个部分的内容进行计算得出的</li><li>载入RDB文件的时候，会将载入数据所计算出来的校验和与check_sum所记录的进行对比</li></ul></li></ul></li></ul><h1 id="3-AOF和RDB混用模式"><a href="#3-AOF和RDB混用模式" class="headerlink" title="3. AOF和RDB混用模式"></a>3. AOF和RDB混用模式</h1><ul><li>为什么要混用<ul><li>AOF执行速度会比较慢</li><li>RDB的全量复制频率难以把控，太低，会容易丢失数据；太高，系统开销会很大</li></ul></li><li>如何实现的<ul><li>RDB以一定的频率来执行</li><li>在两次快照之间，使用AOF日志记录这期间所有的命令操作</li></ul></li></ul><p><img src="https://i.loli.net/2021/01/03/C98RNZ7PanDWyUr.png" alt="RDB增量快照的实现"></p><p>AOF &amp; RDB Mix</p><ul><li>如上图所示，到了第二次做全量快照的时候，就可以清空AOF日志，因为所有的操作都已经保存到了第二次的全量快照当中了</li></ul><h1 id="4-实际场景探究"><a href="#4-实际场景探究" class="headerlink" title="4. 实际场景探究"></a>4. 实际场景探究</h1><blockquote><p>我们使用一个 2 核 CPU、4GB 内存、500GB 磁盘的云主机运行 Redis，Redis 数据库的数据量大小差不多是 2GB，我们使用了 RDB 做持久化保证。当时 Redis 的运行负载以修改操作为主，写读比例差不多在 8:2 左右，也就是说，如果有 100 个请求，80 个请求执行的是修改操作。你觉得，在这个场景下，用 RDB 做持久化有什么风险吗？</p></blockquote><ul><li>内存资源风险<ul><li>Redis fork子进程做RDB持久化，由于写的比例为80%，那么在持久化过程中，“写实复制”会重新分配整个实例80%的内存副本，大约需要重新分配1.6GB内存空间，这样整个系统的内存使用接近饱和，</li><li>如果此时父进程又有大量新key写入，很快机器内存就会被吃光，如果机器开启了Swap机制，那么Redis会有一部分数据被换到磁盘上，当Redis访问这部分在磁盘上的数据时，性能会急剧下降，已经达不到高性能的标准（可以理解为武功被废）。如果机器没有开启Swap，会直接触发OOM，父子进程会面临被系统kill掉的风险。<ul><li>swap 机制<ul><li>将一块磁盘或者一个本地文件当做内存来使用<ul><li>换入<ul><li>当进程再次访问内存的时候，从磁盘读取数据到内存当中</li></ul></li><li>换出<br><a href="https://blog.csdn.net/qq_24436765/article/details/103822548">Linux系统的swap机制_囚牢-峰子的博客-CSDN博客</a><ul><li>将进程暂时不用的内存数据保存到磁盘上，再释放内存给其他进程使用</li><li>当进程再次访问内存的时候，从磁盘读取数据到内存中</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>CPU资源风险<ul><li>虽然子进程在做RDB持久化，但生成RDB快照过程会消耗大量的CPU资源，</li><li>虽然Redis处理处理请求是单线程的，但Redis Server还有其他线程在后台工作，例如AOF每秒刷盘、异步关闭文件描述符这些操作。</li><li>由于机器只有2核CPU，这也就意味着父进程占用了超过一半的CPU资源，此时子进程做RDB持久化，可能会产生CPU竞争，导致的结果就是父进程处理请求延迟增大，子进程生成RDB快照的时间也会变长，整个Redis Server性能下降。</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>极客时间</li><li>Redis设计与实现</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis持久化机制-AOF</title>
      <link href="/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-AOF/"/>
      <url>/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6-AOF/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis持久化机制-AOF"><a href="#Redis持久化机制-AOF" class="headerlink" title="Redis持久化机制-AOF"></a>Redis持久化机制-AOF</h1><h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>Redis很大的一个应用场景就是缓存，因为速度很快，通过将后端数据库中的数据存储在内存当中，然后直接从内存中读取数据。</p><p>但是这样做的一个问题，是如果服务器宕机，内存中的数据将会全部丢失掉。对于恢复数据，我们可能的解决方案是：</p><ul><li>从后端数据库访问<ul><li>对数据库的频繁访问会给数据库造成巨大的压力</li><li>会导致应用程序响应速度变慢</li></ul></li><li>理念 - 不从后端数据库读取，实现数据的持久化<ul><li>AOF日志</li><li>RDB快照</li></ul></li></ul><h1 id="2-AOF日志的实现"><a href="#2-AOF日志的实现" class="headerlink" title="2. AOF日志的实现"></a>2. AOF日志的实现</h1><h2 id="2-1-什么是AOF"><a href="#2-1-什么是AOF" class="headerlink" title="2.1 什么是AOF"></a>2.1 什么是AOF</h2><ul><li><p>AOF - Append Only File</p></li><li><p>写后日志</p><ul><li><p>Redis先执行命令，将数据写入内存，然后才记录日志</p><p>  [写后日志]](<a href="https://i.loli.net/2020/12/29/bNUOftoVI19G8Wj.png">https://i.loli.net/2020/12/29/bNUOftoVI19G8Wj.png</a>)</p></li></ul></li></ul><h2 id="2-2-AOF记录了什么"><a href="#2-2-AOF记录了什么" class="headerlink" title="2.2 AOF记录了什么"></a>2.2 AOF记录了什么</h2><ul><li><p>传统数据库日志</p><ul><li>记录修改后的数据</li></ul></li><li><p>AOF</p><ul><li><p>写后日志</p></li><li><p>记录Redis收到的每一条指令，这些命令以文本形式保存</p></li><li><p><strong>AOF记录日志的时候，不会进行语法检查的</strong>！ 因此，如果先记录日志，再做执行的话，日志当中就有可能记录错误的命令，在使用日志恢复数据的时候，就有可能出错</p><ul><li><p>还是对于速度和保证性的tradeoff</p><p><img src="https://i.loli.net/2020/12/29/qn9adxRcv2ZSJiD.png" alt="AOF文件EG"></p><p>AOF日志范例</p></li></ul></li><li><p>写后日志可以避免出现记录错误命令的情况</p></li><li><p>而且因为是在命令执行后才记录日志，所以不会阻塞当前的写操作</p></li></ul></li></ul><h3 id="2-2-1-写后日志的风险"><a href="#2-2-1-写后日志的风险" class="headerlink" title="2.2.1 写后日志的风险"></a>2.2.1 写后日志的风险</h3><ul><li>如果刚执行完一个命令，还没有记录日志就宕机了，那么命令和相应的数据都有丢失的风险。</li><li>AOF虽然避免了对当前命令的阻塞，但是可能会给下一个操作带来阻塞风险<ul><li>因为AOF日志也是在主线程中执行，如果将日志文件写入磁盘的时候，磁盘写压力大，会导致写盘非常慢</li></ul></li></ul><p>解决方案： 需要控制写命令执行完成后AOF日志写回磁盘的时机</p><h2 id="2-3-AOF文件载入与数据还原"><a href="#2-3-AOF文件载入与数据还原" class="headerlink" title="2.3 AOF文件载入与数据还原"></a>2.3 AOF文件载入与数据还原</h2><ul><li>详细步骤<ul><li>创建一个不带网络连接的fake client<ul><li>因为Redis命令只能在客户端的上下文当中来执行</li></ul></li><li>从AOF文件当中分析并读取一条写命令</li><li>使用伪客户端来执行被读出的写命令</li><li>重复执行上述的读取和执行指令，直到处理完毕</li></ul></li></ul><h1 id="3-单点研究"><a href="#3-单点研究" class="headerlink" title="3. 单点研究"></a>3. 单点研究</h1><h2 id="3-1-写回策略"><a href="#3-1-写回策略" class="headerlink" title="3.1 写回策略"></a>3.1 写回策略</h2><ul><li>Redis的服务器进程是一个事件循环，这个循环当中的文件事件负责<ul><li>接收客户端的命令请求</li><li>向客户端发送命令回复</li></ul></li><li>时间事件负责接收客户端的命令请求</li></ul><pre><code class="jsx">def eventLoop():     while true:         // 处理文件事件，可能会有新内容追加到aof_but缓冲区        processFileEvents()        processTimeEvents()        flushAppendOnlyFile()</code></pre><ul><li><p>可用的写回策略 - AOF当中的appendfsync的三个可选值</p><ul><li><p>Always 同步写回</p><ul><li>每个写命令执行完，立刻同步将日志写回磁盘</li></ul></li><li><p>EverySec 每秒写回</p><ul><li>每个写命令执行完，只是先把日志写到<strong>AOF文件的内存缓冲区</strong>，每隔一秒将缓冲区中的内容写入磁盘</li></ul></li><li><p>No 操作系统控制的写回</p><ul><li>每个写命令执行完，只是将日志写到AOF文件的缓冲区，由操作系统决定何时将缓冲区内容写回磁盘</li></ul><p><img src="https://i.loli.net/2020/12/29/RkfhClbVDv5JKzp.png" alt="appendfsync 规定的写回策略"></p><p>写回策略对比</p></li></ul></li><li><p>写回策略的选择 — 根据对于性能和可靠性的要求，来选择选用哪一种写回策略</p><ul><li>想要获得高性能，选用No策略</li><li>想要高可靠性的保证，选用Always策略</li><li>如果允许数据有一点丢失，又希望性能不受太大的影响，选用EverySec策略</li></ul></li></ul><h2 id="3-2-如何处理过大的日志文件-—-AOF重写机制"><a href="#3-2-如何处理过大的日志文件-—-AOF重写机制" class="headerlink" title="3.2 如何处理过大的日志文件 — AOF重写机制"></a>3.2 如何处理过大的日志文件 — AOF重写机制</h2><p>日志过大会产生性能问题，主要在以下三个方面： </p><ol><li><p>文件系统本身对文件大小的限制，无法保存过大的文件 </p></li><li><p>如果文件太大，再向里面追加命令记录，效率会降低 </p></li><li><p>如果发生宕机，AOF中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程会非常缓慢，这就会影响到Redis的正常使用</p></li></ol><h3 id="3-2-1-重写可以优化日志大小的原理"><a href="#3-2-1-重写可以优化日志大小的原理" class="headerlink" title="3.2.1 重写可以优化日志大小的原理"></a>3.2.1 重写可以优化日志大小的原理</h3><ul><li><p>AOF重写机制</p><ul><li><p>重写的时候，根据数据库现状创建一个新的AOF文件</p><ul><li>读取数据库所有的键值对</li><li>针对每一个键值对用一条命令记录它的写入</li><li>需要回复的时候，直接执行这条命令</li></ul></li><li><p>重写可以使得日志文件变小，因为可以压缩多条指令到一条</p><ul><li><p>即AOF日志是用来做恢复的，我不需要记录每一步的中间状态，只要知道最终对应的key的value是多少就好</p><p>  <img src="https://i.loli.net/2020/12/29/R7fgD2tVBvZUk8z.png" alt="AOF重写E.G"></p><p>  重写原理</p></li></ul></li></ul></li></ul><h3 id="3-2-2-重写如何避免阻塞？"><a href="#3-2-2-重写如何避免阻塞？" class="headerlink" title="3.2.2 重写如何避免阻塞？"></a>3.2.2 重写如何避免阻塞？</h3><ul><li><p>AOF日志由主线程写回 — 是在执行了主操作以后，直接call的AOF的方法来进行执行的，而重写过程是由<strong>后台子进程bgrewriteaof</strong>来完成的，是为了避免阻塞主线程，导致数据库性能的下降</p></li><li><p>重写的整个流程</p><ul><li><p>一处拷贝</p><ul><li>每次执行重写的时候，主线程fork到bgrewriteaof子进程</li><li>主线程的内存会被拷贝一份到bgrewriteaof子进程当中，其中会包含数据库的最新数据</li><li>然后该子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志</li></ul></li><li><p>两处日志</p><ul><li><p>主线程当中的AOF日志</p><ul><li>但有新的操作进入，Redis会将该操作写到AOF日志缓冲区</li><li>这样即使宕机，AOF日志的操作仍齐全，可以用来做恢复</li></ul></li><li><p>AOF重写日志</p><ul><li><p>该操作同时也会被写入到重写日志的缓冲区</p></li><li><p>等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以<strong>用新的 AOF 文件替代旧文件</strong>了。</p><p><img src="https://i.loli.net/2020/12/29/6vco3pLJNDBwU52.png" alt="AOF重写缓冲"></p></li></ul></li><li><p>如何解决在AOF重写过程当中数据库新的更新导致的服务器当前的数据库状态和重写后AOF文件所保存的数据库状态不一致的问题？？</p><ul><li>AOF重写缓冲区会在服务器创建了子进程之后开始使用</li><li>当redis服务器执行一个写命令之后，它会同时将其发给AOF缓冲区还有AOF重写缓冲区</li><li>当子进程完成了AOF重写工作之后，会向父进程发出信号，父进程接收到以后，会调用一个信号处理函数，而后：<ul><li>将AOF重写缓冲区中的所有内容写入到新AOF文件里</li><li>对新的AOF文件改名，覆盖现有的AOF文件，完成新旧两个AOF文件的替换</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="3-3-AOF-日志重写过程当中的阻塞风险"><a href="#3-3-AOF-日志重写过程当中的阻塞风险" class="headerlink" title="3.3 AOF 日志重写过程当中的阻塞风险"></a>3.3 AOF 日志重写过程当中的阻塞风险</h2><ul><li>Fork子进程的过程<ul><li>fork并不会一次性拷贝所有内存数据给子进程，采用的是操作系统提供的copy on write机制<ul><li>copy on write机制就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞的问题<ul><li>fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会<strong>把触发的异常的页复制一份</strong>，于是父子进程各自持有独立的一份。</li></ul></li></ul></li><li>fork子进程需要先拷贝进程必要的数据结构<ul><li>拷贝内存页表 — 即虚拟内存和物理内存的映射索引表</li><li>这个拷贝过程会消耗大量的CPU资源，并且拷贝完成之前整个进程是会阻塞的</li><li>阻塞时间取决于整个实例的内存大小<ul><li>实例越大，内存页表也越大，fork阻塞时间就会越久</li></ul></li></ul></li><li>在完成了拷贝内存页表之后，子进程和父进程指向的是相同的内存地址空间<ul><li>这个时候虽然产生了子进程，但是并没有申请和父进程相同的内存大小</li><li>真正的内存分离是<strong>在写发生的时候，这个时候才会真正拷贝内存的数据</strong></li></ul></li></ul></li><li>AOF重写过程中父进程产生写入的过程<ul><li>Fork出的子进程当前状态是指向了和父进程相同的内存地址空间，这个时候子进程就可以执行AOF重写，将内存中的所有数据写入到AOF文件里</li><li>但是同时父进程仍然会有流量写入<ul><li>如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离</li><li>父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险</li><li>如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间</li></ul></li></ul></li></ul><h2 id="3-4-AOF重写日志为什么不共享AOF本身的日志？"><a href="#3-4-AOF重写日志为什么不共享AOF本身的日志？" class="headerlink" title="3.4 AOF重写日志为什么不共享AOF本身的日志？"></a>3.4 AOF重写日志为什么不共享AOF本身的日志？</h2><p>AOF重写不复用AOF本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果AOF重写过程中失败了，那么原本的AOF文件相当于被污染了，无法做恢复使用。所以Redis AOF重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的AOF文件产生影响。等重写完成之后，直接替换旧文件即可</p><h2 id="3-5-如何触发AOF重写？"><a href="#3-5-如何触发AOF重写？" class="headerlink" title="3.5 如何触发AOF重写？"></a>3.5 如何触发AOF重写？</h2><p>有两个配置项在控制AOF重写的触发时机：</p><ol><li>auto-aof-rewrite-min-size: 表示运行AOF重写时文件的最小大小，默认为64MB</li><li>auto-aof-rewrite-percentage: 这个值的计算方法是：当前AOF文件大小和上一次重写后AOF文件大小的差值，再除以上一次重写后AOF文件大小。也就是当前AOF文件比上一次重写后AOF文件的增量大小，和上一次重写后AOF文件大小的比值。</li></ol><p>AOF文件大小同时超出上面这两个配置项时，会触发AOF重写。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://time.geekbang.org/column/article/271754">https://time.geekbang.org/column/article/271754</a></li><li><a href="https://juejin.cn/post/6844903702373859335">https://juejin.cn/post/6844903702373859335</a> </li><li>Redis设计与实现</li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis IO 模型</title>
      <link href="/Redis-IO-%E6%A8%A1%E5%9E%8B/"/>
      <url>/Redis-IO-%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis-IO-模型"><a href="#Redis-IO-模型" class="headerlink" title="Redis IO 模型"></a>Redis IO 模型</h1><blockquote><p>为什么单线程的Redis会那么快？</p></blockquote><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>这里的单线程主要指Redis的网络IO和键值对读写是由一个线程来完成的，而Redis的其他功能，比如持久化，异步删除，集群数据同步等，是由额外的线程执行的。</p><h1 id="2-为什么要使用单线程？"><a href="#2-为什么要使用单线程？" class="headerlink" title="2. 为什么要使用单线程？"></a>2. 为什么要使用单线程？</h1><ul><li><p>使用多线程的开销</p><ul><li><p>使用多线程，一定程度上可以增加系统的吞吐率/ 拓展性</p></li><li><p>但是值得注意的是多线程本身有开销，并不是线程增多吞吐率会线性增长的。达到了某个线程数之后，系统吞吐率的增长就会开始迟缓了，有时甚至会出现下降的情况</p><p><img src="https://i.loli.net/2020/12/24/UNVLxyIRokWmjTQ.png" alt="吞吐率Metrics"></p><p>吞吐率随着线程数增长的变化</p></li><li><p>出现这种情况的原因在于</p><ul><li>系统中通常会存在被<strong>多线程同时访问的共享资源</strong> — 比如一个共享的数据结构</li><li>当有多个线程要修改这个共享资源的时候，为了保证共享资源的正确性，就需要有额外的机制进行保证。这会带来额外的开销</li></ul></li></ul></li><li><p>Redis采用单线程就是希望能够避免这种共享资源放锁的情况</p><ul><li>而且CPU往往不是Redis的瓶颈，瓶颈很可能是机器内存或者网络带宽</li></ul></li></ul><h1 id="3-单线程Redis是如何实现低延时的"><a href="#3-单线程Redis是如何实现低延时的" class="headerlink" title="3. 单线程Redis是如何实现低延时的"></a>3. 单线程Redis是如何实现低延时的</h1><ul><li>High Level Takeaway<ul><li>内存上完成操作</li><li>高效的数据结构</li><li>多路复用机制 — 网络IO能够并发处理大量的客户端请求</li></ul></li></ul><h2 id="3-1-基本IO模型和阻塞点"><a href="#3-1-基本IO模型和阻塞点" class="headerlink" title="3.1  基本IO模型和阻塞点"></a>3.1  基本IO模型和阻塞点</h2><p>以前面的SimpleKV为例，为了处理一个Get请求，数据库需要：</p><ol><li>监听客户端请求(bind/ listen)</li><li>和客户端建立连接 (accept)</li><li>从socket中读取请求(recv)</li><li>解析客户端发送请求(parse)</li><li>根据请求类型读取键值数据(get)</li><li>从客户端返回结果，即向socket中写回数据(send)</li></ol><p><img src="https://i.loli.net/2020/12/24/1pFsDaMO452fGkQ.png" alt="处理IO流程"></p><p>Get请求处理示意图</p><p>在上述的整个过程当中，如果Redis监听到客户端请求，但没有成功建立连接的时候，<strong>会阻塞在accept函数上，导致其他的客户端无法建立连接</strong>。这种基本IO模型效率会非常低，因为是阻塞式的，任何一个请求出现了任何一个问题，都会导致其他的请求无法成功完成。</p><h2 id="3-2-非阻塞模式"><a href="#3-2-非阻塞模式" class="headerlink" title="3.2 非阻塞模式"></a>3.2 非阻塞模式</h2><p>Socket网络模型的非阻塞模式体现在不同操作调用后会<strong>返回不同的套接字类型</strong>。socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。</p><p>这样子可以实现非阻塞，值得注意的是我们需要一些机制来监听套接字，有数据到达的时候再通知数据库线程</p><h2 id="3-3-基于多路复用的高性能I-O模型"><a href="#3-3-基于多路复用的高性能I-O模型" class="headerlink" title="3.3  基于多路复用的高性能I/O模型"></a>3.3  基于多路复用的高性能I/O模型</h2><ul><li>是什么<ul><li>指让一个线程能够处理多个IO流</li><li>select epoll机制<ul><li>在内核中，存在多个监听套接字和已连接套接字</li><li>内核会一直监听这些套接字上的连接请求或者数据请求</li></ul></li></ul></li><li>为什么使用I/O多路复用这种技术<ul><li>解决单线程下阻塞操作的问题</li></ul></li><li>如何实现的<ul><li>select epoll方法同时监控多个文件描述符FD的读写情况，当某些FD可读/ 可写的时候，该方法就会返回可读/ 写的FD个数<br><a href="https://cloud.tencent.com/developer/article/1639569">IO多路复用：Redis中经典的Reactor设计模式</a><ul><li>将用户Socket对应的FD注册进epoll，然后epoll告诉那些需要进行读写操作的socket，只处理那些活跃的，有变化的socket FD</li></ul></li></ul></li></ul><p><a href="https://draveness.me/redis-io-multiplexing/">https://draveness.me/redis-io-multiplexing/</a></p><p><a href="https://cloud.tencent.com/developer/article/1639569">https://cloud.tencent.com/developer/article/1639569</a></p><p><a href="https://blog.csdn.net/u014590757/article/details/79860766">https://blog.csdn.net/u014590757/article/details/79860766</a></p><ul><li><p>一个线程处理多个IO流 — select / epoll机制</p><p>  <img src="https://i.loli.net/2020/12/24/QUKfj9ExTgy4tMN.png" alt="select/ epoll机制流程"></p><p>  epoll机制</p><ul><li><p>允许内核中，同时存在多个监听套接字和已连接套接字</p></li><li><p>内核会一直监听这些套接字上的连接请求或数据请求</p></li><li><p>一旦有请求到达，就会交给Redis线程处理</p><p><img src="https://i.loli.net/2020/12/24/4Cp7TQMZ3csAUIm.png" alt="epoll过程"></p><p>多路复用全程</p></li></ul></li><li><p>select/ epoll 一旦检测到FD上有请求到达，就会触发相应的事件</p><ul><li>事件会被放到一个事件队列，Redis单线程对该事件队列不断进行处理</li></ul></li></ul><h2 id="3-3-单线程处理的性能瓶颈"><a href="#3-3-单线程处理的性能瓶颈" class="headerlink" title="3.3 单线程处理的性能瓶颈"></a>3.3 单线程处理的性能瓶颈</h2><p>1、任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：</p><p>a、操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；</p><p>b、使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；</p><p>c、大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；</p><p>d、淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；</p><p>e、AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；</p><p>f、主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；</p><p>2、并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。</p><p>针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。</p><p>针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。</p>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis数据结构</title>
      <link href="/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
      <url>/Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis数据结构"><a href="#Redis数据结构" class="headerlink" title="Redis数据结构"></a>Redis数据结构</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>Redis的快速除了基于内存的原因以外，另外一个是在其数据结构上的操作执行的很快。这里会走一遍Redis的现有数据结构，总结其各自的特点，Redis的数据类型和其底层数据结构的对应关系。</p><p><img src="https://i.loli.net/2021/07/03/L6sH52KacFyROMf.png" alt="Redis数据类型和底层数据结构对应关系"></p><ul><li>Redis底层共有6中基本数据结构，其有着不同的和Redis的数据类型的对应</li><li>List, Hash, Sorted Set, 以及Set都有两种实现结构</li></ul><h1 id="2-键值之间的对应关系如何组织"><a href="#2-键值之间的对应关系如何组织" class="headerlink" title="2. 键值之间的对应关系如何组织"></a>2. 键值之间的对应关系如何组织</h1><h2 id="2-1-全局哈希表"><a href="#2-1-全局哈希表" class="headerlink" title="2.1 全局哈希表"></a>2.1 全局哈希表</h2><ul><li>Redis使用一个哈希表来保存所有的键值对</li><li>一个哈希表由多个哈希桶组成，每个哈希桶保存了键值对数据</li><li>哈希桶当中的entry元素这能够保存的是key和value的指针，分别指向实际的键值</li></ul><p><img src="https://i.loli.net/2021/07/03/tXTca4hIin1zNyH.png" alt="全局哈希表"></p><ul><li>访问流程为<ul><li>计算键的哈希值</li><li>访问到对应的哈希桶</li><li>根据哈希桶来找到key和value的地址</li></ul></li><li>为什么需要哈希桶？<ul><li>因为值的底层实现会是不一样的，这样子哈希桶所占内存空间是整齐且可控的</li><li>然后通过指针来找到在内存当中的具体地址</li><li>这个时候value 是可以分散的放置在内存块当中的</li></ul></li></ul><h2 id="2-2-哈希表的冲突问题"><a href="#2-2-哈希表的冲突问题" class="headerlink" title="2.2 哈希表的冲突问题"></a>2.2 哈希表的冲突问题</h2><ul><li>哈希冲突不可避免，即两个key的哈希值和哈希桶计算对应关系的时候，落到了同一个哈希桶当中了</li><li>解决方式<ul><li>短期解决方案<ul><li>链式哈希<ul><li>同一个哈希桶中多个元素用一个链表来保存，依次用指针连接</li><li>注意新的元素会加到头上</li></ul></li><li>存在的问题<ul><li>当哈希冲突链变得过长，查找速度会退化，无法实现O(1)了</li></ul></li></ul></li><li>中长期解决方案<ul><li>rehash  —→ 增加现有的哈希桶数量<ul><li>是逐渐增多的entry在更多的桶之间分散保存</li></ul></li></ul></li></ul></li></ul><h2 id="2-3-哈希表Rehash策略"><a href="#2-3-哈希表Rehash策略" class="headerlink" title="2.3 哈希表Rehash策略"></a>2.3 哈希表Rehash策略</h2><ul><li><p>整体流程</p><ul><li>首先Redis默认有两个全局哈希表</li><li>当你插入数据的时候，默认使用哈希表1， 此时哈希表2没有被分配空间</li><li>随着数据增多，Redis开始执行rehash<ul><li>给哈希表2分配更大的空间，例如是1的两倍</li><li>将哈希表1中的数据重新映射并拷贝到哈希表2当中<ul><li>这一步会涉及到大量的数据拷贝，会造成Redis线程阻塞</li></ul></li><li>释放哈希表1的空间</li></ul></li><li>另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表</li></ul></li><li><p>渐进式哈希</p><ul><li>是为了解决在做哈希表的复制过程当中，可能造成的线程阻塞问题</li><li>一次处理分成多次，处理请求的时候顺带着更新的哈希表2当中</li><li>rehash的整体流程<ol><li>为 <code>ht[1]</code> 分配空间，让字典同时持有 <code>ht[0]</code> 和 <code>ht[1]</code> 两个哈希表。</li><li>在字典中维持一个索引计数器变量 <code>rehashidx</code> ，并将它的值设置为 <code>0</code> ，表示 rehash 工作正式开始。</li><li>在 rehash 进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将 <code>ht[0]</code> 哈希表在 <code>rehashidx</code> 索引上的所有键值对 rehash 到 <code>ht[1]</code> ，当 rehash 工作完成之后，程序将 <code>rehashidx</code> 属性的值增 <code>1</code></li><li>随着字典操作的不断执行，最终在某个时间点上，<code>ht[0]</code> 的所有键值对都会被 rehash 至 <code>ht[1]</code> ，这时程序将 <code>rehashidx</code> 属性的值设为 <code>1</code> ，表示 rehash 操作已完成。</li></ol></li><li>在渐进式哈希没有完成的时候，会同时所使用 <code>ht[0]</code> 还有 <code>ht[1]</code> 两个哈希表<ul><li>delete find update等操作都会在两个哈希表上进行</li><li>先在 <code>ht[0]</code> 然后再在 <code>ht[1]</code></li><li>而对于添加操作，会一律被保存到 <code>ht[1]</code></li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2021/07/03/pGzqNjfegolP7Lt.png" alt="渐进式哈希的实现"></p><h1 id="3-值的底层实现"><a href="#3-值的底层实现" class="headerlink" title="3. 值的底层实现"></a>3. 值的底层实现</h1><h2 id="3-1-简单动态字符串"><a href="#3-1-简单动态字符串" class="headerlink" title="3.1 简单动态字符串"></a>3.1 简单动态字符串</h2><h3 id="3-1-1-什么是简单动态字符串？"><a href="#3-1-1-什么是简单动态字符串？" class="headerlink" title="3.1.1 什么是简单动态字符串？"></a>3.1.1 什么是简单动态字符串？</h3><ul><li>Simple Dynamic String — SDS</li><li>Redis需要一个可以被修改的字符串值<ul><li>利用SDS来做键值</li><li>也会被用来做缓冲区<ul><li>AOF缓冲区</li><li>客户端状态下的输入缓冲区</li></ul></li></ul></li><li>定义</li></ul><pre><code class="jsx">struct sdshrd &#123;    // 计算buf数组已经使用的字节的数量    int len;    // 记录buf数组未使用的字节的数量    int free;    // 字节数组，用来保存字符串    char buf[];&#125;</code></pre><p><img src="https://i.loli.net/2021/07/03/ALkWVo5jDeX1fyY.png" alt="简单动态字符串的实现"></p><h3 id="3-1-2-为什么需要SDS？"><a href="#3-1-2-为什么需要SDS？" class="headerlink" title="3.1.2 为什么需要SDS？"></a>3.1.2 为什么需要SDS？</h3><ul><li>相比于常规string的优势在于：<ul><li>常数复杂度获取字符串长度<ul><li>有len字段</li><li>设置和更新长度是在API执行过程当中自动完成的</li></ul></li><li>杜绝了缓冲区溢出<ul><li>C字符串不会记录自身长度，容易造成缓冲区溢出—buffer overflow</li><li>可能造成一些数据意外被修改</li><li>而SDS的空间分配策略可以杜绝发生溢出的可能性<ul><li>API会检测free标注的大小</li><li>如果不够，那么就会进行扩展</li></ul></li></ul></li><li>减少了内存重分配次数<ul><li>在C里面如果你做增加或者删除的操作，都会涉及内存重分配</li></ul></li></ul></li><li>空间优化策略<ul><li>空间预分配<ul><li>当需要扩展的时候，程序不仅为SDS分配修改所必须的空间，还会为SDS分配额外的未使用空间</li></ul></li><li>惰性空间释放<ul><li>缩短的时候并不立即使用内存重分配来回收缩短后多出来的字节</li><li>使用free属性将这些字节的数量记录起来，并等待将来使用</li></ul></li></ul></li><li>使用SDS的很大的一个好处在于相对于String  减少了内存开销  避免了因为大内存Redis实例，生成RDB导致响应变慢的问题 </li></ul><h3 id="3-1-3-SDS的内存开销"><a href="#3-1-3-SDS的内存开销" class="headerlink" title="3.1.3 SDS的内存开销"></a>3.1.3 SDS的内存开销</h3><ul><li><p>案例</p><ul><li>开发一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片在存储系统中保存时的 ID（可以直接叫作图片存储对象 ID）。同时，还要能够根据图片 ID 快速查找到图片存储对象 ID。</li><li>用10位数来表示图片ID和图片存储对象ID   是一个键 + 单值的模式</li></ul></li><li><p>方案一</p><ul><li><p>使用String 作为entry来保存数据 — 发现String保存数据时消耗的内存空间较多</p></li><li><p>一个键值对需要使用64字节的原因</p><ul><li><p>记录基准数据  两个8字节的long类型</p></li><li><p>额外的内存空间记录数据长度，空间使用  — 元数据</p></li><li><p>一个SDC包括三部分的数据</p><ul><li>buf — 字节数组，保存实际数据</li><li>len — 4字节，表示buf已用长度</li><li>alloc — 4字节，表示buf的实际分配长度，一般大于len</li></ul></li><li><p>RedisObject</p><ul><li>统一记录当前数据类型的元数据 — 访问时间，引用次数等</li><li>RedisObject 包括<ul><li>8字节元数据</li><li>8字节指针 — 指向SDS 、</li></ul></li></ul></li><li><p>根据SDS长度的不同编码方式</p><p>  <img src="https://i.loli.net/2021/08/09/ZeP7RkmsQxhpb5w.png" alt="SDS编码方式"></p></li></ul></li><li><p>上述的RedisObject + SDS 本身会占据32字节的空间，然后Redis会使用一个全局哈希表保存所有键值对</p><ul><li>哈希表的每一项是一个dickEntry结构体，用来指向一个键值对</li><li>dictEntry有三个8字节指针，分别指向key, value, dictEntry</li><li>24字节，然后Redis使用jemalloc来分配内存，申请24  会发给32字节，2的指数</li></ul></li></ul></li><li><p>方案二</p><ul><li>使用集合类型来保存数据，使用二级编码的方式，实现用集合类型保存单值键值对，以此减少Redis实例的内存空间消耗</li><li>可以使用压缩列表来节省对于内存的使用<ul><li>节省内存的原因<ul><li>使用一系列连续的entry保存数据，元数据包括<ul><li>prev_len<ul><li>大小可为1字节或者5字节</li><li>根据上一个entry的长度是否小于254字节来进行判定</li></ul></li><li>len<ul><li>表示自身长度  4字节</li></ul></li><li>encoding<ul><li>编码方式  1字节</li></ul></li><li>content<ul><li>保存实际数据</li></ul></li></ul></li><li>因为连续保存，所以不用额外的指针了</li><li>这样每个entry只要 1 + 4 + 1 + 8 = 14, 只需要16字节</li><li>另外，可以节省dictEntry的开销，因为原先的话使用String类型，一个键值对就是一个dictEntry，但采用集合类型的话，一个key就对应一个集合的数据，节省了大量dictEntry的内存</li></ul></li></ul></li><li>如何用集合类型保存单值的键值对？<ul><li>采用基于Hash类型的二级编码方法<ul><li>将一个单值的数据拆分成两部分<ul><li>前一部分作为Hash集合的key</li><li>后一部分作为Hash集合的value的key值</li></ul></li><li>注意这里因为我们想要利用的是压缩列表来节省空间，因为对于Hash类型，底层是有两种数据结构的： 压缩列表以及哈希表<ul><li>当超过一定阈值的时候，就会从压缩列表膨胀到哈希表</li><li>因此在这里我们需要注意后一部分key的长度选择  比如选择3位，然后设置 <code>hash-max-ziplist-entries</code> 这个参数，来保证我们能够使用压缩列表，而且性能也不会受到很大影响</li></ul></li></ul></li></ul></li><li>使用ziplist方案的一些问题<ul><li>在查询指定元素的时候，都要遍历整个ziplist来找到指定的元素；因此ziplist max entry的数量不能放到过大，否则查询性能就会下降的比较厉害了</li><li>因为每个元素都是紧凑排列的，而且每个元素存储了上一个元素的长度；因此如果修改其中一个元素超过一定大小的时候，就会引发多个元素的联级调整，会引发性能问题</li><li>设置过期时间变得非常困难，因为只能整个key过期，或者业务层单独维护每个元素过期删除的逻辑</li><li>因此选用这个方案意味着你希望将Redis作为数据库使用，需要保证可靠性 — 主从备份+备份</li><li>使用String作为value的话可以将Redis作为缓存来使用，每个key设置过期时间，还可以设置maxmemory和淘汰策略，以此控制整个实例的内存上限</li></ul></li></ul></li></ul><h2 id="3-2-双向链表"><a href="#3-2-双向链表" class="headerlink" title="3.2 双向链表"></a>3.2 双向链表</h2><h3 id="3-2-1-概述"><a href="#3-2-1-概述" class="headerlink" title="3.2.1 概述"></a>3.2.1 概述</h3><ul><li>链表<ul><li>可以提供高效的节点重排能力，</li><li>顺序性的节点访问方法</li></ul></li><li>什么时候会被使用<ul><li>当一个列表包含了数量比较多的元素</li><li>列表当中包含的元素都是比较长的字符串</li></ul></li></ul><h3 id="3-2-2-链表和链表节点的实现"><a href="#3-2-2-链表和链表节点的实现" class="headerlink" title="3.2.2 链表和链表节点的实现"></a>3.2.2 链表和链表节点的实现</h3><pre><code class="jsx">typedef struct listNode &#123;    struct listNode *prev;    struct listNode *next;    void *value;&#125;listNode;</code></pre><pre><code class="jsx">typedef struct list &#123;    listNode *head;    listNode *tail;    // 链表包含的节点数量    unsigned long len;    // 节点值复制函数    void *(*dup)(void *ptr);    // 节点值释放函数    void (*free) (void *ptr);    // 节点值对比函数    void (*match)(void *ptr, void *key);&#125;</code></pre><ul><li><p>下方是由一个list结构和多个listNode结构组成的链表</p><p>  <img src="https://i.loli.net/2021/07/03/uJoTHhdLkr4qlAc.png" alt="list + multi listNodes"></p></li></ul><h2 id="3-3-哈希表-字典"><a href="#3-3-哈希表-字典" class="headerlink" title="3.3 哈希表(字典)"></a>3.3 哈希表(字典)</h2><h3 id="3-3-1-什么是字典"><a href="#3-3-1-什么是字典" class="headerlink" title="3.3.1 什么是字典"></a>3.3.1 什么是字典</h3><ul><li>用于保存键值对的数据结构</li><li>Redis自己构建了字典的实现</li><li>哈希表当中可以有多个哈希表节点，而每个哈希表节点就保存了字典当中的一个键值对</li></ul><h3 id="3-3-2-dictht-—-哈希表数组的实现"><a href="#3-3-2-dictht-—-哈希表数组的实现" class="headerlink" title="3.3.2 dictht — 哈希表数组的实现"></a>3.3.2 dictht — 哈希表数组的实现</h3><pre><code class="jsx">typedef struct dictht &#123;    // 哈希表数组    dictEntry **table;    // 哈希表大小    unsigned long size;    // 哈希表大小掩码，用于计算索引值    unsigned long sizemask;    // 已有节点数量    unsigned long used;&#125; dictht;</code></pre><ul><li><p>table是一个数组，数组的每个元素都指向dictEntry结构的指针</p><ul><li>每个dictEntry结构保存着一个键值对</li></ul></li><li><p>size记录哈希表大小</p></li><li><p>used记录目前已有节点的数量</p></li><li><p>sizemask总是等于size - 1</p><ul><li><p>这个属性和哈希值一起决定了一个键应该被放到table数组的哪个索引上面</p><p>  <img src="https://i.loli.net/2021/07/03/3QTOZK1YwX6VyfG.png" alt="dictht + dictEntry"></p></li></ul></li></ul><h3 id="3-3-3-哈希表节点的实现"><a href="#3-3-3-哈希表节点的实现" class="headerlink" title="3.3.3 哈希表节点的实现"></a>3.3.3 哈希表节点的实现</h3><ul><li>而哈希表节点是这么实现的<ul><li>值得注意的是有指向下一个节点的指针，是为了解决键的冲突问题</li></ul></li></ul><pre><code class="jsx">typedef struct dictEntry &#123;    void *key;    union &#123;        void *val;        unit64_tu64;        int64_ts64;    &#125; v;    // 指向下一个哈希表节点    struct dictEntry *next;&#125; dictEntry;</code></pre><h3 id="3-3-4-哈希表整体实现"><a href="#3-3-4-哈希表整体实现" class="headerlink" title="3.3.4 哈希表整体实现"></a>3.3.4 哈希表整体实现</h3><pre><code class="jsx">typedef struct dict &#123;    dictType *type;    void *privatedata;    dictht ht[2];    // rehash索引  当rehash停止了以后，值为-1     in rehashidx;&#125;</code></pre><ul><li>type和privatedata是针对不同类型的键值对，为创建多态字典而设置的</li><li>ht是一个大小为2的数组，都是哈希表<ul><li>一般只用ht[0]的哈希表</li><li>只有在做rehash的时候用ht[1]</li></ul></li><li>rehashidx 记录当前的进度</li><li>hashfunction<ul><li>使用MurmurHash2算法<ul><li>特点<ul><li>即使输入的键是有规律的，算法仍能给出一个很好的随机分布性</li><li>算法的计算速度也非常快</li></ul></li></ul></li></ul></li></ul><h2 id="3-4-跳表"><a href="#3-4-跳表" class="headerlink" title="3.4 跳表"></a>3.4 跳表</h2><h3 id="3-4-1-什么是跳表"><a href="#3-4-1-什么是跳表" class="headerlink" title="3.4.1 什么是跳表"></a>3.4.1 什么是跳表</h3><ul><li>为了解决链表的不足的<ul><li>有序链表只能逐一查找元素，导致操作起来非常缓慢</li></ul></li><li>跳表<ul><li>在链表的基础上增加了多级索引，通过索引位置的跳转，实现数据的快速定位</li><li>是有序集合的底层实现之一</li><li>支持平均O(logN), 最坏O(N)复杂度的节点查找，还可以通过顺序性操作来批量处理节点</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/03/YgFw2MkjmpSvf7P.png" alt="跳表的实现"></p><h3 id="3-4-2-跳表的实现"><a href="#3-4-2-跳表的实现" class="headerlink" title="3.4.2 跳表的实现"></a>3.4.2 跳表的实现</h3><ul><li><p>由两大部分构成</p><ul><li><p>zskiplist 用来保存跳跃表节点的相关信息</p><ul><li>下图最左侧的方框</li><li>属性包括<ul><li>header — 指向跳跃表的表头节点</li><li>tail — 指向跳跃表的表尾节点</li><li>level — 记录当前跳跃表内，层数最大的那个节点的层数</li><li>length — 记录跳跃表的长度</li></ul></li></ul></li><li><p>zskiplistNode用于表示跳跃表单个节点</p><ul><li><p>属性包括</p><ul><li>level<ul><li>前进指针<ul><li>用于访问其他结点</li></ul></li><li>跨度<ul><li>记录了前进指针所指向节点和当前节点的距离</li><li>累加可以用来记录某个节点在跳表当中的排位</li></ul></li></ul></li><li>backward 后退指针<ul><li>指向位于当前节点的前一个节点</li><li>后退指针在程序从表尾向表头遍历的时候使用</li></ul></li><li>score</li><li>obj 成员对象<ul><li>是一个指针，指向一个字符串对象，</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/03/blB24Gdk5MzXIhH.png" alt="跳表实现"></p></li></ul></li></ul></li></ul><pre><code class="jsx">typedef struct zskiplistNode &#123;    struct zskiplistLevel &#123;        struct zskiplistNode *forward;         unsigned int span;    &#125; level[];    struct zskiplistNode *backward;    double score;    robj *obj;&#125; zskiplistNode;</code></pre><pre><code class="jsx">typedef struct zskiplist &#123;    struct zskiplistNode *header, *tail;    unsigned long length;     int level;&#125;</code></pre><h2 id="3-5-整数数组"><a href="#3-5-整数数组" class="headerlink" title="3.5 整数数组"></a>3.5 整数数组</h2><h3 id="3-5-1-什么是整数数组"><a href="#3-5-1-什么是整数数组" class="headerlink" title="3.5.1 什么是整数数组"></a>3.5.1 什么是整数数组</h3><ul><li>是set的底层实现之一，当一个集合只包含整数值元素，并且这个集合元素数量不多，Redis就会用整数集合作为集合键的底层实现</li></ul><h3 id="3-5-2-整数数组的实现"><a href="#3-5-2-整数数组的实现" class="headerlink" title="3.5.2 整数数组的实现"></a>3.5.2 整数数组的实现</h3><pre><code class="jsx">typedef struct intset &#123;    uinit32_t encoding;    uinit32_t length;  int8_t contents[];&#125;</code></pre><ul><li>encoding<ul><li>记录编码方式<ul><li>INTSET_ENC_INT16</li><li>INTSET_ENC_INT32</li><li>INTSET_ENC_INT64</li></ul></li></ul></li><li>length<ul><li>记录集合包含的元素数量</li></ul></li><li>contents<ul><li>数组，是其底层实现</li><li>整数数组的每个原色都是contents数组的一个item</li><li>各个项在数组中按照值的大小从小到大有序排列，数组中不包含任何重复项</li></ul></li></ul><h3 id="3-5-3-整数数组的升级和降级"><a href="#3-5-3-整数数组的升级和降级" class="headerlink" title="3.5.3 整数数组的升级和降级"></a>3.5.3 整数数组的升级和降级</h3><ul><li>什么时候需要升级？<ul><li>当添加一个新元素，且新元素的类型比整数集合现有的所有元素的类型都要长的时候</li></ul></li><li>如何进行升级<ul><li>根据新元素的类型，扩展整数集合底层数组的空间大小，并且为新元素分配空间</li><li>将底层数组现有所有元素都转换成和新元素相同的类型，并将类型转换后的元素放置到正确的位上</li><li>放置过程需要保证顺序不变</li><li>新元素添加到底层数组当中</li></ul></li><li>整数数组不支持降级！</li></ul><h2 id="3-6-压缩列表"><a href="#3-6-压缩列表" class="headerlink" title="3.6 压缩列表"></a>3.6 压缩列表</h2><h3 id="3-6-1-什么是压缩列表"><a href="#3-6-1-什么是压缩列表" class="headerlink" title="3.6.1 什么是压缩列表"></a>3.6.1 什么是压缩列表</h3><ul><li>类似一个数组<ul><li>每一个元素都对应保存一个数据</li><li>表头有三个字段<ul><li>zlbytes — 列表长度，整个压缩列表占用的字节数</li><li>zltail — 列表尾的偏移量</li><li>zllen — 列表中entry个数</li></ul></li><li>表尾一个字段<ul><li>zlend — 表示列表的结束</li></ul></li></ul></li><li>压缩列表是Redis为了节约内存而开发的，由一系列特殊编码的连续内存块组成的顺序型数据结构<ul><li>一个压缩列表可以包含任意多个节点</li><li>每个节点可以保存一个字节数组或者一个整数值</li><li>比起双端链表来说，更节约内存，而且内存当中连续的保存的方式，能更快的载入到缓存当中</li><li>随着列表对象包含的元素越来越多，使用压缩列表的优势会逐渐消失，对象就会从底层的压缩列表的实现转向双端链表上面</li></ul></li></ul><h3 id="3-6-2-压缩列表的实现"><a href="#3-6-2-压缩列表的实现" class="headerlink" title="3.6.2 压缩列表的实现"></a>3.6.2 压缩列表的实现</h3><ul><li><p>压缩列表节点的构成</p><ul><li><p>previous_entry_length</p><ul><li><p>字节为单位</p></li><li><p>记录压缩列表中前一个节点的长度</p></li><li><p>可以借此通过指针运算，从当前节点的起始地址来计算出前一个节点的起始地址</p></li><li><p>压缩列表的从表尾向表头遍历的操作就是使用这一原理实现的</p><p>  <img src="https://i.loli.net/2021/07/03/743T9ocpMWeksxH.png" alt="压缩列表从尾端向表头的遍历"></p></li></ul></li><li><p>encoding</p><ul><li>记录了节点的content属性所保存的数据类型和长度</li></ul></li><li><p>content</p><ul><li>负责保存节点的值<ul><li>可以使一个字节数组或者一个整数</li></ul></li></ul></li></ul></li></ul><h3 id="3-6-3-压缩列表的连锁更新"><a href="#3-6-3-压缩列表的连锁更新" class="headerlink" title="3.6.3 压缩列表的连锁更新"></a>3.6.3 压缩列表的连锁更新</h3><ul><li>假设一个原先节点长度小于254字节的增长大于了</li><li>那么原先用一个字节保存的previous_entry_length已然无法保存新的数据了，那么就需要对压缩列表执行空间重分配操作</li><li>连锁更新，最坏情况要对压缩列表执行N次空间重分配操作，而每次空间重分配的最坏复杂度为O(N)  所以连锁更新的最坏复杂度为O(N^2)</li><li>连锁更新出现概率比较低，只有在压缩列表当中恰好有多个连续，长度介于250 和253字节之间的节点的时候</li></ul><h2 id="3-7-对象"><a href="#3-7-对象" class="headerlink" title="3.7 对象"></a>3.7 对象</h2><ul><li>用对象来代表Redis对于底层数据结构的上层抽象<ul><li>字符串</li><li>双向链表</li><li>哈希表</li><li>集合</li><li>有序集合</li></ul></li><li>好处<ul><li>针对不同使用场景，为对象设置多种不同的底层数据结构实现，从而优化对象在不同场景下的使用效率</li><li>Redis对象系统实现了基于引用计数技术的内存回收机制</li><li>当程序不再使用某个对象的时候，这个对象所占用的内存就会被自动释放</li></ul></li></ul><h3 id="3-7-1-对象的实现"><a href="#3-7-1-对象的实现" class="headerlink" title="3.7.1 对象的实现"></a>3.7.1 对象的实现</h3><ul><li>键和值都是对象，都由redisObject结构来实现的<ul><li>type  用于记录对象的类型<ul><li>REDIS_STRING</li><li>REDIS_LIST<br>REDIT_HASH</li><li>REDIS_SET</li><li>REDIS_ZSET</li></ul></li><li>encoding 记录对象所使用的编码<ul><li>即对象试用了什么数据结构的底层实现</li></ul></li></ul></li></ul><pre><code class="jsx">typedef struct redisObject &#123;    unsigned type:4;    unsigned encoding:4;    void *ptr;&#125; robj;</code></pre><h3 id="3-7-2-字符串对象"><a href="#3-7-2-字符串对象" class="headerlink" title="3.7.2 字符串对象"></a>3.7.2 字符串对象</h3><ul><li><p>编码可以是</p><ul><li><p>int</p></li><li><p>raw</p><ul><li><p>当保存一个字符串值，且长度大于32字节</p><p>  <img src="https://i.loli.net/2021/07/03/gbGY6fzD3rF7okB.png" alt="字符串对象的raw编码方式"></p></li></ul></li><li><p>embstr</p><ul><li><p>当字符串值的长度小于等于32字节的时候，会用embstr编码方式</p></li><li><p>embstr介绍</p><ul><li><p>专门用于保存短字符串的优化编码方式</p></li><li><p>通过调用一次内存分配函数来分配一块连续空间，依次包含redisObject和sdshdr两个结构</p><p>  <img src="https://i.loli.net/2021/07/03/G6ozCbK1UkYRO4T.png" alt="字符串对象embstr编码方式"></p></li></ul></li></ul></li></ul></li><li><p>编码类型会在需要的时候进行自动的转换</p></li></ul><h3 id="3-7-3-列表对象"><a href="#3-7-3-列表对象" class="headerlink" title="3.7.3 列表对象"></a>3.7.3 列表对象</h3><ul><li><p>列表对象的编码方式是</p><ul><li><p>ziplist — 使用压缩列表来实现</p><p>  <img src="https://i.loli.net/2021/07/03/DHqScpNEFLiCxO7.png" alt="列表对象的压缩列表编码方式"></p></li><li><p>linkedlist — 使用双向链表来实现</p><p>  <img src="https://i.loli.net/2021/07/03/zndxC5jTAhNY7Ek.png" alt="列表对象的双向链表编码方式"></p></li></ul></li><li><p>注意：在上面的示意图当中，StringObject是做了简化的，相当于我在链表或者压缩列表对象里面嵌入了字符串对象，字符串本身是用的embstr编码方式实现的一个redisObject</p></li><li><p>编码转化规则</p><ul><li>使用ziplist的条件<ul><li>列表对象保存的所有字符串元素的长度都小于64字节</li><li>列表对象保存的元素数量小于512个</li></ul></li><li>条件是可以进行改变的，通过改变config paras:<ul><li><code>list-max-ziplist-value</code></li><li><code>list-max-ziplist-entries</code></li></ul></li></ul></li></ul><h3 id="3-7-4-哈希对象"><a href="#3-7-4-哈希对象" class="headerlink" title="3.7.4 哈希对象"></a>3.7.4 哈希对象</h3><ul><li><p>编码方式</p><ul><li><p>ziplist</p><ul><li><p>每当加新的键值对的时候，会将保存了键的压缩列表节点推入到压缩列表表尾，然后再将保存了值的压缩列表节点推入到压缩列表表尾</p><ul><li><p>保存了同一键值对的两个节点总是紧挨在一起</p></li><li><p>值得注意  用ziplist 来实现哈希，查找是无法做到O(1)的，但同时因为值少，所以影响不会很大  <a href="https://blog.csdn.net/zhoucheng05_13/article/details/79864568">https://blog.csdn.net/zhoucheng05_13/article/details/79864568</a></p></li><li><p>保存键的节点在前，保存值的节点在后</p><p>  <img src="https://i.loli.net/2021/07/03/bOavAyDF7u2KjhU.png" alt="哈希对象的压缩列表编码方式"></p></li></ul></li></ul></li><li><p>hashtable</p><p>  <img src="https://i.loli.net/2021/07/03/5AzFotmNTxdLySB.png" alt="哈希对象的hashtable编码方式"></p></li></ul></li><li><p>编码转换条件</p><ul><li>使用ziplist的条件<ul><li>所有键值对键值字符串长度都小于64字节</li><li>键值对数量小于512个</li></ul></li><li>修改阈值方式<ul><li><code>hash-max-ziplist-value</code></li><li><code>hash-max-ziplist-entries</code></li></ul></li></ul></li></ul><h3 id="3-7-5-集合对象"><a href="#3-7-5-集合对象" class="headerlink" title="3.7.5 集合对象"></a>3.7.5 集合对象</h3><ul><li><p>编码方式有</p><ul><li>intset<ul><li>使用整数集合作为底层实现</li></ul></li><li>hashtable<ul><li>使用自定作为底层实现</li></ul></li></ul></li><li><p>编码转换</p><ul><li>使用intset的条件<ul><li>集合对象保存的所有元素都是整数值</li><li>集合对象保存的元素数量不超过512个</li></ul></li></ul></li></ul><h3 id="3-7-6-有序集合对象"><a href="#3-7-6-有序集合对象" class="headerlink" title="3.7.6 有序集合对象"></a>3.7.6 有序集合对象</h3><ul><li><p>编码方式</p><ul><li><p>ziplist</p><ul><li><p>每个集合元素用两个紧挨在一起的压缩列表节点来进行保存</p></li><li><p>第一个结点保存member</p></li><li><p>第二个节点保存score</p><p>  <img src="https://i.loli.net/2021/07/03/1KvRnXyzwk54eLV.png" alt="有序集合对象的压缩列表编码方式"></p></li></ul></li><li><p>skiplist</p><ul><li><p>包括一个字典还有一个跳跃表</p><ul><li>zs1 按照分值从小到大保存了所有集合元素<ul><li>跳跃表节点的object属性保存了元素的成员</li><li>通过跳跃表 就可以对有序集合进行范围性操作了</li></ul></li><li>而字典创建了成员到分值的映射<ul><li>可以实现O(1)复杂度查找给定成员的分值</li></ul></li></ul><pre><code class="jsx">typedef struct zset &#123;  zskiplist *zs1;  dict *dict;&#125; zset;</code></pre><p><img src="https://i.loli.net/2021/07/03/KeBGYXIasS4JL71.png" alt="有序集合的跳表编码方式"></p></li></ul></li></ul></li><li><p>编码转换</p><ul><li>使用ziplist的条件<ul><li>元素数量小于128个</li><li>有序集合保存的元素成员长度小于64字节</li></ul></li></ul></li></ul><h1 id="4-内存和对象的生命周期"><a href="#4-内存和对象的生命周期" class="headerlink" title="4. 内存和对象的生命周期"></a>4. 内存和对象的生命周期</h1><h2 id="4-1-类型检查"><a href="#4-1-类型检查" class="headerlink" title="4.1 类型检查"></a>4.1 类型检查</h2><ul><li><p>有些指令需要底层的特定的数据结构的实现，所以需要进行类型检查</p></li><li><p>通过redisObject结构的type属性来实现</p><p>  <img src="https://i.loli.net/2021/07/03/F45sjTVhqWSaQfH.png" alt="LLEN类型检查逻辑"></p></li></ul><h2 id="4-2-内存回收"><a href="#4-2-内存回收" class="headerlink" title="4.2 内存回收"></a>4.2 内存回收</h2><ul><li>C语言不具备自动内存回收功能，所以Redis在自己的对象系统当中构建了一个引用计数 reference counting技术实现的内存回收机制</li><li>通过这一机制，程序可以通过跟踪对象的引用计数信息，在适当的时候自动释放对象进行内存回收</li><li>引用计数信息变化的方式<ul><li>创建对象，被初始化为1</li><li>当对象被一个新程序使用，+1</li><li>当对象不再被一个程序使用，-1</li><li>当引用计数值变为0，释放内存</li></ul></li></ul><h2 id="4-3-对象共享"><a href="#4-3-对象共享" class="headerlink" title="4.3 对象共享"></a>4.3 对象共享</h2><ul><li><p>highlight！ 只对包含整数值的字符串对象来进行共享，因为其他的类型的对象验证操作的时间复杂度比较高</p></li><li><p>通过引用计数来实现</p></li><li><p>如果键A使用值100，键B也要使用同样的值</p></li><li><p>那么键B的值指针会指向现在有的键A的值对象</p></li><li><p>然后共享的值对象的引用计数+1</p><p>  <img src="https://i.loli.net/2021/07/03/plCK4RXTqOrID8W.png" alt="SDS整数值对象共享"></p></li></ul><h2 id="4-4-对象的空转时长"><a href="#4-4-对象的空转时长" class="headerlink" title="4.4 对象的空转时长"></a>4.4 对象的空转时长</h2><ul><li>redisObject有个lru属性，来记录这个对象上次被访问的timestamp</li><li>如果服务器占用的内存数超过了设定的maxmemory选项，那么空转时间比较长的那部分键就会优先被服务器释放，从而回收内存</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>极客时间 — Redis核心技术与实战</li><li>《Redis设计与实现》</li><li><a href="http://redisbook.com/preview/dict/incremental_rehashing.html">http://redisbook.com/preview/dict/incremental_rehashing.html</a> </li><li><a href="https://blog.csdn.net/zhoucheng05_13/article/details/79864568">https://blog.csdn.net/zhoucheng05_13/article/details/79864568</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis基本架构</title>
      <link href="/Redis%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/"/>
      <url>/Redis%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis基本架构"><a href="#Redis基本架构" class="headerlink" title="Redis基本架构"></a>Redis基本架构</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>为什么需要Redis</p><ul><li>key value内存数据库</li><li>支持丰富的数据结构，</li><li>性能非常高，可以支持很高的TPS</li></ul></li><li><p>在使用Redis过程中可能遇到的一些问题</p><ul><li>CPU使用方面的问题<ul><li>数据结构的复杂度</li><li>跨CPU核的访问</li></ul></li><li>内存使用方面<ul><li>主从同步和AOF的内存竞争</li></ul></li><li>存储持久化方面<ul><li>SSD上做快照的性能抖动</li></ul></li><li>网络通信方面<ul><li>多实例时的异常网络丢包</li></ul></li></ul></li><li><p>如何进行学习 — 需要系统化</p><ul><li><p>从应用维度和系统维度进行研究</p></li><li><p>分别看其在以下三个方面的表现</p><ul><li><p>高性能</p><ul><li>线程模型</li><li>数据结构</li><li>持久化</li><li>网络框架</li></ul></li><li><p>高可靠</p><ul><li>主从复制</li><li>哨兵机制</li></ul></li><li><p>高可扩展性</p><ul><li><p>数据分片</p></li><li><p>负载均衡</p><p>  <img src="https://i.loli.net/2020/12/20/vKdkl934yUw7pOe.png" alt="Redis系统"></p></li></ul></li></ul></li></ul></li></ul><h2 id="2-如何构建一个键值数据库"><a href="#2-如何构建一个键值数据库" class="headerlink" title="2. 如何构建一个键值数据库"></a>2. 如何构建一个键值数据库</h2><ul><li>目标<ul><li>创建一个叫做SimpleKV的数据库</li></ul></li><li>几个需要思考的问题<ul><li>问题<ul><li>里面会存什么样的数据 (数据模型)</li><li>需要对数据做什么样的操作 (操作接口)</li></ul></li><li>为什么需要思考这种问题？<ul><li>这影响到你认为这个数据库到底能做什么</li><li>譬如如果支持集合，那么对于存储用户信息的一个关系型数据库，我们也可以将用户Id作为Key，剩余信息作为一个集合存储到我们的键值数据库当中<ul><li>这个点很有意思，可以直接将Redis当成一个数据库来使用</li></ul></li><li>接口的定义确定了我们希望使用这个数据库做什么，是简单的get, put操作，还是说相对复杂的聚合型的操作</li></ul></li></ul></li><li>脉络<ul><li>访问框架</li><li>操作模块<ul><li>内存空间分配 — 分配器</li><li>持久化</li></ul></li><li>索引模块</li></ul></li></ul><hr><h2 id="2-1-可以存哪些数据？"><a href="#2-1-可以存哪些数据？" class="headerlink" title="2.1 可以存哪些数据？"></a>2.1 可以存哪些数据？</h2><ul><li>基本数据类型 Key - Value</li><li>希望Value能够支持复杂类型<ul><li>memcache只支持String</li><li>Redis支持String, HashMap, 列表，集合等<ul><li>值得注意的点是不同的数据结构在实际使用的时候会有在性能，空间效率等方面的差异，从而导致不同的value操作之间也会存在差异</li></ul></li></ul></li></ul><h2 id="2-2-可以对数据做什么操作？"><a href="#2-2-可以对数据做什么操作？" class="headerlink" title="2.2 可以对数据做什么操作？"></a>2.2 可以对数据做什么操作？</h2><ul><li>PUT/ SET<ul><li>新写入或者更新一个KV对</li></ul></li><li>GET<ul><li>根据KEY读取相应的VALUE值</li></ul></li><li>DELETE<ul><li>根据KEY删除整个KV对</li></ul></li><li>SCAN<ul><li>根据一段Key的范围返回相应的value值</li></ul></li><li>Tips<ul><li>当一个键值数据库的value类型多样的时候，也需要包含相应的操作接口的</li></ul></li></ul><h2 id="2-3-数据库存储位置"><a href="#2-3-数据库存储位置" class="headerlink" title="2.3 数据库存储位置"></a>2.3 数据库存储位置</h2><ul><li>可选方案<ul><li>内存<ul><li>读写非常快</li><li>访问速度在百ns级别</li><li>潜在风险是一旦断电，所有的数据都会丢失</li></ul></li><li>外存<ul><li>可以避免数据的丢失，但是受限于磁盘的慢速读写（几个ms）键值数据库的整体性能会被拉低</li></ul></li></ul></li><li>考量的因素<ul><li>主要应用场景<ul><li>缓存场景<ul><li>需要能够快速访问但允许丢失 — 可以采用内存保存键值数据</li><li>memcache 和Redis都属于内存键值数据库</li></ul></li></ul></li></ul></li></ul><h2 id="2-4-数据库基本组件"><a href="#2-4-数据库基本组件" class="headerlink" title="2.4 数据库基本组件"></a>2.4 数据库基本组件</h2><ul><li>一个基本的内部结构需要包括<ul><li>访问框架<ul><li>动态库访问</li><li>网络访问框架</li></ul></li><li>操作模块<ul><li>上述的一系列操作 DELETE/PUT/SCAN etc</li></ul></li><li>索引模块</li><li>存储模块</li></ul></li></ul><p><img src="https://i.loli.net/2020/12/20/ILR4uFc73ZVmevP.png" alt="SimpleKV基本内部架构"></p><p>SimpleKV 内部架构</p><ul><li>采用什么访问模式？— 连接层<ul><li>通过函数库调用的方式供外部应用使用<ul><li>比如图片当中的<code>libsimplekv.so</code> 就是通过动态链接库的形式链接到我们的程序当中，来提供键值存储功能<ul><li>在运行的时候载入的包，而不是像静态库一样在编译的时候就和目标代码进行连接</li><li>这样做可以减少对于空间的浪费，解决了静态库对程序的更新，部署和发布带来的麻烦</li><li><a href="https://www.zhihu.com/question/20484931">https://www.zhihu.com/question/20484931</a></li></ul></li></ul></li><li>通过网络框架以Socket通信的形式对外提供键值对操作<ul><li>系统设计上的问题 — 单线程，多线程还是多个进程来进行交互？<strong>IO模型的选择</strong><ul><li>网络连接的处理</li><li>网络请求的解析</li><li>数据存取的处理</li></ul></li></ul></li></ul></li><li>如何定位键值对的位置？<ul><li>需要依赖于键值数据库的索引模块<ul><li>让键值数据库能够根据key找到相应value的存储位置，进而执行操作<ul><li>索引类型<ul><li>哈希表</li><li>B+树</li><li>字典树</li></ul></li><li>Redis选用的是哈希表，是因为保存在内存中，内存的高性能随机访问特性可以很好地与哈希表O(1)的操作复杂度匹配<ul><li>关于Redis值得注意的是它的value支持多种类型，当我们通过索引找到一个key对应的value后，仍然需要从value的复杂结构中进一步找到我们实际需要的数据</li><li>这个的复杂度取决于具体的数据类型</li><li>Redis采用一些高效索引结构作为某些value类型的底层数据结构，可以为Redis实现高性能访问提供良好的支撑</li></ul></li></ul></li></ul></li></ul></li><li>不同操作的具体逻辑是？<ul><li>对于GET/SCAN 操作而言，根据value的存储位置返回value的值即可</li><li>对于PUT操作，需要为新的键值对分配内存空间<ul><li>—&gt; 如何分配内存空间呢？</li><li>比较重要，当我们的value能支持多种类型的时候，那么如何高效使用内存空间就变得尤为重要了</li></ul></li><li>对于DELETE操作，需要删除键值对，并释放相应的内存空间，这个过程由分配器完成</li></ul></li><li>内存分配器<ul><li>采用内存分配器glibc的malloc和free<ul><li>但是键值对因为通常大小不一，glibc分配器在处理随机大小的内存块分配时表现会不太好。一旦保存的键值对数据规模过大，就可能造成较为严重的内存碎片的问题</li></ul></li></ul></li><li>如何实现重启后快速提供服务？<ul><li>持久化功能<ul><li>采用文件形式，将键值数据通过调用本地文件系统的操作接口保存在磁盘上<ul><li>需要考虑什么时候，什么间隔来做从内存到文件的键值数据的保存工作</li></ul></li><li>也可以每一个键值对都进行持久化<ul><li>坏处是因为每次都要写到磁盘里面，性能会受到很大影响</li><li>好处是能确保所有数据更新都会在磁盘里</li></ul></li><li>可以周期性的将内存中的键值数据保存到文件当中，这样就可以避免频繁写盘操作的性能影响<ul><li>潜在的风险就是数据仍然有可能丢失</li></ul></li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2020/12/20/52Hgk6apwXFtzSU.png" alt="SimpleKV与Redis的比较"></p><p>SimpleKV vs Redis</p><ul><li>SimpleKV和Redis的对比<ul><li>Redis通过网络访问，可以作为一个基础性的网络服务来进行访问</li><li>value类型丰富，就带来了更多的操作接口<ul><li>面向列表的LPush/ LPop</li><li>面向集合的SADD</li></ul></li><li>Redis持久化模块支持日志(AOF)和快照(RDB)两种模式</li><li>Redis支持高可靠集群和高可扩展集群</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.usenix.org/conference/atc17/technical-sessions/presentation/xia">HiKV: A Hybrid Index Key-Value Store for DRAM-NVM Memory Systems</a></li><li>极客时间 - Redis核心技术与实战</li><li><a href="https://www.zhihu.com/question/20484931">https://www.zhihu.com/question/20484931</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM垃圾回收</title>
      <link href="/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
      <url>/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="JVM垃圾回收"><a href="#JVM垃圾回收" class="headerlink" title="JVM垃圾回收"></a>JVM垃圾回收</h1><ul><li>内存是如何分配和回收的</li><li>哪些垃圾需要回收</li><li>什么时候回收</li><li>如何回收</li></ul><h1 id="1-堆的基本结构"><a href="#1-堆的基本结构" class="headerlink" title="1. 堆的基本结构"></a>1. 堆的基本结构</h1><p><img src="https://i.loli.net/2021/07/01/h3pULFu4rDBA9ei.png" alt="堆的基本结构"></p><ul><li>对象首先在Eden区域分配</li><li>在第一次新生代垃圾回收之后<ul><li>如果对象还存活，就会进入s0或者s1</li><li>对象的年龄还会加1</li><li>当其年龄增加到15岁的时候，就会晋升到老年代</li></ul></li><li>对象晋升到老年代的年龄阈值，可以通过参数 <code>-XX:MaxTenuringThreshold</code> 来进行设置</li><li>每次GC后，Eden区和From区会被清空，然后to和from会替换<ul><li>即新的To就是上次GC的From</li><li>当to区被填满的时候，会将所有对象移动到老年代当中</li></ul></li></ul><h1 id="2-堆的分配策略"><a href="#2-堆的分配策略" class="headerlink" title="2. 堆的分配策略"></a>2. 堆的分配策略</h1><h2 id="2-1-对象优先在eden区分配"><a href="#2-1-对象优先在eden区分配" class="headerlink" title="2.1 对象优先在eden区分配"></a>2.1 对象优先在eden区分配</h2><ul><li>优先在eden区进行分配</li><li>如果eden区已经几乎被分配完了，虚拟机就会发起一次minor GC</li><li>取决于是否survivor区有足够的空间<ul><li>会先放到survivor区</li><li>或者将新生代的对象提前转移到了老年代当中</li><li>如果老年代也空间不够，那就会导致full GC的出现了</li></ul></li></ul><h2 id="2-2-大对象直接进入老年代"><a href="#2-2-大对象直接进入老年代" class="headerlink" title="2.2 大对象直接进入老年代"></a>2.2 大对象直接进入老年代</h2><p>大对象是需要大量连续内存空间的对象，比如字符串，数组等。  为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。</p><ul><li>分配担保机制<ul><li>一个权衡，是把现在正在处理的大对象放到永久代里面</li><li>还是说把现在在eden的一些对象放到永久代当中</li><li><a href="https://cloud.tencent.com/developer/article/1082730" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1082730</a></li></ul></li></ul><h2 id="2-3-长期存活的对象将进入老年代"><a href="#2-3-长期存活的对象将进入老年代" class="headerlink" title="2.3 长期存活的对象将进入老年代"></a>2.3 长期存活的对象将进入老年代</h2><p>如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1.对象在 Survivor 中每熬过一次 MinorGC,年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。</p><p>“Hotspot 遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了 survivor 区的 50% 时（默认值是 50%，可以通过 <strong>-XX:TargetSurvivorRatio=percent</strong> 来设置，参见 issue1199 ），取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值”。</p><pre><code class="jsx">uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) { //survivor_capacity是survivor空间的大小 size_t desired_survivor_size = (size_t)((((double)survivor_capacity)*TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; while (age &lt; table_size) {     //sizes数组是每个年龄段对象大小     total += sizes[age];     if (total &gt; desired_survivor_size) {         break;     }     age++; } uint result = age &lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; ...}</code></pre><h1 id="3-如何判断对象的死亡"><a href="#3-如何判断对象的死亡" class="headerlink" title="3. 如何判断对象的死亡"></a>3. 如何判断对象的死亡</h1><h2 id="3-1-判断对象无效的方法"><a href="#3-1-判断对象无效的方法" class="headerlink" title="3.1 判断对象无效的方法"></a>3.1 判断对象无效的方法</h2><h3 id="3-1-1-引用计数法"><a href="#3-1-1-引用计数法" class="headerlink" title="3.1.1 引用计数法"></a>3.1.1 引用计数法</h3><ul><li>给对象添加引用计数器<ul><li>多一个地方引用它，计数器就加1</li><li>当引用失效，计数器就减1</li><li>任何时候计数器为0的对象就是不可能再被使用的</li></ul></li><li>主流的虚拟机并没有使用这个算法，因为很难解决对象之间相互循环引用的问题</li></ul><h3 id="3-1-2-可达性分析算法"><a href="#3-1-2-可达性分析算法" class="headerlink" title="3.1.2 可达性分析算法"></a>3.1.2 可达性分析算法</h3><ul><li>从GC Roots对象作为起点开始向下搜索，节点所走过的路径称为引用链</li><li>当一个对象到GC Roots没有任何引用链相连的话，就证明此对象不可用</li><li>可以作为GC Roots的对象包括<ul><li>虚拟机栈当中引用的对象</li><li>本地方法栈中引用的对象</li><li>方法区中类静态属性引用的对象</li><li>方法区中常量引用的对象</li><li>所有被同步锁持有的对象</li></ul></li></ul><h2 id="3-2-引用的类别"><a href="#3-2-引用的类别" class="headerlink" title="3.2 引用的类别"></a>3.2 引用的类别</h2><h3 id="3-2-1-强引用-StrongReference"><a href="#3-2-1-强引用-StrongReference" class="headerlink" title="3.2.1 强引用  StrongReference"></a>3.2.1 强引用  StrongReference</h3><p>我们当前常使用的基本都属于强引用，如果一个对象具有强引用，那么垃圾回收期绝对不会回收它</p><h3 id="3-2-2-软引用-SoftReference"><a href="#3-2-2-软引用-SoftReference" class="headerlink" title="3.2.2 软引用 SoftReference"></a>3.2.2 软引用 SoftReference</h3><p>如果内存空间足够，GC不会回收</p><p>如果内存空间不足，就会回收这些对象的内存</p><p>软引用可以用来实现内存敏感的高速缓存, 软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 </p><h3 id="3-2-3-弱引用-WeakReference"><a href="#3-2-3-弱引用-WeakReference" class="headerlink" title="3.2.3 弱引用 WeakReference"></a>3.2.3 弱引用 WeakReference</h3><p>弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。</p><h3 id="3-2-4-虚引用-PhantomReference"><a href="#3-2-4-虚引用-PhantomReference" class="headerlink" title="3.2.4 虚引用 PhantomReference"></a>3.2.4 虚引用 PhantomReference</h3><p>“虚引用”顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。虚引用主要用来跟踪对象被垃圾回收的活动。</p><h2 id="3-3-不可达的类是否必须要回收"><a href="#3-3-不可达的类是否必须要回收" class="headerlink" title="3.3 不可达的类是否必须要回收"></a>3.3 不可达的类是否必须要回收</h2><p>要真正宣告一个对象死亡，至少要经历两次标记过程；可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行<br>finalize 方法。当对象没有覆盖 finalize 方法，或 finalize<br>方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。</p><p>被判定为需要执行的对象将会被放在一个队列中进行第二次标记，除非这个对象与引用链上的任何一个对象建立关联，否则就会被真的回收。</p><h2 id="3-4-如何判断一个类是无用的类"><a href="#3-4-如何判断一个类是无用的类" class="headerlink" title="3.4 如何判断一个类是无用的类"></a>3.4 如何判断一个类是无用的类</h2><p>类需要同时满足下面 3 个条件才能算是 <strong>“无用的类”</strong> ：</p><ul><li>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li><li>加载该类的 <code>ClassLoader</code> 已经被回收。</li><li>该类对应的 <code>java.lang.Class</code> 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li></ul><h1 id="4-垃圾收集算法"><a href="#4-垃圾收集算法" class="headerlink" title="4. 垃圾收集算法"></a>4. 垃圾收集算法</h1><ul><li>标记清除</li><li>标记复制</li><li>标记整理</li><li>分代收集</li></ul><h1 id="5-垃圾收集器"><a href="#5-垃圾收集器" class="headerlink" title="5. 垃圾收集器"></a>5. 垃圾收集器</h1><h2 id="5-1-HotSpot-VM-GC-分类"><a href="#5-1-HotSpot-VM-GC-分类" class="headerlink" title="5.1 HotSpot VM GC 分类"></a>5.1 HotSpot VM GC 分类</h2><ul><li>部分收集 (Partial GC)：<ul><li>新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；</li><li>老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；</li><li>混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。</li></ul></li><li>整堆收集 (Full GC)：收集整个 Java 堆和方法区。</li></ul><h2 id="5-2-Serial-收集器"><a href="#5-2-Serial-收集器" class="headerlink" title="5.2 Serial 收集器"></a>5.2 Serial 收集器</h2><ul><li>串行收集器<ul><li>进行垃圾收集的时候工作线程需要停止</li></ul></li><li>新生代<ul><li>标记复制</li></ul></li><li>老年代<ul><li>标记整理</li></ul></li><li>简单高效，适合在client端运转</li></ul><p><img src="https://i.loli.net/2021/07/01/yoZaLX7NrKgldbM.png" alt="Serial收集器"></p><h2 id="5-3-ParNew收集器"><a href="#5-3-ParNew收集器" class="headerlink" title="5.3 ParNew收集器"></a>5.3 ParNew收集器</h2><ul><li>Serail收集器的多线程版本</li><li>新生代<ul><li>标记复制</li></ul></li><li>老年代<ul><li>标记整理</li></ul></li><li>适合在server模式下</li></ul><p><img src="https://i.loli.net/2021/07/01/plw2YaeWKT9CERc.png" alt="ParNew收集器"></p><h2 id="5-4-Parallel-Scavenge收集器"><a href="#5-4-Parallel-Scavenge收集器" class="headerlink" title="5.4 Parallel Scavenge收集器"></a>5.4 Parallel Scavenge收集器</h2><ul><li>注重对于吞吐量的优化 — 提高CPU的利用率</li><li>吞吐量 —&gt; CPU中用于运行用户代码的时间和CPU总消耗时间的比值</li><li>其提供了很多的参数来实现优化</li><li>新生代<ul><li>标记复制</li></ul></li><li>老年代<ul><li>标记整理</li></ul></li></ul><h2 id="5-5-Serial-Old收集器"><a href="#5-5-Serial-Old收集器" class="headerlink" title="5.5 Serial Old收集器"></a>5.5 Serial Old收集器</h2><ul><li>Serail收集器的老年代版本</li><li>两个用途<ul><li>JDK1.5之前版本和Parallel Scavenge收集器搭配使用</li><li>作为CMS收集器的后备方案</li></ul></li></ul><h2 id="5-6-Parallel-Old收集器"><a href="#5-6-Parallel-Old收集器" class="headerlink" title="5.6 Parallel Old收集器"></a>5.6 Parallel Old收集器</h2><ul><li>Parallel Scavenge的老年版本</li><li>使用多线程和标记整理法</li></ul><h2 id="5-7-CMS收集器"><a href="#5-7-CMS收集器" class="headerlink" title="5.7 CMS收集器"></a>5.7 CMS收集器</h2><ul><li>Concurrent Mark Sweep<ul><li>以获取最短回收停顿时间为目标的收集器</li><li>非常符合注重用户体验的应用</li><li>实现了让垃圾收集线程和用户线程的同时工作</li></ul></li><li>工作步骤<ul><li><strong>初始标记：</strong> 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；</li><li><strong>并发标记：</strong> 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。</li><li><strong>重新标记：</strong> 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短</li><li><strong>并发清除：</strong> 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。</li></ul></li></ul><p><img src="https://i.loli.net/2021/07/01/t5de1FrcE9bOAnf.png" alt="CMS收集器"></p><ul><li>优势<ul><li>并发，低停顿</li></ul></li><li>缺陷<ul><li>对CPU资源敏感</li><li>无法处理浮动垃圾</li><li>标记 清除算法会导致收集结束会产生大量的空间碎片</li></ul></li></ul><h2 id="5-8-G1-收集器"><a href="#5-8-G1-收集器" class="headerlink" title="5.8 G1 收集器"></a>5.8 G1 收集器</h2><ul><li>面向服务器的垃圾收集器，主要针对多核有大容量内存的机器，以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.</li><li>特征<ul><li><strong>并行与并发</strong>：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者<br>CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1<br>收集器仍然可以通过并发的方式让 java 程序继续执行。</li><li><strong>分代收集</strong>：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。</li><li><strong>空间整合</strong>：与 CMS 的“标记-清理”算法不同，G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的。</li><li><strong>可预测的停顿</strong>：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。</li><li>优先列表： 在后台维护一个后台列表，每次根据允许的收集时间，优先选择回收价值最大的region</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6" target="_blank" rel="noopener">JavaGuide</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HotSpot虚拟机 对象声明流程</title>
      <link href="/HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AF%B9%E8%B1%A1%E5%A3%B0%E6%98%8E%E6%B5%81%E7%A8%8B/"/>
      <url>/HotSpot%E8%99%9A%E6%8B%9F%E6%9C%BA-%E5%AF%B9%E8%B1%A1%E5%A3%B0%E6%98%8E%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Java虚拟机基本原理"><a href="#Java虚拟机基本原理" class="headerlink" title="Java虚拟机基本原理"></a>Java虚拟机基本原理</h1><h1 id="1-Java-代码运行方式"><a href="#1-Java-代码运行方式" class="headerlink" title="1. Java 代码运行方式"></a>1. Java 代码运行方式</h1><h2 id="1-1-为什么需要虚拟机"><a href="#1-1-为什么需要虚拟机" class="headerlink" title="1.1 为什么需要虚拟机"></a>1.1 为什么需要虚拟机</h2><ul><li>设计一个面向Java语言特性的虚拟机<ul><li>做这个的原因是为了能够在各种机器上来实现对Java的支持</li><li>通过编译器将Java程序转换成该虚拟机所能识别的指令序列，又被称为Java字节码<ul><li>叫做Java字节码的原因是字节码指令的操作码opcode被定义成了一个字节</li></ul></li></ul></li><li>Java的虚拟机是可以由硬件实现的，也可以在各个平台上(Windows/ Linux) 提供软件的实现<ul><li>好处1： 一旦一个程序被转换成了Java字节码，那么便可以在不同平台上的虚拟机里来运行</li><li>好处2： 带来了托管环境，这个托管环境能够代替我们处理一些代码当中冗长而且容易出错的部分<ul><li>自动内存管理</li><li>垃圾回收</li><li>诸如数组越界，动态类型，安全权限等等的动态检测功能</li></ul></li></ul></li></ul><h2 id="1-2-如何运行Java字节码的？"><a href="#1-2-如何运行Java字节码的？" class="headerlink" title="1.2 如何运行Java字节码的？"></a>1.2 如何运行Java字节码的？</h2><ul><li><p>从虚拟机视角来看</p><ul><li><p>首先将其编译成的class文件加载到Java虚拟机当中</p></li><li><p>加载后的Java类会被存放于方法区里 Method Area</p></li><li><p>实际执行的时候，执行方法区的代码</p></li><li><p>空间分配</p><ul><li><p>线程共享的</p><ul><li><p>方法区</p><ul><li>用来存放类似于元数据信息方面的数据<ul><li>类信息</li><li>常量</li><li>静态变量</li><li>编译后代码</li></ul></li><li>JDK 1.8之后，不再有方法区了，元数据会放到本地内存的Metaspace 即元空间里面<ul><li>使用Metaspace的优势<ul><li>元空间大小默认为Unlimited 即只受到系统内存的限制</li><li>因为元数据大小不再由MaxPermSize控制，而由实际的可用空间控制，这样能加载的类就更多了</li></ul></li></ul></li></ul></li><li><p>堆</p><ul><li><p>放置对象实例，数组等</p></li><li><p>和方法区同属于线程共享区域，是线程不安全的</p></li><li><p>堆内存的划分</p><ul><li>年轻代<ul><li>Eden 8<ul><li>当我们new一个对象以后，会放到Eden划分出来的一块作为存储空间的内存当中</li><li>每个线程都会预先申请一块连续空间的内存空间并且规定了对象存放的位置，如果空间不足就再多申请内存空间</li></ul></li><li>Survivor<ul><li>FromPlace 1</li><li>ToPlace 1</li></ul></li></ul></li><li>老年代</li></ul></li><li><p>GC的运行逻辑</p><ul><li><p>Eden空间满了以后，会触发Minor GC</p></li><li><p>存活下来的对象移动到Survivor 0区</p></li><li><p>Survivor 0区满后触发Minor GC，将存活对象移动到Survivor 1区，此时还会将from和to指针交换，保证了一段时间内总有一个survivor区为空，且to所指向的survivor区为空</p></li><li><p>经过多次Minor GC仍存活的对象移动到老年代，一般是15次，因为Hotpot给记录年龄分配到的空间只有4位</p></li><li><p>老年代用来存储长期存活的对象，占满了就会触发Full GC，期间会停止所有线程等待GC的完成 —→ 需要尽量避免这种情况的发生</p></li><li><p>当老年区执行了full GC 还是无法对对象保存，就会产生OOM， 这意味着虚拟机中的堆内存不足</p><ul><li>可能原因<ul><li>设置的堆内存过小</li><li>代码中创建的对象大且多，一直被引用导致GC无法收集他们</li></ul></li></ul><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled.png"></p></li></ul></li></ul></li></ul></li><li><p>线程私有</p><ul><li>程序计数器<ul><li>完成加载工作</li><li>本身是一个指针，指向程序当中下一句需要执行的命令<ul><li>分支，循环，跳转，异常处理，线程恢复等功能都依赖于这个计数器来完成</li></ul></li><li>占用空间非常非常小</li><li>这个内存仅仅代表了当前线程所执行的字节码的行号指示器</li><li>字节码解析器通过改变这个计数器的值来选取下一条需要执行的字节码指令</li></ul></li><li>VM 栈<ul><li>当调用一个Java方法的时候，会在当前线程生成一个栈帧，用来存放局部变量以及字节码的操作数</li><li>栈帧大小是已经计算好了的，栈帧不需要连续分布</li><li>方法执行的内存模型<ul><li>对局部变量，动态链表，方法出口，栈的操作，对象引用进行存储，并且线程独享</li></ul></li><li>如果线程请求的栈的深度大于虚拟机栈的最大深度，就会报StackOverflowError</li><li>JVM是可以动态扩展的，但随着扩展会不断申请内存，当无法申请足够内存的时候就会报OutOfMemoryError</li><li>栈并不存在垃圾回收，因为只要程序运行结束，栈的空间自然会释放的。— 栈的生命周期和所处的线程是一致的</li></ul></li><li>本地方法栈<ul><li>由native修饰的方法</li><li>和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务</li></ul></li></ul></li><li><p>直接内存</p><ul><li>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机定义的内存区域</li><li>是通过基于通道和缓存区的NIO，直接使用Native函数库来分配堆外内存，然后通过一个存储在Java堆当中的DirectByteBuffer对象作为这块内存的引用，进而进行操作</li></ul></li></ul></li></ul></li><li><p>从硬件视角来看</p><ul><li>需要虚拟机将字节码翻译成机器码</li><li>翻译方式<ul><li>解释执行<ul><li>逐条将字节码翻译成机器码并且执行</li><li>优势<ul><li>无需等待编译</li></ul></li></ul></li><li>即时编译 Just In Time Compilation<ul><li>将一个方法中包含的所有字节码编译成机器码以后再执行</li><li>优势<ul><li>实际执行速度会更快</li></ul></li></ul></li></ul></li><li>hotpot的翻译方式<ul><li>先解释执行字节码</li><li>而后将反复执行的热点代码按照方法来作为基本单元进行JIT 即时编译</li></ul></li></ul></li><li><p>走一个代码例子</p></li></ul><pre><code class="jsx">@RequireAllArgConstructorpublic class People {    public String name;    public void sayName() {        System.out.println(&quot;People&#39;s name is: &quot; + name);    }}public class App {    public static void main(String[] args) {        People people = new People(&quot;test&quot;);        people.sayName();    }}</code></pre><ul><li>执行main方法的步骤如下<ul><li>编译好App.java之后得到App.class，执行App.class</li><li>系统会启动一个JVM进程</li><li>从classpath路径当中找到一个名为App.class的二进制文件，将App的类信息加载到运行时数据区的方法区内</li><li>JVM找到App主程序入口，执行main方法</li><li>当要执行new People的时候，发现方法区当中还没有People类的信息，所以JVM马上加载，并将其类的信息放到方法区里面</li><li>JVM在堆当中为一个新的People实例分配内存，然后调用构造函数初始化People实例，这个实例持有指向方法区中的People类的类型信息的引用</li><li>执行people.sayName();时，JVM 根据 people 的引用找到 people 对象，然后根据 people 对象持有的引用定位到方法区中 people 类的类型信息的方法表，获得 sayName() 的字节码地址</li><li>执行sayName()</li></ul></li></ul><h2 id="1-3-Java虚拟机执行效率"><a href="#1-3-Java虚拟机执行效率" class="headerlink" title="1.3 Java虚拟机执行效率"></a>1.3 Java虚拟机执行效率</h2><ul><li>优化方式<ul><li>即时编译<ul><li>底层逻辑 — 二八定律<ul><li>认为20%代码会占据80%的计算资源</li></ul></li><li>编译器类别 — tradeoff 编译时间 vs 执行效率<ul><li>C1<ul><li>Client编译器</li><li>面向对启动性能有要求的客户端GUI程序</li></ul></li><li>C2<ul><li>Server编译器</li><li>面向对峰值性能有要求的服务器端程序</li><li>采用的优化手段相对复杂，因此编译时间较长，但同时生成代码的效率比较高</li></ul></li><li>Graal</li></ul></li></ul></li></ul></li><li>Hotpot对于各种编译器的采用方式<ul><li>分层编译<ul><li>热点方法先被C1 编译</li><li>热点方法里的热点会进一步被C2 编译器编译</li></ul></li><li>会影响应用的正常进行么？<ul><li>即时编译是在额外的编译线程当中进行的</li><li>会根据CPU的数量设置编译线程的数目，并且按照1:2的比例配置给C1 及C2 编译器</li></ul></li></ul></li></ul><h1 id="2-基本类型在虚拟机当中的实现"><a href="#2-基本类型在虚拟机当中的实现" class="headerlink" title="2. 基本类型在虚拟机当中的实现"></a>2. 基本类型在虚拟机当中的实现</h1><ul><li><p>为什么要引入基本类型而不是全都使用对象呢？</p><ul><li>基本类型更靠近底层，在执行效率和内存使用方面都能够提升软件的性能</li></ul></li><li><p>boolean 类型</p><ul><li><p>映射成int类型</p><ul><li><p>true被映射为整数1</p></li><li><p>false被映射为整数0</p><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%201.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%201.png"></p></li></ul></li></ul></li><li><p>Java虚拟机在调用Java方法的时候，会创建出一个栈帧，对于其中的解释栈帧来说，有两个主要组成部分</p><ul><li>局部变量区<ul><li>局部变量</li><li>this指针</li><li>方法接收的参数</li><li>各个基本类型在局部变量区的表现<ul><li>局部变量区等价于一个数组<ul><li>long double需要两个数组单元存储</li><li>其他基本类型和引用类型的值均占用一个数组单元</li></ul></li></ul></li></ul></li><li>字节码的操作数栈</li></ul></li><li><p>存储操作</p><ul><li>如果我们将一个int类型的值放到char short 等里面，相当于做了一次掩码  只会保留低位了</li></ul></li><li><p>加载</p><ul><li>算数运算完全依赖于操作数栈</li><li>堆当中的boolean, byte, char, short 加载到操作数栈当中，而后将栈上的值当成int类型来运算</li></ul></li></ul><h1 id="3-类的加载，链接，初始化过程"><a href="#3-类的加载，链接，初始化过程" class="headerlink" title="3. 类的加载，链接，初始化过程"></a>3. 类的加载，链接，初始化过程</h1><ul><li>首先.java文件会被编译成.class文件，而后我们需要类加载器来处理.class文件，让JVM对其进行处理</li><li>从class文件到内存当中的类，需要经过：<ul><li>加载<ul><li>查找字节流，并且根据此来创建类的过程<ul><li>将class类加载到内存当中</li><li>将静态数据结构转化为方法区当中运行时的数据结构</li><li>在堆当中生成一个代表这个类的java.lang.class对象作为数据访问的入口</li></ul></li><li>借助类加载器来完成查找字节流的过程<ul><li>启动类加载器 — bootstrap class loader<ul><li>负责加载最基础最重要的类，譬如JRE lib目录下Jar包中的类</li><li>由虚拟机参数 -Xbootclasspath指定的类</li></ul></li><li>其他类加载器 — 都是java.lang.ClassLoader的子类<ul><li>需要先由启动类加载器，将其加载至Java虚拟机当中，方能执行类的加载</li><li>E.G<ul><li>扩展类加载器 — 父类是启动类加载器<ul><li>负责加载相对次要、但又通用的类，比如存放在 JRE 的 lib/ext 目录下 jar 包中的类（以及由系统变量 java.ext.dirs 指定的类）</li></ul></li><li>应用类加载器 — 父类是扩展类加载器<ul><li>负责加载应用程序路径下的类<ul><li>例如虚拟机参数 -cp/-classpath, 系统变量java.class.path或者环境变量CLASSPATH所指定的路径</li><li>默认应用程序里包含的类应该由应用类加载器来进行加载</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>双亲委派模型<ul><li>当一个类加载器接收到加载请求时，会先将请求转发给父类加载器</li><li>在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载</li></ul></li><li>类加载器 — 命名空间的作用<ul><li>类的唯一性由类加载器实例和类的全名共同确定</li><li>即使同一串字节流，经由不同的类加载器加载，也会得到不同的类</li></ul></li></ul></li><li>链接<ul><li>将创建的类合并到Java虚拟机当中，并且使其能够执行的过程</li><li>过程<ul><li>验证<ul><li>确保被加载类能够满足Java虚拟机的约束条件</li><li>安全检查</li></ul></li><li>准备<ul><li>为被加载类的静态字段分配内存<ul><li>就是为static变量在方法区当中分配内存空间，设置变量的初始值</li></ul></li><li>也会来构造和其他类层次相关的数据结构，比如说用来实现虚方法的动态绑定的方法表</li></ul></li><li>解析 — 对于字节码符号引用的解析<ul><li>在 class 文件被加载至 Java 虚拟机之前，这个类无法知道其他类及其方法、字段所对应的具体地址，甚至不知道自己方法、字段的地址。</li><li>因此，每当需要引用这些成员时，Java 编译器会生成一个符号引用。在运行阶段，这个符号引用一般都能够无歧义地定位到具体目标上。</li><li>举例来说，对于一个方法调用，编译器会生成一个包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法。</li><li>解析阶段的目的，正是将这些符号引用解析成为实际引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）</li></ul></li></ul></li></ul></li><li>初始化<ul><li>内容<ul><li>为标记为常量值的字段赋值</li><li>执行clinit方法 — Java虚拟机通过加锁确定clinit方法仅仅会被执行一次<ul><li>如果直接赋值的静态字段被 final 所修饰，并且它的类型是基本类型或字符串时，那么该字段便会被 Java 编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成。</li><li>除此之外的直接赋值操作，以及所有静态代码块中的代码，则会被 Java 编译器置于同一方法中，并把它命名为 &lt; clinit &gt;。</li></ul></li></ul></li><li>触发情况<ul><li>当虚拟机启动时，初始化用户指定的主类；</li><li>当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类；</li><li>当遇到调用静态方法的指令时，初始化该静态方法所在的类；</li><li>当遇到访问静态字段的指令时，初始化该静态字段所在的类；</li><li>子类的初始化会触发父类的初始化；</li><li>如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化；</li><li>使用反射 API 对某个类进行反射调用时，初始化这个类；</li><li>当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。</li></ul></li></ul></li><li>卸载<ul><li>GC将无用对象从内存当中卸载掉</li></ul></li></ul></li><li>基本类型是Java虚拟机已经设置好的，而另一大类引用类型，Java将其细分为四种<ul><li>类<ul><li>有对应的字节流 — class文件</li></ul></li><li>接口<ul><li>有对应的字节流 - class文件</li></ul></li><li>数组类<ul><li>由Java虚拟机直接生成</li></ul></li><li>泛型参数</li></ul></li></ul><h1 id="4-JVM执行方法调用"><a href="#4-JVM执行方法调用" class="headerlink" title="4. JVM执行方法调用"></a>4. JVM执行方法调用</h1><h2 id="4-1-重载和重写"><a href="#4-1-重载和重写" class="headerlink" title="4.1 重载和重写"></a>4.1 重载和重写</h2><ul><li>重载<ul><li>同一个类当中方法名称相同，但是方法的参数不相同的情况</li><li>在编译过程当中就可以完成识别，Java编译器根据传入参数的声明类型，来选取重载方法<ul><li>三个阶段<ul><li>不考虑基本类型的自动拆箱装箱，还有可变长参数的情况下选择重载方法</li><li>1阶段没有找到适配的方法，那么就在允许自动拆装箱，但不允许可变长参数的情况下选取重载方法</li><li>2阶段没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法</li></ul></li><li>如果Java编译器在同一个阶段找到了多个适配方法，那么就会选择一个最为贴切的，决定贴切程度的一个关键就是形式参数类型的继承关系<ul><li>会选择那个范围更小的，比如某某的子类这样子</li></ul></li></ul></li></ul></li><li>重写<ul><li>子类定义了和父类非私有方法同名的方法，而且这两个方法的参数类型相同</li><li>如果这两个方法都是静态的，那么子类中的方法隐藏了父类中的方法</li><li>如果都不是静态，也不是私有的，那么子类的方法重写了父类当中的方法</li><li>方法重写 — 允许子类在继承父类部分功能的同时，拥有自己独特的行为</li></ul></li></ul><h2 id="4-2-JVM-静态和动态绑定"><a href="#4-2-JVM-静态和动态绑定" class="headerlink" title="4.2 JVM 静态和动态绑定"></a>4.2 JVM 静态和动态绑定</h2><ul><li>Java虚拟机识别方法<ul><li>类名</li><li>方法名</li><li>方法描述符 — method descriptor<ul><li>由方法的参数类型以及<strong>返回类型</strong>所构成的</li></ul></li></ul></li><li>JVM和Java语言在这里不太一样，同一个类下同样方法名，同样参数，但是不同返回值从JVM角度来说是可以被认为是不同的方法，是可以通过的</li><li>静态绑定<ul><li>在解析的时候便能够识别目标方法的情况</li><li>重载 — 是在编译阶段就完成了的，也可以成为static binding</li></ul></li><li>动态绑定<ul><li>在运行过程当中根据调用者的动态类型来识别目标方法的情况</li><li>重写 — 在JVM当中来做识别，dynamic binding</li></ul></li><li>Java字节码当中和调用相关的指令<ul><li>invokestatic  - 用于调用静态方法</li><li>invokespecial - 用于调用私有实例方法，构造器  以及使用super关键字调用父类的实例方法或者构造器</li><li>invokevirtual  - 用于调用非私有实例方法</li><li>invokeinterface - 用于调用接口方法</li><li>invokedynamic - 用于调用动态方法</li></ul></li></ul><h2 id="4-3-调用指令的符号引用"><a href="#4-3-调用指令的符号引用" class="headerlink" title="4.3 调用指令的符号引用"></a>4.3 调用指令的符号引用</h2><ul><li>在编译过程当中，我们并不知道目标方法的具体内存地址<ul><li>Java编译器会暂时用符号引用来表示该目标方法</li><li>这一符号引用包括目标方法所在的类或接口的名字，以及目标方法的方法名和方法描述符。</li></ul></li></ul><h1 id="5-垃圾回收"><a href="#5-垃圾回收" class="headerlink" title="5. 垃圾回收"></a>5. 垃圾回收</h1><h2 id="5-1-如何判断需要清理一个对象"><a href="#5-1-如何判断需要清理一个对象" class="headerlink" title="5.1 如何判断需要清理一个对象"></a>5.1 如何判断需要清理一个对象</h2><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%202.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%202.png"></p><ul><li>绿色部分是线程拥有的，会随着线程的结束而自动被回收 这里不需要考虑垃圾回收的问题</li><li>橙色部分是共享的，内存分配和回收都是动态的，因此垃圾收集器所关注的都是堆和方法这部分内存</li><li>判断对象存活的方法<ul><li>引用计数器计算<ul><li>给对象添加一个引用计数器，每次引用这个对象的时候计数器加一，引用失效则减一</li><li>计数器等于零的时候就不会再次试用了</li></ul></li><li>可达性分析计算<ul><li>将一系列GC ROOTS作为起始的存活对象集，从这个节点往下搜索</li><li>搜索所走过的路径成为引用链，将能被该集合引用的对象加入到集合当中</li><li>当搜索到一个对象到GC roots没有使用任何引用链的时候，就说明这个对象是不可用的</li></ul></li></ul></li></ul><h2 id="5-2-如何宣告一个对象的结束-死亡"><a href="#5-2-如何宣告一个对象的结束-死亡" class="headerlink" title="5.2 如何宣告一个对象的结束/ 死亡"></a>5.2 如何宣告一个对象的结束/ 死亡</h2><ul><li>finalize()是Object类的一个方法，一个对象的finalize()方法只会被系统自动调用一次，经过finalize()方法逃脱死亡的对象，二次标记的时候会给移出</li><li>整个流程如下<ol><li>如果对象进行可达性分析之后没发现与GC Roots相连的引用链，那它将会第一次标记并且进行一次筛选。判断的条件是决定这个对象是否有必要执行finalize()方法。如果对象有必要执行finalize()方法，则被放入F-Queue队列中。</li><li>GC对F-Queue队列中的对象进行二次标记。如果对象在finalize()方法中重新与引用链上的任何一个对象建立了关联，那么二次标记时则会将它移出“即将回收”集合。如果此时对象还没成功逃脱，那么只能被回收了。</li></ol></li></ul><h2 id="5-3-垃圾回收算法"><a href="#5-3-垃圾回收算法" class="headerlink" title="5.3 垃圾回收算法"></a>5.3 垃圾回收算法</h2><h3 id="5-3-1-标记清除算法"><a href="#5-3-1-标记清除算法" class="headerlink" title="5.3.1 标记清除算法"></a>5.3.1 标记清除算法</h3><ul><li><p>阶段</p><ul><li>标记<ul><li>标记处所有需要回收的对象</li></ul></li><li>清除<ul><li>标记结束以后进行统一的回收</li></ul></li></ul></li><li><p>原理</p><ul><li>将已死亡的对象标记为空闲内存，记录在一个空闲列表当中</li><li>当我们需要new一个对象的时候，内存管理模块会从空闲列表当中寻找空闲的内存来分给新的对象</li></ul></li><li><p>缺陷</p><ul><li><p>会使得内存当中的碎片非常多</p></li><li><p>容易导致当我们需要使用大块的内存的时候，无法分配足够的连续内存</p><p>  <img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%203.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%203.png"></p></li></ul></li></ul><h3 id="5-3-2-复制算法"><a href="#5-3-2-复制算法" class="headerlink" title="5.3.2 复制算法"></a>5.3.2 复制算法</h3><ul><li><p>在标记清除算法的基础上做的优化</p><ul><li>将可用内存按照容量划分成两等分，每次只使用其中一块</li><li>当一块存满了 就将存活的对象复制到另一块上，然后交换指针的内容</li><li>以此解决碎片化的问题</li></ul></li><li><p>缺陷</p><ul><li><p>可用内存减少了！</p><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%204.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%204.png"></p></li></ul></li></ul><h3 id="5-3-3-标记整理算法"><a href="#5-3-3-标记整理算法" class="headerlink" title="5.3.3 标记整理算法"></a>5.3.3 标记整理算法</h3><ul><li>标记了以后会做整理，将所有存活的对象都向内存块一端移动，然后直接清理掉边界以外的内存</li></ul><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%205.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%205.png"></p><h3 id="5-3-4-分代收集算法"><a href="#5-3-4-分代收集算法" class="headerlink" title="5.3.4 分代收集算法"></a>5.3.4 分代收集算法</h3><ul><li>根据对象存活周期的不同将内存划分为几块</li><li>新生代<ul><li>每次垃圾收集都有大批对象死去，少量存活</li><li>所以可以选用复制算法</li></ul></li><li>老年代<ul><li>对象存活率高，没有额外空间对其进行分配和担保</li><li>需要使用标记-清理或者标记整理算法来进行回收</li></ul></li></ul><h2 id="5-4-垃圾收集器"><a href="#5-4-垃圾收集器" class="headerlink" title="5.4 垃圾收集器"></a>5.4 垃圾收集器</h2><ul><li>jdk8 默认收集器是Parallel Scavenge 和 Parallel Old</li><li>jdk9开始，G1收集器成为默认的垃圾收集器</li></ul><p><img src="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%206.png" alt="Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%20b3e8d9d4a04740b09ba93ad433759c05/Untitled%206.png"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/[%E5%8A%A0%E9%A4%90]%E5%A4%A7%E7%99%BD%E8%AF%9D%E5%B8%A6%E4%BD%A0%E8%AE%A4%E8%AF%86JVM" target="_blank" rel="noopener">JavaGuide</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>01背包问题</title>
      <link href="/01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"/>
      <url>/01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="01背包问题"><a href="#01背包问题" class="headerlink" title="01背包问题"></a>01背包问题</h1><p>Created: Jun 23, 2021 8:02 PM</p><h1 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h1><p>背包问题 即有N件物品，和一个最多能装重量W的背包，第i件物品的重量是weight[i], 得到的价值是value[i], 每件物品只能用一次，求解将哪些物品装入背包里物品价值总和最大。</p><h1 id="2-暴力破解方法"><a href="#2-暴力破解方法" class="headerlink" title="2. 暴力破解方法"></a>2. 暴力破解方法</h1><ul><li>每件物品只有选和不选两种途径，可以使用回溯法搜索出所有的情况，然后取最大的值</li><li>这样写非常慢，因为遍历了每个物品的取和不取的所有情况，时间复杂度为O(2^n)</li></ul><pre><code class="jsx">class Solution {    int result = 0;  int cur = 0;    public maxValue(int[] value, int[] weight, int w) {        backTracking(value, weight, w, 0);        return result;    }    private void backTracking(int[] value, int[] weight, int w, int startIndex) {        if (startIndex &gt; value.length - 1 || w &lt; 0) {            return;        }        for (int i = startIndex; i &lt; value.length; i++) {            cur += value[i];            w -= weight[i];                        result = Math.max(result, cur);            backTracking(value, weight, w, i + 1);            cur -= value[i];            w += weight[i];        }    }}</code></pre><h1 id="3-二维dp数组01背包"><a href="#3-二维dp数组01背包" class="headerlink" title="3. 二维dp数组01背包"></a>3. 二维dp数组01背包</h1><p>因为每一步都是依托于上一步你的物品的取放的选择的，是一个可以用dp来做的类型题目~ </p><p>我们需要做以下几步来思考整个逻辑</p><h2 id="3-1-确定dp数组和下标的含义"><a href="#3-1-确定dp数组和下标的含义" class="headerlink" title="3.1 确定dp数组和下标的含义"></a>3.1 确定dp数组和下标的含义</h2><ul><li>在二维数组里面，我们希望用dp[i][j] 表示我在做了对于前i个产品的选择，在容量为j的时候能够获得的最大的价值</li><li>在这个定义下，那么最终我需要的值就是dp[n][W], 这就是我在做了n个关于这些产品的选取放弃的决定，在满足重量不超过W的限定条件下能取得的最大价值了</li></ul><h2 id="3-2-确定递推公式"><a href="#3-2-确定递推公式" class="headerlink" title="3.2 确定递推公式"></a>3.2 确定递推公式</h2><pre><code class="jsx">// 不选i这件产品，容量为j的值; 还有选了i这件产品，那么i-1件产品的总重量需要满足 j - weight[i], 这个时候再加上i这件产品的价值，  这两个dp数组位置的最大值就是dp[i][j]需要取的值了dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j - weight[i]] + value[i])</code></pre><h2 id="3-3-如何初始化这个数组"><a href="#3-3-如何初始化这个数组" class="headerlink" title="3.3 如何初始化这个数组"></a>3.3 如何初始化这个数组</h2><ul><li>对于第一列  j = 0 意味着现在背包允许的重量为0，所以不管是哪个产品，有的价值都为0</li><li>对于第一行 i = 0, 此时我们只能选择物品0，而且题目中说了只能最多拿一件产品，所以可以将这一行都声明为weight[0]</li></ul><h2 id="3-4-确定遍历顺序"><a href="#3-4-确定遍历顺序" class="headerlink" title="3.4 确定遍历顺序"></a>3.4 确定遍历顺序</h2><p>先遍历物品，再遍历背包重量  其实均可</p><pre><code class="jsx">// weight数组的大小 就是物品个数for(int i = 1; i &lt; weight.size(); i++) { // 遍历物品    for(int j = 0; j &lt;= bagWeight; j++) { // 遍历背包容量        if (j &lt; weight[i]) dp[i][j] = dp[i - 1][j]; // 这个是为了展现dp数组里元素的变化        else dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]);    }}</code></pre><h2 id="3-5-代码"><a href="#3-5-代码" class="headerlink" title="3.5 代码"></a>3.5 代码</h2><pre><code class="jsx">public int WeightBagProblem(int[] weight, int[] value, int bagSize){        int wLen = weight.length, value0 = 0;        //定义dp数组：dp[i][j]表示背包容量为j时，前i个物品能获得的最大价值        int[][] dp = new int[wLen + 1][bagSize + 1];        //初始化：背包容量为0时，能获得的价值都为0        for (int i = 0; i &lt;= wLen; i++){            dp[i][0] = value0;        }        //遍历顺序：先遍历物品，再遍历背包容量        for (int i = 1; i &lt;= wLen; i++){            for (int j = 1; j &lt;= bagSize; j++){                if (j &lt; weight[i - 1]){                    dp[i][j] = dp[i - 1][j];                }else{                    dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - weight[i - 1]] + value[i - 1]);                }            }        }                return dp[wLen][bagSize];    }</code></pre><h1 id="4-数组降维-—-利用滚动数组解决01背包问题"><a href="#4-数组降维-—-利用滚动数组解决01背包问题" class="headerlink" title="4. 数组降维 — 利用滚动数组解决01背包问题"></a>4. 数组降维 — 利用滚动数组解决01背包问题</h1><ul><li>在第三部分当中，我们的递归公式推导出来是：</li></ul><pre><code class="jsx">dp[i][j] = max(dp[i-1][j], dp[i-1][j-weight[i]] + value[i])</code></pre><ul><li>如果在这里 我们将dp[i-1][]那一层的东西拷贝到dp[i]这一层，那么我们是可以使用一个一维数组来解决这个问题的</li></ul><h2 id="4-1-确定dp数组的定义"><a href="#4-1-确定dp数组的定义" class="headerlink" title="4.1 确定dp数组的定义"></a>4.1 确定dp数组的定义</h2><p>在一维dp数组当中, dp[j]表示容量为j的背包所背的物品价值可以最大为dp[j] </p><h2 id="4-2-一维数组递推公式"><a href="#4-2-一维数组递推公式" class="headerlink" title="4.2 一维数组递推公式"></a>4.2 一维数组递推公式</h2><pre><code class="jsx">dp[j] = max(dp[j], dp[j-weight[i]] + value[i])</code></pre><h2 id="4-3-一维数组初始化"><a href="#4-3-一维数组初始化" class="headerlink" title="4.3 一维数组初始化"></a>4.3 一维数组初始化</h2><ul><li>首先确定背包容量为0所背的物品的最大价值也为0</li><li>假设所有产品价值非负，那么我们就不用初始化数组其他位置的值为负无穷了，保持为0即可</li></ul><h2 id="4-4-一维数组遍历顺序"><a href="#4-4-一维数组遍历顺序" class="headerlink" title="4.4 一维数组遍历顺序"></a>4.4 一维数组遍历顺序</h2><pre><code class="jsx">or(int i = 0; i &lt; weight.size(); i++) { // 遍历物品    for(int j = bagWeight; j &gt;= weight[i]; j--) { // 遍历背包容量        dp[j] = max(dp[j], dp[j - weight[i]] + value[i]);    }}</code></pre><ul><li>不能正序遍历，因为正序的话物品会被重复加入很多次<ul><li>因为在遍历后一个的时候实际上已经用了前一个的结果</li><li>譬如<ul><li>dp[1] = dp[1 - weight[0]] + value[0]</li><li>dp[2] = dp[2 - weight[0]] + value[0]</li><li>dp[2] 会用到dp[1] (当weight[0] = 1的时候)  这个时候相当于我们把0号产品用了两次了 这是不能够的</li></ul></li></ul></li></ul><pre><code class="jsx">public static void main(String[] args) {        int[] weight = {1, 3, 4};        int[] value = {15, 20, 30};        int bagWight = 4;        testWeightBagProblem(weight, value, bagWight);    }    public static void testWeightBagProblem(int[] weight, int[] value, int bagWeight){        int wLen = weight.length;        //定义dp数组：dp[j]表示背包容量为j时，能获得的最大价值        int[] dp = new int[bagWeight + 1];        //遍历顺序：先遍历物品，再遍历背包容量        for (int i = 0; i &lt; wLen; i++){            for (int j = bagWeight; j &gt;= weight[i]; j--){                dp[j] = Math.max(dp[j], dp[j - weight[i]] + value[i]);            }        }        //打印dp数组        for (int j = 0; j &lt;= bagWeight; j++){            System.out.print(dp[j] + &quot; &quot;);        }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 01背包 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java虚拟机基本原理</title>
      <link href="/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/"/>
      <url>/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Java虚拟机基本原理"><a href="#Java虚拟机基本原理" class="headerlink" title="Java虚拟机基本原理"></a>Java虚拟机基本原理</h1><h1 id="1-Java-代码运行方式"><a href="#1-Java-代码运行方式" class="headerlink" title="1. Java 代码运行方式"></a>1. Java 代码运行方式</h1><h2 id="1-1-为什么需要虚拟机"><a href="#1-1-为什么需要虚拟机" class="headerlink" title="1.1 为什么需要虚拟机"></a>1.1 为什么需要虚拟机</h2><ul><li>设计一个面向Java语言特性的虚拟机<ul><li>做这个的原因是为了能够在各种机器上来实现对Java的支持</li><li>通过编译器将Java程序转换成该虚拟机所能识别的指令序列，又被称为Java字节码<ul><li>叫做Java字节码的原因是字节码指令的操作码opcode被定义成了一个字节</li></ul></li></ul></li><li>Java的虚拟机是可以由硬件实现的，也可以在各个平台上(Windows/ Linux) 提供软件的实现<ul><li>好处1： 一旦一个程序被转换成了Java字节码，那么便可以在不同平台上的虚拟机里来运行</li><li>好处2： 带来了托管环境，这个托管环境能够代替我们处理一些代码当中冗长而且容易出错的部分<ul><li>自动内存管理</li><li>垃圾回收</li><li>诸如数组越界，动态类型，安全权限等等的动态检测功能</li></ul></li></ul></li></ul><h2 id="1-2-如何运行Java字节码的？"><a href="#1-2-如何运行Java字节码的？" class="headerlink" title="1.2 如何运行Java字节码的？"></a>1.2 如何运行Java字节码的？</h2><ul><li><p>从虚拟机视角来看</p><ul><li><p>首先将其编译成的class文件加载到Java虚拟机当中</p></li><li><p>加载后的Java类会被存放于方法区里 Method Area</p></li><li><p>实际执行的时候，执行方法区的代码</p></li><li><p>空间分配</p><ul><li><p>线程共享的</p><ul><li><p>方法区</p><ul><li>用来存放类似于元数据信息方面的数据<ul><li>类信息</li><li>常量</li><li>静态变量</li><li>编译后代码</li></ul></li><li>JDK 1.8之后，不再有方法区了，元数据会放到本地内存的Metaspace 即元空间里面<ul><li>使用Metaspace的优势<ul><li>元空间大小默认为Unlimited 即只受到系统内存的限制</li><li>因为元数据大小不再由MaxPermSize控制，而由实际的可用空间控制，这样能加载的类就更多了</li></ul></li></ul></li></ul></li><li><p>堆</p><ul><li><p>放置对象实例，数组等</p></li><li><p>和方法区同属于线程共享区域，是线程不安全的</p></li><li><p>堆内存的划分</p><ul><li>年轻代<ul><li>Eden 8<ul><li>当我们new一个对象以后，会放到Eden划分出来的一块作为存储空间的内存当中</li><li>每个线程都会预先申请一块连续空间的内存空间并且规定了对象存放的位置，如果空间不足就再多申请内存空间</li></ul></li><li>Survivor<ul><li>FromPlace 1</li><li>ToPlace 1</li></ul></li></ul></li><li>老年代</li></ul></li><li><p>GC的运行逻辑</p><ul><li><p>Eden空间满了以后，会触发Minor GC</p></li><li><p>存活下来的对象移动到Survivor 0区</p></li><li><p>Survivor 0区满后触发Minor GC，将存活对象移动到Survivor 1区，此时还会将from和to指针交换，保证了一段时间内总有一个survivor区为空，且to所指向的survivor区为空</p></li><li><p>经过多次Minor GC仍存活的对象移动到老年代，一般是15次，因为Hotpot给记录年龄分配到的空间只有4位</p></li><li><p>老年代用来存储长期存活的对象，占满了就会触发Full GC，期间会停止所有线程等待GC的完成 —→ 需要尽量避免这种情况的发生</p></li><li><p>当老年区执行了full GC 还是无法对对象保存，就会产生OOM， 这意味着虚拟机中的堆内存不足</p><ul><li>可能原因<ul><li>设置的堆内存过小</li><li>代码中创建的对象大且多，一直被引用导致GC无法收集他们</li></ul></li></ul><p><img src="https://i.loli.net/2021/06/28/q7NYfmdDapVOBU9.png" alt="GC运行逻辑"></p></li></ul></li></ul></li></ul></li><li><p>线程私有</p><ul><li>程序计数器<ul><li>完成加载工作</li><li>本身是一个指针，指向程序当中下一句需要执行的命令<ul><li>分支，循环，跳转，异常处理，线程恢复等功能都依赖于这个计数器来完成</li></ul></li><li>占用空间非常非常小</li><li>这个内存仅仅代表了当前线程所执行的字节码的行号指示器</li><li>字节码解析器通过改变这个计数器的值来选取下一条需要执行的字节码指令</li></ul></li><li>VM 栈<ul><li>当调用一个Java方法的时候，会在当前线程生成一个栈帧，用来存放局部变量以及字节码的操作数</li><li>栈帧大小是已经计算好了的，栈帧不需要连续分布</li><li>方法执行的内存模型<ul><li>对局部变量，动态链表，方法出口，栈的操作，对象引用进行存储，并且线程独享</li></ul></li><li>如果线程请求的栈的深度大于虚拟机栈的最大深度，就会报StackOverflowError</li><li>JVM是可以动态扩展的，但随着扩展会不断申请内存，当无法申请足够内存的时候就会报OutOfMemoryError</li><li>栈并不存在垃圾回收，因为只要程序运行结束，栈的空间自然会释放的。— 栈的生命周期和所处的线程是一致的</li></ul></li><li>本地方法栈<ul><li>由native修饰的方法</li><li>和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务</li></ul></li></ul></li><li><p>直接内存</p><ul><li>直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机定义的内存区域</li><li>是通过基于通道和缓存区的NIO，直接使用Native函数库来分配堆外内存，然后通过一个存储在Java堆当中的DirectByteBuffer对象作为这块内存的引用，进而进行操作</li></ul></li></ul></li></ul></li><li><p>从硬件视角来看</p><ul><li>需要虚拟机将字节码翻译成机器码</li><li>翻译方式<ul><li>解释执行<ul><li>逐条将字节码翻译成机器码并且执行</li><li>优势<ul><li>无需等待编译</li></ul></li></ul></li><li>即时编译 Just In Time Compilation<ul><li>将一个方法中包含的所有字节码编译成机器码以后再执行</li><li>优势<ul><li>实际执行速度会更快</li></ul></li></ul></li></ul></li><li>hotpot的翻译方式<ul><li>先解释执行字节码</li><li>而后将反复执行的热点代码按照方法来作为基本单元进行JIT 即时编译</li></ul></li></ul></li><li><p>走一个代码例子</p></li></ul><pre><code class="jsx">@RequireAllArgConstructorpublic class People {    public String name;    public void sayName() {        System.out.println(&quot;People&#39;s name is: &quot; + name);    }}public class App {    public static void main(String[] args) {        People people = new People(&quot;test&quot;);        people.sayName();    }}</code></pre><ul><li>执行main方法的步骤如下<ul><li>编译好App.java之后得到App.class，执行App.class</li><li>系统会启动一个JVM进程</li><li>从classpath路径当中找到一个名为App.class的二进制文件，将App的类信息加载到运行时数据区的方法区内</li><li>JVM找到App主程序入口，执行main方法</li><li>当要执行new People的时候，发现方法区当中还没有People类的信息，所以JVM马上加载，并将其类的信息放到方法区里面</li><li>JVM在堆当中为一个新的People实例分配内存，然后调用构造函数初始化People实例，这个实例持有指向方法区中的People类的类型信息的引用</li><li>执行people.sayName();时，JVM 根据 people 的引用找到 people 对象，然后根据 people 对象持有的引用定位到方法区中 people 类的类型信息的方法表，获得 sayName() 的字节码地址</li><li>执行sayName()</li></ul></li></ul><h2 id="1-3-Java虚拟机执行效率"><a href="#1-3-Java虚拟机执行效率" class="headerlink" title="1.3 Java虚拟机执行效率"></a>1.3 Java虚拟机执行效率</h2><ul><li>优化方式<ul><li>即时编译<ul><li>底层逻辑 — 二八定律<ul><li>认为20%代码会占据80%的计算资源</li></ul></li><li>编译器类别 — tradeoff 编译时间 vs 执行效率<ul><li>C1<ul><li>Client编译器</li><li>面向对启动性能有要求的客户端GUI程序</li></ul></li><li>C2<ul><li>Server编译器</li><li>面向对峰值性能有要求的服务器端程序</li><li>采用的优化手段相对复杂，因此编译时间较长，但同时生成代码的效率比较高</li></ul></li><li>Graal</li></ul></li></ul></li></ul></li><li>Hotpot对于各种编译器的采用方式<ul><li>分层编译<ul><li>热点方法先被C1 编译</li><li>热点方法里的热点会进一步被C2 编译器编译</li></ul></li><li>会影响应用的正常进行么？<ul><li>即时编译是在额外的编译线程当中进行的</li><li>会根据CPU的数量设置编译线程的数目，并且按照1:2的比例配置给C1 及C2 编译器</li></ul></li></ul></li></ul><h1 id="2-基本类型在虚拟机当中的实现"><a href="#2-基本类型在虚拟机当中的实现" class="headerlink" title="2. 基本类型在虚拟机当中的实现"></a>2. 基本类型在虚拟机当中的实现</h1><ul><li><p>为什么要引入基本类型而不是全都使用对象呢？</p><ul><li>基本类型更靠近底层，在执行效率和内存使用方面都能够提升软件的性能</li></ul></li><li><p>boolean 类型</p><ul><li>映射成int类型<ul><li>true被映射为整数1</li><li>false被映射为整数0<br><img src="https://i.loli.net/2021/06/28/k6pXaMj4rUJOFoH.png" alt="基本类型"></li></ul></li></ul></li><li><p>Java虚拟机在调用Java方法的时候，会创建出一个栈帧，对于其中的解释栈帧来说，有两个主要组成部分</p><ul><li>局部变量区<ul><li>局部变量</li><li>this指针</li><li>方法接收的参数</li><li>各个基本类型在局部变量区的表现<ul><li>局部变量区等价于一个数组<ul><li>long double需要两个数组单元存储</li><li>其他基本类型和引用类型的值均占用一个数组单元</li></ul></li></ul></li></ul></li><li>字节码的操作数栈</li></ul></li><li><p>存储操作</p><ul><li>如果我们将一个int类型的值放到char short 等里面，相当于做了一次掩码  只会保留低位了</li></ul></li><li><p>加载</p><ul><li>算数运算完全依赖于操作数栈</li><li>堆当中的boolean, byte, char, short 加载到操作数栈当中，而后将栈上的值当成int类型来运算</li></ul></li></ul><h1 id="3-类的加载，链接，初始化过程"><a href="#3-类的加载，链接，初始化过程" class="headerlink" title="3. 类的加载，链接，初始化过程"></a>3. 类的加载，链接，初始化过程</h1><ul><li>首先.java文件会被编译成.class文件，而后我们需要类加载器来处理.class文件，让JVM对其进行处理</li><li>从class文件到内存当中的类，需要经过：<ul><li>加载<ul><li>查找字节流，并且根据此来创建类的过程<ul><li>将class类加载到内存当中</li><li>将静态数据结构转化为方法区当中运行时的数据结构</li><li>在堆当中生成一个代表这个类的java.lang.class对象作为数据访问的入口</li></ul></li><li>借助类加载器来完成查找字节流的过程<ul><li>启动类加载器 — bootstrap class loader<ul><li>负责加载最基础最重要的类，譬如JRE lib目录下Jar包中的类</li><li>由虚拟机参数 -Xbootclasspath指定的类</li></ul></li><li>其他类加载器 — 都是java.lang.ClassLoader的子类<ul><li>需要先由启动类加载器，将其加载至Java虚拟机当中，方能执行类的加载</li><li>E.G<ul><li>扩展类加载器 — 父类是启动类加载器<ul><li>负责加载相对次要、但又通用的类，比如存放在 JRE 的 lib/ext 目录下 jar 包中的类（以及由系统变量 java.ext.dirs 指定的类）</li></ul></li><li>应用类加载器 — 父类是扩展类加载器<ul><li>负责加载应用程序路径下的类<ul><li>例如虚拟机参数 -cp/-classpath, 系统变量java.class.path或者环境变量CLASSPATH所指定的路径</li><li>默认应用程序里包含的类应该由应用类加载器来进行加载</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>双亲委派模型<ul><li>当一个类加载器接收到加载请求时，会先将请求转发给父类加载器</li><li>在父类加载器没有找到所请求的类的情况下，该类加载器才会尝试去加载</li></ul></li><li>类加载器 — 命名空间的作用<ul><li>类的唯一性由类加载器实例和类的全名共同确定</li><li>即使同一串字节流，经由不同的类加载器加载，也会得到不同的类</li></ul></li></ul></li><li>链接<ul><li>将创建的类合并到Java虚拟机当中，并且使其能够执行的过程</li><li>过程<ul><li>验证<ul><li>确保被加载类能够满足Java虚拟机的约束条件</li><li>安全检查</li></ul></li><li>准备<ul><li>为被加载类的静态字段分配内存<ul><li>就是为static变量在方法区当中分配内存空间，设置变量的初始值</li></ul></li><li>也会来构造和其他类层次相关的数据结构，比如说用来实现虚方法的动态绑定的方法表</li></ul></li><li>解析 — 对于字节码符号引用的解析<ul><li>在 class 文件被加载至 Java 虚拟机之前，这个类无法知道其他类及其方法、字段所对应的具体地址，甚至不知道自己方法、字段的地址。</li><li>因此，每当需要引用这些成员时，Java 编译器会生成一个符号引用。在运行阶段，这个符号引用一般都能够无歧义地定位到具体目标上。</li><li>举例来说，对于一个方法调用，编译器会生成一个包含目标方法所在类的名字、目标方法的名字、接收参数类型以及返回值类型的符号引用，来指代所要调用的方法。</li><li>解析阶段的目的，正是将这些符号引用解析成为实际引用。如果符号引用指向一个未被加载的类，或者未被加载类的字段或方法，那么解析将触发这个类的加载（但未必触发这个类的链接以及初始化。）</li></ul></li></ul></li></ul></li><li>初始化<ul><li>内容<ul><li>为标记为常量值的字段赋值</li><li>执行clinit方法 — Java虚拟机通过加锁确定clinit方法仅仅会被执行一次<ul><li>如果直接赋值的静态字段被 final 所修饰，并且它的类型是基本类型或字符串时，那么该字段便会被 Java 编译器标记成常量值（ConstantValue），其初始化直接由 Java 虚拟机完成。</li><li>除此之外的直接赋值操作，以及所有静态代码块中的代码，则会被 Java 编译器置于同一方法中，并把它命名为 &lt; clinit &gt;。</li></ul></li></ul></li><li>触发情况<ul><li>当虚拟机启动时，初始化用户指定的主类；</li><li>当遇到用以新建目标类实例的 new 指令时，初始化 new 指令的目标类；</li><li>当遇到调用静态方法的指令时，初始化该静态方法所在的类；</li><li>当遇到访问静态字段的指令时，初始化该静态字段所在的类；</li><li>子类的初始化会触发父类的初始化；</li><li>如果一个接口定义了 default 方法，那么直接实现或者间接实现该接口的类的初始化，会触发该接口的初始化；</li><li>使用反射 API 对某个类进行反射调用时，初始化这个类；</li><li>当初次调用 MethodHandle 实例时，初始化该 MethodHandle 指向的方法所在的类。</li></ul></li></ul></li><li>卸载<ul><li>GC将无用对象从内存当中卸载掉</li></ul></li></ul></li><li>基本类型是Java虚拟机已经设置好的，而另一大类引用类型，Java将其细分为四种<ul><li>类<ul><li>有对应的字节流 — class文件</li></ul></li><li>接口<ul><li>有对应的字节流 - class文件</li></ul></li><li>数组类<ul><li>由Java虚拟机直接生成</li></ul></li><li>泛型参数</li></ul></li></ul><h1 id="4-JVM执行方法调用"><a href="#4-JVM执行方法调用" class="headerlink" title="4. JVM执行方法调用"></a>4. JVM执行方法调用</h1><h2 id="4-1-重载和重写"><a href="#4-1-重载和重写" class="headerlink" title="4.1 重载和重写"></a>4.1 重载和重写</h2><ul><li>重载<ul><li>同一个类当中方法名称相同，但是方法的参数不相同的情况</li><li>在编译过程当中就可以完成识别，Java编译器根据传入参数的声明类型，来选取重载方法<ul><li>三个阶段<ul><li>不考虑基本类型的自动拆箱装箱，还有可变长参数的情况下选择重载方法</li><li>1阶段没有找到适配的方法，那么就在允许自动拆装箱，但不允许可变长参数的情况下选取重载方法</li><li>2阶段没有找到适配的方法，那么在允许自动装拆箱以及可变长参数的情况下选取重载方法</li></ul></li><li>如果Java编译器在同一个阶段找到了多个适配方法，那么就会选择一个最为贴切的，决定贴切程度的一个关键就是形式参数类型的继承关系<ul><li>会选择那个范围更小的，比如某某的子类这样子</li></ul></li></ul></li></ul></li><li>重写<ul><li>子类定义了和父类非私有方法同名的方法，而且这两个方法的参数类型相同</li><li>如果这两个方法都是静态的，那么子类中的方法隐藏了父类中的方法</li><li>如果都不是静态，也不是私有的，那么子类的方法重写了父类当中的方法</li><li>方法重写 — 允许子类在继承父类部分功能的同时，拥有自己独特的行为</li></ul></li></ul><h2 id="4-2-JVM-静态和动态绑定"><a href="#4-2-JVM-静态和动态绑定" class="headerlink" title="4.2 JVM 静态和动态绑定"></a>4.2 JVM 静态和动态绑定</h2><ul><li>Java虚拟机识别方法<ul><li>类名</li><li>方法名</li><li>方法描述符 — method descriptor<ul><li>由方法的参数类型以及<strong>返回类型</strong>所构成的</li></ul></li></ul></li><li>JVM和Java语言在这里不太一样，同一个类下同样方法名，同样参数，但是不同返回值从JVM角度来说是可以被认为是不同的方法，是可以通过的</li><li>静态绑定<ul><li>在解析的时候便能够识别目标方法的情况</li><li>重载 — 是在编译阶段就完成了的，也可以成为static binding</li></ul></li><li>动态绑定<ul><li>在运行过程当中根据调用者的动态类型来识别目标方法的情况</li><li>重写 — 在JVM当中来做识别，dynamic binding</li></ul></li><li>Java字节码当中和调用相关的指令<ul><li>invokestatic  - 用于调用静态方法</li><li>invokespecial - 用于调用私有实例方法，构造器  以及使用super关键字调用父类的实例方法或者构造器</li><li>invokevirtual  - 用于调用非私有实例方法</li><li>invokeinterface - 用于调用接口方法</li><li>invokedynamic - 用于调用动态方法</li></ul></li></ul><h2 id="4-3-调用指令的符号引用"><a href="#4-3-调用指令的符号引用" class="headerlink" title="4.3 调用指令的符号引用"></a>4.3 调用指令的符号引用</h2><ul><li>在编译过程当中，我们并不知道目标方法的具体内存地址<ul><li>Java编译器会暂时用符号引用来表示该目标方法</li><li>这一符号引用包括目标方法所在的类或接口的名字，以及目标方法的方法名和方法描述符。</li></ul></li></ul><h1 id="5-垃圾回收"><a href="#5-垃圾回收" class="headerlink" title="5. 垃圾回收"></a>5. 垃圾回收</h1><h2 id="5-1-如何判断需要清理一个对象"><a href="#5-1-如何判断需要清理一个对象" class="headerlink" title="5.1 如何判断需要清理一个对象"></a>5.1 如何判断需要清理一个对象</h2><p><img src="https://i.loli.net/2021/06/28/dtOa3GUh5SkbAVY.png" alt="判断是否需要清理对象的逻辑"></p><ul><li>绿色部分是线程拥有的，会随着线程的结束而自动被回收 这里不需要考虑垃圾回收的问题</li><li>橙色部分是共享的，内存分配和回收都是动态的，因此垃圾收集器所关注的都是堆和方法这部分内存</li><li>判断对象存活的方法<ul><li>引用计数器计算<ul><li>给对象添加一个引用计数器，每次引用这个对象的时候计数器加一，引用失效则减一</li><li>计数器等于零的时候就不会再次试用了</li></ul></li><li>可达性分析计算<ul><li>将一系列GC ROOTS作为起始的存活对象集，从这个节点往下搜索</li><li>搜索所走过的路径成为引用链，将能被该集合引用的对象加入到集合当中</li><li>当搜索到一个对象到GC roots没有使用任何引用链的时候，就说明这个对象是不可用的</li></ul></li></ul></li></ul><h2 id="5-2-如何宣告一个对象的结束-死亡"><a href="#5-2-如何宣告一个对象的结束-死亡" class="headerlink" title="5.2 如何宣告一个对象的结束/ 死亡"></a>5.2 如何宣告一个对象的结束/ 死亡</h2><ul><li>finalize()是Object类的一个方法，一个对象的finalize()方法只会被系统自动调用一次，经过finalize()方法逃脱死亡的对象，二次标记的时候会给移出</li><li>整个流程如下<ol><li>如果对象进行可达性分析之后没发现与GC Roots相连的引用链，那它将会第一次标记并且进行一次筛选。判断的条件是决定这个对象是否有必要执行finalize()方法。如果对象有必要执行finalize()方法，则被放入F-Queue队列中。</li><li>GC对F-Queue队列中的对象进行二次标记。如果对象在finalize()方法中重新与引用链上的任何一个对象建立了关联，那么二次标记时则会将它移出“即将回收”集合。如果此时对象还没成功逃脱，那么只能被回收了。</li></ol></li></ul><h2 id="5-3-垃圾回收算法"><a href="#5-3-垃圾回收算法" class="headerlink" title="5.3 垃圾回收算法"></a>5.3 垃圾回收算法</h2><h3 id="5-3-1-标记清除算法"><a href="#5-3-1-标记清除算法" class="headerlink" title="5.3.1 标记清除算法"></a>5.3.1 标记清除算法</h3><ul><li><p>阶段</p><ul><li>标记<ul><li>标记处所有需要回收的对象</li></ul></li><li>清除<ul><li>标记结束以后进行统一的回收</li></ul></li></ul></li><li><p>原理</p><ul><li>将已死亡的对象标记为空闲内存，记录在一个空闲列表当中</li><li>当我们需要new一个对象的时候，内存管理模块会从空闲列表当中寻找空闲的内存来分给新的对象</li></ul></li><li><p>缺陷</p><ul><li><p>会使得内存当中的碎片非常多</p></li><li><p>容易导致当我们需要使用大块的内存的时候，无法分配足够的连续内存</p><p> <img src="https://i.loli.net/2021/06/28/TkZEf72unqIHLBY.png" alt="标记清除算法"></p></li></ul></li></ul><h3 id="5-3-2-复制算法"><a href="#5-3-2-复制算法" class="headerlink" title="5.3.2 复制算法"></a>5.3.2 复制算法</h3><ul><li><p>在标记清除算法的基础上做的优化</p><ul><li>将可用内存按照容量划分成两等分，每次只使用其中一块</li><li>当一块存满了 就将存活的对象复制到另一块上，然后交换指针的内容</li><li>以此解决碎片化的问题</li></ul></li><li><p>缺陷</p><ul><li><p>可用内存减少了！</p><p><img src="https://i.loli.net/2021/06/28/fQY3p1658zJkIxb.png" alt="复制算法"></p></li></ul></li></ul><h3 id="5-3-3-标记整理算法"><a href="#5-3-3-标记整理算法" class="headerlink" title="5.3.3 标记整理算法"></a>5.3.3 标记整理算法</h3><ul><li>标记了以后会做整理，将所有存活的对象都向内存块一端移动，然后直接清理掉边界以外的内存</li></ul><p><img src="https://i.loli.net/2021/06/28/7CNKE8HvLgVzrPk.png" alt="标记整理算法"></p><h3 id="5-3-4-分代收集算法"><a href="#5-3-4-分代收集算法" class="headerlink" title="5.3.4 分代收集算法"></a>5.3.4 分代收集算法</h3><ul><li>根据对象存活周期的不同将内存划分为几块</li><li>新生代<ul><li>每次垃圾收集都有大批对象死去，少量存活</li><li>所以可以选用复制算法</li></ul></li><li>老年代<ul><li>对象存活率高，没有额外空间对其进行分配和担保</li><li>需要使用标记-清理或者标记整理算法来进行回收</li></ul></li></ul><h2 id="5-4-垃圾收集器"><a href="#5-4-垃圾收集器" class="headerlink" title="5.4 垃圾收集器"></a>5.4 垃圾收集器</h2><ul><li>jdk8 默认收集器是Parallel Scavenge 和 Parallel Old</li><li>jdk9开始，G1收集器成为默认的垃圾收集器</li></ul><p><img src="https://i.loli.net/2021/06/28/hsKHpeEGm4lQydA.png" alt="垃圾收集器列表"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://snailclimb.gitee.io/javaguide/#/docs/java/jvm/[%E5%8A%A0%E9%A4%90]%E5%A4%A7%E7%99%BD%E8%AF%9D%E5%B8%A6%E4%BD%A0%E8%AE%A4%E8%AF%86JVM" target="_blank" rel="noopener">JavaGuide</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Log4j 是如何工作的？ </title>
      <link href="/Log4j-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F/"/>
      <url>/Log4j-%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="Log4j-是如何工作的？"><a href="#Log4j-是如何工作的？" class="headerlink" title="Log4j 是如何工作的？"></a>Log4j 是如何工作的？</h1><p>Created: Apr 24, 2021 5:02 PM<br>Tags: backend, tech<br>status: In Progress</p><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>组件化设计的日志系统</li></ul><pre><code>log.info(&quot;User signed in.&quot;); │ │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐ ├──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│ Console  │ │   └──────────┘    └──────────┘    └──────────┘    └──────────┘ │ │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐ ├──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│   File   │ │   └──────────┘    └──────────┘    └──────────┘    └──────────┘ │ │   ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐ └──&gt;│ Appender │───&gt;│  Filter  │───&gt;│  Layout  │───&gt;│  Socket  │     └──────────┘    └──────────┘    └──────────┘    └──────────┘</code></pre><ul><li>通过appender将同一条日志输出到不同的目的地</li></ul><h2 id="1-1-Logger组件"><a href="#1-1-Logger组件" class="headerlink" title="1.1 Logger组件"></a>1.1 Logger组件</h2><ul><li>负责产生日志，</li><li>级别<ul><li>DEBUG</li><li>INFO</li><li>WARN</li><li>ERROR</li><li>FATAL</li></ul></li></ul><h2 id="1-2-Appenders-组件"><a href="#1-2-Appenders-组件" class="headerlink" title="1.2 Appenders 组件"></a>1.2 Appenders 组件</h2><ul><li>负责将日志输出到不同的地方<ul><li>控制台 Console</li><li>文件 Files<ul><li>根据天数或者文件大小来产生新的文件</li></ul></li></ul></li></ul><h2 id="1-3-Layout"><a href="#1-3-Layout" class="headerlink" title="1.3 Layout"></a>1.3 Layout</h2><ul><li>完整文档<ul><li><a href="https://logging.apache.org/log4j/2.x/manual/layouts.html" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/manual/layouts.html</a></li></ul></li><li>说明你的日志要以何种格式来进行输出</li></ul><pre><code class="jsx">－X号: X信息输出时左对齐；%p: 输出日志信息优先级，即DEBUG，INFO，WARN，ERROR，FATAL,%d: 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss,SSS}输出类似：2002年10月18日 22：10：28，921%r: 输出自应用启动到输出该log信息耗费的毫秒数%c: 输出日志信息所属的类目，通常就是所在类的全名%t: 输出产生该日志事件的线程名%l: 输出日志事件的发生位置，相当于%C.%M(%F:%L)的组合,包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java:10)%x: 输出和当前线程相关联的NDC(嵌套诊断环境),尤其用到像java servlets这样的多客户多线程的应用中。%%: 输出一个&quot;%&quot;字符%F: 输出日志消息产生时所在的文件名称%L: 输出代码中的行号%m: 输出代码中指定的消息,产生的日志具体信息%n: 输出一个回车换行符，Windows平台为&quot;/r/n&quot;，Unix平台为&quot;/n&quot;输出日志信息换行</code></pre><h1 id="2-XML-配置文件格式"><a href="#2-XML-配置文件格式" class="headerlink" title="2. XML 配置文件格式"></a>2. XML 配置文件格式</h1><ul><li>通过Filter来过滤哪些需要输出，哪些不需要</li><li>通过Layout来格式化日志信息</li></ul><pre><code class="jsx">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration&gt;    &lt;Properties&gt;        &lt;!-- 定义日志格式 --&gt;        &lt;Property name=&quot;log.pattern&quot;&gt;%d{MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36}%n%msg%n%n&lt;/Property&gt;        &lt;!-- 定义文件名变量 --&gt;        &lt;Property name=&quot;file.err.filename&quot;&gt;log/err.log&lt;/Property&gt;        &lt;Property name=&quot;file.err.pattern&quot;&gt;log/err.%i.log.gz&lt;/Property&gt;    &lt;/Properties&gt;    &lt;!-- 定义Appender，即目的地 --&gt;    &lt;Appenders&gt;        &lt;!-- 定义输出到屏幕 --&gt;        &lt;Console name=&quot;console&quot; target=&quot;SYSTEM_OUT&quot;&gt;            &lt;!-- 日志格式引用上面定义的log.pattern --&gt;            &lt;PatternLayout pattern=&quot;${log.pattern}&quot; /&gt;        &lt;/Console&gt;        &lt;!-- 定义输出到文件,文件名引用上面定义的file.err.filename --&gt;        &lt;RollingFile name=&quot;err&quot; bufferedIO=&quot;true&quot; fileName=&quot;${file.err.filename}&quot; filePattern=&quot;${file.err.pattern}&quot;&gt;            &lt;PatternLayout pattern=&quot;${log.pattern}&quot; /&gt;            &lt;Policies&gt;                &lt;!-- 根据文件大小自动切割日志 --&gt;                &lt;SizeBasedTriggeringPolicy size=&quot;1 MB&quot; /&gt;            &lt;/Policies&gt;            &lt;!-- 保留最近10份 --&gt;            &lt;DefaultRolloverStrategy max=&quot;10&quot; /&gt;        &lt;/RollingFile&gt;    &lt;/Appenders&gt;    &lt;Loggers&gt;        &lt;Root level=&quot;info&quot;&gt;            &lt;!-- 对info级别的日志，输出到console --&gt;            &lt;AppenderRef ref=&quot;console&quot; level=&quot;info&quot; /&gt;            &lt;!-- 对error级别的日志，输出到err，即上面定义的RollingFile --&gt;            &lt;AppenderRef ref=&quot;err&quot; level=&quot;error&quot; /&gt;        &lt;/Root&gt;    &lt;/Loggers&gt;&lt;/Configuration&gt;</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.liaoxuefeng.com/wiki/1252599548343744/1264739436350112" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/1252599548343744/1264739436350112</a> </li><li><a href="https://blog.csdn.net/Mos_wen/article/details/50598967" target="_blank" rel="noopener">https://blog.csdn.net/Mos_wen/article/details/50598967</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> log </tag>
            
            <tag> log4j </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Route53</title>
      <link href="/Route53/"/>
      <url>/Route53/</url>
      
        <content type="html"><![CDATA[<h1 id="Route-53"><a href="#Route-53" class="headerlink" title="Route 53"></a>Route 53</h1><h1 id="1-How-Route53-works"><a href="#1-How-Route53-works" class="headerlink" title="1. How Route53 works?"></a>1. How Route53 works?</h1><ul><li>Intro<ul><li>DNS webservice</li><li>functionalities<ul><li>domain registration</li><li>DNS routing</li><li>health checking</li></ul></li></ul></li><li>Domain Registration<ul><li>You choose a domain name and confirm that it’s available</li><li>You provide names and contact information for the domain owner and other contacts</li><li>Route 53 automatically makes itself the DNS service for the domain by doing:<ul><li>create a hosted zone that has the same name as your domain</li><li>Assigns a set of <strong>four name servers to the hosted zone</strong>. When someone uses a browser to access your website, such as <a href="http://www.example.com/" target="_blank" rel="noopener">www.example.com</a>, these name servers tell the browser where to find your resources, such as a web server or an Amazon S3 bucket.</li><li>Gets the name servers from the hosted zone and adds them to the domain.</li></ul></li></ul></li></ul><h1 id="2-Concepts"><a href="#2-Concepts" class="headerlink" title="2. Concepts"></a>2. Concepts</h1><ul><li>Hosted Zone<ul><li>A container for records<ul><li>include info about how you want to route traffic for a domain and all of its subdomains</li><li>It has the same name as domain</li><li></li></ul></li></ul></li><li>Records<ul><li>Created in your hosted zone</li><li>For routing traffic to your resources</li><li>Each record includes information about how you want to route traffic for your domain<ul><li>Name</li><li>Type</li><li>Value</li></ul></li></ul></li><li>Name server<ul><li>Route53 will assign a set of 4 name servers to the hosted zone</li><li>name server tell the accessor (browser) where to find your resources</li></ul></li><li>Domain Name System Concepts<ul><li>Alias Record<ul><li>Record you create to route traffic to AWS resources</li></ul></li><li>subdomain<ul><li>A domain name that has one or more labels prepended to the registered domain name. For example, if you register the domain name <a href="http://example.com/" target="_blank" rel="noopener">example.com</a>, then <a href="http://www.example.com/" target="_blank" rel="noopener">www.example.com</a> is a subdomain. If you create the hosted zone <a href="http://accounting.example.com/" target="_blank" rel="noopener">accounting.example.com</a> for the <a href="http://example.com/" target="_blank" rel="noopener">example.com</a> domain, then <a href="http://seattle.accounting.example.com/" target="_blank" rel="noopener">seattle.accounting.example.com</a> is a subdomain.</li></ul></li></ul></li></ul><h1 id="3-Working-with-Hosted-Zones"><a href="#3-Working-with-Hosted-Zones" class="headerlink" title="3. Working with Hosted Zones"></a>3. Working with Hosted Zones</h1><p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-working-with.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/hosted-zones-working-with.html</a> </p><h1 id="4-Routing-Traffic-for-subdomains"><a href="#4-Routing-Traffic-for-subdomains" class="headerlink" title="4. Routing Traffic for subdomains"></a>4. Routing Traffic for subdomains</h1><p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-routing-traffic-for-subdomains.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-routing-traffic-for-subdomains.html</a> </p><ul><li>Option 1:<ul><li>Create records in the hosted zone for the doamin</li><li>we could create a record named <a href="http://test.example.com" target="_blank" rel="noopener">test.example.com</a> in the example.com hosted zone</li></ul></li><li>Option 2:<ul><li>Create a hosted zone for the subdomain, and create records in the new hosted zone</li></ul></li></ul><h1 id="5-Routing-Traffic-to-AWS-Resources"><a href="#5-Routing-Traffic-to-AWS-Resources" class="headerlink" title="5. Routing Traffic to AWS Resources"></a>5. Routing Traffic to AWS Resources</h1><p><a href="https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-aws-resources.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-to-aws-resources.html</a> </p><ul><li>The logic is to leverage on AWS PrivateLink for cross vpc connection, create the interface endpoint in your service, and build connection between your VPC and Route53</li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DNS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elastic Load Balancing </title>
      <link href="/Elastic-Load-Balancing/"/>
      <url>/Elastic-Load-Balancing/</url>
      
        <content type="html"><![CDATA[<h1 id="Elastic-Load-Balancing"><a href="#Elastic-Load-Balancing" class="headerlink" title="Elastic Load Balancing"></a>Elastic Load Balancing</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>What is ELB?</p><ul><li>ELB distributes your incoming traffic across multiple targets, such as EC2 instances, containers, and IP addresses, in one or more AZs</li><li>It monitors the health of its registered targets, and routes traffic to the healthy targets</li><li>Elastic Load Balancing help scale your load balancer as your incoming traffic change over time — automatically scale to the vast majority of workloads</li></ul></li><li><p>Benefits</p><ul><li>Increase the availability and fault tolerance</li><li>You could configure health checks, thus ELB monitor the health of the compute resources, LB only send requests to the healthy ones</li></ul></li><li><p>How it works</p><ul><li>Listener<ul><li>configure your LB to accept incoming traffic by specifying one or more listeners</li><li>a process that checks for connection requests<ul><li>with a protocol</li><li>port number</li></ul></li></ul></li><li>cross zone load balancing<ul><li>we should enable it cause it could make sure traffic is well distributed</li><li>when client send request, it will first go through route 53, and route 53 will distribute traffic thus each lb node receives 50% of traffic (2 LB nodes in total )</li></ul></li><li>request routing<ul><li>client — amazon dns service — return IP address to client side — client use the ip address to make call to LB</li><li>dns entry specify the TTL to 60 seconds, this ensure that the IP addresses can be remapped quickly in response to changing traffic</li></ul></li></ul></li></ul><h1 id="2-ELB-Types"><a href="#2-ELB-Types" class="headerlink" title="2. ELB Types"></a>2. ELB Types</h1><p><a href="https://aws.amazon.com/elasticloadbalancing/features/#Product_comparisons" target="_blank" rel="noopener">https://aws.amazon.com/elasticloadbalancing/features/#Product_comparisons</a>  </p><h1 id="3-Network-Load-Balancer"><a href="#3-Network-Load-Balancer" class="headerlink" title="3. Network Load Balancer"></a>3. Network Load Balancer</h1><h2 id="3-1-NLB-Overview"><a href="#3-1-NLB-Overview" class="headerlink" title="3.1 NLB Overview"></a>3.1 NLB Overview</h2><ul><li>Similar to ELB overview, NLB has listener<ul><li>a listener checks for connection requests from clients, using the protocol and port number you configure, and then forwards requests to a target group</li></ul></li><li>you can configure your health checks on a per target group basis</li><li>Health checks are performed on all targets registered to a target group that is specified in a listener rule for your load balancer.</li><li>functions at 4th layer of OSI, capable of handling millions of requests per second<ul><li>when receives a connection request, it <strong>selects a target from the target group</strong> for the default rule</li><li>attempts to <strong>open a TCP connection</strong> to the selected target <strong>on the port specified</strong> in the listener configuration</li></ul></li></ul><h2 id="3-2-How-to-create-one-NLB-via-Console"><a href="#3-2-How-to-create-one-NLB-via-Console" class="headerlink" title="3.2 How to create one NLB via Console?"></a>3.2 How to create one NLB via Console?</h2><ul><li>Create a target group<ul><li>set target type, name, protocol, port number, health check method</li></ul></li><li>Configure load balancer and listener<ul><li>Network mapping<ul><li>select the VPC that you used for your EC2 instances</li><li>select AZ and then select public subnet for the AZ</li></ul></li></ul></li></ul><h2 id="3-3-Concepts"><a href="#3-3-Concepts" class="headerlink" title="3.3 Concepts"></a>3.3 Concepts</h2><ul><li>Listener<ul><li>A listener is a process that checks for connection requests, using the protocol and port that you configure. The rules that you define for a listener determine how the load balancer routes requests to the targets in one or more target groups.</li></ul></li><li>Target Groups<ul><li>Each target group is used to route requests to one or more registered targets. When you create a listener, you specify a target group for its default action. Traffic is forwarded to the target group specified in the listener rule. You can create different target groups for different types of requests</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Load Balancer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VPC General</title>
      <link href="/VPC-General/"/>
      <url>/VPC-General/</url>
      
        <content type="html"><![CDATA[<h1 id="VPC-General"><a href="#VPC-General" class="headerlink" title="VPC General"></a>VPC General</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>Enable you to launch AWS resources into a virtual network that you’ve defined</li><li>VPC helps you to resemble a traditional network that you’d operate in your own data center</li></ul><h2 id="1-1-Concepts"><a href="#1-1-Concepts" class="headerlink" title="1.1 Concepts"></a>1.1 Concepts</h2><ul><li>VPC</li><li>Subnet<ul><li>A range of IP addresses in the VPC</li></ul></li><li>Route Table<ul><li>A set of rules, called routes, used to determine where network traffic is directed</li></ul></li><li>Internet Gateway<ul><li>A gateway that you attach to your VPC to enable communication between resources in your VPC and the internet</li></ul></li><li>VPC endpoint<ul><li>Enable you to privately connect your VPC to supported AWS services and VPC endpoint services powered by PrivateLink without requiring an internet gateway , NAT device, VPN connection, or AWS Direct Connect Connenction</li></ul></li><li>CIDR block<ul><li>classless inter domain routing</li></ul></li></ul><h1 id="2-How-Amazon-VPC-Work"><a href="#2-How-Amazon-VPC-Work" class="headerlink" title="2. How Amazon VPC Work?"></a>2. How Amazon VPC Work?</h1><h2 id="2-1-VPC-and-Subnets"><a href="#2-1-VPC-and-Subnets" class="headerlink" title="2.1 VPC and Subnets"></a>2.1 VPC and Subnets</h2><ul><li>Use public subnet for resources that must be connected to the internet</li><li>Use private subnet for resources that won’t be connected to the internet</li><li>To protect the AWS resources in each subnet<ul><li>you could use Security groups, network access control lists</li></ul></li></ul><h2 id="2-2-Accessing-the-internet"><a href="#2-2-Accessing-the-internet" class="headerlink" title="2.2 Accessing the internet"></a>2.2 Accessing the internet</h2><ul><li>Both subnets are public, they have both private and public IP address</li><li>They could access internet via Internet gateway</li></ul><p><img src="https://i.loli.net/2021/03/03/zdUi1WXuODGofjK.png" alt="1.png"></p><ul><li>NAT Device vs Internet Gateway<ul><li>When using NAT, it’s another layer of protection, but ultimately, you still need to use Internet Gateway</li><li>NAT  — network address translation device<ul><li>Allow instance in your VPC to instantiate outbound connections to the internet but prevent unsolicited inbound connections from the internet</li><li>It maps multiple private IPv4 addresses to a single public IPv4 address</li><li>A NAT device has an Elastic IP address and is connected to the internet through an internet gateway</li><li>You can connect an instance in a private subnet to the internet through the NAT device, which <strong>routes traffic from the instance to the internet gateway</strong>, and routes any responses to the instance.</li></ul></li></ul></li></ul><h2 id="2-3-Accessing-services-through-AWS-PrivateLink"><a href="#2-3-Accessing-services-through-AWS-PrivateLink" class="headerlink" title="2.3 Accessing services through AWS PrivateLink"></a>2.3 Accessing services through AWS PrivateLink</h2><ul><li><p>AWS PrivateLink enables you to privately connect your VPC to supported AWS services, services hosted by other AWS accounts (VPC endpoint services), and supported AWS Marketplace partner services.</p></li><li><p>To use AWS PrivateLink, create a VPC endpoint for a service in your VPC</p><ul><li><p>this creates an elastic network interface in your subnet with a private IP address that serves as an entry point for the traffic destined to the service</p><p>  <img src="https://i.loli.net/2021/03/03/KdQbqJLR2Or1DnB.png" alt="2.png"></p></li></ul></li></ul><h1 id="3-Getting-Started"><a href="#3-Getting-Started" class="headerlink" title="3. Getting Started"></a>3. Getting Started</h1><ul><li>Create a VPC with a /16 CIDR block<ul><li>has 65,536 private IP addresses</li></ul></li><li>attach an internet gateway to the VPC</li><li>for instances in public subnet, you need to assign an Elastic IP address to the instance</li><li>create a size /24 subnet in the VPC</li><li>create a custom route table, associate it with subnet<ul><li>to flow traffic between the subnet and the internet gateway</li></ul></li></ul><h2 id="3-1-EG-VPC-with-a-single-public-subnet"><a href="#3-1-EG-VPC-with-a-single-public-subnet" class="headerlink" title="3.1 EG - VPC with a single public subnet"></a>3.1 EG - VPC with a single public subnet</h2><h3 id="3-1-1-Basic-Setting"><a href="#3-1-1-Basic-Setting" class="headerlink" title="3.1.1 Basic Setting"></a>3.1.1 Basic Setting</h3><ul><li><p>VPC with/16 CIDR</p></li><li><p>subnet with /24 CIDR</p></li><li><p>internet gateway</p><ul><li>help connect the VPC to the internet and to other AWS services</li></ul></li><li><p>custom route table</p><ul><li><p>enable instances in the subnet to use IPV4 to communicate with other instances in the VPC</p><p><img src="https://i.loli.net/2021/03/03/PulS8ZxvFVXQtcJ.png" alt="3.png"></p></li></ul></li></ul><h3 id="3-1-2-Security"><a href="#3-1-2-Security" class="headerlink" title="3.1.2 Security"></a>3.1.2 Security</h3><ul><li>Security Groups<ul><li>control inbound and outbound traffic for your instances</li></ul></li><li>Network ACLs<ul><li>control inbound and outbound traffic for your subnets</li></ul></li></ul><p>See the recommended Security Group Setting and Network ACLs setting <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario1.html" target="_blank" rel="noopener">here</a> </p><h2 id="3-2-EG-VPC-with-Public-and-Private-subnets-NAT"><a href="#3-2-EG-VPC-with-Public-and-Private-subnets-NAT" class="headerlink" title="3.2 EG - VPC with Public and Private subnets (NAT)"></a>3.2 EG - VPC with Public and Private subnets (NAT)</h2><h3 id="3-2-1-Overview"><a href="#3-2-1-Overview" class="headerlink" title="3.2.1 Overview"></a>3.2.1 Overview</h3><ul><li><p>Scenario</p><ul><li>A public facing web application<ul><li>maintain back end servers that are not publicly accessible</li><li>database server in private subnet while the webserver in a public subnet</li></ul></li></ul></li><li><p>Public subnet vs private subnet</p><ul><li><p>instances in the public subnet can send outbound traffic directly to the internet, whereas the instances in the private subnet can’t</p></li><li><p>the instances in the private subnet can access the Internet by using a network address translation (NAT) gateway that resides in the public subnet</p></li><li><p>The database servers can connect to the Internet for software updates using the NAT gateway, but the Internet cannot establish connections to the database servers</p><p><img src="https://i.loli.net/2021/03/03/cb6tYu79jkWyMOH.png" alt="4.png"></p><h3 id="3-2-2-Security-Setting"><a href="#3-2-2-Security-Setting" class="headerlink" title="3.2.2 Security Setting"></a>3.2.2 Security Setting</h3><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html" target="_blank" rel="noopener">VPC with public and private subnets (NAT)</a></p><h2 id="3-3-Sharing-Public-Subnets-and-Private-Subnets"><a href="#3-3-Sharing-Public-Subnets-and-Private-Subnets" class="headerlink" title="3.3 Sharing Public Subnets and Private Subnets"></a>3.3 Sharing Public Subnets and Private Subnets</h2></li><li><p>still need to leverage on PrivateLinks, VPC Peering, etc.</p><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/example-vpc-share.html" target="_blank" rel="noopener">Example: Sharing public subnets and private subnets</a></p></li><li><p>Consider this scenario where you want an account to be responsible for the infrastructure, including subnets, route tables, gateways, and CIDR ranges and other accounts that are in the same AWS Organization to use the subnets. A VPC owner (Account A) creates the routing infrastructure, including the VPCs, subnets, route tables, gateways, and network ACLs. Account D wants to create public facing applications. Account B and Account C want to create private applications that do not need to connect to the internet and should reside in private subnets. Account A can use AWS Resource Access Manager to create a Resource Share for the subnets and then share the subnets. Account A shares the public subnet with Account D and the private subnet with Account B, and Account C. Account B, Account C, and Account D can create resources in the subnets. Each account can only see the subnets that are shared with them, for example, Account D can only see the public subnet. Each of the accounts can control their resources, including instances, and security groups.</p><p><a href="https://aws.amazon.com/cn/blogs/networking-and-content-delivery/vpc-sharing-a-new-approach-to-multiple-accounts-and-vpc-management/" target="_blank" rel="noopener">VPC sharing: A new approach to multiple accounts and VPC management | Amazon Web Services</a></p><h2 id="3-4-Service-using-AWS-PrivateLink-and-VPC-Peering"><a href="#3-4-Service-using-AWS-PrivateLink-and-VPC-Peering" class="headerlink" title="3.4 Service using AWS PrivateLink and VPC Peering"></a>3.4 Service using AWS PrivateLink and VPC Peering</h2><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-peer-region-example.html" target="_blank" rel="noopener">Examples: Services using AWS PrivateLink and VPC peering</a></p><p><a href="https://www.notion.so/PrivateLinks-e8e5f6802544401299fc3be21b10ed06" target="_blank" rel="noopener">PrivateLinks</a></p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>互联网广告竞价策略</title>
      <link href="/%E4%BA%92%E8%81%94%E7%BD%91%E5%B9%BF%E5%91%8A%E7%AB%9E%E4%BB%B7%E7%AD%96%E7%95%A5/"/>
      <url>/%E4%BA%92%E8%81%94%E7%BD%91%E5%B9%BF%E5%91%8A%E7%AB%9E%E4%BB%B7%E7%AD%96%E7%95%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="互联网广告竞价策略"><a href="#互联网广告竞价策略" class="headerlink" title="互联网广告竞价策略"></a>互联网广告竞价策略</h1><h1 id="1-传统竞价策略"><a href="#1-传统竞价策略" class="headerlink" title="1. 传统竞价策略"></a>1. 传统竞价策略</h1><h2 id="1-1-英式拍卖-公开增价拍卖OAB"><a href="#1-1-英式拍卖-公开增价拍卖OAB" class="headerlink" title="1.1 英式拍卖/ 公开增价拍卖OAB"></a>1.1 英式拍卖/ 公开增价拍卖OAB</h2><ul><li>OAB<ul><li>Open Ascending Bid</li></ul></li><li>卖家提供物品，在物品拍卖过程中，买家按照竞价阶梯由低至高喊价，出价最高者成为竞买的赢家</li><li>一般会为竞价设定一个终止时间</li></ul><h2 id="1-2-荷兰式拍卖-Sealed-Bid-Auction"><a href="#1-2-荷兰式拍卖-Sealed-Bid-Auction" class="headerlink" title="1.2 荷兰式拍卖 Sealed Bid Auction"></a>1.2 荷兰式拍卖 Sealed Bid Auction</h2><ul><li>竞价由高到低</li><li>递减直到第一个买家应价成交</li></ul><h2 id="1-3-第一价格密封拍卖-FPSB"><a href="#1-3-第一价格密封拍卖-FPSB" class="headerlink" title="1.3 第一价格密封拍卖 FPSB"></a>1.3 第一价格密封拍卖 FPSB</h2><ul><li>FPSB<ul><li>The first price sealed auction</li></ul></li><li>买方将自己的出价写在一个信封里面，众多买方进行投标，同一时间揭晓信封价格，出价最高者竞价成功</li></ul><h2 id="1-4-第二价格密封拍卖-SPSB"><a href="#1-4-第二价格密封拍卖-SPSB" class="headerlink" title="1.4 第二价格密封拍卖 SPSB"></a>1.4 第二价格密封拍卖 SPSB</h2><ul><li>SPSB<ul><li>The Second Price Sealed Auction</li></ul></li><li>买方将自己的出价写在一个信封里面，众多买方进行投标，同一时间揭晓信封价格，呦出价最高的买家获得物品，但他只需要支付<strong>所有投标者中的第二高价</strong></li></ul><h1 id="2-互联网广告竞价策略"><a href="#2-互联网广告竞价策略" class="headerlink" title="2. 互联网广告竞价策略"></a>2. 互联网广告竞价策略</h1><h2 id="2-1-广义第一价格GFP-Generalized-First-Price"><a href="#2-1-广义第一价格GFP-Generalized-First-Price" class="headerlink" title="2.1 广义第一价格GFP - Generalized First Price"></a>2.1 广义第一价格GFP - Generalized First Price</h2><ul><li>出价高者得，需要支付自己提出的报价</li><li>搜索广告竞价往往按照这种形式，缺点是<ul><li>平台方收益不稳定</li><li>竞价效率不高</li></ul></li><li>只考虑到出价没考虑到点击率，</li><li>价格上会因为相互广告商之间的比较，在一定范围内形成波动</li></ul><h2 id="2-2-广义第二价格GSP-Generalized-Second-Price"><a href="#2-2-广义第二价格GSP-Generalized-Second-Price" class="headerlink" title="2.2 广义第二价格GSP - Generalized Second Price"></a>2.2 广义第二价格GSP - Generalized Second Price</h2><ul><li>出价高者得到广告位，需要支付的是第二高者提出的报价加上一个最小值</li><li>不足之处在于不是一种鼓励讲真话的方式，大家有可能都会写一个很大的数字，认为会用到其他人标识的价格，所以整个解不一定是全局最优化的</li><li>这里的排序可以通过广告的出价排序，也可以通过期望收益最大来排序，即CTR x bid</li></ul><h2 id="2-3-VCG-Vickrey-Clarke-Groves"><a href="#2-3-VCG-Vickrey-Clarke-Groves" class="headerlink" title="2.3 VCG - Vickrey Clarke Groves"></a>2.3 VCG - Vickrey Clarke Groves</h2><ul><li>广告主为网民的一次点击支付他对其他广告主造成的效用损失</li><li>但是这种效用损失在实际场景中会非常难以计算</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.geek-share.com/detail/2606975685.html" target="_blank" rel="noopener">https://www.geek-share.com/detail/2606975685.html</a> </li><li><a href="https://www.wandouip.com/t5i229763/" target="_blank" rel="noopener">https://www.wandouip.com/t5i229763/</a></li><li><a href="https://en.wikipedia.org/wiki/Vickrey%E2%80%93Clarke%E2%80%93Groves_auction" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Vickrey–Clarke–Groves_auction</a>  </li><li><a href="https://en.wikipedia.org/wiki/Vickrey%E2%80%93Clarke%E2%80%93Groves_auction" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Vickrey–Clarke–Groves_auction</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis 数据结构使用</title>
      <link href="/Redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BD%BF%E7%94%A8/"/>
      <url>/Redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis-数据结构使用"><a href="#Redis-数据结构使用" class="headerlink" title="Redis 数据结构使用"></a>Redis 数据结构使用</h1><h1 id="1-String的内存空间消耗问题"><a href="#1-String的内存空间消耗问题" class="headerlink" title="1. String的内存空间消耗问题"></a>1. String的内存空间消耗问题</h1><h2 id="1-1-String在保存数据时内存空间消耗较多"><a href="#1-1-String在保存数据时内存空间消耗较多" class="headerlink" title="1.1 String在保存数据时内存空间消耗较多"></a>1.1 String在保存数据时内存空间消耗较多</h2><ul><li>String类型除了实际记录的数据，还需要额外的内存空间记录数据长度，空间使用等信息，这些信息被称为元数据</li><li>当实际保存的数据比较小的时候，元数据的空间开销就会比较大</li><li>当保存64位有符号整数的时候<ul><li>String类型会将其保存为一个8字节的Long类型整数</li><li>int编码方式</li></ul></li><li>当保存的数据中包含字符的时候<ul><li>String 用简单动态字符串 Simple Dynamic String ， 共有三部分组成<ul><li>buf<ul><li>字节数组，保存实际数据</li><li>为了表示字节数组的结束，会在数组最后加一个\0. 这里会额外占用一个字节的开销</li></ul></li><li>len<ul><li>占四个字节，表示buf的已用长度</li></ul></li><li>alloc<ul><li>占四个字节，表示buf的实际分配长度，一般来说会大于len</li></ul></li></ul></li><li>故而在上述的分析当中，len 和alloc就是元数据，带来了一部分的额外开销</li></ul></li></ul><h2 id="1-2-RedisObject-的结构"><a href="#1-2-RedisObject-的结构" class="headerlink" title="1.2 RedisObject 的结构"></a>1.2 RedisObject 的结构</h2><ul><li><p>Redis本身支持多种数据类型，而不同数据类型都会有一些相同的元数据需要记录</p><ul><li>最后一次访问的时间</li><li>被引用的次数等</li></ul></li><li><p>因此Redis会用一个RedisObject结构体来统一记录这些元数据，同时指向实际数据</p></li><li><p>另外出于节省内存空间的考虑</p><ul><li><p>当保存的是Long类型整数时，RedisObject中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数，节省了指针的空间开销</p></li><li><p>当保存的是字符串数据，并且字符串小于等于44个字节，RedisObject中的元数据，指针的SDS是一块连续的内存区域，来避免内存碎片</p></li><li><p>当保存的数据量大于44字节的时候，SDS的数据量就会变多，Redis就不再把SDS和RedisObject布局在一起了，会给SDS分配独立的空间，并且用指针指向SDS结构</p><p><img src="https://i.loli.net/2021/02/09/JoY9Hi8NqIElBDW.png" alt="Redis Object"></p></li></ul></li><li><p>在计算总共消耗的内存的时候，值得注意的是除了使用RedisObject本身，Redis还维护了一个全局哈希表来保存所有键值对，这个结构体有三个8字节的指针，共24字节。Redis使用的是jemalloc内存分配库，会根据申请的字节数N，找一个比N大，但是最接近N的2的幂次数作为分配的空间，来减少频繁分配的次数</p></li></ul><p><img src="https://i.loli.net/2021/02/09/xO2vECGYoRdl4jB.png" alt="RedisObject Entity"></p><h1 id="2-压缩列表"><a href="#2-压缩列表" class="headerlink" title="2. 压缩列表"></a>2. 压缩列表</h1><ul><li><p>压缩列表的构成</p><p>  <img src="https://i.loli.net/2021/02/18/ALm8GYT2r7cRXqW.png" alt="压缩列表构成"></p><ul><li><p>表头</p><ul><li>zlbytes — 列表长度</li><li>zltail — 列表尾</li><li>zllen — 列表entry个数</li></ul></li><li><p>表尾</p><ul><li>zlend — 列表结束</li></ul></li><li><p>表entry</p><ul><li>是连续的entry<ul><li>因为是挨着来进行放置的，所以不需要再使用额外的指针进行连接，就可以节省指针所占用的空间了</li></ul></li><li>包括以下几部分：<ul><li>prev_len — 前一个entry的长度</li><li>len — 自身长度  4字节</li><li>encoding — 编码方式 1字节</li><li>content — 保存实际数据</li></ul></li></ul></li><li><p>Redis Hash类型底层有两种实现结构</p><ul><li>压缩列表</li><li>哈希表</li></ul></li><li><p>通过阈值确定应该使用哪一种来保存数据</p><ul><li>hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数。</li><li>hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度。</li></ul></li></ul></li></ul><h1 id="3-集合的使用"><a href="#3-集合的使用" class="headerlink" title="3. 集合的使用"></a>3. 集合的使用</h1><ul><li>使用场景<ul><li>一个key对应一个数据集合<ul><li>比如手机app的用户登录信息 — 一天对应一系列用户ID或者移动设备ID</li><li>电商商品用户评价列表 — 一个商品对应一系列评论</li></ul></li><li>在这样子的场景当中，除了记录信息，我们还需要对集合当中的数据进行统计，而我们选用的数据类型必须能够高效的统计这些数据</li></ul></li></ul><h2 id="3-1-聚合统计"><a href="#3-1-聚合统计" class="headerlink" title="3.1 聚合统计"></a>3.1 聚合统计</h2><ul><li><p>定义</p><ul><li>指统计多个集合元素的聚合结果</li></ul></li><li><p>例子</p><ul><li>统计多个集合的共有元素</li><li>将两个集合相比，统计其中一个集合独有的元素</li><li>统计多个集合的所有元素</li></ul></li><li><p>当你需要对多个集合进行聚合计算时，Set 类型会是一个非常不错的选择。</p></li><li><p>这里有一个潜在的风险。Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。</p><ul><li>你可以从主从集群中选择一个从库，让它专门负责聚合计算</li><li>或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了。</li></ul></li></ul><h2 id="3-2-排序统计"><a href="#3-2-排序统计" class="headerlink" title="3.2 排序统计"></a>3.2 排序统计</h2><ul><li>E.G<ul><li>电商网站提供最新评论列表，需要使得集合当中的元素可以按序排列<ul><li>List和Sorted Set属于有序集合</li><li>List按照元素进入List的顺序进行排序，而Sorted Set根据元素的权重来排序</li></ul></li></ul></li><li>使用list来做排序的问题在于是通过元素在List当中的位置来排序，新元素插入会改变原有的顺序，都会顺次后移</li><li>Sorted Set相对应的是根据元素的实际权重来排序和获取数据<ul><li>Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样的话，即使集合中的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确地获取到按序排列的数据。</li></ul></li></ul><h2 id="3-3-二值状态统计"><a href="#3-3-二值状态统计" class="headerlink" title="3.3 二值状态统计"></a>3.3 二值状态统计</h2><ul><li>集合元素的取值只有0和1两种<ul><li>可以对于数据结构进行优化，使用Bitmap</li><li>Bitmap本身是使用String类型作为底层数据结构来实现的一种统计二值状态的数据类型，可以将其理解为一个bit数组</li></ul></li><li>查看签到情况的基本操作</li></ul><pre><code class="jsx">// 记录8.3 签到SETBIT uid:sign:3000:202008 2 1// 查询8.3是否签到GETBIT uid:sign:3000:202008 2// 统计该用户20年8月份的签到次数BITCOUNT uid:sign:3000:202008</code></pre><ul><li>统计应用当中10天连续签到的用户数量<ul><li>Bitmap支持使用BITOP命令来对多个Bitmap按位做与，或，异或，的操作，操作结果会保存到一个新的bitmap当中</li><li>在统计 1 亿个用户连续 10 天的签到情况时，你可以把每天的日期作为 key，每个 key 对应一个 1 亿位的 Bitmap，每一个 bit 对应一个用户当天的签到情况。接下来，我们对 10 个 Bitmap 做“与”操作，得到的结果也是一个 Bitmap。在这个 Bitmap 中，只有 10 天都签到的用户对应的 bit 位上的值才会是 1。最后，我们可以用 BITCOUNT 统计下 Bitmap 中的 1 的个数，这就是连续签到 10 天的用户总数了。</li></ul></li></ul><h2 id="3-4-基数统计"><a href="#3-4-基数统计" class="headerlink" title="3.4 基数统计"></a>3.4 基数统计</h2><ul><li>统计一个集合中不重复的元素个数 — 统计网页的UV<ul><li>需要去重 — 一个用户一天内的多次访问只能算一次</li><li>使用set 或者hash的话都会需要将不同的id记录下来，最后看整个数据结构内元素的数量，会很大程度上占用内存</li></ul></li><li>HyperLogLog<ul><li>用于统计基数的数据集合<ul><li>当集合元素数量非常多的时候，计算基数所需的空间是固定的，而且比较小</li><li>有一点需要你注意一下，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误算率是 0.81%。这也就意味着，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但是，如果你需要精确统计结果的话，最好还是继续用 Set 或 Hash 类型。</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>lsof/ ulimit/ ps</title>
      <link href="/lsof-ulimit-ps/"/>
      <url>/lsof-ulimit-ps/</url>
      
        <content type="html"><![CDATA[<h1 id="1-lsof"><a href="#1-lsof" class="headerlink" title="1. lsof"></a>1. lsof</h1><h1 id="1-1-File-Descriptor-in-Linux"><a href="#1-1-File-Descriptor-in-Linux" class="headerlink" title="1.1 File Descriptor in Linux"></a>1.1 File Descriptor in Linux</h1><ul><li>Linux consider everything as a file<ul><li>pipes, sockets, directories, devices, etc</li></ul></li></ul><h1 id="1-2-What-does-lsof-do"><a href="#1-2-What-does-lsof-do" class="headerlink" title="1.2 What does lsof do?"></a>1.2 What does lsof do?</h1><ul><li>lsof means — List Open Files</li><li>some columns need to understand<ul><li>FD<ul><li>stands for file descriptor</li><li>possible values<ul><li>cwd — current working directory</li><li>rtd — root directory</li><li>txt — program text</li><li>mem — memory mapped file</li><li>(number)(parameter)<ul><li>r for read acccess</li><li>w for write</li><li>u for both read and write</li></ul></li></ul></li></ul></li><li>TYPE<ul><li>DIR — directory</li><li>REG — Regular file</li><li>CHR — Character special file</li><li>FIFO — First In First Out</li></ul></li></ul></li></ul><pre><code class="jsx">// show long listing of open files, show cols like Command, PID, USER, FD, TYPE# lsof // display the list of all opened file of uder leilei# lsof -u leilei// find process running on specific port# lsof -i TCP:22// list only IPv4 &amp; IPv6 Open Files # lsof -i 4# lsof -i 6// list open files of TCP port ranges from 11 - 1023# lsof -i TCP:1-1023// exclude user with ^# lsof -i -u^leilei// list all network connections # lsof -i// search by PID # lsof -p PID // kill all activities of particular user # kill -9 `lsof -t -u leilei`</code></pre><h1 id="2-ulimit"><a href="#2-ulimit" class="headerlink" title="2. ulimit"></a>2. ulimit</h1><h1 id="2-1-Overview"><a href="#2-1-Overview" class="headerlink" title="2.1 Overview"></a>2.1 Overview</h1><ul><li>Set or report the resource limit of the current user.</li><li>Use with ulimit requires admin access, it only work on systems that allow control through the shell</li><li>Types of resource limitation<ul><li>hard limit<ul><li>define the physical limit that the user can reach</li></ul></li><li>soft limit<ul><li>manageable by the user, its value can go up to the hard limit</li></ul></li></ul></li><li>system resources are defined in a configuration file located at <code>/etc/security/limits.conf</code></li></ul><h1 id="2-2-Common-Commands"><a href="#2-2-Common-Commands" class="headerlink" title="2.2 Common Commands"></a>2.2 Common Commands</h1><pre><code class="jsx">// print all the resource limits for the current user # ulimit -a// check the value of max core file size # ulimit -c // check the max data seg size# ulimit -d// check the max stack size of current user # ulimit -s// check the max number of user processes # ulimit -u// check the max number of threads # ulimit -T // check the size of virtual memory # ulimit -v // check time each process is allowed to run for # ulimit -t // check how many file descriptors a process can have # ulimit -n </code></pre><h1 id="3-ps"><a href="#3-ps" class="headerlink" title="3. ps"></a>3. ps</h1><h1 id="3-1-Overview"><a href="#3-1-Overview" class="headerlink" title="3.1 Overview"></a>3.1 Overview</h1><ul><li><p>Linux is a multi-tasking and multi-user system</p></li><li><p>so it allows multiple processes to operate simultaneously without interfering with each other</p></li><li><p>A process is an executing instance of a program and carry out different tasks within the operating system</p></li><li><p>PS command help us to review information related with the processes on a system</p><ul><li>used to list the currently running processes and their PIDs along with some other information depends on different options</li></ul></li></ul><h1 id="3-2-Some-common-commands"><a href="#3-2-Some-common-commands" class="headerlink" title="3.2 Some common commands"></a>3.2 Some common commands</h1><ul><li>Some common columns you should know what it means<ul><li>PID - the unique process ID</li><li>TTY - terminal type that the user is logged into</li><li>TIME - amount of CPU in minutes and seconds that the process has been running<ul><li>sometimes you see TIME as 00:00:00, merely means the total accumulated CPU utilization time for any process currently is 0</li></ul></li><li>CMD - name of the command that launched the process</li><li>C - the CPU utilization in percentage</li><li>STIME - the start time of the process</li></ul></li></ul><pre><code class="java"># ps PID TTY          TIME CMD12330 pts/0    00:00:00 bash21621 pts/0    00:00:00 ps// view all the running processes # ps -A # ps -e// view all processes associated with the terminal # ps -T // view all the running processes # ps -r // view all the processes owned by you # ps -x // print all the processes within the system # ps -e// More detailed output by using -f option # ps -e -f // Search for a particular process # ps -C systemd</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.geeksforgeeks.org/lsof-command-in-linux-with-examples/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/lsof-command-in-linux-with-examples/</a>  </p><p><a href="https://www.tecmint.com/10-lsof-command-examples-in-linux/" target="_blank" rel="noopener">https://www.tecmint.com/10-lsof-command-examples-in-linux/</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Distributed Locks with the DynamoDB Lock Client </title>
      <link href="/Distributed-Locks-with-the-DynamoDB-Lock-Client/"/>
      <url>/Distributed-Locks-with-the-DynamoDB-Lock-Client/</url>
      
        <content type="html"><![CDATA[<h1 id="Distributed-Locks-with-the-DynamoDB-Lock-Client"><a href="#Distributed-Locks-with-the-DynamoDB-Lock-Client" class="headerlink" title="Distributed Locks with the DynamoDB Lock Client"></a>Distributed Locks with the DynamoDB Lock Client</h1><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>DynamoDB Lock Client</p><ul><li>enable you to solve distributed computing problems like leader election and distributed locking with client only code and a DDB table</li></ul></li><li><p>Why we need it</p><ul><li>Distributed Locking is complicated<ul><li>you need to <strong>atomically ensure</strong> only one actor is modifying a <strong>stateful resource</strong> at any given time</li></ul></li></ul></li></ul><h1 id="2-Practical-Example"><a href="#2-Practical-Example" class="headerlink" title="2. Practical Example"></a>2. Practical Example</h1><ul><li>Background<ul><li>A retail bank that want to ensure at most one customer service representative change customer details at a time</li><li>solution<ul><li>temporarily lock customer records during an update</li><li>suppose there are bunch different tables to contain all customer information, as the tables are independent, so we cannot just wrap the changes we need in a relational transaction</li><li>we need to lock customer id at a high level</li><li>You’d do so with a locking API action for a certain duration in your application before making any changes.</li></ul></li></ul></li></ul><h2 id="2-1-Locking-Protocol"><a href="#2-1-Locking-Protocol" class="headerlink" title="2.1 Locking Protocol"></a>2.1 Locking Protocol</h2><ul><li>For a new lock, the lock clients store a lock item in the lock table<ul><li>it stores<ul><li>the host name of the owner</li><li>the lease duration in milliseconds</li><li>a UUID unique to the host</li><li>the host system clock time when the lock was initially created</li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2021/01/15/gk6qico4zUw1YXK.png" alt="Whole Workflow"></p><ol><li>Host A acquires a lock on Moe by writing an item to the lock table on the condition that no item keyed at “Moe” exists yet. Host A<br>acquires the lock with a revision version number (RVN) of UUID.</li><li>Host B tries to get a lock on Moe with a RVN UUID.</li><li>Host B checks to see if a lock already exists with a GetItem call.</li><li>In this case, host B finds that host A holds a lock on Moe with a record version number (RVN) of UUID. The same application runs on hosts A and B. That being so, host B<br>expects host A to heartbeat and renew the lock on Moe in less than 10 seconds, if host A intends to keep the lock on Moe. Host A heartbeats once, and uses a conditional update on the lock keyed at Moe to update the RVN of the lock to UUID.</li><li>Host B checks 10 seconds after the first AcquireLock call to see if the RVN in A’s lock on Moe changed with a conditional UpdateItem call and a RVN of UUID.</li><li>Host A successfully updates the lock. Thus, host B finds the new RVN equal to UUID and waited 10 more seconds. Host A died after the first heartbeat, so it never changes the RVN past UUID. When host B calls tries to acquire a lock on Moe for the third time, it finds that the RVN was still UUID, the same RVN retrieved on the second lock attempt.</li><li>In this case, hosts A and B run the same application. Because host B expects host A to heartbeat if host A is healthy and intends to keep the lock, host B considers the lock on Moe expired. Host B’s conditional update to acquire the lock on Moe succeeds, and your application makes progress!</li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://aws.amazon.com/blogs/database/building-distributed-locks-with-the-dynamodb-lock-client/" target="_blank" rel="noopener">https://aws.amazon.com/blogs/database/building-distributed-locks-with-the-dynamodb-lock-client/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>序列化和反序列化</title>
      <link href="/%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"/>
      <url>/%E5%BA%8F%E5%88%97%E5%8C%96%E5%92%8C%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="序列化和反序列化"><a href="#序列化和反序列化" class="headerlink" title="序列化和反序列化"></a>序列化和反序列化</h1><h1 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h1><ul><li><p>序列化</p><ul><li>将对象转化为可传输的字节序列的过程<ul><li>是属于TCP/ IP协议应用层的一部分</li><li>常用的你可能看到的名字<ul><li>serialization</li><li>marshalling</li><li>flatteing</li></ul></li></ul></li><li>常见序列化方式<ul><li>JSON</li><li>XML</li></ul></li></ul></li><li><p>反序列化</p><ul><li>将字节序列还原为对象的过程称为反序列化</li></ul></li><li><p>二进制串</p><ul><li>二进制串：序列化所生成的二进制串指的是存储在内存中的一块数据。</li><li>C++语言具有内存操作符，所以二进制串的概念容易理解，例如，C++语言的字符串可以直接被传输层使用，因为其本质上就是以’\0’结尾的存储在内存中的二进制串。</li><li>在Java语言里面，二进制串的概念容易和String混淆。实际上String 是Java的一等公民，是一种特殊对象（Object）。对于跨语言间的通讯，序列化后的数据当然不能是某种语言的特殊数据类型。二进制串在Java里面所指的是<strong>byte[]</strong>，byte是Java的8中原生数据类型之一（Primitive data types）</li></ul></li></ul><h1 id="2-为什么要序列化"><a href="#2-为什么要序列化" class="headerlink" title="2. 为什么要序列化"></a>2. 为什么要序列化</h1><ul><li>为了使得对象可以跨平台进行存储，进行网络传输</li><li>本质上存储和网络传输都需要将一个对象状态保存成一种跨平台识别的字节格式，然后其他的平台才可以通过字节信息解析还原对象的信息</li><li>而且序列化后可以存在文件当中，永久性的存到硬盘上</li></ul><h1 id="3-序列化技术选择的metrics"><a href="#3-序列化技术选择的metrics" class="headerlink" title="3. 序列化技术选择的metrics"></a>3. 序列化技术选择的metrics</h1><h2 id="3-1-跨平台-amp-跨语言"><a href="#3-1-跨平台-amp-跨语言" class="headerlink" title="3.1 跨平台 &amp; 跨语言"></a>3.1 跨平台 &amp; 跨语言</h2><p>是否需要支持多种语言，应该选择没有语言局限性的序列化协议</p><ul><li>Json会是一个很好的选择，因为Json表示出来就是一个字符串，可以被所有语言读取，也可以方便地存储到磁盘或者通过网络传输</li><li>JSON不仅是标准格式，并且比XML更快，而且可以直接在Web页面当中读取</li></ul><h2 id="3-2-性能"><a href="#3-2-性能" class="headerlink" title="3.2 性能"></a>3.2 性能</h2><h3 id="3-2-1-速度"><a href="#3-2-1-速度" class="headerlink" title="3.2.1 速度"></a>3.2.1 速度</h3><p>如果序列化的频率非常高，那么选择序列化速度快的协议会为你的系统性能提升不少</p><h3 id="3-2-3-序列化后的大小"><a href="#3-2-3-序列化后的大小" class="headerlink" title="3.2.3 序列化后的大小"></a>3.2.3 序列化后的大小</h3><p>数据量小对于网络的压力小，传输也会快，能够提升整体的性能</p><p>序列化需要在原有的数据上加上描述字段，以为反序列化解析之用。如果序列化过程引入的额外开销过高，可能会导致过大的网络，磁盘等各方面的压力。对于海量分布式存储系统，数据量往往以TB为单位，巨大的的额外空间开销意味着高昂的成本。</p><h2 id="3-3-鲁棒性"><a href="#3-3-鲁棒性" class="headerlink" title="3.3 鲁棒性"></a>3.3 鲁棒性</h2><p>从两方面来进行考虑</p><ul><li>成熟度<ul><li>一个协议从制定，实施到成熟是一个很漫长的阶段。协议的强健性依赖于大量而全面的测试。对于致力于提供高质量服务的系统，采用处于测试阶段的序列化协议会带来很高的风险。</li></ul></li><li>语言/ 平台的公平性<ul><li>当所支持的语言或者平台之间存在难以调和的特性的时候，协议制定者需要做权衡<ul><li>做支持更多人使用的语言/平台  vs 为了支持更多的语言/ 平台而放弃某个特性</li></ul></li></ul></li></ul><h2 id="3-4-可调试性-可读性"><a href="#3-4-可调试性-可读性" class="headerlink" title="3.4 可调试性/ 可读性"></a>3.4 可调试性/ 可读性</h2><ul><li>序列化和反序列化的数据正确性和业务正确性的调试往往需要很长的时间，良好的调试机制会大大提高开发效率。</li><li>序列化后的二进制串往往不具备人眼可读性，为了验证序列化结果的正确性，写入方不得同时撰写反序列化程序，或提供一个查询平台–这比较费时；</li><li>另一方面，如果读取方未能成功实现反序列化，这将给问题查找带来了很大的挑战–难以定位是由于自身的反序列化程序的bug所导致还是由于写入方序列化后的错误数据所导致</li></ul><h2 id="3-5-可扩展性-兼容性"><a href="#3-5-可扩展性-兼容性" class="headerlink" title="3.5 可扩展性/ 兼容性"></a>3.5 可扩展性/ 兼容性</h2><p>移动互联时代，业务系统需求的更新周期变得更快，新的需求不断涌现，而老的系统还是需要继续维护。如果序列化协议具有良好的可扩展性，支持自动增加新的业务字段，而不影响老的服务，这将大大提供系统的灵活度</p><h2 id="3-6-安全性-访问限制"><a href="#3-6-安全性-访问限制" class="headerlink" title="3.6 安全性/ 访问限制"></a>3.6 安全性/ 访问限制</h2><p>在序列化选型的过程中，安全性的考虑往往发生在<strong>跨局域网访问的场景</strong>。当通讯发生在公司之间或者跨机房的时候，出于安全的考虑，对于跨局域网的访问往往被限制为基于HTTP/HTTPS的80和443端口。如果使用的序列化协议没有兼容成熟的HTTP传输层框架支持，可能会导致以下三种结果之一：</p><p>第一、因为访问限制而降低服务可用性。<br>第二、被迫重新实现安全协议而导致实施成本大大提高。<br>第三、开放更多的防火墙端口和协议访问，而牺牲安全性。</p><h1 id="4-序列化和反序列化的组件"><a href="#4-序列化和反序列化的组件" class="headerlink" title="4. 序列化和反序列化的组件"></a>4. 序列化和反序列化的组件</h1><h2 id="4-1-IDL-—-Interface-Description-Language"><a href="#4-1-IDL-—-Interface-Description-Language" class="headerlink" title="4.1 IDL — Interface Description Language"></a>4.1 IDL — Interface Description Language</h2><ul><li>参与通讯的各方需要对通讯的内容做相关的约定 — specifications</li><li>这个约定需要和语言以及平台无关</li><li>被称为接口描述语言</li></ul><h2 id="4-2-IDL-Compiler"><a href="#4-2-IDL-Compiler" class="headerlink" title="4.2 IDL Compiler"></a>4.2 IDL Compiler</h2><ul><li>IDL文件中约定的内容为了在各个语言和平台可见，需要有一个编译器，将IDL文件转换成各个语言对应的动态库</li></ul><h2 id="4-3-Stub-Skeleton-Lib"><a href="#4-3-Stub-Skeleton-Lib" class="headerlink" title="4.3 Stub/ Skeleton Lib"></a>4.3 Stub/ Skeleton Lib</h2><ul><li>负责序列化和反序列化的工作代码</li><li>Stub是一段部署在分布式系统客户端的代码，一方面接收应用层的参数，并对其序列化后通过底层协议栈发送到服务端，另一方面接收服务端序列化后的结果数据，反序列化后交给客户端应用层；</li><li>Skeleton部署在服务端，其功能与Stub相反，从传输层接收序列化参数，反序列化后交给服务端应用层，并将应用层的执行结果序列化后最终传送给客户端Stub。</li></ul><p><img src="https://i.loli.net/2021/01/14/l1jSYEnHLxdzD92.png" alt="序列化反序列化过程"></p><h1 id="5-常见的序列化和反序列化协议"><a href="#5-常见的序列化和反序列化协议" class="headerlink" title="5. 常见的序列化和反序列化协议"></a>5. 常见的序列化和反序列化协议</h1><p>下面以这两个类的序列化反序列化为例</p><pre><code class="java">class Address{    private String city;    private String postcode;    private String street;}public class UserInfo{    private Integer userid;    private String name;    private List&lt;Address&gt; address;}</code></pre><h2 id="5-1-XML-amp-SOAP"><a href="#5-1-XML-amp-SOAP" class="headerlink" title="5.1 XML &amp; SOAP"></a>5.1 XML &amp; SOAP</h2><h3 id="5-1-1-XML"><a href="#5-1-1-XML" class="headerlink" title="5.1.1 XML"></a>5.1.1 XML</h3><ul><li>特点<ul><li>描述语言，self-describing</li><li>XML自身可以被用于XML序列化的IDL</li><li>标准的XML描述格式有<ul><li>DTD - Document Type Definition</li><li>XSD - XML Schema Definition</li></ul></li></ul></li><li>优点<ul><li>跨机器，跨语言</li><li>可读性<ul><li>因为其最初的目标是对互联网文档Document进行标记，所以其设计理念当中就包含了对于人和机器都具备可读性</li></ul></li></ul></li><li>缺点<ul><li>冗长，复杂</li></ul></li></ul><h3 id="5-1-2-SOAP-Simple-Object-Access-Protocol"><a href="#5-1-2-SOAP-Simple-Object-Access-Protocol" class="headerlink" title="5.1.2 SOAP - Simple Object Access Protocol"></a>5.1.2 SOAP - Simple Object Access Protocol</h3><ul><li><p>概念</p><ul><li>基于XML为序列化和反序列化协议的结构化的消息传递协议</li><li>SOAP支持多种传输层协议，最常见的使用方式是XML + HTTP</li></ul></li><li><p>IDL</p><ul><li>SOAP协议的主要接口描述语言IDL是WSDL — Web Service Description Language</li></ul></li><li><p>SOAP具有安全、可扩展、跨语言、跨平台并支持多种传输层协议。如果不考虑跨平台和跨语言的需求，XML的在某些语言里面具有非常简单易用的序列化使用方法，无需IDL文件和第三方编译器， 例如Java＋XStream</p></li><li><p>自我描述和递归</p><ul><li><p>SOAP是一种采用XML进行序列化和反序列化的协议，它的IDL是WSDL. 而WSDL的描述文件是XSD，而XSD自身是一种XML文件。 这里产生了一种有趣的在数学上称之为“递归”的问题，这种现象往往发生在一些具有自我属性（Self-description）的事物上</p><pre><code class="java">&lt;xsd:complexType name=&#39;Address&#39;&gt;   &lt;xsd:attribute name=&#39;city&#39; type=&#39;xsd:string&#39; /&gt;   &lt;xsd:attribute name=&#39;postcode&#39; type=&#39;xsd:string&#39; /&gt;   &lt;xsd:attribute name=&#39;street&#39; type=&#39;xsd:string&#39; /&gt;&lt;/xsd:complexType&gt;&lt;xsd:complexType name=&#39;UserInfo&#39;&gt;   &lt;xsd:sequence&gt;   &lt;xsd:element name=&#39;address&#39; type=&#39;tns:Address&#39;/&gt;   &lt;xsd:element name=&#39;address1&#39; type=&#39;tns:Address&#39;/&gt;    &lt;/xsd:sequence&gt;   &lt;xsd:attribute name=&#39;userid&#39; type=&#39;xsd:int&#39; /&gt;   &lt;xsd:attribute name=&#39;name&#39; type=&#39;xsd:string&#39; /&gt; &lt;/xsd:complexType&gt;</code></pre></li></ul></li><li><p>优点</p><ul><li>安全性</li><li>XML肉眼可读，可调试性好</li></ul></li><li><p>缺点</p><ul><li>XML空间开销会大很多，序列化后的数据量剧增，这意味着巨大的内存和磁盘开销</li></ul></li><li><p>适用场景</p><ul><li>对于公司之间传输数据量小或者实时性要求相对低的服务是一个很好的选择</li></ul></li></ul><h2 id="5-2-JSON-Javascript-Object-Notation"><a href="#5-2-JSON-Javascript-Object-Notation" class="headerlink" title="5.2 JSON - Javascript Object Notation"></a>5.2 JSON - Javascript Object Notation</h2><ul><li><p>概念</p><ul><li>出自Javascript，产生来自于Associative array的概念，本质是采用Attribute-value的方法来描述对象</li></ul></li><li><p>优点</p><ul><li>这种Associative array格式非常符合工程师对对象的理解。</li><li>它保持了XML的人眼可读（Human-readable）的优点。</li><li>相对于XML而言，序列化后的数据更加简洁。 来自于的以下链接的研究表明：XML所产生序列化之后文件的大小接近JSON的两倍。<a href="http://www.codeproject.com/Articles/604720/JSON-vs-XML-Some-hard-numbers-about-verbosity" target="_blank" rel="noopener">http://www.codeproject.com/Articles/604720/JSON-vs-XML-Some-hard-numbers-about-verbosity</a></li><li>它具备Javascript的先天性支持，所以被广泛应用于Web browser的应用常景中，是Ajax的事实标准协议。</li><li>与XML相比，其协议比较简单，解析速度比较快。</li><li>松散的Associative array使得其具有良好的可扩展性和兼容性。</li></ul></li><li><p>应用场景</p><ul><li>公司之间传输数据量<strong>相对小</strong>，实时性要求相对低（<strong>例如秒级别）</strong>的服务。</li><li>基于Web browser的Ajax请求。</li><li>由于JSON具有非常强的前后兼容性，对于接口经常发生变化，并对可调式性要求高的场景，例如Mobile app与服务端的通讯。</li><li>由于JSON的典型应用场景是JSON＋HTTP，适合跨防火墙访问</li></ul></li><li><p>缺点</p><ul><li>采用JSON进行序列化的额外空间开销比较大，对于大数据量服务或持久化，这意味着巨大的内存和磁盘开销，这种场景不适合。</li><li>没有统一可用的IDL降低了对参与方的约束，实际操作中往往只能<strong>采用文档方式来进行约定</strong>，这可能会给调试带来一些不便，延长开发周期。</li><li>由于JSON在一些语言中的序列化和反序列化需要采用反射机制，所以在性能要求为ms级别，不建议使用</li></ul></li></ul><pre><code class="java">{&quot;userid&quot;:1,&quot;name&quot;:&quot;messi&quot;,&quot;address&quot;:[{&quot;city&quot;:&quot;北京&quot;,&quot;postcode&quot;:&quot;1000000&quot;,&quot;street&quot;:&quot;wangjingdonglu&quot;}]}</code></pre><h2 id="5-3-Thrift"><a href="#5-3-Thrift" class="headerlink" title="5.3 Thrift"></a>5.3 Thrift</h2><ul><li>简介<ul><li>FB开源的一个高性能轻量级的RPC框架</li><li>为了满足当前大数据量、分布式、跨语言、跨平台数据通讯的需求</li><li>，Thrift并不仅仅是序列化协议，而是一个RPC框架。相对于JSON和XML而言，Thrift在空间开销和解析性能上有了比较大的提升，对于对性能要求比较高的分布式系统，它是一个优秀的RPC解决方案；但是由于Thrift的序列化被嵌入到Thrift框架里面，Thrift框架本身并没有透出序列化和反序列化接口，这导致其很难和其他传输层协议共同使用</li></ul></li></ul><pre><code class="java">// IDL wenstruct Address{     1: required string city;    2: optional string postcode;    3: optional string street;} struct UserInfo{     1: required string userid;    2: required i32 name;    3: optional list&lt;Address&gt; address;}</code></pre><h2 id="5-4-Protobuf"><a href="#5-4-Protobuf" class="headerlink" title="5.4 Protobuf"></a>5.4 Protobuf</h2><ul><li>特征<ul><li>标准的IDL和IDL编译器，这使得其对工程师非常友好。</li><li>序列化数据非常简洁，紧凑，与XML相比，其序列化之后的数据量约为1/3到1/10。</li><li>解析速度非常快，比对应的XML快约20-100倍。</li><li>提供了非常友好的动态库，使用非常简介，反序列化只需要一行代码。</li><li>Protobuf是一个纯粹的展示层协议，可以和各种传输层协议一起使用；Protobuf的文档也非常完善。 但是由于Protobuf产生于Google，所以目前其仅仅支持Java、C++、Python三种语言。另外Protobuf支持的数据类型相对较少，不支持常量类型。由于其设计的理念是纯粹的展现层协议（Presentation Layer），目前并没有一个专门支持Protobuf的RPC框架</li></ul></li><li>应用场景<ul><li>Protobuf具有广泛的用户基础，空间开销小以及高解析性能是其亮点，非常适合于公司内部的对性能要求高的RPC调用。</li><li>由于Protobuf提供了标<strong>准的IDL以及对应的编译器，其IDL文件是参与各方的非常强的业务约束</strong>，</li><li>另外，Protobuf与传输层无关，采用HTTP具有良好的跨防火墙的访问属性，所以Protobuf也适用于公司间对性能要求比较高的场景</li><li>由于其解析性能高，序列化后数据量相对少，非常适合应用层对象的持久化场景。</li></ul></li></ul><pre><code class="java">// IDL File E.Gmessage Address{    required string city=1;        optional string postcode=2;        optional string street=3;}message UserInfo{    required string userid=1;    required string name=2;    repeated Address address=3;}</code></pre><h2 id="5-5-Avro"><a href="#5-5-Avro" class="headerlink" title="5.5 Avro"></a>5.5 Avro</h2><ul><li>介绍<ul><li>Apache Hadoop的子项目</li><li>提供两种序列化方式<ul><li>Json<ul><li>为了方便测试的调试过程</li></ul></li><li>Binary<ul><li>空间开销和解析性能可以和Protobuf媲美</li></ul></li></ul></li></ul></li><li>优点<ul><li>Avro支持JSON格式的IDL和类似于Thrift和Protobuf的IDL（实验阶段），这两者之间可以互转。</li><li>Schema可以在传输数据的同时发送，加上JSON的自我描述属性，这使得Avro非常适合动态类型语言。</li><li>Avro在做文件持久化的时候，一般会和Schema一起存储，所以Avro序列化文件自身具有自我描述属性，所以非常适合于做Hive、Pig和MapReduce的持久化数据格式。</li><li>对于不同版本的Schema，在进行RPC调用的时候，服务端和客户端可以在握手阶段对Schema进行互相确认，大大提高了最终的数据解析速度。</li></ul></li></ul><h1 id="6-Benchmark"><a href="#6-Benchmark" class="headerlink" title="6. Benchmark"></a>6. Benchmark</h1><ul><li>通过下面链接可以发现Protobuf和Avro在两个方面都表现很优越</li></ul><p><a href="https://code.google.com/archive/p/thrift-protobuf-compare/wikis/Benchmarking.wiki" target="_blank" rel="noopener">https://code.google.com/archive/p/thrift-protobuf-compare/wikis/Benchmarking.wiki</a> </p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zhuanlan.zhihu.com/p/40462507" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/40462507</a></li><li><a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017624706151424" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/1016959663602400/1017624706151424</a> </li><li><a href="https://tech.meituan.com/2015/02/26/serialization-vs-deserialization.html" target="_blank" rel="noopener">https://tech.meituan.com/2015/02/26/serialization-vs-deserialization.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis数据同步</title>
      <link href="/Redis%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"/>
      <url>/Redis%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis数据同步"><a href="#Redis数据同步" class="headerlink" title="Redis数据同步"></a>Redis数据同步</h1><h1 id="1-Redis的高可靠性"><a href="#1-Redis的高可靠性" class="headerlink" title="1. Redis的高可靠性"></a>1. Redis的高可靠性</h1><p>Redis的高可靠性体现在两个方面： </p><ul><li>数据尽量少丢失<ul><li>AOF</li><li>RDB</li></ul></li><li>服务尽量少中断<ul><li>增加副本冗余量 — 将一份数据同时保存在多个实例上</li></ul></li></ul><h1 id="2-数据同步-—-主从库模式"><a href="#2-数据同步-—-主从库模式" class="headerlink" title="2. 数据同步 — 主从库模式"></a>2. 数据同步 — 主从库模式</h1><ul><li><p>主从库之间采用的是读写分离的方式</p><ul><li><p>读操作</p><ul><li>主库，从库都可以接收</li></ul></li><li><p>写操作</p><ul><li><p>首先到主库执行</p></li><li><p>然后主库将写操作同步给从库</p><p>  <img src="https://i.loli.net/2021/01/04/8wE4dPDgFxqRX6r.png" alt="主从读写分离"></p></li></ul></li></ul></li><li><p>主从库的好处是修改操作都只会在一个库实现</p><ul><li>可以减少加锁，实例间协商这类开销</li></ul></li></ul><h2 id="2-1-主从库之间如何进行第一个同步？"><a href="#2-1-主从库之间如何进行第一个同步？" class="headerlink" title="2.1 主从库之间如何进行第一个同步？"></a>2.1 主从库之间如何进行第一个同步？</h2><ul><li><p>多个Redis实例之间通过replicaof命令形成主库和从库的关系，然后按照三个阶段完成数据的第一次同步：</p><p>  <img src="https://i.loli.net/2021/01/04/KZemoVB6CFjNlJI.png" alt="主从首次同步过程"></p></li><li><p>第一阶段</p><ul><li>主从库之间建立连接，协商同步</li><li>为全量复制做准备</li><li>从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复以后，主从库间就可以开始同步了<ul><li>从库给主库发送psync命令，表示要进行数据同步</li><li>主库根据这个命令的参数来启动复制<ul><li>psync命令包含主库的runId和复制进度的offset两个参数<ul><li>runID — Redis实例启动的时候自动随机生成的ID，用来唯一标识当前实例</li><li>offset 此时设为-1，表示第一次复制</li></ul></li></ul></li><li>主库收到psync命令后，使用FULLRESYNC响应命令，包括了主库的runID还有主库目前的复制进度offset，返回给从库<ul><li>从库记录下两个参数</li></ul></li><li>FULLRESYNC表示第一次复制使用的是全量复制</li></ul></li></ul></li><li><p>第二阶段</p><ul><li>主库将所有数据同步给从库</li><li>从库收到数据后，在本地完成数据加载 — 依赖于内存快照生成的RDB文件<ul><li>主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。</li><li>从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。<ul><li>这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空</li></ul></li></ul></li><li>在做数据同步的过程中，主库不会被阻塞。对于这个过程中接收到的正常请求，写操作会记录在主库的Replication Buffer当中</li></ul></li><li><p>第三阶段</p><ul><li>主库会将第二阶段新收到的修改命令，再发给从库</li><li>当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了</li></ul></li></ul><h2 id="2-2-主从级联方式分担全量复制时的主库压力"><a href="#2-2-主从级联方式分担全量复制时的主库压力" class="headerlink" title="2.2 主从级联方式分担全量复制时的主库压力"></a>2.2 主从级联方式分担全量复制时的主库压力</h2><ul><li><p>现状/ 问题</p><ul><li>一次全量复制主库需要完成两个耗时操作<ul><li>生成RDB文件和传输RDB文件</li></ul></li><li>如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。</li><li>传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力</li></ul></li><li><p>解决方案 — 主从从模式</p><ul><li><p>我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。replicaof 所选从库的IP 6379</p><p><img src="https://i.loli.net/2021/01/04/eihQpmN6FJdRxLy.png" alt="级联主从库"></p></li></ul></li></ul><h2 id="2-3-突发情况下的增量复制"><a href="#2-3-突发情况下的增量复制" class="headerlink" title="2.3 突发情况下的增量复制"></a>2.3 突发情况下的增量复制</h2><ul><li><p>网络断了以后我们需要一种开销相对合理的复制方式，即增量复制</p><ul><li>将主从库断联期间主库收到的命令，同步给从库</li></ul></li><li><p>增量复制的时候，主从库之间依靠repl_backlog_buffer这个缓冲区来做同步</p></li><li><p>整个过程如下：</p><ul><li><p>当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。</p></li><li><p>repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。</p></li><li><p>刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。</p></li><li><p>同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。</p></li><li><p>主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距</p></li><li><p>在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。</p><p><img src="https://i.loli.net/2021/01/04/w3TLhzRgOH2A65d.png" alt="增量复制过程"></p></li></ul></li></ul><blockquote><p>因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。</p></blockquote><p>我们要想办法避免这一情况，一般而言，我们可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：<strong>缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小</strong>。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值</p><ul><li>repl_backlog_buffer<ul><li>是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量同步带来的性能开销</li><li>如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量同步，所以repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量同步的概率</li><li>而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer</li></ul></li><li>replication_buffer<ul><li>Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互</li><li>客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的</li><li>Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。</li><li>所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer</li><li>这个buffer需要做大小的限制<ul><li>如果主从在传播命令时，因为某些原因从库处理得非常慢，那么主库上的这个buffer就会持续增长，消耗大量的内存资源，甚至OOM</li><li>所以Redis提供了<strong>client-output-buffer-limit</strong>参数限制这个buffer的大小，如果超过限制，主库会强制断开这个client的连接，也就是说从库处理慢导致主库内存buffer的积压达到限制后，主库会强制断开从库的连接，此时主从复制会中断，中断后如果从库再次发起复制请求，那么此时可能会导致恶性循环，引发复制风暴，这种情况需要格外注意。</li></ul></li></ul></li></ul><h2 id="2-4-主从全量同步-RDB-vs-AOF"><a href="#2-4-主从全量同步-RDB-vs-AOF" class="headerlink" title="2.4 主从全量同步 RDB vs AOF"></a>2.4 主从全量同步 RDB vs AOF</h2><p>1、RDB文件内容是<strong>经过压缩的二进制数据（不同数据类型数据做了针对性优化）</strong>，文件很小。而AOF文件记录的是每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个key的多次冗余操作。在主从全量数据同步时，传输RDB文件可以尽量降低对主库机器网络带宽的消耗，从库在加载RDB文件时，一是文件小，读取整个文件的速度会很快，二是因为<strong>RDB文件存储的都是二进制数据</strong>，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比RDB会慢得多，所以使用RDB进行主从全量同步的成本最低。</p><p>2、假设要使用AOF做全量同步，意味着必须打开AOF功能，打开AOF就要选择文件刷盘的策略，选择不当会严重影响Redis性能。而RDB只有在需要定时备份和主从全量同步数据时才会触发生成一次快照。而在很多丢失数据不敏感的业务场景，其实是不需要开启AOF的。</p>]]></content>
      
      
      <categories>
          
          <category> 数据存储 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>使用AWS EC2搭建Halo博客</title>
      <link href="/%E4%BD%BF%E7%94%A8AWS-EC2%E6%90%AD%E5%BB%BAHalo%E5%8D%9A%E5%AE%A2/"/>
      <url>/%E4%BD%BF%E7%94%A8AWS-EC2%E6%90%AD%E5%BB%BAHalo%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-EC2-设置"><a href="#1-EC2-设置" class="headerlink" title="1. EC2 设置"></a>1. EC2 设置</h1><p>在完成了AWS注册之后，登录后台，在EC2的看板左侧点击Instances，选择Launch Instances，这时候会带你进入到选择AMI的界面，按照Halo的推荐是选择CentOS比较合适，不过亲测了下RHEL，CentOS都没有什么问题，按照自己的需要 (如果新账号的话，会有eligible free tier)，可以免费使用一年，使用其即可。</p><p>对于运行的EC2实例，我们还需要对VPC, Security Group. Elastic IP做配置，目的是为了能够在VPC之外(公网)能够访问HTTP, HTTPS端口，一般来说就是80,还有443. 这里的整个过程(troubleshooting)可以根据这篇官方博客来做。</p><p><a href="https://aws.amazon.com/cn/premiumsupport/knowledge-center/ec2-connect-internet-gateway/" target="_blank" rel="noopener">排查 EC2 实例的互联网网关连接问题</a></p><h1 id="2-Halo基本设置"><a href="#2-Halo基本设置" class="headerlink" title="2. Halo基本设置"></a>2. Halo基本设置</h1><p>在根据第一部分的说明设置好服务器之后，我们可以ssh上服务器，然后开始做Halo的基本设置</p><p>详情可以看Halo安装的官方教程 — <a href="https://halo.run/archives/install-with-linux.html" target="_blank" rel="noopener">在Linux服务器部署Hal</a>o</p><ul><li>几个值得注意的地方<ul><li>JVM启动内存的分配</li><li>halo版本的更新</li><li>端口的设置</li></ul></li></ul><h1 id="3-反向代理"><a href="#3-反向代理" class="headerlink" title="3. 反向代理"></a>3. 反向代理</h1><p>使用Catty或者Nginx来做反向代理，完成https证书的申请，在你自己域名的服务商下设置dns，开始访问你自己的博客。</p><p>Halo域名的配置与访问</p><h1 id="4-Troubleshooting"><a href="#4-Troubleshooting" class="headerlink" title="4. Troubleshooting"></a>4. Troubleshooting</h1><ol><li>服务器上启动了服务，port开了但是Public Ip还是无法访问到</li></ol><p>这的错误很可能不在开启的服务(halo) 方面，而在于EC2防火墙 VPC等的配置，检查下端口是否都正常开启，根据第一部分的排查EC2互联网网关连接问题的文章一步步排查，基本上可以解决。</p><ol start="2"><li>在服务器上查看开启的端口，发现服务只开在IPV6上而没有在IPV4上开启</li></ol><p>发现这个问题是发现在使用telnet -tlnp 指令的时候，发现Halo的进程确实开启了，但是是监听在tcp6 下，在Ipv4下没有端口监听。查询资料发现Java 网络模块现在是默认先检察当前操作系统是否支持IPv6， 如果支持，就会直接使用IPv6， 否则才会使用ipv4. <a href="https://stackoverflow.com/questions/44718174/spring-boot-application-listens-over-ipv6-without-djava-net-preferipv4stack-tru" target="_blank" rel="noopener">StackOverflow 上的问答</a> 如果想要设置先监听ipv4的话，我们可以在指令上加上</p><pre><code class="jsx">-Djava.net.preferIPv4Stack=true-Djava.net.preferIPv4Addresses// 整个语句如下所示 (是在/etc/systemd/system/halo.service这个文件里做配置) ExecStart=/usr/bin/java -server -Xms256m -Xmx256m -jar YOUR_JAR_PATH -Djava.net.preferIPv4Stack=true -Djava.net.preferIPv4Addresses</code></pre><p><a href="https://aws.amazon.com/premiumsupport/knowledge-center/connect-http-https-ec2/" target="_blank" rel="noopener">Connect to an Amazon EC2 instance on HTTP or HTTPS ports</a></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> EC2 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>API Rate Limiter Design</title>
      <link href="/API-Rate-Limiter-Design/"/>
      <url>/API-Rate-Limiter-Design/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>What is a rate limiter? </p><ul><li>due to limited resources, also get rid of some abusive action, we need some kind of throttling or rate limiting mechanism thus only a certain number of requests will go to our service, and we are able to respond all of them </li><li>a rate limiter limits the number of events an entity can perform in a particular time window, then block requests once the cap is reached </li></ul></li><li><p>why we need to do rate limiting? </p><ul><li><p>Protect services against abusive behaviors targeting the application layer like </p><ul><li>DOS attacks </li><li>Brute Force credit card transactions </li></ul></li><li><p>why we need such protection?</p><ul><li>these attacks are a barrage of HTTP/S requests which may look like they are coming from real users, but are actually generated by machines </li><li>thus such attachs are harder to detect and can more easily bring down a service, application or an API </li></ul></li><li><p>could make a service and APIs more reliable</p><ul><li><p>misbehaving clients/ scripts </p></li><li><p>security </p><ul><li>second factor attempts </li></ul></li><li><p>prevent abusive behavior and bad design practices </p></li><li><p>keep costs and resource usage under control </p></li><li><p>revenue </p><ul><li>revenue model based on rate limiting </li></ul></li><li><p>eliminate spikiness in traffic </p></li></ul></li></ul></li></ul><h1 id="2-Requirement-and-Goal"><a href="#2-Requirement-and-Goal" class="headerlink" title="2. Requirement and Goal"></a>2. Requirement and Goal</h1><ul><li>functional <ul><li>limit the number of requests an entity can send to an API within a time window </li><li>APIs are accessible through a cluster, so the rate limit should be considered across different servers <ul><li>users should get an error message whenever the defined threshold is crossed within a single server or across a combination of servers </li></ul></li></ul></li></ul><h1 id="3-Thoughts"><a href="#3-Thoughts" class="headerlink" title="3. Thoughts"></a>3. Thoughts</h1><ul><li><p>table to store the request information, </p><ul><li><p>every entry will look like </p><ul><li>userId</li><li>api name </li><li>accessTime</li><li>api parameters</li></ul></li><li><p>and then we could query and sort by the accesstime to get related info </p></li></ul></li><li><p>there should have a caching layer to store the related info, most important one is for a specific user and specific api, based on the throttle limit(suppose n), what’s the time when they made the recent nth request, thus we could take a notes on this info </p></li></ul><h1 id="4-Design"><a href="#4-Design" class="headerlink" title="4. Design"></a>4. Design</h1><h2 id="4-1-High-Level"><a href="#4-1-High-Level" class="headerlink" title="4.1 High Level"></a>4.1 High Level</h2><ul><li>Clients make call to our web server </li><li>when request come, first sync with rate limiter server to decide if it will be served or throttled</li><li>web server then sync with API servers if rate limiter says it should not be blocked </li></ul><h2 id="4-2-Basic-System-Design-and-Algo"><a href="#4-2-Basic-System-Design-and-Algo" class="headerlink" title="4.2 Basic System Design and Algo"></a>4.2 Basic System Design and Algo</h2><ul><li><p>target </p><ul><li>limit the number of requests per user <ul><li>keep a count representing how many requestss the user has made </li><li>a timestamp when we started counting the requests </li></ul></li></ul></li><li><p>use a hashtable to store the info</p><ul><li>key - userId</li><li>value - count + startTime <ul><li>count would be enough if we don’t need detail about the metrics or we say there are some other stuff controlling it </li><li>so based on the count and requirement, we could either increase the count, reset the count, or reset the start time. </li></ul></li><li>one issue for only store the starttime is it’s possible to allow twice the configured number during a period. End of the previous window, with full capacity; and start at the next window, with full capacity. </li></ul></li></ul><ul><li>then we need to store timestamp of each request thus we could keep a sliding window <ul><li>use redis sorted set </li><li>steps when new request comes in<ul><li>remove all timestamps from the sorted set that are older than currentTime - 1 min (suppose that’s the configured window)</li><li>count the total number of elements in the sorted set </li><li>reject the request if count is greater than throttling limit </li><li>insert the current time in the sorted set and accept the reuqest </li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rate limiter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dropbox Design Scratch</title>
      <link href="/Dropbox-Design-Scratch/"/>
      <url>/Dropbox-Design-Scratch/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro-and-requirement"><a href="#1-Intro-and-requirement" class="headerlink" title="1. Intro and requirement"></a>1. Intro and requirement</h1><ul><li><p>cloud file storage services </p><ul><li>simplify the storage and exchange of digital resources among multiple devices </li><li>benefits <ul><li>availability </li><li>reliability and durability </li><li>scalability </li></ul></li></ul></li><li><p>requirements and goals </p><ul><li>users should be able to upload and download their files/ photos from any device </li><li>users should be able to share files or folders with other users </li><li>service should support automatic synchronization between devices </li><li>support storing large files </li><li>ACID support </li><li>Offline editing, CURD offline, and get synced when online </li><li>snapshotting of the data </li></ul></li></ul><h1 id="2-Thoughts"><a href="#2-Thoughts" class="headerlink" title="2. Thoughts"></a>2. Thoughts</h1><ul><li><p>size, limit , pattern </p><ul><li>read heavy </li><li>write huge file </li></ul></li><li><p>synchronize among different devices</p><ul><li>all devices make call to backend to grab newest status </li></ul></li><li><p>file/ folder share </p><ul><li>permission management </li></ul></li><li><p>Offline editing </p><ul><li>Use queue to store the data locally? </li></ul></li></ul><h1 id="3-Design"><a href="#3-Design" class="headerlink" title="3. Design"></a>3. Design</h1><h2 id="3-1-considerations"><a href="#3-1-considerations" class="headerlink" title="3.1  considerations"></a>3.1  considerations</h2><pre><code>+ huge read and write volumes    + read write almost equal + files can be stored in &lt;u&gt;**small parts or chunks (4MB)**&lt;/u&gt;, when fails, only the failed chunk should be retried + reduce the amount of data exchange by transfering updated chunks only + keep a local copy of metadata (file name, size, etc.) with the client can save us a lot of round trips to the server </code></pre><ul><li>high level design <ul><li>need to store files and metadata information like File name, file size, directory, who this file is shared with </li><li>need some servers that can help the clients to upload/ download files to cloud storage and some servers that can facilitate updating metadata about files and users</li><li>need some mechanism to notify all clients whenever an updates happens so they can synchronize their files </li></ul></li></ul><h2 id="3-2-high-level-design"><a href="#3-2-high-level-design" class="headerlink" title="3.2 high level design"></a>3.2 high level design</h2><pre><code>+ user specify folder as the workspace on the device     + file in the folder will be uploaded to the cloud     + updater/ delete will be reflected in the same way + modification on one device should be freely synced across others + systems we need based on requirements     + a storage server to store all real files     + a metadata service store file metadata, thus we could quickly get info about it     + a synchronizer service, to notify all clients whenever an update happens so they can synchronize files </code></pre><h2 id="3-3-Component-Design"><a href="#3-3-Component-Design" class="headerlink" title="3.3 Component Design"></a>3.3 Component Design</h2><h3 id="3-3-1-Client"><a href="#3-3-1-Client" class="headerlink" title="3.3.1 Client"></a>3.3.1 Client</h3><ul><li><p>responsibility </p><ul><li>need to monitor the workspace folder on user’s machine </li><li>sync files/ folders with remote cloud storage </li><li>interact with the remote synchronization service to handle file metadata updates </li></ul></li><li><p>how to handle file transfer efficiently</p><ul><li><p>break each file into smaller chunks so that we transfer only those chunks that are modified and not the whole file </p></li><li><p>calculate chunk size based on:</p><ul><li>storage devices we use in the cloud </li><li>network bandwidth </li><li>average file size in the storage </li></ul></li><li><p>need to keep a record of each file and the chunks in metadata </p></li></ul></li><li><p>shall we keep a copy of metadata with client? </p><ul><li>yes, it then allows us to do offline updates </li></ul></li><li><p>how can clients efficiently listen to changes happening with other clients? </p><ul><li><p>Solution 1</p><ul><li>clients periodically check with the server if there are any changes </li><li>issues <ul><li>have a delay in reflecting changes locally as clients will be checking for changes periodically compared to server notifying whever there is some change </li></ul></li></ul></li><li><p>Solution 2</p><ul><li>HTTP long polling </li><li>client requests information from the server with the expectation that the server may not respond immediately </li><li>servers hold the request open and waits for response information to become available </li></ul></li></ul></li><li><p>components </p><ul><li><p>inernal metadata db </p><ul><li>keep track of all the files, chunks, versions and location </li></ul></li><li><p>chunker </p><ul><li>split files into smaller pieces </li><li>reconstruct a file from its chunks </li></ul></li><li><p>watcher </p><ul><li>monitor the local workspace folders and notify the indexer of any action performed by the users </li></ul></li><li><p>indexer </p><ul><li>process the events received from the watcher and update the internal metadata database with information about the chunks of the modified files </li><li>once confirm chunks are successfully uploaded to the cloud storage, the indexer will communicate with the remote synchronization service to broadcast changes to other clients and update remote metadata database </li></ul></li></ul></li><li><p>for phone users, probably should sync on demand to save bandwidth and capacity </p></li></ul><h3 id="3-3-2-Metadata-Database"><a href="#3-3-2-Metadata-Database" class="headerlink" title="3.3.2 Metadata Database"></a>3.3.2 Metadata Database</h3><ul><li>responsible for maintaing the versioning and metadata information about files/ chunks, users and workspaces </li><li>store info like <ul><li>chunks </li><li>files </li><li>users</li><li>devices</li><li>workspace </li></ul></li></ul><h3 id="3-3-3-Synchronization-Service"><a href="#3-3-3-Synchronization-Service" class="headerlink" title="3.3.3 Synchronization Service"></a>3.3.3 Synchronization Service</h3><ul><li><p>component that processes file updates made by a client and apply these changes to other subscribed clients </p></li><li><p>also synchronizes clients local databases with the information stored in the remote metadata db </p></li><li><p>Implement a differenciation algo to reduce the amount of the data that needs to be synchronized </p><ul><li>just transmit the difference between two versions instead of the whole file </li></ul></li><li><p>to support a scalable synchronization protocol</p><ul><li>use a communication middleware </li><li>messaging system <ul><li>push or pull strategies </li></ul></li></ul></li></ul><h3 id="3-3-4-Message-Queuing-Service"><a href="#3-3-4-Message-Queuing-Service" class="headerlink" title="3.3.4 Message Queuing Service"></a>3.3.4 Message Queuing Service</h3><ul><li>Message queue service <ul><li>supports asynchronous message based communication between clients and the synchronization service </li></ul></li></ul><h3 id="3-3-5-Cloud-Storage"><a href="#3-3-5-Cloud-Storage" class="headerlink" title="3.3.5 Cloud Storage"></a>3.3.5 Cloud Storage</h3><p>Cloud/Block Storage stores chunks of files uploaded by the users. Clients directly interact with the storage to send and receive objects from it. Separation of the metadata from storage enables us to use any storage either in the cloud or in-house.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.educative.io/courses/grokking-the-system-design-interview/m22Gymjp4mG" target="_blank" rel="noopener">Grokking the system design</a></li><li><a href="https://www.youtube.com/watch?v=U0xTu6E2CT8&t=9s&ab_channel=TechDummiesNarendraL" target="_blank" rel="noopener">Tech Dummies</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>LC-Dynamic Programming</title>
      <link href="/LC-Dynamic-Programming/"/>
      <url>/LC-Dynamic-Programming/</url>
      
        <content type="html"><![CDATA[<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><h1 id="1-动态规划问题的一些思路"><a href="#1-动态规划问题的一些思路" class="headerlink" title="1. 动态规划问题的一些思路"></a>1. 动态规划问题的一些思路</h1><h2 id="1-1-原理"><a href="#1-1-原理" class="headerlink" title="1.1 原理"></a>1.1 原理</h2><ul><li>一般形式 –&gt; 求最值<ul><li>核心思路： 穷举</li><li>特殊性： 因为其存在重叠子问题<ul><li>暴力穷举的时间复杂度就会非常高</li><li>我们就需要备忘录/ DP table来优化穷举的过程，避免不必要的计算</li><li>一般会具备最优子结构，才能通过子问题的最值得到原问题的最值</li><li>关于如何穷举所有的可能解，就需要分析得出状态转移方程，以上也就是动态规划的三要素</li></ul></li></ul></li><li>三要素<ul><li>重叠子问题<ul><li>子问题之间需要互相独立</li><li>重叠子问题 需要做某种记录，使用dp table 或者备忘录<ul><li>可以尝试通过状态压缩，来缩小DP table的大小，只记录必要的数据</li></ul></li></ul></li><li>最优子结构</li><li>状态转移方程<ul><li>就是n 和 n-1, n-2之间的关系</li><li>如何思考<ul><li>明确base case</li><li>明确状态</li><li>明确选择</li><li>定义dp数组/ 函数的含义</li></ul></li></ul></li></ul></li><li>和递归的对比<ul><li>递归往往是自上而下，分解出子问题，再利用栈的逻辑，反向拿到结果</li><li>而动态规划是自下而上的，直接定义出了子问题，然后我们来定义状态是如何转移的</li></ul></li></ul><h2 id="1-2-基本方法论"><a href="#1-2-基本方法论" class="headerlink" title="1.2 基本方法论"></a>1.2 基本方法论</h2><ul><li>逻辑是需要找到一些规律来指导我们解决动态规划问题<ul><li>寻找子问题</li><li>递归求解</li><li>重叠子问题</li><li>无后效性</li><li>状态存储</li></ul></li></ul><h2 id="1-3-递归"><a href="#1-3-递归" class="headerlink" title="1.3 递归"></a>1.3 递归</h2><ul><li>使用贪心算法是有可能失效导致无法生成全局最优解的</li><li>最优化问题本身指的是一种求极值的方法，即在一组约束为等式或不等式的条件下，使系统的目标函数达到极值，即最大值或最小值的过程</li><li>我们需要做到的是在满足条件的组合里找出最优解的组合<ul><li>枚举<ul><li>求出所有满足条件的组合，然后看看这些组合能否得到最大值或者最小值</li><li>关键问题 – 如何得到满足条件的所有组合<ul><li>使用递归来获得满足约束条件的所有组合</li><li>–》 递归是一种枚举的手法，满足限定条件下，做递归</li><li>在递归的过程中，每一步都对需要求解的问题来进行判断</li></ul></li><li>使用递归的好处<ul><li>是在使用堆栈的时候实际上自然的就保存了每一层的局部变量们</li><li>递归的形式也给了回溯的能力，通过堆栈保存了上一步的状态的</li></ul></li></ul></li></ul></li><li>直接使用递归的问题<ul><li>实际上是穷举了所有的组合，导致效率很低</li><li>构成的递归树会随着数据规模的增长而指数级别的增长</li><li>直接使用递归调试相对比较困难，因为需要思考每一层的表现</li></ul></li><li>递归的优化<ul><li>剪枝<ul><li>减少搜索的分支数量</li><li>重叠子问题，可以通过提前存储，来减少重复的运算</li></ul></li></ul></li></ul><h2 id="1-4-备忘录"><a href="#1-4-备忘录" class="headerlink" title="1.4 备忘录"></a>1.4 备忘录</h2><ul><li>前面说过我们可以通过枚举来获得满足条件的所有组合，然后再来求需要的极值，但是在这中间是很有可能有重叠子问题的</li><li>可用的前提条件<ul><li>无后效性<ul><li>即在通过 A 阶段的子问题推导 B 阶段的子问题的时候，我们不需要回过头去再根据 B 阶段的子问题重新推导 A 阶段的子问题</li><li>即子问题之间的依赖是单向性的</li></ul></li></ul></li><li>以斐波那契数列为例<ul><li>我们在疯狂的重复计算子函数，大部分的递归树都是重复的</li><li>举个例子<ul><li>f(9) = f(8) + f(7)</li><li>在计算f(8)的时候，又需要计算一遍f(7)</li><li>如此反复</li></ul></li></ul></li><li>因此我们需要使用备忘录来解决重复计算的问题<ul><li>在每次计算出一个子问题的答案以后，将这个临时的中间结果记录到备忘录当中，然后再返回</li></ul></li><li>常见的可用数据结构<ul><li>数组</li><li>哈希表</li></ul></li></ul><h2 id="1-5-动归的应用场景"><a href="#1-5-动归的应用场景" class="headerlink" title="1.5 动归的应用场景"></a>1.5 动归的应用场景</h2><h3 id="1-5-1-0-1背包问题"><a href="#1-5-1-0-1背包问题" class="headerlink" title="1.5.1 0-1背包问题"></a>1.5.1 0-1背包问题</h3><ul><li><p>问题描述</p><ul><li>总重量为W的背包和N个物品，对每个物品，有重量w和价值v两个属性，即第i个物品重量为w[i],价值为v[i]</li></ul></li><li><p>算法问题分析</p><ul><li><p>首先看是什么类型的问题</p><ul><li><p>求最优解的问题（max / min）</p><ul><li>考虑下使用贪心算法的可能性</li><li>暴力递归做穷举</li><li>动态规划</li></ul></li><li><p>求可行性的问题</p></li><li><p>求方案总数的问题</p></li></ul></li><li><p>进一步确认是否为动态规划问题</p><ul><li>数据需要不可排序</li><li>数据不可交换</li></ul></li></ul></li><li><p>状态转移方程</p><ul><li>确定终止条件<ul><li>背包容量为0了或者物品数量为0要终止执行</li><li>背包中的物品数量和背包还能装下的重量是这个问题的状态参数</li></ul></li></ul></li></ul><pre><code class="jsx">int dp(int[] w, int[] v, int N, int W) {    // 创建备忘录    int[][] dp = new int[N+1][W+1];    // 初始化状态    for (int i = 0; i &lt; N + 1; i++) { dp[i][0] = 0; }    for (int j = 0; j &lt; W + 1; j++) { dp[0][j] = 0; }    for (int tn = 1; tn &lt; N + 1; tn++) { // 遍历每一件物品    for (int rw = 1; rw &lt; W + 1; rw++) { // 背包容量有多大就还要计算多少次        if (rw &lt; w[tn]) {          // 当背包容量小于第tn件物品重量时，只能放入前tn-1件          dp[tn][rw] = dp[tn-1][rw];        } else {                // 当背包容量还大于第tn件物品重量时，进一步作出决策          dp[tn][rw] = Math.max(dp[tn-1][rw], dp[tn-1][rw-w[tn]] + v[tn]);        }      }    }  return dp[N][W];}int solveDP() {  int N = 3, W = 5; // 物品的总数，背包能容纳的总重量  int[] w = {0, 3, 2, 1}; // 物品的重量  int[] v = {0, 5, 2, 3}; // 物品的价值  return dp(w, v, N, W); // 输出答案}</code></pre><h1 id="2-动态规划的写法分析"><a href="#2-动态规划的写法分析" class="headerlink" title="2. 动态规划的写法分析"></a>2. 动态规划的写法分析</h1><ul><li>动态规划问题描述<ul><li>重叠子问题<ul><li>穷举过程中存在重复计算的现象</li></ul></li><li>无后效性<ul><li>子问题之间的依赖是单向性的</li><li>某阶段状态一旦确定，就不受后续决策的影响</li></ul></li><li>最优子结构<ul><li>子问题之间必须相互独立，或者说后续的计算可以通过前面的状态推导出来</li></ul></li></ul></li></ul><h1 id="3-案例分析"><a href="#3-案例分析" class="headerlink" title="3. 案例分析"></a>3. 案例分析</h1><h2 id="3-1-硬币找零问题"><a href="#3-1-硬币找零问题" class="headerlink" title="3.1 硬币找零问题"></a>3.1 硬币找零问题</h2><ul><li>问题描述<ul><li>给定n种不同面值的硬币 分别记为c[0], c[1], c[2]…c[n]</li><li>总数额k</li><li>编写一个函数计算出最少需要几枚硬币凑出这个金额K</li><li>若无可能的组合，返回-1</li></ul></li><li>思路<ul><li>这是个求最值的问题</li><li>求最值问题的核心原理就是穷举，将所有可能的凑硬币的方法做穷举，看看最少需要多少枚硬币</li></ul></li><li>贪心算法<ul><li>每一步计算做出的都是在当前看起来最好的选择<ul><li>即局部最优解，并不从整体来考虑</li></ul></li><li>基本思路<ul><li>建立数学模型</li><li>将待求解的问题划分为若干子问题，对每个子问题进行求解，得到子问题的局部最优解</li><li>将子问题的局部最优解进行合并，最终得到基于局部最优解的一个解</li></ul></li></ul></li><li>用贪心算法来解决上述问题的时候，会遇到“过于贪心”导致最终无解的问题，所以需要引入回溯来解决过于贪心的问题</li><li>贪心算法的实现</li></ul><pre><code>int getMinCoinCountHelper(int total, int[] values, int valueCount) {    int rest = total;    int count = 0;    // 从大到小遍历所有面值    for (int i = 0; i &lt; valueCount; ++ i) {        int currentCount = rest / values[i]; // 计算当前面值最多能用多少个        rest -= currentCount * values[i]; // 计算使用完当前面值后的余额        count += currentCount; // 增加当前面额用量        if (rest == 0) {            return count;        }    }    return -1; // 如果到这里说明无法凑出总价，返回-1}int getMinCoinCount() {    int[] values = { 5, 3 }; // 硬币面值    int total = 11; // 总价    return getMinCoinCountHelper(total, values, 2); // 输出结果}</code></pre><ul><li>贪心算法 + 回溯的实现</li></ul><pre><code>int getMinCoinCountOfValue(int total, int[] values, int valueIndex) {    int valueCount = values.length;    if (valueIndex == valueCount) { return Integer.MAX_VALUE; }    int minResult = Integer.MAX_VALUE;    int currentValue = values[valueIndex];    int maxCount = total / currentValue;    for (int count = maxCount; count &gt;= 0; count --) {        int rest = total - count * currentValue;        // 如果rest为0，表示余额已除尽，组合完成        if (rest == 0) {            minResult = Math.min(minResult, count);            break;        }        // 否则尝试用剩余面值求当前余额的硬币总数        int restCount = getMinCoinCountOfValue(rest, values, valueIndex + 1);        // 如果后续没有可用组合        if (restCount == Integer.MAX_VALUE) {            // 如果当前面值已经为0，返回-1表示尝试失败            if (count == 0) { break; }            // 否则尝试把当前面值-1            continue;        }        minResult = Math.min(minResult, count + restCount);    }    return minResult;}int getMinCoinCountLoop(int total, int[] values, int k) {    int minCount = Integer.MAX_VALUE;    int valueCount = values.length;    if (k == valueCount) {        return Math.min(minCount, getMinCoinCountOfValue(total, values, 0));    }    for (int i = k; i &lt;= valueCount - 1; i++) {        // k位置已经排列好        int t = values[k];        values[k] = values[i];        values[i]=t;        minCount = Math.min(minCount, getMinCoinCountLoop(total, values, k + 1)); // 考虑后一位        // 回溯        t = values[k];        values[k] = values[i];        values[i]=t;    }    return minCount;}int getMinCoinCountOfValue() {    int[] values = { 5, 3 }; // 硬币面值    int total = 11; // 总价    int minCoin = getMinCoinCountLoop(total, values, 0);    return (minCoin == Integer.MAX_VALUE) ? -1 : minCoin;  // 输出答案}</code></pre><ul><li><p>使用动态规划来求解</p><ul><li>初始化状态<ul><li>终止条件</li></ul></li><li>状态参数<ul><li>子问题与原问题之间会发生变化的变量</li><li>变量是目标兑换金额K</li></ul></li><li>整体思路<ul><li>确定初始化状态</li><li>确定状态参数</li><li>设计决策</li></ul></li></ul></li><li><p>递归与动态规划的对比</p><ul><li><p>递归是自上而下的，从目标问题开始，不断将大问题拆解成子问题，直到子问题不可拆借为止</p></li><li><p>如果要自底向上，那就应该首先求出所有的子问题，然后通过底层的子问题向上求解更大的问题</p><pre><code>// 伪代码DP(values, k) {res = MAXfor c in values// 作出决策，找到需要硬币最少的那个结果res = min(res, 1 + DP(values, k-c)) // 递归调用if res == MAXreturn -1return res}</code></pre></li></ul></li></ul><pre><code>int getMinCounts(int k, int[] values) {   int[] memo = new int[k + 1]; // 创建备忘录   memo[0] = 0; // 初始化状态   for (int i = 1; i &lt; k + 1; i++) { memo[i] = k + 1; }   for (int i = 1; i &lt; k + 1; i++) {       for (int coin : values) {           if (i - coin &lt; 0) { continue; }           memo[i] = Math.min(memo[i], memo[i - coin] + 1); // 作出决策       }   }   return memo[k] == k + 1 ? -1 : memo[k];}int getMinCountsDPSolAdvance() {   int[] values = { 3, 5 }; // 硬币面值   int total = 22; // 总值   return getMinCounts(total, values); // 输出答案}</code></pre><h1 id="62-Unique-Paths"><a href="#62-Unique-Paths" class="headerlink" title="62. Unique Paths"></a>62. Unique Paths</h1><h2 id="Solution-1-Recursion"><a href="#Solution-1-Recursion" class="headerlink" title="Solution 1: Recursion"></a>Solution 1: Recursion</h2><pre><code>class Solution {    int result = 0;    public int uniquePaths(int m, int n) {        // direction is either right or down         helper(1, 1, m, n);        return result;    }    private void helper(int x, int y, int m, int n) {        if (x &lt; 1 || x &gt; m || y &lt; 1 || y &gt; n) {            return;        }        if (x == m &amp;&amp; y == n) {            result ++;        }        helper(x + 1, y, m, n);        helper(x, y + 1, m, n);    }}</code></pre><h2 id="Solution-2-DP"><a href="#Solution-2-DP" class="headerlink" title="Solution 2: DP"></a>Solution 2: DP</h2><ul><li>注意的点<ul><li>状态转移方程<ul><li><code>dp[m][n] = dp[m-1][n] + dp[m][n-1];</code></li></ul></li><li>因为只有两个方向，实际上第一行第一列能到达的方法都只有一种，所以我们在做初始化的时候可以都初始化为1，具体的迭代从col = 1, row = 1开始，即第二行和第二列 这样来做就okay了</li></ul></li></ul><pre><code>class Solution {     public int uniquePaths(int m, int n) {        // 二维DP           // dp[m][n] = dp[m-1][n] + dp[m][n-1];        int[][] dp = new int[m][n];        for (int[] arr: dp) {            Arrays.fill(arr, 1);        }        for (int col = 1; col &lt; n; col ++) {            for(int row = 1; row &lt; m; row ++) {                dp[row][col] = dp[row-1][col] + dp[row][col-1];            }        }        return dp[m-1][n-1];    }}</code></pre><h1 id="70-Climbing-Stairs"><a href="#70-Climbing-Stairs" class="headerlink" title="70. Climbing Stairs"></a>70. Climbing Stairs</h1><h2 id="Solution-1-DP"><a href="#Solution-1-DP" class="headerlink" title="Solution 1: DP"></a>Solution 1: DP</h2><ul><li><code>dp[n] = dp[n-1] + dp[n-2]</code></li></ul><pre><code>class Solution {    public int climbStairs(int n) {        // dp[n] = dp[n-1] + dp[n-2]        if (n &lt;= 0) {            return 0;        }        int[] dp = new int[n + 1];        dp[0] = 1;        dp[1] = 1;        for (int i = 2; i &lt;= n; i++) {            dp[i] = dp[i-1] + dp[i-2];        }        return dp[n];    }}</code></pre><h1 id="91-Decode-Ways"><a href="#91-Decode-Ways" class="headerlink" title="91. Decode Ways"></a>91. Decode Ways</h1><h2 id="Solution-1-DP-1"><a href="#Solution-1-DP-1" class="headerlink" title="Solution 1: DP"></a>Solution 1: DP</h2><ul><li>每次可以选择往前走一步或者两步</li></ul><pre><code>class Solution {    public int numDecodings(String s) {        if (s == null || s.length() == 0) {            return 0;        }        int[] dp = new int[s.length() + 1];        // could go by 1 step or 2 step         // dp[n] = dp[n-1] + dp[n-2]        //     s.charAt(n) 1 --9        //     s.charAt(n-1) 1 -- 2  if n-1 == 1  n 0 - 9  if n-1 == 2 n 0 - 6         dp[0] = 1;        dp[1] = s.charAt(0) == &#39;0&#39; ? 0 : 1;        for (int i = 2; i &lt;= s.length(); i ++) {            if (s.charAt(i - 1) != &#39;0&#39;) {                dp[i] += dp[i-1];            }            if (s.charAt(i-2) == &#39;1&#39; || (s.charAt(i-2) == &#39;2&#39; &amp;&amp;                                          s.charAt(i - 1) &gt;= &#39;0&#39; &amp;&amp; s.charAt(i-1) &lt;= &#39;6&#39; )){                dp[i] += dp[i-2];            }        }        return dp[s.length()];    }}</code></pre><h2 id="Solution-2-Recursive"><a href="#Solution-2-Recursive" class="headerlink" title="Solution 2: Recursive"></a>Solution 2: Recursive</h2><ul><li>每次都可以往前走两步或者一步</li></ul><pre><code>class Solution {    HashMap&lt;Integer, Integer&gt; memo = new HashMap&lt;&gt;();    public int numDecodings(String s) {        if (s == null || s.length() == 0) {            return 0;        }        return helper(s, 0);    }    private int helper(String s, int pos) {        if (pos == s.length()) {            return 1;        }         if (s.charAt(pos) == &#39;0&#39;) {            return 0;        }        if (pos == s.length() - 1) {            return 1;        }        if (memo.containsKey(pos)) {            return memo.get(pos);        }        int ans = helper(s, pos + 1);        if (Integer.parseInt(s.substring(pos, pos+2)) &lt;= 26) {             ans += helper(s, pos + 2);        }        memo.put(pos, ans);        return ans;    }}</code></pre><h1 id="121-Best-Time-to-Buy-and-Sell-Stock"><a href="#121-Best-Time-to-Buy-and-Sell-Stock" class="headerlink" title="121. Best Time to Buy and Sell Stock"></a>121. Best Time to Buy and Sell Stock</h1><h2 id="Solution-1-Brute-Force"><a href="#Solution-1-Brute-Force" class="headerlink" title="Solution 1: Brute Force"></a>Solution 1: Brute Force</h2><pre><code>class Solution {    public int maxProfit(int[] prices) {        int result = 0;        for (int i = 0; i &lt; prices.length; i++) {            for (int j = i + 1; j &lt; prices.length; j++) {                result = Math.max(result, prices[j] - prices[i]);            }        }        return result;    }}</code></pre><h2 id="Solution-2-One-Pass"><a href="#Solution-2-One-Pass" class="headerlink" title="Solution 2: One Pass"></a>Solution 2: One Pass</h2><ul><li>记录当前的最小值，碰到比最小值大的值，就更新最大利润</li></ul><pre><code>class Solution {    public int maxProfit(int prices[]) {        int minprice = Integer.MAX_VALUE;        int maxprofit = 0;        for (int i = 0; i &lt; prices.length; i++) {            if (prices[i] &lt; minprice)                minprice = prices[i];            else if (prices[i] - minprice &gt; maxprofit)                maxprofit = prices[i] - minprice;        }        return maxprofit;    }}</code></pre><h1 id="LC-139-Word-Break"><a href="#LC-139-Word-Break" class="headerlink" title="LC 139 Word Break"></a>LC 139 Word Break</h1><ul><li>字典里的词可以选用</li><li>可以重复使用</li><li>目的是需要拼起string</li><li>DFS 深度优先遍历</li></ul><h2 id="Solution-1-Brute-Force-1"><a href="#Solution-1-Brute-Force-1" class="headerlink" title="Solution 1 Brute Force"></a>Solution 1 Brute Force</h2><ul><li>Kind of DFS</li><li>Go through one way to the very bottom, and we need to go through all possible result if needed</li></ul><pre><code>class Solution {    public boolean wordBreak(String s, List&lt;String&gt; wordDict) {        if (s == null || s.length() == 0 || wordDict == null || wordDict.size() == 0) {            return false;        }        return subString(s, new HashSet(wordDict), 0);    }    private boolean subString(String testStr, Set&lt;String&gt; wordDict, int position) {        if (position == testStr.length()) {            return true;        }        // 注意这里的&lt;=  因为substring的第二个参数是不包括在第二个参数里面的        for (int n = position + 1; n &lt;= testStr.length(); n ++) {            if (wordDict.contains(testStr.substring(position, n)) &amp;&amp; subString(testStr, wordDict, n)) {                return true;            }        }        return false;    }}</code></pre><h2 id="Solution-1-1-Brute-Force-with-array-record"><a href="#Solution-1-1-Brute-Force-with-array-record" class="headerlink" title="Solution 1.1 Brute Force with array record"></a>Solution 1.1 Brute Force with array record</h2><ul><li>解法1 包含太多的重复，通过记录在某个位置以后能不能成功来保证不会重复运行</li></ul><pre><code>class Solution {    public boolean wordBreak(String s, List&lt;String&gt; wordDict) {        if (s == null || s.length() == 0 || wordDict == null || wordDict.size() == 0) {            return false;        }        return subString(s, new HashSet(wordDict), 0, new Boolean[s.length()]);    }    private boolean subString(String testStr, Set&lt;String&gt; wordDict, int position, Boolean[] memo) {        if (position == testStr.length()) {            return true;        }        if (memo[position] != null) {            return memo[position];        }        // 注意这里的&lt;=  因为substring的第二个参数是不包括在第二个参数里面的        for (int n = position + 1; n &lt;= testStr.length(); n ++) {            if (wordDict.contains(testStr.substring(position, n)) &amp;&amp; subString(testStr, wordDict, n, memo)) {                return true;            }        }        memo[position] = false;        return false;    }}</code></pre><h2 id="Solution-2-Dynamic-Programming"><a href="#Solution-2-Dynamic-Programming" class="headerlink" title="Solution 2 Dynamic Programming"></a>Solution 2 Dynamic Programming</h2><pre><code>class Solution {    public boolean wordBreak(String s, List&lt;String&gt; wordDict) {        Set&lt;String&gt; wordDictSet = new HashSet(wordDict);        boolean[] dp = new boolean[s.length() + 1];        dp[0] = true;        for (int i = 1; i &lt;= s.length(); i ++) {            for (int j = 0; j &lt; i; j++) {                if (dp[j] &amp;&amp; wordDictSet.contains(s.substring(j, i))) {                    dp[i] = true;                    break;                }            }        }        return dp[s.length()];    }}</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://labuladong.gitbook.io/algo/dong-tai-gui-hua-xi-lie/1.1-dong-tai-gui-hua-ji-ben-ji-qiao/dong-tai-gui-hua-xiang-jie-jin-jie" target="_blank" rel="noopener">https://labuladong.gitbook.io/algo/dong-tai-gui-hua-xi-lie/1.1-dong-tai-gui-hua-ji-ben-ji-qiao/dong-tai-gui-hua-xiang-jie-jin-jie</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Instagram Design Scratch</title>
      <link href="/Instagram-Design-Scratch/"/>
      <url>/Instagram-Design-Scratch/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro-and-Instagram"><a href="#1-Intro-and-Instagram" class="headerlink" title="1. Intro and Instagram"></a>1. Intro and Instagram</h1><ul><li>social networking service </li><li>upload and share photos and videos </li><li>share info either publicly or privately </li><li>share through other social networking platforms <ul><li>facebook</li><li>twitter</li><li>flickr</li><li>tumblr</li></ul></li></ul><ul><li><p>requirement </p><ul><li><p>functional </p><ul><li>users should be able to upload/ download/ view photos </li><li>search based on photo/ video titles </li><li>users can follow other users </li><li>system will generate and display a user’s News Feed consisting of top photos from all the people the user follows </li></ul></li><li><p>non-functional </p><ul><li>services need to be highly available </li><li>latency come to be 200ms for News Feed Generation </li></ul></li></ul></li></ul><h1 id="2-Design"><a href="#2-Design" class="headerlink" title="2. Design"></a>2. Design</h1><ul><li>patterns<ul><li>read heavy system <ul><li>need to effectively manage storage </li><li>100% reliable of data </li><li>low latency </li></ul></li></ul></li></ul><ul><li><p>system design </p><ul><li><p>we need to support two scenarios</p><ul><li>upload photos </li><li>view/ search photos</li></ul></li><li><p>db </p><ul><li>image storage </li><li>image metadata storage </li></ul></li></ul></li></ul><ul><li><p>Separate read and write servers </p><ul><li>web servers have a connection limit </li><li>assume max is 500 connections, that means server cannot have more than 500 concurrent uploads or reads </li></ul></li><li><p>reliability </p><ul><li>run a redundant secondary copy of the service that is not serving any traffic if only one instance of a service is required to run at any point </li></ul></li><li><p>data sharding </p><ul><li><p>partition based on UserID?</p><ul><li>hot user </li><li>non-uniform storage as some users may upload a lot of images </li><li>what if one shard is full? </li><li>unavailability – all users data come to be unavailable all of sudden </li></ul></li><li><p>use photoId as partition key </p></li></ul></li><li><p>news feeds - e.g 100 feeds </p><ul><li><p>real time generation </p><ul><li>need to go to user follow table to get all of its following people </li><li>then query with user id to get their 100 updates </li><li>combine them, go through our ranking algo </li><li>then generate the output </li></ul></li><li><p>should choose pre-generating way as it will save a lot of times </p><ul><li>have dedicated servers that are continuously generating users’ News Feeds and storing them in a UserNewsFeed table</li></ul></li></ul></li><li><p>approaches for seanding news feed contents to users </p><ul><li><p>pull</p><ul><li><p>clients can pull the News Feed contents from the server on a regular basis or manually whenever they need it </p><ul><li><p>problems</p><ul><li>new data might not be shown to the users until clients issue a pull request </li><li>most of time, pull requests response could be empty </li></ul></li><li><p>push </p><ul><li>servers can push new data to the users as soon as it is available </li><li>users then need to maintain a long poll request with the server for receiving the updates </li><li>issue <ul><li>user has follow a lot of people </li><li>celebrity user who has meillions of followers </li><li>server then have to push updates quite frequently </li></ul></li></ul></li><li><p>hybrid </p><ul><li>move all the users who have a high number of follows to a pull based model and only push data to those users who have a few hundred follows </li></ul></li></ul></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Designing Pastebin</title>
      <link href="/Designing-Pastebin/"/>
      <url>/Designing-Pastebin/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro-and-requirements"><a href="#1-Intro-and-requirements" class="headerlink" title="1. Intro and requirements"></a>1. Intro and requirements</h1><ul><li>Pastebin<ul><li>service enable users to store plain text or images over the network and generate unique urls to access the uploaded data </li></ul></li></ul><ul><li><p>requirements</p><ul><li><p>functional </p><ul><li>users could upload/ paste their data and get a unique URL to access it </li><li>users only able to upload text </li><li>data and links will expire after a specific timespan, user should be able to specify expeiration time </li><li>users should optionally be able to pick a custom alias for their paste </li></ul></li><li><p>non functional </p><ul><li>system should be highly reliable, no data loss any time </li><li>system should be highly available</li><li>small latency </li><li>paste links should not be guessable </li></ul></li></ul></li></ul><h1 id="2-thoughts"><a href="#2-thoughts" class="headerlink" title="2. thoughts"></a>2. thoughts</h1><ul><li><p>requirement clarification </p><ul><li>what’s the accept types of the file? </li><li>what’s the maximum size of the file? <ul><li>10MB</li></ul></li></ul></li><li><p>hardware requirement </p><ul><li>read write request number </li><li>average request size </li><li>storage size <ul><li>we probably don’t want to use more than 70% of our total storage capacity at any point </li></ul></li><li>cache size </li></ul></li><li><p>how to achieve highly reliable, and highly available </p><ul><li>duplicate host </li></ul></li><li><p>how you want to store those file </p><ul><li>of course key value<ul><li>then question come to be what’s the overall number of key we need to store </li></ul></li></ul></li><li><p>high level design </p><ul><li>besides normal client, application server, and object storage </li><li>we could have another db to store metadata, like paste id, user </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Designing a URL Shortening service like TinyURL</title>
      <link href="/Designing-a-URL-Shortening-service-like-TinyURL/"/>
      <url>/Designing-a-URL-Shortening-service-like-TinyURL/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Thoughts"><a href="#1-Thoughts" class="headerlink" title="1. Thoughts"></a>1. Thoughts</h1><p>Based on System Design Guide, our thoughts could follow the framework described <a href="https://llchen60.com/System-Design-General-Guides-from-Grokking-SDI/" target="_blank" rel="noopener">here</a></p><p>Based on that: </p><ul><li><p>Requirement Clarification </p><ul><li>what feature we need<ul><li>create new tinyUrl </li><li>read existing tinyUrl, parse it to websites url </li></ul></li></ul></li><li><p>Envelope estimation </p><ul><li>what traffic amount it would be? Read/ Write Ratio? </li><li>Compute storage size we need</li><li>Network bandwidth usage </li></ul></li><li><p>System Interface Design </p><ul><li>generateNewTinyUrl<ul><li>original url </li><li>output parsed url </li></ul></li><li>parseTinyUrl()<ul><li>input tiny url </li><li>output - mapped original url </li></ul></li></ul></li><li><p>Data Model </p><ul><li>how data will flow between different components of the system </li></ul></li><li><p>High level design and detailed design </p></li><li><p>bottle neck resolving </p></li></ul><h1 id="2-Detail"><a href="#2-Detail" class="headerlink" title="2. Detail"></a>2. Detail</h1><h2 id="2-1-Requirements"><a href="#2-1-Requirements" class="headerlink" title="2.1 Requirements"></a>2.1 Requirements</h2><ul><li><p>Functional </p><ul><li>shorten given url </li><li>access a short url, user will be redirected to original link </li><li>users should optionally be able to pick a custom short link for their url </li><li>links will expire after a standard timespan, users should be able to specify the expiration time </li></ul></li><li><p>Non-Functional Requirements </p><ul><li>System should be highly available </li><li>Url redirection should happen in real time with minimal latency </li><li>Shortened links should not be guessable </li></ul></li><li><p>Extended Requirements</p><ul><li>analytics - how many times a redirection happen</li><li>should also be accessible through REST APIs by other services </li></ul></li></ul><h2 id="2-2-Capacity-Estimation-and-Constraints"><a href="#2-2-Capacity-Estimation-and-Constraints" class="headerlink" title="2.2 Capacity Estimation and Constraints"></a>2.2 Capacity Estimation and Constraints</h2><ul><li><p>read heavy system </p><ul><li>estimate read write ratio 100:1 </li></ul></li><li><p>traffic estimates </p><ul><li>suppose 500M new URL shortening request </li><li>then based on ratio, could be 50B read request </li><li>QPS<ul><li>for write <ul><li>500MM/ (30days * 24 hours * 3600 seconds) = ~ 200 URL/s</li></ul></li><li>for read <ul><li>200 * 100 = 20K/s</li></ul></li></ul></li></ul></li><li><p>storage estimate </p><ul><li>how long do we want to store them? <ul><li>what’s the total number of objects we want to store? <ul><li>suppose 5 years </li><li>500MM * 5 years * 12 months = 30 billion </li><li>suppose every object is about 500 bytes, then in total <ul><li>30B * 500 bytes = 15 TB</li></ul></li></ul></li></ul></li></ul></li><li><p>bandwidth estimate </p><ul><li><p>for write </p><ul><li>200 * 500 bytes/ s = ~100KB/s</li></ul></li><li><p>for read </p><ul><li>20K * 500 bytes = ~ 10MB/s </li></ul></li></ul></li><li><p>memory estimates </p><ul><li>we may want to cache some hot URLs that are frequently accessed, 20/ 80 rule </li><li>cache 20% hot URLs for a day </li><li>memory usage <ul><li>0.2 * 1.7 B * 500 bytes = ~170GB </li></ul></li></ul></li></ul><h2 id="2-3-System-APIs"><a href="#2-3-System-APIs" class="headerlink" title="2.3 System APIs"></a>2.3 System APIs</h2><ul><li><p>createURL (clientId, originalUrl, userName, customAlias, expireDate)</p><ul><li>clientId could be used for throttling based on allocated quota </li><li>return <ul><li>shortened url </li></ul></li></ul></li><li><p>deleteURL (clientId, urlKey)</p></li></ul><h2 id="2-4-DB-design"><a href="#2-4-DB-design" class="headerlink" title="2.4 DB design"></a>2.4 DB design</h2><ul><li>need two table, one store info for the URL mappings; one for the user’s data about who created the short link </li></ul><h2 id="2-5-System-Design-and-Algorithm"><a href="#2-5-System-Design-and-Algorithm" class="headerlink" title="2.5 System Design and Algorithm"></a>2.5 System Design and Algorithm</h2><ul><li><p>How to generate a short and unique key for a given URL </p><ul><li><p>Encoding actual URL </p><ul><li>compute a unique hash of the given URL </li><li>hash could be encoded for display </li><li>If we use MD5 algorithm as our hash function, it’ll produce a 128 bit hash value</li><li>After base64 encoding, we’ll get a string having more than 21 characters<ul><li>take the first 8 letters for the key <ul><li>for duplication, choose some other characters out of the encoding string or swap some characters </li></ul></li></ul></li></ul></li><li><p>generate keys offline </p><ul><li>have a standalon key generation service that generates random six letter strings beforehand and stores them in a database</li><li>whenever we want to shorten a URL, we will take one of the already generated keys and use it </li></ul></li></ul></li></ul><h2 id="2-6-Deta-Partitioning-and-Replication"><a href="#2-6-Deta-Partitioning-and-Replication" class="headerlink" title="2.6 Deta Partitioning and Replication"></a>2.6 Deta Partitioning and Replication</h2><ul><li>Range based partitioning<ul><li>Store URLs in separate partitions based on the hash key’s first letter</li><li>could lead to unbalanced DB servers  </li></ul></li><li>Hash Based Partitioning <ul><li>use hash, and calculate which partition to use based on that </li></ul></li></ul><h2 id="2-7-Cache"><a href="#2-7-Cache" class="headerlink" title="2.7 Cache"></a>2.7 Cache</h2><ul><li><p>could use memcache or other similar in memory cache solution </p></li><li><p>how muach cache memory should we have?</p><ul><li>20% of daily traffic </li></ul></li><li><p>what cache eviction policy should we use?</p><ul><li>LRU </li></ul></li></ul><h2 id="2-8-Load-Balancer"><a href="#2-8-Load-Balancer" class="headerlink" title="2.8 Load Balancer"></a>2.8 Load Balancer</h2><ul><li>We could choose to add LB at: <ul><li>between clients and application servers</li><li>between application servers and database servers</li><li>between apllication servers and cache servers </li></ul></li></ul><h2 id="2-9-Purging-DB-cleanup"><a href="#2-9-Purging-DB-cleanup" class="headerlink" title="2.9 Purging / DB cleanup"></a>2.9 Purging / DB cleanup</h2><ul><li>We should not actively search for expired links to remove them, as it would put a lot of pressure on our db <ul><li>slowlyremove and do a lazy cleanup</li></ul></li></ul><h2 id="2-10-Metrics-and-Security"><a href="#2-10-Metrics-and-Security" class="headerlink" title="2.10 Metrics and Security"></a>2.10 Metrics and Security</h2><ul><li><p>Record metrics </p><ul><li>country of visitor</li><li>data and time </li><li>web page that referred the click </li><li>browser </li><li>platform</li><li>etc. </li></ul></li><li><p>security and permissions </p><ul><li>store the permission level with each URL in the database </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>LC - Tree</title>
      <link href="/LC-Tree/"/>
      <url>/LC-Tree/</url>
      
        <content type="html"><![CDATA[<h1 id="Lc-98-Validate-Binary-Search-Tree"><a href="#Lc-98-Validate-Binary-Search-Tree" class="headerlink" title="Lc 98. Validate Binary Search Tree"></a>Lc 98. Validate Binary Search Tree</h1><h2 id="Solution-1-Recursion"><a href="#Solution-1-Recursion" class="headerlink" title="Solution 1: Recursion"></a>Solution 1: Recursion</h2><pre><code>class Solution {    public boolean isValidBST(TreeNode root) {        return isValidSubTree(root, null, null);    }    boolean isValidSubTree(TreeNode node, Integer lower, Integer upper) {        if (node == null) {            return true;        }        int val = node.val;        if (lower != null &amp;&amp; val &lt;= lower) return false;        if (upper != null &amp;&amp; val &gt;= upper) return false;        if (!isValidSubTree(node.right, val, upper)) return false;        if (!isValidSubTree(node.left, lower, val)) return false;        return true;    }}</code></pre><h2 id="Solution-2-Inorder-Traversal"><a href="#Solution-2-Inorder-Traversal" class="headerlink" title="Solution 2: Inorder Traversal"></a>Solution 2: Inorder Traversal</h2><ul><li>这样遍历前一个比后一个小才是BST</li></ul><pre><code>class Solution {  public boolean isValidBST(TreeNode root) {    Stack&lt;TreeNode&gt; stack = new Stack();    double inorder = - Double.MAX_VALUE;    while (!stack.isEmpty() || root != null) {      while (root != null) {        stack.push(root);        root = root.left;      }      root = stack.pop();      // If next element in inorder traversal      // is smaller than the previous one      // that&#39;s not BST.      if (root.val &lt;= inorder) return false;      inorder = root.val;      root = root.right;    }    return true;  }}</code></pre><h1 id="LC-105-Construct-Binary-Tree-from-Preorder-and-Inorder-Traversal"><a href="#LC-105-Construct-Binary-Tree-from-Preorder-and-Inorder-Traversal" class="headerlink" title="LC 105. Construct Binary Tree from Preorder and Inorder Traversal"></a>LC 105. Construct Binary Tree from Preorder and Inorder Traversal</h1><ul><li>前序遍历  根节点，左子节点，右子节点</li><li>中序遍历  左子节点，根节点，右子节点</li><li>没有重复数字</li><li>前序遍历的第一个节点是根节点，其在中序遍历当中出现的位置，其之前是左子树，其之后是右子树，可以用这个逻辑来递归进行判断</li></ul><h1 id="LC-226-Invert-Binary-Tree"><a href="#LC-226-Invert-Binary-Tree" class="headerlink" title="LC 226. Invert Binary Tree"></a>LC 226. Invert Binary Tree</h1><h2 id="Solution-1-Recursion-1"><a href="#Solution-1-Recursion-1" class="headerlink" title="Solution 1: Recursion"></a>Solution 1: Recursion</h2><ul><li>逻辑是每个根节点的左子树是其右子树的翻转，即层层都翻转过了  用递归完成这个逻辑就好</li></ul><pre><code>class Solution {    public TreeNode invertTree(TreeNode root) {        if (root == null) {            return null;        }        TreeNode right = invertTree(root.right);        TreeNode left = invertTree(root.left);        root.left = right;        root.right = left;        return root;    }}</code></pre><h2 id="Solution-2-Iteration"><a href="#Solution-2-Iteration" class="headerlink" title="Solution 2: Iteration"></a>Solution 2: Iteration</h2><pre><code>class Solution {    public TreeNode invertTree(TreeNode root) {        if (root == null) return null;        Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;();        queue.add(root);        while (!queue.isEmpty()) {            TreeNode current = queue.poll();            TreeNode temp = current.left;            current.left = current.right;            current.right = temp;            if (current.left != null) queue.add(current.left);            if (current.right != null) queue.add(current.right);        }        return root;    }}</code></pre><h2 id="Solution-2-Iterative"><a href="#Solution-2-Iterative" class="headerlink" title="Solution 2: Iterative"></a>Solution 2: Iterative</h2><h1 id="LC-543-Diameter-of-Binary-Tree"><a href="#LC-543-Diameter-of-Binary-Tree" class="headerlink" title="LC 543. Diameter of Binary Tree"></a>LC 543. Diameter of Binary Tree</h1><ul><li><p>Diameter – length of the longest path between any two nodes in a tre </p></li><li><p>Binary Tree </p><pre><code>public class Solution {  int max = 0;  public int diameterOfBinaryTree(TreeNode root) {      maxDepth(root);      return max;  }  private int maxDepth(TreeNode root) {      if (root == null) return 0;      int left = maxDepth(root.left);      int right = maxDepth(root.right);      max = Math.max(max, left + right);      return Math.max(left, right) + 1;  }}</code></pre></li></ul><h1 id="LC-938-Range-Sum-of-BST"><a href="#LC-938-Range-Sum-of-BST" class="headerlink" title="LC 938. Range Sum of BST"></a>LC 938. Range Sum of BST</h1><ul><li><p>二叉查找树</p><ul><li>左子树的值会小于根节点的值</li><li>右子树的值都大于根节点的值</li></ul></li><li><p>二叉查找树当中找区间，一定是需要用到二叉查找树本身的性质的</p></li></ul><h2 id="Solution-1-Brute-Force"><a href="#Solution-1-Brute-Force" class="headerlink" title="Solution 1: Brute Force"></a>Solution 1: Brute Force</h2><ul><li>遍历整个树，对于每个节点，对其进行判断，若值在区间内，则累加到一个全局变量上</li></ul><pre><code>class Solution {    int sum = 0;    public int rangeSumBST(TreeNode root, int L, int R) {        addToSum(root, L, R);        return sum;    }    void addToSum(TreeNode node, int L, int R) {        if (node == null) return;        if (node.val &gt;= L &amp;&amp; node.val &lt;= R) {            sum += node.val;        }        addToSum(node.left, L, R);        addToSum(node.right, L, R);    }}</code></pre><h2 id="Solution-2-Leverage-on-BST"><a href="#Solution-2-Leverage-on-BST" class="headerlink" title="Solution 2: Leverage on BST"></a>Solution 2: Leverage on BST</h2><ul><li><p>逻辑是如果node.val &lt; L, 那么只有右子树是有可能获取在区间内的值的</p><pre><code>class Solution {  int ans;  public int rangeSumBST(TreeNode root, int L, int R) {      ans = 0;      dfs(root, L, R);      return ans;  }  public void dfs(TreeNode node, int L, int R) {      if (node != null) {          if (L &lt;= node.val &amp;&amp; node.val &lt;= R)              ans += node.val;          if (L &lt; node.val)              dfs(node.left, L, R);          if (node.val &lt; R)              dfs(node.right, L, R);      }  }}</code></pre></li><li><p>Q: L13 – L16, 为什么不能写成</p><ul><li><code>node.val &gt; R</code></li><li><code>node.val &lt; L</code></li></ul></li><li><p>因为其实第10行的if判断只是为了加进去ans，没有做其他的逻辑运算的</p></li></ul><h1 id="LC-199-Binary-Tree-Right-Side-View"><a href="#LC-199-Binary-Tree-Right-Side-View" class="headerlink" title="LC 199: Binary Tree Right Side View"></a>LC 199: Binary Tree Right Side View</h1><ul><li>对树的分层操作<ul><li>使用BFS算法</li></ul></li></ul><h2 id="Solution-1-使用两个队列"><a href="#Solution-1-使用两个队列" class="headerlink" title="Solution 1: 使用两个队列"></a>Solution 1: 使用两个队列</h2><ul><li>两个队列，一个为当前层，一个为下一层</li></ul><pre><code>class Solution {    public List&lt;Integer&gt; rightSideView(TreeNode root) {        if (root == null) {            return new ArrayList&lt;&gt;();        }        ArrayDeque&lt;TreeNode&gt; currentQueue = new ArrayDeque&lt;&gt;();        ArrayDeque&lt;TreeNode&gt; nextQueue = new ArrayDeque&lt;&gt;();        nextQueue.add(root);        List&lt;Integer&gt; result = new ArrayList&lt;&gt;();        TreeNode node = null;        while(!nextQueue.isEmpty()) {            currentQueue = nextQueue.clone();            nextQueue.clear();            while (!currentQueue.isEmpty()) {                node = currentQueue.poll();                if (node.left != null) {                    nextQueue.add(node.left);                }                if (node.right != null) {                    nextQueue.add(node.right);                }            }            if (currentQueue.isEmpty()) {                result.add(node.val);            }        }        return result;    }}</code></pre><h2 id="Solution-2-一个队列-Sentinel"><a href="#Solution-2-一个队列-Sentinel" class="headerlink" title="Solution 2: 一个队列 + Sentinel"></a>Solution 2: 一个队列 + Sentinel</h2><ul><li>使用null作为卫兵节点来区分不同层</li></ul><pre><code>class Solution {    public List&lt;Integer&gt; rightSideView(TreeNode root) {        if (root == null) {            return new ArrayList&lt;&gt;();        }        Queue&lt;TreeNode&gt; queue = new LinkedList() {            {offer(root);            offer(null);}        };        TreeNode prev, cur = root;        List&lt;Integer&gt; result = new ArrayList();        while (!queue.isEmpty()) {            prev = cur;            cur = queue.poll();            while(cur != null) {                if (cur.left != null) {                    queue.offer(cur.left);                }                if (cur.right != null) {                    queue.offer(cur.right);                }                prev = cur;                cur = queue.poll();            }            result.add(prev.val);            if (!queue.isEmpty()) queue.offer(null);        }        return result;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tree </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LC - Linked List</title>
      <link href="/LC-Linked-List/"/>
      <url>/LC-Linked-List/</url>
      
        <content type="html"><![CDATA[<h1 id="LC-23-Merge-K-Sorted-Lists"><a href="#LC-23-Merge-K-Sorted-Lists" class="headerlink" title="LC-23 Merge K Sorted Lists"></a>LC-23 Merge K Sorted Lists</h1><ul><li>给定k个链表，每个链表都按照升序排列，合并链表使得最终的链表也按照升序排列</li><li>最直观的想法</li><li>以一个链表为基准，拿出一个链表来做比较，各保留一个指针，然后来做合并操作</li></ul><h2 id="Solution1-Brute-Force"><a href="#Solution1-Brute-Force" class="headerlink" title="Solution1: Brute Force"></a>Solution1: Brute Force</h2><ul><li><p>都放到一个arraylist当中</p></li><li><p>使用Collection的排序算法，对其进行排序</p></li><li><p>然后创建一个新的链表，来返回结果</p><pre><code>class Solution {  public ListNode mergeKLists(ListNode[] lists) {      if (lists == null || lists.length == 0) {          return null;      }      List&lt;Integer&gt; list = new ArrayList();      for (ListNode ln : lists) {          while (ln != null) {              list.add(ln.val);              ln = ln.next;          }      }      Collections.sort(list);      ListNode dummy = new ListNode(0);      ListNode result = dummy;      for (int i = 0; i &lt; list.size(); i++) {          result.next = new ListNode(list.get(i));          result = result.next;      }      return dummy.next;  }}</code></pre></li></ul><h2 id="Solution-2"><a href="#Solution-2" class="headerlink" title="Solution 2"></a>Solution 2</h2><ul><li>比较每个链表头，将最小的放到result中，一个一个这样比较，相当于只遍历了以便就生成了结果</li><li>注意终止循环的判断，应该是几个链表都到头了才退出</li></ul><pre><code>class Solution {    public ListNode mergeKLists(ListNode[] lists) {        if (lists == null || lists.length == 0) {            return null;        }        ListNode result = new ListNode(0);        ListNode head = result;        while (true) {            int min = Integer.MAX_VALUE;            int min_index = -1;            boolean shouldBreak = true;            for (int i = 0; i &lt; lists.length; i++) {                if (lists[i] != null &amp;&amp; lists[i].val &lt; min) {                    min = lists[i].val;                    min_index = i;                    shouldBreak = false;                }            }            if (shouldBreak) break;            // get one value min             head.next = lists[min_index];            head = head.next;            lists[min_index] = lists[min_index].next;        }        return result.next;    }}</code></pre><h2 id="Solution-3-使用Priority-Queue"><a href="#Solution-3-使用Priority-Queue" class="headerlink" title="Solution 3: 使用Priority Queue"></a>Solution 3: 使用Priority Queue</h2><pre><code>public ListNode mergeKLists(ListNode[] lists) {         PriorityQueue q = new PriorityQueue&lt;&gt;((o1, o2) -&gt; o1.val - o2.val);        for(ListNode l : lists){            if(l!=null){                // 这里加进去的不是value 而是几个ListNode                q.add(l);            }                }        ListNode head = new ListNode(0);        ListNode point = head;        while(!q.isEmpty()){             point.next = q.poll();            point = point.next;             ListNode next = point.next;            if(next!=null){                // 顺次下移以后比较下一个节点                q.add(next);            }        }        return head.next;    }</code></pre><h1 id="LC-24-Swap-Nodes-in-Pairs"><a href="#LC-24-Swap-Nodes-in-Pairs" class="headerlink" title="LC-24 Swap Nodes in Pairs"></a>LC-24 Swap Nodes in Pairs</h1><ul><li><p>交换相邻节点</p></li><li><p>临界条件</p><ul><li>单个节点</li><li>没有节点</li></ul></li><li><p>因为会涉及到首节点的替换变动，所以为了简化问题，需要设置一个 dummy node，使得<code>dummy.next = head</code></p></li><li><p>画一个基本的swap示意图可以发现整个替换会涉及四个节点</p><ul><li>首节点的上个节点原先指向首节点的指针</li><li>首节点本身</li><li>次节点本身</li><li>次节点原先指向次节点下一个节点的指针</li></ul></li><li><p>因为是单向链表，我们没法用prev指针来找到上一个节点，所以需要在过程中做好prev的记录，而对于次节点的下一个节点，完全可以用next指针来表示</p></li><li><p>另外要注意做swap的时候的顺序问题</p></li></ul><pre><code>// Iteration的版本class Solution {    public ListNode swapPairs(ListNode head) {        ListNode dummy = new ListNode(0);        dummy.next = head;        ListNode prev = dummy;        while (head != null &amp;&amp; head.next != null) {            ListNode cur = head;            ListNode next = head.next;            // Swapping             prev.next = next;            cur.next = next.next;            next.next = cur;            prev = cur;            head = cur.next;        }        return dummy.next;    }}</code></pre><h1 id="92-Reverse-Linked-List-II"><a href="#92-Reverse-Linked-List-II" class="headerlink" title="92. Reverse Linked List II"></a>92. Reverse Linked List II</h1><ul><li>reverse a linked list from position m to n </li></ul><pre><code>/** * Definition for singly-linked list. * public class ListNode { *     int val; *     ListNode next; *     ListNode() {} *     ListNode(int val) { this.val = val; } *     ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution {    public ListNode reverseBetween(ListNode head, int m, int n) {        // how to reverse a         ListNode prev = null;        ListNode cur = head;        while (m &gt; 1) {            prev = cur;            cur = cur.next;            m --;            n --;        }        ListNode next;        // at this point, current prev is the final front we need to keep record        ListNode toConnectStart = prev;        ListNode toConnextEnd = cur;        while (n &gt; 0) {            next = cur.next;            cur.next = prev;            prev = cur;            cur = cur.next;            n --;        }        if (toConnectStart != null) {            toConnectStart.next = prev;        } else {            head = prev;        }        toConnextEnd.next = cur;        return head;    }}</code></pre><h1 id="LC-146-LRU-Cache"><a href="#LC-146-LRU-Cache" class="headerlink" title="LC-146 LRU Cache"></a>LC-146 LRU Cache</h1><ul><li>为了实现O(1)的get put请求，需要使用双向链表 + HashMap</li><li>Hashmap来跟踪在双向链表当中的key 和value</li></ul><pre><code>class LRUCache {    private Map&lt;Integer, LinkedNode&gt; cache = new HashMap&lt;&gt;();    private LinkedNode head, tail;    private int size;    private int capacity;    class LinkedNode {        int key;        int value;        LinkedNode prev;        LinkedNode next;    }    // addNode right after the head    private void addNode (LinkedNode node) {        node.prev = head;        node.next = head.next;        head.next.prev = node;        head.next = node;    }    private void moveToHead(LinkedNode node) {        removeNode(node);        addNode(node);    }    private void removeNode(LinkedNode node) {        LinkedNode prev = node.prev;        LinkedNode next = node.next;        prev.next = next;        next.prev = prev;    }    public LRUCache(int capacity) {        this.size = 0;        this.capacity = capacity;        head = new LinkedNode();        tail = new LinkedNode();        head.next = tail;        tail.prev = head;    }    private LinkedNode popTail() {        /**         * Pop the current tail.         */        LinkedNode res = tail.prev;        removeNode(res);        return res;    }    public int get(int key) {        LinkedNode node = cache.get(key);        if (node == null) return -1;        moveToHead(node);        return node.value;    }    public void put(int key, int value) {        LinkedNode node = cache.get(key);        if (node == null) {            LinkedNode newNode = new LinkedNode();            newNode.key = key;            newNode.value = value;            cache.put(key, newNode);            addNode(newNode);            ++size;          if(size &gt; capacity) {            // pop the tail            LinkedNode tail = popTail();            cache.remove(tail.key);            --size;          }        }  else {            // update the value.            node.value = value;            moveToHead(node);        }      }}/** * Your LRUCache object will be instantiated and called as such: * LRUCache obj = new LRUCache(capacity); * int param_1 = obj.get(key); * obj.put(key,value); */</code></pre><h1 id="LC-234-Palindrome-Linked-List"><a href="#LC-234-Palindrome-Linked-List" class="headerlink" title="LC-234 Palindrome Linked List"></a>LC-234 Palindrome Linked List</h1><h2 id="Solution-1-递归"><a href="#Solution-1-递归" class="headerlink" title="Solution 1: 递归"></a>Solution 1: 递归</h2><ul><li><p>反向输出链表的递归逻辑</p><pre><code>function print_values_in_reverse(ListNode head)  if head is NOT null      print_values_in_reverse(head.next)      print head.val</code></pre></li><li><p>题解</p></li></ul><pre><code>class Solution {    private ListNode front;    private boolean recursiveCheck(ListNode cur) {        if (cur != null) {            if (!recursiveCheck(cur.next)) return false;            if (cur.val != front.val) return false;            front = front.next;        }        return true;    }    public boolean isPalindrome(ListNode head) {        front = head;        return recursiveCheck(head);    }}</code></pre><h2 id="Solution-2-反向后半链表来做比较"><a href="#Solution-2-反向后半链表来做比较" class="headerlink" title="Solution 2: 反向后半链表来做比较"></a>Solution 2: 反向后半链表来做比较</h2><pre><code>class Solution {    public boolean isPalindrome(ListNode head) {        if (head == null) return true;        // Find the end of first half and reverse second half.        ListNode firstHalfEnd = endOfFirstHalf(head);        ListNode secondHalfStart = reverseList(firstHalfEnd.next);        // Check whether or not there is a palindrome.        ListNode p1 = head;        ListNode p2 = secondHalfStart;        boolean result = true;        while (result &amp;&amp; p2 != null) {            if (p1.val != p2.val) result = false;            p1 = p1.next;            p2 = p2.next;        }                // Restore the list and return the result.        firstHalfEnd.next = reverseList(secondHalfStart);        return result;    }    // Taken from https://leetcode.com/problems/reverse-linked-list/solution/    private ListNode reverseList(ListNode head) {        ListNode prev = null;        ListNode curr = head;        while (curr != null) {            ListNode nextTemp = curr.next;            curr.next = prev;            prev = curr;            curr = nextTemp;        }        return prev;    }    private ListNode endOfFirstHalf(ListNode head) {        ListNode fast = head;        ListNode slow = head;        while (fast.next != null &amp;&amp; fast.next.next != null) {            fast = fast.next.next;            slow = slow.next;        }        return slow;    }}</code></pre><h1 id="LC-1474-Delete-N-nodes-after-M-nodes-of-a-linked-list"><a href="#LC-1474-Delete-N-nodes-after-M-nodes-of-a-linked-list" class="headerlink" title="LC-1474 Delete N nodes after M nodes of a linked list"></a>LC-1474 Delete N nodes after M nodes of a linked list</h1><ul><li><p>链表热身题</p></li><li><p>注意边界条件的判定，题中已给m和n的限定范围，所以不需要额外做判断了</p></li><li><p>对于n的周期性去除的node，注意可以不用额外空间，通过改变指针的指向即可</p><pre><code>class Solution {  public ListNode deleteNodes(ListNode head, int m, int n) {      ListNode cur = head;      ListNode last = head;      while (cur != null) {          int mCount = m;          int nCount = n;          while (cur != null &amp;&amp; mCount &gt; 0 ) {              last = cur;              cur = cur.next;              mCount --;          }          while (cur != null &amp;&amp; nCount &gt; 0) {              cur = cur.next;              nCount --;          }          last.next = cur;      }      return head;  }}</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LinkedList </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>System Design Basics</title>
      <link href="/System-Design-Basics/"/>
      <url>/System-Design-Basics/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Key-Characteristics-of-Distributed-Systems"><a href="#1-Key-Characteristics-of-Distributed-Systems" class="headerlink" title="1. Key Characteristics of Distributed Systems"></a>1. Key Characteristics of Distributed Systems</h1><h2 id="1-1-Scalability"><a href="#1-1-Scalability" class="headerlink" title="1.1 Scalability"></a>1.1 Scalability</h2><ul><li><p>Capability of a system, process, or a network to grow and manage increased demand. Achieve the scaling without performance loss </p></li><li><p>Why need to scale?</p><ul><li>Increased data volume </li><li>Increased amount of work <ul><li>number of transactions </li></ul></li></ul></li><li><p>Performance curve </p><ul><li>Usually performance of a system would decline with the system size due to the management or environment cost <ul><li>network speed come to be slower because machines tend to be far apart from one another </li><li>some tasks may not be distributed, either because of their inherent atomic nature or because of some flaw in the system design </li></ul></li></ul></li></ul><ul><li><p>Horizontal vs Vertical Scaling </p><ul><li><p>Horizontal Scaling </p><ul><li>Scale by adding more servers into your pool of resources </li><li>Easier to scale dynamically by adding more machines into the existing pool </li></ul></li><li><p>Vertical scaling </p><ul><li><p>Scale by adding more power to an existing server </p><ul><li>CPU</li><li>RAM</li><li>Storage </li></ul></li><li><p>limited to the capacity of a single server, and scaling beyond that capacity often <strong>involves downtime</strong> and comes with an upper limit </p></li></ul></li></ul></li></ul><h2 id="1-2-Reliability"><a href="#1-2-Reliability" class="headerlink" title="1.2 Reliability"></a>1.2 Reliability</h2><ul><li>Probability a system will fail in a given period</li><li>A distributed system is considered reliable if it keeps delivering its services even when one or more software or hardware components fail </li><li>A reliable distributed system achieves this through redundancy of both the software components and data <ul><li>Eliminate every single point of failure</li></ul></li></ul><h2 id="1-3-Availability"><a href="#1-3-Availability" class="headerlink" title="1.3 Availability"></a>1.3 Availability</h2><ul><li>The time a system remains operational to perform its required function in s specific period </li><li>Percentage of time that a system, service, or a machine remains operational under normal conditions </li><li>Reliability  is availability over time considering the full range of possible real world conditions that can occur</li><li>If a system is reliable, it is available. However, if it is available, it is not necessarily reliable. In other words, high reliability contributes to high availability, but it is possible to achieve a high availability even with an unreliable product by minimizing repair time and ensuring that spares are always available when they are needed</li></ul><h2 id="1-4-Efficiency"><a href="#1-4-Efficiency" class="headerlink" title="1.4 Efficiency"></a>1.4 Efficiency</h2><ul><li><p>Standard measures of its efficiency </p><ul><li><p>Response time/ latency </p><ul><li>denotes the delay to obtain the first item </li></ul></li><li><p>Throughput / bandwidth</p><ul><li>number of items delivered in a given time unit </li></ul></li></ul></li><li><p>two measures above correspond to the following unit costs </p><ul><li>number of messages globally sent by the nodes of the system regardless of the message size </li><li>size of messages representing the volume of data exchanges </li></ul></li></ul><h2 id="1-5-Serviceability-Manageability"><a href="#1-5-Serviceability-Manageability" class="headerlink" title="1.5 Serviceability / Manageability"></a>1.5 Serviceability / Manageability</h2><ul><li>How easy it is to operate and maintain </li><li>Simplicity and speed with which a system can be repared or maintained </li><li>Ease of diagnosing and understanding problems when they occur, ease of making updates or modifications, </li></ul><h1 id="2-Load-Balancing"><a href="#2-Load-Balancing" class="headerlink" title="2. Load Balancing"></a>2. Load Balancing</h1><h2 id="2-1-What-is-Load-Balancer"><a href="#2-1-What-is-Load-Balancer" class="headerlink" title="2.1 What is Load Balancer?"></a>2.1 What is Load Balancer?</h2><ul><li><p>A critical component of any distributed system</p><ul><li><p>help to spread the traffic across a cluster of servers to improve responsiveness and availability of applications/ websites/ databases </p></li><li><p>also keep track of the status of all the resources while distributing requests </p><ul><li>if one server is not available to take new requests, not responding, has elevated error rate </li><li>LB will stop sending traffic to such server </li></ul></li><li><p>sit between client and the server accepting incoming network and application traffic, distribute traffic across multiple backend servers using various algorithm</p></li><li><p>could prevents any one application server from becoming a single point of failure </p></li></ul></li><li><p>where to add LB?</p><ul><li>between the user and the web server </li><li>between web servers and an internal platform layer, like application servers or cache servers </li><li>between internal platform layer and database <h2 id="2-2-Benefits"><a href="#2-2-Benefits" class="headerlink" title="2.2 Benefits"></a>2.2 Benefits</h2></li></ul></li><li><p>from user side </p><ul><li>faster, uninterrupted service; their requests could be immediately passed on to a more readily available resource </li></ul></li><li><p>from service provider side </p><ul><li>experience less downtime and higher throughput </li></ul></li><li><p>long term benefits</p><ul><li>smart load balancers provide benefits like predictive analytics that determine traffic bottlenecks before they happen </li></ul></li></ul><h2 id="2-3-Load-Balancing-Algorithms"><a href="#2-3-Load-Balancing-Algorithms" class="headerlink" title="2.3 Load Balancing Algorithms"></a>2.3 Load Balancing Algorithms</h2><ul><li><p>How does the load balancer choose the backend server?</p><ul><li><ol><li>Make sure servers could respond appropriately to requests <ul><li>routinely do health check <ul><li>regularly attempt to connect to backend servers to ensure that servers are listening </li></ul></li></ul></li></ol></li><li><ol start="2"><li><p>Use pre configured algorithm to select one from the set of healthy servers </p><ul><li><p>Least connection Method </p><ul><li>direct traffic to the server with fewest active connections </li><li>useful when there are a large number of persistent client connections which are unevenly distributed between the servers</li></ul></li><li><p>Least Response Time Method </p><ul><li>direct traffic to the server with the fewest active connections and the lowest average response time </li></ul></li><li><p>Least Bandwidth Method </p><ul><li>selects the server that is currently serving the least amount of traffic measured in megabits per second (Mbps)</li></ul></li><li><p>Round Robin Method </p><ul><li>cycles through a list of servers and sends each new request to the next server </li><li>most useful when the servers are of equal specification and there are not many persistent connections</li></ul></li><li><p>weighted round robin </p><ul><li>desifned to better handle servers with different processing capacities </li><li>each server is assigned a weight which indicates the processing capacity </li></ul></li><li><p>IP Hash </p><ul><li>A hash of the IP address of the client is calculated to redirect the request to a server </li></ul></li></ul></li></ol></li></ul></li></ul><h2 id="2-4-Redundant-Load-Balancers"><a href="#2-4-Redundant-Load-Balancers" class="headerlink" title="2.4 Redundant Load Balancers"></a>2.4 Redundant Load Balancers</h2><ul><li>Load Balancer can be a single point of failure <ul><li>thus we need a second load balancer, to form a cluster </li><li>each LB monitors the health of the other</li><li>passive one could be switched to be active anytime since they keep monitoring same </li></ul></li></ul><h1 id="3-Caching"><a href="#3-Caching" class="headerlink" title="3. Caching"></a>3. Caching</h1><p>Caching enable you to make vastly better use of the resources you already have as well as make otherwise unattainable product requirements feasible。 </p><p>It takes advantage of the locality of reference principle: recently requested data is likely to be requested again, could be used in almost every layer of computing </p><h2 id="3-1-Application-Server-Cache"><a href="#3-1-Application-Server-Cache" class="headerlink" title="3.1 Application Server Cache"></a>3.1 Application Server Cache</h2><ul><li><p>place a cache directly on a request layer node </p></li><li><p>cache could be located both in memory and on the node’s local disk </p></li><li><p>One note here </p><ul><li>if expand this to many nodes, depends on your load balancer behavior, if it randomly distributes requests across the nodes, the same request will go to different nodes, thus increasing cache misses. <ul><li>could use either global caches or distributed caches for it </li></ul></li></ul></li></ul><h2 id="3-2-Content-Distribution-Network"><a href="#3-2-Content-Distribution-Network" class="headerlink" title="3.2 Content Distribution Network"></a>3.2 Content Distribution Network</h2><ul><li><p>For sites serving large amounts of static media </p></li><li><p>A typical workflow </p><ul><li>A request first ask the CDN for a piece of static media </li><li>CDN will serve the content if it has it locally available </li><li>If not, CDN will query the back end servers for the file </li><li>Then cache it locally, and serve it to the requesting user <h2 id="3-3-Cache-Invalidation"><a href="#3-3-Cache-Invalidation" class="headerlink" title="3.3 Cache Invalidation"></a>3.3 Cache Invalidation</h2></li></ul></li><li><p>Cache needs maintenance for keeping cache coherent with the source of truth</p><ul><li>if data is modified in db, should be invalidated in the cache </li></ul></li><li><p>Write Through Cache </p><ul><li>Data is written into the cache and the corresponding database at the same time </li><li>It could minimize the risk of data loss, but since every write operation mush be done twice before returning success to the client, latency would be higher </li></ul></li><li><p>Write Around Cache </p><ul><li>Data is written directly to permanent storage, bypassing the cache </li><li>Could reduce the cache being flooded with write operations that will not subsequently be re-read</li><li>But a read request for recently written data will create a cache miss </li></ul></li><li><p>Write Back Cache </p><ul><li>Data is written to cache alone</li><li>Write to permanent storage is done after specified intervals or under certain conditions </li><li>Low latency and high throughput for write intensive applications </li><li>However this speed up could cause issue of data loss in case of a crash or other adverse event because the only copy of the written data is in the cache </li></ul></li></ul><h2 id="3-4-Cache-Eviction-Policies"><a href="#3-4-Cache-Eviction-Policies" class="headerlink" title="3.4 Cache Eviction Policies"></a>3.4 Cache Eviction Policies</h2><ul><li>First In First Out </li><li>Last In First Out </li><li>Least Recently Used </li><li>Most Recently Used </li><li>Least Frequently Used </li><li>Randowm Replacement </li></ul><h1 id="4-Data-Partitioning"><a href="#4-Data-Partitioning" class="headerlink" title="4. Data Partitioning"></a>4. Data Partitioning</h1><p>It aims to break up a big database into many smaller parts. It’s a process of splitting up a DB/ table across multiple machines to improve the manageability, performance, availability, and load balancing of an application. </p><p>The justification for data partitioning is after a certain scale point, it’s cheaper and more feasible to scale horizontally by adding more machines that to grow it vertically by adding beefier servers </p><h2 id="4-1-Partitioning-Methods"><a href="#4-1-Partitioning-Methods" class="headerlink" title="4.1 Partitioning Methods"></a>4.1 Partitioning Methods</h2><h3 id="4-1-1-Horizontal-Partitioning-Sharding"><a href="#4-1-1-Horizontal-Partitioning-Sharding" class="headerlink" title="4.1.1 Horizontal Partitioning/ Sharding"></a>4.1.1 Horizontal Partitioning/ Sharding</h3><ul><li><p>Put different rows into different tables </p></li><li><p>range based partitioning as we store different ranges of data in separate tables </p></li><li><p>Probelm here</p><ul><li>is the range value isn’t chosen carefully, the partitioning scheme will lead to unbalanced servers <h3 id="4-1-2-Vertical-Partitioning"><a href="#4-1-2-Vertical-Partitioning" class="headerlink" title="4.1.2 Vertical Partitioning"></a>4.1.2 Vertical Partitioning</h3></li></ul></li><li><p>store data related to a specific feature in their own server </p><ul><li>like photo in one server, video in another, people they follow in another </li></ul></li><li><p>not quite scalable, if our app experience some high traffic, then the single server will not be enough to handle such traffic </p></li></ul><h3 id="4-1-3-Directory-Based-Partitioning"><a href="#4-1-3-Directory-Based-Partitioning" class="headerlink" title="4.1.3 Directory Based Partitioning"></a>4.1.3 Directory Based Partitioning</h3><ul><li>Create a lookup service which knows your current partitioning scheme and abstracts it away from the DB access code </li><li>To find a particular data entity, query the directory server that holds the mapping between each tuple key to its DB server</li></ul><h2 id="4-2-Partitioning-Criteria"><a href="#4-2-Partitioning-Criteria" class="headerlink" title="4.2 Partitioning Criteria"></a>4.2 Partitioning Criteria</h2><ul><li><p>Key or hash based partitioning </p><ul><li>apply a hash function to some key attributes of the entity we are storing </li><li>need to ensure a uniform allocation of data among servers </li><li>it will change the hash function when every time you add / remove some servers, the workaround is to use consistent hashing </li></ul></li><li><p>List Partitioning </p><ul><li>each partition is assigned a list of values </li></ul></li><li><p>Round robind partitioning </p></li><li><p>Composite Partitioning </p><ul><li>combination of criteria above</li></ul></li></ul><h2 id="4-3-Common-Problems-of-Data-Partitioning"><a href="#4-3-Common-Problems-of-Data-Partitioning" class="headerlink" title="4.3 Common Problems of Data Partitioning"></a>4.3 Common Problems of Data Partitioning</h2><ul><li><p>Joins and Denormalization </p><ul><li>Performing joins on a database that runs on several different servers </li><li>will not be performance efficient </li><li>Workaround is to denormalize database so queries perviously requiring joins can be performed from a single table <ul><li>but need to deal with data inconsistency issue </li></ul></li></ul></li><li><p>Referential Integrity </p><ul><li>nforce data integrity constraints such as foreign keys in a partitioned database can be extremely difficult</li></ul></li><li><p>Rebalancing </p><ul><li><p>need to do that due to </p><ul><li>data distribution is not uniform </li><li>could be a lot of load on one partition </li></ul></li><li><p>In such cases, either we have to create more DB partitions or have to rebalance existing partitions, which means the partitioning scheme changed and all existing data moved to new locations. Doing this without incurring downtime is extremely difficult. Using a scheme like directory based partitioning does make rebalancing a more palatable experience at the cost of increasing the complexity of the system and creating a new single point of failure </p></li></ul></li></ul><h1 id="5-Indexes"><a href="#5-Indexes" class="headerlink" title="5. Indexes"></a>5. Indexes</h1><p>Leverage on indexes when current database performance is no longer satisfactory. Indexing could help make search faster, it could be created using one or more columns of a ddb table, providing the basis for both rapid random lookups and efficient access of ordered records. </p><p>Index can dramatically speed up data retrieval but may itself be large due to the additional keys, which will slow down data insertion and update. </p><p>When adding rows or making updates to existing rows for a table with an active index, we not only have to write the data but also have to update the index. This will decrease the write performance. </p><p>This performance degradation applies to all insert, update, and delete operations for the table. For this reason, adding unnecessary indexes on tables should be avoided and indexes that are no longer used should be removed.</p><p>If the goal of ddb is often written to and rarely read from, in that case, decreasing the performance of the more common operation, which is writing, is probably not worth the increase in performance we get from reading.</p><h1 id="6-Proxies"><a href="#6-Proxies" class="headerlink" title="6. Proxies"></a>6. Proxies</h1><h2 id="6-1-What-is-Proxy-Server"><a href="#6-1-What-is-Proxy-Server" class="headerlink" title="6.1 What is Proxy Server?"></a>6.1 What is Proxy Server?</h2><ul><li><p>Intermediate server between the client and the backend server </p></li><li><p>Clients connect to proxy servers to make a request for a service like</p><ul><li>web page</li><li>file connection </li></ul></li><li><p>Proxy server is a piece of software or hardware that acts as an intermediary for requests from clients seeking resources from other servers </p></li><li><p>Proxy are used to </p><ul><li><p>filter requests </p></li><li><p>transform requests </p><ul><li>add/ remove headers </li><li>encrypt and decrypt</li><li>compress a resource </li></ul></li><li><p>caching </p><ul><li>if multiple clients access a particular resource, the proxy server can cache it and serve it to all clients without going to the remote server </li></ul></li></ul></li></ul><h2 id="6-2-Types"><a href="#6-2-Types" class="headerlink" title="6.2 Types"></a>6.2 Types</h2><ul><li><p>Open Proxy </p><ul><li>A proxy server that is accessible by any internet user </li><li>type<ul><li>anonymous proxy <ul><li>reveals its identity as a server but does not disclose the initial IP address </li></ul></li><li>transparent proxy <ul><li>Identify itself and with the suppot of HTTP headers </li><li>IP address could be viewed </li><li>main benefit of using this sort of server is its ability to cache the websites </li></ul></li></ul></li></ul></li><li><p>reverse proxy </p><ul><li>retrieve resources on behalf of a client from one or more servers </li><li>these resources are then returned to the client, appearing as if they originated from the proxy server itself </li></ul></li></ul><h1 id="7-Redundancy-and-Replication"><a href="#7-Redundancy-and-Replication" class="headerlink" title="7. Redundancy and Replication"></a>7. Redundancy and Replication</h1><ul><li>redundancy <ul><li>duplication of critical components or functions of a system with the intention of increasing the reliability of the system <ul><li>backup</li><li>fail saft </li><li>direct improvement on actual system performance </li></ul></li></ul></li></ul><ul><li><p>replication </p><ul><li><p>shareing information to ensure consistency between redundant resources</p><ul><li>to improve reliability</li><li>fault tolerance</li><li>accessibility </li></ul></li><li><p>primary replica relationship </p><ul><li>primary server gets all the updates </li><li>then ripple through to the replica servers </li><li>each replica outputs a message stating that it has received the update successfully <h1 id="8-SQL-vs-NoSQL"><a href="#8-SQL-vs-NoSQL" class="headerlink" title="8. SQL vs NoSQL"></a>8. SQL vs NoSQL</h1></li></ul></li></ul></li></ul><h2 id="8-1-Concepts"><a href="#8-1-Concepts" class="headerlink" title="8.1 Concepts"></a>8.1 Concepts</h2><ul><li><p>Relational databases </p><ul><li>structured </li><li>predefiend schemas </li></ul></li><li><p>Non-relational database </p><ul><li>unstrutured </li><li>distributed</li><li>dynamic schema </li></ul></li></ul><ul><li><p>SQL</p><ul><li><p>store data in rows and columns </p></li><li><p>each row contains:</p><ul><li>all the info about one entity </li></ul></li><li><p>each column contains:</p><ul><li>all separate data points </li></ul></li></ul></li><li><p>NoSQL</p><ul><li><p>Key-Value Stores </p><ul><li>store in an arry of key value pairs</li><li>key is an attribute name which is linked to a vlue <ul><li>redis</li><li>voldemort</li><li>dynamo</li></ul></li></ul></li><li><p>document database</p><ul><li>data is stored in documents (instead of rows and columns in a table)</li><li>documents are grouped together in collections </li><li>each document can have an entirely different structure</li></ul></li><li><p>wide column databases</p><ul><li>have column families, which are containers for rows </li><li>no need to know all the columns up front and each row doesn’t have to have the same number of columns</li><li>best suited for analyzing large datasets </li><li>type <ul><li>HBase</li><li>Cassandra</li></ul></li></ul></li><li><p>Graph Database</p><ul><li>used to store data whose relations are best represented in a graph </li><li>data is saved in graph structures with:<ul><li>nodes <ul><li>entities</li></ul></li><li>properties<ul><li>information about the entities </li></ul></li><li>lines <ul><li>connections between the entities</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="8-2-Differences-between-SQL-and-NoSQL"><a href="#8-2-Differences-between-SQL-and-NoSQL" class="headerlink" title="8.2 Differences between SQL and NoSQL"></a>8.2 Differences between SQL and NoSQL</h2><ul><li><p>Storage</p><ul><li><p>SQL </p><ul><li>each row represents an entity </li><li>each column represents a data point about the entity </li></ul></li><li><p>NoSQL</p><ul><li>could be key value</li><li>document</li><li>graph </li></ul></li></ul></li><li><p>Schema</p><ul><li><p>SQL</p><ul><li>each record conforms to a fixed schema <ul><li>columns must be decided and chosen before data entry </li><li>each row must have data for each column </li></ul></li><li>schema modification need to involve modifying the whole database and go offline </li></ul></li><li><p>NoSQL</p><ul><li>schemas are dynamic </li><li>columns can be added on the fly, and each row doesn’t have to contain data for each column</li></ul></li></ul></li><li><p>Query </p><ul><li><p>SQL </p><ul><li>Structured query language for defining and manipulating the data </li></ul></li><li><p>NoSQL </p><ul><li>Query focus on a collection of documents </li><li>UnQL - unstructured query language </li></ul></li></ul></li></ul><ul><li><p>Scalability</p><ul><li><p>SQL</p><ul><li>vetically scalable <ul><li>by increase the horsepower (memory, CPU, etc.) of the hardware </li></ul></li></ul></li><li><p>NoSQL</p><ul><li>horizontally scalable <ul><li>we could add more servers easily in database infrastructure to handle more traffic </li><li>any cheap hardware could host NoSQL database</li></ul></li></ul></li></ul></li><li><p>Reliability or ACID comliancy</p><ul><li><p>ACID</p><ul><li>atomocity</li><li>consistency</li><li>isolation</li><li>durability </li></ul></li><li><p>most NoSQL solutions sacrifice ACID compliance for performance and scalability </p></li></ul></li></ul><h2 id="8-3-Choose-which-one"><a href="#8-3-Choose-which-one" class="headerlink" title="8.3 Choose which one?"></a>8.3 Choose which one?</h2><ul><li>Reasons for use SQL<ul><li>Need ACID compliance <ul><li>ACID reduces anomalies and protects the integrity of your db by prescribing exactly how transactions interact with the database </li></ul></li><li>Data is structured and unchanging </li></ul></li></ul><ul><li><p>Reasons for use NoSQL </p><ul><li><p>Store large volumens of data that often have little to no structure </p><ul><li>NoSQL allows use to add new types </li><li>with document based databases, you can store data in one place without having to define what types of data those are in advance </li></ul></li><li><p>Making the most of cloud computing and storage </p><ul><li>cloud based storage requires data to be easily spread across multiple servers to scale up </li></ul></li><li><p>Rapid development </p></li></ul></li></ul><h1 id="9-CAP-Theorem"><a href="#9-CAP-Theorem" class="headerlink" title="9. CAP Theorem"></a>9. CAP Theorem</h1><p>CAP states it’s impossible for a distributed software system to simultaneously provide more than two out of three of the following gurantees:</p><ul><li>consistency </li><li>availability </li><li>partition tolerance </li></ul><p>CAP say when designing a distributed system we could only pick two of them: </p><ul><li><p>consistency </p><ul><li>all nodes see the same data at the same time </li><li>consistency is achieved by updating several nodes before allowing further reads </li></ul></li><li><p>availability </p><ul><li>every requests get a response on success/ failure </li><li>availability is achieved by replicating the data across different servers </li></ul></li><li><p>partition tolerance </p><ul><li>system continues to work despite msg loss or partial failure </li><li>data is sufficiently replicated across combinations of nodes and networks to keep the system up through intermittent outages </li></ul></li></ul><p>We cannot build a general data store that is continually available, sequentially consistent, and tolerant to any partition failures. We can only build a system that has any two of these three properties. Because, to be consistent, all nodes should see the same set of updates in the same order. But if the network loses a partition, updates in one partition might not make it to the other partitions before a client reads from the out-of-date partition after having read from the up-to-date one. The only thing that can be done to cope with this possibility is to stop serving requests from the out-of-date partition, but then the service is no longer 100% available.</p><h1 id="10-Consistent-Hashing"><a href="#10-Consistent-Hashing" class="headerlink" title="10. Consistent Hashing"></a>10. Consistent Hashing</h1><h2 id="10-1-Existing-Hash-Funciton"><a href="#10-1-Existing-Hash-Funciton" class="headerlink" title="10.1 Existing Hash Funciton"></a>10.1 Existing Hash Funciton</h2><p>Distributed Hash Table is super important in distributed scalable systems. Hash Tables need a key, a value, and a hash function where hash function maps the key to a location where the value is stored. </p><p>A common thought of hash function would be key%n, but it has several drawbacks:</p><ol><li><p>Not horizontally scalable </p><ol><li>whenever a new cache host is added to the system, all existing mappings are broken </li></ol></li><li><p>Not load balanced </p><ol><li>expecially for non-uniformly distributed data </li><li>some caches would come to be hot and saturated while the others idel and are almost empty </li></ol></li></ol><h2 id="10-2-Consistent-Hashing"><a href="#10-2-Consistent-Hashing" class="headerlink" title="10.2 Consistent Hashing"></a>10.2 Consistent Hashing</h2><ul><li>want to minimize reorganization when nodes are added or removed </li><li>when the hash table is resized  only k/n keys need to be remapped where k is the total number of keys and n is the total number of servers </li><li>objects are mapped to the same host if possible </li></ul><ul><li>how it works <ul><li>map a key to an integer</li><li>all integers are placed on a ring such that the values are wrapped around </li><li>each object is assigned to the next server that appears o nthe circle in clockwise order  –&gt; provide an even distribution of objects to servers </li><li>if a server fails and is removed from the circle, only the objects that were mapped to the failed server need to be reassigned to the next server in clockwise order </li></ul></li></ul><h1 id="11-Long-Polling-WebSockets-Server-Sent-Events"><a href="#11-Long-Polling-WebSockets-Server-Sent-Events" class="headerlink" title="11. Long-Polling, WebSockets, Server-Sent Events"></a>11. Long-Polling, WebSockets, Server-Sent Events</h1><p>Long Polling, WebSockets and Server Sent events are popular communication protocols between a client like web browser and a web server </p><h2 id="11-1-Ajax-Polling"><a href="#11-1-Ajax-Polling" class="headerlink" title="11.1 Ajax Polling"></a>11.1 Ajax Polling</h2><ul><li><p>Client repeatedly polls a server for data</p></li><li><p>Client make a request and wait for the server to respond with data. If no data available, an empty response is returned </p></li><li><p>whole workflow</p><ul><li>client opens a connection and requests data from the server using regular HTTP </li><li>the requested webpage sends requests to the server at regular intervals </li><li>the server calculates the response and sends it back, like regular HTTP traffic </li><li>the client repeats the above three steps periodically to get updates from the server </li></ul></li></ul><ul><li>pitfall<ul><li>Polling let client continue to ask server for any new data, as a result, a lot of responses are empty, creating HTTP overhead </li></ul></li></ul><h2 id="11-2-HTTP-Long-Polling"><a href="#11-2-HTTP-Long-Polling" class="headerlink" title="11.2 HTTP Long-Polling"></a>11.2 HTTP Long-Polling</h2><ul><li>Workflow <ul><li>If the server does not have any data available for the client, instead of sending an empty response, the server holds the request and waits until some data becomes available </li><li>once available, a full response is sent to the client. Client then immediately request information from the server so that the server will almost always have an available waiting request that it can use to deliver data in response to an event </li></ul></li></ul><ul><li>The client makes an initial request using regular HTTP and then waits for a response.</li><li>The server delays its response until an update is available or a timeout has occurred.</li><li>When an update is available, the server sends a full response to the client.</li><li>The client typically sends a new long-poll request, either immediately upon receiving a response or after a pause to allow an acceptable latency period.</li><li>Each Long-Poll request has a timeout. The client has to reconnect periodically after the connection is closed due to timeouts.</li></ul><h2 id="11-3-WebSockets"><a href="#11-3-WebSockets" class="headerlink" title="11.3 WebSockets"></a>11.3 WebSockets</h2><ul><li>Provides Full duplex communication channels over a single TCP connection. </li><li>Provides a persistent connection between a client and a server that both parties can use to start sending data at any time. </li><li>lower overhead, real time data transfer <ul><li>it provides a standardized way for the server to send content to the browser without being asked by the client and allowing for messages to be passed back and forth while keeping the connection open </li></ul></li><li>Workflow <ul><li>Client establish a websocket connection through a process known as the WebSocket handshake</li><li>if the process succeeds server and client can exchange data in both directions at any time </li></ul></li></ul><h2 id="11-4-Server-Sent-Events-SSEs"><a href="#11-4-Server-Sent-Events-SSEs" class="headerlink" title="11.4 Server Sent Events - SSEs"></a>11.4 Server Sent Events - SSEs</h2><ul><li>Client establish a persistent and long term connection with the server </li><li>Server use this connection to send data to a client </li><li>But client would need another tech/ protocol to send data to the server </li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/Consistent_hashing#:~:text=In%20computer%20science%2C%20consistent%20hashing,is%20the%20number%20of%20slots" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Consistent_hashing#:~:text=In%20computer%20science%2C%20consistent%20hashing,is%20the%20number%20of%20slots</a>. </li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>System Design General Guides - from Grokking SDI</title>
      <link href="/System-Design-General-Guides-from-Grokking-SDI/"/>
      <url>/System-Design-General-Guides-from-Grokking-SDI/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Requirements-Clarifications"><a href="#1-Requirements-Clarifications" class="headerlink" title="1. Requirements Clarifications"></a>1. Requirements Clarifications</h1><ul><li>Ask about the exact scope of the problem <ul><li>For a twitter like system design <ul><li>will users of our service be able to post tweets and follow others? </li><li>Create and display user’s timeline?</li><li>Tweets contain photos and videos?</li><li>Front end design too?</li><li>Searchable tweets?</li><li>Display hot trending topics?</li><li>Push notification for new tweets? </li></ul></li></ul></li></ul><h1 id="2-Back-of-the-envelope-estimation"><a href="#2-Back-of-the-envelope-estimation" class="headerlink" title="2. Back of the envelope estimation"></a>2. Back of the envelope estimation</h1><ul><li><p>estimate the scale of the system we are going to design </p><ul><li><p>could help later when we will be focusing on scaling, partitioning, load balancing and caching</p><ul><li><p>what scale is expected </p><ul><li>number of new tweets</li><li>number of tweet views</li><li>number of timeline generations per sec </li></ul></li><li><p>how much storage will we need</p><ul><li>videos and photos will play important role on our estimation </li></ul></li><li><p>what network bandwidth usage are we expecting</p><ul><li>crucial in deciding how we will manage traffic and balance load between servers </li></ul></li></ul></li></ul></li></ul><h1 id="3-System-Interface-Definition"><a href="#3-System-Interface-Definition" class="headerlink" title="3. System Interface Definition"></a>3. System Interface Definition</h1><p>Establish exact contract expected from the system </p><pre><code>postTweet(user_id, tweet_data, tweet_location, user_location, timestamp, …)  generateTimeline(user_id, current_time, user_location, …)  markTweetFavorite(user_id, tweet_id, timestamp, …)  </code></pre><h1 id="4-Define-Data-Model"><a href="#4-Define-Data-Model" class="headerlink" title="4. Define Data Model"></a>4. Define Data Model</h1><p>Define the data model, to clarify how data will flow between different components of the system. Later, will guide for data partitioning and management. </p><p>User: UserID, Name, Email, DoB, CreationData, LastLogin, etc.<br>Tweet: TweetID, Content, TweetLocation, NumberOfLikes, TimeStamp, etc.<br>UserFollow: UserID1, UserID2<br>FavoriteTweets: UserID, TweetID, TimeStamp</p><h1 id="5-High-level-design"><a href="#5-High-level-design" class="headerlink" title="5. High level design"></a>5. High level design</h1><ul><li>Draw a block diagram with 5 - 6 boxes representing the core components of our system. We need to identify enough components that are needed to solve the actual problem from end2end. </li><li>For twitter <ul><li>Multiple application servers to serve all the read/ write requests with load balancers in front of them for traffic distributions </li><li>we could have separate servers for handling specific traffic (like much more read than write)</li><li>Efficient database that can store all the tweets and can support a huge number of reads </li><li>Also need a distributed file storage system for storing photos and videos </li></ul></li></ul><h1 id="6-Detailed-Design"><a href="#6-Detailed-Design" class="headerlink" title="6. Detailed Design"></a>6. Detailed Design</h1><ul><li>Dig deeper to 2 or 3 components <ul><li>present different approaches</li><li>pros and cons </li><li>explain why we prefer one on the other </li><li>consider tradeoffs between different options while keeping system contraints in mind </li></ul></li></ul><ul><li>Question Examples<ul><li>Since we will be storing a massive amount of data, how should we partition our data to distribute it to multiple databases? Should we try to store all the data of a user on the same database? What issue could it cause?</li><li>How will we handle hot users who tweet a lot or follow lots of people?</li><li>Since users’ timeline will contain the most recent (and relevant) tweets, should we try to store our data in such a way that is optimized for scanning the latest tweets?</li><li>How much and at which layer should we introduce cache to speed things up?</li><li>What components need better load balancing?</li></ul></li></ul><h1 id="7-Identifying-and-resolving-bottlenecks"><a href="#7-Identifying-and-resolving-bottlenecks" class="headerlink" title="7 Identifying and resolving bottlenecks"></a>7 Identifying and resolving bottlenecks</h1><ul><li>Discuss as many bottlenecks as possible and different approaches to mitigate them <ul><li>Any single point of failure in our system? </li><li>Do we have enough replicas of the data so that if we lose a few servers, we can still serve our users? </li><li>Do we have enough copies of different services running such that a fewe failures will not cause a total system shutdown?</li><li>How to monitor performance of our service? </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>缓存的常见问题</title>
      <link href="/%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
      <url>/%E7%BC%93%E5%AD%98%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-缓存雪崩"><a href="#1-缓存雪崩" class="headerlink" title="1. 缓存雪崩"></a>1. 缓存雪崩</h1><p>缓存系统的IOPS比数据库高很多，因此需要注意短时间内的大量缓存失效的情况。这种情况一旦发生，可能就会在瞬间有大量的数据需要回源到数据库查询，对数据库造成极大的压力，极限情况下甚至导致后端数据库直接崩溃。这就是我们说的缓存雪崩。</p><p>产生雪崩的原因有两种：</p><ul><li>缓存系统本身不可用，导致大量请求直接回源到数据库</li><li>应用设计层面大量的Key在同一时间过期，导致大量的数据回源<ul><li>解决方法<ul><li>差异化缓存过期时间<ul><li>不让大量的Key在同一时间过期</li><li>初始化缓存的时候，设置缓存的过期时间为30秒 + 10秒以内的随机延迟（扰动值）。这样key就不会集中在30秒这个时刻过期，而是会分散在30 - 40秒之间</li></ul></li><li>让缓存不主动过期<ul><li>初始化缓存数据的时候设置缓存永不过期，然后启动一个后台线程30秒一次定时将所有数据更新到缓存，通过适当的休眠，控制从数据库更新数据的频率，降低数据库的压力</li><li>如果无法全量缓存所有的数据，那么就无法使用该种方案</li></ul></li></ul></li></ul></li></ul><pre><code>// 差异化缓存过期时间@PostConstructpublic void rightInit1() {    //这次缓存的过期时间是30秒+10秒内的随机延迟    IntStream.rangeClosed(1, 1000).forEach(i -&gt; stringRedisTemplate.opsForValue().set(&quot;city&quot; + i, getCityFromDb(i), 30 + ThreadLocalRandom.current().nextInt(10), TimeUnit.SECONDS));    log.info(&quot;Cache init finished&quot;);    //同样1秒一次输出数据库QPS：   Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&gt; {        log.info(&quot;DB QPS : {}&quot;, atomicInteger.getAndSet(0));    }, 0, 1, TimeUnit.SECONDS);}// 让缓存不主动过期@PostConstructpublic void rightInit2() throws InterruptedException {    CountDownLatch countDownLatch = new CountDownLatch(1);    //每隔30秒全量更新一次缓存     Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&gt; {        IntStream.rangeClosed(1, 1000).forEach(i -&gt; {            String data = getCityFromDb(i);            //模拟更新缓存需要一定的时间            try {                TimeUnit.MILLISECONDS.sleep(20);            } catch (InterruptedException e) { }            if (!StringUtils.isEmpty(data)) {                //缓存永不过期，被动更新                stringRedisTemplate.opsForValue().set(&quot;city&quot; + i, data);            }        });        log.info(&quot;Cache update finished&quot;);        //启动程序的时候需要等待首次更新缓存完成        countDownLatch.countDown();    }, 0, 30, TimeUnit.SECONDS);    Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -&gt; {        log.info(&quot;DB QPS : {}&quot;, atomicInteger.getAndSet(0));    }, 0, 1, TimeUnit.SECONDS);    countDownLatch.await();}</code></pre><h1 id="2-缓存击穿"><a href="#2-缓存击穿" class="headerlink" title="2. 缓存击穿"></a>2. 缓存击穿</h1><p>在某些Key属于极端热点数据并且并发量很大的情况下，如果这个Key过期，可能会在某个瞬间出现大量的并发请求同时回源，相当于大量的并发请求直接打到了数据库。这就是我们所说的缓存击穿或缓存并发问题。</p><p>如果说回源操作比较昂贵的话，那么这种并发就不能忽略不计了。可以考虑使用锁机制来限制回源的并发，或者可以使用类似Semaphore的工具来限制并发数，比如限制为10.这样子既限制了回源并发数不至于太大，又能够使得一定量的线程可以同时回源。</p><h1 id="3-缓存穿透"><a href="#3-缓存穿透" class="headerlink" title="3. 缓存穿透"></a>3. 缓存穿透</h1><p>缓存穿透指的是实际上缓存里有key 和value，但是其value可能为空，如果没做正确处理，那我们的逻辑可能会认为没有对当前的key做好缓存，会对所有的请求都回源到数据库上，这就会给数据库造成压力了。</p><p>针对这种问题，可以用以下方案解决：</p><ul><li><p>对于不存在的数据，同样设置一个特殊的Value到缓存当中，比如NODATA，这样子就不会有缓存穿透的问题</p><ul><li>可能会将大量无效的数据加入到缓存当中</li></ul></li><li><p>使用布隆过滤器</p><ul><li>放在缓存数据读取前先进行过滤操作</li><li>Google Guava BloomFilter </li></ul></li></ul><pre><code>private BloomFilter&lt;Integer&gt; bloomFilter;@PostConstructpublic void init() {    //创建布隆过滤器，元素数量10000，期望误判率1%    bloomFilter = BloomFilter.create(Funnels.integerFunnel(), 10000, 0.01);    //填充布隆过滤器    IntStream.rangeClosed(1, 10000).forEach(bloomFilter::put);}@GetMapping(&quot;right2&quot;)public String right2(@RequestParam(&quot;id&quot;) int id) {    String data = &quot;&quot;;    //通过布隆过滤器先判断    if (bloomFilter.mightContain(id)) {        String key = &quot;user&quot; + id;        //走缓存查询        data = stringRedisTemplate.opsForValue().get(key);        if (StringUtils.isEmpty(data)) {            //走数据库查询            data = getCityFromDb(id);            stringRedisTemplate.opsForValue().set(key, data, 30, TimeUnit.SECONDS);        }    }    return data;}</code></pre><h1 id="4-缓存数据同步策略"><a href="#4-缓存数据同步策略" class="headerlink" title="4. 缓存数据同步策略"></a>4. 缓存数据同步策略</h1><ul><li>当原始数据被修改了以后，我们很可能会采用主动更新缓存的策略<ul><li>可能的策略有<ul><li>先更新缓存，再更新数据库<ul><li>不可行</li><li>数据库操作失败是有可能的，会导致缓存和数据库当中的数据不一致</li></ul></li><li>先更新数据库，再更新缓存<ul><li>不可行</li><li>多线程情况下数据库中更新的顺序和缓存更新的顺序会不同，可能会导致旧数据最后到，导致问题的出现</li></ul></li><li>先删除缓存，再更新数据库，访问的时候按需加载数据到缓存当中<ul><li>很可能删除缓存以后还没来得及更新数据库，就有另外一个线程先读取了旧值到缓存中</li></ul></li><li>先更新数据库，再删除缓存，访问的时候按需加载数据到缓存当中<ul><li>出现缓存不一致的概率很低</li></ul></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>利用注解 + 反射消除重复代码</title>
      <link href="/%E5%88%A9%E7%94%A8%E6%B3%A8%E8%A7%A3-%E5%8F%8D%E5%B0%84%E6%B6%88%E9%99%A4%E9%87%8D%E5%A4%8D%E4%BB%A3%E7%A0%81/"/>
      <url>/%E5%88%A9%E7%94%A8%E6%B3%A8%E8%A7%A3-%E5%8F%8D%E5%B0%84%E6%B6%88%E9%99%A4%E9%87%8D%E5%A4%8D%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h1 id="1-案例分析"><a href="#1-案例分析" class="headerlink" title="1. 案例分析"></a>1. 案例分析</h1><h2 id="1-1-案例场景"><a href="#1-1-案例场景" class="headerlink" title="1.1 案例场景"></a>1.1 案例场景</h2><p>假设银行提供了一些 API 接口，对参数的序列化有点特殊，不使用 JSON，而是需要我们把参数依次拼在一起构成一个大字符串</p><ul><li>按照银行提供的API文档顺序，将所有的参数构成定长的数据，并且拼接在一起作为一整个字符串</li><li>因为每一种参数都有固定长度，未达到长度需要进行填充处理<ul><li>字符串类型参数不满长度部分要以下划线右填充，即字符串内容靠左</li><li>数字类型的参数不满长度部分以0左填充，即实际数字靠右</li><li>货币类型的表示需要把金额向下舍入2位到分，以分为单位，作为数字类型同样进行左填充</li><li>参数做MD5 操作作为签名</li></ul></li></ul><h2 id="1-2-初步代码实现"><a href="#1-2-初步代码实现" class="headerlink" title="1.2 初步代码实现"></a>1.2 初步代码实现</h2><pre><code>public class BankService {    //创建用户方法    public static String createUser(String name, String identity, String mobile, int age) throws IOException {        StringBuilder stringBuilder = new StringBuilder();        //字符串靠左，多余的地方填充_        stringBuilder.append(String.format(&quot;%-10s&quot;, name).replace(&#39; &#39;, &#39;_&#39;));        //字符串靠左，多余的地方填充_        stringBuilder.append(String.format(&quot;%-18s&quot;, identity).replace(&#39; &#39;, &#39;_&#39;));        //数字靠右，多余的地方用0填充        stringBuilder.append(String.format(&quot;%05d&quot;, age));        //字符串靠左，多余的地方用_填充        stringBuilder.append(String.format(&quot;%-11s&quot;, mobile).replace(&#39; &#39;, &#39;_&#39;));        //最后加上MD5作为签名        stringBuilder.append(DigestUtils.md2Hex(stringBuilder.toString()));        return Request.Post(&quot;http://localhost:45678/reflection/bank/createUser&quot;)                .bodyString(stringBuilder.toString(), ContentType.APPLICATION_JSON)                .execute().returnContent().asString();    }    //支付方法    public static String pay(long userId, BigDecimal amount) throws IOException {        StringBuilder stringBuilder = new StringBuilder();        //数字靠右，多余的地方用0填充        stringBuilder.append(String.format(&quot;%020d&quot;, userId));        //金额向下舍入2位到分，以分为单位，作为数字靠右，多余的地方用0填充        stringBuilder.append(String.format(&quot;%010d&quot;, amount.setScale(2, RoundingMode.DOWN).multiply(new BigDecimal(&quot;100&quot;)).longValue()));        //最后加上MD5作为签名        stringBuilder.append(DigestUtils.md2Hex(stringBuilder.toString()));        return Request.Post(&quot;http://localhost:45678/reflection/bank/pay&quot;)                .bodyString(stringBuilder.toString(), ContentType.APPLICATION_JSON)                .execute().returnContent().asString();    }}</code></pre><ul><li>这样做能够基本满足需求，但是存在一些问题：<ul><li>处理逻辑互相之间有重复，稍有不慎就会出现Bug</li><li>处理流程中字符串拼接、加签和发请求的逻辑，在所有方法重复</li><li>实际方法的入参的参数类型和顺序，不一定和接口要求一致，容易出错</li><li>代码层面参数硬编码，无法清晰进行核对</li></ul></li></ul><h2 id="1-3-使用接口和反射优化代码"><a href="#1-3-使用接口和反射优化代码" class="headerlink" title="1.3 使用接口和反射优化代码"></a>1.3 使用接口和反射优化代码</h2><h3 id="1-3-1-实现定义了所有接口参数的POJO类"><a href="#1-3-1-实现定义了所有接口参数的POJO类" class="headerlink" title="1.3.1 实现定义了所有接口参数的POJO类"></a>1.3.1 实现定义了所有接口参数的POJO类</h3><pre><code>@Datapublic class CreateUserAPI {    private String name;    private String identity;    private String mobile;    private int age;}</code></pre><h3 id="1-3-2-定义注解本身"><a href="#1-3-2-定义注解本身" class="headerlink" title="1.3.2 定义注解本身"></a>1.3.2 定义注解本身</h3><pre><code>@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Inheritedpublic @interface BankAPI {    String desc() default &quot;&quot;;    String url() default &quot;&quot;;}@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)@Documented@Inheritedpublic @interface BankAPIField {    int order() default -1;    int length() default -1;    String type() default &quot;&quot;;}</code></pre><h3 id="1-3-3-反射配合注解实现动态的接口参数组装"><a href="#1-3-3-反射配合注解实现动态的接口参数组装" class="headerlink" title="1.3.3 反射配合注解实现动态的接口参数组装"></a>1.3.3 反射配合注解实现动态的接口参数组装</h3><pre><code>private static String remoteCall(AbstractAPI api) throws IOException {    //从BankAPI注解获取请求地址    BankAPI bankAPI = api.getClass().getAnnotation(BankAPI.class);    bankAPI.url();    StringBuilder stringBuilder = new StringBuilder();    Arrays.stream(api.getClass().getDeclaredFields()) //获得所有字段            .filter(field -&gt; field.isAnnotationPresent(BankAPIField.class)) //查找标记了注解的字段            .sorted(Comparator.comparingInt(a -&gt; a.getAnnotation(BankAPIField.class).order())) //根据注解中的order对字段排序            .peek(field -&gt; field.setAccessible(true)) //设置可以访问私有字段            .forEach(field -&gt; {                //获得注解                BankAPIField bankAPIField = field.getAnnotation(BankAPIField.class);                Object value = &quot;&quot;;                try {                    //反射获取字段值                    value = field.get(api);                } catch (IllegalAccessException e) {                    e.printStackTrace();                }                //根据字段类型以正确的填充方式格式化字符串                switch (bankAPIField.type()) {                    case &quot;S&quot;: {                        stringBuilder.append(String.format(&quot;%-&quot; + bankAPIField.length() + &quot;s&quot;, value.toString()).replace(&#39; &#39;, &#39;_&#39;));                        break;                    }                    case &quot;N&quot;: {                        stringBuilder.append(String.format(&quot;%&quot; + bankAPIField.length() + &quot;s&quot;, value.toString()).replace(&#39; &#39;, &#39;0&#39;));                        break;                    }                    case &quot;M&quot;: {                        if (!(value instanceof BigDecimal))                            throw new RuntimeException(String.format(&quot;{} 的 {} 必须是BigDecimal&quot;, api, field));                        stringBuilder.append(String.format(&quot;%0&quot; + bankAPIField.length() + &quot;d&quot;, ((BigDecimal) value).setScale(2, RoundingMode.DOWN).multiply(new BigDecimal(&quot;100&quot;)).longValue()));                        break;                    }                    default:                        break;                }            });    //签名逻辑   stringBuilder.append(DigestUtils.md2Hex(stringBuilder.toString()));    String param = stringBuilder.toString();    long begin = System.currentTimeMillis();    //发请求    String result = Request.Post(&quot;http://localhost:45678/reflection&quot; + bankAPI.url())            .bodyString(param, ContentType.APPLICATION_JSON)            .execute().returnContent().asString();    log.info(&quot;调用银行API {} url:{} 参数:{} 耗时:{}ms&quot;, bankAPI.desc(), bankAPI.url(), param, System.currentTimeMillis() - begin);    return result;}</code></pre><p>通过反射来动态获得class的信息，并在runtime的时候完成组装过程。这样做的好处是开发的时候会方便直观很多，然后将逻辑与细节隐藏起来，并且集中放到了一个方法当中，减少了重复，以及维护当中bug的出现。</p><h3 id="1-3-4-在代码中的应用"><a href="#1-3-4-在代码中的应用" class="headerlink" title="1.3.4 在代码中的应用"></a>1.3.4 在代码中的应用</h3><pre><code>@BankAPI(url = &quot;/bank/createUser&quot;, desc = &quot;创建用户接口&quot;)@Datapublic class CreateUserAPI extends AbstractAPI {    @BankAPIField(order = 1, type = &quot;S&quot;, length = 10)    private String name;    @BankAPIField(order = 2, type = &quot;S&quot;, length = 18)    private String identity;    @BankAPIField(order = 4, type = &quot;S&quot;, length = 11) //注意这里的order需要按照API表格中的顺序    private String mobile;    @BankAPIField(order = 3, type = &quot;N&quot;, length = 5)    private int age;}@BankAPI(url = &quot;/bank/pay&quot;, desc = &quot;支付接口&quot;)@Datapublic class PayAPI extends AbstractAPI {    @BankAPIField(order = 1, type = &quot;N&quot;, length = 20)    private long userId;    @BankAPIField(order = 2, type = &quot;M&quot;, length = 10)    private BigDecimal amount;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Annotations </tag>
            
            <tag> Reflection </tag>
            
            <tag> 注解 </tag>
            
            <tag> 反射 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring IoC, AOP浅析</title>
      <link href="/Spring-IoC-AOP%E6%B5%85%E6%9E%90/"/>
      <url>/Spring-IoC-AOP%E6%B5%85%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="1-IoC"><a href="#1-IoC" class="headerlink" title="1. IoC"></a>1. IoC</h1><h2 id="1-1-Overview"><a href="#1-1-Overview" class="headerlink" title="1.1 Overview"></a>1.1 Overview</h2><ul><li><p>Inversion of control </p><ul><li>控制反转</li><li>将设计好的对象交给Spring容器来控制，而不是在对象内部控制</li></ul></li><li><p>好处</p><ul><li>可以无侵入的调整对象的关系</li><li>同时可以无侵入的调整对象的属性，甚至实现对象的替换</li></ul></li></ul><h2 id="1-2-单例Bean注入Prototype的Bean"><a href="#1-2-单例Bean注入Prototype的Bean" class="headerlink" title="1.2 单例Bean注入Prototype的Bean"></a>1.2 单例Bean注入Prototype的Bean</h2><p>Spring创建的Bean默认是单例的，但是当Bean遇到继承的时候，是会忽略这一点的。</p><pre><code>@Slf4jpublic abstract class SayService {    List&lt;String&gt; data = new ArrayList&lt;&gt;();    public void say() {        data.add(IntStream.rangeClosed(1, 1000000)                .mapToObj(__ -&gt; &quot;a&quot;)                .collect(Collectors.joining(&quot;&quot;)) + UUID.randomUUID().toString());        log.info(&quot;I&#39;m {} size:{}&quot;, this, data.size());    }}@Service@Slf4jpublic class SayHello extends SayService {    @Override    public void say() {        super.say();        log.info(&quot;hello&quot;);    }}@Service@Slf4jpublic class SayBye extends SayService {    @Override    public void say() {        super.say();        log.info(&quot;bye&quot;);    }}</code></pre><p>上述代码中，基类SayService是有状态的，dataList一直在增加。当SayHello类继承基类，并且声明为Service的时候，将其注册为Bean。这时候有状态的基类就很有可能造成内存泄露或者线程安全的问题了。</p><p>正确做法是在将类标记为<code>@Service</code>并交给容器进行管理之前，需要首先评估一下类是否有状态，然后为Bean设置合适的Scope。</p><pre><code>@Scope(value = ConfigurableBeanFactory.SCOPE_PROTOTYPE, proxyMode = ScopedProxyMode.TARGET_CLASS)</code></pre><p>让其以代理的方式注入，这样虽然controller还是单例的，但是每次都从代理那里获得Service，这样prototype范围的配置才会真正生效。</p><h1 id="2-AOP"><a href="#2-AOP" class="headerlink" title="2. AOP"></a>2. AOP</h1><ul><li><p>体现了松耦合，高内聚</p></li><li><p>在切面集中实现横切关注点</p><ul><li>缓存</li><li>权限</li><li>日志</li></ul></li><li><p>然后通过切点配置将代码注入到合适的地方</p></li><li><p>关键点</p><ul><li><p>连接点 Join Point </p><ul><li>实现AOP的地方</li><li>方法执行</li></ul></li><li><p>切点 PointCut</p><ul><li>告诉程序在哪里做切入</li><li>Spring中默认使用AspectJ查询表达式，通过在连接点运行查询表达式来匹配切入点</li></ul></li><li><p>增强 Advice</p><ul><li>定义了切入切点后增强的方式<ul><li>前</li><li>后</li><li>环绕</li></ul></li></ul></li><li><p>切面 Aspect</p><ul><li>切面 = 切点 + 增强 </li><li>实现整个AOP操作</li></ul></li></ul></li></ul><h2 id="2-1-实现整个日志记录，异常处理，方法耗时的统一切面"><a href="#2-1-实现整个日志记录，异常处理，方法耗时的统一切面" class="headerlink" title="2.1 实现整个日志记录，异常处理，方法耗时的统一切面"></a>2.1 实现整个日志记录，异常处理，方法耗时的统一切面</h2><pre><code>// 定义一个自定义注解Metrics @Retention(RetentionPolicy.RUNTIME)@Target({ElementType.METHOD, ElementType.TYPE})public @interface Metrics {    /**     * 在方法成功执行后打点，记录方法的执行时间发送到指标系统，默认开启     *     * @return     */    boolean recordSuccessMetrics() default true;    /**     * 在方法成功失败后打点，记录方法的执行时间发送到指标系统，默认开启     *     * @return     */    boolean recordFailMetrics() default true;    /**     * 通过日志记录请求参数，默认开启     *     * @return     */    boolean logParameters() default true;    /**     * 通过日志记录方法返回值，默认开启     *     * @return     */    boolean logReturn() default true;    /**     * 出现异常后通过日志记录异常信息，默认开启     *     * @return     */    boolean logException() default true;    /**     * 出现异常后忽略异常返回默认值，默认关闭     *     * @return     */    boolean ignoreException() default false;}</code></pre><pre><code>// 实现一个切面完成Metrics注解提供的功能@Aspect@Component@Slf4jpublic class MetricsAspect {    @Autowired    private ObjectMapper ObjectMapper;    //实现一个返回Java基本类型默认值的工具。其实，你也可以逐一写很多if-else判断类型，然后手动设置其默认值。    //这里为了减少代码量用了一个小技巧，即通过初始化一个具有1个元素的数组，然后通过获取这个数组的值来获取基本类型默认值     //Array.newInstance(Class&lt;?&gt; componentType, int length) 创建一个有特定的类的类型和长度的对象    private static final Map&lt;Class&lt;?&gt;, Object&gt; DEFAULT_VALUES =         Stream.of(boolean.class, byte.class, char.class, double.class, float.class, int.class, long.class, short.class)             .collect(toMap(clazz -&gt; (Class) clazz, clazz -&gt; Array.get(Array.newInstance(clazz, 1), 0)));     public static T getDefaultValue(Class clazz) {         return (T) DEFAULT_VALUES.get(clazz);     }    // 实现了对标记了Metrics注解的方法进行匹配    @PointCut(&quot;within(@org.cleilei.commonmistakes.springpart1.aopmetrics.Metrics *)&quot;)    public void withMetricsAnnotation() {    }    // 实现了匹配类型上标记了@RestController注解的方法    @PointCut(&quot;within(@org.springframework.web.bind.annotation.RestController *)&quot;)    public void controllerBean() {    }    @Around(&quot;controllerBean() || withMetricsAnnotation()&quot;)    public Object metrics(ProceedingJoinPoint pjp) throws Throwable {        // 通过连接点获取方法签名和方法上Metrics的注解，并根据方法签名生成日志中要输出的方法定义描述        MethodSignature signature = (MethodSignature)pjp.getSignature();        Metrics metrics = signature.getMethod().getAnnotation(Metrics.class);        String name = String.format(&quot;%s %s&quot;, signature.getDeclaringType().toString(), signature.toLongString());        if (metrics == null) {            @Metrics            final class c {}             metrics = c.class.getAnnotation(Metrics.class);        }        // 尝试从上下文获取请求的URL，来方便定位问题        RequestAttributes RequestAttributes = RequestContextHolder.getRequestAttributes();        if (requestAttributes != null) {            HttpServletRequest request = ((ServletRequestAttributes) requestAttributes).getRequest();            if (request != null) {                name += String.format(&quot; %s &quot;, request.getRequestURL().toString());            }        }        // 记录参数        if (metrics.logParameters()) {            log.info(String.format(&quot;Call method %s with parameters %s&quot;, name. objectMapper.writeValueAsString(pjp.getArgs())));        }        // 记录方法的执行，break points, 异常时记录        Object returnValue;        Instant start = Instant.now();        try {            returnValue = pjp.proceed();            if (metrics.recordSuccessMetrics())                //在生产级代码中，我们应考虑使用类似Micrometer的指标框架，把打点信息记录到时间序列数据库中，实现通过图表来查看方法的调用次数和执行时间                log.info(String.format(&quot;Call method %s succeed，time used：%d ms&quot;, name, Duration.between(start, Instant.now()).toMillis()));        } catch (Exception ex) {            if (metrics.recordFailMetrics())                log.info(String.format(&quot;Call method %s fail，time used：%d ms&quot;, name, Duration.between(start, Instant.now()).toMillis()));            if (metrics.logException())                log.error(String.format(&quot;Call method %s with exceptions&quot;, name), ex);            //忽略异常的时候，使用一开始定义的getDefaultValue方法，来获取基本类型的默认值            if (metrics.ignoreException())                returnValue = getDefaultValue(signature.getReturnType());            else                throw ex;        }        //实现了返回值的日志输出        if (metrics.logReturn())            log.info(String.format(&quot;Call method %s with result: %s&quot;, name, returnValue));        return returnValue;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java8 日期时间类</title>
      <link href="/Java8-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E7%B1%BB/"/>
      <url>/Java8-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>在Java8之前，处理日期时间需求的时候需要使用Data, Calendar, SimpleDateFormat来声明时间戳，使用日历处理日期和格式化解析日期时间，Java8之后有了新的日期时间类，定义的比原来要清晰很多，且支持线程安全。</p><p>这篇文章看看时间错乱问题背后的原因，看看使用遗留的日期时间类，来处理日期时间初始化，格式化，解析，计算等可能会遇到的问题，以及如何使用新日期时间类来解决。</p><h1 id="初始化日期时间"><a href="#初始化日期时间" class="headerlink" title="初始化日期时间"></a>初始化日期时间</h1><h2 id="使用Date初始化日期时间"><a href="#使用Date初始化日期时间" class="headerlink" title="使用Date初始化日期时间"></a>使用Date初始化日期时间</h2><pre><code>Date date = new Date(2019, 12, 31, 11, 12, 13);System.out.println(date);// Output Sat Jan 31 11:12:13 CST 3920</code></pre><p>这是因为Date初始化时间的时候是用的和1970的差值，月的值是从0- 11 的</p><p>我们可以使用Calendar来定义时区的信息 </p><h1 id="时区问题"><a href="#时区问题" class="headerlink" title="时区问题"></a>时区问题</h1><pre><code>Calendar calendar = Calendar.getInstance();calendar.set(2019, 11, 31, 11, 12, 13);System.out.println(calendar.getTime());Calendar calendar2 = Calendar.getInstance(TimeZone.getTimeZone(&quot;America/New_York&quot;));calendar2.set(2019, Calendar.DECEMBER, 31, 11, 12, 13);System.out.println(calendar2.getTime());</code></pre><ul><li>Date类<ul><li>Date本身没有时区的问题，都是保存的UTC时间</li><li>Date当中保存的是一个时间戳，是从1970-1-1 0点到现在的毫秒数</li><li>保存方法<ul><li>以UTC保存</li><li>以字面量保存<ul><li>年月日 时分秒  时区信息</li></ul></li></ul></li></ul></li></ul><ul><li><p>ZoneId </p><ul><li><code>ZoneId.of</code>用来初始化一个标准的时区</li><li><code>ZoneOffset.ofHours</code> 通过offset来初始化具有指定的时间差的时区</li></ul></li><li><p>LocalDateTime</p><ul><li>不带有时区属性，是本地时区的日期时间</li></ul></li><li><p>ZonedDateTime </p><ul><li>= LocalDateTime + ZoneId </li></ul></li><li><p>DateTimeFormatter</p><ul><li>可以通过withZone方法直接设置需要使用的时区</li></ul></li><li><p>因此对于国际化时间的处理，应当使用Java8的日期时间类，通过ZonedDateTime来保存时间</p></li></ul><h1 id="日期时间格式化和解析"><a href="#日期时间格式化和解析" class="headerlink" title="日期时间格式化和解析"></a>日期时间格式化和解析</h1><ul><li>SimpleDateFormat的问题<ul><li>注意使用SimpleDateFormat的时候，大写的YYYY表示的是week year，即所在的周属于哪一年，yyyy表示的是年</li><li>static 的SimpleDateFormat可能会出现线程安全的问题，其解析和格式化操作是非线程安全的</li><li>SimpleDateFormat对于格式不匹配表现的非常宽容，可能会隐藏一些错误，要注意格式上的不同</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java文件读写Tips</title>
      <link href="/Java%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99Tips/"/>
      <url>/Java%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99Tips/</url>
      
        <content type="html"><![CDATA[<h1 id="1-字符编码问题"><a href="#1-字符编码问题" class="headerlink" title="1. 字符编码问题"></a>1. 字符编码问题</h1><p>FileReader是以当前机器的默认字符集来读取文件的，如果希望指定字符集的话，需要直接使用InputStreamReader和FileInputStream </p><p>因此对于字符编码问题，我们应当使用FileInputStream来读取文件流，然后使用InputStreamReader读取字符流，并且制定字符集</p><h1 id="2-Files类的静态方法"><a href="#2-Files类的静态方法" class="headerlink" title="2. Files类的静态方法"></a>2. Files类的静态方法</h1><ul><li><p><code>Files.readAllLines</code> </p><ul><li>可以很方便的一行代码完成文件内容的读取</li><li>但是读取超出内存大小的大文件的时候会出现OOM<ul><li>是因为readAllLines读取文件所有内容之后会放到一个List<String>当中返回，如果内存无法容纳这个List，就会OOM </li></ul></li></ul></li><li><p><code>Files.lines</code></p><ul><li>返回的是Stream<String></li><li>使得我们在需要的时候可以不断读取，使用文件中的内容，而不是一次性的把所有内容都读取到内存当中，因此避免了OOM</li></ul></li><li><p>对于返回是Stream的方法要注意关闭句柄，可以通过使用try with resources 的方式来确保流的close方法可以调用释放资源</p></li></ul><pre><code>LongAdder longAdder = new LongAdder();IntStream.rangeClosed(1, 1000000).forEach(i -&gt; {    try (Stream&lt;String&gt; lines = Files.lines(Paths.get(&quot;demo.txt&quot;))) {        lines.forEach(line -&gt; longAdder.increment());    } catch (IOException e) {        e.printStackTrace();    }});log.info(&quot;total : {}&quot;, longAdder.longValue());</code></pre><h1 id="3-读写文件的缓冲区设置"><a href="#3-读写文件的缓冲区设置" class="headerlink" title="3. 读写文件的缓冲区设置"></a>3. 读写文件的缓冲区设置</h1><h2 id="3-1-为什么执行缓慢？"><a href="#3-1-为什么执行缓慢？" class="headerlink" title="3.1 为什么执行缓慢？"></a>3.1 为什么执行缓慢？</h2><pre><code>private static void perByteOperation() throws IOException {    try (FileInputStream fileInputStream = new FileInputStream(&quot;src.txt&quot;);         FileOutputStream fileOutputStream = new FileOutputStream(&quot;dest.txt&quot;)) {        int i;        while ((i = fileInputStream.read()) != -1) {            fileOutputStream.write(i);        }    }}</code></pre><ul><li>上述代码运行起来功能上完全没有问题<ul><li>但是会非常缓慢</li><li>原因是每读取一个字节，每写入一个字节就进行一次IO操作，代价太大了</li><li>解决方案是可以使用缓冲区作为过渡，一次性从原文件当中读取一定数量的数据到缓冲区当中，一次性写入一定数量的数据到目标文件</li></ul></li></ul><pre><code>private static void bufferOperationWith100Buffer() throws IOException {    try (FileInputStream fileInputStream = new FileInputStream(&quot;src.txt&quot;);         FileOutputStream fileOutputStream = new FileOutputStream(&quot;dest.txt&quot;)) {        byte[] buffer = new byte[100];        int len = 0;        while ((len = fileInputStream.read(buffer)) != -1) {            fileOutputStream.write(buffer, 0, len);        }    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前端请求的timeout设置</title>
      <link href="/%E5%89%8D%E7%AB%AF%E8%AF%B7%E6%B1%82%E7%9A%84timeout%E8%AE%BE%E7%BD%AE/"/>
      <url>/%E5%89%8D%E7%AB%AF%E8%AF%B7%E6%B1%82%E7%9A%84timeout%E8%AE%BE%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<p>当我们发出一个网络请求，但是没有做超时设置，一个隐含的假设是我们认为这个请求一定会成功。然而，我们无法做出请求一定会成功的保证的。</p><ul><li>当你发出的同步请求从没有返回的时候，线程会一直被占用的</li><li>异步请求未返回的线程也无法继续复用，因为sockets会有泄露，socket池的容量是有限的，未返回结果的线程会一直开着连接，最终可能会导致连接的短缺</li></ul><p>因此best practice应当是对于ajax请求，做好timeout的设置，因为XMLHttpRequest的默认timeout是0，即没有超时设置。</p><p>Client端的timeout设置和server端一样重要，浏览器可以开的socket的数量也是有限的，我们应该通过设置timeout来充分利用socket pool。Fetch API是当前比较流行的XMLHttpRequest API的替代品，然而现在还没有一个直接的设置timeout的方法，最近刚刚推出了abort API，可以用来支持timeout。</p><p>用法比如： </p><pre><code>const controller = new AbortController();const signal = controller.signal;const fetchPromise = fetch(url, {signal});  // No timeout by default!setTimeout(() =&gt; controller.abort(), 10000); </code></pre><p>而对于Jquery的ajax call，我们可以使用： </p><pre><code>$.ajax({    url: &quot;test.html&quot;,    error: function(){        // will fire when timeout is reached    },    success: function(){        //do something    },    timeout: 3000 // sets timeout to 3 seconds});</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://robertovitillo.com/default-timeouts/" target="_blank" rel="noopener">https://robertovitillo.com/default-timeouts/</a> </p>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java日志记录Tips</title>
      <link href="/Java%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95Tips/"/>
      <url>/Java%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95Tips/</url>
      
        <content type="html"><![CDATA[<p>使用Java来记录日志有几个需要注意的地方的</p><ul><li>首先日志框架很多，不同的类库有可能会使用不同的日志框架，如何兼容是一个问题</li><li>配置文件的复杂性</li></ul><p>Java体系的日志框架有：</p><ul><li>Logback</li><li>Log4j</li><li>Log4j2</li><li>commons-logging </li><li>JDK 自带的Java.util.logging</li></ul><p>如果不同的包使用不同的日志框架的话，那管理就会变得非常麻烦。为了解决这个问题，就有了SLF4J – Simple Logging Facade For Java </p><ul><li>提供了统一的日志门面API，实现了中立的日志记录API</li><li>桥接功能<ul><li>可以将各种日志框架的API桥接到SLF4J API上。这样一来，即便你的程序试用了各种日志API记录日志，最终都可以桥接到Slf4j门面API上</li></ul></li><li>适配功能<ul><li>实现slf4j和实际日志框架的绑定</li><li>slf4j知识日志标准，还是需要一个实际的日志框架</li></ul></li></ul><p>下面一起梳理下常见的日志记录中的错误</p><h1 id="1-理解Logback配置，避免重复记录"><a href="#1-理解Logback配置，避免重复记录" class="headerlink" title="1. 理解Logback配置，避免重复记录"></a>1. 理解Logback配置，避免重复记录</h1><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;configuration&gt;    &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;        &lt;layout class=&quot;ch.qos.logback.classic.PatternLayout&quot;&gt;            &lt;pattern&gt;[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%thread] [%-5level] [%logger{40}:%line] - %msg%n&lt;/pattern&gt;        &lt;/layout&gt;    &lt;/appender&gt;    &lt;logger name=&quot;org.geekbang.time.commonmistakes.logging&quot; level=&quot;DEBUG&quot;&gt;        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;    &lt;/logger&gt;    &lt;root level=&quot;INFO&quot;&gt;        &lt;appender-ref ref=&quot;CONSOLE&quot;/&gt;    &lt;/root&gt;&lt;/configuration&gt;</code></pre><p>要注意在使用appender的时候，appender是如何挂载的，上述代码将appender挂载在了两个不同的地方，而且两个都定义在了root下，所以会造成重复。 </p><p>对于需要将不同的日志放到不同的文件的应用场景，可以通过设置Logger的additivity属性来实现这个操作</p><pre><code> &lt;logger name=&quot;org.geekbang.time.commonmistakes.logging&quot; level=&quot;DEBUG&quot; additivity=&quot;false&quot;&gt;            &lt;appender-ref ref=&quot;FILE&quot;/&gt;     &lt;/logger&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>《网易一千零一夜》读书笔记</title>
      <link href="/%E3%80%8A%E7%BD%91%E6%98%93%E4%B8%80%E5%8D%83%E9%9B%B6%E4%B8%80%E5%A4%9C%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/%E3%80%8A%E7%BD%91%E6%98%93%E4%B8%80%E5%8D%83%E9%9B%B6%E4%B8%80%E5%A4%9C%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="0-为什么开始看这本书？"><a href="#0-为什么开始看这本书？" class="headerlink" title="0. 为什么开始看这本书？"></a>0. 为什么开始看这本书？</h1><p>接到了让人兴奋的项目，小振奋，然后突然意识到项目的复杂程度，需要涉及的方方面面可能已经超过了我能够处理的能力范畴，所以需要补课了…</p><p>看了很多知乎的答案啊，看着看着意识到当自己在努力寻找沉淀下来的经过思考的单领域的内容的时候，从知乎或者其他快节奏的平台找倒是真的有点舍本逐末哎。项目管理还是有很多核心理念是可以也已经沉淀下来的，所以就开始了找书看，对照着自己现在的境况，一点点解决的状态。</p><p>另外踩的一个小坑是太追求优质的工具，即疯狂比较各种管理记录的软件，比较omniplan vs xxx vs blablabla, 瞎倒腾了好一顿才意识到对于一个不懂项目管理的我来说，倒腾哪个都是白瞎。一定会按照完全不是软件本身设定的方式，来使用它，应该说是完全解决不了问题。</p><p>所以还是踏踏实实的带着敬畏感的从一本不太学术的书开始，从互联网公司 – 网易的产品经理的视角，来看看怎么做项目管理，怎么跟进项目的进程，如何应对各种过程中的设计变化，如何做各种取舍。</p><h1 id="1-项目管理Overview"><a href="#1-项目管理Overview" class="headerlink" title="1. 项目管理Overview"></a>1. 项目管理Overview</h1><h2 id="1-1-High-Level的建议"><a href="#1-1-High-Level的建议" class="headerlink" title="1.1 High Level的建议"></a>1.1 High Level的建议</h2><ul><li><p>项目到底需要什么</p><ul><li>接手一个项目之前，应当与项目的重要干系人加强沟通，理解前因后果<ul><li>对于技术项目，理解整个大致技术实现的思路，其中的痛点难点，潜在的不确定因素<ul><li>比如跨组的合作</li></ul></li></ul></li><li>而后，理解项目到底需要什么<ul><li>时间成本质量要素的权衡与取舍<ul><li>范围</li><li>时间</li><li>成本和质量</li></ul></li><li>各个角色目前的痛点</li></ul></li><li>大家对项目管理的认知和接受度<ul><li>通过怎样的途径，是全面推进，还是步步改善？ </li><li>从哪一个角度切入？ </li><li>蓝图是否清晰？</li><li>是否与项目负责人沟通到位并且达成一致？ </li></ul></li></ul></li><li><p>不要凡事事必躬亲</p><ul><li>替别人待办他们本该做的事情，对于团队来说反而效率最低</li><li>需要努力让别人能够做好这件事情<ul><li>Awareness<ul><li>使得团队成员知道需要做什么 </li></ul></li><li>Desire<ul><li>需要给予某方面的动能<ul><li>技术挑战程度？</li><li>项目完成以后的影响力？ </li><li>升职加薪？ </li></ul></li></ul></li><li>Ability <ul><li>确保其有足够的能力来做好这件事情<ul><li>初期的辅助</li><li>必要的培训等</li></ul></li></ul></li></ul></li></ul></li></ul><ul><li><p>不要追在别人屁股后面做监工</p><ul><li>项目经历不是监督事情做得怎么样的人</li><li>他是应该和大家一起将整个事情环节捋顺的人，需要建议<u><strong>一套对应的流程规则</strong></u>，明确各个角色在过程中的职责</li><li>获得认同，使得这个机制自行运转起来</li><li>努力做到是<strong>规则在约束大家的行为</strong>，而不是靠人看着来做</li></ul></li><li><p>言必信，行必果</p><ul><li><p>无权力下的领导力 – leadership without authority </p><ul><li>在弱矩阵结构下项目经历必修课</li></ul></li><li><p>需要构建起团队对你的信任，建立自己的可信度，打造个人品牌</p></li><li><p>信任的获取需要一点一滴的积累了</p></li><li><p>专业度上</p><ul><li>确定自己足够专业</li><li>至少相对更专业</li></ul></li><li><p>跟进</p><ul><li>会议，发布，邮件，承诺</li></ul></li></ul></li><li><p>处理争端</p><ul><li>与人一起解决问题，会因为不同的对于事情的看法产生很多争论</li><li>需要找出一致的地方并且努力放大</li></ul></li></ul><h2 id="1-2-关于时间估算"><a href="#1-2-关于时间估算" class="headerlink" title="1.2 关于时间估算"></a>1.2 关于时间估算</h2><ul><li><p>有没有必要进行时间估算以及进行到什么程度的时间估算？</p><ul><li><p>现状</p><ul><li>用了很多时间，但是最终的实际使用时间往往和估算的有不小的偏差</li></ul></li><li><p>房子从凌乱到整洁需要20%的努力，从整洁到一尘不染可能需要80%</p><ul><li>有估算实际上是完成了相对性价比比较高的一段</li></ul></li><li><p>估算可以给一个相对合理的计划，使得用户，管理层和团队都有一个稳定的预期</p></li></ul></li></ul><ul><li><p>估算单位</p><ul><li><p>理想人日</p><ul><li>指成员在不受干扰的情况下，全部时间用来开发需求所需的天数</li><li>劣势<ul><li>人的不同会导致整个估算的不同</li><li>这样的差异会导致我们队任务规模认识的偏差，很难衡量项目的实际大小</li></ul></li></ul></li><li><p>理想人时</p><ul><li>对应理想人日而存在</li><li>在充分理解需求的情况下，能帮助团队做到更靠近真实值的估算</li></ul></li><li><p>故事点</p><ul><li><p>对任务规模的估计，是一种相对的概念</p></li><li><p>优势</p><ul><li>基于故事点的估算不会因为开发人员的变更，时间的推移而改变</li></ul></li><li><p>劣势</p><ul><li>难以找到合适的估算单位</li></ul></li></ul></li></ul></li><li><p>估算的方式</p><ul><li><p>自下而上的估算</p><ul><li><p>每个开发人员估算自己的任务时间，然后将所有的任务汇总</p></li><li><p>团队特征</p><ul><li>成员间业务独立性强</li><li>相互之间业务熟悉度不高，熟悉成本高</li><li>各成员相对经验比较丰富</li></ul></li><li><p>优势</p><ul><li>估算效率高</li><li>准确度也会比较高</li></ul></li></ul></li><li><p>专家判断</p><ul><li>专家根据响应开发的情况给出任务的估算值</li></ul></li><li><p>扑克估算</p><ul><li><p>流程</p><ul><li>每个估计者都会分到一叠扑克牌，每张上有一个数值</li><li>由负责人对某个需求进行估算的需求或者任务进行讲解</li><li>讲解后，所有人都可以向该负责人提问关于该条需求或者任务的问题，直至足够了解</li><li>然后所有成员挑选一张扑克牌代表自己对该条目的估算</li><li>如果差值比较大，就需要人员说明各自给出这个估值的理由，然后再进行下一轮的估算</li><li>最后取平均值</li></ul></li><li><p>优势</p><ul><li>多成员一件，更客观</li><li>估算过程中，强化了大家对于需求和任务的理解，将任务考虑得更加细致，降低了不确定性给计划带来的冲击</li><li>使得相对严肃的计划和估算变得更加有趣，但是会花费更多的时间成本</li><li>需求探索的会更加深入，估算也会更加全面细致</li><li>让潜在的冲突公开化，台面化，让大家去充分碰撞，然后用一种近似游戏化的方式再去化解掉</li></ul></li></ul></li></ul></li><li><p>估算的注意事项</p><ul><li>估算仅仅是预测，当对外承诺项目完成时间的时候，最好提供一个日期范围，让听者知道你的估算只是预测</li><li>将任务分成更细的粒度是会有利于估算的</li><li>团队需要练习估算方式并且收集反馈，有迭代，有过去的数据，就可以做分析，来进行优化</li><li>估算需要进行反复进行，当项目进行一半，发现估算过于乐观的话，就需要对剩下的工作进行重新估算</li></ul></li><li><p>估算与Scrum</p><ul><li>在Scrum项目当中，我们会以迭代Sprint为周期来做增量交付</li><li>和传统的项目不一样的是在每个迭代计划当中我们不需要确定日期，只需要估算一个迭代我们能完成多少工作</li></ul></li></ul><h2 id="1-3-进度计划"><a href="#1-3-进度计划" class="headerlink" title="1.3 进度计划"></a>1.3 进度计划</h2><ul><li><p>制定计划的重要性</p><ul><li>计划的本质是团队对何时完成任务的承诺</li><li>排斥做计划的原因，在于人们不愿轻易做出承诺。人们都会有一种言行一致的愿望，一旦做出承诺，来自内心和外部的压力会迫使我们按照承诺去做。</li></ul></li><li><p>制定计划的时间点</p><ul><li>应该尽量早的制定出计划<ul><li>因为在混沌不清的时候，需要某种方式来做锚定，相当于挖个坑，根据少量的信息给出期望值，然后让人们一点点来填满它</li><li>当有了坑以后，就让大家一起来填</li></ul></li></ul></li><li><p>调整计划的注意事项</p><ul><li>计划是调整的基础和依据，但是调整计划需要注意：<ul><li>确保项目的每一个人都知道当前的计划是什么</li><li>调整计划需要怎样的决策过程</li><li>需要谁参与决策</li></ul></li></ul></li><li><p>如何做好计划</p><ul><li><p>项目立项前</p><ul><li>将目标按照功能体系分割成几个重大的里程碑</li><li>这个时候注意要给出立项的时间表 – 能够使得各个资源方有明确的预期，以便提前做好资源的调配<ul><li>什么时候完成初期调研和评估</li><li>何时做好立项准备</li><li>何时启动项目</li></ul></li></ul></li><li><p>项目立项后</p><ul><li>根据启动过程当中对于里程碑的大致预期，进一步推导出<ul><li>需求确认</li><li>设计确认</li><li>功能完成</li></ul></li></ul></li><li><p>需求确认后</p><ul><li>由设计，开发，测试一起做WBS，将工作细化分解<ul><li>注意的几个节点<ul><li>设计确认</li><li>功能完成</li><li>no bug</li><li>发布前的代码冻结</li></ul></li></ul></li></ul></li><li><p>完成标准</p><ul><li><p>需求设计确认</p><ul><li>团队要准备好怎么编写，在哪里编写代码</li></ul></li><li><p>功能完成</p><ul><li>所有定义的功能都已经完成，已经通过测试，允许质量差距和少量的Bug存在</li></ul></li><li><p>里程碑完成</p><ul><li>质量已达到适当水平，可以上线发布，或者开始下一个里程碑</li></ul></li></ul></li><li><p>Tips</p><ul><li>计划本质上是一种承诺，因此应该让团队共同参与制定出来</li><li>想让承诺有效，必须要是当事人积极公开且经过一番努力后自由选择得来的  </li></ul></li></ul></li></ul><h2 id="1-4-每日站会"><a href="#1-4-每日站会" class="headerlink" title="1.4 每日站会"></a>1.4 每日站会</h2><ul><li>定位在沟通交流<ul><li>不是汇报会</li><li>是用来分享信息，做出承诺以及提出路障的，解决的是团队协同的问题</li><li>需要让人参与进来<ul><li>红黄绿三牌的方式<ul><li>黄牌 – 进行相关提问，向发言者了解协同和依赖的信息</li><li>红牌 – 用来打断谈话，避免过度的讨论和无结果的时间浪费，提高站会效率</li><li>绿牌 – 代表每个人的发言权，将牌归还给主持人则意味着站会结束</li></ul></li></ul></li></ul></li></ul><h2 id="1-5-周会周报"><a href="#1-5-周会周报" class="headerlink" title="1.5 周会周报"></a>1.5 周会周报</h2><ul><li><p>周会的目的</p><ul><li>不仅仅是同步状态，汇总团队信息，这些是邮件，文件共享就可以实现的</li><li>目的在于<ul><li>面对面感受项目当前的整体状态，重要问题，接下去的目标，以及所需的调整</li><li>借此对项目当前重要的问题有一致的认识，进行小幅度的讨论，并形成下一步的工作事项 </li></ul></li></ul></li><li><p>Tips</p><ul><li><p>控制规模和时间</p><ul><li>最多10 - 15</li><li>1.5h maximum </li></ul></li><li><p>要不要轮流汇报？</p><ul><li>大部分项目整体情况可以通过项目经历事先收集来直接做整体概述</li><li>对于部分方向性或者商务性的小组，可以简单汇报主要工作和主要问题</li></ul></li><li><p>什么适合在周会中讨论？</p><ul><li>急事不适合</li><li>非跨团队的问题不适合周会讨论</li><li>纯执行细节问题不适合周会讨论</li><li>大方向决策问题不适合</li><li>可以讨论跨团队的涉及整体性计划的问题</li><li>中期改进型问题</li></ul></li><li><p>说话比例</p><ul><li>三分<ul><li>会议主持人，更新整体状态，主持讨论</li><li>需要回报的与会者的发言</li><li>所有与会者的讨论</li></ul></li></ul></li></ul></li><li><p>全体类周会</p></li><li><p>组长类周会</p></li><li><p>三方类 – 产品，运营，市场三方周会</p></li></ul><h2 id="1-6-工作汇报"><a href="#1-6-工作汇报" class="headerlink" title="1.6 工作汇报"></a>1.6 工作汇报</h2><ul><li><p>工作汇报的目的</p><ul><li><p>将状态，问题，风险知会相关干系人</p></li><li><p>寻求帮助</p><ul><li>需要在遇到问题的初期就积极主动寻求帮助，进而迅速的去解决</li></ul></li><li><p>自我审视</p><ul><li>周报是一种自我审视的过程，看看自己制定的目标和项目的完成情况</li></ul></li></ul></li><li><p>个人周报</p><ul><li><p>内容</p><ul><li><p>本周工作完成程度</p><ul><li>做了什么</li><li>完成结果如何</li></ul></li><li><p>下周工作计划</p><ul><li>需要做什么</li><li>时间点</li><li>完成的定义</li></ul></li><li><p>工作中遇到的问题和建议</p></li><li><p>个人感言和建议</p><ul><li>工作中的总结和分享，让上司知道你在想什么</li></ul></li></ul></li></ul></li></ul><ul><li>团队工作周报<ul><li>团队周报更多聚焦在结果和计划上，而非个人微观层面的事件总结</li><li>计划的时间跨度根据团队规模大小不同可以从1个月到3个月不等</li><li>内容<ul><li>上周达成的结果<ul><li>量化的结果指标<ul><li>销售额</li><li>用户数等</li></ul></li></ul></li><li>未来一段时间的规划<ul><li>通过图形化的方式言简意赅地列出任务的时间点和期望达到的结果</li></ul></li><li>达成如上规划图的风险/ 需要的协助<ul><li>资源风险</li><li>合作方风险</li><li>建议的应对方案</li></ul></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 项目管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《你早该这么玩Excel》</title>
      <link href="/%E3%80%8A%E4%BD%A0%E6%97%A9%E8%AF%A5%E8%BF%99%E4%B9%88%E7%8E%A9Excel%E3%80%8B/"/>
      <url>/%E3%80%8A%E4%BD%A0%E6%97%A9%E8%AF%A5%E8%BF%99%E4%B9%88%E7%8E%A9Excel%E3%80%8B/</url>
      
        <content type="html"><![CDATA[<p>一次对Excel的了解和正视之旅。相较于编程实现与通过Excel进行数据分析，编程在Scalability上胜出的，但是对于操作的便捷性，以及验证假设的速度上，确确实实Excel要胜出一筹。尤其是学到了三表的操作，VLookUp这种函数之后，开始理解Excel在数据分析上的巨大的作用。</p><ul><li><p>Highlights</p><ul><li>三表<ul><li>参数表</li><li>源数据表</li><li>分类汇总表</li></ul></li><li>巧用各种函数</li></ul></li><li><p>源数据表</p><ul><li>应当只有一张，对于每一个你想要研究的领域</li><li>应当为一维数据格式</li><li>标题内容不要写在表格当中，因为我们很可能需要索引的，<ul><li>可以对工作簿， 工作表进行命名来做区分</li></ul></li><li>源数据顺序<ul><li>应该按照工作当中的逻辑顺序来对列进行排序</li><li>列数据位置调整，shift + 拖动</li></ul></li><li>凡是同一种属性的数据都应该记录在同一列当中的</li><li>多个单元格批量录入<ul><li>选定多个单元格</li><li>在一个单元格当中输入内容</li><li>Ctrl + enter 输入一次的内容会被加载到你选中的所有单元格上</li></ul></li><li>源数据表当中不应该使用合并居中这种操作<ul><li>明细数据应当有一条记录一条</li><li>所有单元格应该被填满</li><li>每一行数据必须完整且整齐</li><li>合并单元格会导致只有首个单元格有数据，其他的都是空白单元格</li></ul></li><li>元数据只保留在一张表当中，放在多张表当中的话合并会非常非常麻烦</li><li>源数据表是为了商业上的use case服务的，需要理清楚需要什么数据<ul><li>按照逻辑顺序来分清各个column</li><li>在这之后可以按照可能的手动输入，复制粘贴来做cluster</li></ul></li></ul></li><li><p>三张表的定义</p><ul><li>参数表<ul><li>系统的配置参数，供源数据表和分类汇总表来调用</li><li>表示数据匹配关系或者某属性明细不会经常变更的数据</li></ul></li><li>源数据表<ul><li>数据的录入</li><li>一切与数据录入相关的工作都应该在源数据表当中进行</li><li>应满足一下条件<ul><li>一维数据</li><li>一个标题行</li><li>字段分类清晰</li><li>数据属性完整</li><li>数据连续</li><li>无合并单元格</li><li>无合计行</li><li>无分隔行/ 列</li><li>无空白单元格</li><li>单元格内容禁用短语句子</li></ul></li><li>分类汇总表<ul><li>希望是通过函数关联等从数据表当中获取一切所需的数据</li></ul></li><li>Thoughts <ul><li>企业信息化是必须的，需要有ERP, CRM, WMS, OA等企业系统</li><li>但是对于信息的个性化处理上来说，Excel会更占上风，可以更快速的给出各类数据</li></ul></li></ul></li></ul></li><li><p>数据透视表</p><ul><li>在源数据表当中选中想要做分析的数据，然后来生成Pivot table</li><li>步骤<ul><li>确认数据来源和待创建的报表类型</li><li>确认选定的数据区域</li><li>标题行需要被包含在内</li></ul></li><li>Tips<ul><li>分类多的字段尽量作为航字段</li></ul></li></ul></li><li><p>录入安全</p><ul><li>设置有关于数据有效性的限制，比如规定必须输入某种日期格式</li><li>对于包含公式的部分，可以直接进行锁定，这样其他人就无法对其进行修改了</li><li>手工录入，复制粘贴，公式链接的数据区域要用不同的填充色区分，来告知使用者什么地方需要填写，什么地方需要复制粘贴</li></ul></li><li><p>Vlookup</p><ul><li>查找引用函数<ul><li>查找某单元格数据在源数据库中是否存在，如果存在，就返回源数据库中同行指定列的单元格内容</li></ul></li><li>四个参数<ul><li>用什么找</li><li>在哪个表找</li><li>找到了返回什么值</li><li>精确找还是模糊找</li></ul></li></ul></li><li><p>图表</p><ul><li>做图表的目的是为了能够更加准确直观的诠释数据</li><li>饼状图<ul><li>说明比例关系</li></ul></li><li>柱状图<ul><li>比较数值</li></ul></li><li>折线图<ul><li>关注趋势</li></ul></li><li>概念图<ul><li>左右对比，适合男女</li><li>生成图标的源数据当中制造负数，来生成这种向两边延伸的效</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Excel </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 集合处理/ 空值处理/ 异常处理</title>
      <link href="/Java-%E9%9B%86%E5%90%88%E5%A4%84%E7%90%86-%E5%92%8C-%E7%A9%BA%E5%80%BC%E5%A4%84%E7%90%86/"/>
      <url>/Java-%E9%9B%86%E5%90%88%E5%A4%84%E7%90%86-%E5%92%8C-%E7%A9%BA%E5%80%BC%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Arrays-asList"><a href="#1-Arrays-asList" class="headerlink" title="1. Arrays.asList"></a>1. <code>Arrays.asList</code></h1><p>业务开发当中，我们常常会将原始的数组转换为List类数据结构，来继续展开各种Stream操作</p><ul><li><p>Arrays.asList无法转换基本类型的数组，可以使用Arrays.stream来进行转换</p></li><li><p>Arrays.asList返回的list是不支持增删操作的，其返回的List是Arrays的内部类ArrayList。内部继承自AbstractList，没有覆写父类的add方法</p></li><li><p>对原始数组的修改会影响到我们获得的那个List</p><ul><li>ArrayList实际上是使用了原始的数组，因此在使用的时候，最好再使用New ArrayList来实现解耦</li></ul></li></ul><h1 id="2-空值处理"><a href="#2-空值处理" class="headerlink" title="2. 空值处理"></a>2. 空值处理</h1><h2 id="2-1-NullPointerException"><a href="#2-1-NullPointerException" class="headerlink" title="2.1 NullPointerException"></a>2.1 NullPointerException</h2><ul><li>可能出现的场景<ul><li>参数值是Integer等包装类型，使用时因为自动拆箱出现了空指针异常</li><li>字符串比较</li><li>ConcurrentHashMap这种容器不支持Key和Value为null，强行put null的key或Value会出现空指针异常</li><li>方法或远程服务返回的list是null，没做判空就直接调用，出现空指针异常</li><li>联级调用的null check</li></ul></li></ul><ul><li>best practice<ul><li><code>string.equalsTo(variableName)</code></li><li><code>Optional.ofNullable()</code></li><li><code>orElse()</code></li></ul></li></ul><h1 id="3-异常处理"><a href="#3-异常处理" class="headerlink" title="3. 异常处理"></a>3. 异常处理</h1><h2 id="3-1-在业务代码层面考虑异常处理"><a href="#3-1-在业务代码层面考虑异常处理" class="headerlink" title="3.1 在业务代码层面考虑异常处理"></a>3.1 在业务代码层面考虑异常处理</h2><ul><li><p>大多数业务应用都采用三层架构</p><ul><li><p>Controller层</p><ul><li>负责信息收集，参数校验，转换服务层处理的数据适配前端，轻业务逻辑</li><li>Controller 捕获异常，然后需要给用户友好用户的提示</li></ul></li><li><p>Service层</p><ul><li>负责核心业务逻辑，包括外部服务调用，访问数据库，缓存处理，消息处理等</li><li>一般会涉及到数据库事务，出现异常不适合捕获，否则事务无法自动回滚</li></ul></li><li><p>Repository层</p><ul><li>负责数据访问实现，一般没有业务逻辑</li><li>根据情况来做忽略，降级，或者转化为一个友好的异常</li></ul></li></ul></li><li><p>框架层面的异常处理</p><ul><li>尽量不要在框架层面做异常的自动，统一的处理</li><li>框架应当来做兜底工作，如果异常上升到最上层逻辑还是无法处理的话，可以用统一的方式进行异常转换<ul><li><code>@RestControllerAdvice</code></li><li><code>@ExceptionHandler</code></li></ul></li></ul></li></ul><h2 id="3-2-不要直接生吞异常"><a href="#3-2-不要直接生吞异常" class="headerlink" title="3.2 不要直接生吞异常"></a>3.2 不要直接生吞异常</h2><p>捕获了异常以后不应该生吞，因为吞掉的异常如果没有正常处理的话，出现Bug会很难发现。</p><p>需要有合适的转化成用户友好的异常，或者至少在warn， error级别来做log</p><h2 id="3-3-保留原始的信息"><a href="#3-3-保留原始的信息" class="headerlink" title="3.3 保留原始的信息"></a>3.3 保留原始的信息</h2><p>在捕捉了异常之后，一定要记得在log 或者在向外扔出的异常之中记录原始异常信息</p><pre><code>catch (IOException e) {    //只保留了异常消息，栈没有记录    log.error(&quot;文件读取错误, {}&quot;, e.getMessage());    throw new RuntimeException(&quot;系统忙请稍后再试&quot;);}catch (IOException e) {    throw new RuntimeException(&quot;系统忙请稍后再试&quot;, e);}</code></pre><h2 id="3-4-小心finally中的异常-try-with-resources"><a href="#3-4-小心finally中的异常-try-with-resources" class="headerlink" title="3.4 小心finally中的异常 + try with resources"></a>3.4 小心finally中的异常 + try with resources</h2><p>注意在资源释放处理等收尾操作的时候也可能会出现异常，这种时候，如果try block逻辑和finnally逻辑都有异常抛出的话，try当中的异常会被finnally中的异常覆盖掉，这会让问题变得非常不明显</p><pre><code>@GetMapping(&quot;wrong&quot;)public void wrong() {    try {        log.info(&quot;try&quot;);        //异常丢失        throw new RuntimeException(&quot;try&quot;);    } finally {        log.info(&quot;finally&quot;);        throw new RuntimeException(&quot;finally&quot;);    }}</code></pre><p>对于实现了AutoCloseable接口的资源，可以使用try-with-resources来释放资源，就是在try中带资源的声明</p><ul><li>try catch finally vs try with resources </li></ul><pre><code>Scanner scanner = null;try {    scanner = new Scanner(new File(&quot;test.txt&quot;));    while (scanner.hasNext()) {        System.out.println(scanner.nextLine());    }} catch (FileNotFoundException e) {    e.printStackTrace();} finally {    if (scanner != null) {        scanner.close();    }}try (Scanner scanner = new Scanner(new File(&quot;test.txt&quot;))) {    while (scanner.hasNext()) {        System.out.println(scanner.nextLine());    }} catch (FileNotFoundException fnfe) {    fnfe.printStackTrace();}</code></pre><h2 id="3-5-线程池任务的异常处理"><a href="#3-5-线程池任务的异常处理" class="headerlink" title="3.5 线程池任务的异常处理"></a>3.5 线程池任务的异常处理</h2><ul><li>设置自定义的异常处理程序作为保底，比如在声明线程池时自定义线程池的未捕获异常处理程序</li></ul><pre><code>new ThreadFactoryBuilder()  .setNameFormat(prefix+&quot;%d&quot;)  .setUncaughtExceptionHandler((thread, throwable)-&gt; log.error(&quot;ThreadPool {} got exception&quot;, thread, throwable))  .get()</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.baeldung.com/java-try-with-resources" target="_blank" rel="noopener">https://www.baeldung.com/java-try-with-resources</a> </li><li><a href="https://time.geekbang.org/column/article/220230" target="_blank" rel="noopener">https://time.geekbang.org/column/article/220230</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java数值计算精度问题</title>
      <link href="/Java%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98/"/>
      <url>/Java%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97%E7%B2%BE%E5%BA%A6%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Double"><a href="#1-Double" class="headerlink" title="1. Double"></a>1. Double</h1><pre><code>System.out.println(0.1+0.2);System.out.println(1.0-0.8);System.out.println(4.015*100);System.out.println(123.3/100);double amount1 = 2.15;double amount2 = 1.10;if (amount1 - amount2 == 1.05)    System.out.println(&quot;OK&quot;);// Output 0.300000000000000040.19999999999999996401.499999999999941.2329999999999999</code></pre><p>上述问题出现的原因是因为计算机是以二进制存储数值的，浮点数也是如此。 Java采用的是IEEE754标准来实现浮点数的表达和运算，当将一个10进制的数值转化成浮点数的时候，会出现无限循环的结果。当使用二进制表示是无限循环的时候，转换成10进制就会造成精度的缺失了。</p><h1 id="2-BigDecimal"><a href="#2-BigDecimal" class="headerlink" title="2. BigDecimal"></a>2. BigDecimal</h1><p>BigDecimal可以用于浮点数精确表达的场景，但是使用BigDecimal的时候，一定要注意使用字符串的构造方法来初始化</p><pre><code>System.out.println(new BigDecimal(&quot;0.1&quot;).add(new BigDecimal(&quot;0.2&quot;)));System.out.println(new BigDecimal(&quot;1.0&quot;).subtract(new BigDecimal(&quot;0.8&quot;)));System.out.println(new BigDecimal(&quot;4.015&quot;).multiply(new BigDecimal(&quot;100&quot;)));System.out.println(new BigDecimal(&quot;123.3&quot;).divide(new BigDecimal(&quot;100&quot;)));0.30.2401.5001.233</code></pre><ul><li><p>BigDecimal </p><ul><li>有scale, Precision的概念</li><li>scale 表示小数点右边的位数</li><li>precision 表示精度，即有效数字的长度</li></ul></li><li><p>BigDecimal的equals判等</p><ul><li>比较的是value和scale 两个值的！</li></ul></li></ul><pre><code>System.out.println(new BigDecimal(&quot;1.0&quot;).equals(new BigDecimal(&quot;1&quot;)))false</code></pre><pre><code>/** * Compares this {@code BigDecimal} with the specified * {@code Object} for equality.  Unlike {@link * #compareTo(BigDecimal) compareTo}, this method considers two * {@code BigDecimal} objects equal only if they are equal in * value and scale (thus 2.0 is not equal to 2.00 when compared by * this method). * * @param  x {@code Object} to which this {@code BigDecimal} is *         to be compared. * @return {@code true} if and only if the specified {@code Object} is a *         {@code BigDecimal} whose value and scale are equal to this *         {@code BigDecimal}&#39;s. * @see    #compareTo(java.math.BigDecimal) * @see    #hashCode */@Overridepublic boolean equals(Object x)</code></pre><h1 id="3-数值溢出问题"><a href="#3-数值溢出问题" class="headerlink" title="3. 数值溢出问题"></a>3. 数值溢出问题</h1><p>所有的基本数值类型都有超出表达范围的可能性，而且是没有任何异常的默默的溢出</p><ul><li>可以使用Math类的addExact, substractExact等方法进行数值运算，在溢出的时候主动抛出异常</li><li>也可以使用BigInteger，也会主动抛出异常</li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 判等问题</title>
      <link href="/Java-%E5%88%A4%E7%AD%89%E9%97%AE%E9%A2%98/"/>
      <url>/Java-%E5%88%A4%E7%AD%89%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-equals-vs"><a href="#1-equals-vs" class="headerlink" title="1. equals vs =="></a>1. equals vs <code>==</code></h1><ul><li>对于基本类型，应使用==，比较的是值 </li><li>对于引用类型，需要使用equals，进行内容判等。使用<code>==</code>判断的是指针 –&gt; 代表的是两个对象在内存中的地址</li></ul><p>这里要注意的是Java是有字符串常量池机制的，当代码中出现双引号形式创建字符串对象的时候，JVM会先对字符串进行检查，如果字符串常量池存在相同内容的字符串对象的引用，就将这个引用返回；否则就创建新的字符串对象，然后将这个引用放入字符串常量池当中，并返回该引用</p><p>另外一个小坑是Integer在[-128,127]之间的数值是会做缓存的，即对于这中间的数值，即便你直接用<code>==</code>进行判断，有可能是直接会过的…</p><pre><code>public static Integer valueOf(int i) {    if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)        return IntegerCache.cache[i + (-IntegerCache.low)];    return new Integer(i);}</code></pre><h2 id="1-1-equals方法的实现"><a href="#1-1-equals方法的实现" class="headerlink" title="1.1 equals方法的实现"></a>1.1 equals方法的实现</h2><ul><li>equals在Object类当中的定义比较的是对象的引用</li></ul><pre><code>public boolean equals(Object obj) {    return (this == obj);}</code></pre><ul><li>而Integer，String类都重写了这个方法</li></ul><pre><code>public boolean equals(Object anObject) {    if (this == anObject) {        return true;    }    if (anObject instanceof String) {        String anotherString = (String)anObject;        int n = value.length;        if (n == anotherString.value.length) {            char v1[] = value;            char v2[] = anotherString.value;            int i = 0;            while (n-- != 0) {                if (v1[i] != v2[i])                    return false;                i++;            }            return true;        }    }    return false;}</code></pre><p>上述代码是先比较了引用，如果引用的地址一致，那么久可以直接返回true了。如果不一致，那就首先判断类的类型，如果是String类，再进行长度判断，如果长度一致，就逐个比较字符</p><ul><li>实现一个equals方法，需要注意<ul><li>首先进行指针判断，如果对象相同直接返回true</li><li>需要对另一方进行判空，空对象和自身的比较结果一定是false</li><li>需要判断两个对象的类型，如果类型都不同，那么直接返回false</li><li>在确保类型相同的情况下进行类型的强制转换，然后逐一判断所有字段<ul><li>需要进行类型强制转换是因为我们override的equals方法默认的输入参数是Object</li></ul></li></ul></li></ul><h2 id="1-2-使用Lombok的小坑"><a href="#1-2-使用Lombok的小坑" class="headerlink" title="1.2 使用Lombok的小坑"></a>1.2 使用Lombok的小坑</h2><p>Lombok的@Data注解会帮助我们实现equals和hashcode方法，但是有继承关系的时候，Lombok自动生成的方法是不会考虑到父类的</p><ul><li><p>对于不想进行equals和hashCode判断的参数，可以使用：</p><ul><li><code>@EqualsAndHashCode.Exclude</code></li></ul></li><li><p>对于想要使用父类属性的场景，可以使用</p><ul><li><code>@EqualsAndHashCode(callSuper = true)</code></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring @Transactional 事务Tips</title>
      <link href="/Spring-Transactional-%E4%BA%8B%E5%8A%A1Tips/"/>
      <url>/Spring-Transactional-%E4%BA%8B%E5%8A%A1Tips/</url>
      
        <content type="html"><![CDATA[<p>Spring针对Transaction APi, JDBC, Hibernate, Java Persistence API等事务API，实现了一致的编程模型，而Spring的声明式事务功能提供了非常方便的事务配置方式，使用<code>@Transactional</code>注解，就可以一键开启方法的事务性配置。</p><p>但是不是加上标注就能实现事务的，还是需要去关注事务是否有效，出错以后事务是否会正确回滚，当业务代码设计到多个子业务逻辑的时候，怎么正确处理事务。</p><h1 id="1-事务生效问题"><a href="#1-事务生效问题" class="headerlink" title="1. 事务生效问题"></a>1. 事务生效问题</h1><pre><code>@Entity@Datapublic class UserEntity {    @Id    @GeneratedValue(strategy = AUTO)    private Long id;    private String name;    public UserEntity() { }    public UserEntity(String name) {        this.name = name;    }}@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity, Long&gt; {    List&lt;UserEntity&gt; findByName(String name);}@Service@Slf4jpublic class UserService {    @Autowired    private UserRepository userRepository;    //一个公共方法供Controller调用，内部调用事务性的私有方法    public int createUserWrong1(String name) {        try {            this.createUserPrivate(new UserEntity(name));        } catch (Exception ex) {            log.error(&quot;create user failed because {}&quot;, ex.getMessage());        }        return userRepository.findByName(name).size();    }    //标记了@Transactional的private方法    @Transactional    private void createUserPrivate(UserEntity entity) {        userRepository.save(entity);        if (entity.getName().contains(&quot;test&quot;))            throw new RuntimeException(&quot;invalid username!&quot;);    }    //根据用户名查询用户数    public int getUserCount(String name) {        return userRepository.findByName(name).size();    }}</code></pre><p>上述代码使用JPA做数据库访问，Entity定义在UserEntity当中，在服务层，声明了createUsr方法，当名字包含test的时候，希望抛出异常，然后实现数据库的回滚（只是例子，当然实际实现上将判断和数据库存储执行顺序换过来就能避开这里的问题了）</p><p>当调用的时候，发现即使用户名不合法，也能够调用成功，这是因为上述代码将注解定义到了private方法，因此不生效</p><blockquote><p>只有定义在public方法上的@Transactional才能生效，因为Spring默认通过动态代理的方式实现AOP，对目标方法进行增强，private方法无法代理到，Spring也就无法使用动态增强事务处理的逻辑了。</p></blockquote><p>然而就算把上述的private方法改为public transactional依旧不会生效，这是因为：</p><blockquote><p>Transactional需要通过代理过的类从外部调用目标方法才能生效</p></blockquote><p>Spring通过AOP技术对方法进行增强，要调用增强过的方法必然是调用代理之后的对象</p><p>因此我们可以在controller层调用这个逻辑，来实现整个transactional的支持。即你需要使用Spring注入的类，通过代理调用才有机会来进行动态的增强。</p><h1 id="2-事务回滚问题"><a href="#2-事务回滚问题" class="headerlink" title="2. 事务回滚问题"></a>2. 事务回滚问题</h1><p>通过AOP锁实现的事务处理可以理解为使用try catch来包裹标记了<code>@Transactional</code>注解的方法，当方法出现了异常并且满足一定条件的时候，在catch里面我们可以设置事务回滚，没有异常则直接提交事务。</p><ol><li>只有异常传播出标记了注解的方法，事务才能回滚</li></ol><pre><code>try {   // This is an around advice: Invoke the next interceptor in the chain.   // This will normally result in a target object being invoked.   retVal = invocation.proceedWithInvocation();}catch (Throwable ex) {   // target invocation exception   completeTransactionAfterThrowing(txInfo, ex);   throw ex;}finally {   cleanupTransactionInfo(txInfo);}</code></pre><ol start="2"><li>默认情况下，出现RuntimeException或者Error的时候，Spring才会回滚事务</li></ol><p>在必要的时候，可以选择手动进行回滚，以及遇到所有的Exception都回滚事务</p><pre><code>@Transactionalpublic void createUserRight1(String name) {    try {        userRepository.save(new UserEntity(name));        throw new RuntimeException(&quot;error&quot;);    } catch (Exception ex) {        log.error(&quot;create user failed&quot;, ex);        TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();    }}@Transactional(rollbackFor = Exception.class)public void createUserRight2(String name) throws IOException {    userRepository.save(new UserEntity(name));    otherTask();}</code></pre><ul><li>有时我们会遇到嵌套逻辑，分别需要实现事务的问题，而子逻辑事务的回滚不希望影响到父逻辑，可以使用<code>@Transactional(propagation = Propagation.REQUIRES_NEW)</code>, 以此来设置事务传播策略，即执行到这个方法的时候需要开启新的事务，并挂起当前事务。</li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP调用的超时，并发</title>
      <link href="/HTTP%E8%B0%83%E7%94%A8%E7%9A%84%E8%B6%85%E6%97%B6%EF%BC%8C%E5%B9%B6%E5%8F%91/"/>
      <url>/HTTP%E8%B0%83%E7%94%A8%E7%9A%84%E8%B6%85%E6%97%B6%EF%BC%8C%E5%B9%B6%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<p>HTTP调用的时候，是通过HTTP协议进行一次网络请求，网络请求会有超时的可能性，我们需要考虑到：</p><ul><li>使用的框架设置的默认超时的合理性</li><li>超时后的请求重试需要考虑到服务端接口的幂等性 – 即任意多次执行所产生的影响是否与一次执行的影响相同</li><li>需要考虑框架是否会限制并发连接数，以免在服务并发很大的情况下，HTTP调用的并发数限制成为瓶颈 </li></ul><p>常用框架： </p><ul><li>Spring Cloud <ul><li>需要使用Feign进行声明式的服务调用</li></ul></li><li>Spring Boot<ul><li>使用Apache HttpClient进行服务调用</li></ul></li></ul><h1 id="1-如何配置连接超时"><a href="#1-如何配置连接超时" class="headerlink" title="1. 如何配置连接超时"></a>1. 如何配置连接超时</h1><ul><li><p>HTTP调用应用层走的是HTTP协议，但是网络层还是TCP/IP协议的</p><ul><li><p>TCP/ IP协议是面向连接的协议，在传输数据之前需要建立连接</p></li><li><p>网络框架会提供两个超时参数</p><ul><li><p>连接超时参数 ConnectTimeout</p><ul><li>建立连接阶段的最长等待时间</li><li>应该配置在1 - 5s之间，因为TCP的三次握手建立连接需要的时间实际上是非常短的，超出往往是网络或者防火墙配置的问题</li></ul></li><li><p>读取超时参数 ReadTimeout</p><ul><li><p>用来控制从Socket上读取数据的最长等待时间</p></li><li><p>读取超时包括</p><ul><li>网络问题</li><li>服务端处理业务逻辑的时间</li></ul></li><li><p>参数配置不应过大</p><ul><li>HTTP请求一般是同步调用，如果超时很长，在等待服务端返回数据的同时，客户端线程也在等待</li><li>当下游服务出现大量超时的时候，程序可能也会受到拖累创建大量线程，最终崩溃</li></ul></li></ul></li></ul></li></ul></li></ul><ul><li>首先对于超时本身<ul><li>是客户端和服务端需要都有贡献的</li><li>有一致的时间估计</li><li>平衡吞吐量和错误率</li></ul></li></ul><h1 id="2-HTTP调用并发问题"><a href="#2-HTTP调用并发问题" class="headerlink" title="2. HTTP调用并发问题"></a>2. HTTP调用并发问题</h1><p>如果使用Apache 的httpClient，在PoolingHttpClientConnectionManager当中，定义的参数： </p><ul><li>defaultMaxPerRoute = 2<ul><li>同一个主机最大的并发请求书为2</li></ul></li><li>maxTotal = 20<ul><li>主机的最大并发为20</li></ul></li></ul><pre><code>httpClient2 = HttpClients.custom().setMaxConnPerRoute(10).setMaxConnTotal(20).build();</code></pre>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线程池创建: Executors  vs ThreadPoolExecutor</title>
      <link href="/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%9B%E5%BB%BA-Executors-vs-ThreadPoolExecutor/"/>
      <url>/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%88%9B%E5%BB%BA-Executors-vs-ThreadPoolExecutor/</url>
      
        <content type="html"><![CDATA[<p>工程上对于线程池的使用必不可少，很多人会选择使用Executors class定义的<code>newCachedThreadPool</code>以及<code>newFixedThreadPool</code>。这篇博文就稍微分析一下二者适用的场景，以及我们应该使用Executors的方法还是直接调用ThreadPoolExecutor来创建线程池。</p><p>首先让我们一起看看二者的源码</p><pre><code>   /**     * Creates a thread pool that reuses a fixed number of threads     * operating off a shared unbounded queue.  At any point, at most     * {@code nThreads} threads will be active processing tasks.     * If additional tasks are submitted when all threads are active,     * they will wait in the queue until a thread is available.     * If any thread terminates due to a failure during execution     * prior to shutdown, a new one will take its place if needed to     * execute subsequent tasks.  The threads in the pool will exist     * until it is explicitly {@link ExecutorService#shutdown shutdown}.     *     * @param nThreads the number of threads in the pool     * @return the newly created thread pool     * @throws IllegalArgumentException if {@code nThreads &lt;= 0}     */    public static ExecutorService newFixedThreadPool(int nThreads) {        return new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());    }    /**     * Creates a thread pool that creates new threads as needed, but     * will reuse previously constructed threads when they are     * available.  These pools will typically improve the performance     * of programs that execute many short-lived asynchronous tasks.     * Calls to {@code execute} will reuse previously constructed     * threads if available. If no existing thread is available, a new     * thread will be created and added to the pool. Threads that have     * not been used for sixty seconds are terminated and removed from     * the cache. Thus, a pool that remains idle for long enough will     * not consume any resources. Note that pools with similar     * properties but different details (for example, timeout parameters)     * may be created using {@link ThreadPoolExecutor} constructors.     *     * @return the newly created thread pool     */    public static ExecutorService newCachedThreadPool() {        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                      60L, TimeUnit.SECONDS,                                      new SynchronousQueue&lt;Runnable&gt;());    } </code></pre><p>二者对比，你会发现实际上他们都是调用的ThreadPoolExecutor,只是参数是不一样的。那让我们看看ThreadPoolExecutor的源码</p><pre><code>    /**     * Creates a new {@code ThreadPoolExecutor} with the given initial     * parameters and default thread factory and rejected execution handler.     * It may be more convenient to use one of the {@link Executors} factory     * methods instead of this general purpose constructor.     *     * @param corePoolSize the number of threads to keep in the pool, even     *        if they are idle, unless {@code allowCoreThreadTimeOut} is set     * @param maximumPoolSize the maximum number of threads to allow in the     *        pool     * @param keepAliveTime when the number of threads is greater than     *        the core, this is the maximum time that excess idle threads     *        will wait for new tasks before terminating.     * @param unit the time unit for the {@code keepAliveTime} argument     * @param workQueue the queue to use for holding tasks before they are     *        executed.  This queue will hold only the {@code Runnable}     *        tasks submitted by the {@code execute} method.     * @throws IllegalArgumentException if one of the following holds:&lt;br&gt;     *         {@code corePoolSize &lt; 0}&lt;br&gt;     *         {@code keepAliveTime &lt; 0}&lt;br&gt;     *         {@code maximumPoolSize &lt;= 0}&lt;br&gt;     *         {@code maximumPoolSize &lt; corePoolSize}     * @throws NullPointerException if {@code workQueue} is null     */    public ThreadPoolExecutor(int corePoolSize,                              int maximumPoolSize,                              long keepAliveTime,                              TimeUnit unit,                              BlockingQueue&lt;Runnable&gt; workQueue) {        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,             Executors.defaultThreadFactory(), defaultHandler);    }</code></pre><p>看一下其中需要的几个参数：</p><ul><li><p>corePoolSize</p><ul><li>在线程池中最少要保持的线程数量，哪怕已经超过了定义的keepAliveTime </li></ul></li><li><p>maximumPoolSize</p><ul><li>线程池允许的最大线程数量</li></ul></li><li><p>keepAliveTime</p><ul><li>当当前线程数超过核心线程数量的时候，就会检查闲置的线程，如果在这段时间没有新的任务，就暂停当前线程</li></ul></li><li><p>unit</p><ul><li>定义事件单位</li></ul></li><li><p>workQueue</p><ul><li>在任务还没有执行之前，被用来持有这些任务的</li><li>queue之后持有execute方法提交的Runnable任务</li></ul></li></ul><p>带着这些信息我们再来看Executors.newFixedThreadPool的定义，方法传入了线程数量，然后核心线程数和最大线程数被设为一样的数值，让我们来看看在不同情况下他的表现：</p><ul><li><p>任务数小于等于设定的线程数</p><ul><li>一切运行正常</li><li>限制的线程不会被关闭</li></ul></li><li><p>任务数大于设定的线程数</p><ul><li>任务会加入到队列当中，进行等待</li><li>值得注意的是在实例化LinkedBlockingQueue的时候，传入的参数是<code>this(Integer.MAX_VALUE);</code><ul><li>这意味着如果任务在线程中执行的时间非常长，任务可以在队列中堆积到无限大，最终结果会是内存被占满..程序崩溃</li></ul></li></ul></li></ul><p>而对于Executors.newCachedThreadPool来说，其定义的核心线程数量为0，最大线程数是<code>Integer.MAX_VALUE</code>,即理论上是可以有无限多的线程，keepAliveTime是60秒，使用的是SynchrounousQueue。</p><ul><li>当任务进来的时候<ul><li>会增加线程</li><li>有多少任务进来，就会使用ThreadFactory开多少线程，因为允许的最大线程数时无限大，所以可以一直这么开下去</li><li>而其workqueue是SynchrounousQueue,其大小始终为0，在这里我们可以直接任务当任务进来的时候，如果没有空闲的线程，会直接让ThreadFactory来构建新的线程了</li><li>那么当任务无限多的时候，就会创建无数多的线程，直接撑爆内存了</li></ul></li></ul><p>由此可以看出来使用Executors的两个方法直接构建线程池因为设定的参数是无界的，可能会导致OOM的错误，更好的方式是自己根据当前线程池的应用场景，来设定参数。</p><p>根据应用场景的不同，根据doc，我们有三大类的queue可以选择，分别为：</p><ul><li><p><code>Synchronous queue</code></p><ul><li>直接讲任务交给线程</li><li>自己本身不持有任何任务的</li><li>针对的应用场景可以是各个线程之间任务的执行有某些内在的联系，阻碍一个的执行可能会影响另外一个</li><li>为了不拒绝新的线程的创建，就必须设定线程池的大小为Integer.MAX_VALUE</li><li>这样如果处理速度低于新任务的提交速度的话，可能会导致非常非常大的线程池</li></ul></li><li><p><code>LinkedBlockingQueue</code></p><ul><li>使用没有边界的queue</li><li>这样当所有核心线程都忙碌的时候，任务就都会在队列当中排队</li><li>这种方式可以环节突发性的峰值，但是如果处理速度慢于任务堆积的速度，queue会变得很大</li></ul></li><li><p><code>ArrayBlockingQueue</code></p><ul><li>有限长的queue</li><li>这样可以防止资源耗尽，但是也很难做调整和优化</li><li>队列的大小和最大线程数相互影响，很难做到优化</li><li>使用大队列，小线程池可以减少对于CPU的使用，线程切换的损耗，但是单位时间处理速度不会太高</li><li>使用小队列，大线程池可以让CPU更忙碌，但是切换线程会有不小的损耗</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.ibm.com/developerworks/library/j-jtp0730/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/library/j-jtp0730/index.html</a> </li><li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ThreadPoolExecutor.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Executors </tag>
            
            <tag> ThreadPoolExecutor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS CDK Overview</title>
      <link href="/AWS-CDK-Overview/"/>
      <url>/AWS-CDK-Overview/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li><p>AWS CDK </p><ul><li><p>Open source software development framework </p></li><li><p>Model and provision your cloud application resources</p></li><li><p>To resolve what issue? </p><ul><li>provision cloud applications is challenging cause require<ul><li>manual actions</li><li>custom scripts </li><li>maintain templates </li><li>domain specific languages </li></ul></li></ul></li><li><p>How does CDK resolve the issue?</p><ul><li>Provides with high level component that pre-configure cloud resources with proven defaults</li><li>Provision your resources through AWS CloudFormation </li></ul></li></ul></li></ul><h2 id="1-1-Workflow"><a href="#1-1-Workflow" class="headerlink" title="1.1 Workflow"></a>1.1 Workflow</h2><ul><li>Creating an Amazon ECS service with AWS Fargate launch type </li></ul><pre><code>public class MyEcsConstructStack extends Stack {    public MyEcsConstructStack(final Construct scope, final String id) {        this(scope, id, null);    }    public MyEcsConstructStack(final Construct scope, final String id,            StackProps props) {        super(scope, id, props);        Vpc vpc = Vpc.Builder.create(this, &quot;MyVpc&quot;).maxAzs(3).build();        Cluster cluster = Cluster.Builder.create(this, &quot;MyCluster&quot;)                .vpc(vpc).build();        ApplicationLoadBalancedFargateService.Builder.create(this, &quot;MyFargateService&quot;)                .cluster(cluster)                .cpu(512)                .desiredCount(6)                .taskImageOptions(                       ApplicationLoadBalancedTaskImageOptions.builder()                               .image(ContainerImage                                       .fromRegistry(&quot;amazon/amazon-ecs-sample&quot;))                               .build()).memoryLimitMiB(2048)                .publicLoadBalancer(true).build();    }}</code></pre><ul><li><p>Basic workflow</p><ul><li>create the app from a template provided by the AWS CDK</li><li>add code to the app to create resources within stacks</li><li>build the app </li><li>synthesize one or more stacks in the app to create an AWS CloudFormation template </li><li>deploy one or more stacks to your AWS account </li></ul></li><li><p>Benefits </p><ul><li>Could use logic when defining infrastructure </li><li>Use object-oriented techniques to create a model of system </li><li>Define high level abstractions</li></ul></li><li><p>Tools</p><ul><li><p><a href="https://docs.aws.amazon.com/cdk/latest/guide/cli.html" target="_blank" rel="noopener">CDK Toolkit</a> </p><ul><li>CLI for interacting with CDK apps </li><li>Enable developers to synthesize artifacts such as AWS CloudFormation templates, deploy stacks to development AWS accounts, and diff against a deployed stack to understand the impact of a code change </li></ul></li><li><p><a href="https://docs.aws.amazon.com/cdk/latest/guide/constructs.html" target="_blank" rel="noopener">AWS Construct Library</a></p><ul><li>contains constructs representing AWS resources </li><li>encapsulate the details of how to create resources for an Amazon or AWS service </li></ul></li></ul></li></ul><h2 id="1-1-1-Create-and-build-the-app"><a href="#1-1-1-Create-and-build-the-app" class="headerlink" title="1.1.1 Create and build the app"></a>1.1.1 Create and build the app</h2><pre><code>mkdir hello-cdk &amp;&amp; cd hello-cdkcdk init TEMPLATE --language LANGUAGE cdk init app --language java// In your IDE, import it as maven project mvn compile cdk ls </code></pre><h3 id="1-1-2-Add-an-Amazon-S3-Bucket"><a href="#1-1-2-Add-an-Amazon-S3-Bucket" class="headerlink" title="1.1.2 Add an Amazon S3 Bucket"></a>1.1.2 Add an Amazon S3 Bucket</h3><pre><code>// Add dependencies to pom.xml &lt;dependency&gt;    &lt;groupId&gt;software.amazon.awscdk&lt;/groupId&gt;    &lt;artifactId&gt;s3&lt;/artifactId&gt;    &lt;version&gt;${cdk.version}&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>Define an Amazon S3 bucket in the stack using L2 construct </p><pre><code>package com.myorg;import software.amazon.awscdk.core.*;import software.amazon.awscdk.services.s3.Bucket;public class HelloCdkStack extends Stack {    public HelloCdkStack(final Construct scope, final String id) {        this(scope, id, null);    }    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {        super(scope, id, props);        Bucket.Builder.create(this, &quot;MyFirstBucket&quot;)            .versioned(true).build();    }}</code></pre><h3 id="1-1-3-Systhesize-an-AWS-CloudFormation-Template"><a href="#1-1-3-Systhesize-an-AWS-CloudFormation-Template" class="headerlink" title="1.1.3 Systhesize an AWS CloudFormation Template"></a>1.1.3 Systhesize an AWS CloudFormation Template</h3><pre><code>cdk synth</code></pre><h3 id="1-1-4-Deploying-the-stack"><a href="#1-1-4-Deploying-the-stack" class="headerlink" title="1.1.4 Deploying the stack"></a>1.1.4 Deploying the stack</h3><p><code>cdk deploy</code></p><h3 id="1-1-5-Modifying-the-stack"><a href="#1-1-5-Modifying-the-stack" class="headerlink" title="1.1.5 Modifying the stack"></a>1.1.5 Modifying the stack</h3><pre><code>// after make your change cdk diff cdk deploy // Possibly destroy cdk destroy </code></pre><ul><li>Synthesize before deploying <h1 id="2-Basic-concepts"><a href="#2-Basic-concepts" class="headerlink" title="2. Basic concepts"></a>2. Basic concepts</h1></li></ul><h2 id="2-1-Constructs"><a href="#2-1-Constructs" class="headerlink" title="2.1 Constructs"></a>2.1 Constructs</h2><h3 id="2-1-1-Basics"><a href="#2-1-1-Basics" class="headerlink" title="2.1.1 Basics"></a>2.1.1 Basics</h3><ul><li><p>Constructs </p><ul><li><p>Basic building blocks </p></li><li><p>represents a cloud component, encapsulates everything AWS CloudFormation needs to create the component </p></li><li><p>[AWS Construct Library](<a href="https://docs.aws.amazon.com/cdk/api/latest/docs/aws-construct-library.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/cdk/api/latest/docs/aws-construct-library.html</a></p></li><li><p>defferent level of constructs </p><ul><li><p>CFN Resources/ L1 </p><ul><li>directly represent all of the AWS resources that are available in AWS CloudFormation </li><li>named as CfnXyz, where xyz is name of the resource </li><li><strong>When you use CFN resources, you must explicitly configure all resource properties, which requires a complete understanding of the details of the underlying AWS CloudFormation resource model</strong></li></ul></li><li><p>AWS Reousources/ L2 Constrcuts</p><ul><li>higher level, intent based API </li><li>provide defaults, boilerplate, and glue logic you’d be writing with a CFN resource construct</li><li>Offer convenient defaults thus reduce the need for the detail of AWS resources  </li></ul></li><li><p>Patterns - higher level constructs </p><ul><li>designed to help you complete common tasks in AWS, often involving multiple kinds of resources </li></ul></li></ul></li></ul></li></ul><pre><code>// L1 ConstructCfnBucket bucket = CfnBucket.Builder.create(this, &quot;MyBucket&quot;)                        .bucketName(&quot;MyBucket&quot;)                        .corsConfiguration(new CfnBucket.CorsConfigurationProperty.Builder()                            .corsRules(Arrays.asList(new CfnBucket.CorsRuleProperty.Builder()                                .allowedOrigins(Arrays.asList(&quot;*&quot;))                                .allowedMethods(Arrays.asList(&quot;GET&quot;))                                .build()))                            .build())                        .build();// L2 Constructimport software.amazon.awscdk.services.s3.*;public class HelloCdkStack extends Stack {    public HelloCdkStack(final Construct scope, final String id) {        this(scope, id, null);    }    public HelloCdkStack(final Construct scope, final String id, final StackProps props) {        super(scope, id, props);        Bucket.Builder.create(this, &quot;MyFirstBucket&quot;)                .versioned(true).build();    }}</code></pre><h3 id="2-1-2-Hierarchy-Composition"><a href="#2-1-2-Hierarchy-Composition" class="headerlink" title="2.1.2 Hierarchy - Composition"></a>2.1.2 Hierarchy - Composition</h3><ul><li><p>Composition </p><ul><li>High level construct can be composed from any number of lower level constructs </li><li>In turn, those could be composed from even lower level constructs</li><li>Scoping pattern results in a hierarchy of constructs known as a construct tree </li></ul></li><li><p>Composition means you can define reusable components and share them like any other code </p></li></ul><h3 id="2-1-3-Initialization"><a href="#2-1-3-Initialization" class="headerlink" title="2.1.3 Initialization"></a>2.1.3 Initialization</h3><ul><li><p>Being implemented in classes that extend the Construct base class </p></li><li><p>3 parameters </p><ul><li><p>scope </p><ul><li>the construct within which this construct is defined </li></ul></li><li><p>id </p><ul><li>an identifier that much be unique within this scope </li><li>serves as a namespace for everything that’s encapsulated within the scope’s subtree </li><li>used to allocate unique identities such as resource names and AWS CloudFormation logical IDs </li></ul></li><li><p>props </p><ul><li>a set of properties or keyword arguments </li><li>define the construct’s initial configuration </li></ul></li></ul></li></ul><h1 id="3-Java-Related"><a href="#3-Java-Related" class="headerlink" title="3. Java Related"></a>3. Java Related</h1><h2 id="3-1-AWS-CDK-idioms-in-Java"><a href="#3-1-AWS-CDK-idioms-in-Java" class="headerlink" title="3.1 AWS CDK idioms in Java"></a>3.1 AWS CDK idioms in Java</h2><ul><li>Props <ul><li>expressed with Builder pattern </li><li>define a bundle of key/ value pairs that the construct uses to configure the resources it creates </li></ul></li></ul><pre><code>Bucket bucket = new Bucket(this, &quot;MyBucket&quot;, new BucketProps.Builder()                           .versioned(true)                           .encryption(BucketEncryption.KMS_MANAGED)                           .build());</code></pre><ul><li>missing values <ul><li>it will be represented by <code>null</code></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Git 流程</title>
      <link href="/Git-%E6%B5%81%E7%A8%8B/"/>
      <url>/Git-%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>解决git conflict永远都是件很让人头疼的事情，为了让生活更简单，还是需要设定正确的git流程的。现在有如下几种git 流程</p><h1 id="1-基本的Git-流程"><a href="#1-基本的Git-流程" class="headerlink" title="1. 基本的Git 流程"></a>1. 基本的Git 流程</h1><p>只有一个branch – master. 开发者直接commit进去，然后会进入到alpha，beta, gamma, prod等不同的生产状态当中。</p><p>一般来说，除非你在自己单独完成某项小任务，是很不推荐这样做的。</p><p>缺陷在于：</p><ul><li>代码上的合作变得很困难，可能会有多次冲突，需要逐次进行解决</li></ul><h1 id="2-Git-feature分支流程"><a href="#2-Git-feature分支流程" class="headerlink" title="2. Git feature分支流程"></a>2. Git feature分支流程</h1><p>当在同一个codebase我们有多个工程师共同工作的时候，使用feature分治就变成了必不可少的事情了。</p><p>如果现在有两个工程师在同一个branch上工作，来提交自己的代码，那最终一定是冲突不断的，很容易出现各种问题。</p><p>为了避免出现这种情况，两个开发者可以创建两个不同的分支，分别在自己的分治上来开发自己的项目。</p><p>这样做的好处是不用担心大量需要解决的冲突了。</p><h1 id="3-Git-feature分支流程与Develop分支"><a href="#3-Git-feature分支流程与Develop分支" class="headerlink" title="3. Git feature分支流程与Develop分支"></a>3. Git feature分支流程与Develop分支</h1><p>和上述的feature分支流程很类似，只是又加了一个Develop分支，在这个流程下，master 分支永远反映一个prod ready的状态。</p><p>无论何时，当小组想要将代码部署到prod的时候，他们从master分支来进行部署</p><p>develop branch反映的是带着最新的为了下次发布准备的所有改动。开发者fork develop 分支的代码，来做独立开发。一旦项目做好，经过了测试，就合并到develop分支当中，在develop分支来做充分的测试，然后再merge到master分支当中去。</p><p>这样做的好处是能够允许小组持续merge新的功能，做持续集成。不过过程相对比较麻烦。个人观点是在小规模的前提下，使用特征分支就足够了，再加上持续集成的工具，譬如Jerkins，很安全，效率也很不错。</p><p><a href="https://zepel.io/blog/5-git-workflows-to-improve-development/" target="_blank" rel="noopener">https://zepel.io/blog/5-git-workflows-to-improve-development/</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java Notes</title>
      <link href="/Java-Notes/"/>
      <url>/Java-Notes/</url>
      
        <content type="html"><![CDATA[<h1 id="1-并发"><a href="#1-并发" class="headerlink" title="1. 并发"></a>1. 并发</h1><h2 id="1-1-ThreadLocal复用问题"><a href="#1-1-ThreadLocal复用问题" class="headerlink" title="1.1 ThreadLocal复用问题"></a>1.1 ThreadLocal复用问题</h2><p>ThreadLocal适用于变量在线程间隔离，而在方法或类之间共享的场景。如果用户信息的获取比较昂贵，那么在ThreadLocal中缓存数据时比较合适的做法。</p><pre><code>private static final ThreadLocal&lt;Integer&gt; currentUser = ThreadLocal.withInitial(() -&gt; null);@GetMapping(&quot;wrong&quot;)public Map wrong(@RequestParam(&quot;userId&quot;) Integer userId) {    //设置用户信息之前先查询一次ThreadLocal中的用户信息    String before  = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();    //设置用户信息到ThreadLocal    currentUser.set(userId);    //设置用户信息之后再查询一次ThreadLocal中的用户信息    String after  = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();    //汇总输出两次查询结果    Map result = new HashMap();    result.put(&quot;before&quot;, before);    result.put(&quot;after&quot;, after);    return result;}</code></pre><p>上述例子当中，我们在设置前设置后都做了记录，来看threadLocal当中都记录了什么信息，。值得注意的是程序是运行在Tomcat当中的，执行程序的线程是Tomcat的工作线程，而Tomcat的工作线程是基于线程池的。</p><p>即会重用几个固定的线程，一旦线程重用，那么很可能首次从ThreadLocal获取的值是之前其他用户的请求遗留的值。这时ThreadLocal中的用户信息就是其他用户的信息了。</p><p>Take Away: </p><ol><li>代码中没用多线程不以为着你的程序没有使用多线程，Tomcat的Web服务器的业务代码，本身就运行在一个多线程环境当中</li><li>使用线程池处理数据就意味着线程是会被重用的，使用类似ThreadLocal工具来存放一些数据的时候，需要注意在代码运行完之后，显式去清空设置的数据。</li></ol><p>修正复用的问题的bug： </p><pre><code>private static final ThreadLocal&lt;Integer&gt; currentUser = ThreadLocal.withInitial(() -&gt; null);@GetMapping(&quot;right&quot;)public Map right(@RequestParam(&quot;userId&quot;) Integer userId) {    String before  = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();    currentUser.set(userId);    try {        String after = Thread.currentThread().getName() + &quot;:&quot; + currentUser.get();        Map result = new HashMap();        result.put(&quot;before&quot;, before);        result.put(&quot;after&quot;, after);        return result;    } finally {        //在finally代码块中删除ThreadLocal中的数据，确保数据不串        currentUser.remove();    }}</code></pre><h2 id="1-2-ConcurrentHashMap"><a href="#1-2-ConcurrentHashMap" class="headerlink" title="1.2 ConcurrentHashMap"></a>1.2 ConcurrentHashMap</h2><ul><li>ConcurrentHashMap是线程安全的哈希表容器，这里的线程安全是指原子性读写操作是线程安全的。</li><li>例子 – 10个线程一起来补充总共100个元素进去</li></ul><pre><code>    //线程个数    private static int THREAD_COUNT = 10;    //总元素数量    private static int ITEM_COUNT = 1000;    //帮助方法，用来获得一个指定元素数量模拟数据的ConcurrentHashMap    private ConcurrentHashMap&lt;String, Long&gt; getData(int count) {        return LongStream.rangeClosed(1, count)                .boxed()                .collect(Collectors.toConcurrentMap(i -&gt; UUID.randomUUID().toString(), Function.identity(),                        (o1, o2) -&gt; o1, ConcurrentHashMap::new));    }    @GetMapping(&quot;wrong&quot;)    public String wrong() throws InterruptedException {        ConcurrentHashMap&lt;String, Long&gt; concurrentHashMap = getData(ITEM_COUNT - 100);        //初始900个元素        log.info(&quot;init size:{}&quot;, concurrentHashMap.size());        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);        //使用线程池并发处理逻辑        forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, 10).parallel().forEach(i -&gt; {            //查询还需要补充多少个元素            int gap = ITEM_COUNT - concurrentHashMap.size();            log.info(&quot;gap size:{}&quot;, gap);            //补充元素            concurrentHashMap.putAll(getData(gap));        }));        //等待所有任务完成        forkJoinPool.shutdown();        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);        //最后元素个数会是1000吗？        log.info(&quot;finish size:{}&quot;, concurrentHashMap.size());        return &quot;OK&quot;;    }</code></pre><p>这样子执行的结果就是加入远远超过预期的数量，因为ConcurrentHashMap可以保证多个worker工作的时候不会互相干扰，但是无法保证看到的当前ConcurrentHashMap数据数量的同步</p><ul><li>Take Aways<ul><li>使用ConcurrentHashMap，不代表对其多个操作之间的状态是一致的，是没有其他线程在操作它的，如果需要确保，需要手动加锁</li><li>诸如size,isEmpty和containsValue等聚合方法，在并发情况下可能会反映ConcurrentHashMap的<strong>中间状态</strong>，因此在并发情况下，<strong>*这些方法的返回值只能用作参考，而不能用于流程控制</strong></li></ul></li></ul><p>解决方案就是通过加锁，使得同时只有一个线程可以操作ConcurrentHashMap</p><pre><code>@GetMapping(&quot;right&quot;)public String right() throws InterruptedException {    ConcurrentHashMap&lt;String, Long&gt; concurrentHashMap = getData(ITEM_COUNT - 100);    log.info(&quot;init size:{}&quot;, concurrentHashMap.size());    ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);    forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, 10).parallel().forEach(i -&gt; {        //下面的这段复合逻辑需要锁一下这个ConcurrentHashMap        synchronized (concurrentHashMap) {            int gap = ITEM_COUNT - concurrentHashMap.size();            log.info(&quot;gap size:{}&quot;, gap);            concurrentHashMap.putAll(getData(gap));        }    }));    forkJoinPool.shutdown();    forkJoinPool.awaitTermination(1, TimeUnit.HOURS);    log.info(&quot;finish size:{}&quot;, concurrentHashMap.size());    return &quot;OK&quot;;}</code></pre><ul><li>充分使用ConcurrentHashMap的特性<ul><li>例如面对一个使用Map来统计Key出现次数的场景</li><li>key范围为10， 最多使用10个并发，循环操作1000万次，每次操作累加随机的key</li><li>如果key不存在的话，首次设置值为1 </li></ul></li></ul><pre><code>    //循环次数    private static int LOOP_COUNT = 10000000;    //线程数量    private static int THREAD_COUNT = 10;    //元素数量    private static int ITEM_COUNT = 10;    private Map&lt;String, Long&gt; normaluse() throws InterruptedException {        ConcurrentHashMap&lt;String, Long&gt; freqs = new ConcurrentHashMap&lt;&gt;(ITEM_COUNT);        ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);        forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&gt; {            //获得一个随机的Key            String key = &quot;item&quot; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);                    synchronized (freqs) {                              if (freqs.containsKey(key)) {                            //Key存在则+1                            freqs.put(key, freqs.get(key) + 1);                        } else {                            //Key不存在则初始化为1                            freqs.put(key, 1L);                        }                    }                }        ));        forkJoinPool.shutdown();        forkJoinPool.awaitTermination(1, TimeUnit.HOURS);        return freqs;    }</code></pre><p>但是实际上ConcurrentHashMap本身是使用的Java自带的CAS操作的，在虚拟机层面确保了写入数据的原子性，比加锁的效率高很多，因此相较于直接加synchronized重量锁，我们可以通过computeIfAbsent()操作，和线程安全累加器LongAdder来更有效率的实现我们的统计目的</p><pre><code>private Map&lt;String, Long&gt; gooduse() throws InterruptedException {    ConcurrentHashMap&lt;String, LongAdder&gt; freqs = new ConcurrentHashMap&lt;&gt;(ITEM_COUNT);    ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT);    forkJoinPool.execute(() -&gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -&gt; {        String key = &quot;item&quot; + ThreadLocalRandom.current().nextInt(ITEM_COUNT);                //利用computeIfAbsent()方法来实例化LongAdder，然后利用LongAdder来进行线程安全计数                freqs.computeIfAbsent(key, k -&gt; new LongAdder()).increment();            }    ));    forkJoinPool.shutdown();    forkJoinPool.awaitTermination(1, TimeUnit.HOURS);    //因为我们的Value是LongAdder而不是Long，所以需要做一次转换才能返回    return freqs.entrySet().stream()            .collect(Collectors.toMap(                    e -&gt; e.getKey(),                    e -&gt; e.getValue().longValue())            );}</code></pre><ul><li>上述代码中，直接使用了ConcurrentHashMap的原子性方法computeIfAbsent来做符合逻辑操作，判断Key是否存在Value，如果不存在则把Lambda表达式运行后的结果放入Map作为Value</li><li>LongAdder是线程安全的累加器，因此可以直接调用其increment()方法来做累加。</li></ul><h2 id="1-3-锁"><a href="#1-3-锁" class="headerlink" title="1.3 锁"></a>1.3 锁</h2><ul><li>加锁前需要知道锁和被保护的对象是不是一个层面上的<ul><li>静态字段属于类，需要类级别的锁来进行保护</li><li>非静态字段属于类实例，实例级别的锁就可以保护</li></ul></li></ul><pre><code>// 定义一个静态int字段counter和一个非静态的wrong方法，实现counter字段的累加操作class Data {    @Getter    private static int counter = 0;    public static int reset() {        counter = 0;        return counter;    }    public synchronized void wrong() {        counter++;    }}// 测试代码@GetMapping(&quot;wrong&quot;)public int wrong(@RequestParam(value = &quot;count&quot;, defaultValue = &quot;1000000&quot;) int count) {    Data.reset();    //多线程循环一定次数调用Data类不同实例的wrong方法    IntStream.rangeClosed(1, count).parallel().forEach(i -&gt; new Data().wrong());    return Data.getCounter();}</code></pre><p>输出结果，因为默认运行100万次，但是页面输出的并不会是100万。</p><ul><li>在非静态的wrong方法上加锁，只能够保证多个线程无法执行同一个实例的wrong方法，但无法保证其不会执行不同实例的wrong方法。而静态的counter是被共享的</li><li>解决方案时保证在一个实例的方法操作静态变量的时候，其他的实例无法操作这个静态变量</li></ul><pre><code>class Data {    @Getter    private static int counter = 0;    private static Object locker = new Object();    public void right() {        synchronized (locker) {            counter++;        }    }}</code></pre><ul><li>除此以外，对锁可以做的优化还包括<ul><li>精细化锁应用的范围</li><li>区分读写场景以及资源的访问冲突，考虑使用悲观锁还是乐观锁<ul><li>对于读写比例差异明显的场景，考虑使用ReentrantReadWriteLock细化区分读写锁，来提高性能</li><li>如果共享资源冲突概率不大，可以考虑使用StampedLock的乐观读的特性，进一步提高性能</li></ul></li></ul></li></ul><h2 id="1-4-线程池"><a href="#1-4-线程池" class="headerlink" title="1.4 线程池"></a>1.4 线程池</h2><p>开发当中，我们会使用各种池化技术来缓存创建昂贵的对象，比如线程池，连接池，内存池。一般是预先创建一些对象放入到池当中，使用的时候直接取出使用，用完归还以便复用。通过一定的策略调整池中缓存对象的数量，实现池的动态伸缩。</p><ul><li>应当手动进行线程池的声明<ul><li>Java Executors定义了一些快捷的工具办法，来帮助我们快速创建线程池</li><li>应当禁止使用这些方法来创建线程池，应当手动new ThreadPoolExecutor来创建线程池<ul><li>资源耗尽导致OOM问题<ul><li>newFixedThreadPool</li><li>newCachedThreadPool</li></ul></li></ul></li></ul></li></ul><h3 id="1-4-1-newFixedThreadPool-OOM-问题"><a href="#1-4-1-newFixedThreadPool-OOM-问题" class="headerlink" title="1.4.1 newFixedThreadPool OOM 问题"></a>1.4.1 newFixedThreadPool OOM 问题</h3><pre><code>    @GetMapping(&quot;oom1&quot;)    public void oom1() throws InterruptedException {        ThreadPoolExecutor threadPool = (ThreadPoolExecutor) Executors.newFixedThreadPool(1);        //打印线程池的信息，稍后我会解释这段代码        printStats(threadPool);         for (int i = 0; i &lt; 100000000; i++) {            threadPool.execute(() -&gt; {                String payload = IntStream.rangeClosed(1, 1000000)                        .mapToObj(__ -&gt; &quot;a&quot;)                        .collect(Collectors.joining(&quot;&quot;)) + UUID.randomUUID().toString();                try {                    TimeUnit.HOURS.sleep(1);                } catch (InterruptedException e) {                }                log.info(payload);            });        }        threadPool.shutdown();        threadPool.awaitTermination(1, TimeUnit.HOURS);    }</code></pre><ul><li>日志显示出现了OOM</li><li>newFixedThreadPool源码：</li></ul><pre><code>    public static ExecutorService newFixedThreadPool(int nThreads) {        return new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());    }    public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt;            implements BlockingQueue&lt;E&gt;, java.io.Serializable {        ...        /**         * Creates a {@code LinkedBlockingQueue} with a capacity of         * {@link Integer#MAX_VALUE}.         */        public LinkedBlockingQueue() {            this(Integer.MAX_VALUE);        }    ...    }</code></pre><ul><li>直接使用了一个LinkedBlockingQueue，而默认构造方法是一个Integer.MAX_VALUE长度的队列，是无界的。</li><li>尽管使用newFixedThreadPool可以把工作线程控制在固定的数量上，但任务队列是无界的。如果任务比较多并且执行比较慢的话，队列可能会迅速积压，撑爆内存导致OOM</li></ul><h3 id="1-4-2-newCachedThreadPool-OOM问题"><a href="#1-4-2-newCachedThreadPool-OOM问题" class="headerlink" title="1.4.2 newCachedThreadPool OOM问题"></a>1.4.2 newCachedThreadPool OOM问题</h3><pre><code>public static ExecutorService newCachedThreadPool() {    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                  60L, TimeUnit.SECONDS,                                  new SynchronousQueue&lt;Runnable&gt;());</code></pre><ul><li>线程池最大线程数为Integer.MAX_VALUE，是没有上限的，其工作队列SynchronizedQueue是一个没有存储空间的阻塞队列。</li><li>SynchronousQueue是没有存储空间的阻塞队列，有请求到来的时候，必须要找到一条工作线程来处理，如果当前没有空闲的线程就再创建一条新的</li></ul><h3 id="1-4-3-线程池配置Best-Practice"><a href="#1-4-3-线程池配置Best-Practice" class="headerlink" title="1.4.3 线程池配置Best Practice"></a>1.4.3 线程池配置Best Practice</h3><ul><li><p>根据自己的场景，并发情况来评估线程池的几个核心参数，需要设置有界的工作队列和可控的线程数</p><ul><li>核心线程数</li><li>最大线程数</li><li>线程回收策略</li><li>工作队列的类型</li><li>拒绝策略</li></ul></li><li><p>为线程池指定有意义的名称，来方便问题的排查，当出现线程数暴增，线程死锁，线程占用大量CPU这类问题的时候，会抓取线程栈来进行分析，这个时候有意义的线程名称，可以很大程度上方便我们对问题的定位</p></li><li><p>Metrics， alarm来观察线程池的状态</p></li></ul><ul><li>线程池特性<ul><li>不会初始化corePoolSize个线程，有任务来了才创建工作线程</li><li>当核心线程满了之后不会立即扩容线程池，而是把任务堆积到工作队列当中</li><li>当工作队列满了之后扩容线程池，一直到线程个数达到maximumPoolSize为止</li><li>如果队列已满其达到了最大线程后还有任务来，就按照拒绝策略来处理</li><li>当线程数大于核心线程数时，线程等待KeepAliveTime后还没有任务需要处理的话，收缩线程到核心线程数</li></ul></li></ul><pre><code>@GetMapping(&quot;right&quot;)public int right() throws InterruptedException {    //使用一个计数器跟踪完成的任务数    AtomicInteger atomicInteger = new AtomicInteger();    //创建一个具有2个核心线程、5个最大线程，使用容量为10的ArrayBlockingQueue阻塞队列作为工作队列的线程池，使用默认的AbortPolicy拒绝策略    ThreadPoolExecutor threadPool = new ThreadPoolExecutor(            2, 5,            5, TimeUnit.SECONDS,            new ArrayBlockingQueue&lt;&gt;(10),            new ThreadFactoryBuilder().setNameFormat(&quot;demo-threadpool-%d&quot;).get(),            new ThreadPoolExecutor.AbortPolicy());    printStats(threadPool);    //每隔1秒提交一次，一共提交20次任务    IntStream.rangeClosed(1, 20).forEach(i -&gt; {        try {            TimeUnit.SECONDS.sleep(1);        } catch (InterruptedException e) {            e.printStackTrace();        }        int id = atomicInteger.incrementAndGet();        try {            threadPool.submit(() -&gt; {                log.info(&quot;{} started&quot;, id);                //每个任务耗时10秒                try {                    TimeUnit.SECONDS.sleep(10);                } catch (InterruptedException e) {                }                log.info(&quot;{} finished&quot;, id);            });        } catch (Exception ex) {            //提交出现异常的话，打印出错信息并为计数器减一            log.error(&quot;error submitting task {}&quot;, id, ex);            atomicInteger.decrementAndGet();        }    });    TimeUnit.SECONDS.sleep(60);    return atomicInteger.intValue();}</code></pre><h3 id="1-4-4-线程池本身不复用"><a href="#1-4-4-线程池本身不复用" class="headerlink" title="1.4.4 线程池本身不复用"></a>1.4.4 线程池本身不复用</h3><pre><code>@GetMapping(&quot;wrong&quot;)public String wrong() throws InterruptedException {    ThreadPoolExecutor threadPool = ThreadPoolHelper.getThreadPool();    IntStream.rangeClosed(1, 10).forEach(i -&gt; {        threadPool.execute(() -&gt; {            ...            try {                TimeUnit.SECONDS.sleep(1);            } catch (InterruptedException e) {            }        });    });    return &quot;OK&quot;;}class ThreadPoolHelper {    public static ThreadPoolExecutor getThreadPool() {        //线程池没有复用        return (ThreadPoolExecutor) Executors.newCachedThreadPool();    }}</code></pre><p>通过这种方式，会不停产生新的线程，整个业务程序会不停产生新的threadPool，因为newCachedThreadPool的核心线程数是0， keepAliveTime是60秒，过了60s以后线程就会被回收了。</p><h3 id="1-4-5-线程池的使用策略"><a href="#1-4-5-线程池的使用策略" class="headerlink" title="1.4.5 线程池的使用策略"></a>1.4.5 线程池的使用策略</h3><ul><li>对于线程池如何使用，放什么样的任务进去，是需要根据任务的轻重缓急来指定线程池的核心参数，包括线程数，回收策略和任务队列<ul><li>对于执行比较慢，数量不大的IO任务，可以考虑更多的线程数，而不需要太大的队列</li><li>对于吞吐量比较大的计算型任务，线程数量不应该过多，可以是CPU核心数，或者核心数 x 2。<ul><li>因为线程是需要调度到某个CPU当中进行的，如果任务本身是CPU绑定的任务，那么过多的线程只会增加线程切换的开销，并不能提升吞吐量</li><li>需要比较长的队列来做缓冲</li></ul></li></ul></li></ul><h1 id="2-连接池"><a href="#2-连接池" class="headerlink" title="2. 连接池"></a>2. 连接池</h1><h2 id="2-1-连接池定义"><a href="#2-1-连接池定义" class="headerlink" title="2.1 连接池定义"></a>2.1 连接池定义</h2><ul><li>对外提供获得连接</li><li>归还连接的接口给客户端使用</li><li>暴露最小空闲连接数，最大连接数等可配置参数</li><li>内部实现连接建立，连接心跳保持，连接管理，空闲连接回收，连接可用性检测等功能</li></ul><p><img src="https://i.loli.net/2020/08/21/8qialtrxJoB2MNF.png" alt="连接池.png"></p><ul><li>应用场景<ul><li>数据库连接池</li><li>Redis连接池</li><li>HTTP连接池</li></ul></li></ul><h2 id="2-2-应用场景"><a href="#2-2-应用场景" class="headerlink" title="2.2 应用场景"></a>2.2 应用场景</h2><h3 id="2-2-1-判断客户端SDK是否基于连接池"><a href="#2-2-1-判断客户端SDK是否基于连接池" class="headerlink" title="2.2.1 判断客户端SDK是否基于连接池"></a>2.2.1 判断客户端SDK是否基于连接池</h3><ul><li><p>使用第三方客户端进行网络通信的时候，需要确定客户端SDK是否是基于连接池技术实现的</p><ul><li><p>TCP是面向连接的基于字节流的协议</p><ul><li><p>面向连接</p><ul><li>连接需要先创建，需要先做三次握手，是有开销的</li></ul></li><li><p>基于字节流</p><ul><li>字节是发送数据的最小单元</li><li>TCP是数据读写的通道，本身不知道哪些是完整的消息体，也不知道是否有多个客户端在使用同一个TCP连接</li></ul></li></ul></li></ul></li><li><p>客户端SDK对外提供API的方式</p><ul><li>连接池和连接分离的 API：有一个 XXXPool 类负责连接池实现，先从其获得连接 XXXConnection，然后用获得的连接进行服务端请求，完成后使用者需要归还连接。通常，XXXPool 是线程安全的，可以并发获取和归还连接，而 XXXConnection 是非线程安全的。对应到连接池的结构示意图中，XXXPool 就是右边连接池那个框，左边的客户端是我们自己的代码</li><li>内部带有连接池的 API：对外提供一个 XXXClient 类，通过这个类可以直接进行服务端请求；这个类内部维护了连接池，SDK 使用者无需考虑连接的获取和归还问题。一般而言，XXXClient 是线程安全的。对应到连接池的结构示意图中，整个 API 就是蓝色框包裹的部分</li><li>非连接池的 API：一般命名为 XXXConnection，以区分其是基于连接池还是单连接的，而不建议命名为 XXXClient 或直接是 XXX。直接连接方式的 API 基于单一连接，每次使用都需要创建和断开连接，性能一般，且通常不是线程安全的。对应到连接池的结构示意图中，这种形式相当于没有右边连接池那个框，客户端直接连接服务端创建连接</li></ul></li></ul><h3 id="2-2-2-复用连接池"><a href="#2-2-2-复用连接池" class="headerlink" title="2.2.2 复用连接池"></a>2.2.2 复用连接池</h3><ul><li>创建连接池的时候很可能一次性创建了多个连接，大多数连接池考虑到性能，会在初始化的时候维护一定数量的最小连接（毕竟初始化连接池的过程一般是一次性的），可以直接使用。如果每次使用连接池都按需创建连接池，那么很可能你只用到一个连接，但是创建了 N 个连接</li><li>连接池有管理模块，会有闲置超时，定时来回收闲置的连接，将活跃连接数降到最低连接的配置值，以此减轻服务端的压力</li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-行为型-备忘录模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-备忘录模式的原理与实现"><a href="#1-备忘录模式的原理与实现" class="headerlink" title="1. 备忘录模式的原理与实现"></a>1. 备忘录模式的原理与实现</h1><ul><li>snapshot模式 <ul><li>Memento Design Pattern </li><li>Captures and externalizes an object’s internal state so that it can be restored later, all without violating encapsulation </li><li>在不违背封装原则的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便之后恢复对象先前的状态。<ul><li>存储副本以便后期恢复</li><li>在不违背封装原则的前提下，进行对象的备份和恢复</li></ul></li></ul></li></ul><pre><code>    public class InputText {      private StringBuilder text = new StringBuilder();      public String getText() {        return text.toString();      }      public void append(String input) {        text.append(input);      }      public Snapshot createSnapshot() {        return new Snapshot(text.toString());      }      public void restoreSnapshot(Snapshot snapshot) {        this.text.replace(0, this.text.length(), snapshot.getText());      }    }    public class Snapshot {      private String text;      public Snapshot(String text) {        this.text = text;      }      public String getText() {        return this.text;      }    }    public class SnapshotHolder {      private Stack&lt;Snapshot&gt; snapshots = new Stack&lt;&gt;();      public Snapshot popSnapshot() {        return snapshots.pop();      }      public void pushSnapshot(Snapshot snapshot) {        snapshots.push(snapshot);      }    }    public class ApplicationMain {      public static void main(String[] args) {        InputText inputText = new InputText();        SnapshotHolder snapshotsHolder = new SnapshotHolder();        Scanner scanner = new Scanner(System.in);        while (scanner.hasNext()) {          String input = scanner.next();          if (input.equals(&quot;:list&quot;)) {            System.out.println(inputText.toString());          } else if (input.equals(&quot;:undo&quot;)) {            Snapshot snapshot = snapshotsHolder.popSnapshot();            inputText.restoreSnapshot(snapshot);          } else {            snapshotsHolder.pushSnapshot(inputText.createSnapshot());            inputText.append(input);          }        }      }    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 备忘录模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《目标：简单而有效的常识管理》</title>
      <link href="/%E3%80%8A%E7%9B%AE%E6%A0%87%EF%BC%9A%E7%AE%80%E5%8D%95%E8%80%8C%E6%9C%89%E6%95%88%E7%9A%84%E5%B8%B8%E8%AF%86%E7%AE%A1%E7%90%86%E3%80%8B/"/>
      <url>/%E3%80%8A%E7%9B%AE%E6%A0%87%EF%BC%9A%E7%AE%80%E5%8D%95%E8%80%8C%E6%9C%89%E6%95%88%E7%9A%84%E5%B8%B8%E8%AF%86%E7%AE%A1%E7%90%86%E3%80%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-企业问题的着手点"><a href="#1-企业问题的着手点" class="headerlink" title="1. 企业问题的着手点"></a>1. 企业问题的着手点</h1><ul><li><p>着眼于每个环节的改善 vs 从系统视角着手</p></li><li><p>系统</p><ul><li>首先要掌握和妥善处理这个系统内各个环节间的互动关系</li><li>TOC – 希望能够指导企业如何集中利用有限资源，将其用在整个系统中最重要的地方，来达到最大的效益。</li></ul></li><li><p>现状</p><ul><li>企业势必会遇到无数问题<ul><li>而这些问题往往会使得管理人员废寝忘食，疲于奔命</li><li>需要去寻找在这些问题背后，是受到什么东西支配着的，有没有什么规律法则和秩序可以遵循</li></ul></li></ul></li></ul><h1 id="2-TOC"><a href="#2-TOC" class="headerlink" title="2. TOC"></a>2. TOC</h1><h2 id="2-1-目标是什么？"><a href="#2-1-目标是什么？" class="headerlink" title="2.1 目标是什么？"></a>2.1 目标是什么？</h2><ul><li><p>赚钱 目标</p><ul><li><p>本质就是赚钱 – 下述的是具体的方法</p><ul><li>采购发挥成本效益</li><li>雇佣好的人才</li><li>高科技，生产有品质的产品</li><li>销售有品质的产品</li><li>争取市场占有率</li><li>良好的沟通，顾客满意度</li></ul></li><li><p>关注指标</p><ul><li>利润</li><li>投资回报率</li><li>现金流量</li></ul></li><li><p>将实际运作状况和关注的各个指标再连接起来，如何做连接呢？？？？？？？？？？  – 用你建立的指标来表达你的目标</p><ul><li>有效产出 throughput<ul><li>系统通过销售获取金钱的速度</li></ul></li><li>存货 inventory<ul><li>整个系统投资在采购上的钱</li><li>采购的是打算卖出去的东西</li><li>可以借销售回收的投资都算是存货</li></ul></li><li>营运费用  operationalExpense<ul><li>系统为了把存货转为有效产出而花的钱 </li></ul></li></ul></li></ul></li></ul><h2 id="2-2-如何达成目标"><a href="#2-2-如何达成目标" class="headerlink" title="2.2 如何达成目标"></a>2.2 如何达成目标</h2><ul><li><p>一些列详尽的指标</p><ul><li>在改善一个指标的时候，要思考对其他指标的影响</li><li>单纯面向一个指标的改善可能对整个企业的改善并不是最有利的</li></ul></li><li><p>依存关系</p><ul><li>在一条链上，越到下游受影响越大，牛鞭效应，因为上游不确定太大，平均时间无法说明每天的实际状况</li><li>下游只能追上上游的速度，而不能超过上游的速度，因此不会是各种不同速度的相互抵消平均，而会是统计波动的累积</li><li>有效产出要看的是最终端的产出，即要看的是整体生产环节这个角度上的生产效率</li><li>优先解决瓶颈！ </li></ul></li><li><p>统计波动</p><ul><li>生产率的波动</li><li>生产线最后部分的产能应该比开始的时候高，需要能够处理更大的波动</li></ul></li><li><p>区分资源</p><ul><li><p>瓶颈资源</p><ul><li>产能等于或少于其需求</li><li>当出现瓶颈的时候，其成本已不能按照单环节的成本来计算了，相反的，他直接影响了产品的产出，所以要从全局成本的角度来进行考虑。</li><li>制定优先级，严格按照优先级顺序来执行</li></ul></li><li><p>非瓶颈资源</p><ul><li>产能大于需求</li></ul></li><li><p>需要在产品在工厂当中的流量和市场需求之间获取平衡</p></li></ul></li></ul><h2 id="2-3-Under-the-hood"><a href="#2-3-Under-the-hood" class="headerlink" title="2.3 Under the hood"></a>2.3 Under the hood</h2><p>一群人如何试图了解世界运转的窍门，并且因此改善周遭的一切。</p><p>科学代表着的是我们对于这个世界如何运作，以及为何如此运作的理解。但是他也只代表着我们现在所知的。</p><p>没有绝对的真理，绝对的真理反而会阻碍我们追求更深入的理解。</p><h2 id="2-4-制约理论"><a href="#2-4-制约理论" class="headerlink" title="2.4 制约理论"></a>2.4 制约理论</h2><ul><li><p>任何系统都至少存在着一个制约因素 – 瓶颈，否则它就可能有无限的产出。</p></li><li><p>核心步骤</p><ul><li><p>寻找约束</p><ul><li>确定生产速度和需求速度</li></ul></li><li><p>利用约束</p><ul><li>最大限度开发利用瓶颈工序，使得瓶颈工序产出量最大化</li></ul></li><li><p>服从约束</p><ul><li>使得企业的所有其他活动服从关于约束的各种措施，确保企业的所有活动，都是基于最大化利用瓶颈工序而展开的</li></ul></li><li><p>打破约束</p><ul><li>如果无法有效提高瓶颈工序的利用率，就需要采取其他方法来打破约束</li></ul></li><li><p>寻找新的约束</p><ul><li>重新寻找新的约束，重新解决问题</li></ul></li></ul></li></ul><h1 id="3-案例分析"><a href="#3-案例分析" class="headerlink" title="3. 案例分析"></a>3. 案例分析</h1><h2 id="3-1-现状分析"><a href="#3-1-现状分析" class="headerlink" title="3.1 现状分析"></a>3.1 现状分析</h2><ul><li><p>工厂</p><ul><li><p>技术，机器齐备</p></li><li><p>员工</p><ul><li>优质</li><li>技术实力过硬</li></ul></li><li><p>良好的工会关系</p></li><li><p>问题</p><ul><li>无法按时交付</li></ul></li></ul></li><li><p>当你升级机器了以后，真的能够提升效率么？ </p><ul><li><p>宣传当中，升级了机器，效率会提高，即单位时间生产速度会得到提升</p></li><li><p>问题在于</p><ul><li>会解雇人么？ 即生产成本得到降低了么？</li><li>出货数量有提升么？ </li><li>中间生产物的堆积量以及平均存储时间怎么样呢？ </li></ul></li><li><p>回到上述问题，首先要做的是对生产力给一个更合理的定义</p><ul><li>怎么样才算有生产力？ <ul><li>工作上的输出</li><li>通过目标来量化自己的生产力</li><li>能更接近目标的行动才是有生产力的行动</li><li>所以要问的是你的目标到底是什么</li></ul></li></ul></li></ul></li><li><p>窘境</p><ul><li>将人在做事和能带来效益等价</li><li>通过调动人员来保证有事可做？ </li><li>看到的各种数据报表当中的数据真的能够反映出赚钱能力么？ <ul><li>做满工作时数？ </li><li>产品成本？</li><li>直接人工差异？ </li></ul></li></ul></li></ul><h2 id="3-2-策略"><a href="#3-2-策略" class="headerlink" title="3.2 策略"></a>3.2 策略</h2><ul><li><p>thought 1: 通过改变各个环节的在供应链当中的顺序，尝试缓解依存关系； 尝试通过增加机器，缓解某个缓解的瓶颈</p><ul><li>投入成本高</li><li>时间长</li><li>既定工序难以改变</li></ul></li><li><p>thought 2：识别出瓶颈之后，分析瓶颈处机器的时间利用</p><ul><li>人需要按照工会要求每4小时休息30min，但是机器需要尽可能运转</li><li>质检不应该只放在成品前，在瓶颈前就进行检查，确保瓶颈处加工的产品在那个时刻是合格的，相当于省了加工坏损品的时间 </li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://zhuanlan.zhihu.com/p/51536566" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/51536566</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-行为型-迭代器模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-迭代器模式的原理和实现"><a href="#1-迭代器模式的原理和实现" class="headerlink" title="1. 迭代器模式的原理和实现"></a>1. 迭代器模式的原理和实现</h1><ul><li>迭代器模式<ul><li>Iterator Design Pattern / Cursor Design Patten </li><li>用来遍历集合对象</li><li>编程语言基本上都将迭代器作为一个基础类库来提供了</li><li>集合对象指的是一个容器，而迭代器需要迭代的对象实际上是一组对象的对象</li><li>迭代器模式将集合对象的遍历操作从集合类当中拆分出来，放到迭代器类当中，使得二者的职责更加单一</li></ul></li></ul><ul><li>涉及部分<ul><li>容器<ul><li>接口</li><li>实现类</li></ul></li><li>容器迭代器<ul><li>接口</li><li>实现类</li></ul></li></ul></li></ul><h2 id="1-1-实现一个线性结构容器的迭代器"><a href="#1-1-实现一个线性结构容器的迭代器" class="headerlink" title="1.1 实现一个线性结构容器的迭代器"></a>1.1 实现一个线性结构容器的迭代器</h2><pre><code>// 接口定义方式一public interface Iterator&lt;E&gt; {  boolean hasNext();  void next();  E currentItem();}// 接口定义方式二public interface Iterator&lt;E&gt; {  boolean hasNext();  E next();}</code></pre><ul><li>定义方式一的好处在可以多次获得当前的对象，会更加灵活</li></ul><pre><code>public class ArrayIterator&lt;E&gt; implements Iterator&lt;E&gt; {  private int cursor;  private ArrayList&lt;E&gt; arrayList;  public ArrayIterator(ArrayList&lt;E&gt; arrayList) {    this.cursor = 0;    this.arrayList = arrayList;  }  @Override  public boolean hasNext() {    return cursor != arrayList.size(); //注意这里，cursor在指向最后一个元素的时候，hasNext()仍旧返回true。  }  @Override  public void next() {    cursor++;  }  @Override  public E currentItem() {    if (cursor &gt;= arrayList.size()) {      throw new NoSuchElementException();    }    return arrayList.get(cursor);  }}public class Demo {  public static void main(String[] args) {    ArrayList&lt;String&gt; names = new ArrayList&lt;&gt;();    names.add(&quot;xzg&quot;);    names.add(&quot;wang&quot;);    names.add(&quot;zheng&quot;);    Iterator&lt;String&gt; iterator = new ArrayIterator(names);    while (iterator.hasNext()) {      System.out.println(iterator.currentItem());      iterator.next();    }  }}</code></pre><ul><li>这里一个问题是还需要<code>new ArrayIterator()</code>，我们可以通过在List的接口当中定义迭代器，然后再ArrayList的类当中定义一个iterator()方法。然后在使用的时候，我们就可以通过实例化以后的容器，比如ArrayList，直接来调用iterator()方法了</li></ul><pre><code>public interface List&lt;E&gt; {  Iterator iterator();  //...省略其他接口函数...}public class ArrayList&lt;E&gt; implements List&lt;E&gt; {  //...  public Iterator iterator() {    return new ArrayIterator(this);  }  //...省略其他代码}public class Demo {  public static void main(String[] args) {    List&lt;String&gt; names = new ArrayList&lt;&gt;();    names.add(&quot;xzg&quot;);    names.add(&quot;wang&quot;);    names.add(&quot;zheng&quot;);    Iterator&lt;String&gt; iterator = names.iterator();    while (iterator.hasNext()) {      System.out.println(iterator.currentItem());      iterator.next();    }  }}</code></pre><ul><li><p>实现方式/ 设计思路</p><ul><li><p>迭代器当中实现</p><ul><li>hasNext()</li><li>currentItem()</li><li>next()</li></ul></li><li><p>待遍历的容器</p><ul><li>通过依赖注入传递到迭代器当中</li><li>容器通过iterator()方法来创建迭代器</li></ul></li></ul></li></ul><h2 id="1-2-为什么需要迭代器模式来遍历集合？"><a href="#1-2-为什么需要迭代器模式来遍历集合？" class="headerlink" title="1.2 为什么需要迭代器模式来遍历集合？"></a>1.2 为什么需要迭代器模式来遍历集合？</h2><ol><li>复杂数据结构遍历方式也会非常复杂，比如对于树，对于图来说。我们将遍历的方式定义到迭代器当中，这样就避免了要自己实现这样复杂的操作了。</li><li>通过迭代器模式，可以同时创建多个不同的迭代器，对同一个容器进行遍历而不互相影响</li><li>容器和迭代器都提供了抽象的接口，当我们需要改变遍历算法的时候，对代码的影响会很小，只在依赖注入处使用新的迭代器类所提供的算法即可</li></ol><h2 id="1-3-遍历时的增删"><a href="#1-3-遍历时的增删" class="headerlink" title="1.3 遍历时的增删"></a>1.3 遍历时的增删</h2><p>遍历时进行增删很大的一个问题是数组在做了增删以后，其他元素的位置会随之改变的。这样就会出现在迭代器当中有些元素无法迭代到的问题了</p><p>遍历时增删是会产生不可预期的遍历错误的，可以通过对遍历时候增删元素的限制来解决这个问题</p><ul><li>遍历的时候不允许增删元素<ul><li>比较难以实现</li></ul></li><li>增删元素之后让遍历报错<ul><li>在ArrayList当中定义一个成员变量modCount<ul><li>记录集合被修改的次数</li><li>集合每调用一次增加或删除元素的函数，就会加1 </li><li>当调用集合上的iterator()函数创建迭代器的时候，将modCount值传递给迭代器的expectedModCount成员变量</li><li>然后在每次调用迭代器上的函数的时候，都会检查一下modCount是否改变过</li></ul></li></ul></li></ul><pre><code>public class ArrayIterator implements Iterator {  private int cursor;  private ArrayList arrayList;  private int expectedModCount;  public ArrayIterator(ArrayList arrayList) {    this.cursor = 0;    this.arrayList = arrayList;    this.expectedModCount = arrayList.modCount;  }  @Override  public boolean hasNext() {    checkForComodification();    return cursor &lt; arrayList.size();  }  @Override  public void next() {    checkForComodification();    cursor++;  }  @Override  public Object currentItem() {    checkForComodification();    return arrayList.get(cursor);  }  private void checkForComodification() {    if (arrayList.modCount != expectedModCount)        throw new ConcurrentModificationException();  }}//代码示例public class Demo {  public static void main(String[] args) {    List&lt;String&gt; names = new ArrayList&lt;&gt;();    names.add(&quot;a&quot;);    names.add(&quot;b&quot;);    names.add(&quot;c&quot;);    names.add(&quot;d&quot;);    Iterator&lt;String&gt; iterator = names.iterator();    iterator.next();    names.remove(&quot;a&quot;);    iterator.next();//抛出ConcurrentModificationException异常  }}</code></pre><h1 id="2-实现支持快照功能的iterator"><a href="#2-实现支持快照功能的iterator" class="headerlink" title="2. 实现支持快照功能的iterator"></a>2. 实现支持快照功能的iterator</h1><ul><li>快照<ul><li>为容器创建迭代器的时候，给容器拍的快照</li><li>使得即便我们之后增删容器中的元素，快照中的元素并不会做相应的变动</li><li>这样迭代器使用的对象是快照，而不是容器，这样就避免了在使用迭代器遍历的过程中，因为增删容器中的元素而导致的不可预期的结果或报错。</li></ul></li></ul><ul><li>可以在迭代器类当中定义一个成员变量snapshot来存储快照<ul><li>每当迭代器需要被创建的时候，都拷贝一份容器中的元素到快照当中，后续的遍历操作都基于这个迭代器自己持有的快照来进行</li><li>问题<ul><li>代价高，每次创建迭代器的时候，都要拷贝一份数据到快照当中，会增加内存的消耗</li></ul></li></ul></li></ul><pre><code>public class SnapshotArrayIterator&lt;E&gt; implements Iterator&lt;E&gt; {  private int cursor;  private ArrayList&lt;E&gt; snapshot;  public SnapshotArrayIterator(ArrayList&lt;E&gt; arrayList) {    this.cursor = 0;    this.snapshot = new ArrayList&lt;&gt;();    this.snapshot.addAll(arrayList);  }  @Override  public boolean hasNext() {    return cursor &lt; snapshot.size();  }  @Override  public E next() {    E currentItem = snapshot.get(cursor);    cursor++;    return currentItem;  }}</code></pre><ul><li>可以在容器当中为每个元素保存两个时间戳<ul><li>addTimestamp</li><li>delTimestamp</li><li>当元素被加入到集合当中的时候，addTimestamp设置为当前时间，将delTimestamp设置成最大长整形值。当元素被删除时，将delTimestamp更新为当前时间，表示已经被删除</li><li>每个迭代器也保存一个迭代器创建时间戳 snapshotTimestamp<ul><li>只有满足addTimestamp &lt; snapshotTimestamp &lt; delTimestamp，才是属于这个迭代器的快照</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 迭代器模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-行为型-状态模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-原理与实现"><a href="#1-原理与实现" class="headerlink" title="1. 原理与实现"></a>1. 原理与实现</h1><p>状态模式一般用来实现状态机，常常用在游戏，工作流引擎等系统开发当中。</p><p>做法是将状态，事件，以及动作都放置到不同的类当中，通过接口与继承，来实现各个方法，其中共享变量可以作为输入传入。 </p><h1 id="2-以有限状态机的实现为例"><a href="#2-以有限状态机的实现为例" class="headerlink" title="2. 以有限状态机的实现为例"></a>2. 以有限状态机的实现为例</h1><ul><li>有限状态机<ul><li>Finite State Machine</li><li>组成部分<ul><li>状态</li><li>事件/ 转移条件<ul><li>触发状态的转移</li><li>动作的执行</li></ul></li><li>动作</li></ul></li></ul></li></ul><p>以下面的状态转移图为例： </p><p><img src="https://i.loli.net/2020/07/21/jzSQHTRxkybDBYE.png" alt="状态转移图"></p><h2 id="2-1-分支逻辑法实现"><a href="#2-1-分支逻辑法实现" class="headerlink" title="2.1 分支逻辑法实现"></a>2.1 分支逻辑法实现</h2><p>会包含大量的if-else语句</p><pre><code>public class MarioStateMachine {  private int score;  private State currentState;  public MarioStateMachine() {    this.score = 0;    this.currentState = State.SMALL;  }  public void obtainMushRoom() {    if (currentState.equals(State.SMALL)) {      this.currentState = State.SUPER;      this.score += 100;    }  }  public void obtainCape() {    if (currentState.equals(State.SMALL) || currentState.equals(State.SUPER) ) {      this.currentState = State.CAPE;      this.score += 200;    }  }  public void obtainFireFlower() {    if (currentState.equals(State.SMALL) || currentState.equals(State.SUPER) ) {      this.currentState = State.FIRE;      this.score += 300;    }  }  public void meetMonster() {    if (currentState.equals(State.SUPER)) {      this.currentState = State.SMALL;      this.score -= 100;      return;    }    if (currentState.equals(State.CAPE)) {      this.currentState = State.SMALL;      this.score -= 200;      return;    }    if (currentState.equals(State.FIRE)) {      this.currentState = State.SMALL;      this.score -= 300;      return;    }  }  public int getScore() {    return this.score;  }  public State getCurrentState() {    return this.currentState;  }}</code></pre><h2 id="2-2-查表法"><a href="#2-2-查表法" class="headerlink" title="2.2 查表法"></a>2.2 查表法</h2><p><img src="https://i.loli.net/2020/07/21/127jeqv5CwsIWKP.png" alt="查表法.png"></p><p>使用一张二维表来表示状态机，纵向表示当前状态，横向表示事件，值表示当前状态经过事件以后，转移到的新状态和其执行的动作</p><pre><code>public enum Event {  GOT_MUSHROOM(0),  GOT_CAPE(1),  GOT_FIRE(2),  MET_MONSTER(3);  private int value;  private Event(int value) {    this.value = value;  }  public int getValue() {    return this.value;  }}public class MarioStateMachine {  private int score;  private State currentState;  private static final State[][] transitionTable = {          {SUPER, CAPE, FIRE, SMALL},          {SUPER, CAPE, FIRE, SMALL},          {CAPE, CAPE, CAPE, SMALL},          {FIRE, FIRE, FIRE, SMALL}  };  private static final int[][] actionTable = {          {+100, +200, +300, +0},          {+0, +200, +300, -100},          {+0, +0, +0, -200},          {+0, +0, +0, -300}  };  public MarioStateMachine() {    this.score = 0;    this.currentState = State.SMALL;  }  public void obtainMushRoom() {    executeEvent(Event.GOT_MUSHROOM);  }  public void obtainCape() {    executeEvent(Event.GOT_CAPE);  }  public void obtainFireFlower() {    executeEvent(Event.GOT_FIRE);  }  public void meetMonster() {    executeEvent(Event.MET_MONSTER);  }  private void executeEvent(Event event) {    int stateValue = currentState.getValue();    int eventValue = event.getValue();    this.currentState = transitionTable[stateValue][eventValue];    this.score = actionTable[stateValue][eventValue];  }  public int getScore() {    return this.score;  }  public State getCurrentState() {    return this.currentState;  }}</code></pre><h2 id="2-3-状态模式"><a href="#2-3-状态模式" class="headerlink" title="2.3 状态模式"></a>2.3 状态模式</h2><p>当要执行的动作是比较复杂的一系列逻辑操作的时候，我们就无法使用二维数组来表示了。状态模式是将事件触发的状态转移和动作执行来拆分到不同的状态类当中，来避免分支判断逻辑。</p><pre><code>public interface IMario {  State getName();  void obtainMushRoom(MarioStateMachine stateMachine);  void obtainCape(MarioStateMachine stateMachine);  void obtainFireFlower(MarioStateMachine stateMachine);  void meetMonster(MarioStateMachine stateMachine);}public class SmallMario implements IMario {  private static final SmallMario instance = new SmallMario();  private SmallMario() {}  public static SmallMario getInstance() {    return instance;  }  @Override  public State getName() {    return State.SMALL;  }  @Override  public void obtainMushRoom(MarioStateMachine stateMachine) {    stateMachine.setCurrentState(SuperMario.getInstance());    stateMachine.setScore(stateMachine.getScore() + 100);  }  @Override  public void obtainCape(MarioStateMachine stateMachine) {    stateMachine.setCurrentState(CapeMario.getInstance());    stateMachine.setScore(stateMachine.getScore() + 200);  }  @Override  public void obtainFireFlower(MarioStateMachine stateMachine) {    stateMachine.setCurrentState(FireMario.getInstance());    stateMachine.setScore(stateMachine.getScore() + 300);  }  @Override  public void meetMonster(MarioStateMachine stateMachine) {    // do nothing...  }}// 省略SuperMario、CapeMario、FireMario类...public class MarioStateMachine {  private int score;  private IMario currentState;  public MarioStateMachine() {    this.score = 0;    this.currentState = SmallMario.getInstance();  }  public void obtainMushRoom() {    this.currentState.obtainMushRoom(this);  }  public void obtainCape() {    this.currentState.obtainCape(this);  }  public void obtainFireFlower() {    this.currentState.obtainFireFlower(this);  }  public void meetMonster() {    this.currentState.meetMonster(this);  }  public int getScore() {    return this.score;  }  public State getCurrentState() {    return this.currentState.getName();  }  public void setScore(int score) {    this.score = score;  }  public void setCurrentState(IMario currentState) {    this.currentState = currentState;  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 状态模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-行为型-职责链模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E8%81%8C%E8%B4%A3%E9%93%BE%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E8%81%8C%E8%B4%A3%E9%93%BE%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-原理与实现"><a href="#1-原理与实现" class="headerlink" title="1. 原理与实现"></a>1. 原理与实现</h1><ul><li>职责链模式<ul><li>Chian of Responsibility Design Pattern </li><li>Avoid coupling the sender of a request to its receiver by giving more than one object a chance to hadle the request. Chain the receiving objects and pass the request along the chain until an object handles it. </li><li>将请求的发送和接收解耦，让多个接收对象都有机会处理这个请求。将这些接收对象串成一条链，并沿着这条链传递这个请求，直到链上的某个接收对象能够处理它为止</li><li>在职责链模式当中，多个处理器依次处理同一个请求，一个请求先经过A处理器处理，再把请求传递给B处理器，B处理器处理完以后再传递给C处理器。各个处理器之间形成了一个链条，链条上的每个处理器各自承担各自的处理职责，所以叫做职责链模式。</li></ul></li></ul><h2 id="1-1-使用链表实现HandlerChain"><a href="#1-1-使用链表实现HandlerChain" class="headerlink" title="1.1 使用链表实现HandlerChain"></a>1.1 使用链表实现HandlerChain</h2><ul><li>Handler是所有处理器的抽象父类</li><li>handle()是抽象方法</li><li>每个具体的处理器类的handle()函数结构会比较类似，如果能处理请求，则进行处理；如果不能，则交由后面的处理器来进行处理</li><li>HandlerChain是处理器链，从数据结构来看，是一个记录了链头、链尾的链表。</li></ul><p>public abstract class Handler {<br>  protected Handler successor = null;</p><p>  public void setSuccessor(Handler successor) {<br>    this.successor = successor;<br>  }</p><p>  public final void handle() {<br>    boolean handled = doHandle();</p><pre><code>if (successor != null &amp;&amp; !handled) {    successor.handle();}</code></pre><p>  }<br>  public abstract boolean doHandle();<br>}</p><p>public class HandlerA extends Handler {<br>  @Override<br>  public void doHandle() {<br>    boolean handled = false;<br>    //…<br>    return handled;<br>  }<br>}</p><p>public class HandlerB extends Handler {<br>  @Override<br>  public void doHandle() {<br>    boolean handled = false;<br>    //…<br>    return handled;<br>  }<br>}</p><p>public class HandlerChain {<br>  private Handler head = null;<br>  private Handler tail = null;</p><p>  public void addHandler(Handler handler) {<br>    handler.setSuccessor(null);</p><pre><code>if (head == null) {  head = handler;  tail = handler;  return;}tail.setSuccessor(handler);tail = handler;</code></pre><p>  }</p><p>  public void handle() {<br>    if (head != null) {<br>      head.handle();<br>    }<br>  }<br>}</p><p>// 使用举例<br>public class Application {<br>  public static void main(String[] args) {<br>    HandlerChain chain = new HandlerChain();<br>    chain.addHandler(new HandlerA());<br>    chain.addHandler(new HandlerB());<br>    chain.handle();<br>  }<br>}</p><h2 id="1-2-使用数组实现HandlerChain"><a href="#1-2-使用数组实现HandlerChain" class="headerlink" title="1.2 使用数组实现HandlerChain"></a>1.2 使用数组实现HandlerChain</h2><pre><code>public interface IHandler {  boolean handle();}public class HandlerA implements IHandler {  @Override  public boolean handle() {    boolean handled = false;    //...    return handled;  }}public class HandlerB implements IHandler {  @Override  public boolean handle() {    boolean handled = false;    //...    return handled;  }}public class HandlerChain {  private List&lt;IHandler&gt; handlers = new ArrayList&lt;&gt;();  public void addHandler(IHandler handler) {    this.handlers.add(handler);  }  public void handle() {    for (IHandler handler : handlers) {      boolean handled = handler.handle();      if (handled) {        break;      }    }  }}// 使用举例public class Application {  public static void main(String[] args) {    HandlerChain chain = new HandlerChain();    chain.addHandler(new HandlerA());    chain.addHandler(new HandlerB());    chain.handle();  }}</code></pre><h1 id="2-过滤器、拦截器的实现"><a href="#2-过滤器、拦截器的实现" class="headerlink" title="2. 过滤器、拦截器的实现"></a>2. 过滤器、拦截器的实现</h1><p>职责链模式最长建的使用位置是在框架的开发当中，比如过滤器和拦截器。</p><h2 id="2-1-Servlet-Filter"><a href="#2-1-Servlet-Filter" class="headerlink" title="2.1 Servlet Filter"></a>2.1 Servlet Filter</h2><ul><li><p>实现堆HTTP请求的过滤功能</p><ul><li>鉴权</li><li>限流</li><li>记录日志</li><li>验证参数等</li></ul></li><li><p>在实际使用当中，定义一个实现<code>javax.servlet.Filter</code>接口的过滤器类，并且将其配置在web.xml配置文件当中。Web容器启动的时候，会读取web.xml中的配置，创建过滤器对象。</p></li><li><p>当有请求到来的时候，就会先经过过滤器，然后经由Servlet来进行处理</p></li></ul><pre><code>public class LogFilter implements Filter {  @Override  public void init(FilterConfig filterConfig) throws ServletException {    // 在创建Filter时自动调用，    // 其中filterConfig包含这个Filter的配置参数，比如name之类的（从配置文件中读取的）  }  @Override  public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {    System.out.println(&quot;拦截客户端发送来的请求.&quot;);    chain.doFilter(request, response);    System.out.println(&quot;拦截发送给客户端的响应.&quot;);  }  @Override  public void destroy() {    // 在销毁Filter时自动调用  }}// 在web.xml配置文件中如下配置：&lt;filter&gt;  &lt;filter-name&gt;logFilter&lt;/filter-name&gt;  &lt;filter-class&gt;com.xzg.cd.LogFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt;    &lt;filter-name&gt;logFilter&lt;/filter-name&gt;    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;</code></pre><ul><li>FilterChain的实现</li></ul><pre><code>public final class ApplicationFilterChain implements FilterChain {  private int pos = 0; //当前执行到了哪个filter  private int n; //filter的个数  private ApplicationFilterConfig[] filters;  private Servlet servlet;  @Override  public void doFilter(ServletRequest request, ServletResponse response) {    if (pos &lt; n) {      ApplicationFilterConfig filterConfig = filters[pos++];      Filter filter = filterConfig.getFilter();      filter.doFilter(request, response, this);    } else {      // filter都处理完毕后，执行servlet      servlet.service(request, response);    }  }  public void addFilter(ApplicationFilterConfig filterConfig) {    for (ApplicationFilterConfig filter:filters)      if (filter==filterConfig)         return;    if (n == filters.length) {//扩容      ApplicationFilterConfig[] newFilters = new ApplicationFilterConfig[n + INCREMENT];      System.arraycopy(filters, 0, newFilters, 0, n);      filters = newFilters;    }    filters[n++] = filterConfig;  }}</code></pre><h2 id="2-2-Spring-Interceptor"><a href="#2-2-Spring-Interceptor" class="headerlink" title="2.2 Spring Interceptor"></a>2.2 Spring Interceptor</h2><p>有Spring MVC框架来提供实现，客户端发送的请求，会先经过Servlet Filter，然后在经过Spring Interceptor，最后再到达具体的业务代码当中。 </p><pre><code>// 代码实现public class LogInterceptor implements HandlerInterceptor {  @Override  public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {    System.out.println(&quot;拦截客户端发送来的请求.&quot;);    return true; // 继续后续的处理  }  @Override  public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {    System.out.println(&quot;拦截发送给客户端的响应.&quot;);  }  @Override  public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {    System.out.println(&quot;这里总是被执行.&quot;);  }}//在Spring MVC配置文件中配置interceptors&lt;mvc:interceptors&gt;   &lt;mvc:interceptor&gt;       &lt;mvc:mapping path=&quot;/*&quot;/&gt;       &lt;bean class=&quot;com.xzg.cd.LogInterceptor&quot; /&gt;   &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;</code></pre><ul><li>Spring Interceptor底层实现<ul><li>基于职责链模式</li><li>使用HandlerExecutionChain来处理</li></ul></li></ul><pre><code>public class HandlerExecutionChain { private final Object handler; private HandlerInterceptor[] interceptors; public void addInterceptor(HandlerInterceptor interceptor) {  initInterceptorList().add(interceptor); } boolean applyPreHandle(HttpServletRequest request, HttpServletResponse response) throws Exception {  HandlerInterceptor[] interceptors = getInterceptors();  if (!ObjectUtils.isEmpty(interceptors)) {   for (int i = 0; i &lt; interceptors.length; i++) {    HandlerInterceptor interceptor = interceptors[i];    if (!interceptor.preHandle(request, response, this.handler)) {     triggerAfterCompletion(request, response, null);     return false;    }   }  }  return true; } void applyPostHandle(HttpServletRequest request, HttpServletResponse response, ModelAndView mv) throws Exception {  HandlerInterceptor[] interceptors = getInterceptors();  if (!ObjectUtils.isEmpty(interceptors)) {   for (int i = interceptors.length - 1; i &gt;= 0; i--) {    HandlerInterceptor interceptor = interceptors[i];    interceptor.postHandle(request, response, this.handler, mv);   }  } } void triggerAfterCompletion(HttpServletRequest request, HttpServletResponse response, Exception ex)   throws Exception {  HandlerInterceptor[] interceptors = getInterceptors();  if (!ObjectUtils.isEmpty(interceptors)) {   for (int i = this.interceptorIndex; i &gt;= 0; i--) {    HandlerInterceptor interceptor = interceptors[i];    try {     interceptor.afterCompletion(request, response, this.handler, ex);    } catch (Throwable ex2) {     logger.error(&quot;HandlerInterceptor.afterCompletion threw exception&quot;, ex2);    }   }  } }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 职责链模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-行为型-策略模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>策略模式，用于避免冗长的if else或者switch分支判断，并且可以像模板模式那样提供框架的扩展点。</p><h1 id="1-原理与实现"><a href="#1-原理与实现" class="headerlink" title="1. 原理与实现"></a>1. 原理与实现</h1><ul><li>策略模式<ul><li>Strategy Design Pattern </li><li>Define a family of algorithms, encapsulate each one, and make them interchangeable. Strategy lets the algorithm vary independently from clients that use it. </li><li>对策略的定义，创建和使用进行解耦</li></ul></li></ul><h2 id="1-1-策略的定义"><a href="#1-1-策略的定义" class="headerlink" title="1.1 策略的定义"></a>1.1 策略的定义</h2><ul><li>策略接口</li><li>一组实现了这个接口的策略类</li></ul><pre><code>public interface Strategy {  void algorithmInterface();}public class ConcreteStrategyA implements Strategy {  @Override  public void  algorithmInterface() {    //具体的算法...  }}public class ConcreteStrategyB implements Strategy {  @Override  public void  algorithmInterface() {    //具体的算法...  }}</code></pre><h2 id="1-2-策略的创建"><a href="#1-2-策略的创建" class="headerlink" title="1.2 策略的创建"></a>1.2 策略的创建</h2><ul><li><p>策略在使用的时候需要根据类型来判断创建哪个策略来使用</p></li><li><p>因此，为了封装创建逻辑，需要对客户端代码屏蔽创建细节</p><p>  public class StrategyFactory {</p><pre><code>private static final Map&lt;String, Strategy&gt; strategies = new HashMap&lt;&gt;();static {  strategies.put(&quot;A&quot;, new ConcreteStrategyA());  strategies.put(&quot;B&quot;, new ConcreteStrategyB());}public static Strategy getStrategy(String type) {  if (type == null || type.isEmpty()) {    throw new IllegalArgumentException(&quot;type should not be empty.&quot;);  }  return strategies.get(type);}</code></pre><p>  }</p></li></ul><p>这里是需要根据策略是否是有状态的，根据业务场景的需要，来看是否需要返回新创建的对象，或者来复用已经创建好的对象。</p><pre><code>// 返回新创建好的对象的范例public class StrategyFactory {  public static Strategy getStrategy(String type) {    if (type == null || type.isEmpty()) {      throw new IllegalArgumentException(&quot;type should not be empty.&quot;);    }    if (type.equals(&quot;A&quot;)) {      return new ConcreteStrategyA();    } else if (type.equals(&quot;B&quot;)) {      return new ConcreteStrategyB();    }    return null;  }}</code></pre><h2 id="1-3-策略的使用"><a href="#1-3-策略的使用" class="headerlink" title="1.3 策略的使用"></a>1.3 策略的使用</h2><p>使用的时候一般是运行时动态来决定使用哪一种策略。即根据配置，用户的输入，计算结果等因素，来决定 </p><pre><code>// 策略接口：EvictionStrategy// 策略类：LruEvictionStrategy、FifoEvictionStrategy、LfuEvictionStrategy...// 策略工厂：EvictionStrategyFactorypublic class UserCache {  private Map&lt;String, User&gt; cacheData = new HashMap&lt;&gt;();  private EvictionStrategy eviction;  public UserCache(EvictionStrategy eviction) {    this.eviction = eviction;  }  //...}// 运行时动态确定，根据配置文件的配置决定使用哪种策略public class Application {  public static void main(String[] args) throws Exception {    EvictionStrategy evictionStrategy = null;    Properties props = new Properties();    props.load(new FileInputStream(&quot;./config.properties&quot;));    String type = props.getProperty(&quot;eviction_type&quot;);    evictionStrategy = EvictionStrategyFactory.getEvictionStrategy(type);    UserCache userCache = new UserCache(evictionStrategy);    //...  }}// 非运行时动态确定，在代码中指定使用哪种策略public class Application {  public static void main(String[] args) {    //...    EvictionStrategy evictionStrategy = new LruEvictionStrategy();    UserCache userCache = new UserCache(evictionStrategy);    //...  }}</code></pre><h1 id="2-实例"><a href="#2-实例" class="headerlink" title="2. 实例"></a>2. 实例</h1><h2 id="2-1-策略模式避免分支判断"><a href="#2-1-策略模式避免分支判断" class="headerlink" title="2.1 策略模式避免分支判断"></a>2.1 策略模式避免分支判断</h2><pre><code>public class OrderService {  public double discount(Order order) {    double discount = 0.0;    OrderType type = order.getType();    if (type.equals(OrderType.NORMAL)) { // 普通订单      //...省略折扣计算算法代码    } else if (type.equals(OrderType.GROUPON)) { // 团购订单      //...省略折扣计算算法代码    } else if (type.equals(OrderType.PROMOTION)) { // 促销订单      //...省略折扣计算算法代码    }    return discount;  }}// 策略的定义public interface DiscountStrategy {  double calDiscount(Order order);}// 省略NormalDiscountStrategy、GrouponDiscountStrategy、PromotionDiscountStrategy类代码...// 策略的创建public class DiscountStrategyFactory {  private static final Map&lt;OrderType, DiscountStrategy&gt; strategies = new HashMap&lt;&gt;();  static {    strategies.put(OrderType.NORMAL, new NormalDiscountStrategy());    strategies.put(OrderType.GROUPON, new GrouponDiscountStrategy());    strategies.put(OrderType.PROMOTION, new PromotionDiscountStrategy());  }  public static DiscountStrategy getDiscountStrategy(OrderType type) {    return strategies.get(type);  }}// 策略的使用public class OrderService {  public double discount(Order order) {    OrderType type = order.getType();    DiscountStrategy discountStrategy = DiscountStrategyFactory.getDiscountStrategy(type);    return discountStrategy.calDiscount(order);  }}</code></pre><h2 id="2-2-根据大小对文件排序"><a href="#2-2-根据大小对文件排序" class="headerlink" title="2.2 根据大小对文件排序"></a>2.2 根据大小对文件排序</h2><ul><li><p>对文件进行排序</p><ul><li>整型数</li><li>逗号间隔</li></ul></li><li><p>100GB大小的话</p><ul><li>利用外部排序算法  – MapReduce框架</li></ul></li></ul><pre><code>public class SortAlgFactory {  private static final Map&lt;String, ISortAlg&gt; algs = new HashMap&lt;&gt;();  static {    algs.put(&quot;QuickSort&quot;, new QuickSort());    algs.put(&quot;ExternalSort&quot;, new ExternalSort());    algs.put(&quot;ConcurrentExternalSort&quot;, new ConcurrentExternalSort());    algs.put(&quot;MapReduceSort&quot;, new MapReduceSort());  }  public static ISortAlg getSortAlg(String type) {    if (type == null || type.isEmpty()) {      throw new IllegalArgumentException(&quot;type should not be empty.&quot;);    }    return algs.get(type);  }}public class Sorter {  private static final long GB = 1000 * 1000 * 1000;  public void sortFile(String filePath) {    // 省略校验逻辑    File file = new File(filePath);    long fileSize = file.length();    ISortAlg sortAlg;    if (fileSize &lt; 6 * GB) { // [0, 6GB)      sortAlg = SortAlgFactory.getSortAlg(&quot;QuickSort&quot;);    } else if (fileSize &lt; 10 * GB) { // [6GB, 10GB)      sortAlg = SortAlgFactory.getSortAlg(&quot;ExternalSort&quot;);    } else if (fileSize &lt; 100 * GB) { // [10GB, 100GB)      sortAlg = SortAlgFactory.getSortAlg(&quot;ConcurrentExternalSort&quot;);    } else { // [100GB, ~)      sortAlg = SortAlgFactory.getSortAlg(&quot;MapReduceSort&quot;);    }    sortAlg.sort(filePath);  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 策略模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Intellij IDEA tips and tricks</title>
      <link href="/Intellij-IDEA-tips-and-tricks/"/>
      <url>/Intellij-IDEA-tips-and-tricks/</url>
      
        <content type="html"><![CDATA[<ol><li><p>Magic shortcut for almost everything<br>Alt + Enter </p></li><li><p>Jump to next error  </p></li></ol><p>F2 </p><ol start="3"><li><p>Project window<br>cmd + 1 </p></li><li><p>focus on editor  </p></li></ol><p>esc </p><ol start="5"><li>The recent file box  </li></ol><p>cmd E </p><ol start="6"><li>Go to declaration </li></ol><p>cmd + B </p><ol start="7"><li>Find usage </li></ol><p>Alt + F7 </p><ol start="8"><li>Run Anything </li></ol><p>double ctrl </p><p>*<em>9. Extend/ shrink selection *</em></p><p>option + up arrow </p><p>option + down arrow </p><ol start="10"><li>Add/ Remove comments</li></ol><p>cmd + / </p><ol start="11"><li>Complete current statement </li></ol><p>shift + cmd + enter </p><ol start="12"><li>Reformat file </li></ol><p>alt + cmd + l</p><ol start="13"><li>Refactor </li></ol><p>ctrl + t </p><p>Show all the refactor option </p><ol start="14"><li>Find action </li></ol><p>shift + cmd + A </p><ol start="15"><li>Search everywhere </li></ol><p>shift + shift </p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.youtube.com/watch?v=QYO5_riePOQ" target="_blank" rel="noopener">https://www.youtube.com/watch?v=QYO5_riePOQ</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-行为型-模板模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-原理与实现"><a href="#1-原理与实现" class="headerlink" title="1. 原理与实现"></a>1. 原理与实现</h1><ul><li>模板方法设计模式<ul><li>Template Method Design Pattern </li><li>Define the skeleton of an algorithm in an operation, deferring some steps to subclasses. Template method lets subclasses redefine certain steps of an algorithm without changing the algorithm’s structure </li><li>在一个方法中定义一个算法股价，并将某些步骤推迟到子类当中进行实现，模板方法模式可以让子类在不改变算法整体结构的情况下，重新定义算法中的某些不好走。</li></ul></li></ul><p>实现的基本方式就是设置一个抽象类，对于不想被子类重写的方法可以加上final关键字，其余的可以设置为抽象方法，让子类来实现。</p><pre><code>public abstract class AbstractClass {  public final void templateMethod() {    //...    method1();    //...    method2();    //...  }  protected abstract void method1();  protected abstract void method2();}public class ConcreteClass1 extends AbstractClass {  @Override  protected void method1() {    //...  }  @Override  protected void method2() {    //...  }}public class ConcreteClass2 extends AbstractClass {  @Override  protected void method1() {    //...  }  @Override  protected void method2() {    //...  }}AbstractClass demo = ConcreteClass1();demo.templateMethod();</code></pre><h1 id="2-功能实现的例子"><a href="#2-功能实现的例子" class="headerlink" title="2. 功能实现的例子"></a>2. 功能实现的例子</h1><h2 id="2-1-以复用为目的"><a href="#2-1-以复用为目的" class="headerlink" title="2.1 以复用为目的"></a>2.1 以复用为目的</h2><ol><li><p>InputStream 类的实现</p><p> public abstract class InputStream implements Closeable {<br>   //…省略其他代码…</p><p>   public int read(byte b[], int off, int len) throws IOException {</p><pre><code> if (b == null) {   throw new NullPointerException(); } else if (off &lt; 0 || len &lt; 0 || len &gt; b.length - off) {   throw new IndexOutOfBoundsException(); } else if (len == 0) {   return 0; } int c = read(); if (c == -1) {   return -1; } b[off] = (byte)c; int i = 1; try {   for (; i &lt; len ; i++) {     c = read();     if (c == -1) {       break;     }     b[off + i] = (byte)c;   } } catch (IOException ee) { } return i;</code></pre><p>   }</p><p>   // 在这里定义了一个可以供子类实现的抽象方法<br>   public abstract int read() throws IOException;<br> }</p><p> public class ByteArrayInputStream extends InputStream {<br>   //…省略其他代码…</p><p>   @Override<br>   public synchronized int read() {</p><pre><code> return (pos &lt; count) ? (buf[pos++] &amp; 0xff) : -1;</code></pre><p>   }<br> }</p></li></ol><ol start="2"><li>AbstractList的实现</li></ol><pre><code>public boolean addAll(int index, Collection&lt;? extends E&gt; c) {    rangeCheckForAdd(index);    boolean modified = false;    for (E e : c) {        add(index++, e);        modified = true;    }    return modified;}public void add(int index, E element) {    throw new UnsupportedOperationException();}</code></pre><h2 id="2-2-以扩展为目的"><a href="#2-2-以扩展为目的" class="headerlink" title="2.2 以扩展为目的"></a>2.2 以扩展为目的</h2><ol><li>Java Servlet</li></ol><p>抛开框架直接使用Servlet做开发的话，Servlet在接收到请求之后，会根据URL和Servlet的映射关系，找到对应的Servlet，然后来执行它的service()方法。service方法定义在父类HttpServelet当中，会调用doGet()还有doPost()方法。</p><p>为了实现上述的整个流程，我们需要继承HttpServlet，重新实现我们自己的doGet()以及doPost()方法。</p><pre><code>public class HelloServlet extends HttpServlet {  @Override  protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {    this.doPost(req, resp);  }  @Override  protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {    resp.getWriter().write(&quot;Hello World.&quot;);  }}// 存储映射关系的xml，也可以使用annotation来实现映射&lt;servlet&gt;    &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt;    &lt;servlet-class&gt;com.xzg.cd.HelloServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;    &lt;servlet-name&gt;HelloServlet&lt;/servlet-name&gt;    &lt;url-pattern&gt;/hello&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;public void service(ServletRequest req, ServletResponse res)    throws ServletException, IOException{    HttpServletRequest  request;    HttpServletResponse response;    if (!(req instanceof HttpServletRequest &amp;&amp;            res instanceof HttpServletResponse)) {        throw new ServletException(&quot;non-HTTP request or response&quot;);    }    request = (HttpServletRequest) req;    response = (HttpServletResponse) res;    service(request, response);}protected void service(HttpServletRequest req, HttpServletResponse resp)    throws ServletException, IOException{    String method = req.getMethod();    if (method.equals(METHOD_GET)) {        long lastModified = getLastModified(req);        if (lastModified == -1) {            // servlet doesn&#39;t support if-modified-since, no reason            // to go through further expensive logic            doGet(req, resp);        } else {            long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE);            if (ifModifiedSince &lt; lastModified) {                // If the servlet mod time is later, call doGet()                // Round down to the nearest second for a proper compare                // A ifModifiedSince of -1 will always be less                maybeSetLastModified(resp, lastModified);                doGet(req, resp);            } else {                resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED);            }        }    } else if (method.equals(METHOD_HEAD)) {        long lastModified = getLastModified(req);        maybeSetLastModified(resp, lastModified);        doHead(req, resp);    } else if (method.equals(METHOD_POST)) {        doPost(req, resp);    } else if (method.equals(METHOD_PUT)) {        doPut(req, resp);    } else if (method.equals(METHOD_DELETE)) {        doDelete(req, resp);    } else if (method.equals(METHOD_OPTIONS)) {        doOptions(req,resp);    } else if (method.equals(METHOD_TRACE)) {        doTrace(req,resp);    } else {        String errMsg = lStrings.getString(&quot;http.method_not_implemented&quot;);        Object[] errArgs = new Object[1];        errArgs[0] = method;        errMsg = MessageFormat.format(errMsg, errArgs);        resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg);    }}</code></pre><ol start="2"><li>JUnit TestCase</li></ol><p>Junit定义的功能扩展点为：</p><ul><li>setUp() </li><li>tearDown()</li><li>etc.</li></ul><p>写的测试类都是继承框架提供的testCase类，在这个类当中，runBare()函数是模板方法，定义了执行测试用例的整体流程:先执行setUp()做准备工作，然后执行runTest()运行真正的测试代码，最后执行tearDown()做扫尾工作。</p><pre><code>public abstract class TestCase extends Assert implements Test {  public void runBare() throws Throwable {    Throwable exception = null;    setUp();    try {      runTest();    } catch (Throwable running) {      exception = running;    } finally {      try {        tearDown();      } catch (Throwable tearingDown) {        if (exception == null) exception = tearingDown;      }    }    if (exception != null) throw exception;  }  /**  * Sets up the fixture, for example, open a network connection.  * This method is called before a test is executed.  */  protected void setUp() throws Exception {  }  /**  * Tears down the fixture, for example, close a network connection.  * This method is called after a test is executed.  */  protected void tearDown() throws Exception {  }}</code></pre><h2 id="2-3-模板模式对比Callback函数"><a href="#2-3-模板模式对比Callback函数" class="headerlink" title="2.3 模板模式对比Callback函数"></a>2.3 模板模式对比Callback函数</h2><p>回调函数可以起到和模板模式相同的作用，回调是一种双向调用关系</p><p>A 类事先注册某个函数 F 到 B 类，A 类在调用 B 类的 P 函数的时候，B 类反过来调用 A 类注册给它的 F 函数。这里的 F 函数就是“回调函数”。A 调用 B，B 反过来又调用 A，这种调用机制就叫作“回调”。</p><p>回调分为同步回调和异步回调，同步回调指函数返回之前执行回调函数；异步回调指函数返回之后执行回调函数。</p><pre><code>public interface ICallback {  void methodToCallback();}public class BClass {  public void process(ICallback callback) {    //...    callback.methodToCallback();    //...  }}public class AClass {  public static void main(String[] args) {    BClass b = new BClass();    b.process(new ICallback() { //回调对象      @Override      public void methodToCallback() {        System.out.println(&quot;Call back me.&quot;);      }    });  }}</code></pre><ul><li>使用Callback函数实现的JDBCTemplate</li></ul><pre><code>@Overridepublic &lt;T&gt; List&lt;T&gt; query(String sql, RowMapper&lt;T&gt; rowMapper) throws DataAccessException { return query(sql, new RowMapperResultSetExtractor&lt;T&gt;(rowMapper));}@Overridepublic &lt;T&gt; T query(final String sql, final ResultSetExtractor&lt;T&gt; rse) throws DataAccessException { Assert.notNull(sql, &quot;SQL must not be null&quot;); Assert.notNull(rse, &quot;ResultSetExtractor must not be null&quot;); if (logger.isDebugEnabled()) {  logger.debug(&quot;Executing SQL query [&quot; + sql + &quot;]&quot;); } class QueryStatementCallback implements StatementCallback&lt;T&gt;, SqlProvider {  @Override  public T doInStatement(Statement stmt) throws SQLException {   ResultSet rs = null;   try {    rs = stmt.executeQuery(sql);    ResultSet rsToUse = rs;    if (nativeJdbcExtractor != null) {     rsToUse = nativeJdbcExtractor.getNativeResultSet(rs);    }    return rse.extractData(rsToUse);   }   finally {    JdbcUtils.closeResultSet(rs);   }  }  @Override  public String getSql() {   return sql;  } } return execute(new QueryStatementCallback());}@Overridepublic &lt;T&gt; T execute(StatementCallback&lt;T&gt; action) throws DataAccessException { Assert.notNull(action, &quot;Callback object must not be null&quot;); Connection con = DataSourceUtils.getConnection(getDataSource()); Statement stmt = null; try {  Connection conToUse = con;  if (this.nativeJdbcExtractor != null &amp;&amp;    this.nativeJdbcExtractor.isNativeConnectionNecessaryForNativeStatements()) {   conToUse = this.nativeJdbcExtractor.getNativeConnection(con);  }  stmt = conToUse.createStatement();  applyStatementSettings(stmt);  Statement stmtToUse = stmt;  if (this.nativeJdbcExtractor != null) {   stmtToUse = this.nativeJdbcExtractor.getNativeStatement(stmt);  }  T result = action.doInStatement(stmtToUse);  handleWarnings(stmt);  return result; } catch (SQLException ex) {  // Release Connection early, to avoid potential connection pool deadlock  // in the case when the exception translator hasn&#39;t been initialized yet.  JdbcUtils.closeStatement(stmt);  stmt = null;  DataSourceUtils.releaseConnection(con, getDataSource());  con = null;  throw getExceptionTranslator().translate(&quot;StatementCallback&quot;, getSql(action), ex); } finally {  JdbcUtils.closeStatement(stmt);  DataSourceUtils.releaseConnection(con, getDataSource()); }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 模板模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-行为型-观察者模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A1%8C%E4%B8%BA%E5%9E%8B-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<ul><li>创建型设计模式<ul><li>解决对象创建的问题</li></ul></li></ul><ul><li><p>结构型设计模式</p><ul><li>解决类或者对象的组合或组装问题</li></ul></li><li><p>行为型设计模式</p><ul><li>解决类或对象之间的交互问题</li></ul></li></ul><h1 id="1-观察者模式原理"><a href="#1-观察者模式原理" class="headerlink" title="1. 观察者模式原理"></a>1. 观察者模式原理</h1><p>根据应用场景的不同，观察者模式是会有不同的代码实现的<br>    + 同步阻塞<br>    + 异步非阻塞<br>    + 进程内的实现方式<br>    + 跨进程的实现方式</p><ul><li>观察者模式  Observer Design Pattern<ul><li>发布订阅模式 Publish - Subscribe Design Pattern </li><li>Define a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically. </li><li>角色划分<ul><li>observable and observer </li><li>publisher and subscriber </li><li>producer and consumer </li><li>subject and observer </li><li>dispatcher and listener </li><li>eventEmitter and EventListener </li></ul></li></ul></li></ul><pre><code>// Example public interface RegObserver {  void handleRegSuccess(long userId);}public class RegPromotionObserver implements RegObserver {  private PromotionService promotionService; // 依赖注入  @Override  public void handleRegSuccess(long userId) {    promotionService.issueNewUserExperienceCash(userId);  }}public class RegNotificationObserver implements RegObserver {  private NotificationService notificationService;  @Override  public void handleRegSuccess(long userId) {    notificationService.sendInboxMessage(userId, &quot;Welcome...&quot;);  }}public class UserController {  private UserService userService; // 依赖注入  private List&lt;RegObserver&gt; regObservers = new ArrayList&lt;&gt;();  // 一次性设置好，之后也不可能动态的修改  public void setRegObservers(List&lt;RegObserver&gt; observers) {    regObservers.addAll(observers);  }  public Long register(String telephone, String password) {    //省略输入参数的校验代码    //省略userService.register()异常的try-catch代码    long userId = userService.register(telephone, password);    for (RegObserver observer : regObservers) {      observer.handleRegSuccess(userId);    }    return userId;  }}</code></pre><h1 id="2-探究异步非阻塞的EventBus框架"><a href="#2-探究异步非阻塞的EventBus框架" class="headerlink" title="2. 探究异步非阻塞的EventBus框架"></a>2. 探究异步非阻塞的EventBus框架</h1><h2 id="2-1-基本的异步非阻塞模式"><a href="#2-1-基本的异步非阻塞模式" class="headerlink" title="2.1 基本的异步非阻塞模式"></a>2.1 基本的异步非阻塞模式</h2><pre><code>// 第一种实现方式，其他类代码不变，就没有再重复罗列public class RegPromotionObserver implements RegObserver {  private PromotionService promotionService; // 依赖注入  @Override  public void handleRegSuccess(long userId) {    Thread thread = new Thread(new Runnable() {      @Override      public void run() {        promotionService.issueNewUserExperienceCash(userId);      }    });    thread.start();  }}// 第二种实现方式，其他类代码不变，就没有再重复罗列public class UserController {  private UserService userService; // 依赖注入  private List&lt;RegObserver&gt; regObservers = new ArrayList&lt;&gt;();  private Executor executor;  public UserController(Executor executor) {    this.executor = executor;  }  public void setRegObservers(List&lt;RegObserver&gt; observers) {    regObservers.addAll(observers);  }  public Long register(String telephone, String password) {    //省略输入参数的校验代码    //省略userService.register()异常的try-catch代码    long userId = userService.register(telephone, password);    for (RegObserver observer : regObservers) {      executor.execute(new Runnable() {        @Override        public void run() {          observer.handleRegSuccess(userId);        }      });    }    return userId;  }}</code></pre><ul><li><p>方法1 </p><ul><li>频繁创建销毁线程比较耗时</li><li>并且创建过多线程会导致堆栈溢出</li></ul></li><li><p>方法2 </p><ul><li>线程池，异步执行的逻辑耦合在了register()函数当中，维护成本会提高</li></ul></li></ul><h2 id="2-2-EventBus功能需求"><a href="#2-2-EventBus功能需求" class="headerlink" title="2.2 EventBus功能需求"></a>2.2 EventBus功能需求</h2><p>以google guava eventBus为例</p><pre><code>public class UserController {  private UserService userService; // 依赖注入  private EventBus eventBus;  private static final int DEFAULT_EVENTBUS_THREAD_POOL_SIZE = 20;  public UserController() {    //eventBus = new EventBus(); // 同步阻塞模式    eventBus = new AsyncEventBus(Executors.newFixedThreadPool(DEFAULT_EVENTBUS_THREAD_POOL_SIZE)); // 异步非阻塞模式  }  public void setRegObservers(List&lt;Object&gt; observers) {    for (Object observer : observers) {      eventBus.register(observer);    }  }  public Long register(String telephone, String password) {    //省略输入参数的校验代码    //省略userService.register()异常的try-catch代码    long userId = userService.register(telephone, password);    eventBus.post(userId);    return userId;  }}public class RegPromotionObserver {  private PromotionService promotionService; // 依赖注入  @Subscribe  public void handleRegSuccess(long userId) {    promotionService.issueNewUserExperienceCash(userId);  }}public class RegNotificationObserver {  private NotificationService notificationService;  @Subscribe  public void handleRegSuccess(long userId) {    notificationService.sendInboxMessage(userId, &quot;...&quot;);  }}</code></pre><ul><li>使用EventBus框架实现的观察者模式，大流程上相同，但是区别在于<ul><li>不用定义Observer接口了</li><li>任意类型的对象都可以注册到EventBus当中，通过<code>@Subscribe</code>注解来标明类当中哪个函数可以接收被观察者发送的消息</li></ul></li></ul><ul><li>EventBus, AsyncEventBus <ul><li>Guava EventBus 的所有可调用接口</li></ul></li></ul><pre><code>EventBus eventBus = new EventBus(); // 同步阻塞模式EventBus eventBus = new AsyncEventBus(Executors.newFixedThreadPool(8))；// 异步阻塞模式</code></pre><ul><li><p><code>register()</code>函数</p><ul><li>用来注册观察者</li><li>可以接受任何类型的观察者</li></ul></li><li><p><code>unregister()</code>函数</p><ul><li>删除某个观察者</li></ul></li><li><p><code>post()</code>函数</p><ul><li>用于给观察者发送消息</li></ul></li><li><p><code>@Subscribe</code>注解</p><ul><li>通过注解说明某个函数能够接收哪种类型的消息</li></ul></li></ul><p>最关键的一个数据结构是 Observer 注册表，记录了消息类型和可接收消息函数的对应关系。当调用 register() 函数注册观察者的时候，EventBus 通过解析 @Subscribe 注解，生成 Observer 注册表。当调用 post() 函数发送消息的时候，EventBus 通过注册表找到相应的可接收消息的函数，然后通过 Java 的反射语法来动态地创建对象、执行函数。对于同步阻塞模式，EventBus 在一个线程内依次执行相应的函数。对于异步非阻塞模式，EventBus 通过一个线程池来执行相应的函数。</p><h2 id="2-3-EventBus的实现"><a href="#2-3-EventBus的实现" class="headerlink" title="2.3 EventBus的实现"></a>2.3 EventBus的实现</h2><ol><li>Subscirbe 注解</li></ol><p>用于标明观察者中的哪个函数可以接收信息</p><pre><code>@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@Betapublic @interface Subscribe {}</code></pre><ol start="2"><li>ObserverAction</li></ol><p>ObserverAction类用来表示Subscribe注解的方法，其中target表示观察者类，method表示方法，主要用在ObserverRegistry观察者注册表当中。</p><pre><code>public class ObserverAction {  private Object target;  private Method method;  public ObserverAction(Object target, Method method) {    this.target = Preconditions.checkNotNull(target);    this.method = method;    this.method.setAccessible(true);  }  public void execute(Object event) { // event是method方法的参数    try {      method.invoke(target, event);    } catch (InvocationTargetException | IllegalAccessException e) {      e.printStackTrace();    }  }}</code></pre><ol start="3"><li>ObserverRegistry</li></ol><p>Observer注册表类，大量使用Java的反射语法</p><pre><code>public class ObserverRegistry {  private ConcurrentMap&lt;Class&lt;?&gt;, CopyOnWriteArraySet&lt;ObserverAction&gt;&gt; registry = new ConcurrentHashMap&lt;&gt;();  public void register(Object observer) {    Map&lt;Class&lt;?&gt;, Collection&lt;ObserverAction&gt;&gt; observerActions = findAllObserverActions(observer);    for (Map.Entry&lt;Class&lt;?&gt;, Collection&lt;ObserverAction&gt;&gt; entry : observerActions.entrySet()) {      Class&lt;?&gt; eventType = entry.getKey();      Collection&lt;ObserverAction&gt; eventActions = entry.getValue();      CopyOnWriteArraySet&lt;ObserverAction&gt; registeredEventActions = registry.get(eventType);      if (registeredEventActions == null) {        registry.putIfAbsent(eventType, new CopyOnWriteArraySet&lt;&gt;());        registeredEventActions = registry.get(eventType);      }      registeredEventActions.addAll(eventActions);    }  }  public List&lt;ObserverAction&gt; getMatchedObserverActions(Object event) {    List&lt;ObserverAction&gt; matchedObservers = new ArrayList&lt;&gt;();    Class&lt;?&gt; postedEventType = event.getClass();    for (Map.Entry&lt;Class&lt;?&gt;, CopyOnWriteArraySet&lt;ObserverAction&gt;&gt; entry : registry.entrySet()) {      Class&lt;?&gt; eventType = entry.getKey();      Collection&lt;ObserverAction&gt; eventActions = entry.getValue();      if (postedEventType.isAssignableFrom(eventType)) {        matchedObservers.addAll(eventActions);      }    }    return matchedObservers;  }  private Map&lt;Class&lt;?&gt;, Collection&lt;ObserverAction&gt;&gt; findAllObserverActions(Object observer) {    Map&lt;Class&lt;?&gt;, Collection&lt;ObserverAction&gt;&gt; observerActions = new HashMap&lt;&gt;();    Class&lt;?&gt; clazz = observer.getClass();    for (Method method : getAnnotatedMethods(clazz)) {      Class&lt;?&gt;[] parameterTypes = method.getParameterTypes();      Class&lt;?&gt; eventType = parameterTypes[0];      if (!observerActions.containsKey(eventType)) {        observerActions.put(eventType, new ArrayList&lt;&gt;());      }      observerActions.get(eventType).add(new ObserverAction(observer, method));    }    return observerActions;  }  private List&lt;Method&gt; getAnnotatedMethods(Class&lt;?&gt; clazz) {    List&lt;Method&gt; annotatedMethods = new ArrayList&lt;&gt;();    for (Method method : clazz.getDeclaredMethods()) {      if (method.isAnnotationPresent(Subscribe.class)) {        Class&lt;?&gt;[] parameterTypes = method.getParameterTypes();        Preconditions.checkArgument(parameterTypes.length == 1,                &quot;Method %s has @Subscribe annotation but has %s parameters.&quot;                        + &quot;Subscriber methods must have exactly 1 parameter.&quot;,                method, parameterTypes.length);        annotatedMethods.add(method);      }    }    return annotatedMethods;  }}</code></pre><ol start="4"><li>EventBus</li></ol><pre><code>public class EventBus {  private Executor executor;  private ObserverRegistry registry = new ObserverRegistry();  public EventBus() {    this(MoreExecutors.directExecutor());  }  protected EventBus(Executor executor) {    this.executor = executor;  }  public void register(Object object) {    registry.register(object);  }  public void post(Object event) {    List&lt;ObserverAction&gt; observerActions = registry.getMatchedObserverActions(event);    for (ObserverAction observerAction : observerActions) {      executor.execute(new Runnable() {        @Override        public void run() {          observerAction.execute(event);        }      });    }  }}</code></pre><ol start="5"><li>AsyncEventBus</li></ol><pre><code>public class AsyncEventBus extends EventBus {  public AsyncEventBus(Executor executor) {    super(executor);  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 观察者模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微观经济学 课程学习</title>
      <link href="/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"/>
      <url>/%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6-%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-导论"><a href="#1-导论" class="headerlink" title="1. 导论"></a>1. 导论</h1><h2 id="1-1-经济学发展史"><a href="#1-1-经济学发展史" class="headerlink" title="1.1 经济学发展史"></a>1.1 经济学发展史</h2><ul><li><p>国富论</p><ul><li>工业革命开始</li><li>市场的运作方式</li><li>自由市场经济是自我平衡的，人人皆会受益</li></ul></li><li><p>微观经济学</p><ul><li>单个生产者，管理者的研究</li></ul></li><li><p>资本论</p><ul><li>有辩证方法 批判 得出结论</li><li>资本主义制度是暂时的，潜在的本质性的矛盾</li></ul></li><li><p>就业、利息和货币通论</p></li></ul><ul><li>经济学分类<ul><li>微观经济学<ul><li>对于大的经济体系的某个经济单位</li></ul></li><li>宏观经济学<ul><li>整个经济系统的总体分析</li></ul></li></ul></li></ul><h2 id="1-2-经济学研究什么"><a href="#1-2-经济学研究什么" class="headerlink" title="1.2 经济学研究什么"></a>1.2 经济学研究什么</h2><p>根源是稀缺性，因为稀缺，所以要选择，机会成本是我们做出选择的方法论。</p><ul><li>经济学 – 稀缺资源配置的学科<ul><li>稀缺<ul><li>生产的产品资源无法满足人们的需要的情况 </li><li>稀缺是经济学最重要的假定</li><li>稀缺是普遍存在的</li><li>选择A还是选择B</li></ul></li><li>选择</li><li>机会成本<ul><li>因为稀缺，所以我们需要是的有限的物品，劳务在有限的时间内满足人们最急需的欲望</li><li>因此人们需要去选择</li><li>选择A B 选择A的机会成本是B的收益</li></ul></li></ul></li></ul><h2 id="1-3-十大经济学原理"><a href="#1-3-十大经济学原理" class="headerlink" title="1.3 十大经济学原理"></a>1.3 十大经济学原理</h2><p>看整个的学习框架</p><h3 id="1-3-1-关于个人的"><a href="#1-3-1-关于个人的" class="headerlink" title="1.3.1 关于个人的"></a>1.3.1 关于个人的</h3><ul><li>基本思想：人会通过权衡取舍来对激励做出反应</li><li>基本概念： <ul><li>收益</li><li>(机会)成本</li><li>激励</li></ul></li><li>分析方法<ul><li>边际分析</li></ul></li></ul><ol><li>People face tradeoffs. </li></ol><p>鱼和熊掌不可兼得</p><ul><li>国防 vs 消费</li><li>食品 vs 衣服</li><li>工作 vs 休息</li><li>效率 vs 公平</li></ul><ol start="2"><li>The cost of something is what you give up to get it </li></ol><ul><li>机会成本<ul><li>为了得到某种东西所必须放弃的东西</li></ul></li></ul><ol start="3"><li>Rational people think at the margin </li></ol><ul><li>理性人<ul><li>理性人 会使用所有可获得的信息来进行判断 </li><li>对某个决策的收益和成本进行比较</li></ul></li><li>边际<ul><li>微分的理念</li><li>对当前行动进行的微小的调整</li><li>边际成本–增量成本，指的是每增产以单位的产品所造成的总成本的增量</li><li>边际成本和单位平均成本不同，单位平均成本考虑了全部的产品，而边际成本忽略了最后一个产品之前的。例如每辆汽车的平均成本包括生产第一辆车的很大的固定成本，而边际成本根本不考虑固定成本<ul><li>因为固定成本几乎沉没了，理论上边际成本是可以让企业无损失的继续运转下去的 </li></ul></li><li>一个决策的额外或者追加的成本</li><li>E.G<ul><li>上两节课，很累，是否要上第三节课</li><li>第三节课的收益  边际收益</li><li>成本 休息一下 这个带来的收益就是你第三节课翘课的边际成本了</li></ul></li></ul></li></ul><ol start="4"><li>People respond to incentives 人们对激励做出反应</li></ol><ul><li><p>人们会对激励产生反应</p></li><li><p>对于价格的反应</p></li><li><p>对于竞争的反应</p></li><li><p>对产权 契约制度做出的反应</p></li><li><p><strong>最大值 边际收益 == 边际成本</strong></p></li></ul><h3 id="1-3-2-关于人和人之间的"><a href="#1-3-2-关于人和人之间的" class="headerlink" title="1.3.2 关于人和人之间的"></a>1.3.2 关于人和人之间的</h3><ol start="5"><li>Trade can make everyone better off </li></ol><ul><li>竞争 促进了交易的盈利</li><li>贸易造成的分工</li></ul><ol start="6"><li>Markets are usually a good way to organize economic activity </li></ol><ul><li>市场经济<ul><li>资源配置的办法</li><li>通过卖家买家单独分别的决策来做出最好的选择</li><li>公司  以及 家庭会分别决定怎么生产，生产多少</li></ul></li></ul><p>As if guided by an invisible hand. </p><p>通过价格来决定自己的买卖行为</p><ul><li>市场是否真的有效？<ul><li>法治体系不能由商人 利益集团来左右  亚当斯密</li><li>马克思 自由放任的市场会爆发周期性经济危机  因为人非理性</li><li>凯恩斯 非理性  动物精神  市场波动与宏观波动</li></ul></li></ul><ol start="7"><li>Governments can sometimes improve market outcomes </li></ol><ul><li>因为市场本身弊病，即非理性人的非理性决策</li><li>市场有可能在一些时候无法自身去有效的配置资源，那就需要政府的帮助了</li><li>譬如效率和公平的问题</li><li>市场失灵，无法调控的现象<ul><li>收入与财富分配不公</li><li>外部负效应问题<ul><li>污染</li></ul></li><li>竞争失败和市场垄断的形成</li><li>失业问题</li><li>区域经济的不协调问题</li><li>公共产品供给不足</li><li>公共资源的过度使用</li></ul></li></ul><h3 id="1-3-3-根据宏观经济现象提出的原理"><a href="#1-3-3-根据宏观经济现象提出的原理" class="headerlink" title="1.3.3 根据宏观经济现象提出的原理"></a>1.3.3 根据宏观经济现象提出的原理</h3><ol start="8"><li>一国的生活水平取决于它生产物品与劳务的能力</li><li>当政府发行了过多货币的时候，物价上升</li><li>社会面临通货膨胀与失业之间的短期权衡取舍</li></ol><h1 id="2-像经济学家一样思考"><a href="#2-像经济学家一样思考" class="headerlink" title="2.  像经济学家一样思考"></a>2.  像经济学家一样思考</h1><h2 id="2-1-经济学的社会科学属性"><a href="#2-1-经济学的社会科学属性" class="headerlink" title="2.1 经济学的社会科学属性"></a>2.1 经济学的社会科学属性</h2><ul><li>经济学家<ul><li>一方面，另一方面，lol  </li><li>考虑问题常常两个方面<ul><li>作为科学家<ul><li>经济分析</li></ul></li><li>作为政策顾问<ul><li>时政分析</li></ul></li></ul></li></ul></li></ul><ul><li><p>什么是科学？</p><ul><li><p>通常当我们定义一个概念的时候，需要一个外延更宽泛的概念</p></li><li><p>用科学定义经济学</p></li><li><p>用认识定义科学</p><ul><li>认识： 人们通过实践和思维，对单个事物的属性和事物之间联系的理解和判断</li></ul></li><li><p>科学的本质</p><ul><li>用实证的方法，实证性</li><li>解释对象是怎么样的问题，以及应该怎么样的规范性问题</li></ul></li><li><p>科学的性质</p><ul><li>可证伪性</li><li>假设与简化</li><li>内部一致性<ul><li>统一的假设系统，能够解释多种现象</li></ul></li><li>经验一致性<ul><li>观察事实等经验证据与理论相对照</li><li>通过可控制的试验来进行检验<ul><li>经济学</li><li>符合科学的可证伪原则</li><li>采用假设手段构造理论，并使用简化的模型表达理论</li><li>坚持内部逻辑的一致性</li><li>不断将卢纶假设和经验事实相对照，来检验理论的真伪 </li><li>主题</li><li>人们的选择如何引导他们的生活，以及他们是如何相互影响的</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="2-2-经济学的研究步骤"><a href="#2-2-经济学的研究步骤" class="headerlink" title="2.2 经济学的研究步骤"></a>2.2 经济学的研究步骤</h2><ol><li>确定研究问题</li><li>形成假设</li><li>建立模型</li><li>经验检验，也测货解释现实</li><li>通过检验结果决定放弃，修改模型</li></ol><ul><li>研究方法<ul><li>描述性的方法</li><li>分析性的办法 – 抽象推理</li></ul></li></ul><p>下面描述一些经常使用的经济模型：</p><h3 id="2-2-1-循环流量图"><a href="#2-2-1-循环流量图" class="headerlink" title="2.2.1 循环流量图"></a>2.2.1 循环流量图</h3><ul><li><p>说明货币如何通过市场在家庭和企业之间流动</p></li><li><p>主体</p><ul><li>家庭<ul><li>拥有并出售或出租生产要素给企业来获得收入</li><li>购买并消费物品与劳务</li></ul></li><li>企业<ul><li>购买或雇佣生产要素并用以生产物品与劳务</li><li>出售物品与劳务</li></ul></li></ul></li><li><p>两个市场</p><ul><li>物品与劳务市场</li><li>生产要素市场<ul><li>生产要素指经济体用来生产物品与劳务的资源<ul><li>劳动</li><li>土地</li><li>资本<ul><li>建筑物</li><li>用来生产的机器<h3 id="2-2-2-生产可能性边界"><a href="#2-2-2-生产可能性边界" class="headerlink" title="2.2.2 生产可能性边界"></a>2.2.2 生产可能性边界</h3></li></ul></li></ul></li></ul></li></ul></li><li><p>表明的是在生产要素和生产技术既定的情况下，一个经济所能生产的产品的各种数量的组合</p><ul><li>一条凹下去的曲线</li><li>在内部，失业，窝工</li><li>外部，无法实现</li><li>生产力提升，边界，y，x轴点的提升</li></ul></li><li><p>为什么不是直线呢？ </p><ul><li>边际转化率<ul><li>一个产品的增加导致另外一个产品的减少</li><li>转化率会有很大的变化<ul><li>比如边际状态，一个产品制造的转移，会使得做这个产品最熟练的工人转移，生产力大大减小，而对于另外一个产品的生产力的提升并不会有同等程度的增加</li></ul></li></ul></li></ul></li></ul><h2 id="2-3-作为政策顾问的经济学家"><a href="#2-3-作为政策顾问的经济学家" class="headerlink" title="2.3 作为政策顾问的经济学家"></a>2.3 作为政策顾问的经济学家</h2><ul><li>作为政策顾问，试图做出关于世界应该是什么样子的规范表述<ul><li>不是已经发生的，或者是能够规范到</li><li>是不能证伪的</li></ul></li></ul><h1 id="3-相互依存性与贸易的好处"><a href="#3-相互依存性与贸易的好处" class="headerlink" title="3. 相互依存性与贸易的好处"></a>3. 相互依存性与贸易的好处</h1><h2 id="3-1-相互依存性与贸易好处"><a href="#3-1-相互依存性与贸易好处" class="headerlink" title="3.1 相互依存性与贸易好处"></a>3.1 相互依存性与贸易好处</h2><ul><li><p>我们正在享用世界上的人给我们提供的服务</p><ul><li>为什么我们要相互依赖？ <ul><li>贸易使得每个人的状况会更好。</li><li>为什么国家之间会相互依存？</li><li>为什么还会存在贸易保护呢？ </li></ul></li></ul></li><li><p>贸易的必要性</p><ul><li><p>贸易有可能使得生产可能性曲线更凹 </p><ul><li>对双方都会有利</li></ul></li><li><p>绝对优势</p><ul><li>用比另一个生产者更少的投入来生产某种物品的能力</li></ul></li><li><p>比较优势原理</p><ul><li>用比另一个生产者更少的机会成本来生产某种物品的能力</li></ul></li><li><p>贸易获得的利益来源于比较优势。当每个国家专门生产它具有比较优势的物品的时候，所有国家的总产量会更高，世界的经济蛋糕也会更大。</p></li></ul></li></ul><h2 id="3-2-实际应用"><a href="#3-2-实际应用" class="headerlink" title="3.2 实际应用"></a>3.2 实际应用</h2><ul><li><p>小国更容易在贸易当中获利 </p><ul><li>亚洲四小龙  – 出口导向<ul><li>经济腾飞</li><li>劳动密集型</li><li>贸易获利，经济同质性强</li></ul></li></ul></li><li><p>中美贸易</p><ul><li>产品摩擦变大</li><li>中国对美国进出口依赖度降低，然而美国对中国的是呈上升趋势的</li></ul></li><li><p>我国强调产业升级，开始出现重叠了</p></li></ul><h1 id="4-供给与需求的市场力量"><a href="#4-供给与需求的市场力量" class="headerlink" title="4. 供给与需求的市场力量"></a>4. 供给与需求的市场力量</h1><ul><li><p>供给与供给量</p></li><li><p>需求与需求量</p></li><li><p>供需曲线的研究，对实际场景的分析</p><h2 id="4-1-物品需求"><a href="#4-1-物品需求" class="headerlink" title="4.1 物品需求"></a>4.1 物品需求</h2></li><li><p>市场</p><ul><li>买方卖方在一起</li></ul></li><li><p>市场势力</p><ul><li>卖方买方不适当的影响商品价格的能力</li></ul></li><li><p>完全竞争市场</p><ul><li>可供销售物品完全相同</li><li>买方卖方人数众多，以至于没有任何一个买方或卖方可以影响市场价格，每个人都是价格接受者(price taker)</li><li>比如农贸市场，地摊</li></ul></li><li><p>垄断</p><ul><li>电网</li><li>铁路</li><li>烟草</li></ul></li><li><p>寡头市场</p><ul><li>汽车</li><li>钢铁</li><li>造船</li><li>石油化工</li><li>有色冶金</li><li>飞机制造</li><li>航空运输</li></ul></li><li><p>垄断竞争</p><ul><li>洗发水</li><li>服装</li><li>药品</li></ul></li><li><p>需求</p><ul><li>物品需求量</li><li>买者愿意并且能够购买的一种物品的数量</li></ul></li><li><p>需求定理</p><ul><li>认为在其他条件不变的时候，一种物品的价格上升，对该物品的需求量会减少</li></ul></li><li><p>需求曲线</p><ul><li><p>表示在其他条件不变的情况下，价格和需求量之间的关系的图形</p></li><li><p>纵轴为价格，横轴为需求量，斜率为负，因为二者的增长态势是相反的</p></li><li><p>价格为自变量，需求为因变量</p></li><li><p>常见的其他条件 – 影响需求曲线变动的因素</p><ul><li><p>买者数量</p><ul><li>买者数量的增加会增加每一种价格水平下的需求量，从而使需求曲线向右移动</li></ul></li><li><p>收入</p><ul><li>正常商品<ul><li>收入上升，需求上升</li></ul></li><li>低档商品<ul><li>收入上升，需求下降</li></ul></li></ul></li><li><p>相关物品的价格</p><ul><li>替代品<ul><li>披萨和汉堡</li><li>可口可乐和百事可乐</li></ul></li><li>互补品<ul><li>电脑和软件</li><li>汽车和石油</li></ul></li></ul></li><li><p>嗜好</p></li><li><p>预期</p><ul><li>对未来的价格的预期</li><li>预期未来收入增加，那么对一些高档品的需求现在就有可能增加</li></ul></li></ul></li></ul></li><li><p>市场需求量</p><ul><li>所有买者在每一个价格水平下的需求量的总和</li></ul></li><li><p>需求 vs 需求量</p><ul><li>需求的变动指除了商品价格以外的其他因素引起的变动，图上表现为需求曲线的平行移动</li><li>供给量的变动指由价格变动引起的变动<h2 id="4-2-物品供给"><a href="#4-2-物品供给" class="headerlink" title="4.2 物品供给"></a>4.2 物品供给</h2></li></ul></li><li><p>从卖方角度来看</p></li><li><p>供给量</p><ul><li>卖者愿意并且能够出售的一种物品的数量</li></ul></li><li><p>供给定理</p><ul><li>认为在其他条件不变的时候，一种物品价格的上升，会使得该物品的供给量增加</li></ul></li><li><p>市场供给</p><ul><li>在每种价格水平下所有卖者的供给量之和</li></ul></li><li><p>市场供给曲线</p><ul><li>价格为纵轴，横轴为供给量，价格为自变量</li><li>影响曲线移动的因素<ul><li>投入品的价格<ul><li>价格下降，供给量提高</li></ul></li><li>技术水平</li><li>卖者的数量</li><li>预期</li></ul></li></ul></li></ul><h2 id="4-3-需求与供给的结合"><a href="#4-3-需求与供给的结合" class="headerlink" title="4.3 需求与供给的结合"></a>4.3 需求与供给的结合</h2><ul><li><p>供给需求曲线 – 大剪刀图 lol </p><ul><li>交点<ul><li>均衡<ul><li>供给量和需求量的相等</li></ul></li></ul></li><li>过剩  <ul><li>供给大于需求</li><li>厂商需要降价</li><li>需求量会相对上升</li></ul></li><li>短缺<ul><li>厂商愿意供给量少</li><li>想买，买不到，买者提高价格买</li><li>厂商来更多生产</li></ul></li></ul></li><li><p>分析市场价格的变动</p><ul><li><ol><li>使供给曲线移动还是需求曲线移动还是都移动</li></ol></li><li><ol start="2"><li>确定曲线的移动方向</li></ol></li><li><ol start="3"><li>用供求图来说明这种移动如何改变均衡价格和均衡数量的</li></ol></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>学堂在线 经济学原理(微观部分) <a href="https://next.xuetangx.com/learn/THU02011001169" target="_blank" rel="noopener">https://next.xuetangx.com/learn/THU02011001169</a> </li><li>曼昆 经济学原理 第6版</li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-结构型-享元模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-原理与实现"><a href="#1-原理与实现" class="headerlink" title="1. 原理与实现"></a>1. 原理与实现</h1><ul><li><p>享元模式 Flyweight Design Pattern </p><ul><li><p>用来复用对象，节省内存，</p></li><li><p>前提条件，享元对象是不可变对象</p><ul><li>不可以暴露任何set（）等修改内部状态的方法</li></ul></li><li><p>当一个系统中存在大量重复对象的时候，如果重复对象都是不可变对象，我们就可以利用享元模式将对象设计成享元，在内存中只保留一份实例，供多处代码来引用。</p></li></ul></li></ul><ul><li>是通过工厂模式，在工厂类当中，通过一个Map来缓存已经创建过的享元对象，来达到复用的目的</li></ul><ul><li>文本文件对于字体格式进行享元操作</li></ul><pre><code>public class CharacterStyle {  private Font font;  private int size;  private int colorRGB;  public CharacterStyle(Font font, int size, int colorRGB) {    this.font = font;    this.size = size;    this.colorRGB = colorRGB;  }  @Override  public boolean equals(Object o) {    CharacterStyle otherStyle = (CharacterStyle) o;    return font.equals(otherStyle.font)            &amp;&amp; size == otherStyle.size            &amp;&amp; colorRGB == otherStyle.colorRGB;  }}public class CharacterStyleFactory {  private static final List&lt;CharacterStyle&gt; styles = new ArrayList&lt;&gt;();  public static CharacterStyle getStyle(Font font, int size, int colorRGB) {    CharacterStyle newStyle = new CharacterStyle(font, size, colorRGB);    for (CharacterStyle style : styles) {      if (style.equals(newStyle)) {        return style;      }    }    styles.add(newStyle);    return newStyle;  }}public class Character {  private char c;  private CharacterStyle style;  public Character(char c, CharacterStyle style) {    this.c = c;    this.style = style;  }}public class Editor {  private List&lt;Character&gt; chars = new ArrayList&lt;&gt;();  public void appendCharacter(char c, Font font, int size, int colorRGB) {    Character character = new Character(c, CharacterStyleFactory.getStyle(font, size, colorRGB));    chars.add(character);  }}</code></pre><h1 id="2-享元模式在Java-Integer以及String当中的应用"><a href="#2-享元模式在Java-Integer以及String当中的应用" class="headerlink" title="2. 享元模式在Java Integer以及String当中的应用"></a>2. 享元模式在Java Integer以及String当中的应用</h1><pre><code>/** * Cache to support the object identity semantics of autoboxing for values between * -128 and 127 (inclusive) as required by JLS. * * The cache is initialized on first usage.  The size of the cache * may be controlled by the {@code -XX:AutoBoxCacheMax=&lt;size&gt;} option. * During VM initialization, java.lang.Integer.IntegerCache.high property * may be set and saved in the private system properties in the * sun.misc.VM class. */private static class IntegerCache {    static final int low = -128;    static final int high;    static final Integer cache[];    static {        // high value may be configured by property        int h = 127;        String integerCacheHighPropValue =            sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;);        if (integerCacheHighPropValue != null) {            try {                int i = parseInt(integerCacheHighPropValue);                i = Math.max(i, 127);                // Maximum array size is Integer.MAX_VALUE                h = Math.min(i, Integer.MAX_VALUE - (-low) -1);            } catch( NumberFormatException nfe) {                // If the property cannot be parsed into an int, ignore it.            }        }        high = h;        cache = new Integer[(high - low) + 1];        int j = low;        for(int k = 0; k &lt; cache.length; k++)            cache[k] = new Integer(j++);        // range [-128, 127] must be interned (JLS7 5.1.7)        assert IntegerCache.high &gt;= 127;    }    private IntegerCache() {}}</code></pre><p>IntegerCache 缓存在-128到127之间的内容，即指向的是同样的内存地址的</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 享元模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-结构型-组合模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-原理和实现"><a href="#1-原理和实现" class="headerlink" title="1. 原理和实现"></a>1. 原理和实现</h1><p>组合模式，是用来处理树形结构的数据的。</p><ul><li>Compose objects into tree structure to represent part-whole hierarchies. Composite lets client treat individual objects and compositions of objects uniformly. </li><li>将一组对象组织成树形结构，来表示一种 部分-整体的层次结构，组合让客户端可以统一单个对象和组合对象的处理逻辑。</li></ul><h1 id="2-应用场景"><a href="#2-应用场景" class="headerlink" title="2. 应用场景"></a>2. 应用场景</h1><ul><li>现在设计一个类来表示文件系统中的目录，来方便地实现下面的功能：<ul><li>动态添加、删除某个目录下的子目录或文件</li><li>统计指定目录下的文件个数</li><li>统计指定目录下的文件总大小</li></ul></li></ul><pre><code>public class FileSystemNode {  private String path;  private boolean isFile;  private List&lt;FileSystemNode&gt; subNodes = new ArrayList&lt;&gt;();  public FileSystemNode(String path, boolean isFile) {    this.path = path;    this.isFile = isFile;  }  public int countNumOfFiles() {    if (isFile) { return 1; }     int numOfFiles = 0;     for (FileSystemNode fileOrDir : subNodes) {         numOfFiles += fileOrDir.countNumOfFiles();     }     return numOfFiles;  }  public long countSizeOfFiles() {    if (isFile) {              File file = new File(path);              if (!file.exists()) return 0;              return file.length();        }        long sizeofFiles = 0;        for (FileSystemNode fileOrDir : subNodes) {              sizeofFiles += fileOrDir.countSizeOfFiles();        }        return sizeofFiles;  }  public String getPath() {    return path;  }  public void addSubNode(FileSystemNode fileOrDir) {    subNodes.add(fileOrDir);  }  public void removeSubNode(FileSystemNode fileOrDir) {    int size = subNodes.size();    int i = 0;    for (; i &lt; size; ++i) {      if (subNodes.get(i).getPath().equalsIgnoreCase(fileOrDir.getPath())) {        break;      }    }    if (i &lt; size) {      subNodes.remove(i);    }  }}</code></pre><ul><li>而后对文件和目录进行区分设计</li></ul><pre><code>public abstract class FileSystemNode {  protected String path;  public FileSystemNode(String path) {    this.path = path;  }  public abstract int countNumOfFiles();  public abstract long countSizeOfFiles();  public String getPath() {    return path;  }}public class File extends FileSystemNode {  public File(String path) {    super(path);  }  @Override  public int countNumOfFiles() {    return 1;  }  @Override  public long countSizeOfFiles() {    java.io.File file = new java.io.File(path);    if (!file.exists()) return 0;    return file.length();  }}public class Directory extends FileSystemNode {  private List&lt;FileSystemNode&gt; subNodes = new ArrayList&lt;&gt;();  public Directory(String path) {    super(path);  }  @Override  public int countNumOfFiles() {    int numOfFiles = 0;    for (FileSystemNode fileOrDir : subNodes) {      numOfFiles += fileOrDir.countNumOfFiles();    }    return numOfFiles;  }  @Override  public long countSizeOfFiles() {    long sizeofFiles = 0;    for (FileSystemNode fileOrDir : subNodes) {      sizeofFiles += fileOrDir.countSizeOfFiles();    }    return sizeofFiles;  }  public void addSubNode(FileSystemNode fileOrDir) {    subNodes.add(fileOrDir);  }  public void removeSubNode(FileSystemNode fileOrDir) {    int size = subNodes.size();    int i = 0;    for (; i &lt; size; ++i) {      if (subNodes.get(i).getPath().equalsIgnoreCase(fileOrDir.getPath())) {        break;      }    }    if (i &lt; size) {      subNodes.remove(i);    }  }}public class Demo {  public static void main(String[] args) {    /**     * /     * /wz/     * /wz/a.txt     * /wz/b.txt     * /wz/movies/     * /wz/movies/c.avi     * /xzg/     * /xzg/docs/     * /xzg/docs/d.txt     */    Directory fileSystemTree = new Directory(&quot;/&quot;);    Directory node_wz = new Directory(&quot;/wz/&quot;);    Directory node_xzg = new Directory(&quot;/xzg/&quot;);    fileSystemTree.addSubNode(node_wz);    fileSystemTree.addSubNode(node_xzg);    File node_wz_a = new File(&quot;/wz/a.txt&quot;);    File node_wz_b = new File(&quot;/wz/b.txt&quot;);    Directory node_wz_movies = new Directory(&quot;/wz/movies/&quot;);    node_wz.addSubNode(node_wz_a);    node_wz.addSubNode(node_wz_b);    node_wz.addSubNode(node_wz_movies);    File node_wz_movies_c = new File(&quot;/wz/movies/c.avi&quot;);    node_wz_movies.addSubNode(node_wz_movies_c);    Directory node_xzg_docs = new Directory(&quot;/xzg/docs/&quot;);    node_xzg.addSubNode(node_xzg_docs);    File node_xzg_docs_d = new File(&quot;/xzg/docs/d.txt&quot;);    node_xzg_docs.addSubNode(node_xzg_docs_d);    System.out.println(&quot;/ files num:&quot; + fileSystemTree.countNumOfFiles());    System.out.println(&quot;/wz/ files num:&quot; + node_wz.countNumOfFiles());  }}</code></pre><blockquote><p>将一组对象（文件和目录）组织成树形结构，以表示一种‘部分 - 整体’的层次结构（目录与子目录的嵌套结构）。组合模式让客户端可以统一单个对象（文件）和组合对象（目录）的处理逻辑（递归遍历）</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 组合模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-结构型-门面模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E9%97%A8%E9%9D%A2%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E9%97%A8%E9%9D%A2%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-原理与实现"><a href="#1-原理与实现" class="headerlink" title="1. 原理与实现"></a>1. 原理与实现</h1><p>门面模式应用场景主要在于接口设计方面，是为了处理和解决接口粒度的相关问题。</p><p>为了保证接口的可复用性(通用性)，我们需要将接口设计的粒度细一些，职责单一。但是，如果接口的粒度过小，在接口使用者开发一个业务功能的时候，就需要开发不同的接口来满足，这样会导致系统的接口无限膨胀。</p><ul><li>门面模式  Facade Design Pattern <ul><li>provide a unified interface to a set of interfaces in a subsystem</li><li>facade pattern defines a higher level interface that makes the subsystem easier to use </li></ul></li></ul><ul><li>场景举例<ul><li>比如系统A提供a,b,c,d四个接口，系统B完成某个业务功能，需要调用A系统的a,b,d接口。利用门面模式，提供一个包裹a,b,d接口调用的门面接口x，给系统B直接使用</li><li>如果上述AB一个是后端，一个是APP端的话，那么他们之间网络通信耗时会比较多</li></ul></li></ul><h1 id="2-门面模式的应用场景"><a href="#2-门面模式的应用场景" class="headerlink" title="2. 门面模式的应用场景"></a>2. 门面模式的应用场景</h1><h2 id="2-1-解决易用性问题"><a href="#2-1-解决易用性问题" class="headerlink" title="2.1 解决易用性问题"></a>2.1 解决易用性问题</h2><ul><li>封装系统的底层实现，隐藏系统的复杂性</li><li>提供一组更加简单易用，更高层的接口</li><li>例子<ul><li>Linux系统调用函数<ul><li>封装了底层Linux内核的调用</li></ul></li><li>Shell指令<ul><li>封装系统调用</li><li>提供更加友好的指令</li></ul></li></ul></li></ul><h2 id="2-2-解决性能问题"><a href="#2-2-解决性能问题" class="headerlink" title="2.2 解决性能问题"></a>2.2 解决性能问题</h2><ul><li>当使用一个门面接口替换多个接口的调用的时候，减少了网络通信成本</li><li>如果门面接口比较多<ul><li>可以抽象出一层，专门放置门面接口</li><li>如果跨多个子系统，可以将门面接口放到一个新的子系统当中</li></ul></li></ul><h2 id="2-3-解决分布式事务问题"><a href="#2-3-解决分布式事务问题" class="headerlink" title="2.3 解决分布式事务问题"></a>2.3 解决分布式事务问题</h2><p>在一个金融系统中，有两个业务领域模型，用户和钱包。这两个业务领域模型都对外暴露了一系列接口，比如用户的增删改查接口、钱包的增删改查接口。假设有这样一个业务场景：在用户注册的时候，我们不仅会创建用户（在数据库 User 表中），还会给用户创建一个钱包（在数据库的 Wallet 表中）。</p><p>对于这样一个简单的业务需求，我们可以通过依次调用用户的创建接口和钱包的创建接口来完成。但是，用户注册需要支持事务，也就是说，创建用户和钱包的两个操作，要么都成功，要么都失败，不能一个成功、一个失败。</p><p>要支持两个接口调用在一个事务中执行，是比较难实现的，这涉及分布式事务问题。虽然我们可以通过引入分布式事务框架或者事后补偿的机制来解决，但代码实现都比较复杂。而最简单的解决方案是，利用数据库事务或者 Spring 框架提供的事务（如果是 Java 语言的话），在一个事务中，执行创建用户和创建钱包这两个 SQL 操作。这就要求两个 SQL 操作要在一个接口中完成，所以，我们可以借鉴门面模式的思想，再设计一个包裹这两个操作的新接口，让新接口在一个事务中执行两个 SQL 操作。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 门面模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-结构型-适配器模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-适配器模式原理和实现"><a href="#1-适配器模式原理和实现" class="headerlink" title="1. 适配器模式原理和实现"></a>1. 适配器模式原理和实现</h1><ul><li><p>Adapter Design Pattern </p><ul><li>做适配的，将不兼容的接口转换为可兼容的接口</li><li>将原本由于接口不兼容而不能一起工作的类一起工作</li></ul></li><li><p>实现方式</p><ul><li>类适配器<ul><li>使用继承关系实现</li></ul></li><li>对象适配器<ul><li>使用组合关系实现</li></ul></li></ul></li></ul><pre><code>// 类适配器: 基于继承public interface ITarget {  void f1();  void f2();  void fc();}public class Adaptee {  public void fa() { //... }  public void fb() { //... }  public void fc() { //... }}public class Adaptor extends Adaptee implements ITarget {  public void f1() {    super.fa();  }  public void f2() {    //...重新实现f2()...  }  // 这里fc()不需要实现，直接继承自Adaptee，这是跟对象适配器最大的不同点}// 对象适配器：基于组合public interface ITarget {  void f1();  void f2();  void fc();}public class Adaptee {  public void fa() { //... }  public void fb() { //... }  public void fc() { //... }}public class Adaptor implements ITarget {  private Adaptee adaptee;  public Adaptor(Adaptee adaptee) {    this.adaptee = adaptee;  }  public void f1() {    adaptee.fa(); //委托给Adaptee  }  public void f2() {    //...重新实现f2()...  }  public void fc() {    adaptee.fc();  }}</code></pre><ul><li><p>类适配器和对象适配器的选择取决于</p><ul><li>Adaptee接口的个数</li><li>Adaptee 和Itarget的契合程度</li></ul></li><li><p>如果 Adaptee 接口并不多，那两种实现方式都可以。</p></li><li><p>如果 Adaptee 接口很多，而且 Adaptee 和 ITarget 接口定义大部分都相同，那我们推荐使用类适配器，因为 Adaptor 复用父类 Adaptee 的接口，比起对象适配器的实现方式，Adaptor 的代码量要少一些。</p></li><li><p>如果 Adaptee 接口很多，而且 Adaptee 和 ITarget 接口定义大部分都不相同，那我们推荐使用对象适配器，因为组合结构相对于继承更加灵活。</p></li></ul><h1 id="2-应用场景总结"><a href="#2-应用场景总结" class="headerlink" title="2. 应用场景总结"></a>2. 应用场景总结</h1><ul><li>适配器模式 – 一种补偿模式<ul><li>主要用来弥补一些设计上的缺陷</li><li>主要用来解决接口不兼容的问题</li></ul></li></ul><h2 id="2-1-封装有缺陷的接口设计"><a href="#2-1-封装有缺陷的接口设计" class="headerlink" title="2.1 封装有缺陷的接口设计"></a>2.1 封装有缺陷的接口设计</h2><p>譬如我们依赖的外部系统在接口设计上有缺陷（包含大量的静态方法），引入后会影响到我们自身代码的可测试性。为了隔离设计上的缺陷，我们希望对外部系统提供的接口进行二次封装，抽象出更好的接口设计。</p><pre><code>public class CD { //这个类来自外部sdk，我们无权修改它的代码  //...  public static void staticFunction1() { //... }  public void uglyNamingFunction2() { //... }  public void tooManyParamsFunction3(int paramA, int paramB, ...) { //... }   public void lowPerformanceFunction4() { //... }}// 使用适配器模式进行重构public class ITarget {  void function1();  void function2();  void fucntion3(ParamsWrapperDefinition paramsWrapper);  void function4();  //...}// 注意：适配器类的命名不一定非得末尾带Adaptorpublic class CDAdaptor extends CD implements ITarget {  //...  public void function1() {     super.staticFunction1();  }  public void function2() {    super.uglyNamingFucntion2();  }  public void function3(ParamsWrapperDefinition paramsWrapper) {     super.tooManyParamsFunction3(paramsWrapper.getParamA(), ...);  }  public void function4() {    //...reimplement it...  }}</code></pre><h2 id="2-2-统一多个类的接口设计"><a href="#2-2-统一多个类的接口设计" class="headerlink" title="2.2 统一多个类的接口设计"></a>2.2 统一多个类的接口设计</h2><p>某个功能的实现依赖多个外部系统，通过适配器模式，将其接口适配为统一的接口定义，然后使用多态的特性来复用代码逻辑。</p><p>下述代码使用适配器模式来处理有不同的接口设计的几个来自第三方做词汇过滤的API</p><pre><code>public class ASensitiveWordsFilter { // A敏感词过滤系统提供的接口  //text是原始文本，函数输出用***替换敏感词之后的文本  public String filterSexyWords(String text) {    // ...  }  public String filterPoliticalWords(String text) {    // ...  } }public class BSensitiveWordsFilter  { // B敏感词过滤系统提供的接口  public String filter(String text) {    //...  }}public class CSensitiveWordsFilter { // C敏感词过滤系统提供的接口  public String filter(String text, String mask) {    //...  }}// 未使用适配器模式之前的代码：代码的可测试性、扩展性不好public class RiskManagement {  private ASensitiveWordsFilter aFilter = new ASensitiveWordsFilter();  private BSensitiveWordsFilter bFilter = new BSensitiveWordsFilter();  private CSensitiveWordsFilter cFilter = new CSensitiveWordsFilter();  public String filterSensitiveWords(String text) {    String maskedText = aFilter.filterSexyWords(text);    maskedText = aFilter.filterPoliticalWords(maskedText);    maskedText = bFilter.filter(maskedText);    maskedText = cFilter.filter(maskedText, &quot;***&quot;);    return maskedText;  }}// 使用适配器模式进行改造public interface ISensitiveWordsFilter { // 统一接口定义  String filter(String text);}public class ASensitiveWordsFilterAdaptor implements ISensitiveWordsFilter {  private ASensitiveWordsFilter aFilter;  public String filter(String text) {    String maskedText = aFilter.filterSexyWords(text);    maskedText = aFilter.filterPoliticalWords(maskedText);    return maskedText;  }}//...省略BSensitiveWordsFilterAdaptor、CSensitiveWordsFilterAdaptor...// 扩展性更好，更加符合开闭原则，如果添加一个新的敏感词过滤系统，// 这个类完全不需要改动；而且基于接口而非实现编程，代码的可测试性更好。public class RiskManagement {   private List&lt;ISensitiveWordsFilter&gt; filters = new ArrayList&lt;&gt;();  public void addSensitiveWordsFilter(ISensitiveWordsFilter filter) {    filters.add(filter);  }  public String filterSensitiveWords(String text) {    String maskedText = text;    for (ISensitiveWordsFilter filter : filters) {      maskedText = filter.filter(maskedText);    }    return maskedText;  }}</code></pre><h2 id="2-3-替换依赖的外部系统"><a href="#2-3-替换依赖的外部系统" class="headerlink" title="2.3 替换依赖的外部系统"></a>2.3 替换依赖的外部系统</h2><pre><code>// 外部系统Apublic interface IA {  //...  void fa();}public class A implements IA {  //...  public void fa() { //... }}// 在我们的项目中，外部系统A的使用示例public class Demo {  private IA a;  public Demo(IA a) {    this.a = a;  }  //...}Demo d = new Demo(new A());// 将外部系统A替换成外部系统Bpublic class BAdaptor implemnts IA {  private B b;  public BAdaptor(B b) {    this.b= b;  }  public void fa() {    //...    b.fb();  }}// 借助BAdaptor，Demo的代码中，调用IA接口的地方都无需改动，// 只需要将BAdaptor如下注入到Demo即可。Demo d = new Demo(new BAdaptor(new B()));</code></pre><h2 id="2-4-兼容老版本的接口"><a href="#2-4-兼容老版本的接口" class="headerlink" title="2.4 兼容老版本的接口"></a>2.4 兼容老版本的接口</h2><p>做版本升级的时候，对于一些要废弃的接口，不能直接将其删除，而是暂时保留，并且标注为deprecated，并将内部实现逻辑委托为新的接口实现。这样就可以是的项目有个过渡期。</p><p>Enumeration –&gt; Iterator的升级</p><pre><code>public class Collections {  public static Emueration emumeration(final Collection c) {    return new Enumeration() {      Iterator i = c.iterator();      public boolean hasMoreElments() {        return i.hashNext();      }      public Object nextElement() {        return i.next():      }    }  }}</code></pre><h1 id="3-代理-vs-桥接-vs-装饰器-vs-适配器"><a href="#3-代理-vs-桥接-vs-装饰器-vs-适配器" class="headerlink" title="3. 代理 vs 桥接 vs 装饰器 vs 适配器"></a>3. 代理 vs 桥接 vs 装饰器 vs 适配器</h1><ul><li><p>代理模式</p><ul><li>在不改变原始类接口的条件下，为原始类定义一个代理类，主要目的是访问控制，而非加强功能</li></ul></li><li><p>桥接模式</p><ul><li>将接口部分和实现部分分离，使得其能够相对独立的进行改变</li></ul></li><li><p>装饰器模式</p><ul><li>在不改变原始类接口的情况下，对原始类功能进行增强，并且支持多个装饰器的嵌套使用</li></ul></li><li><p>适配器模式</p><ul><li>事后补救策略，适配器提供跟原始类不同的接口</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 适配器模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-结构型-装饰器模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><h2 id="1-1-Java-IO类的使用"><a href="#1-1-Java-IO类的使用" class="headerlink" title="1.1 Java IO类的使用"></a>1.1 Java IO类的使用</h2><table><thead><tr><th></th><th>字节流</th><th>字符流</th></tr></thead><tbody><tr><td>输入流</td><td>InputStream</td><td>Reader</td></tr><tr><td>输出流</td><td>OutputStream</td><td>Writer</td></tr></tbody></table><p>JavaIO库非常庞大，几十个类一同来负责IO数据的读取和写入。</p><pre><code>InputStream in = new FileInputStream(&quot;/user/wangzheng/test.txt&quot;);InputStream bin = new BufferedInputStream(in);byte[] data = new byte[128];while (bin.read(data) != -1) {  //...}</code></pre><p>上述代码先使用了FileInputStream来读取文件流，然后又使用了BufferedInputStream，来支持缓存。</p><p>问题来了，为什么不能设置一个继承了FileInputStream并且支持缓存的BufferedFileInputStream类呢？ </p><p>问题在于各种use case太多，如果为了各种功能的组合都设置一个类的话，那么类的继承结构会变得非常负责，代码会变得很难扩展和维护。</p><p>Java IO的设计思路，就是使用组合来替代继承</p><pre><code>public abstract class InputStream {  //...  public int read(byte b[]) throws IOException {    return read(b, 0, b.length);  }  public int read(byte b[], int off, int len) throws IOException {    //...  }  public long skip(long n) throws IOException {    //...  }  public int available() throws IOException {    return 0;  }  public void close() throws IOException {}  public synchronized void mark(int readlimit) {}  public synchronized void reset() throws IOException {    throw new IOException(&quot;mark/reset not supported&quot;);  }  public boolean markSupported() {    return false;  }}public class BufferedInputStream extends InputStream {  protected volatile InputStream in;  protected BufferedInputStream(InputStream in) {    this.in = in;  }  //...实现基于缓存的读数据接口...  }public class DataInputStream extends InputStream {  protected volatile InputStream in;  protected DataInputStream(InputStream in) {    this.in = in;  }  //...实现读取基本类型数据的接口}</code></pre><h2 id="1-2-装饰器模式"><a href="#1-2-装饰器模式" class="headerlink" title="1.2 装饰器模式"></a>1.2 装饰器模式</h2><ul><li>使用组合来替代继承关系</li><li>装饰器类和原始类继承同样的父类，这样我们就可以对原始类嵌套多个装饰器类</li><li>是对功能的增强，是和原始功能相关的</li><li>为了解决继承关系过于复杂的问题</li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 装饰器模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-结构型-桥接模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-原理解析"><a href="#1-原理解析" class="headerlink" title="1. 原理解析"></a>1. 原理解析</h1><ul><li>桥接模式 Bridge Design Pattern<ul><li>将抽象和实现解耦，使之可以独立变化</li><li>一个类存在两个或者多个独立变化的维度，通过组合的方式，让这几个维度都可以独立进行扩展<ul><li>通过组合关系来替代继承关系，避免继承层次的指数级爆炸</li></ul></li></ul></li></ul><h2 id="1-1-JDBC驱动的实现"><a href="#1-1-JDBC驱动的实现" class="headerlink" title="1.1 JDBC驱动的实现"></a>1.1 JDBC驱动的实现</h2><pre><code>    Class.forName(&quot;com.mysql.jdbc.Driver&quot;);//加载及注册JDBC驱动程序    String url = &quot;jdbc:mysql://localhost:3306/sample_db?user=root&amp;password=your_password&quot;;    Connection con = DriverManager.getConnection(url);    Statement stmt = con.createStatement()；    String query = &quot;select * from test&quot;;    ResultSet rs=stmt.executeQuery(query);    while(rs.next()) {      rs.getString(1);      rs.getInt(2);    }</code></pre><ul><li>上述代码中只要改变forName中的路径，就可以改变数据库了</li><li>或者我们可以通过将加载的Driver类写到配置文件当中，来实现数据库的切换，只需要修改配置文件就可以完成数据库的切换了</li></ul><pre><code>package com.mysql.jdbc;import java.sql.SQLException;public class Driver extends NonRegisteringDriver implements java.sql.Driver {  static {    try {      java.sql.DriverManager.registerDriver(new Driver());    } catch (SQLException E) {      throw new RuntimeException(&quot;Can&#39;t register driver!&quot;);    }  }  /**   * Construct a new driver and register it with DriverManager   * @throws SQLException if a database error occurs.   */  public Driver() throws SQLException {    // Required for Class.forName().newInstance()  }}</code></pre><ul><li>在执行<code>Class.forName</code>的时候，首先是使得JVM查找并加载指定的Driver类，</li><li>其次是执行该类的静态代码<ul><li>实例变量需要在类实例化以后才能存在</li><li>静态变量是该类素有对象公有的，不需要实例化就已经存在了</li><li>静态代码会在类被加载的时候自动执行</li></ul></li></ul><pre><code>public class DriverManager {  private final static CopyOnWriteArrayList&lt;DriverInfo&gt; registeredDrivers = new CopyOnWriteArrayList&lt;DriverInfo&gt;();  //...  static {    loadInitialDrivers();    println(&quot;JDBC DriverManager initialized&quot;);  }  //...  public static synchronized void registerDriver(java.sql.Driver driver) throws SQLException {    if (driver != null) {      registeredDrivers.addIfAbsent(new DriverInfo(driver));    } else {      throw new NullPointerException();    }  }  public static Connection getConnection(String url, String user, String password) throws SQLException {    java.util.Properties info = new java.util.Properties();    if (user != null) {      info.put(&quot;user&quot;, user);    }    if (password != null) {      info.put(&quot;password&quot;, password);    }    return (getConnection(url, info, Reflection.getCallerClass()));  }  //...}</code></pre><ul><li>JDBC本身相当于抽象，即和具体的数据库无关的被抽象出来的一套类库</li><li>具体的Driver相当于实现</li></ul><h2 id="1-2-实例"><a href="#1-2-实例" class="headerlink" title="1.2 实例"></a>1.2 实例</h2><p>设计一个根据不同的告警规则，触发不同的类型的告警。</p><ul><li><p>紧急程度</p><ul><li>SEVERE</li><li>URGENCY</li><li>NORMAL</li><li>TRIVIAL</li></ul></li><li><p>通知渠道</p><ul><li>邮件</li><li>短信</li><li>微信</li><li>自动语音通话</li></ul></li><li><p>下述代码实质上就是在实现一个解耦，希望避免复杂的if else逻辑，让代码更易懂，修改更方便。</p></li></ul><pre><code>public interface MsgSender {  void send(String message);}public class TelephoneMsgSender implements MsgSender {  private List&lt;String&gt; telephones;  public TelephoneMsgSender(List&lt;String&gt; telephones) {    this.telephones = telephones;  }  @Override  public void send(String message) {    //...  }}public class EmailMsgSender implements MsgSender {  // 与TelephoneMsgSender代码结构类似，所以省略...}public class WechatMsgSender implements MsgSender {  // 与TelephoneMsgSender代码结构类似，所以省略...}public abstract class Notification {  protected MsgSender msgSender;  public Notification(MsgSender msgSender) {    this.msgSender = msgSender;  }  public abstract void notify(String message);}public class SevereNotification extends Notification {  public SevereNotification(MsgSender msgSender) {    super(msgSender);  }  @Override  public void notify(String message) {    msgSender.send(message);  }}public class UrgencyNotification extends Notification {  // 与SevereNotification代码结构类似，所以省略...}public class NormalNotification extends Notification {  // 与SevereNotification代码结构类似，所以省略...}public class TrivialNotification extends Notification {  // 与SevereNotification代码结构类似，所以省略...}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 桥接模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-结构型-代理模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E7%BB%93%E6%9E%84%E5%9E%8B-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>结构型模式主要总结了一些类和对象组合在一起的经典结构，这些经典的结构可以解决特定应用场景的问题。结构型模式包括：</p><ul><li>代理模式</li><li>桥接模式</li><li>装饰器模式</li><li>适配器模式</li><li>门面模式</li><li>组合模式</li><li>享元模式</li></ul><h1 id="1-代理模式原理解析"><a href="#1-代理模式原理解析" class="headerlink" title="1. 代理模式原理解析"></a>1. 代理模式原理解析</h1><ul><li>代理模式 Proxy Design Pattern <ul><li>在不改变原始类（被代理类）代码的情况下，通过引入代理类来给原始类附加功能</li></ul></li></ul><ul><li><p>下述是实现MetricsCollector的初始想法</p><ul><li><p>框架代码和业务代码耦合度太高，后期维护或者框架的更换代价都会很大</p></li><li><p>业务类职责最好单一，只聚焦业务处理</p><p>// Original idea for metricsCollector<br>public class UserController {<br>//…省略其他属性和方法…<br>private MetricsCollector metricsCollector; // 依赖注入</p><p>public UserVo login(String telephone, String password) {<br>  long startTimestamp = System.currentTimeMillis();</p><p>  // … 省略login逻辑…</p><p>  long endTimeStamp = System.currentTimeMillis();<br>  long responseTime = endTimeStamp - startTimestamp;<br>  RequestInfo requestInfo = new RequestInfo(“login”, responseTime, startTimestamp);<br>  metricsCollector.recordRequest(requestInfo);</p><p>  //…返回UserVo数据…<br>}</p><p>public UserVo register(String telephone, String password) {<br>  long startTimestamp = System.currentTimeMillis();</p><p>  // … 省略register逻辑…</p><p>  long endTimeStamp = System.currentTimeMillis();<br>  long responseTime = endTimeStamp - startTimestamp;<br>  RequestInfo requestInfo = new RequestInfo(“register”, responseTime, startTimestamp);<br>  metricsCollector.recordRequest(requestInfo);</p><p>  //…返回UserVo数据…<br>}<br>}</p></li></ul></li></ul><ul><li>构建代理类UserControllerProxy<ul><li>代理类UserCOntrollerProxy和原始类UserController实现相同的接口IUserController。UserController只负责业务功能，代理类UserControllerProxy负责在业务代码执行前后附加其他逻辑代码，并通过委托的方式来调用原始类执行业务代码。</li></ul></li></ul><pre><code>    public interface IUserController {      UserVo login(String telephone, String password);      UserVo register(String telephone, String password);    }    public class UserController implements IUserController {      //...省略其他属性和方法...      @Override      public UserVo login(String telephone, String password) {        //...省略login逻辑...        //...返回UserVo数据...      }      @Override      public UserVo register(String telephone, String password) {        //...省略register逻辑...        //...返回UserVo数据...      }    }    public class UserControllerProxy implements IUserController {      private MetricsCollector metricsCollector;      private UserController userController;      public UserControllerProxy(UserController userController) {        this.userController = userController;        this.metricsCollector = new MetricsCollector();      }      @Override      public UserVo login(String telephone, String password) {        long startTimestamp = System.currentTimeMillis();        // 委托        UserVo userVo = userController.login(telephone, password);        long endTimeStamp = System.currentTimeMillis();        long responseTime = endTimeStamp - startTimestamp;        RequestInfo requestInfo = new RequestInfo(&quot;login&quot;, responseTime, startTimestamp);        metricsCollector.recordRequest(requestInfo);        return userVo;      }      @Override      public UserVo register(String telephone, String password) {        long startTimestamp = System.currentTimeMillis();        UserVo userVo = userController.register(telephone, password);        long endTimeStamp = System.currentTimeMillis();        long responseTime = endTimeStamp - startTimestamp;        RequestInfo requestInfo = new RequestInfo(&quot;register&quot;, responseTime, startTimestamp);        metricsCollector.recordRequest(requestInfo);        return userVo;      }    }    //UserControllerProxy使用举例    //因为原始类和代理类实现相同的接口，是基于接口而非实现编程    //将UserController类对象替换为UserControllerProxy类对象，不需要改动太多代码    IUserController userController = new UserControllerProxy(new UserController());</code></pre><ul><li>面对原始类无接口，或者属于其他service无法做改动的时候，可以直接通过继承，来对其进行扩展</li></ul><pre><code>public class UserControllerProxy extends UserController {  private MetricsCollector metricsCollector;  public UserControllerProxy() {    this.metricsCollector = new MetricsCollector();  }  public UserVo login(String telephone, String password) {    long startTimestamp = System.currentTimeMillis();    UserVo userVo = super.login(telephone, password);    long endTimeStamp = System.currentTimeMillis();    long responseTime = endTimeStamp - startTimestamp;    RequestInfo requestInfo = new RequestInfo(&quot;login&quot;, responseTime, startTimestamp);    metricsCollector.recordRequest(requestInfo);    return userVo;  }  public UserVo register(String telephone, String password) {    long startTimestamp = System.currentTimeMillis();    UserVo userVo = super.register(telephone, password);    long endTimeStamp = System.currentTimeMillis();    long responseTime = endTimeStamp - startTimestamp;    RequestInfo requestInfo = new RequestInfo(&quot;register&quot;, responseTime, startTimestamp);    metricsCollector.recordRequest(requestInfo);    return userVo;  }}//UserControllerProxy使用举例UserController userController = new UserControllerProxy();</code></pre><h1 id="2-动态代理原理解析"><a href="#2-动态代理原理解析" class="headerlink" title="2. 动态代理原理解析"></a>2. 动态代理原理解析</h1><p>代理类的实现需要将原始类当中的所有方法都实现一遍，并加上你需要的代码逻辑，这样做会创建大量的代理类，很麻烦。因此我们需要使用动态代理来解决这个问题，即我们不事先为每个原始类编写代理类，而是在运行的时候，动态的创建原始类对应的代理类，然后在系统当中用代理类替换掉原始类。</p><p>Java本身用反射语法来实现动态代理。</p><pre><code>public class MetricsCollectorProxy {  private MetricsCollector metricsCollector;  public MetricsCollectorProxy() {    this.metricsCollector = new MetricsCollector();  }  public Object createProxy(Object proxiedObject) {    Class&lt;?&gt;[] interfaces = proxiedObject.getClass().getInterfaces();    DynamicProxyHandler handler = new DynamicProxyHandler(proxiedObject);    return Proxy.newProxyInstance(proxiedObject.getClass().getClassLoader(), interfaces, handler);  }  private class DynamicProxyHandler implements InvocationHandler {    private Object proxiedObject;    public DynamicProxyHandler(Object proxiedObject) {      this.proxiedObject = proxiedObject;    }    @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {      long startTimestamp = System.currentTimeMillis();      Object result = method.invoke(proxiedObject, args);      long endTimeStamp = System.currentTimeMillis();      long responseTime = endTimeStamp - startTimestamp;      String apiName = proxiedObject.getClass().getName() + &quot;:&quot; + method.getName();      RequestInfo requestInfo = new RequestInfo(apiName, responseTime, startTimestamp);      metricsCollector.recordRequest(requestInfo);      return result;    }  }}//MetricsCollectorProxy使用举例MetricsCollectorProxy proxy = new MetricsCollectorProxy();IUserController userController = (IUserController) proxy.createProxy(new UserController());</code></pre><ul><li><p>InvocationHandler </p><ul><li>java的标准接口</li></ul></li><li><p>创建Proxy 实例</p><ul><li>Proxy.newProxyInstance(classLoader, class, handlerClass)</li></ul></li><li><p>Spring的AOP的实现原理就是基于动态代理。用户配置好需要给哪些类创建代理，并定义好在执行原始类的业务代码前后执行哪些附加功能、Spring为这些类创建动态代理对象，并且在JVM中替代原始类对象。通过这种方式，实现了给原始类添加附加功能的目的。</p><h1 id="3-代理模式的应用场景"><a href="#3-代理模式的应用场景" class="headerlink" title="3. 代理模式的应用场景"></a>3. 代理模式的应用场景</h1></li><li><p>业务系统中的非功能性需求的开发</p><ul><li>监控</li><li>统计</li><li>鉴权</li><li>限流</li><li>事务</li><li>幂等</li><li>日志</li></ul></li><li><p>在RPC，缓存中的应用</p><ul><li>RPC将网络通信，数据编解码的细节隐藏起来</li><li>AOP切面完成接口缓存的功能</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.baeldung.com/java-dynamic-proxies" target="_blank" rel="noopener">https://www.baeldung.com/java-dynamic-proxies</a></li><li><a href="https://time.geekbang.org/column/article/201823" target="_blank" rel="noopener">https://time.geekbang.org/column/article/201823</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 代理模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-创建型-原型模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B-%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B-%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是原型模式"><a href="#1-什么是原型模式" class="headerlink" title="1. 什么是原型模式"></a>1. 什么是原型模式</h1><p>如果说对象的创建成本比较大，并且同一个类的不同对象之间的差别不大（大部分字段都相同），在这种情况下，我们可以利用对已有对象(原型)进行复制/拷贝的方式来创建新对象，来达到节省创建时间的目的。</p><ul><li>如何理解对象的创建成本比较大<ul><li>比如对象当中的数据需要经过复杂的计算才能得到（排序，哈希）</li><li>需要IO读取</li></ul></li></ul><p>在这种情况下，我们就可以利用原型模式，从其他已有对象当中直接拷贝，而不是在每次创建对象的时候，重复执行这个非常耗时的操作。</p><h1 id="2-如何使用原型模式"><a href="#2-如何使用原型模式" class="headerlink" title="2.如何使用原型模式"></a>2.如何使用原型模式</h1><h2 id="2-1-实际场景案例"><a href="#2-1-实际场景案例" class="headerlink" title="2.1 实际场景案例"></a>2.1 实际场景案例</h2><ul><li><p>数据库 存储10万条搜索关键词信息</p><ul><li><p>包含关键词，关键词被搜索次数，信息最近被更新的时间</p></li><li><p>系统A启动的时候会加载这份数据到内存当中，用于处理某些其他的业务需求</p></li><li><p>构建散列表索引 – hashmap</p><ul><li>key为搜索关键词</li><li>value为关键词的详细信息</li></ul></li><li><p>系统B分析搜索日志，每隔10分钟就批量更新数据库中的数据，并且标记为新的数据版本</p></li><li><p>系统A需要定期根据数据库的数据更新内存中的索引和数据</p></li></ul></li></ul><h2 id="2-2-根据需求的迭代"><a href="#2-2-根据需求的迭代" class="headerlink" title="2.2 根据需求的迭代"></a>2.2 根据需求的迭代</h2><ul><li>在系统A中记录更新时间，在数据库中拿出更新时间大于系统A当中的搜索关键词，然后针对差集中的每个关键词进行处理</li><li>如果在散列表中了，更新相应的搜索次数，更新时间等</li><li>如果不在，插入散列表当中</li></ul><pre><code>public class Demo {  private ConcurrentHashMap&lt;String, SearchWord&gt; currentKeywords = new ConcurrentHashMap&lt;&gt;();  private long lastUpdateTime = -1;  public void refresh() {    // 从数据库中取出更新时间&gt;lastUpdateTime的数据，放入到currentKeywords中    List&lt;SearchWord&gt; toBeUpdatedSearchWords = getSearchWords(lastUpdateTime);    long maxNewUpdatedTime = lastUpdateTime;    for (SearchWord searchWord : toBeUpdatedSearchWords) {      if (searchWord.getLastUpdateTime() &gt; maxNewUpdatedTime) {        maxNewUpdatedTime = searchWord.getLastUpdateTime();      }      if (currentKeywords.containsKey(searchWord.getKeyword())) {        currentKeywords.replace(searchWord.getKeyword(), searchWord);      } else {        currentKeywords.put(searchWord.getKeyword(), searchWord);      }    }    lastUpdateTime = maxNewUpdatedTime;  }  private List&lt;SearchWord&gt; getSearchWords(long lastUpdateTime) {    // TODO: 从数据库中取出更新时间&gt;lastUpdateTime的数据    return null;  }}</code></pre><ul><li>如果需要任何时刻系统A中的所有数据都必须是同一个版本的</li><li>更新内存数据的时候，系统A不能处于不可用的状态，不能停机更新数据<ul><li>针对需求，我们需要出了正在使用的服务版本之外，创建另外一个版本的数据。当新的版本数据建好之后，再一次性地将服务版本进行切换</li><li>可以保证数据一直可用，并且避免中间状态的存在</li></ul></li></ul><pre><code>public class Demo {  private HashMap&lt;String, SearchWord&gt; currentKeywords=new HashMap&lt;&gt;();  public void refresh() {    HashMap&lt;String, SearchWord&gt; newKeywords = new LinkedHashMap&lt;&gt;();    // 从数据库中取出所有的数据，放入到newKeywords中    List&lt;SearchWord&gt; toBeUpdatedSearchWords = getSearchWords();    for (SearchWord searchWord : toBeUpdatedSearchWords) {      newKeywords.put(searchWord.getKeyword(), searchWord);    }    currentKeywords = newKeywords;  }  private List&lt;SearchWord&gt; getSearchWords() {    // TODO: 从数据库中取出所有的数据    return null;  }}</code></pre><ul><li>新数据结构的构建成本非常高，需要IO读出数据库，计算哈希值，构建newKeywords</li><li>我们可以拷贝当前的版本到新的待处理的散列表当中，然后从数据库当中拿出新增或者有更新的关键词，来做更新</li></ul><pre><code>public class Demo {  private HashMap&lt;String, SearchWord&gt; currentKeywords=new HashMap&lt;&gt;();  private long lastUpdateTime = -1;  public void refresh() {    // 原型模式就这么简单，拷贝已有对象的数据，更新少量差值    HashMap&lt;String, SearchWord&gt; newKeywords = (HashMap&lt;String, SearchWord&gt;) currentKeywords.clone();    // 从数据库中取出更新时间&gt;lastUpdateTime的数据，放入到newKeywords中    List&lt;SearchWord&gt; toBeUpdatedSearchWords = getSearchWords(lastUpdateTime);    long maxNewUpdatedTime = lastUpdateTime;    for (SearchWord searchWord : toBeUpdatedSearchWords) {      if (searchWord.getLastUpdateTime() &gt; maxNewUpdatedTime) {        maxNewUpdatedTime = searchWord.getLastUpdateTime();      }      if (newKeywords.containsKey(searchWord.getKeyword())) {        SearchWord oldSearchWord = newKeywords.get(searchWord.getKeyword());        oldSearchWord.setCount(searchWord.getCount());        oldSearchWord.setLastUpdateTime(searchWord.getLastUpdateTime());      } else {        newKeywords.put(searchWord.getKeyword(), searchWord);      }    }    lastUpdateTime = maxNewUpdatedTime;    currentKeywords = newKeywords;  }  private List&lt;SearchWord&gt; getSearchWords(long lastUpdateTime) {    // TODO: 从数据库中取出更新时间&gt;lastUpdateTime的数据    return null;  }}</code></pre><ul><li>上述代码做的是浅拷贝，因为在散列表当中，key存的是搜索关键词，而value实际上存储的是对象的内存地址</li><li>当我们做浅拷贝的时候，我们实际上是把内存地址给拷贝了过来；这样的话当我们做修改的话，实际上两个版本的数据都做了变动，并没有将其彻底的分割开</li><li>我们实际需要的是深拷贝，即不仅仅复制索引，并且复制数据本身<ul><li>递归拷贝对象，对象的引用对象以及引用对象的引用对象</li><li>先将对象序列化，再反序列化成新对象</li></ul></li></ul><pre><code>// 实现递归深拷贝public class Demo {  private HashMap&lt;String, SearchWord&gt; currentKeywords=new HashMap&lt;&gt;();  private long lastUpdateTime = -1;  public void refresh() {    // Deep copy    HashMap&lt;String, SearchWord&gt; newKeywords = new HashMap&lt;&gt;();    for (HashMap.Entry&lt;String, SearchWord&gt; e : currentKeywords.entrySet()) {      SearchWord searchWord = e.getValue();      SearchWord newSearchWord = new SearchWord(              searchWord.getKeyword(), searchWord.getCount(), searchWord.getLastUpdateTime());      newKeywords.put(e.getKey(), newSearchWord);    }    // 从数据库中取出更新时间&gt;lastUpdateTime的数据，放入到newKeywords中    List&lt;SearchWord&gt; toBeUpdatedSearchWords = getSearchWords(lastUpdateTime);    long maxNewUpdatedTime = lastUpdateTime;    for (SearchWord searchWord : toBeUpdatedSearchWords) {      if (searchWord.getLastUpdateTime() &gt; maxNewUpdatedTime) {        maxNewUpdatedTime = searchWord.getLastUpdateTime();      }      if (newKeywords.containsKey(searchWord.getKeyword())) {        SearchWord oldSearchWord = newKeywords.get(searchWord.getKeyword());        oldSearchWord.setCount(searchWord.getCount());        oldSearchWord.setLastUpdateTime(searchWord.getLastUpdateTime());      } else {        newKeywords.put(searchWord.getKeyword(), searchWord);      }    }    lastUpdateTime = maxNewUpdatedTime;    currentKeywords = newKeywords;  }  private List&lt;SearchWord&gt; getSearchWords(long lastUpdateTime) {    // TODO: 从数据库中取出更新时间&gt;lastUpdateTime的数据    return null;  }}// 实现递归深拷贝public Object deepCopy(Object object) {  ByteArrayOutputStream bo = new ByteArrayOutputStream();  ObjectOutputStream oo = new ObjectOutputStream(bo);  oo.writeObject(object);  ByteArrayInputStream bi = new ByteArrayInputStream(bo.toByteArray());  ObjectInputStream oi = new ObjectInputStream(bi);  return oi.readObject();}</code></pre><ul><li>最快的方式，是可以先用浅拷贝来创建，对于需要更新的对象，再用深拷贝的方式创建一份新的对象，来做替换</li></ul><pre><code>public class Demo {  private HashMap&lt;String, SearchWord&gt; currentKeywords=new HashMap&lt;&gt;();  private long lastUpdateTime = -1;  public void refresh() {    // Shallow copy    HashMap&lt;String, SearchWord&gt; newKeywords = (HashMap&lt;String, SearchWord&gt;) currentKeywords.clone();    // 从数据库中取出更新时间&gt;lastUpdateTime的数据，放入到newKeywords中    List&lt;SearchWord&gt; toBeUpdatedSearchWords = getSearchWords(lastUpdateTime);    long maxNewUpdatedTime = lastUpdateTime;    for (SearchWord searchWord : toBeUpdatedSearchWords) {      if (searchWord.getLastUpdateTime() &gt; maxNewUpdatedTime) {        maxNewUpdatedTime = searchWord.getLastUpdateTime();      }      if (newKeywords.containsKey(searchWord.getKeyword())) {        newKeywords.remove(searchWord.getKeyword());      }      newKeywords.put(searchWord.getKeyword(), searchWord);    }    lastUpdateTime = maxNewUpdatedTime;    currentKeywords = newKeywords;  }  private List&lt;SearchWord&gt; getSearchWords(long lastUpdateTime) {    // TODO: 从数据库中取出更新时间&gt;lastUpdateTime的数据    return null;  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 原型模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-创建型-建造者模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B-%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B-%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-为什么需要建造者模式"><a href="#1-为什么需要建造者模式" class="headerlink" title="1. 为什么需要建造者模式"></a>1. 为什么需要建造者模式</h1><p>一个关于如何使用建造者模式的问题是：当我们能够使用构造函数或者使用set方法就能够创建对象的时候，我们为什么会需要建造者模式来创建呢？ </p><p>一个例子，假设我们要定义一个类，其大部分的属性都是可以选择的，那么我们可以使用构造函数来做如下的声明： </p><pre><code>public class ResourcePoolConfig {  private static final int DEFAULT_MAX_TOTAL = 8;  private static final int DEFAULT_MAX_IDLE = 8;  private static final int DEFAULT_MIN_IDLE = 0;  private String name;  private int maxTotal = DEFAULT_MAX_TOTAL;  private int maxIdle = DEFAULT_MAX_IDLE;  private int minIdle = DEFAULT_MIN_IDLE;  public ResourcePoolConfig(String name, Integer maxTotal, Integer maxIdle, Integer minIdle) {    if (StringUtils.isBlank(name)) {      throw new IllegalArgumentException(&quot;name should not be empty.&quot;);    }    this.name = name;    if (maxTotal != null) {      if (maxTotal &lt;= 0) {        throw new IllegalArgumentException(&quot;maxTotal should be positive.&quot;);      }      this.maxTotal = maxTotal;    }    if (maxIdle != null) {      if (maxIdle &lt; 0) {        throw new IllegalArgumentException(&quot;maxIdle should not be negative.&quot;);      }      this.maxIdle = maxIdle;    }    if (minIdle != null) {      if (minIdle &lt; 0) {        throw new IllegalArgumentException(&quot;minIdle should not be negative.&quot;);      }      this.minIdle = minIdle;    }  }  //...省略getter方法...}</code></pre><p>在这个例子当中，除了name以外的所有选项都是可选的，因此会看到在构造函数当中，我们做了很多的null check。这样做当参数很多的时候，是很难看懂的。我们可以将其改良为一系列的set()函数，构造函数只实例化NonNull的参数，对于Nullable的参数，我们可以用set方法来实现声明。如下所示： </p><pre><code>public class ResourcePoolConfig {  private static final int DEFAULT_MAX_TOTAL = 8;  private static final int DEFAULT_MAX_IDLE = 8;  private static final int DEFAULT_MIN_IDLE = 0;  private String name;  private int maxTotal = DEFAULT_MAX_TOTAL;  private int maxIdle = DEFAULT_MAX_IDLE;  private int minIdle = DEFAULT_MIN_IDLE;  public ResourcePoolConfig(String name) {    if (StringUtils.isBlank(name)) {      throw new IllegalArgumentException(&quot;name should not be empty.&quot;);    }    this.name = name;  }  public void setMaxTotal(int maxTotal) {    if (maxTotal &lt;= 0) {      throw new IllegalArgumentException(&quot;maxTotal should be positive.&quot;);    }    this.maxTotal = maxTotal;  }  public void setMaxIdle(int maxIdle) {    if (maxIdle &lt; 0) {      throw new IllegalArgumentException(&quot;maxIdle should not be negative.&quot;);    }    this.maxIdle = maxIdle;  }  public void setMinIdle(int minIdle) {    if (minIdle &lt; 0) {      throw new IllegalArgumentException(&quot;minIdle should not be negative.&quot;);    }    this.minIdle = minIdle;  }  //...省略getter方法...}</code></pre><p>上述的set方法还是有一些缺陷的，即：</p><ul><li>首先如果必填的配置项有很多，且都需要放置到构造函数当中，那构造函数就会出现参数列表很长的问题了。</li><li>假设配置项之间有一定的依赖关系，我们需要将配置项之间的依赖关系和校验逻辑找地方放</li><li>如果我们希望类对象是不可变对象，即对象在创建好之后就不能再修改内部的属性值，那么我们就不能再ResourcePoolConfig类当中暴露set()方法</li></ul><p>Builder模式可以很好的解决上述我们的需求，我们可以将校验逻辑放在调用build()方法之前，也可以将构造函数私有化，这样就只能通过建造者来创建ResourcePoolConfig类对象</p><h1 id="2-如何使用建造者模式构建对象"><a href="#2-如何使用建造者模式构建对象" class="headerlink" title="2. 如何使用建造者模式构建对象"></a>2. 如何使用建造者模式构建对象</h1><pre><code>public class ResourcePoolConfig {  private String name;  private int maxTotal;  private int maxIdle;  private int minIdle;  private ResourcePoolConfig(Builder builder) {    this.name = builder.name;    this.maxTotal = builder.maxTotal;    this.maxIdle = builder.maxIdle;    this.minIdle = builder.minIdle;  }  //...省略getter方法...  //我们将Builder类设计成了ResourcePoolConfig的内部类。  //我们也可以将Builder类设计成独立的非内部类ResourcePoolConfigBuilder。  public static class Builder {    private static final int DEFAULT_MAX_TOTAL = 8;    private static final int DEFAULT_MAX_IDLE = 8;    private static final int DEFAULT_MIN_IDLE = 0;    private String name;    private int maxTotal = DEFAULT_MAX_TOTAL;    private int maxIdle = DEFAULT_MAX_IDLE;    private int minIdle = DEFAULT_MIN_IDLE;    public ResourcePoolConfig build() {      // 校验逻辑放到这里来做，包括必填项校验、依赖关系校验、约束条件校验等      if (StringUtils.isBlank(name)) {        throw new IllegalArgumentException(&quot;...&quot;);      }      if (maxIdle &gt; maxTotal) {        throw new IllegalArgumentException(&quot;...&quot;);      }      if (minIdle &gt; maxTotal || minIdle &gt; maxIdle) {        throw new IllegalArgumentException(&quot;...&quot;);      }      return new ResourcePoolConfig(this);    }    public Builder setName(String name) {      if (StringUtils.isBlank(name)) {        throw new IllegalArgumentException(&quot;...&quot;);      }      this.name = name;      return this;    }    public Builder setMaxTotal(int maxTotal) {      if (maxTotal &lt;= 0) {        throw new IllegalArgumentException(&quot;...&quot;);      }      this.maxTotal = maxTotal;      return this;    }    public Builder setMaxIdle(int maxIdle) {      if (maxIdle &lt; 0) {        throw new IllegalArgumentException(&quot;...&quot;);      }      this.maxIdle = maxIdle;      return this;    }    public Builder setMinIdle(int minIdle) {      if (minIdle &lt; 0) {        throw new IllegalArgumentException(&quot;...&quot;);      }      this.minIdle = minIdle;      return this;    }  }}// 这段代码会抛出IllegalArgumentException，因为minIdle&gt;maxIdleResourcePoolConfig config = new ResourcePoolConfig.Builder()        .setName(&quot;dbconnectionpool&quot;)        .setMaxTotal(16)        .setMaxIdle(10)        .setMinIdle(12)        .build();</code></pre><h1 id="3-何时使用"><a href="#3-何时使用" class="headerlink" title="3. 何时使用"></a>3. 何时使用</h1><p>建造者模式用来创建一种类型的复杂对象，通过设置不同的可选参数，定制化地创建不同的对象。建造者模式和工厂模式的区别可以用一个例子来说明，顾客走进一家餐馆点餐，我们利用工厂模式，根据用户不同的选择，来制作不同的食物，比如披萨、汉堡、沙拉。对于披萨来说，用户又有各种配料可以定制，比如奶酪、西红柿、起司，我们通过建造者模式根据用户选择的不同配料来制作披萨。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 建造者模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-创建型-工厂模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B-%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B-%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-简单工厂-Simple-Factory"><a href="#1-简单工厂-Simple-Factory" class="headerlink" title="1. 简单工厂 Simple Factory"></a>1. 简单工厂 Simple Factory</h1><p>假设要做一个parser类，根据后缀来实例化Parser</p><pre><code>public class RuleConfigSource {  public RuleConfig load(String ruleConfigFilePath) {    String ruleConfigFileExtension = getFileExtension(ruleConfigFilePath);    IRuleConfigParser parser = RuleConfigParserFactory.createParser(ruleConfigFileExtension);    if (parser == null) {      throw new InvalidRuleConfigException(              &quot;Rule config file format is not supported: &quot; + ruleConfigFilePath);    }    String configText = &quot;&quot;;    //从ruleConfigFilePath文件中读取配置文本到configText中    RuleConfig ruleConfig = parser.parse(configText);    return ruleConfig;  }  private String getFileExtension(String filePath) {    //...解析文件名获取扩展名，比如rule.json，返回json    return &quot;json&quot;;  }}public class RuleConfigParserFactory {  public static IRuleConfigParser createParser(String configFormat) {    IRuleConfigParser parser = null;    if (&quot;json&quot;.equalsIgnoreCase(configFormat)) {      parser = new JsonRuleConfigParser();    } else if (&quot;xml&quot;.equalsIgnoreCase(configFormat)) {      parser = new XmlRuleConfigParser();    } else if (&quot;yaml&quot;.equalsIgnoreCase(configFormat)) {      parser = new YamlRuleConfigParser();    } else if (&quot;properties&quot;.equalsIgnoreCase(configFormat)) {      parser = new PropertiesRuleConfigParser();    }    return parser;  }}</code></pre><p>上述代码是创建了工厂类，并且在工厂类当中制定了静态方法，根据输入参数的不同来分别实例化不同的parser。一般来说工厂当中创建对象的方法都是create开头，或者说明对于instance的操作，常见的方法名比如：</p><ul><li>createXXX()</li><li>getInstance()</li><li>createInstance()</li><li>newInstance() </li></ul><p>同样，如果要声明的类时很可能可以复用的，那么我们就可以在调用前就创建好，来节省对象创建的时间</p><pre><code>public class RuleConfigParserFactory {  private static final Map&lt;String, RuleConfigParser&gt; cachedParsers = new HashMap&lt;&gt;();  static {    cachedParsers.put(&quot;json&quot;, new JsonRuleConfigParser());    cachedParsers.put(&quot;xml&quot;, new XmlRuleConfigParser());    cachedParsers.put(&quot;yaml&quot;, new YamlRuleConfigParser());    cachedParsers.put(&quot;properties&quot;, new PropertiesRuleConfigParser());  }  public static IRuleConfigParser createParser(String configFormat) {    if (configFormat == null || configFormat.isEmpty()) {      return null;//返回null还是IllegalArgumentException全凭你自己说了算    }    IRuleConfigParser parser = cachedParsers.get(configFormat.toLowerCase());    return parser;  }}</code></pre><h1 id="2-工厂方法"><a href="#2-工厂方法" class="headerlink" title="2. 工厂方法"></a>2. 工厂方法</h1><p>利用多态将if分支逻辑给去掉： </p><pre><code>public interface IRuleConfigParserFactory {  IRuleConfigParser createParser();}public class JsonRuleConfigParserFactory implements IRuleConfigParserFactory {  @Override  public IRuleConfigParser createParser() {    return new JsonRuleConfigParser();  }}public class XmlRuleConfigParserFactory implements IRuleConfigParserFactory {  @Override  public IRuleConfigParser createParser() {    return new XmlRuleConfigParser();  }}public class YamlRuleConfigParserFactory implements IRuleConfigParserFactory {  @Override  public IRuleConfigParser createParser() {    return new YamlRuleConfigParser();  }}public class PropertiesRuleConfigParserFactory implements IRuleConfigParserFactory {  @Override  public IRuleConfigParser createParser() {    return new PropertiesRuleConfigParser();  }}// 关于如何选取需要import的factory，使用hashmap，相当于为工厂类创建了一个简单的工厂；一种委托给别人进行生产的模式思路public class RuleConfigSource {  public RuleConfig load(String ruleConfigFilePath) {    String ruleConfigFileExtension = getFileExtension(ruleConfigFilePath);    IRuleConfigParserFactory parserFactory = RuleConfigParserFactoryMap.getParserFactory(ruleConfigFileExtension);    if (parserFactory == null) {      throw new InvalidRuleConfigException(&quot;Rule config file format is not supported: &quot; + ruleConfigFilePath);    }    IRuleConfigParser parser = parserFactory.createParser();    String configText = &quot;&quot;;    //从ruleConfigFilePath文件中读取配置文本到configText中    RuleConfig ruleConfig = parser.parse(configText);    return ruleConfig;  }  private String getFileExtension(String filePath) {    //...解析文件名获取扩展名，比如rule.json，返回json    return &quot;json&quot;;  }}//因为工厂类只包含方法，不包含成员变量，完全可以复用，//不需要每次都创建新的工厂类对象，所以，简单工厂模式的第二种实现思路更加合适。public class RuleConfigParserFactoryMap { //工厂的工厂  private static final Map&lt;String, IRuleConfigParserFactory&gt; cachedFactories = new HashMap&lt;&gt;();  static {    cachedFactories.put(&quot;json&quot;, new JsonRuleConfigParserFactory());    cachedFactories.put(&quot;xml&quot;, new XmlRuleConfigParserFactory());    cachedFactories.put(&quot;yaml&quot;, new YamlRuleConfigParserFactory());    cachedFactories.put(&quot;properties&quot;, new PropertiesRuleConfigParserFactory());  }  public static IRuleConfigParserFactory getParserFactory(String type) {    if (type == null || type.isEmpty()) {      return null;    }    IRuleConfigParserFactory parserFactory = cachedFactories.get(type.toLowerCase());    return parserFactory;  }}</code></pre><h2 id="2-1-工厂模式的好处"><a href="#2-1-工厂模式的好处" class="headerlink" title="2.1 工厂模式的好处"></a>2.1 工厂模式的好处</h2><ul><li>工程上一般来说使用工厂模式可以减少if else的使用，减少对于代码的侵入，可以通过反射来动态获取Bean </li><li><code>AbstractCart cart = (AbstractCart) applicationContext.getBean(userCategory + &quot;UserCart&quot;); return cart.process(userId, items);}</code></li></ul><h1 id="3-Dependency-Injection-框架"><a href="#3-Dependency-Injection-框架" class="headerlink" title="3. Dependency Injection 框架"></a>3. Dependency Injection 框架</h1><p>依赖注入框架想要解决的是在基于Inversion of control的理念下，我们应该如何做，如何简化整个创建对象的过程。</p><p>DI容器底层最基本的设计思路是基于工厂模式来进行的，DI容器就相当于一个大的工厂类，复杂在程序启动的时候，根据配置（需要创建哪些类对象，每个类对象的创建需要依赖哪些其他类的对象）事先创建好对象。当应用程序需要使用某个类对象的时候，直接从容器当中获取即可。</p><p>DI容器的核心功能主要有：</p><ul><li>配置解析</li><li>对象创建</li><li>对象生命周期管理</li></ul><h2 id="3-1-配置解析"><a href="#3-1-配置解析" class="headerlink" title="3.1 配置解析"></a>3.1 配置解析</h2><p>应用需要告知DI容器需要创建哪些对象，需要将由DI容器来创建的类对象和创建类对象的必要信息，放到配置文件当中。容器读取配置文件，根据配置文件提供的信息来创建对象。像在spring当中，就是依靠xml文件或者注解，来告诉spring 用何种方式来创建对象。</p><h2 id="3-2-对象创建"><a href="#3-2-对象创建" class="headerlink" title="3.2 对象创建"></a>3.2 对象创建</h2><p>Spring当中将所有类对象的创建都放到了一个工厂类当中实现</p><h2 id="3-3-对象生命周期管理"><a href="#3-3-对象生命周期管理" class="headerlink" title="3.3 对象生命周期管理"></a>3.3 对象生命周期管理</h2><ul><li><p>通过配置scope属性，决定是每次都返回一个新创建的对象还是每次都返回一个事先创建好的对象 – 单例对象</p></li><li><p>配置是否懒加载；lazy-init</p><ul><li>真正被使用的时候被创建</li><li>在应用启动的时候就事先创建好</li></ul></li><li><p>配置对象的init-method, destroy-method </p><ul><li>DI容器在创建好对象之后，会主动调用init-method属性指定的方法来初始化对象</li><li>在对象被最终销毁之前，DI容器会主动调用destroy-method属性指定的方法来做一些清理工作</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工厂模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>思维模型的搜集/整理</title>
      <link href="/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%90%9C%E9%9B%86-%E6%95%B4%E7%90%86/"/>
      <url>/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%90%9C%E9%9B%86-%E6%95%B4%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>看到了Adam Amran的<a href="https://untools.co/，感觉是有一些元知识是衍生的根本，希望能够用这篇blog作为总结分享的集散地，把自己看到的认为在某些方面有实际效用的思维模型分享给大家。" target="_blank" rel="noopener">https://untools.co/，感觉是有一些元知识是衍生的根本，希望能够用这篇blog作为总结分享的集散地，把自己看到的认为在某些方面有实际效用的思维模型分享给大家。</a></p><h1 id="1-问题树-Issue-Tree"><a href="#1-问题树-Issue-Tree" class="headerlink" title="1. 问题树 - Issue Tree"></a>1. 问题树 - <a href="https://untools.co/issue-trees" target="_blank" rel="noopener">Issue Tree</a></h1><h2 id="1-1-是什么"><a href="#1-1-是什么" class="headerlink" title="1.1 是什么"></a>1.1 是什么</h2><ul><li>一个问题地图</li><li>旨在给你需要解决的问题一个清晰而系统的思考方式</li><li>帮助你对问题进行拆分，其实很符合divide and conquer 即分治的思想</li></ul><p>对自己而言，确实有在做，在思考。值得注意且需要加强的一点是MECE原则 – mutually exclusive, collectively exhaustive。 对提高思维的完备性很有作用</p><h2 id="1-2-怎么做"><a href="#1-2-怎么做" class="headerlink" title="1.2 怎么做"></a>1.2 怎么做</h2><ul><li><p>问题树应该能够覆盖所有的问题，需要非常细致</p></li><li><p>一些需要遵循的原则</p><ul><li><p><strong>MECE - mutually exclusive, collectively exhaustive</strong> </p><ul><li><strong>需要做到相互之间没有交集，并集即为全集</strong></li></ul></li><li><p>不要过度纠结于太小的细节，需要先做大类目的划分，来定义问题</p></li><li><p>二八法则，专注于起于数据的有价值的问题</p></li></ul></li></ul><h1 id="2-Second-order-thinking"><a href="#2-Second-order-thinking" class="headerlink" title="2. Second-order thinking"></a>2. <a href="https://untools.co/second-order-thinking" target="_blank" rel="noopener">Second-order thinking</a></h1><h2 id="2-1-Overview"><a href="#2-1-Overview" class="headerlink" title="2.1 Overview"></a>2.1 Overview</h2><p>有的时候我们下的决定看起来直观上会给我们带来好处，但是长远看来是对我们不利的。我们通常的思考链条是 需求 - 设定方案 - 评估方案 - 执行。其实大到公司的项目，小到晚上吃什么，我们的脑海里都会先给出需求，饿了，需要吃饭。到设定方案，在家吃vs出去吃，然后是吃什么，然后做出决定，并且按照决定来执行。</p><p>这种思考方式希望你做的是在要做出决定的时候，在想了决定的直接影响之后。再多问自己一个问题，即 – 然后呢？ 这个决定后续还会带来什么结果呢？ </p><p><strong>从事情发展的阶段来看，思考二度的发展；也可以从时间维度，去思考做出的决定在接下来几天，几个月，甚至相对更长的时间里可能对你带来的影响。</strong></p><h1 id="3-第一性原理"><a href="#3-第一性原理" class="headerlink" title="3. 第一性原理"></a>3. 第一性原理</h1><p>在每一种系统的探索当中，存在第一性原理，这是一个最基本的命题或假设，不能被忽略或删除，也不能被违反。</p><p>首先是归纳法与演绎法的对比，我们生活中最经常使用的是归纳法，即根据经验，现象到结果的链条来总结事情是如何发生的；而演绎法是基于一些元知识，做出自己的推论。</p><p>第一性原理 – First Principle，说的就是不能被省略，不能被删除，不能违反的最基本的命题或假设。是演绎法的一种，即从根本原理上，剔除干扰因素和常识性知识的思考方法。目的是希望能够将人从错综复杂的现实问题中换一个视角，将复杂的事情努力转化为简单的结构，来从源头上理解。</p><p>“我们运用第一性原理，而不是比较思维去思考问题是非常重要的。我们在生活中总是倾向于比较，对别人已经做过或者正在做的事情我们也都去做，这样发展的结果只能产生细小的迭代发展。</p><p>第一性原理的思想方式是用物理学的角度看待世界，也就是说一层层拨开事物表象，看到里面的本质，再从本质一层层往上走。”</p><h2 id="3-1-如何使用第一性原理"><a href="#3-1-如何使用第一性原理" class="headerlink" title="3.1 如何使用第一性原理"></a>3.1 如何使用第一性原理</h2><ul><li><p>苏格拉底式的提问</p><ul><li>问题源头，源起，具体表现形式？</li><li>这个情况总是发生么？什么因素会导致问题出现？</li><li>假设的证据在哪里？是否可靠？</li><li>替代观点和角度</li><li>影响和后果</li><li>对问题本身的质疑</li></ul></li><li><p>实践过程</p><ul><li>溯源</li><li>拆解</li><li>重构</li><li>迭代</li></ul></li><li><p>比较思维 vs 第一性原理</p><ul><li>看资讯</li><li>自己总结分析想法</li></ul></li></ul><h1 id="4-抽象梯子"><a href="#4-抽象梯子" class="headerlink" title="4. 抽象梯子"></a>4. 抽象梯子</h1><p>通过在不同的抽象层的移动来更好的构建你的问题。我们可以向上移动，从更大的视角看问题，看到树木背后的森林；也可以向下移动，来演化出一个更加精细的解决方案。</p><h2 id="4-1-如何使用"><a href="#4-1-如何使用" class="headerlink" title="4.1 如何使用"></a>4.1 如何使用</h2><ul><li>从一个普通的问题开始</li><li>通过问为什么来获得更大更远的视角</li><li>通过问如何做来逐步获得一个更具体的解决方案</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://untools.co/issue-trees" target="_blank" rel="noopener">https://untools.co/issue-trees</a></li><li><a href="https://medium.com/@idtimw/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B03-first-principles-%E7%AC%AC%E4%B8%80%E6%80%A7%E5%8E%9F%E7%90%86-7571fc664faf" target="_blank" rel="noopener">https://medium.com/@idtimw/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B03-first-principles-%E7%AC%AC%E4%B8%80%E6%80%A7%E5%8E%9F%E7%90%86-7571fc664faf</a></li><li><a href="http://fund.jrj.com.cn/2018/06/04151524634381.shtml" target="_blank" rel="noopener">http://fund.jrj.com.cn/2018/06/04151524634381.shtml</a></li><li><a href="https://36kr.com/p/5068808" target="_blank" rel="noopener">https://36kr.com/p/5068808</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 思维模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式-创建型-单例模式</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-为什么需要单例模式"><a href="#1-为什么需要单例模式" class="headerlink" title="1. 为什么需要单例模式"></a>1. 为什么需要单例模式</h1><p>windows系统的任务管理器，只能有一个,唯一性的原因：</p><ol><li>如果能弹出多个窗口，且这些窗口的内容完全一致，全都是重复对象，那势必会浪费资源，尤其是任务管理器会需要进入内核态调取各种状态信息，会对性能造成一定的影响。</li><li>而且多个窗口之间需要保持一致性，绝对的同步，相互之间的同步也是资源的浪费。</li></ol><p>现实中的例子，就是为了节约系统资源，有时需要确保系统中某个类只有唯一一个实例，当这个实例创建成功以后，我们无法再创建一个同类型的其他对象，所有的操作都只能基于这个唯一的实例。</p><h2 id="1-1-处理资源的访问冲突"><a href="#1-1-处理资源的访问冲突" class="headerlink" title="1.1 处理资源的访问冲突"></a>1.1 处理资源的访问冲突</h2><p>下述代码自定义了一个往文件当中打印日志的logger类： </p><pre><code>public class Logger {  private FileWriter writer;  public Logger() {    File file = new File(&quot;/Users/leilei/log.txt&quot;);    writer = new FileWriter(file, true); //true表示追加写入  }  public void log(String message) {    writer.write(mesasge);  }}// Logger类的应用示例：public class UserController {  private Logger logger = new Logger();  public void login(String username, String password) {    // ...省略业务逻辑代码...    logger.log(username + &quot; logined!&quot;);  }}public class OrderController {  private Logger logger = new Logger();  public void create(OrderVo order) {    // ...省略业务逻辑代码...    logger.log(&quot;Created an order: &quot; + order.toString());  }}</code></pre><p>这段代码的问题在于每个类在实现的过程中都创建了一个新的Logger对象，如果我们同时创建了两个controller，然后执行的话，会同时写入同一个文件当中，这会有可能导致日志信息互相覆盖的情况。</p><p>想要解决这个问题，我们需要加上类级别的锁，让所有的对象都能够共享一把锁：</p><pre><code>public class Logger {  private FileWriter writer;  public Logger() {    File file = new File(&quot;/Users/wangzheng/log.txt&quot;);    writer = new FileWriter(file, true); //true表示追加写入  }  public void log(String message) {    synchronized(Logger.class) { // 类级别的锁      writer.write(mesasge);    }  }}</code></pre><p>我们也可以使用单例模式，使得程序当中只允许创建一个Logger对象，所有的线程共享这一个Logger对象，共享一个FileWriter对象（本身有对象级别的线程安全的保障）</p><pre><code>public class Logger {  private FileWriter writer;  private static final Logger instance = new Logger();  private Logger() {    File file = new File(&quot;/Users/leilei/log.txt&quot;);    writer = new FileWriter(file, true); //true表示追加写入  }  public static Logger getInstance() {    return instance;  }  public void log(String message) {    writer.write(mesasge);  }}// Logger类的应用示例：public class UserController {  public void login(String username, String password) {    // ...省略业务逻辑代码...    Logger.getInstance().log(username + &quot; logined!&quot;);  }}public class OrderController {    public void create(OrderVo order) {    // ...省略业务逻辑代码...    Logger.getInstance().log(&quot;Created a order: &quot; + order.toString());  }}</code></pre><h2 id="1-2-表示全局唯一类"><a href="#1-2-表示全局唯一类" class="headerlink" title="1.2 表示全局唯一类"></a>1.2 表示全局唯一类</h2><p>对于只应该在系统当中保存一份的数据，比较适合设计为单例类。</p><pre><code>import java.util.concurrent.atomic.AtomicLong;public class IdGenerator {  // AtomicLong是一个Java并发库中提供的一个原子变量类型,  // 它将一些线程不安全需要加锁的复合操作封装为了线程安全的原子操作，  // 比如下面会用到的incrementAndGet().  private AtomicLong id = new AtomicLong(0);  private static final IdGenerator instance = new IdGenerator();  private IdGenerator() {}  public static IdGenerator getInstance() {    return instance;  }  public long getId() {     return id.incrementAndGet();  }}// IdGenerator使用举例long id = IdGenerator.getInstance().getId();</code></pre><h1 id="2-单例模式概述"><a href="#2-单例模式概述" class="headerlink" title="2. 单例模式概述"></a>2. 单例模式概述</h1><ul><li><p>单例的定义</p><ul><li>一个类只允许创建唯一一个对象，那这个类就是一个单例类</li></ul></li><li><p>对象的唯一性指</p><ul><li>进程内只允许创建一个对象</li><li>进程之间是不唯一的</li></ul></li></ul><h2 id="2-1-模拟任务管理类"><a href="#2-1-模拟任务管理类" class="headerlink" title="2.1 模拟任务管理类"></a>2.1 模拟任务管理类</h2><pre><code>class TaskManager{     public TaskManager() {...} //初始化窗口     public void displayProcesses()  {……} //显示进程     public void  displayServices() {……} //显示服务}</code></pre><p>对其进行重构，为了使其是单一实例的，那我们需要禁止类的外部直接使用new来创建对象  —–&gt;  将其构造函数的可见性变为private</p><pre><code>public TaskManager() {...}</code></pre><p>在类内部创建对象，保存这个唯一实例</p><pre><code>private static TaskManager tm = null;public static TaskManager getInstance() {    if (tm == null) {        tm = new TaskManager();    }    return tm;}</code></pre><p><code>getInstance()</code>定义成一个静态方法，这样可以直接通过类名来使用</p><h2 id="2-2-定义"><a href="#2-2-定义" class="headerlink" title="2.2 定义"></a>2.2 定义</h2><blockquote><p>单例模式(Singleton Pattern)：确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式是一种对象创建型模式。</p></blockquote><ol><li>只有一个实例</li><li>必须自行创建这个实例</li><li>必须自行向整个系统提供这个实例</li></ol><p><img src="https://i.loli.net/2020/02/03/vKPVAeCrImYXq1U.gif" alt="s1.gif"></p><h2 id="2-3-负载均衡器的设计与实现"><a href="#2-3-负载均衡器的设计与实现" class="headerlink" title="2.3 负载均衡器的设计与实现"></a>2.3 负载均衡器的设计与实现</h2><p> Sunny软件公司承接了一个服务器负载均衡(Load Balance)软件的开发工作，该软件运行在一台负载均衡服务器上，可以将并发访问和数据流量分发到服务器集群中的多台设备上进行并发处理，提高系统的整体处理能力，缩短响应时间。由于集群中的服务器需要动态删减，且客户端请求需要统一分发，因此需要确保负载均衡器的唯一性，只能有一个负载均衡器来负责服务器的管理和请求的分发，否则将会带来服务器状态的不一致以及请求分配冲突等问题。如何确保负载均衡器的唯一性是该软件成功的关键。</p><p>使用单例模式来设计该负载均衡器： </p><p><img src="https://i.loli.net/2020/02/03/4vJzXqlRCITLUge.gif" alt="s2.gif"></p><pre><code>import java.util.*;//负载均衡器LoadBalancer：单例类，真实环境下该类将非常复杂，包括大量初始化的工作和业务方法，考虑到代码的可读性和易理解性，只列出部分与模式相关的核心代码class LoadBalancer {    //私有静态成员变量，存储唯一实例    private static LoadBalancer instance = null;    //服务器集合    private List serverList = null;    //私有构造函数    private LoadBalancer() {        serverList = new ArrayList();    }    //公有静态成员方法，返回唯一实例    public static LoadBalancer getLoadBalancer() {        if (instance == null) {            instance = new LoadBalancer();        }        return instance;    }    //增加服务器    public void addServer(String server) {        serverList.add(server);    }    //删除服务器    public void removeServer(String server) {        serverList.remove(server);    }    //使用Random类随机获取服务器    public String getServer() {        Random random = new Random();        int i = random.nextInt(serverList.size());        return (String)serverList.get(i);    }}</code></pre><h1 id="3-饿汉式单例模式和懒汉式单例模式"><a href="#3-饿汉式单例模式和懒汉式单例模式" class="headerlink" title="3. 饿汉式单例模式和懒汉式单例模式"></a>3. 饿汉式单例模式和懒汉式单例模式</h1><h2 id="3-1-饿汉式单例模式"><a href="#3-1-饿汉式单例模式" class="headerlink" title="3.1 饿汉式单例模式"></a>3.1 饿汉式单例模式</h2><p><img src="https://i.loli.net/2020/02/03/UAk8topvxWQTwfd.gif" alt="s3.gif"></p><pre><code>class EagerSingleton {     private static final EagerSingleton instance = new EagerSingleton();     private EagerSingleton() { }     public static EagerSingleton getInstance() {        return instance;     }   }</code></pre><p>在类加载的时候，静态变量instance就会被初始化，此时类的私有构造函数会被调用，然后单例类的唯一实例会在这个时候被创建出来。</p><p>恶汉模式的好处是没有延迟加载，这样子是在需要用到它的时候才来执行这个耗时长的初始化过程，可以避免在程序运行的时候才初始化导致的新跟那个问题。</p><h2 id="3-2-懒汉式单例模式"><a href="#3-2-懒汉式单例模式" class="headerlink" title="3.2 懒汉式单例模式"></a>3.2 懒汉式单例模式</h2><p><img src="https://i.loli.net/2020/02/03/bDLQtESdzF8Ugmq.gif" alt="s4.gif"></p><p>在第一个调用getInstance()方法的时候进行实例化。又叫做延迟加载技术——在需要的时候再加载实例，为了避免多个线程同时调用getInstance()方法，我们需要使用<strong><em>synchronized关键字</em></strong>：</p><pre><code>class LazySingleton {     private static LazySingleton instance = null;     private LazySingleton() { }     synchronized public static LazySingleton getInstance() {         if (instance == null) {            instance = new LazySingleton();         }        return instance;     }}</code></pre><p>getInstance()方法带锁，并发度很低，如果频繁调用，需要频繁开关锁的话，效率是很低的。</p><h2 id="3-3-兼顾效率和安全性的方式-饱汉-饿汉"><a href="#3-3-兼顾效率和安全性的方式-饱汉-饿汉" class="headerlink" title="3.3 兼顾效率和安全性的方式(饱汉+饿汉)"></a>3.3 兼顾效率和安全性的方式(饱汉+饿汉)</h2><pre><code>class LazySingleton {     private static LazySingleton instance；     private LazySingleton() { }     public static LazySingleton getInstance() {         if (instance == null) {            synchronized(LazySingleton.class) {                instance = new LazySingleton();             }        }        return instance;     }}</code></pre><h2 id="3-4-使用静态内部类"><a href="#3-4-使用静态内部类" class="headerlink" title="3.4 使用静态内部类"></a>3.4 使用静态内部类</h2><p>利用Java的静态内部类，因为静态内部类只有在被调用的时候，才会被加载。而静态内部类的唯一性，线程安全型都由JVM来保证。</p><p>public class LazySingleton {<br>    private static class LazySingletonHolder{<br>        private static final LazySingleton instance = new LazySingleton();<br>    }</p><pre><code>public static LazySingleton getInstance() {    return LazySingletonHolder.instance;}</code></pre><p>}</p><h1 id="4-单例的问题"><a href="#4-单例的问题" class="headerlink" title="4. 单例的问题"></a>4. 单例的问题</h1><ul><li>违背了基于接口而非实现的设计原则，如果我们想要更改的话，是需要到每个类的位置去做更改的</li><li>单例会隐藏类之间的依赖关系<ul><li>一般来说我们通过构造函数，参数传递来声明类之间的依赖关系</li><li>单例不需要显示创建，不需要依赖参数传递，在函数中直接调用</li><li>对代码的扩展性不友好<h1 id="5-优缺点分析"><a href="#5-优缺点分析" class="headerlink" title="5. 优缺点分析"></a>5. 优缺点分析</h1></li></ul></li></ul><h2 id="5-1-优点"><a href="#5-1-优点" class="headerlink" title="5.1 优点"></a>5.1 优点</h2><ol><li>提供了对唯一实例的访问控制</li><li>因为内存中只存在一个对象，因此可以节约系统资源。尤其是对于一些需要频繁创建和销毁的对象，单例模式可以很大程度上提高系统性能</li></ol><h2 id="5-2-缺点"><a href="#5-2-缺点" class="headerlink" title="5.2 缺点"></a>5.2 缺点</h2><ol><li>扩展困难</li><li>职责相对比较重。因为单例类既充当了工厂角色，提供了工厂方法，同时又充当了产品角色，包含一些业务方法，将产品的创建和产品的本身的功能融合到一起。</li><li>一些语言的垃圾自动回收技术，如果实例化的对象在一段时间内没有被使用，系统会认为它是垃圾，会自动销毁并回收资源。</li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design Pattern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计原则，编程规范的总结</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%EF%BC%8C%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E7%9A%84%E6%80%BB%E7%BB%93/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%EF%BC%8C%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83%E7%9A%84%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>本文作为一个对于整理过的设计原则和思想的总结，包括：</p><ul><li>面向对象<ul><li>封装、继承、抽象、多态</li><li>面向对象编程 vs 面向过程编程</li><li>面向对象分析、设计、编程</li><li>接口 vs 抽象类</li><li>基于接口而非实现编程</li><li>多用组合少用继承</li><li>贫血模式 vs 充血模式 </li></ul></li><li>设计原则<ul><li>单一职责原则</li><li>开闭原则</li><li>里氏替换原则</li><li>接口隔离原则</li><li>依赖倒置原则</li><li>DRY</li><li>KISS</li><li>YAGNI</li><li>LOD</li></ul></li><li>规范与重构<ul><li>目的，对象，时机，方法</li><li>单元测试和代码的可测试性</li><li>大重构</li><li>小重构</li></ul></li></ul><h1 id="1-代码质量的评判标准"><a href="#1-代码质量的评判标准" class="headerlink" title="1. 代码质量的评判标准"></a>1. 代码质量的评判标准</h1><ul><li>常用评价标准<ul><li>最常用<ul><li>可维护性</li><li>可读性</li><li>可扩展性</li></ul></li><li>其他<ul><li>灵活性</li><li>简洁性</li><li>可复用性</li><li>可测试性</li></ul></li></ul></li><li>如何写出高质量代码？<ul><li>设计思想</li><li>设计原则</li><li>设计模式</li><li>编码规范</li><li>重构技巧</li></ul></li></ul><h1 id="2-面向对象"><a href="#2-面向对象" class="headerlink" title="2. 面向对象"></a>2. 面向对象</h1><ul><li><p>特性</p><ul><li>封装<ul><li>隐藏信息，数据访问保护</li></ul></li><li>继承<ul><li>is a</li></ul></li><li>多态<ul><li>子类可以替代父类的模式</li><li>在实际代码运行当中，通过调用子类的方法来实现</li></ul></li><li>抽象<ul><li>隐藏类的具体实现方法</li><li>使得修改实现不需要改变定义</li></ul></li></ul></li><li><p>面向对象设计 – 如何设计出具体的类</p><ul><li>划分职责</li><li>定义类及其属性和方法</li><li>定义类和类之间的交互关系</li><li>将类组装起来并提供执行入口</li></ul></li><li><p>接口 vs 抽象类</p><ul><li><p>接口</p><ul><li>对方法的抽象</li><li>是一种has a的关系</li><li>表示具有某一组行为特性</li><li>为了解决解耦问题，隔离接口和具体实现，提高代码扩展性</li></ul></li><li><p>抽象类</p><ul><li>对成员变量和方法的抽象</li><li>是一种is a的关系</li><li>为了解决代码复用的问题</li></ul></li></ul></li><li><p>贫血模型 vs 充血模型</p><ul><li>MVC  贫血模型</li><li>充血模型的设计<ul><li>与贫血模型的区别在于Service层</li><li>在基于充血模型的开发模式下，将service类中的业务逻辑移动到一个充血的domain领域模型当中</li><li>让Service类的实现依赖这个domain类</li></ul></li></ul></li></ul><h1 id="3-设计原则"><a href="#3-设计原则" class="headerlink" title="3. 设计原则"></a>3. 设计原则</h1><ul><li><p>单一职责原则</p><ul><li>一个类只负责一个职责或者功能</li></ul></li><li><p>开闭原则</p><ul><li>对扩展开放，对修改关闭<ul><li>添加一个新的功能，应该是通过在已有的代码基础上扩展代码(新增模块，类，方法，属性)，而非修改已有的代码的方式来完成的</li><li>指的是以最小的修改代码的代价来完成新功能的开发</li></ul></li></ul></li><li><p>里氏替代原则</p><ul><li>子类对象能够替代程序当中父类对象出现的任何地方，并且保证原来程序的逻辑行为不变及正确性不被破坏。</li><li>理解 Design by contract 按照协议来设计</li><li>父类定义函数的约定/协议</li><li>子类可以改变函数的内部实现逻辑，但不能改变函数的原有约定<ul><li>约定包括<ul><li>函数声明要实现的功能</li><li>对输入 输出 异常的约定</li><li>注释中罗列的特殊说明</li></ul></li></ul></li></ul></li><li><p>接口隔离原则</p><ul><li>客户端不应该强迫依赖它不需要的接口<ul><li>将接口理解为一组接口集合<ul><li>如果部分接口只被部分调用者使用，应该将这部分接口隔离起来，单独给他们使用</li></ul></li><li>理解为单个API接口或函数<ul><li>部分调用者只需要函数的部分功能，那我们就应该将函数拆分为粒度更细的多个函数，让调用者只依赖它需要的那个细粒度的函数</li></ul></li><li>理解为OOP中的接口<ul><li>接口的设计需要尽量单一，不要让接口的实现类和调用者，依赖不需要的接口函数</li></ul></li></ul></li></ul></li><li><p>YAGNI - you ain’t gonna need it </p></li><li><p>LOD - 高内聚，低耦合</p></li><li><p>迪米特法则</p><ul><li>不该有直接依赖关系的类之间，不要有依赖；有依赖关系的类之间，尽量只依赖必要的接口</li></ul></li></ul><h1 id="4-相关的文章"><a href="#4-相关的文章" class="headerlink" title="4. 相关的文章"></a>4. 相关的文章</h1><ol><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-general/" target="_blank" rel="noopener">架构学习-general</a></li><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%8E%9F%E5%88%99/" target="_blank" rel="noopener">架构学习-原则</a></li><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%8F%AF%E6%89%A9%E5%B1%95%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/" target="_blank" rel="noopener">架构学习-可扩展架构模式</a></li><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90/" target="_blank" rel="noopener">架构学习-复杂度来源</a></li><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%AE%9E%E6%88%98/" target="_blank" rel="noopener">架构学习 - 实战</a></li><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF/" target="_blank" rel="noopener">架构学习 - 架构设计文档模板</a></li><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B/" target="_blank" rel="noopener">架构学习-架构设计流程</a></li><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/" target="_blank" rel="noopener">架构学习-高可用架构模式</a></li><li><a href="https://llchen60.com/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E9%AB%98%E6%80%A7%E8%83%BD%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/" target="_blank" rel="noopener">架构学习-高性能架构模式</a></li><li><a href="https://llchen60.com/%E5%9F%BA%E4%BA%8E%E5%85%85%E8%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84DDD%E5%BC%80%E5%8F%91%E6%A8%A1%E5%9E%8B/" target="_blank" rel="noopener">基于充血模型的DDD开发模型</a></li><li><a href="https://llchen60.com/SOLID-%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3%E5%8E%9F%E5%88%99/" target="_blank" rel="noopener">SOLID-单一职责原则</a></li><li><a href="https://llchen60.com/SOLID-%E5%BC%80%E9%97%AD%E5%8E%9F%E5%88%99/" target="_blank" rel="noopener">SOLID - 开闭原则</a></li><li><a href="https://llchen60.com/SOLID-%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%8E%9F%E5%88%99/" target="_blank" rel="noopener">SOLID - 里氏替换原则</a></li><li><a href="https://llchen60.com/SOLID-%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99/" target="_blank" rel="noopener">SOLID - 接口隔离原则</a></li><li><a href="https://llchen60.com/SOLID-%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC%E5%8E%9F%E5%88%99/" target="_blank" rel="noopener">SOLID - 依赖反转原则</a></li><li><a href="https://llchen60.com/KISS-and-YAGNI%E5%8E%9F%E5%88%99/" target="_blank" rel="noopener">KISS and YAGNI原则</a></li><li><a href="https://llchen60.com/DRY-%E5%8E%9F%E5%88%99/" target="_blank" rel="noopener">DRY 原则</a></li><li><a href="https://llchen60.com/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99-LOD-%E2%80%94-%E9%AB%98%E5%86%85%E8%81%9A%EF%BC%8C%E4%BD%8E%E8%80%A6%E5%90%88/" target="_blank" rel="noopener">迪米特法则 (LOD) — 高内聚，低耦合</a></li><li><a href="https://llchen60.com/%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1-Practice/" target="_blank" rel="noopener">应用设计 Practice</a></li><li><a href="https://llchen60.com/%E5%85%B3%E4%BA%8E%E6%8F%90%E9%AB%98%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F%E7%9A%84Tips/" target="_blank" rel="noopener">提高代码质量的Tips</a></li></ol><h1 id="5-实战：ID生成器"><a href="#5-实战：ID生成器" class="headerlink" title="5. 实战：ID生成器"></a>5. 实战：ID生成器</h1><p>使用ID来做服务内部的请求追踪，因为在日志文件当中，不同请求的日志是会交织到一起的。我们需要使用ID来标识哪些日志属于同一个请求。</p><p>因此我们需要做的事情就是给每个请求分配一个唯一的ID，并且保存在请求的上下文当中。Java当中可以将ID存储在ThreadLocal当中，或者使用Slf4j的MDC(Mapped Diagnostic Contexts)来实现。每次打印日志的时候，我们就可以从请求上下文当中取出请求ID，跟日志一块输出。</p><h2 id="5-1-原始的生成ID的代码"><a href="#5-1-原始的生成ID的代码" class="headerlink" title="5.1 原始的生成ID的代码"></a>5.1 原始的生成ID的代码</h2><pre><code>public class IdGenerator {  private static final Logger logger = LoggerFactory.getLogger(IdGenerator.class);  public static String generate() {    String id = &quot;&quot;;    try {      String hostName = InetAddress.getLocalHost().getHostName();      String[] tokens = hostName.split(&quot;\\.&quot;);      if (tokens.length &gt; 0) {        hostName = tokens[tokens.length - 1];      }      char[] randomChars = new char[8];      int count = 0;      Random random = new Random();      while (count &lt; 8) {        int randomAscii = random.nextInt(122);        if (randomAscii &gt;= 48 &amp;&amp; randomAscii &lt;= 57) {          randomChars[count] = (char)(&#39;0&#39; + (randomAscii - 48));          count++;        } else if (randomAscii &gt;= 65 &amp;&amp; randomAscii &lt;= 90) {          randomChars[count] = (char)(&#39;A&#39; + (randomAscii - 65));          count++;        } else if (randomAscii &gt;= 97 &amp;&amp; randomAscii &lt;= 122) {          randomChars[count] = (char)(&#39;a&#39; + (randomAscii - 97));          count++;        }      }      id = String.format(&quot;%s-%d-%s&quot;, hostName,              System.currentTimeMillis(), new String(randomChars));    } catch (UnknownHostException e) {      logger.warn(&quot;Failed to get the host name.&quot;, e);    }    return id;  }}</code></pre><ul><li>上述代码存在的问题<ul><li>static 方法可测试性太低</li><li>generate函数的代码实现依赖运行环境，时间函数以及随机函数，本身的可测试性也不强</li><li>随机字符串生成代码难以看懂</li><li>有太多的魔法数，需要告诉读代码的人这些都是什么意思才可以的</li></ul></li></ul><h2 id="5-2-完善后的代码"><a href="#5-2-完善后的代码" class="headerlink" title="5.2 完善后的代码"></a>5.2 完善后的代码</h2><pre><code>public interface IdGenerator {  String generate();}public interface LogTraceIdGenerator extends IdGenerator {}public class RandomIdGenerator implements IdGenerator {  private static final Logger logger = LoggerFactory.getLogger(RandomIdGenerator.class);  @Override  public String generate() {    String substrOfHostName = getLastfieldOfHostName();    long currentTimeMillis = System.currentTimeMillis();    String randomString = generateRandomAlphameric(8);    String id = String.format(&quot;%s-%d-%s&quot;,            substrOfHostName, currentTimeMillis, randomString);    return id;  }  private String getLastfieldOfHostName() {    String substrOfHostName = null;    try {      String hostName = InetAddress.getLocalHost().getHostName();      String[] tokens = hostName.split(&quot;\\.&quot;);      substrOfHostName = tokens[tokens.length - 1];      return substrOfHostName;    } catch (UnknownHostException e) {      logger.warn(&quot;Failed to get the host name.&quot;, e);    }    return substrOfHostName;  }  private String generateRandomAlphameric(int length) {    char[] randomChars = new char[length];    int count = 0;    Random random = new Random();    while (count &lt; length) {      int maxAscii = &#39;z&#39;;      int randomAscii = random.nextInt(maxAscii);      boolean isDigit= randomAscii &gt;= &#39;0&#39; &amp;&amp; randomAscii &lt;= &#39;9&#39;;      boolean isUppercase= randomAscii &gt;= &#39;A&#39; &amp;&amp; randomAscii &lt;= &#39;Z&#39;;      boolean isLowercase= randomAscii &gt;= &#39;a&#39; &amp;&amp; randomAscii &lt;= &#39;z&#39;;      if (isDigit|| isUppercase || isLowercase) {        randomChars[count] = (char) (randomAscii);        ++count;      }    }    return new String(randomChars);  }}//代码使用举例LogTraceIdGenerator logTraceIdGenerator = new RandomIdGenerator();</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计原则 </tag>
            
            <tag> 编程规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>价格心理学</title>
      <link href="/%E4%BB%B7%E6%A0%BC%E5%BF%83%E7%90%86%E5%AD%A6/"/>
      <url>/%E4%BB%B7%E6%A0%BC%E5%BF%83%E7%90%86%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<p>一些定价，看价的技巧。无论你是销售者还是购买者，应该都能从中得到一些对你更有利的定价策略。</p><h1 id="1-使自己的价格看起来更低"><a href="#1-使自己的价格看起来更低" class="headerlink" title="1. 使自己的价格看起来更低"></a>1. 使自己的价格看起来更低</h1><p>我们可以通过一些方式来影响在人们印象当中的产品的价格。当人们将你的产品价格和参考产品比较的时候，你可以用某些方式施加影响，来使得他们拿更低的价格来进行比较。</p><p>这样做有效的原因是我们的大脑是很懒的，我们在大脑中不会记一个物品的数字上的价格，很有可能是记录相对的高或者低</p><h4 id="1-对最左侧的数字减1"><a href="#1-对最左侧的数字减1" class="headerlink" title="1. 对最左侧的数字减1"></a>1. 对最左侧的数字减1</h4><p>通过比较转化率，我们会发现减少一分钱，即例如从$1 到$0.99，转化率就提高了1个百分点。</p><p><img src="https://i.loli.net/2020/05/31/Xr2xVAUkP7SsKM5.jpg" alt="conversion rate in Gumroad.jpg"></p><p>很多人都知道.99的魔力，但是转化率更大的转变出现在当最左侧的数字发生了改变的时候。大脑意识是有锚定效应的，即我们会认为$2.99是属于2的范畴，而$3是属于3的范畴，他们之间相差很大。同理出现在199和200之间，诸如此类。</p><h4 id="2-选择更少音节的价格"><a href="#2-选择更少音节的价格" class="headerlink" title="2. 选择更少音节的价格"></a><strong>2. 选择更少音节的价格</strong></h4><p>价格的整个读音（音节数量）也会影响最终对于价格的认知[3]。当我们需要处理更多音节的刺激的时候，我们会需要更多的意识来处理这种刺激，这同样适用于数字，当我们需要花更多的时间处理这个数字的时候，我们潜意识会认为这个数字非常大。</p><p>当包含更少的读音的时候，人们会认为价格比实际上低。</p><p>这不仅仅发生在读出价格的时候，研究表明哪怕我们看到的是写出来的价格，我们的大脑也会潜意识当中将其编码成听觉版本。[4]</p><h4 id="3-用更小的字号来展示价格"><a href="#3-用更小的字号来展示价格" class="headerlink" title="3. 用更小的字号来展示价格"></a><strong>3. 用更小的字号来展示价格</strong></h4><p>我们的大脑对于大小是有概念上的认知的。视觉大小与数字大小的交汇是很模糊的，即我们潜意识可能会认为视觉上用更小的字体也意味着数字本身是更小的。</p><p>同样，对于折扣来说，我们就应该使用尽可能大的字体来展示了。</p><p><img src="https://i.loli.net/2020/05/31/kMWAyd1LVaNsPEF.png" alt="pricing-tactic-3"></p><h4 id="4-移除价格当中的逗号"><a href="#4-移除价格当中的逗号" class="headerlink" title="4. 移除价格当中的逗号"></a><strong>4. 移除价格当中的逗号</strong></h4><p>移除逗号可以使得你的价格看起来更低！[5]</p><p>首先是视觉上，逗号使得整个数字显得更大；<br>其次是如果不加逗号，比如对于1499这个数字，会读成fourteen niety-nine; 但是如果加了逗号，那么就会读成one thousand four hundred and ninty nine. 音节从5个升到了10个。</p><h4 id="5-选择维度更小的词"><a href="#5-选择维度更小的词" class="headerlink" title="5. 选择维度更小的词"></a><strong>5. 选择维度更小的词</strong></h4><p>对于在显示的价格旁边的词，选择要谨慎。有些词是可以左右人们的设想的。举个例子, low friction vs high performance. 通过测试发现在参与者认为两个词语都同等重要的前提下，更多的人选择了带有Low Friction的。如果可以，在价格旁边选择维度更小的一些词。</p><h4 id="6-将物流和订单处理的费用分开"><a href="#6-将物流和订单处理的费用分开" class="headerlink" title="6. 将物流和订单处理的费用分开"></a><strong>6. 将物流和订单处理的费用分开</strong></h4><p>当你要在线销售产品的时候，往往需要支付物流和订单处理的费用。当将价格都分割开的时候，使得人们能够锚定在基础价格上，而不是整个价格。[6]</p><h4 id="7-提供首付金相关的选择"><a href="#7-提供首付金相关的选择" class="headerlink" title="7. 提供首付金相关的选择"></a><strong>7. 提供首付金相关的选择</strong></h4><p>一下子付1000刀和分10个月每次付100刀给人的感觉是完全不一样的。如果可能，我们通过使用月付可以很大程度上提升人们购买的欲望。他们会认为这个价格很低。</p><h4 id="8-提及每天的等值价格"><a href="#8-提及每天的等值价格" class="headerlink" title="8. 提及每天的等值价格"></a><strong>8. 提及每天的等值价格</strong></h4><p>假设我们在做一个月付的东西，30刀每月，这会显得很多。如果说每天一美元，给人感觉就会少一些了。</p><h4 id="9-关于大额的数字，要精准"><a href="#9-关于大额的数字，要精准" class="headerlink" title="9. 关于大额的数字，要精准"></a><strong>9. 关于大额的数字，要精准</strong></h4><p>比如购房的时候，$359,289和$359,000给人的感觉会很不一样，前者触发的是人们对于低价产品的认知；即足够精准，而后者会被默认为是价格很高的产品。除此以外，一个很精确的数字也会让人感觉谈价的余地相对有限；对方在很认真仔细的准备。 </p><h4 id="10-小额的价格放到左侧"><a href="#10-小额的价格放到左侧" class="headerlink" title="10. 小额的价格放到左侧"></a><strong>10. 小额的价格放到左侧</strong></h4><p>当我们设计一个布局的时候，价格应该往左侧放。这是因为在英文当中，我们将上和高质联系到了一起，低和不好的东西联系起来。譬如：</p><ul><li>go up to heaven </li><li>down to hell </li><li>thumbs up </li><li>thumbs down </li><li>get high</li><li>come down</li><li>etc.</li></ul><p>研究也证实了当好词在屏幕上方，坏词在屏幕下方的时候，我们能更快的识别出他们来。类似的概念也出现在数字上，根据研究[7]发现人们会将数字置于自己想象的一条水平方向的线上，从左到右数字依次增大。</p><p>因此小价格放到左侧，对于大家概念中的大价格，放到右侧。</p><h4 id="11-让用户看到价格的乘积-例子"><a href="#11-让用户看到价格的乘积-例子" class="headerlink" title="11. 让用户看到价格的乘积(例子)"></a><strong>11. 让用户看到价格的乘积(例子)</strong></h4><p><img src="https://i.loli.net/2020/06/03/OgXICK9tdBZHEyp.png" alt="price-multiples.png"></p><p>前两个是给了你无限添加topping的选择，从经济上来说是更好的选择，但是经过试验发现人们普遍更加喜欢后面的两个。</p><p>这是因为后面是可以计算的，即pizza的多少和toppings的数量的乘积等于价格。这种优势看起来有点荒唐，但是心理学能够给予解释。我们从小开始就在被训练一下基本的数学连接，比如熟知的九九乘法表，然后这种连接会终身影响我们，使得我们能够对其迅速反应。</p><p>也正因为这种连接，使得我们能够更加快速的处理几个不同部分的信息，并且通过数字连接建立起内容上的连接。</p><h4 id="12-正确使用取整操作"><a href="#12-正确使用取整操作" class="headerlink" title="12. 正确使用取整操作"></a><strong>12. 正确使用取整操作</strong></h4><p>取整的数字会相对容易处理很多，譬如100 vs 98.65。根据研究发现，当用户能够更快的处理分析价格的时候，他们会感觉这个价格感觉上更对。</p><p>与之相对的，消费者会需要更多的精神来处理非取整的价格，因此这种非取整的价格更适合理性消费的场景。</p><p>而对于基于情感进行的消费，使用整数价格会更容易促进销量的提升。</p><p>同样，不要使用像100，5000这样的数字，会很容易让消费者感觉这个价格虚高。</p><p>基于情感，使用整数；基于理性，可以使用带小数的价格。</p><h4 id="13-根据名字和生日调整价格"><a href="#13-根据名字和生日调整价格" class="headerlink" title="13. 根据名字和生日调整价格"></a><strong>13. 根据名字和生日调整价格</strong></h4><p>尽管略显古怪，但是确实很多研究都支持这个结论，即用户更喜欢有他们的名字同样字母的价格，亦或者是包含他们的生日的价格。[8]</p><p>心理学上的理论支持为implicit egotism – 以自我为中心的倾向。我们潜意识里会更加倾向于那些和我们相关的/ 构筑我们自我的事物。</p><h4 id="14-在最优时间展示价格"><a href="#14-在最优时间展示价格" class="headerlink" title="14. 在最优时间展示价格"></a><strong>14. 在最优时间展示价格</strong></h4><p>我们应该首先展示什么？ 你的产品或者价格？ </p><p>我们首先看到的是产品或者价格很大程度上决定了我们决定是否要去买这件产品的标准[9].</p><p>当产品被首先展示出来的时候，用户会根据产品质量，自己的喜爱程度来决定是否要购买</p><p>当价格首先被展示出来的时候，用户会根据这个产品是否值这个价格来决定是否要买。</p><p>当销售奢侈品的时候，就应该先展示产品，再阐明价格；而对于日常使用的产品来说，用户更倾向于先看到价格，再决定是否购买这件产品。</p><h4 id="15-向男士展示红颜色标注的价格"><a href="#15-向男士展示红颜色标注的价格" class="headerlink" title="15. 向男士展示红颜色标注的价格"></a>15. 向男士展示红颜色标注的价格</h4><p>研究[10]表明当价格标签颜色为红色的时候，男士更有可能买这件产品。</p><p>红色价格会成为关注的中心，很有可能变为做出评估的唯一信息。而且常常将红色价格和省钱联系起来。</p><h1 id="2-最大化参考价格"><a href="#2-最大化参考价格" class="headerlink" title="2. 最大化参考价格"></a>2. 最大化参考价格</h1><h4 id="16-使用一个高且精准的价格开始谈价-（从商家角度来看）"><a href="#16-使用一个高且精准的价格开始谈价-（从商家角度来看）" class="headerlink" title="16. 使用一个高且精准的价格开始谈价 （从商家角度来看）"></a>16. 使用一个高且精准的价格开始谈价 （从商家角度来看）</h4><p>基于锚定效应，使用一个更高的价格，往往能够使得最后商定的价格更高。我们不仅仅应该使用一个更高的价格，更应该使用一个更加精确的价格。</p><blockquote><p>If adjustment is viewed as movement along a subjective representational scale, then the resolution of this scale might also influence the amount of adjustment. X units of adjustment along a fine-resolution scale will cover less objective distance than the same number of units of adjustment along a coarse-resolution scale.</p></blockquote><h4 id="17-使用户看到更高的其他价格"><a href="#17-使用户看到更高的其他价格" class="headerlink" title="17. 使用户看到更高的其他价格"></a>17. 使用户看到更高的其他价格</h4><p>同样是通过锚定效应完成操作的，即 使人们能够看到更高的价格，那会潜意识当中也提高对你的产品的估价。</p><h4 id="18-使用户看到更高的数字"><a href="#18-使用户看到更高的数字" class="headerlink" title="18. 使用户看到更高的数字"></a>18. 使用户看到更高的数字</h4><p>依旧是潜意识，在展示价格之前，先使用户看到一些很大的数字，这已经足够来影响用户接下来对于数字相对大小的认知了。</p><p><img src="https://i.loli.net/2020/06/03/qKZ352bCYk9zPVE.png" alt="pricing-tactic-18.png"></p><h4 id="19-提高过去产品的售价"><a href="#19-提高过去产品的售价" class="headerlink" title="19. 提高过去产品的售价"></a>19. 提高过去产品的售价</h4><p>如果你正在推出一个更新版本的产品，针对行业，是可以尝试提高前一代的产品的售价的。新产品的参考价格会依托于上一代的产品，如果我们降价了的话，那新一代产品锚定的是上一代产品，会让用户有这一代产品相对比较贵的感觉。</p><h4 id="20-价格排序应该从高到低"><a href="#20-价格排序应该从高到低" class="headerlink" title="20. 价格排序应该从高到低"></a>20. 价格排序应该从高到低</h4><p>通过降序的排列，我们可以使得用户更有可能去买相对比较贵的选择。</p><p>首先，先看到的价格会成为我们的参考价格，如果初始价格比较高，用户就会生成一个相对比较高的参考价格。这样子的话，当我们降序排列，看到的新的产品往往感觉都会相对更有性价比好一些，就更容易达成交易，且平均值也会相对大一些。</p><p>还有一个原因是人们对于失去的厌恶，价格从低到高排列，失去的是价格的优势感觉，直觉反应是应该选低价的来减少损失。价格从高到低，感觉失去的是品质，直觉应该是选高品质的物品，哪怕价格高一些。中间当然有权衡。</p><h4 id="21-将价格放在大数量的右面-11"><a href="#21-将价格放在大数量的右面-11" class="headerlink" title="21. 将价格放在大数量的右面[11]"></a>21. 将价格放在大数量的右面[11]</h4><ul><li><p>前提条件</p><ul><li><p>单价计算应该是相对比较困难的</p><ul><li>当困难的时候，会更依赖于直觉去进行判断<ul><li>价格开始，注意力集中在花费</li><li>数量开始，注意力集中在潜在的好处</li></ul></li></ul></li><li><p>物品数量最好大于价格的数字</p><ul><li>锚定于数量，忽略价格</li><li>从而认为这是个很值得买的东西</li></ul></li></ul></li></ul><h1 id="3-强调参考价格之间的不同-鸿沟"><a href="#3-强调参考价格之间的不同-鸿沟" class="headerlink" title="3. 强调参考价格之间的不同/鸿沟"></a>3. 强调参考价格之间的不同/鸿沟</h1><h4 id="22-加入视觉上的售价对比"><a href="#22-加入视觉上的售价对比" class="headerlink" title="22. 加入视觉上的售价对比"></a>22. 加入视觉上的售价对比</h4><p>如果你将自己的价格和更高的其他产品价格对比，那么人们就更可能去买你的产品，因为有了对比以后会相对少一些自行去比价的动力了。</p><p>一些小技巧：</p><ul><li>如果视觉上使用不同大小，或者颜色，我们会给消费者一种很流程的体验，消费者会有将颜色的不同和价格上不同程度做通感的趋向。[12]</li><li>出了颜色和大小，视觉上的距离也会对消费者产生的对价格高低的概念产生影响，距离远会认为数字差的会更大[13]</li></ul><h4 id="23-提供一个“诱饵”的购买选择"><a href="#23-提供一个“诱饵”的购买选择" class="headerlink" title="23. 提供一个“诱饵”的购买选择"></a>23. 提供一个“诱饵”的购买选择</h4><p>举个例子：</p><ul><li>提供三个购买选择<ul><li>web only $59</li><li>print only $125 </li><li>web and print $125 </li></ul></li></ul><p>很多人肯定和我一样，刚开始看到的时候会认为第二个选择是错误的，用同等价格，可以购买网页版和纸质版，那么谁会只选择纸质版呢？ 当时经过试验发现就是这个print only的看似无用的选择，产生了锚定效应，即用户对于如何界定关于web 和 print only自己应该付多少钱的认知，通过放置print only的选择，最终选取web and print的人要多很多，整体GMS也有了很大提高。 </p><p><img src="https://i.loli.net/2020/06/05/C964yTjH2awuzqP.png" alt="psychological-pricing-table-3.png"></p><p><img src="https://i.loli.net/2020/06/05/KqY14GgLlTMkbWy.png" alt="psychological-pricing-table-4.png"></p><h1 id="4-减少付款的“心疼感”"><a href="#4-减少付款的“心疼感”" class="headerlink" title="4. 减少付款的“心疼感”"></a>4. 减少付款的“心疼感”</h1><h4 id="24-移除货币符号"><a href="#24-移除货币符号" class="headerlink" title="24. 移除货币符号"></a>24. 移除货币符号</h4><p>付款的心疼感是很容易被触发的，事实上货币符号本身就很容易触发这种情绪，让人们想花的更少。[14]</p><p>同样，需要取舍，即你放在这里的数字如果没有货币符号，是否会变得难以认清，难以明白这串数字代表价格，是需要做trade-off的。</p><h4 id="25-在用户使用前令他们付费"><a href="#25-在用户使用前令他们付费" class="headerlink" title="25. 在用户使用前令他们付费"></a>25. 在用户使用前令他们付费</h4><p>预付对链条中的所有角色都有例。对于生产方，首先可以减少资金的压力；对于消费者，预付往往会使得他们对产品更加满意，因为当先付款的时候，他们会更加专注于购买了物品以后他们获得的好处，而不是花了钱的痛感当中。如果他们已经使用了你的产品再付费，往往会更不情愿付款的。[15]</p><p>这对于那种收月度会员费的模式很有意义，如果是这种模式，那就应该在月初还没开始使用的时候先收费。当然经验也告诉我们确确实实现在大部分的商家都是这么做的。</p><p>同时不要在月底来推送你这个月总共花了多少钱之类的账单明细，这只会降低消费者的购买欲望。</p><h4 id="26-对非工具类的产品给多件折扣"><a href="#26-对非工具类的产品给多件折扣" class="headerlink" title="26. 对非工具类的产品给多件折扣"></a>26. 对非工具类的产品给多件折扣</h4><p>为了减少付费时候的痛感，可以考虑成套销售。成套来购买的时候，用户就很难给单件产品一个很清晰的定价了。而添加的产品最好是非工具类的，即使用的时候会给人带来一些愉悦的感觉的物品。在做描述的时候，也要注意着重去描述一些好玩的场景，者都会给用户带来愉悦的刺激，提高最终的付费比率。</p><h4 id="27-不要将价格昂贵和便宜的物品一起成套销售"><a href="#27-不要将价格昂贵和便宜的物品一起成套销售" class="headerlink" title="27. 不要将价格昂贵和便宜的物品一起成套销售"></a>27. 不要将价格昂贵和便宜的物品一起成套销售</h4><p>这样建议的原因是便宜的物品会改变消费者对于昂贵产品的认知，会认为其更贵，更不值钱。 </p><h4 id="28-将关注点转移到时间相关的方面"><a href="#28-将关注点转移到时间相关的方面" class="headerlink" title="28. 将关注点转移到时间相关的方面"></a>28. 将关注点转移到时间相关的方面</h4><p>当描述我们的产品的时候，尽量避免用金钱作为参考的描述。相反，使用时间概念来描述。</p><p>譬如，Mogilner，Aaker[16]做过的一个关于柠檬饮品的试验，他们做了三个强调不同属性的广告：</p><ul><li>Time: Spend a little time and enjoy C &amp; D’s lemonade</li><li>Money: Spend a little money and enjoy C &amp; D’s lemonade</li><li>Neutral: Enjoy C &amp; D’s lemonade</li></ul><p>实验结果发现时间相关的广告玩虐其他两个，相较而言，人们愿意付双倍的价格来购买柠檬汁。</p><h4 id="29-建立付费中转商"><a href="#29-建立付费中转商" class="headerlink" title="29. 建立付费中转商"></a>29. 建立付费中转商</h4><p>赌场使用代币而不是现金，礼品卡将钱提前存进去，这样做的好处实际上就是将我们把钱拿出口袋的动作发生的时间前移，和我们享用的时间分割开。这样就能够扭曲付费时候的立场，使得不会觉得那么的痛苦。</p><p>这样做行之有效的原因是因为人都是懒的，会不愿意去算各种方式的转化率的问题.</p><h4 id="30-避免直接联系到金钱的语言"><a href="#30-避免直接联系到金钱的语言" class="headerlink" title="30. 避免直接联系到金钱的语言"></a>30. 避免直接联系到金钱的语言</h4><p>the money in your account vs your credits </p><p>通过尽量避免将app内的点数和实际金钱挂钩，就会使得用户失去对于钱的某些概念。</p><p>同时，可以的话不要做1比1 的转化，太容易做这个计算了。可以搞比如说存100送10块之类的，这样的转化就会在1 - 1.1之间，对于用户来说，计算的难度上来，这样计算的人就会少很多了。</p><h4 id="31-强调你的产品的固定成本"><a href="#31-强调你的产品的固定成本" class="headerlink" title="31. 强调你的产品的固定成本"></a>31. 强调你的产品的固定成本</h4><p>消费者会在看到产品以后做出一个价格高低的判断，但是他们也同样在意价格的合理程度。即便你的价格是低的，用户仍然可能认为这个价格不合理；同样，对于相对高的价格，用户也有可能认为非常合适。这取决于以下几个因素：</p><ul><li>你如何定价的？<ul><li>基于成本的定价</li><li>基于供求的定价</li></ul></li></ul><p>用户会认为基于成本的定价更加公平，这也是你可以通过强调产品本身的成本从而给出价格很合适的认知的原因。强调你的产品的原材料非常好，或者其他很费钱的方面，这些信息会使得用户对你的产品价格有个更真切的认知。</p><h4 id="32-对于相似的产品，价格需要有一点不同"><a href="#32-对于相似的产品，价格需要有一点不同" class="headerlink" title="32. 对于相似的产品，价格需要有一点不同"></a>32. 对于相似的产品，价格需要有一点不同</h4><p>你也许经历过选择困难症，往往是选择越多，人们就越难以做出选择。一旦人们做出一个选择，他们就会失去其他选择可能带来的利益。因为对于失去的厌恶，他们就会推迟自己的决定，尤其是当更多的选择在的时候。</p><p>同样有研究者做过这样的实验，实验者询问两组参与者是否想要买一盒口香糖，每组都有以下两种选择</p><ul><li>组1： 同样价格</li><li>组2： 稍稍不同的价格 (62美分 vs 64美分)</li></ul><p><img src="https://i.loli.net/2020/06/05/2RWLMOteuDTbxpC.png" alt="price-differences.png"></p><p>实验结果发现当价格稍稍有些不同的时候，人们更有可能去买一盒口香糖。</p><p>当两个产品有同样的价格的时候，人们无法立刻区分二者的不同，那么他们只能自己主动去寻找特征上的不同。因为主动寻找，所以产品的不同会看着更加明显。</p><p>然而，当你给价格加上一点点不同的时候，你减少了搜索不同的需求。消费者可以很直接的通过价格来区分不同的产品。因为用户对于产品的不同关注的更少，两个产品直观上就会看起来更加雷斯了。这种相似性是的人们更可能去选择一个产品。</p><p><img src="https://i.loli.net/2020/06/05/6JD8M4dX2Rlfor5.png" alt="pricing-tactic-32.png"></p><h4 id="33-使用更加频繁小额的提价"><a href="#33-使用更加频繁小额的提价" class="headerlink" title="33. 使用更加频繁小额的提价"></a>33. 使用更加频繁小额的提价</h4><p>最简单的控制对于价格相对高低的概念的方法是根于刚刚能注意到的不同。比如你的价格是11.99，那么加到12.99算比较合理的，加到19.99就会很夸张了</p><h4 id="34-减小某特征-vs-提价"><a href="#34-减小某特征-vs-提价" class="headerlink" title="34. 减小某特征 vs 提价"></a>34. 减小某特征 vs 提价</h4><p>除了提价，另外可以选择的是在分量上，某个特征上的一定程度的减少。同样要遵循着小额多次的宗旨，一点点来。 </p><h1 id="5-适量使用折扣"><a href="#5-适量使用折扣" class="headerlink" title="5. 适量使用折扣"></a>5. 适量使用折扣</h1><p>如果没有合理使用，折扣是有可能伤害你的事业的。也有人小极端，认为我们永远不应该使用折扣 [17]. 值得注意的是，如果我们的折扣十分频繁，或者折扣力度太大，是会使得消费者对于产品，品牌的认知改变的。消费者可能会等待下一个折扣期才会购买产品了。</p><p>同样，折扣也会降低你的产品的参考价格，使得人们未来更少买（因为觉得你的当前价格高）</p><h4 id="35-遵循100原则"><a href="#35-遵循100原则" class="headerlink" title="35. 遵循100原则"></a>35. 遵循100原则</h4><p>当你的价格低于100的时候，使用百分比折扣，反之直接使用数字；目的是使得折扣的程度看起来更大。</p><h4 id="36-给折扣一个原因"><a href="#36-给折扣一个原因" class="headerlink" title="36. 给折扣一个原因"></a>36. 给折扣一个原因</h4><p>为了最大化折扣的有效性，我们需要解释为什么提供这样的折扣。</p><p>比如every day low pricing store 指向的是供应商给的折扣，当你提供折扣的理由的时候，你在说明他的临时性。因此人们不太会将你的折扣价和他内在隐含的实际价值做出强关联。</p><p><img src="https://i.loli.net/2020/06/05/3TSGCNQscynW6gi.png" alt="pricing-tactic-36.png"></p><h4 id="37-提供更好计算的折扣"><a href="#37-提供更好计算的折扣" class="headerlink" title="37. 提供更好计算的折扣"></a>37. 提供更好计算的折扣</h4><p>提供更好计算的折扣可以显得折扣更大的</p><h4 id="38-在月末打折"><a href="#38-在月末打折" class="headerlink" title="38. 在月末打折"></a>38. 在月末打折</h4><p>当我们总钱数少的时候，我们会更不愿意付钱出去。到了月末，很多人的钱包都会空下来，就算购买，也很可能只能买折扣的东西了。</p><h4 id="39-将你的促销价放在原价的右侧"><a href="#39-将你的促销价放在原价的右侧" class="headerlink" title="39. 将你的促销价放在原价的右侧"></a>39. 将你的促销价放在原价的右侧</h4><p>研究[18]表明当促销价放在原价的右边的时候，消费者会觉得折扣更大一些。</p><h4 id="40-只给低价商品折扣"><a href="#40-只给低价商品折扣" class="headerlink" title="40. 只给低价商品折扣"></a>40. 只给低价商品折扣</h4><p>折扣有可能有害的，尤其是当你结束一个折扣的时候，人们可能会选择竞品，或者等待下一个折扣期。</p><p>那么这种副作用会在什么时候因为什么而生效呢？ 答案在于你的品牌的定位，是高质量的还是低质量的产品，高质量商品就应该集中注意力于质量</p><h4 id="41-逐渐减小折扣的百分比"><a href="#41-逐渐减小折扣的百分比" class="headerlink" title="41. 逐渐减小折扣的百分比"></a>41. 逐渐减小折扣的百分比</h4><p>这种方式能够吸引流量，也能够保证自己的利润不受到太大的损害。</p><h4 id="42-折扣完价格的右侧数字需要小一些"><a href="#42-折扣完价格的右侧数字需要小一些" class="headerlink" title="42. 折扣完价格的右侧数字需要小一些"></a>42. 折扣完价格的右侧数字需要小一些</h4><p>当右侧的数字小，会显得整个折扣相对比较大。</p><p><img src="https://i.loli.net/2020/06/05/qU7mokILNzFGJ5M.png" alt="right-digit-effect-2.png"></p><p><img src="https://i.loli.net/2020/06/05/KNczCvMyIa2hOrf.png" alt="pricing-tactic-42.png"></p><p><img src="https://i.loli.net/2020/06/05/pfBYcn2QTrbtyJ7.png" alt="psychological-pricing-table5.png"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.nickkolenda.com/psychological-pricing-strategies/" target="_blank" rel="noopener">https://www.nickkolenda.com/psychological-pricing-strategies/</a> </li><li><a href="https://blog.gumroad.com/post/64417917582/a-penny-saved-psychological-pricing" target="_blank" rel="noopener">https://blog.gumroad.com/post/64417917582/a-penny-saved-psychological-pricing</a></li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/S1057740811001082" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/abs/pii/S1057740811001082</a></li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/001002779290049N" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/abs/pii/001002779290049N</a></li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/S1057740811001082" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/abs/pii/S1057740811001082</a></li><li><a href="https://www8.gsb.columbia.edu/sites/decisionsciences/files/files/Divide_and_Prosper.pdf" target="_blank" rel="noopener">https://www8.gsb.columbia.edu/sites/decisionsciences/files/files/Divide_and_Prosper.pdf</a></li><li><a href="http://www.dc.uba.ar/materias/incc/practicas/p1/Dehaene-ParitySNARCeffect-JEPGeneral1993.pdf" target="_blank" rel="noopener">www.dc.uba.ar/materias/incc/practicas/p1/Dehaene-ParitySNARCeffect-JEPGeneral1993.pdf</a></li><li><a href="https://journals.ama.org/doi/abs/10.1509/jm.13.0059" target="_blank" rel="noopener">https://journals.ama.org/doi/abs/10.1509/jm.13.0059</a></li><li><a href="https://journals.ama.org/doi/abs/10.1509/jmr.13.0488" target="_blank" rel="noopener">https://journals.ama.org/doi/abs/10.1509/jmr.13.0488</a></li><li><a href="http://www.dhruvgrewal.com/wp-content/uploads/2014/09/2013-JR-Color.pdf" target="_blank" rel="noopener">http://www.dhruvgrewal.com/wp-content/uploads/2014/09/2013-JR-Color.pdf</a></li><li><a href="https://vtechworks.lib.vt.edu/bitstream/handle/10919/49138/661893.pdf?sequence=1&amp;isAllowed=y" target="_blank" rel="noopener">https://vtechworks.lib.vt.edu/bitstream/handle/10919/49138/661893.pdf?sequence=1&amp;isAllowed=y</a></li><li><a href="https://production.wordpress.uconn.edu/businessmarketing/wp-content/uploads/sites/724/2014/08/size-does-matter.pdf" target="_blank" rel="noopener">https://production.wordpress.uconn.edu/businessmarketing/wp-content/uploads/sites/724/2014/08/size-does-matter.pdf</a></li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/S1057740809000266" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/abs/pii/S1057740809000266</a></li><li><a href="https://www.sciencedirect.com/science/article/abs/pii/S1057740809000266" target="_blank" rel="noopener">https://www.sciencedirect.com/science/article/abs/pii/S1057740809000266</a></li><li><a href="https://www.andrew.cmu.edu/user/gl20/GeorgeLoewenstein/Papers_files/pdf/redblack.pdf" target="_blank" rel="noopener">https://www.andrew.cmu.edu/user/gl20/GeorgeLoewenstein/Papers_files/pdf/redblack.pdf</a></li><li><a href="https://www.jstor.org/stable/10.1086/597161?seq=1" target="_blank" rel="noopener">https://www.jstor.org/stable/10.1086/597161?seq=1</a></li><li><a href="https://socialtriggers.com/why-you-should-never-discount/" target="_blank" rel="noopener">https://socialtriggers.com/why-you-should-never-discount/</a></li><li><a href="https://journals.ama.org/doi/pdf/10.1509/jm.12.0052" target="_blank" rel="noopener">https://journals.ama.org/doi/pdf/10.1509/jm.12.0052</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 心理学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>提高代码质量的Tips</title>
      <link href="/%E5%85%B3%E4%BA%8E%E6%8F%90%E9%AB%98%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F%E7%9A%84Tips/"/>
      <url>/%E5%85%B3%E4%BA%8E%E6%8F%90%E9%AB%98%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F%E7%9A%84Tips/</url>
      
        <content type="html"><![CDATA[<h1 id="1-如何重构"><a href="#1-如何重构" class="headerlink" title="1. 如何重构"></a>1. 如何重构</h1><h2 id="1-1-为什么要重构代码？"><a href="#1-1-为什么要重构代码？" class="headerlink" title="1.1 为什么要重构代码？"></a>1.1 为什么要重构代码？</h2><p>重构是一种对软件内部结构的改善，目的是在不改变软件的可见行为的情况下，使其更易理解，修改成本更低。</p><p>即 重构是指保持功能不变的前提下，利用设计思想、原则、模式和编程规范等理论来优化代码，修改设计上的不足，提高代码的质量。</p><p>如果没有维护，物体势必会往熵增加的方向去演变的。如果不做代码的维护，代码总归会往越来越混乱的方向演进，当混乱到一定程度，量变引起质变，项目的维护成本已经高过了重新开发一套新代码的成本，再去重构就会变得十分困难了。</p><h2 id="1-2-重构的对象"><a href="#1-2-重构的对象" class="headerlink" title="1.2 重构的对象"></a>1.2 重构的对象</h2><ul><li>大型重构<ul><li>对顶层代码设计的重构<ul><li>包括 <ul><li>系统</li><li>模块</li><li>代码结构</li><li>类与类之间的关系</li></ul></li><li>重构的手段<ul><li>分层</li><li>模块化</li><li>解耦</li><li>抽象可复用的组件</li></ul></li></ul></li></ul></li></ul><ul><li>小型重构<ul><li>对于代码细节的重构</li><li>针对类，函数，变量等代码级别的重构</li></ul></li></ul><h2 id="1-3-什么时候重构？"><a href="#1-3-什么时候重构？" class="headerlink" title="1.3 什么时候重构？"></a>1.3 什么时候重构？</h2><p>持续重构的概念，即没事情的时候，看看项目中有哪些写得不够好，可以优化的代码，主动去重构一下。或者在修改添加某个功能代码的时候，也可以顺手把不符合编码规范，不好的设计重构一下。</p><h2 id="1-4-如何解耦代码？"><a href="#1-4-如何解耦代码？" class="headerlink" title="1.4 如何解耦代码？"></a>1.4 如何解耦代码？</h2><ul><li><p>解耦的目的</p><ul><li>高内聚</li><li>松耦合</li></ul></li><li><p>为什么需要解耦</p><ul><li>控制代码的复杂性</li><li>使得我们可以聚焦在某一模块或类当中，不需要了解太多其他模块或类的代码</li><li>使得代码改动相对集中，引入bug的风险就减少了很多</li></ul></li><li><p>如何判断是否需要解耦</p><ul><li>在做修改的时候是否需要跨很多个包来进行改动</li><li>需要通过解耦的方式让依赖关系变得清晰，简单一些</li></ul></li><li><p>如何进行解耦</p><ul><li><p>封装与抽象</p><ul><li>有效隐藏实现的复杂</li><li>隔离实现的易变性</li><li>给依赖的模块提供稳定易用的抽象接口</li></ul></li><li><p>引入中间层</p><ul><li>引入中间层能够简化模块或类之间的依赖关系</li><li>即我们可以让开发和重构同步进行</li><li>例如需要进行接口的修改<ul><li>先引入一个中间层，包裹老的接口，提供新的接口定义</li><li>新开发的代码依赖中间层提供的新接口</li><li>将依赖老街口的代码改为调用新接口</li><li>确保所有的代码都调用新接口之后，删掉老接口</li></ul></li></ul></li><li><p>模块化</p><ul><li>对于一个大型复杂系统来说，没有人能够掌控所有细节</li><li>通过划分成不同的独立模块，让不同的人负责不同的模块</li><li>这样即便在不了解全部细节的情况下，管理者也能够协调各个模块，让整个系统有效运转起来</li><li>将每个模块都当做一个独立的library来进行开发，只提供封装了内部实现细节的接口给其他模块使用，以此来减少不同模块之间的耦合度</li></ul></li><li><p>遵循设计思想和原则</p><ul><li>单一职责原则</li><li>基于接口而非实现编程</li><li>依赖注入</li><li>多用组合少用继承</li><li>迪米特法则<ul><li>不应该有直接依赖关系的类</li></ul></li></ul></li></ul></li></ul><h1 id="2-代码的可测试性"><a href="#2-代码的可测试性" class="headerlink" title="2. 代码的可测试性"></a>2. 代码的可测试性</h1><p>做重构，如何保证你做的改动能够按照既定的想法运行，那么我们需要来写单元测试，来保证新的代码仍然能够通过，即原有的逻辑的正确性没有被破坏。</p><p>另外，单元测试的阅读实际上是快速熟悉代码的一种方式</p><p>一些常见的Anti-patterns:</p><ul><li>未决行为<ul><li>代码的输出是随机的，或者不确定的</li></ul></li><li>全局变量</li><li>静态方法</li><li>复杂继承</li><li>高耦合代码</li></ul><h1 id="3-编程规范"><a href="#3-编程规范" class="headerlink" title="3. 编程规范"></a>3. 编程规范</h1><h2 id="3-1-命名与注释"><a href="#3-1-命名与注释" class="headerlink" title="3.1 命名与注释"></a>3.1 命名与注释</h2><ol><li>在足够表达含义的情况下，命名尽量短</li></ol><p>命名时候的缩写，只对大家比较熟知的使用，减少阅读时候的障碍的感觉。</p><ol start="2"><li>利用上下文简化命名</li></ol><p>比如POJO当中，类名往往对这是个什么类做了定义了，成员变量就不用再添加类前缀了</p><ol start="3"><li>命名需要可读，可搜索</li></ol><p>英文上可读，方便发音，哪怕是第一次见到，也需要尽可能简单的能够直接读出来</p><p>另外需要遵从一些大家约定俗成的规范，即比如使用selectXXX 还是queryXXX 来表示选择，从数据库里面拿东西，一旦选定，就需要一起遵从规定了。</p><ol start="4"><li>对于接口，抽象类的命名</li></ol><ul><li><p>对于接口的命名</p><ul><li>加前缀I，比如IUserService</li><li>或者加后缀Impl, UserServiceImpl</li></ul></li><li><p>抽象类的命名</p><ul><li>加上前缀Abstract</li><li>或者不带</li></ul></li></ul><p>皆可，但是需要形式上的统一。</p><ol start="5"><li>注释</li></ol><ul><li><p>目的</p><ul><li>让代码更容易看懂</li></ul></li><li><p>写什么</p><ul><li>是什么，为什么，怎么办 三大问题</li><li>能够起到总结性和文档的作用</li><li>总结性注释也能够让整个代码更加清晰</li></ul></li><li><p>在哪里写</p><ul><li>一般来说是在类和函数上写注释</li><li>函数内部尽量通过好的命名，提炼函数，解释性的变量来提高代码的可读性</li></ul></li></ul><h2 id="3-2-代码风格"><a href="#3-2-代码风格" class="headerlink" title="3.2 代码风格"></a>3.2 代码风格</h2><ol><li>类和函数的大小</li></ol><p>软标准，只是要尽量注意，对于很大的类，最好将其分割开</p><ol start="2"><li>一行代码的长度的限制，譬如100字符或者150字符</li><li>使用空行分割单元块</li></ol><ul><li>对于比较长的函数，如果逻辑上可以分为几个独立的代码块，可以使用空行来分割各个代码块</li><li>在类的成员变量和函数之间</li><li>静态成员变量和普通成员变量之间</li><li>各个函数之间</li><li>各个成员变量之间</li></ul><ol start="4"><li>缩进风格的统一</li><li>类当中成员的排列顺序</li></ol><ul><li>首先是类的所属包名</li><li>然后罗列import引入的依赖类</li><li>类当中<ul><li>大原则<ul><li>先静态，后普通</li><li>作用域从大到小来排序</li></ul></li><li>成员变量</li><li>各种方法</li></ul></li></ul><h2 id="3-3-编程技巧"><a href="#3-3-编程技巧" class="headerlink" title="3.3 编程技巧"></a>3.3 编程技巧</h2><ol><li>将代码分割为更小的单元块</li></ol><p>大部分人阅读代码的习惯都是先看整体再看细节，因为我们要有模块化和抽象思维，善于将大块的负责逻辑提炼成类或者函数，屏蔽掉细节</p><p>通过提炼函数，通过函数名字，直接读懂这段代码是做什么用的</p><ol start="2"><li>避免函数参数过多</li></ol><ul><li>考虑函数是否职责单一，能否通过拆分多个函数的方式来减少参数</li><li>将函数的参数封装成对象</li><li>不要使用函数的参数(true/ false) 来控制逻辑，直接分成几个不同的函数会更好</li></ul><ol start="3"><li>函数的设计，职责单一</li><li>移除过深的嵌套层次</li></ol><ul><li>去掉多余的if else语句</li><li>使用continue break return等关键字，来提前退出嵌套</li><li>调整执行顺序来减少嵌套</li><li>将部分嵌套逻辑封装成函数调用，以此来减少嵌套</li></ul><ol start="5"><li>使用解释性变量</li></ol><ul><li>常量替代magic number</li><li>使用解释性变量来解释复杂表达式</li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Enzyme + Jest Practice</title>
      <link href="/Enzyme-Jest-Practice/"/>
      <url>/Enzyme-Jest-Practice/</url>
      
        <content type="html"><![CDATA[<h1 id="1-How-to-use-enzyme-with-jest"><a href="#1-How-to-use-enzyme-with-jest" class="headerlink" title="1. How to use enzyme with jest"></a>1. How to use enzyme with jest</h1><h2 id="1-1-children"><a href="#1-1-children" class="headerlink" title="1.1 children()"></a>1.1 children()</h2><p>This blog mainly describe some practice on how to write tests in jest with enzyme. </p><pre><code>// This test make sure the component only have one h1 element describe(&#39;&lt;Add /&gt; rendering&#39;, () =&gt; {    it(&#39;should render one &lt;h1&gt;&#39;, () =&gt; {        let wrapper = shallow(&lt;Add /&gt;);        expect(wrapper.children(&#39;h1&#39;)).toHaveLength(1);    });});</code></pre><h2 id="1-2-snapshot"><a href="#1-2-snapshot" class="headerlink" title="1.2 snapshot"></a>1.2 snapshot</h2><pre><code>// For snapshot test, jest will help you create a directory named __snapshots__ with the autogenerated file inside with the extension `.snap`. Push snapshot into the repository and store it along with the test // it means same as test it(&#39;render correctly text component&#39;, () =&gt; {      const TextInputComponent = renderer.create(&lt;TextInput /&gt;).toJSON();    expect(TextInputComponent).toMatchSnapshot();});</code></pre><h2 id="1-3-Test-with-props-in-your-component"><a href="#1-3-Test-with-props-in-your-component" class="headerlink" title="1.3 Test with props in your component"></a>1.3 Test with props in your component</h2><pre><code>it(&#39;check month and years dropdowns displayed&#39;, () =&gt; {      const props = {            showMonthYearsDropdowns: true        },        DateInputComponent = mount(&lt;DateInput {...props} /&gt;).find(&#39;.datepicker&#39;);    expect(DateInputComponent.hasClass(&#39;react-datepicker-hide-month&#39;)).toEqual(true);});it(&#39;render date input correctly with null value&#39;, () =&gt; {      const props = {            value: null        },        DateInputComponent = mount(&lt;DateInput {...props} /&gt;);    expect((DateInputComponent).prop(&#39;value&#39;)).toEqual(null);});it(&#39;check the type of value&#39;, () =&gt; {      const props = {            value: &#39;10.03.2018&#39;        },        DateInputComponent = mount(&lt;DateInput {...props} /&gt;);    expect(DateInputComponent.prop(&#39;value&#39;)).toBeString();});</code></pre><h2 id="1-4-Test-events"><a href="#1-4-Test-events" class="headerlink" title="1.4 Test events"></a>1.4 Test events</h2><pre><code>it(&#39;check the onChange callback&#39;, () =&gt; {      const onChange = jest.fn(),        props = {            value: &#39;20.01.2018&#39;,            onChange        },        DateInputComponent = mount(&lt;DateInput {...props} /&gt;).find(&#39;input&#39;);    DateInputComponent.simulate(&#39;change&#39;, { target: {value: moment(&#39;2018-01-22&#39;)} });    expect(onChange).toHaveBeenCalledWith(&#39;22.01.2018&#39;);});it(&#39;check DatePicker popup open&#39;, () =&gt; {      const DateComponent = mount(&lt;DateInput /&gt;),        dateInput = DateComponent.find(&quot;input[type=&#39;text&#39;]&quot;);    dateInput.simulate(&#39;click&#39;);    expect(DateComponent.find(&#39;.react-datepicker&#39;)).toHaveLength(1);});</code></pre><h1 id="2-Some-tips"><a href="#2-Some-tips" class="headerlink" title="2. Some tips"></a>2. Some tips</h1><ol><li><p>One component should have only one snapshot. </p><ol><li>mainly because if one fails, most likely the others will fail too </li></ol></li><li><p>Test props. </p><ol><li>check the render od default prop values </li><li>check the custom value of the prop, set your own value and do tests </li></ol></li><li><p>Testing data types </p><ol><li>you could use <code>jest-extended</code> to test the type of data </li></ol></li><li><p>Event testing </p><ol><li>mock event -&gt; simulate it -&gt; expect event was called </li><li>mock event -&gt; simulate event with params -&gt; expect event was called with passed params </li><li>pass necessary props -&gt; render component -&gt; simulate event -&gt; expect a certain behavior on called event </li></ol></li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://blog.bitsrc.io/how-to-test-react-components-with-jest-and-enzyme-in-depth-145fcd06b90" target="_blank" rel="noopener">https://blog.bitsrc.io/how-to-test-react-components-with-jest-and-enzyme-in-depth-145fcd06b90</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>如何高效开Design Meetings</title>
      <link href="/%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%BC%80Design-Meetings/"/>
      <url>/%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%BC%80Design-Meetings/</url>
      
        <content type="html"><![CDATA[<p>能靠规范做的事情就尽量不要靠直觉，把直觉用在更需要直觉的地方吧。</p><p>工作的日常一定少不了开会的，但是你会有感觉到有一些会议效率非常高，你带着问题来开会，问题迅速被解决，每个人都对下一步很清晰，然后会议结束。但是我们也时常经历完全相反的过程，你带着问题进入，但是问题没有被解答，每个人变得更加困惑的结束会议。</p><p>问题在于，如何能够确保我们的会议是有效率的，能够解决问题的，这需要一些规则和日程上的安排，来确保其效率。</p><h1 id="1-清晰认知会议的类型"><a href="#1-清晰认知会议的类型" class="headerlink" title="1. 清晰认知会议的类型"></a>1. 清晰认知会议的类型</h1><p>在项目的设计过程当中，我们可以根据输入和输出将会议分为三个主要的类型：定义，设计与开发</p><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h2><p>定义类型的会议指的是开展一个新项目，以及设定需求的过程。在这个会议当中，我们需要定义：</p><ul><li>问题是什么</li><li>用户是谁</li><li>有哪些限制</li><li>时间轴</li></ul><p>一般来说，需求定义的会议参加的人数少效果会更加理想一些，比如只带产品经理以及设计师。</p><h2 id="1-2-设计"><a href="#1-2-设计" class="headerlink" title="1.2 设计"></a>1.2 设计</h2><p>设计是个交互的过程，会需要大量的和产品，设计，技术来进行交流。可以将整个设计过程划分为以下的步骤：</p><ul><li><p>调研 (Research)</p><ul><li>看看问题和用户是否已经被定义了，花点时间去看看其他人是如何解决这个问题的（不仅限于你的公司，包括工业界）</li></ul></li><li><p>草拟 (Sketch)</p><ul><li>探索不同的选择，然后判断哪一个能够满足需求</li></ul></li><li><p>反馈 (Feedback)</p><ul><li>注意想要得到哪方面的反馈 </li><li>最好专注在某一个方向上</li></ul></li><li><p>迭代 (Refine)</p><ul><li>根据时间轴不断获取反馈，完成迭代</li></ul></li></ul><p>设计会议的关键在于需求解决哪方面的问题，我们需要聚焦于这个问题。对于不同的设计的选择，我们需要从开发者那里拿到反馈。</p><h2 id="1-3-开发"><a href="#1-3-开发" class="headerlink" title="1.3 开发"></a>1.3 开发</h2><p>当我们进入这部分的会议的时候，我们已经有了大致上的设计的思路，这个时候会更多的考虑一些edge case，还有技术上的限制。这里会有一些技术和设计方面的权衡，我们可能会需要调整我们的设计，来满足从技术角度的考量。设计和产品需要一直参与在这个过程当中，以保证哪怕细节上有调整，但是设计的初衷/理念不会被改变。</p><h1 id="2-邀请正确的人"><a href="#2-邀请正确的人" class="headerlink" title="2. 邀请正确的人"></a>2. 邀请正确的人</h1><p>我们需要很清楚这个会议是关于什么的，以及谁应该出现在这里。一个组往往可能会有3 - 10人左右，一般来说，让10个人全都出现在会议当中不是很有效率的方式，我们需要一个模型来决定谁应该出现在会议当中。 </p><p>Decide, Console, Inform模型</p><h2 id="2-1-决策"><a href="#2-1-决策" class="headerlink" title="2.1 决策"></a>2.1 决策</h2><p>决策者是可以对项目付出时间精力以及金钱的人。他们会最终决定要做什么，以及为什么要这样做。我们需要将所有的决策者带入到会议室当中，这样如果相互之间有不同意见，可以很及时的解决。并且提供下一步。</p><p>这种时候，往往相对比较小的会议更容易达成好的结果，即只带入必要的人，一般来说，是产品的带头人，设计的带头人，以及技术方面的带头人。</p><h2 id="2-2-咨询"><a href="#2-2-咨询" class="headerlink" title="2.2 咨询"></a>2.2 咨询</h2><p>这里指的是对这个领域很了解的人，他们会提出很有价值的建议，不过决定权还在决策者手中。比如几种技术方案的最终选择，就需要引入对框架，各种方法很熟悉的工程师来给出建议了。</p><h2 id="2-3-通知"><a href="#2-3-通知" class="headerlink" title="2.3 通知"></a>2.3 通知</h2><p>组里的一员，被邀请 == 被通知，lol </p><h1 id="3-按照时间安排展开会议"><a href="#3-按照时间安排展开会议" class="headerlink" title="3. 按照时间安排展开会议"></a>3. 按照时间安排展开会议</h1><p>我们需要十分清楚这个会议的目的是什么，我们最终想达到什么样的成果</p><ul><li>我们解决了什么样的问题</li><li>我们可以做出什么样的决定</li><li>下一步措施是什么</li></ul><p>一些比较好的行为，强烈推荐：</p><ul><li><p>会议前</p><ul><li>发送邮件，给出安排</li><li>给出相关的链接，使得参会人可以在参会前可以做一些准备</li></ul></li><li><p>会议开始</p><ul><li>说整个会议的安排<ul><li>比如想看看几种设计</li><li>需要基于什么什么得到反馈</li><li>下一步</li></ul></li></ul></li><li><p>会议结束</p><ul><li>总结反馈 以及下一步<ul><li>在会议还剩下5min左右的时候来做总结和下一步计划</li><li>总结获得的反馈，和决定  这样子如果我们忘记了一些东西，其他人可以给我们做补充</li><li>问下一步是什么，以及每一步的负责人</li></ul></li></ul></li><li><p>会议后</p><ul><li>发送邮件总结会议<ul><li>讨论了什么</li><li>下了什么决定</li><li>下一步工作，是什么，谁来做</li></ul></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://blog.prototypr.io/3-tips-to-run-effective-design-meetings-dec2ec238b56" target="_blank" rel="noopener">https://blog.prototypr.io/3-tips-to-run-effective-design-meetings-dec2ec238b56</a> </p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> meeting </tag>
            
            <tag> tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Enzyme -- React测试库</title>
      <link href="/Enzyme-React%E6%B5%8B%E8%AF%95%E5%BA%93/"/>
      <url>/Enzyme-React%E6%B5%8B%E8%AF%95%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p>这是前端用于对React的组件进行测试的一个工具类，我们可以使用这个工具来遍历，控制，以及一定程度上的模拟运行时输出。我们主要是将该工具类和Jest一起使用，写我们的react组件的单元测试们。</p><h1 id="1-Shalow-Rendering"><a href="#1-Shalow-Rendering" class="headerlink" title="1. Shalow Rendering"></a>1. Shalow Rendering</h1><p>用于以单个组件为单元来进行测试，然后确保你的测试不会依赖于子组件的状态。从Enzyme v3开始，shallow API会call React生命周期方法了，譬如<code>componentDidUpdate</code>和<code>componentDidMount</code></p><pre><code>import { shallow } from &#39;enzyme&#39;;import sinon from &#39;sinon&#39;;import Foo from &#39;./Foo&#39;;describe(&#39;&lt;MyComponent /&gt;&#39;, () =&gt; {  it(&#39;renders three &lt;Foo /&gt; components&#39;, () =&gt; {    const wrapper = shallow(&lt;MyComponent /&gt;);    expect(wrapper.find(Foo)).to.have.lengthOf(3);  });  it(&#39;renders an `.icon-star`&#39;, () =&gt; {    const wrapper = shallow(&lt;MyComponent /&gt;);    expect(wrapper.find(&#39;.icon-star&#39;)).to.have.lengthOf(1);  });  it(&#39;renders children when passed in&#39;, () =&gt; {    const wrapper = shallow((      &lt;MyComponent&gt;        &lt;div className=&quot;unique&quot; /&gt;      &lt;/MyComponent&gt;    ));    expect(wrapper.contains(&lt;div className=&quot;unique&quot; /&gt;)).to.equal(true);  });  it(&#39;simulates click events&#39;, () =&gt; {    const onButtonClick = sinon.spy();    const wrapper = shallow(&lt;Foo onButtonClick={onButtonClick} /&gt;);    wrapper.find(&#39;button&#39;).simulate(&#39;click&#39;);    expect(onButtonClick).to.have.property(&#39;callCount&#39;, 1);  });});</code></pre><p><a href="https://enzymejs.github.io/enzyme/docs/api/shallow.html" target="_blank" rel="noopener">API Reference</a></p><h1 id="2-Full-Dom-Rendering"><a href="#2-Full-Dom-Rendering" class="headerlink" title="2. Full Dom Rendering"></a>2. Full Dom Rendering</h1><p>这种测试方式在你需要和DOM API进行交互，或者需要测试在更高次位的组件的时候非常有用。</p><p>需要运行在浏览器环境当中，如果无法运行在真实的浏览器当中，那我们就需要依赖于<code>mount</code>指令，在指令之下，是调用了一个叫做jsdom的包，完全使用JavaScript实现了一个浏览器。</p><p>值得注意的是，full dom rendering是真实的将当前组件渲染到DOM树当中，这也意味着如果用的是同一棵DOM树，那么你做的改动很可能会影响其他的测试，这点是值得我们注意的。</p><pre><code>import { mount } from &#39;enzyme&#39;;import sinon from &#39;sinon&#39;;import Foo from &#39;./Foo&#39;;describe(&#39;&lt;Foo /&gt;&#39;, () =&gt; {  it(&#39;calls componentDidMount&#39;, () =&gt; {    sinon.spy(Foo.prototype, &#39;componentDidMount&#39;);    const wrapper = mount(&lt;Foo /&gt;);    expect(Foo.prototype.componentDidMount).to.have.property(&#39;callCount&#39;, 1);  });  it(&#39;allows us to set props&#39;, () =&gt; {    const wrapper = mount(&lt;Foo bar=&quot;baz&quot; /&gt;);    expect(wrapper.props().bar).to.equal(&#39;baz&#39;);    wrapper.setProps({ bar: &#39;foo&#39; });    expect(wrapper.props().bar).to.equal(&#39;foo&#39;);  });  it(&#39;simulates click events&#39;, () =&gt; {    const onButtonClick = sinon.spy();    const wrapper = mount((      &lt;Foo onButtonClick={onButtonClick} /&gt;    ));    wrapper.find(&#39;button&#39;).simulate(&#39;click&#39;);    expect(onButtonClick).to.have.property(&#39;callCount&#39;, 1);  });});</code></pre><p><a href="https://enzymejs.github.io/enzyme/docs/api/mount.html" target="_blank" rel="noopener">API Reference</a></p><h1 id="3-Static-Rendering"><a href="#3-Static-Rendering" class="headerlink" title="3. Static Rendering"></a>3. Static Rendering</h1><p>Render 使用的是Cheerio这个HTML转化库，用于从我们的React树来生成HTML，然后分析HTML的整个架构。</p><pre><code>import React from &#39;react&#39;;import { render } from &#39;enzyme&#39;;import PropTypes from &#39;prop-types&#39;;describe(&#39;&lt;Foo /&gt;&#39;, () =&gt; {  it(&#39;renders three `.foo-bar`s&#39;, () =&gt; {    const wrapper = render(&lt;Foo /&gt;);    expect(wrapper.find(&#39;.foo-bar&#39;)).to.have.lengthOf(3);  });  it(&#39;rendered the title&#39;, () =&gt; {    const wrapper = render(&lt;Foo title=&quot;unique&quot; /&gt;);    expect(wrapper.text()).to.contain(&#39;unique&#39;);  });  it(&#39;renders a div&#39;, () =&gt; {    const wrapper = render(&lt;div className=&quot;myClass&quot; /&gt;);    expect(wrapper.html()).to.contain(&#39;div&#39;);  });  it(&#39;can pass in context&#39;, () =&gt; {    function SimpleComponent(props, context) {      const { name } = context;      return &lt;div&gt;{name}&lt;/div&gt;;    }    SimpleComponent.contextTypes = {      name: PropTypes.string,    };    const context = { name: &#39;foo&#39; };    const wrapper = render(&lt;SimpleComponent /&gt;, { context });    expect(wrapper.text()).to.equal(&#39;foo&#39;);  });});</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://enzymejs.github.io/enzyme/" target="_blank" rel="noopener">https://enzymejs.github.io/enzyme/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Enzyme </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>应用设计 Practice</title>
      <link href="/%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1-Practice/"/>
      <url>/%E5%BA%94%E7%94%A8%E8%AE%BE%E8%AE%A1-Practice/</url>
      
        <content type="html"><![CDATA[<h1 id="1-thought"><a href="#1-thought" class="headerlink" title="1. thought"></a>1. thought</h1><p>实际应用设计，首先还是需要将工作进行合理分割：</p><ul><li>前期需求沟通分析<ul><li>工程师应该尽量参与到产品设计当中</li><li>寻找类似的产品，进行借鉴</li><li>将借鉴来的东西努力融合到我们自己的产品当中</li></ul></li><li>中期代码设计实现</li><li>后期系统上线维护 <h1 id="2-业务系统设计-–-积分系统"><a href="#2-业务系统设计-–-积分系统" class="headerlink" title="2. 业务系统设计 – 积分系统"></a>2. 业务系统设计 – 积分系统</h1></li></ul><h2 id="2-1-业务需求"><a href="#2-1-业务需求" class="headerlink" title="2.1 业务需求"></a>2.1 业务需求</h2><ul><li><p>功能点</p><ul><li>赚取积分<ul><li>积分赚取渠道<ul><li>订单</li><li>签到</li><li>评论</li></ul></li><li>积分兑换规则<ul><li>订单金额与积分的兑换比例</li><li>签到赠送积分数量等</li></ul></li></ul></li><li>消费积分<ul><li>积分消费渠道<ul><li>抵扣订单金额</li><li>兑换优惠券</li><li>积分换购</li><li>参与活动</li></ul></li></ul></li></ul></li><li><p>方式方法</p><ul><li>借鉴已经相对成熟的产品<ul><li>看其实现的方式方法</li></ul></li><li>通过产品线框图</li><li>user case<ul><li>模拟用户是如何使用我们的产品的</li><li>描述用户在特定的应用场景当中的一个完整的业务操作流程</li></ul></li></ul></li></ul><h2 id="2-2-系统设计"><a href="#2-2-系统设计" class="headerlink" title="2.2 系统设计"></a>2.2 系统设计</h2><h3 id="2-2-1-功能模块划分"><a href="#2-2-1-功能模块划分" class="headerlink" title="2.2.1 功能模块划分"></a>2.2.1 功能模块划分</h3><ul><li>将功能划分到不同的模块当中 <ul><li>做到模块层面的高内聚，低耦合</li></ul></li></ul><ul><li>针对上述的业务需求，我们可以采用<ul><li><ol><li>将关于积分的赚取消费的规则的管理维护放到更上层的营销系统当中，这样积分系统就只负责增删改查的数据库操作了</li></ol></li><li><ol start="2"><li>将规则分散到各个子系统当中，譬如订单系统，评论系统，签到系统，诸如此类</li></ol></li><li><ol start="3"><li>所有功能划分到积分系统当中</li></ol></li></ul></li></ul><p>值得注意的是，为了避免业务知识的耦合，让下层系统更加通用，我们不希望下层系统（被调用系统）包含太多上层系统（调用系统）的业务信息。但上层系统是可以包含下层系统的业务信息的，比如，订单系统、优惠券系统、换购商城等作为调用积分系统的上层系统，可以包含一些积分相关的业务信息。但是，反过来，积分系统中最好不要包含太多跟订单、优惠券、换购等相关的信息。</p><p>因此，1，2都是相对不错的选择，我们希望做的是让积分系统模块只包含积分的增删改查的操作，而不包含太多的业务层面的逻辑。</p><h3 id="2-2-2-模块间交互"><a href="#2-2-2-模块间交互" class="headerlink" title="2.2.2 模块间交互"></a>2.2.2 模块间交互</h3><p>定位需要和积分系统之间进行交互的系统，以及交互方式。</p><p>一般来说，系统之间的交互方式有两大类：</p><ul><li>同步接口调用</li><li>利用信息中间件异步调用</li></ul><h3 id="2-2-3-设计模块的接口、数据库、业务模型"><a href="#2-2-3-设计模块的接口、数据库、业务模型" class="headerlink" title="2.2.3 设计模块的接口、数据库、业务模型"></a>2.2.3 设计模块的接口、数据库、业务模型</h3><p>数据库和接口的设计相对来说都比较重要，一旦设计好，都不能轻易改动。尤其是当有不同的组来调用你的API的时候，让所有的组都快速迁移到新的API上是一件相对比较困难的事情了。  改动数据库表的结构，需要涉及数据的迁移和适配。</p><p>而业务模型，即业务逻辑代码，因为都是内部使用，改动的可能性比较大，对外是不可见的。</p><ul><li><p>数据库设计：</p><ul><li>id - 明细ID</li><li>user_id - 用户ID</li><li>channel_id - 赚取或消费渠道ID</li><li>event_id - 相关事件ID，例如订单ID，评论ID，优惠券换购ID等</li><li>credit - 积分 </li><li>create_time - 积分赚取或消费时间</li><li>expired_time - 积分过期时间</li></ul></li><li><p>接口设计</p><ul><li>单一职责原则 <ul><li>但是粒度太小也不好，比如一个功能的实现需要多个接口，但是每个接口如果都是RPC的一次远程调用的话，那网络上的损耗就很多，多次远程调用会影响性能的</li><li>另外还有数据一致性 - 即操作的原子性方面的考量</li><li>可以借鉴facade外观设计模式，在职责单一的细粒度接口之上，封装一层粗粒度的接口给外部使用</li></ul></li></ul></li><li><p>MVC </p><ul><li>controller负责接口暴露</li><li>service 负责核心业务逻辑</li><li>repository负责数据读写</li><li>为什么要分成MVC三层？<ul><li>代码复用</li><li>隔离变化</li><li>隔离关注点</li><li>提高代码的可测试性</li><li>能够应对系统的复杂性</li></ul></li></ul></li></ul><h1 id="3-非业务通用框架设计"><a href="#3-非业务通用框架设计" class="headerlink" title="3. 非业务通用框架设计"></a>3. 非业务通用框架设计</h1><p>假设我们要设计开发一个小框架，来获取接口调用的各种统计信息。</p><ul><li>响应时间<ul><li>max/ min/ avg/ percentile/ count/ tps </li></ul></li></ul><h2 id="3-1-需求分析"><a href="#3-1-需求分析" class="headerlink" title="3.1 需求分析"></a>3.1 需求分析</h2><p>是一个和业务无关的独立功能，我们可以将其开发成一个独立的框架或者库，集成到很多的业务系统当中。作为一个需要复用性的框架，除了功能上的需求以外，非功能性的需求也非常重要。</p><ul><li><p>功能性需求分析</p><ul><li><p>接口统计信息</p><ul><li>响应时间</li><li>接口调用次数</li></ul></li><li><p>统计信息的类型</p><ul><li>max min ave percentile tps count </li></ul></li><li><p>统计信息显示格式</p><ul><li>json</li><li>html</li><li>自定义</li></ul></li><li><p>统计信息显示终端</p><ul><li>console</li><li>email</li><li>http 页面</li><li>日志</li><li>自定义</li></ul></li><li><p>统计触发方式</p></li><li><p>统计时间区间</p></li><li><p>统计时间间隔</p></li></ul></li></ul><ul><li><p>非功能性需求分析</p><ul><li><p>易用性</p><ul><li>框架是否易集成，易拔插</li><li>跟业务代码是否为松耦合</li><li>提供的接口是否足够灵活</li></ul></li><li><p>性能</p><ul><li>不希望框架本身的代码执行效率会对业务系统有太多性能上的影响</li><li>希望框架低延迟，并且对内存的消耗不能太大</li></ul></li><li><p>扩展性</p><ul><li>在不修改或者尽量少修改代码的情况下添加新功能的能力</li></ul></li><li><p>容错性</p></li><li><p>通用性</p><ul><li>除了接口数据统计，能否将其放到其他事件上来做统计呢？ </li></ul></li></ul></li></ul><h2 id="3-2-框架设计"><a href="#3-2-框架设计" class="headerlink" title="3.2 框架设计"></a>3.2 框架设计</h2><p>可以借鉴TDD (测试驱动开发)和Prototype(最小原型)的思想，先聚焦于一个简单的应用场景，基于此来设计一个简单的原型，然后不断进行迭代。</p><p>而后是将整个框架分为多个模块，分模块进行思考：</p><ul><li>数据采集<ul><li>打点采集原始数据</li><li>记录每次接口请求的响应时间和请求时间</li><li>数据采集过程要高度容错，不能影响到接口本身的可用性</li></ul></li><li>存储<ul><li>负责将采集的原始数据保存下来，以便后面做聚合统计</li><li>数据可以存储在<ul><li>redis</li><li>mysql</li><li>hbase</li><li>日志</li><li>文件</li><li>内存</li></ul></li></ul></li><li>聚合统计<ul><li>将原始数据聚合为统计数据</li></ul></li><li>显示<ul><li>将统计数据以某种格式显示到终端当中</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System Design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中台(二) - 略深入些的探究</title>
      <link href="/%E4%B8%AD%E5%8F%B0-%E4%BA%8C-%E7%95%A5%E6%B7%B1%E5%85%A5%E4%BA%9B%E7%9A%84%E6%8E%A2%E7%A9%B6/"/>
      <url>/%E4%B8%AD%E5%8F%B0-%E4%BA%8C-%E7%95%A5%E6%B7%B1%E5%85%A5%E4%BA%9B%E7%9A%84%E6%8E%A2%E7%A9%B6/</url>
      
        <content type="html"><![CDATA[<p>中台是企业级能力复用平台，整个中台的构建，实际上是将业务数据化，将数据业务化。是需要建立业务中台和数据中台的。业务中台通过抽象，封装可复用的逻辑，提升企业的响应力；数据中台通过打通企业的数据，构建自学习服务的数据能力，让企业更加智慧。</p><h1 id="1-通用化通用能力"><a href="#1-通用化通用能力" class="headerlink" title="1. 通用化通用能力"></a>1. 通用化通用能力</h1><p>目前大部分企业实现的中台，主要是将遗留下的后台系统，比如ERP MES CRM的公共部分进行拆解复用，形成类似交易中心，用户中心，订单中心这样的微服务集合供前台调用，从而保证<strong>逻辑的一致性</strong>同时更快响应前台的变化</p><p>Reference <a href="https://www.infoq.cn/article/wCZV6X5uujxDXFP0Eub9?utm_source=rss&utm_medium=article" target="_blank" rel="noopener">1</a> 当中举了订单服务的演进过程的例子，很值得一看。当平台需要开放多渠道来完成订单的时候，保证用户有着类似的体验是很重要的一项，包括整个系统的的scalability。</p><p>在这种情况下，一个数据中台能够使得用户可以看到在各个平台各个渠道自己下的订单。从平台角度来说，有了数据中台，维护成本，发生错误以后的修改成本都会减轻很多。</p><p>略微解释下，如果是分开的系统，那么每个系统都会有自己的数据库，我们需要做数据的join操作，然后返回给前端用户需要的正确的信息。当发生了逻辑上的错误以后，我们很有可能需要在分开的几个子系统当中来做修改，很容易出错，修改的整个时间消耗也会很长。而且数据仓库在多个系统的情况下，抽取数据，再进行分析是有比较大的时延的，一般都是加一天的样子，无法看到实时的数据。</p><h1 id="2-使用中台去ERP化"><a href="#2-使用中台去ERP化" class="headerlink" title="2. 使用中台去ERP化"></a>2. 使用中台去ERP化</h1><p>ERP， 即企业资源管理系统。最最开始的时候，企业的需求是将企业的流程梳理清晰，做到资源的集约化管理，本质上来讲是为了解决流程复用，业务能力化的问题。</p><p>但是当前ERP软件存在着如下的一些问题：</p><ol><li>商业软件，响应慢<br>企业只有使用权，这就导致企业的业务发生变化的时候，需要找到原厂重新配置或者重新开发，响应比较慢</li><li>封闭架构，不开放<br>套装ERP软件是封闭架构，技术不开放，导致企业无法对其进行大的功能上的扩展，只能像打补丁一样，构建一些外挂，而且效果往往不会很好</li><li>单体架构，弹性不够<br>单体架构，很难支持持续增长的各种需求</li><li>升级 维护成本<br>套装软件升级和维护成本非常高</li></ol><p>过去人们需要ERP更多的是因为我们需要流程，需要知道具体应该如何去组织。但是在互联网化的今天，原来静态化，标准化的业务流程已经不足以支撑企业的快速响应了。因此，诉求<strong>从原来的流程化变成了需要能够快速响应前台市场的变化</strong>。</p><p>企业组织结构从流程式协作走向了平台式协作。</p><p>ERP更像是一种计划式的经济，希望每个角色都按照分配的任务来走，共同完成一个任务，但是这种共同完成会导致不同角色之间的利益相互冲突。局部利益大于整体利益。</p><p>需要的转变是 —- 要开始学习以客户为中心去动态组织资源来提供服务，将原本<strong><em>以流程为独立单元的模块拆解为以客户价值为独立单元的模块</em></strong>。</p><p>以客户价值为独立单元，如何评定绩效就是个很关键也很困难的问题，尤其是对于那些为后端赋能的业务单元，如何将其关联到直接的客户价值当中。这需要数据中台提供这方面的能力，来利用全域的数据分析，建模，通过敏感性分析等算法技术来实时计算。</p><h1 id="3-数据中台成熟度的评估维度"><a href="#3-数据中台成熟度的评估维度" class="headerlink" title="3. 数据中台成熟度的评估维度"></a>3. 数据中台成熟度的评估维度</h1><ul><li><p>数据战略</p><ul><li><p>理念</p><ul><li>究竟做数据中台是为了什么</li><li>一个组织的愿景和目标，来指导我们接下来的行动</li><li>确定组织，团队对于战略的理解是一致的</li></ul></li><li><p>行动</p><ul><li>一个管理组织<ul><li>确保战略目标能够被有效分解</li><li>能够在部门团队之间落地</li></ul></li><li>制度建设<ul><li>如何保证战略落地</li><li>如何处理冲突，不一致</li><li>如果构建决策流程</li><li>战略/行动的优化和调整机制</li></ul></li></ul></li></ul></li><li><p>数据治理</p><ul><li><p>元数据相关</p><ul><li>如何做元数据分类</li><li>技术和业务元数据的管理</li><li>维护机制</li></ul></li><li><p>数据字典相关</p></li><li><p>数据模型相关</p></li><li><p>数据质量相关</p></li><li><p>数据标准相关</p></li><li><p>数据安全相关</p></li><li><p>数据生命周期相关</p></li></ul></li><li><p>数据资产管理</p><ul><li><p>数据资产审核能力</p><ul><li>注册申请</li></ul></li><li><p>数据资产发布能力</p><ul><li>将数据提供给消费者查询使用的能力</li></ul></li><li><p>数据资产标签</p><ul><li>客户特征标签</li><li>关键业务的指标标签</li></ul></li><li><p>数据资产地图</p><ul><li>通过地图或者目录的形式，提供数据资产的查询功能</li><li>实现数据资产的可视化</li></ul></li><li><p>数据资产开放能力</p><ul><li>通过接口提供给内外部用户使用</li></ul></li><li><p>数据资产盘点能力</p></li><li><p>数据资产定价</p></li><li><p>效益评估</p></li></ul></li><li><p>数据平台和架构</p><ul><li>基准<ul><li>易用</li><li>稳定</li><li>可扩展</li><li>支持多应用的平台架构</li></ul></li><li>架构标准<ul><li>架构选择的流程<ul><li>同业调研</li><li>选型</li><li>POC</li><li>决策部门</li></ul></li><li>架构方法<ul><li>架构规划</li><li>基础架构</li><li>评估机制</li></ul></li></ul></li></ul></li><li><p>数据服务化</p><ul><li><p>数据中心以什么样的方式向外界提供服务呢？</p><ul><li><p>API调用</p></li><li><p>服务标准的确立</p><ul><li>服务目标</li><li>提供方式</li><li>流程</li><li>优先级</li></ul></li><li><p>服务监控和维护</p><ul><li>量化的评估标准</li></ul></li><li><p>数据服务的评估和优化</p></li></ul></li></ul></li><li><p>数据产品化</p><ul><li>产品<ul><li>报表分析等</li></ul></li><li>业务支撑能力<ul><li>所能支撑的业务是否能反映战略的方向或战略的执行情况，功能支撑能力是不是能被周期性评估和优化</li></ul></li><li>业务分析响应能力<ul><li>响应机制</li></ul></li><li>数据可视化能力<ul><li>是否支持业务友好的使用方式</li></ul></li><li>统一服务的能力<ul><li>是否能够将业务需求沉淀成统一的服务的能力，从而服务更多业务团队</li></ul></li></ul></li><li><p>中台运营</p><ul><li>将整个平台作为一个产品来看，是否有运营的指标和控制机制</li><li>中台管理平台<ul><li>文档</li><li>规范</li><li>流程等</li></ul></li><li>成本分析<ul><li>存储</li><li>计算</li><li>研发 <h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1></li></ul></li></ul></li></ul><ol><li><a href="https://www.infoq.cn/article/wCZV6X5uujxDXFP0Eub9?utm_source=rss&amp;utm_medium=article" target="_blank" rel="noopener">https://www.infoq.cn/article/wCZV6X5uujxDXFP0Eub9?utm_source=rss&amp;utm_medium=article</a></li><li><a href="https://insights.thoughtworks.cn/data-zhongtai-maturity-model/" target="_blank" rel="noopener">https://insights.thoughtworks.cn/data-zhongtai-maturity-model/</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 中台 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jest - JS测试框架</title>
      <link href="/Jest-JS%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/"/>
      <url>/Jest-JS%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<p>JJest是一个简洁的JavaScript测试框架，我们可以将其与Babel, TS, Node, React, Angular, Vue等来共同使用</p><h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><p>首先jest是希望能够用很轻量的方式来进行前端测试，自己最近在做一个偏向前端的项目，希望把组里的对外页面从其他平台转移出来，通过router完成路径的转接，然后在自己的平台上，就可以更自由，更快捷的进行迭代了。</p><p>整个架构还是RPC 暴露RESTFul接口，用类似于API Gateway的系统完成Authorization Authentication的工作，前端直接调用后端的信息这样子。想要达到的最终的目标就是易于维护且易于扩展的一个前端小平台，几个基本需求，也是要做转移的原因：</p><ul><li><p>前端的埋点，希望有更多的metrics以知道用户的行为</p><ul><li>各个页面的浏览时长</li><li>跳出率</li><li>哪个步骤过滤走了最多的用户请求，诸如此类</li></ul></li><li><p>CI/ CD</p><ul><li>手动QA太容易犯错了，如果能写一部分unit tests &amp; integration tests,实现整个前端页面的可测试，那么就可以实现持续继承持续部署，会很大程度上提高可交付能力</li></ul></li><li><p>访问速度</p><ul><li>利用S3 host页面，使用CDN完成分布，会提高整体的响应速度</li></ul></li></ul><p>Jest是实现CI/CD的很不错的一个工具，on my way learning it ;) </p><h2 id="1-1-匹配器"><a href="#1-1-匹配器" class="headerlink" title="1.1 匹配器"></a>1.1 匹配器</h2><p>与Junit类似，使用expect做关键词，E.G</p><pre><code>test(&#39;two plus two is four&#39;, () =&gt; {  expect(2 + 2).toBe(4);});</code></pre><ul><li><p>toBe </p><ul><li>匹配器，内部使用的是<code>Object.is</code>来做精确相等</li></ul></li><li><p>toEqual</p><ul><li>来检查对象的值</li></ul></li><li><p>比较真实性</p><ul><li>toBeNull</li><li>toBeUndefined</li><li>toBeTruthy<ul><li>匹配任何if语句为真</li></ul></li><li>toBeFalsy <ul><li>匹配任何if语句为假 </li></ul></li></ul></li><li><p>比较数字</p><ul><li>toBeGreaterThan()</li><li>toBeGreaterThanOrEqual()</li><li>toBeLessThan()</li><li>toBeLessThanOrEqual()</li><li>toBe()</li><li>toEqual()</li></ul></li><li><p>字符串</p><ul><li>toMatch()  match一个正则表达式</li></ul></li><li><p>数组 </p><ul><li>toContain() 检查一个数组或可迭代的对象是否包含某个特定项</li></ul></li></ul><pre><code>const shoppingList = [  &#39;diapers&#39;,  &#39;kleenex&#39;,  &#39;trash bags&#39;,  &#39;paper towels&#39;,  &#39;beer&#39;,];test(&#39;the shopping list has beer on it&#39;, () =&gt; {  expect(shoppingList).toContain(&#39;beer&#39;);  expect(new Set(shoppingList)).toContain(&#39;beer&#39;);});</code></pre><h2 id="1-2-测试异步代码"><a href="#1-2-测试异步代码" class="headerlink" title="1.2 测试异步代码"></a>1.2 测试异步代码</h2><pre><code>// 对于回调函数的测试test(&#39;the data is peanut butter&#39;, done =&gt; {  function callback(data) {    try {      expect(data).toBe(&#39;peanut butter&#39;);      done();    } catch (error) {      done(error);    }  }  fetchData(callback);});// Promisestest(&#39;the data is peanut butter&#39;, () =&gt; {  return fetchData().then(data =&gt; {    expect(data).toBe(&#39;peanut butter&#39;);  });});// Resolve/ rejecttest(&#39;the data is peanut butter&#39;, () =&gt; {  return expect(fetchData()).resolves.toBe(&#39;peanut butter&#39;);});// async/ awaittest(&#39;the data is peanut butter&#39;, async () =&gt; {  const data = await fetchData();  expect(data).toBe(&#39;peanut butter&#39;);});test(&#39;the fetch fails with an error&#39;, async () =&gt; {  expect.assertions(1);  try {    await fetchData();  } catch (e) {    expect(e).toMatch(&#39;error&#39;);  }});</code></pre><h2 id="1-3-测试前后的utility方法"><a href="#1-3-测试前后的utility方法" class="headerlink" title="1.3 测试前后的utility方法"></a>1.3 测试前后的utility方法</h2><ul><li>重复设置值 </li></ul><pre><code>beforeEach(() =&gt; {});afterEach(() =&gt; {});</code></pre><ul><li><p>一次性设置 – 单个测试不会改变其值</p><p>  beforeAll(() =&gt; {</p><p>  });</p><p>  afterAll(() =&gt; {</p><p>  });</p></li><li><p>作用域 </p><ul><li>通过describe来将测试进行分组操作 </li><li>注意describe的执行顺序 <ul><li>在真正的测试开始之前执行测试文件当中的所有的describe处理程序</li><li>当describe块运行完后，Jest会按照test出现的顺序依次运行所有测试，等待每一个测试完成并整理好，然后继续往下走</li></ul></li><li>通用建议<ul><li>当测试失败的时候，首先要检查的是如果仅运行这条测试，是否仍然失败</li><li>通过将test指令改为test.only指令来实现</li></ul></li></ul></li></ul><h2 id="1-4-Mock-方法"><a href="#1-4-Mock-方法" class="headerlink" title="1.4 Mock 方法"></a>1.4 Mock 方法</h2><p>Mock函数允许我们来测试代码之间的连接，和Mockito， EasyMock其实是一个理念的，擦除函数的实际实现，专注于当前的文件的方法本身，捕获对函数的调用，实例等</p><pre><code>function forEach(items, callback) {  for (let index = 0; index &lt; items.length; index++) {    callback(items[index]);  }}const mockCallback = jest.fn(x =&gt; 42 + x);forEach([0, 1], mockCallback);// 此 mock 函数被调用了两次expect(mockCallback.mock.calls.length).toBe(2);// 第一次调用函数时的第一个参数是 0expect(mockCallback.mock.calls[0][0]).toBe(0);// 第二次调用函数时的第一个参数是 1expect(mockCallback.mock.calls[1][0]).toBe(1);// 第一次函数调用的返回值是 42expect(mockCallback.mock.results[0].value).toBe(42);</code></pre><h1 id="2-测试方法"><a href="#2-测试方法" class="headerlink" title="2. 测试方法"></a>2. 测试方法</h1><h2 id="2-1-Snapshot-测试"><a href="#2-1-Snapshot-测试" class="headerlink" title="2.1 Snapshot 测试"></a>2.1 Snapshot 测试</h2><p>给当前的UI做快照，然后和过去做过的快照进行比较，看是否有不同。</p><pre><code>import React from &#39;react&#39;;import Link from &#39;../Link.react&#39;;import renderer from &#39;react-test-renderer&#39;;it(&#39;renders correctly&#39;, () =&gt; {  const tree = renderer    .create(&lt;Link page=&quot;http://www.facebook.com&quot;&gt;Facebook&lt;/Link&gt;)    .toJSON();  expect(tree).toMatchSnapshot();});</code></pre><p>实际上是生成一个DOM树，然后来比较两颗DOM树的节点，看设置是否相同。</p><p>在每次提交的时候，会记录下当前的快照，下次提交的时候会和这次的来进行比较。</p><p>然后当我们有目的的引入了变化的时候，我们需要告诉jest 需要更新现在保存的snapshot了，这种情况下需要运行指令<code>jest --updateSnapshot</code>.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://jestjs.io/docs/en/getting-started" target="_blank" rel="noopener">https://jestjs.io/docs/en/getting-started</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jest </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>好玩的网站列表</title>
      <link href="/%E5%A5%BD%E7%8E%A9%E7%9A%84%E7%BD%91%E7%AB%99%E5%88%97%E8%A1%A8/"/>
      <url>/%E5%A5%BD%E7%8E%A9%E7%9A%84%E7%BD%91%E7%AB%99%E5%88%97%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p>好玩的东西，持续更新~ </p><ul><li><p>digital nomad</p><ul><li>以数字技术为生，搬到风景优美，气候温和，物价便宜的地方，做自己想做的事情，这概念有意思的</li><li><a href="https://nomadlist.com/" target="_blank" rel="noopener">https://nomadlist.com/</a> </li></ul></li><li><p>Regex 101 </p><ul><li>神一样的正则网站，可以做在线debug</li><li><a href="https://regex101.com/" target="_blank" rel="noopener">https://regex101.com/</a> </li></ul></li><li><p>中国互联网中讨论的消亡</p><ul><li><a href="https://mp.weixin.qq.com/s/a-32UpINmb_vSj17epysiA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/a-32UpINmb_vSj17epysiA</a></li></ul></li><li><p>经济机器是怎样运行的 by Ray Dalio </p><ul><li>在2020年对着现在的经济形势看，别有一番滋味 lol</li><li>tips<ul><li>不要让债务的增长速度超过收入</li><li>不要让收入的增长速度超过生产率</li><li>尽一切努力提高生产率</li></ul></li><li><a href="https://www.bilibili.com/video/av6496369/" target="_blank" rel="noopener">https://www.bilibili.com/video/av6496369/</a></li></ul></li><li><p>大国周期及储备货币变迁 by Ray Dalio</p><ul><li><a href="https://www.chainnews.com/articles/678538813470.htm" target="_blank" rel="noopener">link</a></li></ul></li><li><p>思考工具的📱</p><ul><li><a href="https://untools.co/" target="_blank" rel="noopener">link</a></li></ul></li><li><p>设计模式的讲解</p><ul><li><a href="https://refactoringguru.cn/design-patterns" target="_blank" rel="noopener">link</a></li></ul></li><li><p>计时攻击 Timing Attack</p><ul><li><a href="https://coolshell.cn/articles/21003.html" target="_blank" rel="noopener">link</a></li></ul></li><li><p>2100年的世界人口</p><ul><li><a href="https://www.thelancet.com/article/S0140-6736%2820%2930677-2/fulltext#seccestitle80" target="_blank" rel="noopener">link</a></li><li>预测中国2035年成为世界最大经济体，此后人口会急剧下降，到2100年到7亿左右</li><li>美国因为是移民国家，移民使得人口基本保持稳定，在2098年重新成为世界最大经济体</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>中台(三) - 看白话中台系列的一些总结</title>
      <link href="/%E4%B8%AD%E5%8F%B0-%E4%B8%89-%E7%9C%8B%E7%99%BD%E8%AF%9D%E4%B8%AD%E5%8F%B0%E7%B3%BB%E5%88%97%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%BB%E7%BB%93/"/>
      <url>/%E4%B8%AD%E5%8F%B0-%E4%B8%89-%E7%9C%8B%E7%99%BD%E8%AF%9D%E4%B8%AD%E5%8F%B0%E7%B3%BB%E5%88%97%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>前面两篇文章讲了一些关于中台的信息, <a href="https://llchen60.com/%E4%B8%AD%E5%8F%B0/" target="_blank" rel="noopener">中台1</a>,<a href="https://llchen60.com/%E4%B8%AD%E5%8F%B0-%E4%BA%8C-%E7%95%A5%E6%B7%B1%E5%85%A5%E4%BA%9B%E7%9A%84%E6%8E%A2%E7%A9%B6/" target="_blank" rel="noopener">中台2</a>。</p><ul><li><p>为什么需要平台化</p><ul><li>赋予企业用户响应力</li></ul></li><li><p>什么是中台</p><ul><li><strong>企业级能力复用平台</strong></li><li>基础的理念和架构</li><li>可以联通，支持上端的业务</li><li>需要能够将后台各式各样的资源转化为前台易于使用的能力 –&gt; 以用户为中心的持续规模化创新</li><li>Platform as a product </li><li>亚马逊大量使用微服务，关于微服务与中台，可以想象成中台是多个有平台化能力的微服务的集合，通过隐藏内部的信息和不必要的接口，对外呈现为单独一个具有平台服务能力的微服务。</li></ul></li><li><p>中台分类/ 为什么要建平台</p><ul><li>内部研发效能提升</li><li>资源整合</li><li>新零售</li><li>全周期</li><li>全渠道</li><li>开放银行</li><li>多品牌战略</li><li>全球化战略</li><li>产业互联</li><li>构建商业生态</li></ul></li><li><p>阿里的数据业务双中台</p><ul><li>业务中台将后台资源进行抽象包装整合，转化为前台友好的可重用可共享的核心能力，实现后端业务资源到前台易用能力的转化</li><li>数据中台从后台及业务中台将数据流入，完成海量数据的存储，计算，产品化包装的过程，构成企业的核心数据能力</li></ul></li><li><p>阿里技术中台</p><ul><li>将使用云或者其他基础设施的能力以及应用各种技术中间件的能力进行整合包装，过滤掉技术细节，提供简单一致，易于使用的应用技术基础设施的能力接口，助力前台和业务中台数据中台的快速建设</li></ul></li><li><p>组织中台</p><ul><li>中台建设真正困难的地方在于组织上的重构，技术架构与组织架构的匹配！！</li><li>组织中台很像企业中的内部风投和创新孵化机构，为前台组织和团队构建创新型前台应用提供类似于投资评估（项目甄别）、投资管理、投后管理（孵化与风控），真正从组织和制度上支撑前台组织和应用的快速迭代规模化创新</li></ul></li><li><p>中台建设的难点 – 需要关注组织架构的调整</p><ul><li>组织架构的调整和演进以及利益的重新分配 </li><li>战略的落地是需要靠组织架构的调整来实现的，企业的发展取决于企业正确的战略以及企业的组织结构。前者决定了后者，后者能够保证前者的落地实现</li><li>如果将中台和前台之间的关系定义成服务和被服务的关系，很容易会因为大量需求占据大量时间，短期利益和长期利益的博弈，造成很多问题</li><li>产品化思维，将中台当做一个产品，和其他组是产品之间互通的关系</li></ul></li><li><p>关于中台 - 产品化思考以后的问题</p><ul><li>愿景是什么？<ul><li>中台作为产品需要有自己的愿景定位，不一定需要满足所有前台客户的需求，这同样也意味着前台可以选择不使用中台的某些能力而选择自建。</li></ul></li><li>用户是谁？ 如何划分？<ul><li>中台作为产品需要有自己清晰的用户定位和用户划分，前台作为中台的用户不再是平等的，VIP 前台用户的需求要优于免费前台用户的诉求，通过产品上常见的用户划分来解决需求膨胀、排期、优先级和冲突问题</li></ul></li><li>解决了什么问题？<ul><li>中台作为一个产品，需要想方设法体现自身的价值，真正为前台客户解决实际问题，并关注前台用户体验，通过营销和售前等手段获取前台客户，通过清晰的用户定位和产品力吸引前台客户，让其主动选择采购中台产品</li></ul></li><li>竞争环境？ 团队构成？<ul><li>产品的建设初期，不一定启动资金直接从业务上切分，可能需要类似于天使投资的企业战略投资进行初始孵化，减少中台前期建设的业务交付压力，甚至作为企业的战略级产品，需要一些内部保护和孵化，但仍需要快速验证其价值，获取客户，实现自负盈亏</li></ul></li><li>如何获取用户？营销？售前？</li><li>如何向用户提供服务？<ul><li>产品的建设过程可以借鉴精益创业思路，需要尽快体现其商业价值，如果一定时期内无法获取相应的前台用户（前台不用），或是其他考核指标不达标，则需要进行中台建设止损，类似于创业失败</li><li>甚至在特殊情况下，允许同一类型的中台产品存在合理的内部竞争，同时对两个相似的中台产品进行孵化，使用类似于内部赛马的机制解决内部服务差异性带来的内部产品垄断和定价困难问题</li><li>中台产品为了用户留存，需要对于前台客户提供产品级 SLA，提供客户运营，客户售后服务，保持产品平滑更新，关注用户满意度，实现客户留存与转化</li></ul></li><li>如何验证价值？成本核算？ 定价机制？</li><li>如何保证服务质量？ </li><li>如何升级演进？产品运营？<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1></li></ul></li></ul><ol><li><a href="https://www.infoq.cn/profile/1084916/publish" target="_blank" rel="noopener">https://www.infoq.cn/profile/1084916/publish</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 中台 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Bash 脚本</title>
      <link href="/Bash-%E8%84%9A%E6%9C%AC/"/>
      <url>/Bash-%E8%84%9A%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p>Bash是大多数Linux发行版的默认Shell（命令行环境），值得去研究一波~</p><p>最近也有很多人转而使用zsh，看到一个不错的<a href="https://apple.stackexchange.com/questions/361870/what-are-the-practical-differences-between-bash-and-zsh" target="_blank" rel="noopener">post</a>,讲了二者的主要区别</p><h1 id="1-基本语法"><a href="#1-基本语法" class="headerlink" title="1. 基本语法"></a>1. 基本语法</h1><ul><li><p>echo 在屏幕输出一行文本，可以将该命令的参数原样输出</p><ul><li><code>-n</code> 取消末尾的回车符</li><li><code>-e</code> 解释引号当中的特殊字符，进行转义 </li></ul></li><li><p>命令格式</p><ul><li><code>command [arg1 ... argN]</code></li><li><code>ls -l</code> 等于 <code>ls --list</code><ul><li>其实主要是写script的时候为了让语句自己能够解释自己，会选用长形式，其余时候一般都选用短形式的语句</li></ul></li></ul></li><li><p>分号</p><ul><li>命令的结束符，使得一行可以放置多个命令</li><li>上个命令执行完之后，才会执行下一个命令</li><li>后一个指令总会接着第一个来执行，不管第一个成功或者失败</li></ul></li><li><p>命令组合符</p><ul><li><code>command1 &amp;&amp; command2</code> <ul><li>如果command1成功，才会继续执行command2</li></ul></li><li><code>command1 || command2</code><ul><li>如果command1成功，就不执行command2了</li></ul></li></ul></li><li><p>type命令  – 用于判断命令的来源，是内置的命令或者外部程序</p><ul><li><code>-a</code> 去查看一个命令的所有定义</li><li><code>-t</code> 可以返回一个命令的类型<ul><li>alias</li><li>keyword</li><li>function</li><li>builtin</li><li>file</li></ul></li></ul></li><li><p>快捷键</p><ul><li><code>Ctrl + L</code>：清除屏幕并将当前行移到页面顶部。</li><li><code>Ctrl + C</code>：中止当前正在执行的命令。</li><li><code>Shift + PageUp</code>：向上滚动。</li><li><code>Shift + PageDown</code>：向下滚动。</li><li><code>Ctrl + U</code>：从光标位置删除到行首。</li><li><code>Ctrl + K</code>：从光标位置删除到行尾。</li><li><code>Ctrl + D</code>：关闭 Shell 会话。</li></ul></li></ul><h1 id="2-模式扩展"><a href="#2-模式扩展" class="headerlink" title="2. 模式扩展"></a>2. 模式扩展</h1><p>Shell接到用户输入命令，通过空格进行对输入的分割，拆成词元，然后扩展词元里面的特殊字符，来调用相应的命令。</p><ul><li><p>波浪线扩展</p><ul><li>自动扩展为当前用户的主目录</li></ul></li><li><p><code>？</code>扩展</p><ul><li>？代表文件路径里面的任意单个字符，不包括空字符</li><li><code>file???</code>就表示file后面跟着三个字符的文件名</li></ul></li><li><p><code>*</code>扩展</p><ul><li>代表文件路径里面的任意数量的字符，包括零个字符</li><li>注意不会匹配隐藏文件</li></ul></li><li><p><code>[]</code>扩展</p><ul><li>匹配内部包含的任意一个</li><li><code>[abcde]</code>就会匹配abcde里面的任意一个</li><li><code>[!abc]</code> or <code>[^abc]</code> 表示匹配除了abc以外的其他字符</li></ul></li><li><p><code>[start-end]</code>扩展</p><ul><li>表示匹配一个连续的范围</li><li><code>[a-c]</code>等同于[abc]</li></ul></li><li><p><code>{...}</code>扩展</p><ul><li>指分别扩展为大括号当中定义的所有值</li><li>大括号颞部逗号前后不能有空格</li><li><code>echo d{a,e,i,u,o}g</code><ul><li>output:  dag deg dig dug dog</li></ul></li></ul></li><li><p><code>{start..end}</code>扩展</p><ul><li><code>echo {1..4}</code><ul><li>output: 1 2 3 4</li></ul></li></ul></li><li><p>字符类</p><ul><li><code>[[:class:]]</code> 表示一个字符类，扩展成某一类特定字符之中的一个</li><li><code>[[:alnum:]]</code>：匹配任意英文字母与数字</li><li><code>[[:alpha:]]</code>：匹配任意英文字母</li><li><code>[[:blank:]]</code>：空格和 Tab 键。</li><li><code>[[:cntrl:]]</code>：ASCII 码 0-31 的不可打印字符。</li><li><code>[[:digit:]]</code>：匹配任意数字 0-9。</li><li><code>[[:graph:]]</code>：A-Z、a-z、0-9 和标点符号。</li><li><code>[[:lower:]]</code>：匹配任意小写字母 a-z。</li><li><code>[[:print:]]</code>：ASCII 码 32-127 的可打印字符。</li><li><code>[[:punct:]]</code>：标点符号（除了 A-Z、a-z、0-9 的可打印字符）。</li><li><code>[[:space:]]</code>：空格、Tab、LF（10）、VT（11）、FF（12）、CR（13）。</li><li><code>[[:upper:]]</code>：匹配任意大写字母 A-Z。</li><li><code>[[:xdigit:]]</code>：16进制字符（A-F、a-f、0-9）</li></ul></li><li><p>量词语法</p><ul><li><code>?(pattern-list)</code>：匹配零个或一个模式。</li><li><code>*(pattern-list)</code>：匹配零个或多个模式。</li><li><code>+(pattern-list)</code>：匹配一个或多个模式。</li><li><code>@(pattern-list)</code>：只匹配一个模式。</li><li><code>!(pattern-list)</code>：匹配零个或一个以上的模式，但不匹配单独一个的模式</li></ul></li><li><p>shopt 命令 – 用来调整bach的行为</p><ul><li>-s 打开某个参数</li><li>-u 关闭某个参数</li><li>直接加 optionName  可以来查询某个参数是关闭的还是打开的</li><li>参数<ul><li>dotglob  让扩展结果包括隐藏文件</li><li>nullglob 让通配符不匹配任何文件名，返回空字符</li><li>failglob 使得通配符不匹配任何文件名时，Bash 会直接报错，而不是让各个命令去处理</li><li>extglob 支持ksh的一些扩展语法</li><li>nocaseglob 让通配符扩展不区分大小写</li><li>globstar  是的<code>**</code>可以匹配零个或多个子目录</li></ul></li></ul></li><li><p>tips</p><ul><li>通配符是先解释，再执行</li><li>文件名扩展不匹配的时候，会原样输出</li><li>只适用于单层路径 </li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://wangdoc.com/bash/grammar.html" target="_blank" rel="noopener">https://wangdoc.com/bash/grammar.html</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于时间管理</title>
      <link href="/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/"/>
      <url>/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>最近给自己添了些个人的项目，然后，瞬间感觉到时间不够用。会有忙了一天不知道自己忙什么了的感觉，会有一天被无穷的琐事，被各种问题，沟通占满，然后本来计划做的事情什么都没做的时候。hmm，看了一些博客和书，试着将学到的一些方法用在每天的安排上，发现效果还不错. </p><p>整理了思维导图，和大家分享下。其中对我帮助最大的一条，是关于如何真正的分清楚一件事情的重要程度和紧急程度，不是老板跟你说很重要，PM在屁股后面追着你这件事情就是很重要的。弄清楚他们为什么有这个需求，有没有更加快捷的解决方式更重要。如果更近距离的看，一种理解就是–不是别人用通信软件找你，你就必须当下看当下回，按照自己的工作节奏，保证自己在做的事情没有被打断，这往往是更有效率的方式。</p><p>喜欢书中所说的”做事情靠系统，而不是靠直觉“。希望大家都能建立自己的系统！ </p><p><img src="https://i.loli.net/2020/05/06/rqCPTkEKiV5pYM3.png" alt="时间管理思维导图"></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 时间管理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 多线程 基础知识(二)</title>
      <link href="/Java-%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E4%BA%8C/"/>
      <url>/Java-%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="1-并发容器"><a href="#1-并发容器" class="headerlink" title="1. 并发容器"></a>1. 并发容器</h1><h2 id="1-1-ConcurrentHashMap"><a href="#1-1-ConcurrentHashMap" class="headerlink" title="1.1 ConcurrentHashMap"></a>1.1 ConcurrentHashMap</h2><ul><li><p>HashMap不是线程安全的</p></li><li><p>并发情况下一个可行的方式是使用Collections.synchronizedMap()来包装HashMap。</p><ul><li>但问题在于一个全局的锁同步不同线程之间的并发访问，会带来不可忽视的性能问题</li></ul></li><li><p>故而使用ConcurrentHashMap</p><ul><li>读写都能保证较高的性能</li><li>读操作时几乎不需要加锁</li><li>写操作的时候通过锁分段技术只对所操作的段加锁而不影响客户端对其他段的访问</li></ul></li></ul><ul><li><p>ConcurrentHashMap和HashTable的区别主要体现在实现线程安全的方式上不同</p><ul><li>底层数据结构<ul><li>ConcurrentHashMap使用分段的数组和链表</li><li>Hashtable用数组和链表，数组为主体，链表是为了解决哈希冲突的</li></ul></li><li>线程安全的实现方式<ul><li>使用node数组 + 链表 + 红黑树的数据结构来实现，并发控制使用synchronized和CAS操作</li><li>Hashtable是使用synchronized来保证线程安全的，效率相对较低<h2 id="1-2-CopyOnWriteArrayList"><a href="#1-2-CopyOnWriteArrayList" class="headerlink" title="1.2 CopyOnWriteArrayList"></a>1.2 CopyOnWriteArrayList</h2></li></ul></li></ul></li><li><p>针对现实应用场景当中，读操作远远多于写操作，因为读操作不会修改原有数据，所以就不对读进行加锁操作了。允许多个线程同时访问list的内部数据。</p></li><li><p>ReentranReadWriteLock 读写锁是读读共享、写写互斥、读写互斥、写读互斥</p></li><li><p>而CopyOnWriteArrayList 是读取完全不加锁，写入也不会阻塞读取操作，只有写入和写入之间需要进行同步等待。</p></li></ul><ul><li>如何实现的<ul><li>所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。</li><li>从计算机系统的角度来说，实际上是拷贝内存，在新内存完成写操作，并将原先的内存指针指向新的内存，原有的内存就可以被回收掉了</li></ul></li></ul><pre><code>    /** The array, accessed only via getArray/setArray. */    private transient volatile Object[] array;    public E get(int index) {        return get(getArray(), index);    }    @SuppressWarnings(&quot;unchecked&quot;)    private E get(Object[] a, int index) {        return (E) a[index];    }    final Object[] getArray() {        return array;    }        /**     * Appends the specified element to the end of this list.     *     * @param e element to be appended to this list     * @return {@code true} (as specified by {@link Collection#add})     */    public boolean add(E e) {        final ReentrantLock lock = this.lock;        lock.lock();//加锁        try {            Object[] elements = getArray();            int len = elements.length;            Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝新数组            newElements[len] = e;            setArray(newElements);            return true;        } finally {            lock.unlock();//释放锁        }    }</code></pre><h2 id="1-3-ConcurrentLinkedQueue"><a href="#1-3-ConcurrentLinkedQueue" class="headerlink" title="1.3 ConcurrentLinkedQueue"></a>1.3 ConcurrentLinkedQueue</h2><p>Java 提供的线程安全的 Queue 可以分为阻塞队列和非阻塞队列，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是 ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。</p><p>从名字可以看出，ConcurrentLinkedQueue这个队列使用链表作为其数据结构．ConcurrentLinkedQueue 应该算是在高并发环境中性能最好的队列了。它之所有能有很好的性能，是因为其内部复杂的实现。</p><p>其中主要使用CAS非阻塞算法来实现</p><h1 id="2-乐观锁悲观锁"><a href="#2-乐观锁悲观锁" class="headerlink" title="2. 乐观锁悲观锁"></a>2. 乐观锁悲观锁</h1><p>乐观锁适用于写比较少的情况，即冲突本身发生的可能性就比较低，这样就能省去锁的开销，加大整个系统的吞吐量；但是多写的情况下，会比较容易产生冲突，这样就会导致上层不断进行retry，反倒会降低性能，所以一般多写的场景下用悲观锁比较合适。</p><h2 id="2-1-乐观锁"><a href="#2-1-乐观锁" class="headerlink" title="2.1 乐观锁"></a>2.1 乐观锁</h2><p>总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用<strong>版本号机制</strong>和<strong>CAS算法</strong>实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。</p><p>关于CAS算法，实质上就先拿到指定内存上的数据，（读取操作），线程操作处理数据，在要写入之前，再次查询该内存位置上的数据，如果数据一致，那就可以写入，如果数据不一致，就throw exception，告知系统出现了问题。</p><h3 id="2-1-1-乐观锁实现方式"><a href="#2-1-1-乐观锁实现方式" class="headerlink" title="2.1.1 乐观锁实现方式"></a>2.1.1 乐观锁实现方式</h3><p>乐观锁可以使用版本号机制或者CAS算法来进行实现</p><ul><li><p>版本号机制</p><ul><li>在数据表中加上数据版本号version字段，表示数据被修改的次数</li><li>被修改，version值会+1</li><li>当线程A要更新数据时，读数据的同时也会读取version值，提交更新的时候，若刚才读取到的version值和当前数据库的version值相等才更新，否在重试</li></ul></li><li><p>CAS算法</p><ul><li>compare and swap算法，无锁编程</li><li>不使用锁的情况下实现多线程之间的变量同步，即在没有线程被阻塞的情况下实现变量的同步 – 非阻塞同步 Non=blocking synchronization </li></ul></li></ul><h3 id="2-1-2-缺点"><a href="#2-1-2-缺点" class="headerlink" title="2.1.2 缺点"></a>2.1.2 缺点</h3><ul><li><p>ABA 问题</p><ul><li>一个变量初始值为A，在准备赋值的时候仍为A，但是在这段时间当中它有可能已经被改为了其他的值了，CAS操作会认为它从来没有被修改过</li><li>可以使用AtomicStampedReference类，compareAndSet方法首先检查当前引用是否等于预期引用，以及当前标志是否等于预期标志。如果全部相等，就以原子方式将该引用和该标志的值设置为给定的更新值。</li></ul></li><li><p>循环时间开销大</p><ul><li>自旋CAS如果长时间不成功，会给CPU带来很大的执行开销</li></ul></li><li><p>只能保证一个共享变量的原子操作</p><ul><li>CAS只对单个共享变量有效，当操作涉及多个共享变量的时候CAS无效</li><li>AtomicReference这一类能够保证引用对象之间的原子性，可以将多个变量放在一个对象里进行CAS操作</li></ul></li></ul><h2 id="2-2-悲观锁"><a href="#2-2-悲观锁" class="headerlink" title="2.2 悲观锁"></a>2.2 悲观锁</h2><p>总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。</p><h1 id="3-线程池"><a href="#3-线程池" class="headerlink" title="3. 线程池"></a>3. 线程池</h1><ul><li>线程池用来限制和管理资源，每个线程池还可以维护一些基本统计信息</li><li>好处<ul><li>降低资源消耗<ul><li>重复利用已经创建的线程，来降低线程创建和销毁造成的消耗</li></ul></li><li>提高响应速度<ul><li>当任务到达时，任务可以不需要的等到线程创建就能立即执行</li></ul></li><li>提高线程的可管理性<ul><li>线程是稀缺资源，无限制创建会消耗系统资源，并且降低系统稳定性；使用线程池可以进行统一分配，调优和监控</li></ul></li></ul></li></ul><h2 id="3-1-ThreadPoolExecutor详解"><a href="#3-1-ThreadPoolExecutor详解" class="headerlink" title="3.1 ThreadPoolExecutor详解"></a>3.1 ThreadPoolExecutor详解</h2><pre><code>/** * 用给定的初始参数创建一个新的ThreadPoolExecutor。 */public ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,                          TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          ThreadFactory threadFactory,                          RejectedExecutionHandler handler) {    if (corePoolSize &lt; 0 ||        maximumPoolSize &lt;= 0 ||        maximumPoolSize &lt; corePoolSize ||        keepAliveTime &lt; 0)        throw new IllegalArgumentException();    if (workQueue == null || threadFactory == null || handler == null)        throw new NullPointerException();    this.corePoolSize = corePoolSize;    this.maximumPoolSize = maximumPoolSize;    this.workQueue = workQueue;    this.keepAliveTime = unit.toNanos(keepAliveTime);    this.threadFactory = threadFactory;    this.handler = handler;}</code></pre><ul><li>corePoolSize <ul><li>定义了不会timeout的最小的同时工作的线程数量</li></ul></li><li>maxPoolSize<ul><li>定义了可以被创建的线程的最大数量</li><li>和CorePoolSize的区别在于当提交一个新的任务，当前线程数量小于corePoolSize的时候，哪怕现在存在的线程是空闲的，还是会创建新线程来运行这个任务；maxPoolSize说的是最多能够创建的线程数量，是上限</li></ul></li><li>workQueue<ul><li>当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中</li></ul></li><li>handler 饱和策略 - 当当前同时运行的线程数量达到最大线程数量，并且队列已经被放满了的时候的策略<ul><li>AbortPolicy<ul><li>抛出RejectedExecutionException来拒绝新的任务的处理</li></ul></li><li>CallerRunsPolicy <ul><li>调用执行自己的线程运行任务，会有延迟</li></ul></li><li>DiscardPolicy  <ul><li>不处理新任务，直接丢弃掉</li></ul></li><li>DiscardOldestPolicy <ul><li>丢弃最早的未处理的任务请求</li></ul></li></ul></li></ul><ul><li><p>Executor.execute代码的源码如下： </p><pre><code>  // 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)  private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));  private static int workerCountOf(int c) {      return c &amp; CAPACITY;  }  private final BlockingQueue&lt;Runnable&gt; workQueue;  public void execute(Runnable command) {      // 如果任务为null，则抛出异常。      if (command == null)          throw new NullPointerException();      // ctl 中保存的线程池当前的一些状态信息      int c = ctl.get();      //  下面会涉及到 3 步 操作      // 1.首先判断当前线程池中之行的任务数量是否小于 corePoolSize      // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。      if (workerCountOf(c) &lt; corePoolSize) {          if (addWorker(command, true))              return;          c = ctl.get();      }      // 2.如果当前之行的任务数量大于等于 corePoolSize 的时候就会走到这里      // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以加入任务，该任务才会被加入进去      if (isRunning(c) &amp;&amp; workQueue.offer(command)) {          int recheck = ctl.get();          // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。          if (!isRunning(recheck) &amp;&amp; remove(command))              reject(command);              // 如果当前线程池为空就新创建一个线程并执行。          else if (workerCountOf(recheck) == 0)              addWorker(null, false);      }      //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。      //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。      else if (!addWorker(command, false))          reject(command);  }</code></pre></li></ul><p><img src="https://i.loli.net/2020/05/02/t7yVTDjNZdnEahw.png" alt="execute process"></p><h2 id="3-2-Executor框架"><a href="#3-2-Executor框架" class="headerlink" title="3.2 Executor框架"></a>3.2 Executor框架</h2><p>Java5以后引入的Executor，用其启动线程比使用Thread的start方法更好，易管理，效率高，还可以帮助避免this逃逸的问题。Executor框架提供了：</p><ul><li>线程池管理</li><li>线程工厂</li><li>队列</li><li>拒绝策略</li></ul><h3 id="3-2-1-框架结构"><a href="#3-2-1-框架结构" class="headerlink" title="3.2.1 框架结构"></a>3.2.1 框架结构</h3><ul><li>任务<ul><li>执行任务实现Runnable或者Callable接口，然后被ThreadPoolExecutor或者ScheduledThreadPoolExecutor来执行</li></ul></li><li>任务执行<ul><li>Executor</li></ul></li><li>异步计算的结果<ul><li>Future接口以及Future接口实现类FutureTask都可以来代表异步计算的结果</li></ul></li></ul><p><img src="https://i.loli.net/2020/05/04/pxtNFGULRe3IT6a.png" alt="Exectuor 流程图"></p><p>整个过程中，主线程首先创建并实现了Runnable或者Callable的任务对象，而后将对象交给ExecutorService来执行，然后拿到返回的Future接口，执行FutureTask.get（）等方法来等待任务执行完成</p><h2 id="3-3-常用线程池"><a href="#3-3-常用线程池" class="headerlink" title="3.3 常用线程池"></a>3.3 常用线程池</h2><h3 id="3-3-1-FixedThreadPool"><a href="#3-3-1-FixedThreadPool" class="headerlink" title="3.3.1 FixedThreadPool"></a>3.3.1 FixedThreadPool</h3><ul><li><p>FixedThreadPool</p><ul><li>如果当前运行的线程数小于 corePoolSize， 如果再来新任务的话，就创建新的线程来执行任务；</li><li>当前运行的线程数等于 corePoolSize 后， 如果再来新任务的话，会将任务加入 LinkedBlockingQueue；</li><li>线程池中的线程执行完 手头的任务后，会在循环中反复从 LinkedBlockingQueue 中获取任务来执行；</li></ul></li><li><p>不推荐使用</p><ul><li><p>线程池中的线程数达到 corePoolSize 后，新任务将在无界队列中等待，因此线程池中的线程数不会超过 corePoolSize</p></li><li><p>由于使用无界队列时 maximumPoolSize 将是一个无效参数，因为不可能存在任务队列满的情况。所以，通过创建 FixedThreadPool的源码可以看出创建的 FixedThreadPool 的 corePoolSize 和 maximumPoolSize 被设置为同一个值</p></li><li><p>由于上述两点，keepAliveTime就会是一个无效参数了</p></li><li><p>因为无法执行shutdown() shutdownNow()，不会拒绝任务，在任务比较多的时候会导致OOM(内存溢出的问题)</p><p>public static ExecutorService newFixedThreadPool(int nThreads) {<br>  return new ThreadPoolExecutor(nThreads, nThreads,</p><pre><code>                            0L, TimeUnit.MILLISECONDS,                            new LinkedBlockingQueue&lt;Runnable&gt;());</code></pre><p>}</p></li></ul></li></ul><h3 id="3-3-2-CachedThreadPool"><a href="#3-3-2-CachedThreadPool" class="headerlink" title="3.3.2 CachedThreadPool"></a>3.3.2 CachedThreadPool</h3><p>可以根据需要来创建新线程的线程池</p><pre><code>    /**     * 创建一个线程池，根据需要创建新线程，但会在先前构建的线程可用时重用它。     */    public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                      60L, TimeUnit.SECONDS,                                      new SynchronousQueue&lt;Runnable&gt;(),                                      threadFactory);    }</code></pre><p>注意看源码中，corePoolSize设置为空，maximumPoolSize设置为无界的了，如果主线程提交任务的速度高于maximumPool中线程处理任务的速度，CachedThreadPool会不断创建新的线程，极端情况下，会耗尽CPU和内存资源的。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/Snailclimb/JavaGuide/" target="_blank" rel="noopener">https://github.com/Snailclimb/JavaGuide/</a> </li><li><a href="https://howtodoinjava.com/java/multi-threading/compare-and-swap-cas-algorithm/" target="_blank" rel="noopener">https://howtodoinjava.com/java/multi-threading/compare-and-swap-cas-algorithm/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Multi-threading </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>货币,信贷,债务是如何运作的 from Ray Dalio</title>
      <link href="/%E8%B4%A7%E5%B8%81-%E4%BF%A1%E8%B4%B7-%E5%80%BA%E5%8A%A1%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%90%E4%BD%9C%E7%9A%84-from-Ray-Dalio/"/>
      <url>/%E8%B4%A7%E5%B8%81-%E4%BF%A1%E8%B4%B7-%E5%80%BA%E5%8A%A1%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%90%E4%BD%9C%E7%9A%84-from-Ray-Dalio/</url>
      
        <content type="html"><![CDATA[<p>Ray Dalio在LinkedIn上的长文，主要分析了在长期债务周期当中，货币、信贷、债务之间的相互运作关系，以及它们驱动全球经济和政治变化的方式。</p><h1 id="1-货币和信贷"><a href="#1-货币和信贷" class="headerlink" title="1. 货币和信贷"></a>1. 货币和信贷</h1><p>所有实体（国家、公司、非营利组织和个人）都需处理基本财务，他们的收入和支出构成了净收入，而这些流动是可以用资产负债表中的数字来衡量的。如果一个人赚的比花的多，他就会有利润，从而使他的储蓄增加。而如果一个人的支出大于收入，那么他的储蓄就会减少，或者他不得不通过借钱或来弥补差额。<br>如果一个实体拥有巨额净资产，它的支出将可以高于收入，直到资金耗尽，这时它必须削减开支。如果不削减开支，它将会有大量负债/债务，如果它没有足够的收入来偿还，它就会违约。<br><strong>由于一个人的债务是另一个人的资产，债务违约会减少其他实体的资产，进而要求它们削减开支，从而导致债务下降和经济收缩。</strong></p><p>这种货币和信用体系适用于所有人、公司、非营利组织和政府，但有一个重要的例外。所有国家都可以印钞给人们消费或放贷。然而，<strong>并不是所有政府发行的货币都具有相同的价值</strong>。</p><p>在世界范围内被广泛接受的被称为储备货币。而在当今世界上，占主导地位的储备货币是美元，由美联储发行，占所有国际交易的55%。另一种则是欧元，由欧洲央行发行，占所有国际交易的25%。目前，日元、人民币和英镑都是相对较小的储备货币，尽管人民币的重要性正迅速上升。</p><p>拥有储备货币的国家更容易通过大量借贷摆脱困境。原因在于，世界上其他国家倾向于持有这些债务和货币，因为它们可以用来在世界各地消费。因此，拥有储备货币的国家可以发行大量以储备货币计价的信贷/债务，尤其是在目前这种储备货币短缺的情况下。</p><p>而相比之下，没有储备货币的国家则没有这种选择。它们在以下情况中，特别需要这些储备货币（如美元）：（1）他们有很多以他们不能印刷的储备货币计价的债务（如美元）；（2）他们在这些储备货币上没有多少储蓄；（3）他们获得所需货币的能力下降。当没有储备货币的国家急需储备货币来偿还他们的债务，以储备货币计价和交易的卖家希望它们用储备货币来支付时，它们就只能破产。这就是现在许多国家的情况。</p><p>这也是许多州、地方政府、公司、非营利组织和个人会面临的情况。当它们遭受了收入损失，有没有多少存款来弥补损失时，它们将不得不削减开支或通过其他方式获得资金和信贷。</p><p>这就是现在的世界上正在发生的事情：<strong><em>风险储蓄即将耗尽，以及债务违约的风险。有能力这样做的政府正在印钞，以帮助减轻债务负担，并帮助为以本国货币计价的开支提供资金。但这将削弱本国货币，提高本币的通胀水平，以抵消需求减少和被迫出售资产所造成的通货紧缩，而那些资金紧张的国家就不得不筹集现金</em></strong>。</p><ul><li>Essense<ul><li>一个人的债务是另外一个人的资产，债务违约会减少其他实体的资产，进而要求其消减开支，从而导致债务下降和经济收缩的自我强化。 </li><li>美国最近的大撒钱计划，致使美元指数强势增长，这是市场的避险情绪的体现。美元是全兑换，全流通的。市场的担忧，降息，使得直接持有美元的成本降低了。机构企业采取增加现金流的方式来防止出现流动性危机</li><li>美国政府通过印钞来减轻债务负担，提供商业运作所需的资金。</li></ul></li></ul><h1 id="2-什么是货币"><a href="#2-什么是货币" class="headerlink" title="2. 什么是货币"></a>2. 什么是货币</h1><p>货币本质上是一种交换媒介，也可以用来储存财富。</p><p>不言而喻，“交换媒介”指的是可以用来买东西的工具。而所谓财富储备，指的是在获取和消费之间储存购买力的工具。最合理的方式显然就是把钱存起来，以备不时之需，但人们往往不愿意持有货币，而总想把货币兑换成他们想买的东西。这就是信贷和债务发挥作用的地方。</p><p>当出借人放贷时，他们认为收回的钱会比本身持有的钱购买更多的商品和服务。如果做得好，借贷者就能有效地使用这些钱并获得利润，进而偿还贷款并保留一些额外的钱。当贷款尚未偿还时，它是贷款人的资产，也是借款人的负债。当钱被偿还时，资产和负债就消失了，这种交换对借方和贷方都有好处。他们从本质上分享了这种生产性贷款的利润。整个社会也得益于这种机制所带来的的生产力提高。</p><p>因此，重要的是要意识到：<br>1.大多数货币和信贷（尤其是现存的法定货币）<strong>没有内在价值</strong>；<br>2.它们只是会计系统中的账目，可以很容易地改变；<br>3.系统的目的是<strong>帮助有效地分配资源以便生产力增长</strong>；<br>4.该系统会周期性崩溃。所有的货币不是被摧毁就是贬值，财富随之发生大规模转移，对经济和市场产生巨大影响。</p><p>更具体地说，货币和信贷系统并没有完美地运转，而是<strong>在循环中改变货币的供应、需求和价值，在上升时产生富裕，在下降时产生重组</strong>。</p><h2 id="2-1-从基本面出发研究货币和信贷系统的周期"><a href="#2-1-从基本面出发研究货币和信贷系统的周期" class="headerlink" title="2.1 从基本面出发研究货币和信贷系统的周期"></a>2.1 从基本面出发研究货币和信贷系统的周期</h2><p><strong>虽然金钱和信贷与财富有关，但它们不是财富</strong>。因为钱和信贷可以买到财富（即商品和服务），所以一个人拥有的金钱和信贷的数量和财富的数量看起来差不多。</p><p>但是，一个人不能仅仅通过创造更多的金钱和信贷来创造更多的财富。要创造更多的财富，就必须要有更高的生产力。金钱和信贷的创造与财富（实际商品和服务）的创造之间的关系经常被混淆，但它是经济周期的最大驱动力，因此，让我们更仔细地研究一下这种关系。</p><p>一般来说，货币和信贷的创造与商品、服务和投资资产的数量之间存在正相关关系，因此很容易混淆。当人们有更多的钱和信贷时，他们就会想消费更多。从某种程度上说，消费增加了经济生产，提高了商品、服务和金融资产的价格，这可以说是增加了财富，因为拥有这些资产的人在我们衡量财富的方式下变得“更富有”。</p><p>然而，这种形式的财富增加更像是一种幻觉。原因有二：<strong>推动价格和生产上升的信贷必须偿还；事物的内在价值并不会增加</strong>。</p><p>举个例子，如果你有一套房子，政府创造了大量的货币和信贷，你的房子的价格会上升，但它仍然是原来的样子。你的实际财富没有增加，只是你计算出来的财富增加了。同样地，如果政府创造了大量的货币和信贷，用于购买商品、服务和金融资产（如股票、债券和房地产），那么你计算所得的财富数量就会增加，但实际财富仍将保持不变。换句话说，用一个人所拥有的市场价值来衡量他的财富，会给人一种财富变化的错觉，而这种变化实际上并不存在。</p><p>重要的是，<strong>货币和信贷在发放时具有刺激作用，而在必须偿还时却有抑制作用。</strong>这就是货币、信贷和经济增长如此具有周期性的原因。</p><p>为了控制市场和整体经济，货币和信贷的成本和可获得性各不相同。当经济增长过快，他们想要放缓增长速度时，就会减少货币和信贷投放，导致两者都变得更加昂贵。这鼓励了人们充当贷方而不是借钱和消费。当经济增长太慢，央行想要刺激经济时，他们就会让货币和信贷廉价而充足，从而鼓励人们借贷、投资和/或消费。货币和信贷的成本和可用性的这些变化也会导致商品、服务和金融资产的价格和数量的涨跌。但是，银行只能在其产生货币和信贷增长的能力范围内控制经济，而它们这样做的能力是有限的。</p><p>想象一下，中央银行有一瓶兴奋剂，他们可以根据需要注入经济，而瓶中的兴奋剂数量是有限的。当市场和经济衰退时，他们会提供货币和信贷刺激来提振经济，当市场过热时，他们会减少刺激。这些变动导致货币、信贷、商品、服务和金融资产的数量和价格的周期性涨跌。而这些举措通常以短期债务周期和长期债务周期的形式出现。</p><p>短期债务周期（即通常所说的“商业周期”）通常持续8年左右。时机取决于刺激措施将需求提升至实体经济生产能力极限所需的时间。而长期债务周期就是将这些短期债务周期加起来，通常持续50-75年。因为可能很多人的一生只会出现一次长期债务周期，所以大多数人都没有意识到。</p><p>长期债务周期通常开始于重组后的低水平债务时期，央行的瓶子里有很多刺激，而结束于高水平债务时期，央行的瓶子里就没有多少刺激了。更具体地说，当央行失去通过经济体系产生货币和信贷增长、进而推动实体经济增长的能力时，央行的刺激能力就会终止。当债务水平高企、利率无法充分降低、货币和信贷的创造对金融资产价格的影响大于对实际经济活动的影响时，央行就会丧失这种能力。在这种时候，那些持有债务的人通常想要把他们持有的货币债务换成其他的财富。当人们普遍认为，将获得资金的货币和债务资产并不是良好的财富储备时，长期债务周期就结束了，必须对货币体系进行重组。</p><ul><li>Essense <ul><li>货币和信贷系统在运行过程中，下降周期里会带来重组，会造成财富的巨大转移。</li><li>金钱和信贷不是财富，但可以买到财富。创造更多的金钱和信贷不意味着更多的财富，更多的生产力才是。</li></ul></li></ul><h1 id="3-长期债务周期"><a href="#3-长期债务周期" class="headerlink" title="3. 长期债务周期"></a>3. 长期债务周期</h1><ol><li>始于无或低债务和“硬通货”</li></ol><p>金银（有时还有铜和镍等其他金属）是首选的货币形式，因为它们具有内在价值，而且可以很容易地塑形，便于携带和兑换。具有内在价值很重要，因为与他们进行交易不需要任何的信任或信用。任何交易都可以当场成交，即使买卖双方是陌生人或敌人。</p><ol start="2"><li>“纸币”的诞生</li></ol><p>因为金属货币携带不便的原因，人们很快就把纸上的“货币债权”当成了货币本身。这种类型的货币系统被称为挂钩货币系统，因为货币的价值与某种东西的价值挂钩，通常是“硬通货”，如黄金。</p><p>3.债务增加</p><p>起初，“硬通货”的债权数量与银行里的硬通货数量相同。然而，持有人和银行发现了信贷和债务的奥妙之处：人们可以把“纸币”借给银行，以换取利息；而向他们借钱的银行又可以把钱借给其他人，换取更高的利息；而那些从银行借钱的人获得了前所未有的购买力。这个过程导致了<strong>资产价格和生产的上升</strong>。</p><p>然而，当一个人没有足够的收入/钱来偿还债务时，麻烦就来了。人们期望通过出售这些债权来获得购买商品和服务的资金，其增长速度超过了商品和服务的数量，这使得从这些债务资产（例如债券）的转换变得不可能。这两个问题往往同时出现。<br>关于第一个问题，可以把债务看作是负收益和负资产，负资产吞噬收益（因为收益必须用来偿还债务），吞噬其他资产（因为必须出售其他资产来获得偿还债务的资金）。它具有更高的优先级，意思是它必须在任何其他类型的资产之前得到支付，所以当收入和一个人的资产价值下降时，有必要削减开支和出售资产来筹集所需的现金。当这还不够时，就需要：</p><p>（1）债务重组，减少债务和债务负担。这对债务人和债权人都是有问题的，因为一个人的债务就是另一个人的资产。</p><p>（2）央行印钱、中央政府<strong>发放货币和信贷，以填补收入和资产负债表的漏洞</strong>（这也是现在正在发生的事情）。</p><p>当债务持有者不相信他们将从债务中获得足够的回报时，就会出现第二个问题。债务资产（如债券）是由投资者持有的，他们认为这些资产是可以出售来获得财富（钱）的，而这些钱可以用来买东西。当债务资产的持有者试图将其转换成真实的货币、真实的商品和服务，却发现他们做不到的时候，这个问题就出现了。然后就会发生所谓的“挤兑”。</p><p>无论是商业银行还是央行，都会面临着这样的选择：允许资金从债务资产中流出，从而提高利率，并导致债务和经济问题恶化；或者“印钞”，购买足够的债券，以防止利率上升，并逆转资金耗尽的趋势。</p><p>但如果货币债权和与货币数量和所要购买的商品和服务数量之比过高，银行就会陷入无法摆脱的困境，因为它根本没有足够的钱来满足这些债权，因此它将不得不违约。</p><p>当这种情况发生在央行身上时，它可以选择要么违约，要么印钞并使其贬值。贬值是无法避免的。当这些债务重组和货币贬值规模很大时，它们会导致货币体系崩溃。无论银行或中央银行做什么，债务越多，货币贬值的可能性就越大。记住，商品和服务的数量总是有限的，因为数量受到生产能力的限制。</p><p>在这里，明白金钱和债务的区别是很重要的。</p><p>金钱是用来应对债权的，也就是说，一个人为他的账单付了钱就完了。债务是未来交付金钱的承诺。</p><p>在观察经济机器是如何运作的过程中，重要的是观察a)债务和货币的数量相对于银行中的硬通货（如黄金）的数量，以及b)商品和服务的数量。</p><p>这两者的数量可能会有所不同，但是要记住，债务周期之所以发生，是因为绝大多数人喜欢扩大购买力（一般是通过债务），而中央银行倾向于扩大货币的数量，因为这样做的时候人们会更高兴。</p><p>但这种情况不可能一直持续下去。重要的是要记住，当银行——无论是私有银行还是中央银行——创造了比银行里的硬通货多得多的凭证（纸币和债务）时，终有一天拿来兑换的纸质凭证的数量会超过银行的偿付能力。</p><ol start="4"><li>随之而来的是债务危机、违约和货币贬值</li></ol><p>历史表明，当银行对货币的索取权的增长速度超过银行的货币总量时，“银行挤兑”就发生了。人们可以通过观察银行的资金数量下降，以及由于提款而接近枯竭的程度，准确地判断出什么时候发生了银行挤兑，什么时候银行业危机即将来临。</p><p>如果一家银行无法提供足够的硬通货来满足人们对它的要求，那么无论它是一家商业银行还是一家央行，都会陷入困境，尽管一般而言，央行比商业银行的选择更多一些。这是因为商业银行不能简单地印钞或修改法律以使其更容易地偿还债务，而中央银行可以。当私人银行家陷入困境时，他们要么违约，要么接受政府的救助。如果他们的债务是以本国货币计价的，中央银行可以贬值他们的债权（例如，偿还50-70%）。但如果债务是以他国货币计价的，那么他们最终也势必违约。</p><ol start="5"><li>法定货币</li></ol><p>央行希望拉长货币和信贷周期，使其持续尽可能长的时间，因为这比其他办法要好得多。所以，当 “硬通货”和”对硬通货的追索权”成为他们的严重束缚时，政府通常会放弃它们，转而采用所谓的 “法定”货币。</p><p>在法币体系中不需要硬通货，有的只是中央银行可以无限制”印制”的”纸币”。因此，央行不会面临 “硬通货”被抽干从而违约的风险。</p><p>此时的风险在于，摆脱了对持有有形黄金或其他 “硬”资产的限制，控制印刷厂的人（即与商业银行家一起工作的中央银行家）将不断创造出更多的货币、债务资产和负债，直到有一天，与商品和服务的数量相比，那些持有大量债务的人将试图把它们换成商品和服务时，会产生与银行挤兑一样的效果，导致债务违约或货币贬值。</p><p>这种转变：从a)债务追索权可按固定比例兑换成有形资产(如黄金)的体系转变为b)不在存在这种兑换的法币体系，最近一次发生是在1971年。</p><p>当年8月15日晚上，尼克松告诉全世界，美元将不再与黄金挂钩，我在电视上看到这些，心想，”我的天，我们所熟悉的货币体系就要结束了，”事实的确如此。</p><p>我当时在纽约证券交易所做职员，那个周一早上，我本来以为股票会下跌，从而出现大乱，结果发现股票上涨而导致大乱。</p><p>因为我从来没有见过贬值，不明白它们是如何运作的。然后我查了一下历史，发现在罗斯福发表类似讲话的那个3月5日星期天晚上，他也做了基本相同的事情，在接下来的几个月里，结果基本相同（货币贬值，股市大涨，金价大涨）。这种情况后来我看到很多国家发生过多次，包括国家元首们发表的基本相同的宣言。</p><p>在1971年之前的几年里，美国政府花了很多钱在军事和社会项目上，当时这被称为 “枪支和黄油”政策，它通过借钱来完成支付，而这些钱就产生了债务。</p><p>这些债务就是他人对货币的追索权，而这些追索权就可以用来换取黄金。投资者购买这些债务作为资产，因为他们得到了这笔政府债务的利息，而且美国政府承诺允许这些票据的持有者用这些票据换取美国金库中的黄金。</p><p>随着美国的支出和预算赤字的增长，美国不得不发行更多的债务，也就是说，创造了更多的黄金债权，但银行里的黄金数量却没有增加。</p><p>自然而然，用这种追索权换取黄金的投资者越来越多。明眼人都能看出美国的黄金已经快用完了，而未偿付的黄金债权数量远远大于银行里的黄金数量，所以他们意识到如果这样下去，美国就会违约。</p><p>当然，在那个时候，很多人看到了美国政府表面上的富有，认为它是不可能在偿付黄金债权上违约的。因此，大多数人对这一宣布以及对市场的影响感到惊讶，不过那些了解货币和信贷运作机制的人却不以为然。</p><p>当信贷周期达到极限时，中央政府及其央行的经典反应是创造大量的债务，并印钞，把钱花在商品、服务和投资资产上，以维持经济的发展。</p><p>这就是2008年债务危机期间的做法，当时利率已经达到0%，无法再降低。正如前文所解释的那样，这也是为了应对1929-32年的债务危机而做的，当时利率已经跌到0%。这种债务和货币的创造，现在出现的数额比二战以来的任何时候都要大。</p><p>说白了，央行 “印钱 “并将其用于支出，而不是用债务增长来支持支出，这并非没有好处。例如，钱可以像信贷一样用于消费，但实际上（而不是理论上）不需要偿还。换句话说，只要货币增长而不是信贷/债务增长，只要把钱用在生产性的用途上，就没有错。</p><p>不过采取印钱手段而不是促进信贷增长的主要风险在于：a)市场参与者不会仔细分析这些钱是否用于生产性用途；b)它省去了让还钱的必要性。</p><p>这两点都会增加激进印钱的概率，而且这些钱也不一定用于生产，所以人们就会停止把钱作为财富储藏手段，并将财富转移到其他东西上。</p><p>纵观历史，当硬通货（债务和货币凭证）的未偿还债权远远大于硬通货和商品和服务的数量时，总会发生大量违约或大量印钞和贬值。</p><p>历史已经告诉我们，我们不应该依赖政府在经济上保护我们。相反，我们应该知道，大多数政府会滥用他们作为货币和信贷的创造者和使用者的特权地位。假设你站在他们的立场上，你可能会做出一样的举动。</p><p>这是因为没有一个政策制定者能够驾驭整个周期。每一个人都是周期的某个阶段参与进来，他们只能根据当时的情况，做着对他们有利的事情。</p><p>因为在债务周期的早期，政府是值得信赖的，他们和其他人一样需要钱，甚至比其他人更需要钱，所以他们通常是最大的借款人。</p><p>而在周期的后期，当后续领导人上台执掌政府时，会面临更多债务。这时新的政府领导人和新的央行决策者们就要面对更大的挑战，此时一方面他们的刺激手段较少，同时还要必须偿还债务。</p><p>更为糟糕的是，政府还必须救助债务人，因为他们的倒下又会伤害到整个系统。因此，他们往往会陷入比个人、公司和大多数其他实体更大的现金流困境。</p><p>换句话说，在几乎所有情况下，政府在行动上助长了债务的积累，成为大的债务人，当债务泡沫破灭时，政府通过印钞和贬值来拯救自己和他人。债务危机越大，就越是如此。</p><p>虽然不可取，但出现这种情况也是可以理解的。当你可以制造货币和信贷，并把它传给每个人，让他们高兴的时候，你很难抵挡住诱惑。”这是典型的金融举动。纵观历史上的统治者，他们都会累积起大量在其统治期结束后很久才会到期的债务，让他们的继任者来收拾残局。</p><p>当政府出现债务问题时，他们会如何应对？</p><p>他们会和任何一个实际债务负担沉重的实体一样，用印钞来解决。无一例外，如果债务是以自己的货币计价，他们就会印钱让货币贬值。</p><p>当央行印钱买入债务，这就把钱放进了金融系统，并使金融资产的价格竞相上涨（这也扩大了贫富差距，因为它让那些拥有金融资产的人相对于没有金融资产的人受益更多）。</p><p>同时，它还把大量的债务掌握在央行手中，让央行可以随心所欲地处理这些债务。而且他们印钱和买入金融资产（主要是债券），也就把利率压低了，这就刺激了借钱和买入，并鼓励那些持有这些债券的人卖出债券，鼓励他们以低利率借钱，把钱投资于回报率较高的资产，这就导致央行印更多的钱，买入更多的债券，有时也买入其他金融资产。</p><p>这通常能很好地推高金融资产价格，但在把钱和信贷以及购买力送到最需要的人手中时，效率就很低了。这就是2008年发生的情况，在那之后的大部分时间里，直到最近也是如此。</p><p>然后，当印钞和央行买入金融资产无法把钱和信贷送到需要的地方时，中央政府——它可以决定把钱花在什么地方——从央行（印钞票的央行）那里借钱，这样它就可以把钱花在需要花的地方。在美国，美联储在2020年4月9日宣布了这一计划。</p><p>这种通过印钱买债（称为债务货币化）的方式，作为一种获取金钱和将财富从拥有金钱的人手中转移到需要金钱的人手中的方式，比起征税导致纳税人不满，在政治上要好得多。这就是为什么央行总是印钞票、让货币贬值的原因。</p><p>当政府印了很多钱，买了很多债，这样钱和债的数量都增加了，钱和债的价格就会便宜，这实质上是向拥有这些钱和债的人征税。</p><p>当这种情况发生得足够多，让这些钱和债务资产的持有者意识到发生了什么，他们就会寻求出售他们的债务资产和借钱，以获得他们可以用低廉资金来偿还的债务。</p><p>他们还经常将财富转移到其他的财富存储工具中，如黄金、某些类型的股票和其他地方（如另一个没有这些问题的国家）。在这种时候，央行通常会继续印钱，直接或间接地购买债务（例如，让银行代为购买），并禁止货币流向可以对冲通胀的资产和其他货币及场所。</p><p>这样的通胀期要么刺激货币和信贷扩张，为另一次经济扩张提供资金（这对股票有好处），要么使货币贬值，从而产生货币通胀（这对黄金等通胀对冲资产有好处）。</p><p>在长期债务周期较早的时候，当未偿债务数额不大，有很大的空间通过降息来刺激（如果不降息，就印钱和买入金融资产），那么信贷增长和经济增长的可能性就越大。</p><p>而在长期债务周期较晚的时候，当债务数额较大，没有太多空间通过降息（或印钱和买入金融资产）来刺激，那么伴随着经济疲软而出现货币通胀的可能性就越大。</p><ol start="6"><li>重回硬通货</li></ol><p>过度印制法币会导致债务资产的抛售，以及之前描述的类似银行”挤兑”的情况，最终会降低货币和信贷的价值，促使人们逃离货币和债务（如债券）。他们也就需要决定将使用何种替代性的财富存储方式。</p><p>历史经验告诉我们，他们通常会转向黄金、其他货币、其他国家没有这些问题的资产，以及能够保留其实际价值的股票。</p><p>有些人认为，世界需要另一种可供选择的储备货币，但事实并非如此，因为在没有可供选择的货币的情况下，从历史上看，货币体系崩溃和财富涌向其他资产，也同样会发生。</p><p>货币自身价值的减弱，会导致货币贬值，人们也会抛弃这种货币，并将资产投入其他地方。历史上，当货币贬值的时候，人们会奔向大量其他东西，甚至包括德国魏玛共和国的石头（用于建筑）。</p><p>通常情况下，在这个阶段的债务周期中，也会出现贫富差距过大造成的经济压力，这就导致了更高的税收和贫富之间的争斗，也使得那些拥有财富的人想要转移到硬资产和其他货币和其他国家。</p><p>很自然的，国家会阻止这种外逃。所以，在这种时候，政府就会加大对黄金（例如，通过取缔黄金的交易和所有权）、外国货币（通过取消其交易能力）、外国资产（通过建立外汇管制来防止资金流出国境）的投资难度。</p><p>最终，债务基本上被消灭，通常是通过让还债的钱既多又便宜，使货币和债务都贬值。</p><p>当这种情况变得极端，以至于货币和信贷体系崩溃，债务贬值和/或违约出现时，政府通常不得不回到某种形式的硬通货，以重建人们对货币作为财富存储的价值的信心，从而恢复信贷增长。</p><p>很多时候，尽管并非总是如此，但政府往往会将其货币与某种硬通货（如黄金或硬储备货币）挂钩，并承诺允许新货币的持有者将其兑换成硬通货。</p><p>有时，这些硬通货可能是另一个国家的硬通货。例如，在过去几十年里，许多弱货币国家将其货币与美元挂钩，或者干脆将其经济美元化（即，将美元作为自己的交易媒介和财富储存手段）。</p><p>回顾一下，在长期的债务周期中，将债务作为一种提供利息的资产持有，在周期初期没有大量债务未还的时候，通常会有回报。但这在周期后期有大量债务未还，且更接近于违约或贬值的时候，相对于给出的利息而言，持有债务是有风险的。</p><p>所以，持有债务（如债券）有点像持有一个定时炸弹，在它还在滴答的时候给你奖励，但一旦爆炸也会将你炸飞。而正如我们所看到的，大爆炸（即大违约或大贬值）大概每50-75年就会发生一次。</p><p>这些债务周期和注销债务的周期已经存在了几千年，在某些情况下已经制度化了。知道债务周期会在这个时间表上发生，会让每个人都能以理性的方式行事，为之做准备。帮助你了解这个情况，让你做好准备，而不是被它吓到，这是我写这篇文章的主要目的。</p><p>因为大多数人对这个周期与他们所经历的事情并不太注意，讽刺的是，越是接近被炸的人往往越是觉得安全。</p><p>那是因为他们一直持有债务，并享受着这样做的回报，而且从上一次爆仓的时间越长，随着上一次爆仓的记忆消退，他们就越是舒服——即使持有这笔债务的风险上升，而回报下降。</p><p>盯住需要偿还的债务相对于硬通货的数量，需要偿还的债务总量相对于债务人的现金流，以及借出资金的利息回报，就可以评估持有这颗定时炸弹的风险/回报。</p><h1 id="4-长期债务周期总结"><a href="#4-长期债务周期总结" class="headerlink" title="4. 长期债务周期总结"></a>4. 长期债务周期总结</h1><p>几千年来，货币制度一直有三种类型：</p><ul><li>硬通货（如金属硬币）</li><li>以“纸币”形式存在的对硬通货的的追索权</li><li>法定货币（如今天的美元）</li></ul><p>硬通货是最具限制性的货币体系，因为除非增加金属或其他具有内在价值的商品（即货币）的供应量，否则就无法创造货币。第二种类型更容易创造货币和信贷，因此硬通货债权与实际持有的硬通货之间的比率上升，最终导致银行挤兑。</p><p>结果有二：一是违约，银行关门且储户失去硬资产；二是有可能跟前者一起发生的债权货币贬值，这意味着储户拿回来的钱变少了。而在第三种类型中，政府可以自由地创造货币和信贷。只要人们对货币有信心，这种做法就持续有效，反之则无效。</p><p>纵观历史，各国在这些不同类型的制度之间过渡，都有合乎逻辑的原因。当一个国家需要的货币和信贷比现有数量更多时，无论是出于应对债务、战争还是其他原因，它自然会从第一种类型过渡到第二种类型，或从第二种类型过渡到第三种类型，这样它就有了更多的印钞灵活性。</p><p>此后，过多的货币供应和债务带来了货币贬值，致使人们不再持有债务和货币作为财富储备，转而回流到硬资产（如黄金）和其他货币中。鉴于这种情况一般发生在产生财富冲突或战争时期，人们通常也会想逃离此地。这类国家需要重新建立起以货币作为财富储备的信心，才能恢复信贷市场。</p><p>下图表达了上述不同的过渡历程。从宋朝到魏玛德国，历史上有很多这样的例子。有很多国家从约束型货币（第一类和第二类）全面过渡到法币，然后随着旧的法币超发，又回到约束型货币。</p><p><img src="https://i.loli.net/2020/05/03/sQkeWX7tDlzEGFn.png" alt="过渡历程"></p><p>如前所述，这个巨大的债务周期将会持续很长一段时间——大约50到75年。在周期结束时，其特征是债务和货币体系的重组。重组的突然之处在于，比如在债务和货币危机时期，重组通常发生得很快，且仅持续数月至三年，具体时间取决于政府采取这些措施所需的时间。然而，此后涟漪效应可能是长期的。</p><p>例如，这样的情况会导致储备货币不再是储备货币。在这些货币制度中，通常会有两到四次大的债务危机，大到足以导致银行业危机和债务减记或贬值30%以上的那种，但这还不足以打破货币体系。</p><p>我在许多国家投资了大约50年，经历了几十次债务危机。它们的运行方式都是一样的，我在《Principles for Navigating Big Debt Crises》一书中曾对此进行了更深入的解释。</p><h1 id="5-拥有储备货币给一个国家带来的不可思议的力量"><a href="#5-拥有储备货币给一个国家带来的不可思议的力量" class="headerlink" title="5. 拥有储备货币给一个国家带来的不可思议的力量"></a>5. 拥有储备货币给一个国家带来的不可思议的力量</h1><p>储备货币是一种在世界范围内被广泛用作交换媒介和财富储备的货币。使用越广泛、对其的依赖程度越深，储备货币和拥有储备货币的国家的实力也就越强。在此，我冒着重复一些之前讲过的东西并让你们觉得无聊的风险来回顾一下美国的情况，以及致使美国和美元让世界变成现在这样的环境情况。</p><p>如前文所述，世界新秩序始于1945年第二次世界大战结束之后，而布雷顿森林协定在1944年确立了美元作为世界主要储备货币的地位。</p><p>美国和美元自然而然地符合这一角色，因为战争结束时，美国政府持有全球约三分之二的黄金（当时是世界货币），美国占世界经济产出的50%，还在军事上占主导地位。新的货币制度属于第二类（即硬通货的债权），其他国家的央行可以35美元/盎司的价格将“纸质美元”兑换成黄金。</p><p>当时，个人持有黄金属于非法，其原因在于政府领导人不想让黄金作为财富储备来与货币和信贷竞争。所以，在那个时候，黄金就是银行里的钱，而纸币就像支票簿里的支票一样，可以兑换成真金白银。</p><p>在这个全新货币体系建立的时候，美国政府每持有一盎司黄金就拥有50美元的纸币，所以几乎100%有黄金做后盾。其他主要的美国盟国（如英国、法国和英联邦国家）或受美国控制的国家（德国、日本和意大利）都有受美国控制的货币与美元挂钩。</p><p>在此后的几年里，为了给自己的活动提供资金，美国政府的支出超过了税收收入，因此不得不借钱，从而产生了更多以美元计价的债务。美联储所允许建立的黄金债权数量（如美元计价的货币和信贷），远远超过了能以35美元价格兑换成的黄金实际数量。在纸币被兑换成硬通货（黄金）之后，美国银行之中的黄金数量随之下降，黄金债权则继续上升。其结果就是，在1971年8月15日，布雷顿森林货币体系崩溃了。</p><p>当时，时任美国总统尼克松和1933年3月5日的罗斯福一样，未能履行当局承诺，即允许美元持有者将其兑换成黄金。于是，美元对黄金和和其他货币贬值。这时，美国和所有国家都进入了第三种类型，法币体系。如果你想读一读有关如何从旧货币体系到新货币体系的精彩过程，我推荐保罗·沃尔克的《Changing Fortunes》，在谈判美国新货币体系应该运作时，他是首席谈判代表。</p><p>这种向法币体系的转变使美联储和其他中央银行得以创造大量以美元计价的货币和信贷，从而导致了1970年代的通货膨胀，其特点是从美元和美元债逃向商品、服务以及黄金等可以对冲通胀的资产。这种对美元债的恐慌情绪还导致了利率走高，并将金价从1944年至1971年期间固定的35美元推至当时的历史高位——1980年的670美元。</p><p>20世纪70年代，货币和信贷主要通过上述方式管理。这时，借入美元并将其转换为商品和服务是有利可图的，所以许多国家的许多实体都大量通过美国银行借入美元。结果，以美元计价的债务在全球范围内迅速增长，而美国银行通过把美元放给借款人来赚了很多钱。</p><p>这种贷款导致了债务周期中经典的债务泡沫。恐慌情绪让人逃离美元和美元债资产并转向通胀对冲资产，快速借入美元和背负债务的速度也在加快。这就造成了1979-1982年期间的货币和信贷危机。</p><p>在那期间，美元和美元债面临着不再担任公认财富储备的风险。当然，普通老百姓并不了解这种货币和信贷的动态是如何运作的，但他们以高通胀和高利率的形式感受到了它，这就成了一个巨大的政治问题。时任总统卡特和大多数政治领导人一样并不太了解货币机制，但他知道必须做点什么来阻止危机，于是任命了一位强有力的货币政策制定者——保罗·沃尔克。</p><p>几乎所有关注危机的人，包括我在内，都会注意听他说的每一句话。他足够强大，能够做一些令人痛苦但正确的事情来打破通货膨胀。他成为了我的英雄，最终还因其很棒的性格和出色的能力，成为了我的好朋友，我也喜欢他冷嘲式的幽默。 </p><p>德国前总理赫尔穆特·施密特认为，为了应对这场货币通胀危机并打破通货膨胀，沃尔克收紧了货币供应，将利率推到了”自耶稣基督诞生以来”的最高水平。</p><p>债务人就不得不在收入和资产贬值的同时，支付更多的偿债款。由此，债务人受到压榨，被逼出售资产。由于美元需求巨大，美元走强。基于这些原因，通货膨胀下降，美联储随之降低利率，放松了美国人的货币和信贷。</p><p>当然，许多债务人和贬值资产持有人都破产了。因此，在80年代，这些债务人，尤其是外国债务人，更尤其是新兴国家的债务人，经历了长达十年的经济萧条和债务重组时期。美联储通过向美国银行提供所需的资金来保护他们，而美国的会计制度则不要求银行将这些坏账作为损失来核算，或无需按照实际价格来对这些债务资产进行估值，从而保护美国银行免于破产。</p><p>这一债务管理和重组过程一直持续到1991年，最后以迎来用时任美国财政部长尼古拉斯·布雷迪名字命名的”布雷迪债券协议”而告终。1971-1991年整个周期几乎影响了世界上所有的人，这是美国脱离金本位的结果。</p><p>它导致了70年代的通胀和通胀对冲资产的飙升，随后又带来1979-1981年的紧缩、非美债务人大量的通缩债务重组、通胀率下降，以及1980年代债券和其他通缩资产的出色表现。这整个时期都有力地证明了拥有世界储备货币的美国具有怎样的力量，以及储备货币管理方式对世界各国的影响。</p><p>从1979-1981年期间以美元计价的通货膨胀率和利率双双达到峰值到现在，通胀和利率都降到了接近0%。你可以清楚地看到，自新的美元计价货币体系建立以来，利率和通胀整个大型周期的起起伏伏。</p><p><img src="https://i.loli.net/2020/05/03/QOHUyPVpERgM2AD.jpg" alt="通胀及利率的起伏"></p><p>在整个这段时间里，世界上以美元计价的货币、信贷和债务以及其他非债务性负债（如养老金和医保等）相对于收入而言持续上升。因为美联储有独特的能力来支撑这种债务增长，上述情况在美国尤为明显。</p><p>20世纪80年代债务重组完成后，全球货币、信贷和债务的全新增长又在90年代开始了。这再次带来了经济繁荣，并且导致投资者举债进行投机性投资，最终形成在2000年破裂的科网泡沫。</p><p>泡沫的破裂引出了2000-2001年的经济衰退，并刺激美联储放宽货币和信贷，将债务水平推到了新的高点。接下来，又一次的经济繁荣到来，另一个更大的债务泡沫在2007年诞生，于2008年破裂。</p><p>于是美联储和其他储备货币国家的央行再次宽松，又带来了近期刚刚破裂的下一个泡沫。然而，这一次创造应对经济衰退所需货币和信贷的方式却被设计得十分不同。</p><p>短期利率在2008年达到0%，而这个降息的幅度尚无法满足货币和信贷扩张的需要。通过降息刺激货币和信贷增长是央行的首选货币政策。我称其为”货币政策1”。随着这种方法不再适用于中央银行，他们就转向了第二选择（我称之为”货币政策2”），即印钞和购买以国债、优质债务为主的金融资产。</p><p>央行上一次需要这样做，是因为利率从1933年开始触及0%，且在战争年代也一直保持零利率。这种做法被称为”量化宽松”而不是”债务货币化”，是因为QE听起来没有那么大的威胁性。世界上所有的主要储备货币央行都已经这么做了。</p><p>这就带来了下一个货币/信贷/经济范式，直到我们现在经历的经济衰退之前，这一范式一直在持续。</p><p>自2008年开始的这一范式是这样的。</p><p>正如从1933年开始所做的那样，央行通过印钞和购买债券维持了货币和债务扩张周期。</p><p>通过购买债券，央行推高了债券价格，并为这些债券的卖家提供现金，致使他们去购买其他资产。这就推高了其他资产的价格，而随着这些资产价格上涨，未来的预期回报率随之下降。</p><p>由于利率低于其他投资的预期回报率，而相对于投资者为其各种支出义务提供资金所需的回报率而言，债券收益率和其他未来预期回报率的水平都很低，因此，投资者越来越频繁地借钱购买他们认为收益将高于借贷成本的资产。</p><p>这既推高了上述资产的价格，又造成了新的债务泡沫脆弱性——如果他们所购资产收益低于其借贷成本，就会产生新的债务泡沫。由于长期和短期利率都在0%左右，而且央行购买债券的资金无法刺激经济增长和帮助那些最需要帮助的人，所以我觉得第二种货币政策显然不能很好地发挥作用，这就需要第三种货币政策——“货币政策3”。</p><p>“货币政策3”的工作原理是，储备货币中央政府增加借贷，并将其支出和贷款的目标定在他们想要的地方，而储备货币中央银行则创造货币和信贷，并购买债务（可能还有其他资产，如股票）来提供资金。虽然我不会在这里解释各种方法，但在我的书《Principles for Navigating Big Debt Crises》当中已经解释过了。</p><p>因此，在疫情引发经济衰退之前，我们就已经做好了准备：一旦经济滑入衰退，就必须走这条路。如果你想要看我更为深入地研究相关话题的文章，可以点击economicprinciples.org。</p><p>无论如何，在这段时期内，债务和非债务性负债（如养老金和医保）相对于收入而言继续上升，而中央银行设法压低了偿债成本（详见我的报告”The Big Picture”，里面对此举所导致的、即将到来的“挤兑”解释得更完整）。</p><p>这就把利率推向了零，并使债务长期化，从而使本金偿付水平降低。诸如中央银行拥有大量的债务、利率在0%左右因此不需要支付利息、构建可以长期偿还的债务并使本金可以分散偿还甚至不用偿还之类的条件，意味着中央银行创造货币和信贷的能力几乎没有限制。这一系列的条件为接下来的事情奠定了基础。</p><p>新冠疫情引发了世界各地的经济和市场衰退，造成了收入和资产负债表方面的窟窿，特别是对那些收入受到衰退影响的负债实体来说，更是如此。</p><p>传统上，中央政府和央行必须创造货币和信贷，才能把钱和信贷送到他们想救的实体手中。如果没有这些钱和信贷，这些实体在财务上是无法生存的。</p><p>由此，2020年4月9日，美国中央政府（总统和国会）和美国央行（美联储）宣布了一项大规模的货币和信用创造计划，采用了“货币政策3”之中所有经典的手法，包括直升机撒钱（政府直接给公民发钱）。</p><p>这基本上与罗斯福在1933年3月5日宣布的计划是一样的。虽然是疫情引发了这次特殊的金融和经济衰退，但就算没有疫情，其他东西最终也会触发衰退。</p><p>无论衰退的起因是什么，但动力基本上都是一样的，因为只有“货币政策3”才会起到扭转经济衰退的作用。欧洲央行、日本央行以及中国人民银行也都采取了类似措施，不过最重要的仍是美联储的举动，因为它是美元的创造者，而美元仍然是世界上占主导地位的货币和信贷。</p><p>目前，美元在全球的国际交易、储蓄、借贷中约占55%。欧元区的欧元约占25%。日元占比不到10%。中国的人民币占2%左右。其他大多数货币都没有在国际上用作交换媒介和财富储存手段，仅在各国国内使用。</p><p>无论是上述各国国内的聪明人，还是这些国家以外的几乎所有人，都不会持有这部分货币并将其作为财富储备。相比之下，我提到的储备货币，就是全世界大多数人喜欢储蓄、借贷、交易的货币，大致比例和我上文所说的相同。</p><p>拥有世界储备货币的国家拥有惊人的力量——储备货币可能是最重要的力量，重要程度甚至超过军事力量。</p><p>这是因为当一个国家拥有储备货币时，它可以在合适的时候像美国现在这样印钱、借钱来消费，而那些没有储备货币的国家则必须先获得他们所需要的钱和信贷（以世界储备货币计价）才能进行交易和储蓄。</p><p>比如说现在，截止发稿，那些有很多债务需要偿还的人对美元的需求很强，因其需要更多的美元来购买商品和服务，但他们的美元收入已经下降。</p><p>正如章节一中表明衡量一国国力上升和下降的八项指标的图表所示，储备货币实力（以该货币的交易和储蓄份额来衡量）明显落后于衡量国家实力的其他指标。美国和美元的情况也是如此。</p><p>例如，在1944年，当美元被选定为全球主要储备货币时，美国政府持有的黄金占全球黄金总量的约三分之二（黄金当时被视为货币），美国经济则约占全球GDP的一半。</p><p>如今，美国GDP只占全球的20%左右，但美元仍占全球外汇储备的60%左右，还占有国际交易量的半壁江山。所以，美元和以美元为基础的货币和支付体系仍然占据着至高无上的地位，相对于美国经济的规模而言，它的规模还是特大号。</p><p>和所有印制储备货币的银行一样，美联储现在处于强势但尴尬的地位。其货币政策的运行方式对美国人有利，但对世界上其他依赖美元的国家来说，可能并不是好事。</p><p>比如美国中央政府最近刚刚决定，将借贷给美国人发放美元和美元信贷，美联储则决定购买美国政府的那笔国债和美国人其他的债务，帮助他们度过这次金融危机。可以理解的是，这些钱几乎没有多少会流向外国人。</p><p>欧洲央行也将对欧元区国家采取类似措施。世界影响力仍旧较小的日本央行也会为日本人做同样的事情，中国人民银行同样会为中国人做类似的事情。</p><p>其他几个相对较小的国家（如瑞士）也许可以为本国人民做类似的事情，但世界上大多数人无法像美国人那样，得到他们所需要的钱和信贷来填补收入和资产负债表的窟窿。</p><p>这一动态，即国家无法获得他们所需要的硬通货就像1982-1991年期间发生的事情一样，只是这次无法再靠大幅削减利率解决问题，而那个时候可以。</p><p>与此同时，非美国人（即新兴市场、欧洲国家和中国）持有的美元债总额约为20万亿美元（比2008年时高50%左右），其中短期债务不到一半。这些美元债务人将不得不拿出美元来偿还这些债务，还要拿出更多的美元来在世界市场上购买商品和服务。</p><p>所以，通过拥有美元作为世界储备货币并拥有生产这种货币的银行，且拥有把这些急需的美元放入美国人手中的实力，美国就可以比其他国家的政府更有效地帮助本国公民。</p><p>同时，美国也有可能会因为制造了太多的货币和债务而失去这种特权地位。在本章的附录中，我们将更深入地研究曾经拥有储备货币的国家是如何失去储备货币的，以及货币贬值是如何运作的。</p><h1 id="6-Summary"><a href="#6-Summary" class="headerlink" title="6. Summary"></a>6. Summary</h1><p>回过头来从大格局的角度看这一切，我想谈论的关系包括1）经济之间（即货币、信贷、债务、经济活动和财富）和2）政治之间（国家内部和各国之间），具体起起落落如下图所示。</p><p><img src="https://i.loli.net/2020/05/03/YEnmcZpRXAota3T.png" alt="债务周期"></p><p>通常情况下，大的周期始于一个全新的世界秩序，即一种囊括全新货币体系和政治制度、包含国内和国际运作的一种全新方式。最近的一次大周期始于1945年。</p><p>因为在那样的时期，冲突之后出现了具有主导力量的大国，大家都不愿意打仗，人们也厌倦了战斗，于是就有了和平重建和日益繁荣的局面，而这种繁荣是由可持续的信贷扩张来支撑的。</p><p>之所以说是可持续的，是因为收入的增长超过或跟上了偿还不断增长的债务所需的偿债支出，也是因为央行有能力刺激信贷，经济增速也很强劲。一路走来，过程中会出现短期的债务和经济周期，我们称之为衰退和扩张。</p><p>随着时间的推移，投资者以过去的收益推断未来，并借钱来押注收益可以实现。这就在贫富差距扩大（有些人的收益比其他人更多）的同时产生了债务泡沫。这种情况将一直持续下去，直到各国央行耗尽一切有效刺激信贷和经济增长的能力。</p><p>随着货币紧缩，债务泡沫破裂，信贷收缩，经济也随之萎缩。同时，当出现巨大的贫富差距、严重的债务问题且经济萎缩时，国家内部和国家之间往往会发生争夺财富和权力的斗争。</p><p>在债务和经济出现问题的时候，中央政府和中央银行通常会发行货币和信贷，并有可能使本币贬值。这些事态发展导致了债务、货币体系、国内秩序和世界秩序的重组。然后，事情又开始了。</p><p>虽然没有一个周期完全符合描述，但几乎所有周期都与之相差无几。比如说，虽然债务泡沫破裂一般会导致经济萎缩，经济萎缩叠加巨大的贫富差距通常会导致内斗和外斗，但有时顺序有些不同。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.thepaper.cn/newsDetail_forward_7147656" target="_blank" rel="noopener">https://www.thepaper.cn/newsDetail_forward_7147656</a></li><li><a href="https://www.linkedin.com/in/raydalio/detail/recent-activity/" target="_blank" rel="noopener">https://www.linkedin.com/in/raydalio/detail/recent-activity/</a></li><li><a href="https://m.chinanews.com/wap/detail/zw/cj/2020/03-19/9131125.shtml" target="_blank" rel="noopener">https://m.chinanews.com/wap/detail/zw/cj/2020/03-19/9131125.shtml</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Economy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 多线程 基础知识(一)</title>
      <link href="/Java-%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
      <url>/Java-%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h1 id="1-多线程知识基础"><a href="#1-多线程知识基础" class="headerlink" title="1. 多线程知识基础"></a>1. 多线程知识基础</h1><h2 id="1-1-线程-vs-进程"><a href="#1-1-线程-vs-进程" class="headerlink" title="1.1 线程 vs 进程"></a>1.1 线程 vs 进程</h2><p>进程是程序的一次执行过程，java当中，启动main函数就是启动了一个JVM进程，main函数所在的线程是其中之一，也称为主线程。</p><p>线程是比进程更小的执行单位，一个进程执行过程当中可以产生多个线程。同类的多个线程互相之间共享进程的堆和方法区的资源。每个线程有自己的程序计数器，虚拟机栈，和本地方法栈</p><p>线程与进程之间的关系如下图所示</p><p><img src="https://i.loli.net/2020/04/30/3AwhmaPDLkcXKMb.png" alt="线程进程关系.png"> </p><p>运行时堆和方法区，还有常量是共享的。</p><p><strong>线程私有的</strong></p><ul><li>程序计数器<ul><li>当前线程所执行的字节码的行号指示器</li><li>字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成</li><li>为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存</li><li>程序计数器是唯一不会出现OutOfMemoryError的内存区域，声明周期是完全跟着线程的，线程创建即创建，线程结束即结束</li><li>程序计数器的私有主要是为了线程切换以后能够恢复到正确的执行位置上</li></ul></li><li>虚拟机栈<ul><li>描述java方法执行的内存模型</li><li>Java虚拟机栈由一个个栈帧组成，每个栈帧都拥有<ul><li>局部变量表<ul><li>存放了编译器已知的各种数据类型</li><li>对象引用</li></ul></li><li>操作数栈</li><li>动态链接</li><li>方法出口信息</li></ul></li></ul></li><li>本地方法栈<ul><li>虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务</li><li>本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。</li></ul></li></ul><p><strong>线程共享资源</strong></p><ul><li><p>堆 </p><ul><li>存放对象实例</li><li>几乎所有对象实例以及数组都在这里分配内存</li><li>堆是Java垃圾收集器的主要区域，因此也被称作GC堆 Garbage Collected Heap </li><li>堆会根据时间的长度分为多种空间，来方便垃圾收集器来更好的回收内存</li><li>还包括运行时常量池</li></ul></li><li><p>方法区</p><ul><li>用于存储已被虚拟机加载的类的信息，常量，静态变量，即时编译器编译后的代码等数据</li></ul></li><li><p>直接内存</p></li></ul><h2 id="1-2-并发-vs-并行"><a href="#1-2-并发-vs-并行" class="headerlink" title="1.2 并发 vs 并行"></a>1.2 并发 vs 并行</h2><p>并发 - 同一时间段的多个任务都在执行<br>并行 - 单位时间内，多个任务同时执行</p><h2 id="1-3-多线程带来的改变"><a href="#1-3-多线程带来的改变" class="headerlink" title="1.3 多线程带来的改变"></a>1.3 多线程带来的改变</h2><h3 id="1-3-1-优势"><a href="#1-3-1-优势" class="headerlink" title="1.3.1 优势"></a>1.3.1 优势</h3><ul><li>线程，是程序执行的最小单位，线程间的切换和调度成本远远小于进程。而且多核CPU时代意味着多个线程同时进行，这减少了线程上下文切换的开销</li><li>多线程并发变成是开发高并发系统的基础</li><li>单核时代多线程做的优化更多是提高CPU和IO的综合利用率。在一个线程做IO的时候，另外一个线程可以到内核当中做利用CPU的大量计算</li><li>多核时代想做的事情就是同时使用多个内核一起来做这件事，提高整个运行的效率</li></ul><h3 id="1-3-2-可能的问题"><a href="#1-3-2-可能的问题" class="headerlink" title="1.3.2 可能的问题"></a>1.3.2 可能的问题</h3><p>需要解决内存泄漏，死锁，线程不安全相关的问题</p><ul><li>死锁<ul><li>多个线程被同时阻塞，在等待某个资源的释放</li><li>产生死锁的条件<ul><li>互斥条件 – 该资源任意时刻只由一个线程占用</li><li>请求与保持条件 – 一个进程因请求资源而阻塞时，对已获得的资源保持不放 </li><li>不剥夺条件 – 线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源</li><li>循环等待条件 – 若干进程之间形成一种头尾相接的循环等待资源关系</li></ul></li></ul></li></ul><pre><code>public class DeadLockDemo {    private static Object resource1 = new Object();//资源 1    private static Object resource2 = new Object();//资源 2    public static void main(String[] args) {        new Thread(() -&gt; {            synchronized (resource1) {                System.out.println(Thread.currentThread() + &quot;get resource1&quot;);                try {                    Thread.sleep(1000);                } catch (InterruptedException e) {                    e.printStackTrace();                }                System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;);                synchronized (resource2) {                    System.out.println(Thread.currentThread() + &quot;get resource2&quot;);                }            }        }, &quot;线程 1&quot;).start();        new Thread(() -&gt; {            synchronized (resource2) {                System.out.println(Thread.currentThread() + &quot;get resource2&quot;);                try {                    Thread.sleep(1000);                } catch (InterruptedException e) {                    e.printStackTrace();                }                System.out.println(Thread.currentThread() + &quot;waiting get resource1&quot;);                synchronized (resource1) {                    System.out.println(Thread.currentThread() + &quot;get resource1&quot;);                }            }        }, &quot;线程 2&quot;).start();    }}</code></pre><h2 id="1-4-sleep（）vs-wait（）"><a href="#1-4-sleep（）vs-wait（）" class="headerlink" title="1.4 sleep（）vs wait（）"></a>1.4 sleep（）vs wait（）</h2><ul><li>最主要的区别在于sleep并没有释放锁，而wait方法会释放锁</li><li>二者都暂停了当前线程的执行</li><li>wait用于线程之间的交互和通信，sleep用于暂停执行</li><li>wait()方法被调用以后，线程不会自动苏醒，需要别的线程调用同一个对象上的notify()或者notifyAll()方法</li></ul><h2 id="1-5-并发编程的重要特性"><a href="#1-5-并发编程的重要特性" class="headerlink" title="1.5 并发编程的重要特性"></a>1.5 并发编程的重要特性</h2><ul><li>原子性<ul><li>被修饰的代码块要不全都执行，要不都不执行，synchronized可以保证代码片段的原子性</li></ul></li><li>可见性<ul><li>当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改以后的新值的。volatile关键字可以保证共享变量的可见性</li></ul></li><li>有序性<ul><li>Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化   </li></ul></li></ul><h2 id="1-6-volatile关键字"><a href="#1-6-volatile关键字" class="headerlink" title="1.6 volatile关键字"></a>1.6 volatile关键字</h2><h3 id="1-6-1-General"><a href="#1-6-1-General" class="headerlink" title="1.6.1 General"></a>1.6.1 General</h3><p>在当前的 Java 内存模型下，线程可以把变量保存本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。要解决这个问题，需要将变量声明为volatile，这就指示JVM，这个变量时不稳定的，每次使用它都到主存当中进行读取。<br>即volatile关键字可以起到：</p><ul><li>保证变量的可见性，从主内存当中拿数据</li><li>防止指令重排序</li></ul><h2 id="1-7-synchronized关键字"><a href="#1-7-synchronized关键字" class="headerlink" title="1.7 synchronized关键字"></a>1.7 synchronized关键字</h2><h3 id="1-7-1-General"><a href="#1-7-1-General" class="headerlink" title="1.7.1 General"></a>1.7.1 General</h3><ul><li>解决多个线程之间访问资源的同步性问题</li><li>可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行</li><li>最开始是基于操作系统的mutex lock来实现，因为有用户态和内核态的转换，需要相对比较长的时间，性能不好；JDK 1.6之后做了大量优化，性能有了不小的提升<ul><li>自旋锁</li><li>适应性自旋锁</li><li>锁消除</li><li>锁粗化</li><li>偏向锁</li><li>轻量级锁</li></ul></li></ul><h3 id="1-7-2-使用方式"><a href="#1-7-2-使用方式" class="headerlink" title="1.7.2 使用方式"></a>1.7.2 使用方式</h3><ul><li>修饰实例方法<ul><li>作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁 </li></ul></li><li>修饰静态方法<ul><li>给当前类加锁，会作用于类的所有对象实例</li></ul></li><li>修饰代码块<ul><li>指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁  </li></ul></li></ul><pre><code>// 线程安全的单例模式的实现public class Singleton {    private volatile static Singleton uniqueInstance;    private Singleton() {    }    public static Singleton getUniqueInstance() {       //先判断对象是否已经实例过，没有实例化过才进入加锁代码        if (uniqueInstance == null) {            //类对象加锁            synchronized (Singleton.class) {                if (uniqueInstance == null) {                    uniqueInstance = new Singleton();                }            }        }        return uniqueInstance;    }}</code></pre><h3 id="1-7-3-底层实现方式"><a href="#1-7-3-底层实现方式" class="headerlink" title="1.7.3 底层实现方式"></a>1.7.3 底层实现方式</h3><ul><li>同步语句块的时候<ul><li>使用的是monitorenter和monitorexit指令</li><li>monitorenter指令指向同步代码块的开始位置</li><li>monitorexit指令指向同步代码块的结束位置</li><li>锁计数器为0时可以获取，释放锁的时候再置为0</li></ul></li><li>同步方法的时候<ul><li>使用的是ACC_SYNCHRONIZED标识，指明该方法为一个同步方法，从而执行相应的同步调用</li></ul></li></ul><h3 id="1-7-4-synchronized-关键字的底层优化"><a href="#1-7-4-synchronized-关键字的底层优化" class="headerlink" title="1.7.4 synchronized 关键字的底层优化"></a>1.7.4 synchronized 关键字的底层优化</h3><p>锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率</p><ul><li><p>偏向锁</p><ul><li>为了在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗</li><li>偏向锁在无竞争的情况下会把整个同步都消除掉</li><li>但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁 </li></ul></li><li><p>轻量级锁</p><ul><li>偏向锁失败的情况下会首先升级为轻量级锁</li><li>在没有多线程竞争的前提下，减少传统重量级锁使用操作系统互斥量产生的性能消耗</li><li>使用轻量级锁，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作 </li><li>轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！</li></ul></li><li><p>自旋锁和自适应自旋</p><ul><li>互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成</li><li>般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的</li><li>自旋锁就是让线程执行一个忙循环，自旋锁和互斥锁不同之处在于不会休眠，调用者一直在那里循环看锁的保持者是否释放了锁</li></ul></li><li><p>锁消除</p><ul><li>编译器在运行的时候，如果检测到共享数据不可能存在竞争，就执行锁消除，以节省毫无意义的请求锁的时间</li></ul></li></ul><h3 id="1-7-5-synchronized关键字和volatile关键字的区别"><a href="#1-7-5-synchronized关键字和volatile关键字的区别" class="headerlink" title="1.7.5 synchronized关键字和volatile关键字的区别"></a>1.7.5 synchronized关键字和volatile关键字的区别</h3><ul><li>volatile是线程同步的轻量级实现，因此volatile性能会比synchronized关键字好。</li><li>多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会</li><li>volatile关键字能保证数据的可见性，不能保证数据的原子性。synchronized都可以保证</li><li>volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性</li></ul><h1 id="2-ThreadLocal"><a href="#2-ThreadLocal" class="headerlink" title="2. ThreadLocal"></a>2. ThreadLocal</h1><h2 id="2-1-ThreadLocal"><a href="#2-1-ThreadLocal" class="headerlink" title="2.1 ThreadLocal"></a>2.1 ThreadLocal</h2><p>通常情况下，我们创建的变量时可以被任何一个线程访问并修改的，如果想实现每一个线程都有自己的专属的本地变量的话，可以使用JDK提供的ThreadLocal类。ThreadLocal类解决的问题就是想让每个线程都绑定自己的值。</p><p>当我们创建了ThreadLocal变量，访问这个变量的每个线程都会有这个变量的本地副本，使用get()以及set()方法获取默认值或者将指改为当前线程所存的副本的值，从而避免线程安全问题。</p><pre><code>import java.text.SimpleDateFormat;import java.util.Random;public class ThreadLocalExample implements Runnable{     // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本    private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyyMMdd HHmm&quot;));    public static void main(String[] args) throws InterruptedException {        ThreadLocalExample obj = new ThreadLocalExample();        for(int i=0 ; i&lt;10; i++){            Thread t = new Thread(obj, &quot;&quot;+i);            Thread.sleep(new Random().nextInt(1000));            t.start();        }    }    @Override    public void run() {        System.out.println(&quot;Thread Name= &quot;+Thread.currentThread().getName()+&quot; default Formatter = &quot;+formatter.get().toPattern());        try {            Thread.sleep(new Random().nextInt(1000));        } catch (InterruptedException e) {            e.printStackTrace();        }        //formatter pattern is changed here by thread, but it won&#39;t reflect to other threads        formatter.set(new SimpleDateFormat());        System.out.println(&quot;Thread Name= &quot;+Thread.currentThread().getName()+&quot; formatter = &quot;+formatter.get().toPattern());    }}</code></pre><p>从ThreadLocal原理上来讲</p><pre><code>public class Thread implements Runnable {     ......    //与此线程有关的ThreadLocal值。由ThreadLocal类维护    ThreadLocal.ThreadLocalMap threadLocals = null;    //与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;     ......}</code></pre><ul><li><p>Thread类中有一个threadLocals和一个inheritableThreadLocals变量，都是由ThreadLocalMap来实现的。默认情况下两个变量的值均为null，只有当前线程调用ThreadLocal类的set/ get方法时才创建他们</p></li><li><p>ThreadLocal类的set()方法</p></li></ul><pre><code>    public void set(T value) {        Thread t = Thread.currentThread();        ThreadLocalMap map = getMap(t);        if (map != null)            map.set(this, value);        else            createMap(t, value);    }    ThreadLocalMap getMap(Thread t) {        return t.threadLocals;    }</code></pre><ul><li>从上面的代码中，可以看出最终的变量是放在了当前线程的ThreadLocalMap当中，并不是直接存在ThreadLocal上，ThreadLocal可以理解为只是ThreadLocalMap的封装，传递了变量值。</li><li>ThreadLocal类可以通过Thread.currentThread()获取当前线程对象之后，直接通过getMap(Thread t) 访问到该线程的ThreadLocalMap对象</li></ul><h1 id="3-AQS"><a href="#3-AQS" class="headerlink" title="3. AQS"></a>3. AQS</h1><p>AQS全称为AbstractQueuedSynchronizer，是一个用来构建锁和同步器的框架。</p><h2 id="3-1-原理分析"><a href="#3-1-原理分析" class="headerlink" title="3.1 原理分析"></a>3.1 原理分析</h2><p>核心思想为如果被请求的共享资源是空闲的，就将现在请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的资源被占用了，那么就需要一整套线程阻塞等待以及被唤醒时锁分配的机制，AQS使用CLH队列锁实现，将暂时获取不到锁的线程加入到队列当中。</p><p>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配</p><ul><li>AQS使用int变量来表示同步状态</li><li>通过内置的FIFO队列来完成获取资源线程的排队工作</li><li>AQS使用CAS对该同步状态进行原子操作实现对其值的修改</li></ul><pre><code>private volatile int state;//共享变量，使用volatile修饰保证线程可见性//返回同步状态的当前值protected final int getState() {          return state;} // 设置同步状态的值protected final void setState(int newState) {         state = newState;}//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）protected final boolean compareAndSetState(int expect, int update) {        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);}</code></pre><h2 id="3-2-AQS资源共享方式"><a href="#3-2-AQS资源共享方式" class="headerlink" title="3.2 AQS资源共享方式"></a>3.2 AQS资源共享方式</h2><ul><li>共有两种资源共享方式<ul><li>Exclusive 独占 <ul><li>只有一个线程能执行，又分为公平锁和非公平锁</li><li>公平锁<ul><li>按照线程在队列中的排队顺序，先到者先拿到锁 </li></ul></li><li>非公平锁  <ul><li>当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的</li></ul></li></ul></li><li>Share 共享<ul><li>多个线程可同时执行<ul><li>semaphore</li><li>coutDownLatch</li></ul></li></ul></li></ul></li></ul><h2 id="3-3-常用组件"><a href="#3-3-常用组件" class="headerlink" title="3.3 常用组件"></a>3.3 常用组件</h2><ul><li><p>Semaphore 信号量 – 允许多个线程同时访问</p><ul><li>synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。</li></ul></li><li><p>CountDownLatch 倒计时器</p><ul><li>CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行</li></ul></li><li><p>CyclicBarrier 循环栅栏</p><ul><li>CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）</li><li>它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞<h1 id="4-Atomic原子类"><a href="#4-Atomic原子类" class="headerlink" title="4. Atomic原子类"></a>4. Atomic原子类</h1></li></ul></li></ul><p>在这里指的是不可中断的操作，即便是多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。原子类体系就是就有原子/原子操作特征的类。</p><h2 id="4-1-General"><a href="#4-1-General" class="headerlink" title="4.1 General"></a>4.1 General</h2><ul><li><p>基本类型 - 使用原子的方式更新基本类型</p><ul><li>AtomicInteger 整形原子类</li><li>AtomicLong 长整形原子类</li><li>AtomicBoolean 布尔型原子类</li></ul></li><li><p>数组类型</p><ul><li>AtomicIntegerArray 整形数组原子类</li><li>AtomicLongArray 长整形数组原子类</li><li>AtomicReferenceArray 引用类型数组原子类</li></ul></li><li><p>引用类型</p><ul><li>AtomicReference 引用类型原子类</li><li>AtomicStampedReference 原子更新引用类型里的字段原子类</li><li>AtomicMarkableReference 原子更新带有标记位的引用类型</li></ul></li><li><p>对象的属性修改类型</p><ul><li>AtomicIntegerFieldUpdater </li><li>AtomicLongFielfUpdater</li><li>AtomicStampedReference </li></ul></li></ul><h2 id="4-2-使用与原理"><a href="#4-2-使用与原理" class="headerlink" title="4.2 使用与原理"></a>4.2 使用与原理</h2><ul><li>以AtomicInteger为例，其方法如下：</li></ul><pre><code>    public final int get() //获取当前的值    public final int getAndSet(int newValue)//获取当前的值，并设置新的值    public final int getAndIncrement()//获取当前的值，并自增    public final int getAndDecrement() //获取当前的值，并自减    public final int getAndAdd(int delta) //获取当前的值，并加上预期的值    boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）    public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。</code></pre><ul><li>AtomicInteger实现原理<ul><li>使用CAS以及volative来保证原子操作，从而避免synchronized的高开销，执行效率大为提升</li><li>CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值</li><li>UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset</li><li>另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。</li></ul></li></ul><pre><code>    // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）    private static final Unsafe unsafe = Unsafe.getUnsafe();    private static final long valueOffset;    static {        try {            valueOffset = unsafe.objectFieldOffset                (AtomicInteger.class.getDeclaredField(&quot;value&quot;));        } catch (Exception ex) { throw new Error(ex); }    }    private volatile int value;</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md" target="_blank" rel="noopener">https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md</a></li><li><a href="https://blog.csdn.net/zqz_zqz/article/details/70233767" target="_blank" rel="noopener">https://blog.csdn.net/zqz_zqz/article/details/70233767</a></li><li><a href="https://www.baeldung.com/java-threadpooltaskexecutor-core-vs-max-poolsize" target="_blank" rel="noopener">https://www.baeldung.com/java-threadpooltaskexecutor-core-vs-max-poolsize</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Multi-threading </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工程上关于SQL数据库 - 你需要知道的事</title>
      <link href="/%E5%B7%A5%E7%A8%8B%E4%B8%8A%E5%85%B3%E4%BA%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93-%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B/"/>
      <url>/%E5%B7%A5%E7%A8%8B%E4%B8%8A%E5%85%B3%E4%BA%8ESQL%E6%95%B0%E6%8D%AE%E5%BA%93-%E4%BD%A0%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B/</url>
      
        <content type="html"><![CDATA[<p>大部分的计算机系统都会有需要维护的状态，大概率就要依赖于一个存储系统。在重数据的系统当中，数据库就会成为整个系统设计的核心，其中会有很多需要考虑到的权衡。我们必须要学习并且了解数据库是如何被使用的，这篇文章会分享一些对于开发者有用的视角和观点。</p><h1 id="1-网络连接问题-–-难以达到的5个9"><a href="#1-网络连接问题-–-难以达到的5个9" class="headerlink" title="1. 网络连接问题 – 难以达到的5个9"></a>1. 网络连接问题 – 难以达到的5个9</h1><p>总有关于当前的网络有多么值得信赖的考量，谷歌云的数据，在服务层面达到99.999%的可访问的程度的时候，大约有7.6%的问题是由于网络造成的。这也同样有相关数据在AWS，甚至阿里云当中。因为挖断光纤，或者网络配置的问题，造成一个数据中心，甚至一个avaliability zone 不可访问。</p><p>根据过往的经验，云服务提供商出现的网络问题，很有可能直接造成使用的公司服务down掉数小时的时间。从用户的角度来看，他们去定位问题所在是很有难度的。首先要尽快判断是IaaS 还是PaaS出现的问题，当判断出是云服务供应商这边出现的问题之后，除了尽快联系，恐怕也别无他法。</p><p>出现网络问题的原因很多，像是硬件炸了，权限更改，停电，光纤被挖断，诸如此类。各大云服务厂商都会在一个地区有多个AZ,每个AZ有多个data center，相互之间再用光纤连接。会需要看哪条光纤无法使用，会对整个系统造成不同程度的影响。</p><h1 id="2-ACID-有多个涵义"><a href="#2-ACID-有多个涵义" class="headerlink" title="2. ACID 有多个涵义"></a>2. ACID 有多个涵义</h1><p>ACID指的是Atomicity, Consistency, Isolation, Durability。这些都是数据库的transaction需要的相关属性，以确保用户的数据属性在程序崩溃，硬件出现错误等各种情况下依旧按照期待来运行。没有ACID的话，开发者无法知道自己的代码的责任，以及数据库的责任，会造成很多问题。当然上述说的还是主要对于SQL数据库而言的，对于NoSQL来说，大部分都没有实现ACID，或者不是默认实现的(譬如AWS DynamoDB，可以选择实现transaction的功能)，因为他们实现起来很昂贵。</p><p>关于为什么NoSQL实现ACID很昂贵，首先需要说的是SQL对于大数据量是有瓶颈的，在上千万的数据规模以上，会难以继续扩容。NoSQL实质上是将传统的纵向扩容改为横向扩容，牺牲了一致性，(保证最终一致性)，来达到对更多数据的支持。</p><p>值得注意的是工业界对于ACID是没有一个非常非常之明确的定义的，首先不是每个数据库都是满足ACID的，然后在那些满足ACID的数据库当中，ACID也可以被不同的方式来做解释。ACID被不同的方式来解释的原因之一是在实现的时候四个特征之间的制衡。他们在处理一个edge case还有“不可能”情况的时候，表现还是会有蛮多不一样的地方的。</p><h1 id="3-每个数据库都有不同的一致性和隔离性能力"><a href="#3-每个数据库都有不同的一致性和隔离性能力" class="headerlink" title="3. 每个数据库都有不同的一致性和隔离性能力"></a>3. 每个数据库都有不同的一致性和隔离性能力</h1><p>在ACID属性当中，一致性和隔离性是在实现的时候最需要权衡的两个属性，因为实现的代价都很高。他们需要协同，在保证数据一致的过程中实质上是加剧了竞争的，竞争共同的资源。</p><p>在云服务的层面，一致性变得尤为困难，尤其是当我们需要横向的去扩展到不同的数据中心当中去的时候。根据CAP理论，一致性，可用性，分区容错性不可能同时满足，当我们要实现一致性的时候，势必会丢失掉一部分可用性，或者分区容错性。</p><p>值得注意的是，工程师是可以在程序的层面去解决一定的一致性的问题的，不一定要完全依赖于数据库层面的一致性检测。</p><p>数据库一般会提供一系列的隔离的层次，因此应用开发者就可以根据他们所需来选择最高效的isolation方式。弱隔离会更快，但也许会带来数据竞争。更强的隔离消减了一些潜在的数据隔离，但是会更慢，而且在慢到一定程度，TPS又相对比较高的情况下，数据库可能会被高TPS拖垮，变得不可访问。</p><p><img src="https://i.loli.net/2020/04/26/wU6biJox59ZanGN.png" alt="Existing concurrency model.png"></p><p>在SQL标准当中，隔离性的层级有：</p><ul><li>Serializable - 最严格，最昂贵的<ul><li>序列化的执行会要求前一个transaction完全执行完，才能去执行下一个transaction  </li><li>常常被称为snapshot isolation </li></ul></li><li>Repeatable reads <ul><li>在当前transaction当中还没提交的读请求对当前transaction是可见的，但是其他transaction做出的改变对当前transaction依旧不可见</li></ul></li><li>Read Committed <ul><li>未提交的读对transaction不可见</li><li>如果另外一个transaction插入并提交了新的行，当前的transaction在query的时候是可以看到的</li></ul></li><li>Read uncommitted <ul><li>脏读是被允许的</li><li>transactions可以看到其他transaction还没有提交的commit。很实用与count这种请求</li></ul></li></ul><p>关于具体的一个数据库，是怎么样对各级别的隔离进行处理的，可以参考 <a href="https://github.com/ept/hermitage" target="_blank" rel="noopener">Github - hermitage</a></p><h1 id="4-当你无法完全锁住的时候，可以选择使用乐观锁"><a href="#4-当你无法完全锁住的时候，可以选择使用乐观锁" class="headerlink" title="4. 当你无法完全锁住的时候，可以选择使用乐观锁"></a>4. 当你无法完全锁住的时候，可以选择使用乐观锁</h1><p>锁是极度昂贵的，这不仅仅是因为在数据库当中造成了强竞争，并且因为他们对于长连接的要求，这种从你的应用服务器到数据库的连接需要一直保持，是非常耗资源的。排它锁收到网络分区的影响更大，并且会导致非常难debug的死锁的问题。在排它锁不易实现的情境下，乐观锁是一个值得考虑的选择。</p><p>乐观锁从实现上是指当你去读一行的时候，记录下来版本号，最后一次修改的时间或者是checksum，想要达成的目的就是知道当前的它还是它。然后我们就可以在修改了数据之后去检测这个数据是否有被改变，如果没有，那么就证实其没有什么问题，我们就可以执行我们接下来的写操作了。</p><pre><code>UPDATE productsSET name = &#39;Telegraph receiver&#39;, version = 2 WHERE id = 1 AND version = 1</code></pre><p>注意乐观锁不是在数据库层面的限制了，而是在应用代码的层面，加以限制。 </p><h1 id="5-除了dirty-reads-和data-loss-你可能遇到其他的一些问题"><a href="#5-除了dirty-reads-和data-loss-你可能遇到其他的一些问题" class="headerlink" title="5. 除了dirty reads 和data loss 你可能遇到其他的一些问题"></a>5. 除了dirty reads 和data loss 你可能遇到其他的一些问题</h1><p>当我们谈论数据一致性的时候，我们会主要将注意力放在可能的race condition当中，其会导致脏读，以及数据的丢失。但是可能出现的问题不仅仅会出现在这个方面的。</p><p>比如说write skew问题 - 写偏序，是指一致性约束下的异常现象，即两个并行事务都基于自己读到的数据去覆盖另一部分数据集，在串行化的情况下两个事务无论何种先后顺序，最终都将达到一致状态，但是在Snapshot Isolation的隔离级别下是无法实现的。</p><pre><code>BEGIN tx1;                      BEGIN tx2;SELECT COUNT(*) FROM operatorsWHERE oncall = true;0                               SELECT COUNT(*)                                FROM operators                                WHERE oncall = TRUE;                                0UPDATE operators           UPDATE operatorsSET oncall = TRUE               SET oncall = TRUEWHERE userId = 4;               WHERE userId = 2;COMMIT tx1;                     COMMIT tx2;</code></pre><p>为了解决write skew问题，需要在事务的运行阶段增加冲突检测，而不是在提交阶段。通过加入事务开始时间戳以及事务结束时间戳，保证一个事务读的数据的最近一个版本的提交时间要早于事务的开始时间。</p><h1 id="6-关于事务提交顺序"><a href="#6-关于事务提交顺序" class="headerlink" title="6. 关于事务提交顺序"></a>6. 关于事务提交顺序</h1><p>数据库首先是提供顺序保证的，但是这个顺序和我们想的可能会又不用。即从数据库的视角来看，关注的是接收到事务(transaction)的顺序，而不是开发者编程看到的顺序。事务执行的顺序是很难预测的，尤其是在高并发的系统当中。</p><p>如果说执行顺序非常关键的话，我们应当将多条命令放到同一个数据库transaction当中。老避开提交时间不确定的问题。</p><h1 id="7-应用层面的数据库分区可以布局在应用之外"><a href="#7-应用层面的数据库分区可以布局在应用之外" class="headerlink" title="7. 应用层面的数据库分区可以布局在应用之外"></a>7. 应用层面的数据库分区可以布局在应用之外</h1><p>有点拗口，想要说明的是当我们的数据库数据量持续增大的时候，横向的分区就变得必不可少了。但是很多数据库可能无法做好横向分区，即traffic会非常不均匀等等。</p><p>标题想要阐述的，这个分区的逻辑不需要必须在你的应用里边，我们可以单独抽取出一个层级，包含分区逻辑。即application server –&gt; shard servers –&gt; database nodes。这样分离的好处是随着数据量的增大以及访问的数据特征的变化，我们需要的分区逻辑也会不断发生变化。分隔开变化，使得分区逻辑的改变不需要重新deploy应用服务器，加速了整个开发的进程。</p><h1 id="8-AUTOINCCREMENT-可能有害"><a href="#8-AUTOINCCREMENT-可能有害" class="headerlink" title="8. AUTOINCCREMENT 可能有害"></a>8. AUTOINCCREMENT 可能有害</h1><p>AUTOINCREMENT是个很常见的生成主键的方式，常常看到数据库被用来作为ID生成器，或者有专门的一个数据库用来负责做ID的生成。这样做有可能会无益，以下是一些原因：</p><ul><li>在分布式数据库系统当中，自动增长是一个很困难的事情。是需要一个global lock来生成ID的。如果你可以用UUID来取而代之的话，那么就不需要各个数据库节点之间的合作了。带锁的自增操作可能会引入冲突，极大的降低插入操作在分布式数据库当中的表现。</li><li>一些数据库根据主键来做分区算法，连续的ID很可能会导致不可测的热点，也许会让一些分区炸掉的同时其他分区很空闲。</li><li>最快访问数据库当中一行的方式就是通过其主键。如果我们能够有更好的定义一条数据的方式，那么使用其他富含意义的属性来作为主键会是个更好的选择。</li></ul><h1 id="9-任何时间源之间可能会有不同"><a href="#9-任何时间源之间可能会有不同" class="headerlink" title="9. 任何时间源之间可能会有不同"></a>9. 任何时间源之间可能会有不同</h1><p>所有的时间相关的API是不准确的，我们的机器并不是清楚的知道当前具体是什么时间的。我们的电脑都包含一个石英晶片，可以用来产生信号，让时间开始走。但是这种方式下，不会非常精准，总会比实际的时间稍微快一些或者慢一些。为了精确性，我们的电脑上的时间就需要根据实际时间来进行同步。</p><p>NTP服务器可以被用来对时间进行同步，但是好玩的是同步本身又会因为网络延时不够准确。谷歌是使用TrueTime服务来做的</p><ul><li>其使用两种不同的资源： GPS和原子钟。他们有不同的失败模式，因此二者并用能够增加可信赖度。</li><li>TrueTime用时间间隔来表示返回的时间，即当前时间一定在一个区间之内，所做的事情就是保证在这个区间的可信度足够高了</li></ul><h1 id="10-评估数据库在单个事务中的表现"><a href="#10-评估数据库在单个事务中的表现" class="headerlink" title="10. 评估数据库在单个事务中的表现"></a>10. 评估数据库在单个事务中的表现</h1><p>有些时候数据库会宣传自己的表现以及特征，然后说自己的latency，读写吞吐量有多么多么的大。但是… 离开具体场景的数据都是耍流氓，我们需要更加细致的衡量方式来评估数据库在一些非常关键的操作或者事务下的表现。</p><p>比如：</p><ul><li>当在一个有5000万行的数据库当中插入新的一行的吞吐量和延时</li><li>当查询用户的朋友的朋友（朋友的平均数量大致为500）的延时</li><li>获取用户时间线上前100条数据的延时，假定用户订阅了500个用户，每个用户每小时会发送n条信息</li></ul><p>我们需要根据使用数据库的实际场景来做针对性的测试，来更加深入的理解这个数据库的特征</p><h1 id="11-事务当中不应该保存应用的状态"><a href="#11-事务当中不应该保存应用的状态" class="headerlink" title="11. 事务当中不应该保存应用的状态"></a>11. 事务当中不应该保存应用的状态</h1><p>还是要注重相互之间的隔离的，client端在网络出现问题的时候常常会不停重试请求。如果事务依赖于一些能够在其他地方被改变的状态，那么事务当中可能就会拿到错误的数据，导致隐含错误的出现，开发者是很难找到这种类型的错误的。</p><pre><code>var seq int64with newTransaction():     newSeq := atomic.Increment(&amp;seq)     Entries.query(newSeq)     // Other operations...</code></pre><p>譬如这种错误，事务当中会对sequence number做累加操作，当网络出现问题，会回滚，但是seq数字已经增加了，这就导致了下次执行的结果和上次本应该获得的结果会出现不同。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78" target="_blank" rel="noopener">https://medium.com/@rakyll/things-i-wished-more-developers-knew-about-databases-2d0178464f78</a> </li><li><a href="https://www.quora.com/Why-doesnt-NoSQL-support-an-ACID-property" target="_blank" rel="noopener">https://www.quora.com/Why-doesnt-NoSQL-support-an-ACID-property</a></li><li><a href="https://en.wikipedia.org/wiki/CAP_theorem" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/CAP_theorem</a></li><li><a href="https://jepsen.io/consistency" target="_blank" rel="noopener">https://jepsen.io/consistency</a> </li><li><a href="https://blog.csdn.net/oaa608868/article/details/54866899" target="_blank" rel="noopener">https://blog.csdn.net/oaa608868/article/details/54866899</a></li><li><a href="http://www.nosqlnotes.com/technotes/mvcc-snapshot-isolation/" target="_blank" rel="noopener">http://www.nosqlnotes.com/technotes/mvcc-snapshot-isolation/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CAP </tag>
            
            <tag> SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript Dependency Hell - 对于JS依赖树的分析</title>
      <link href="/JavaScript-Dependency-Hell-%E5%AF%B9%E4%BA%8EJS%E4%BE%9D%E8%B5%96%E6%A0%91%E7%9A%84%E5%88%86%E6%9E%90/"/>
      <url>/JavaScript-Dependency-Hell-%E5%AF%B9%E4%BA%8EJS%E4%BE%9D%E8%B5%96%E6%A0%91%E7%9A%84%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>做前端开发的同学肯定都对npm很熟悉，node package manager，一个非常受欢迎的包管理器。npm通过<code>package.json</code>来对项目当中的包进行管理，在这个json文件当中的包相当于就被npm注册了。</p><h1 id="1-什么是package-json"><a href="#1-什么是package-json" class="headerlink" title="1. 什么是package.json?"></a>1. 什么是package.json?</h1><ul><li><p>其定义了你的项目所依赖的所有包</p></li><li><p>并指定你的项目所用的包的版本号</p></li><li><p>让你的build是可以复制的，方便其他开发者来使用</p><h1 id="2-Package-json-中的依赖种类"><a href="#2-Package-json-中的依赖种类" class="headerlink" title="2. Package.json 中的依赖种类"></a>2. Package.json 中的依赖种类</h1></li><li><p>dependencies </p><ul><li>这里定义了你的代码所需要的关键依赖</li></ul></li><li><p>devDependencies </p><ul><li>这里定义了你的开发所使用的的依赖，比如给代码样式的perttier 库</li></ul></li><li><p>peerDependencies </p><ul><li>这里是告诉其他开发者，当使用了你的这个包以后，他们需要定义在这里的包的特定版本</li></ul></li><li><p>optionalDependencies </p><ul><li>可选的依赖，不安装他们不会毁坏安装的过程</li></ul></li><li><p>bundledDependencies </p><ul><li>这里包含的是一个列表的包，他们会被打包到一起来引入到你的项目当中。这个在你的依赖包不在npm当中的情况下是很有用的。    <h1 id="3-使用package-lock-json的目的"><a href="#3-使用package-lock-json的目的" class="headerlink" title="3. 使用package-lock.json的目的"></a>3. 使用package-lock.json的目的</h1>package-lock的使用目的，我们在前面的博文当中有详细的描述过 – <a href="https://llchen60.com/%E5%85%B3%E4%BA%8Epackage-lock-json/" target="_blank" rel="noopener">相关博文</a>。总的来说，有packge-lock.json 能够给我们更大的自由度，将commit的回退和依赖的回退分隔开，即我可以使用过去的依赖树运行当前的代码，这在没有lock json的时候是很难实现的。</li></ul></li></ul><h1 id="4-依赖树的例子与简化"><a href="#4-依赖树的例子与简化" class="headerlink" title="4. 依赖树的例子与简化"></a>4. 依赖树的例子与简化</h1><pre><code>// 以gatsby为例, know the size of your node_modules overall du -sh node_modules// list the size decending $ du -sh ./node_modules/* | sort -nr | grep &#39;\dM.*&#39; 17M    ./node_modules/rxjs8.4M    ./node_modules/@types7.4M    ./node_modules/core-js6.8M    ./node_modules/@babel5.4M    ./node_modules/gatsby5.2M    ./node_modules/eslint4.8M    ./node_modules/lodash3.6M    ./node_modules/graphql-compose3.6M    ./node_modules/@typescript-eslint3.5M    ./node_modules/webpack3.4M    ./node_modules/moment3.3M    ./node_modules/webpack-dev-server3.2M    ./node_modules/caniuse-lite3.1M    ./node_modules/graphql</code></pre><p>…</p><pre><code>// !!! moved unused modules and dependenciesnpm dedup </code></pre><p>解耦操作的运行机理，就是寻找不同依赖之间的公有的包，然后复用这些共有的包。</p><p>对于可视化，用一些现成的工具可以被用来观察整个包的依赖状态，譬如：</p><ul><li><a href="https://npm.anvaka.com/#/" target="_blank" rel="noopener">https://npm.anvaka.com/#/</a></li><li><a href="http://npm.broofa.com/" target="_blank" rel="noopener">http://npm.broofa.com/</a></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html" target="_blank" rel="noopener">https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JaveScript </tag>
            
            <tag> JS Dependency </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Typescript学习笔记(二)</title>
      <link href="/Typescript%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C/"/>
      <url>/Typescript%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<ul><li><p>类型别名</p><ul><li>用来为一个类型起一个新名字</li></ul></li></ul><pre><code>type Name = string; </code></pre><ul><li>字符串字面量类型</li></ul><pre><code>type EventNames = &#39;click&#39; | &#39;scroll&#39; | &#39;mousemove&#39;;function handleEvent(ele: Element, event: EventNames) {    // do something}handleEvent(document.getElementById(&#39;hello&#39;), &#39;scroll&#39;);  // 没问题handleEvent(document.getElementById(&#39;world&#39;), &#39;dbclick&#39;); // 报错，event 不能为 &#39;dbclick&#39;// index.ts(7,47): error TS2345: Argument of type &#39;&quot;dbclick&quot;&#39; is not assignable to parameter of type &#39;EventNames&#39;.</code></pre><ul><li>元组  - Tuple<ul><li>Tuple可以用于合并不同类型的对象</li></ul></li></ul><pre><code>let tom: [string, number] = [&#39;Tom&#39;, 25];</code></pre><ul><li>枚举<ul><li>用于取值被限定在一定范围内的场景</li><li>使用enum进行定义的</li><li>枚举成员会被赋值为从0开始递增的数字，同时也会对枚举值到枚举名进行反向映射</li></ul></li></ul><pre><code>enum Days {Sun, Mon, Tue, Wed, Thu, Fri, Sat};console.log(Days[&quot;Sun&quot;] === 0); // trueconsole.log(Days[&quot;Mon&quot;] === 1); // trueconsole.log(Days[&quot;Tue&quot;] === 2); // trueconsole.log(Days[&quot;Sat&quot;] === 6); // trueconsole.log(Days[0] === &quot;Sun&quot;); // trueconsole.log(Days[1] === &quot;Mon&quot;); // trueconsole.log(Days[2] === &quot;Tue&quot;); // trueconsole.log(Days[6] === &quot;Sat&quot;); // true</code></pre><ul><li>类，类与接口<ul><li>使用class定义类，使用constructor定义构造函数，通过new生成新实例的时候，是会自动调用构造函数的</li></ul></li></ul><pre><code>class Animal {    constructor(name) {        this.name = name;    }    sayHi() {        return `My name is ${this.name}`;    }}let a = new Animal(&#39;Jack&#39;);console.log(a.sayHi()); // My name is Jack</code></pre><ul><li><p>类通过extends继承</p><ul><li><p>然后通过super关键词来调用父类的构造函数和方法</p><p>class Cat extends Animal {<br>  constructor(name) {</p><pre><code>  super(name); // 调用父类的 constructor(name)  console.log(this.name);</code></pre><p>  }<br>  sayHi() {</p><pre><code>  return &#39;Meow, &#39; + super.sayHi(); // 调用父类的 sayHi()</code></pre><p>  }<br>}</p><p>let c = new Cat(‘Tom’); // Tom<br>console.log(c.sayHi()); // Meow, My name is Tom</p></li></ul></li><li><p>泛型</p><p>  function createArray<T>(length: number, value: T): Array<T> {</p><pre><code>  let result: T[] = [];  for (let i = 0; i &lt; length; i++) {      result[i] = value;  }  return result;</code></pre><p>  }</p><p>  createArray(3, ‘x’); // [‘x’, ‘x’, ‘x’]</p></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://ts.xcatliu.com/advanced/type-aliases" target="_blank" rel="noopener">https://ts.xcatliu.com/advanced/type-aliases</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TypeScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TypeScript笔记(一)</title>
      <link href="/TypeScript%E7%AC%94%E8%AE%B0-0/"/>
      <url>/TypeScript%E7%AC%94%E8%AE%B0-0/</url>
      
        <content type="html"><![CDATA[<p>Tl;dr </p><p>这会是一篇很长的博文，大部分内容都直接来自Reference当中的TypeScript教程和ES6教程，只是为了总结一些自己认为重要的知识点，以及一些认为需要深入理解的地方及其延伸的链接，希望有帮助。</p><h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><h2 id="1-1-定义"><a href="#1-1-定义" class="headerlink" title="1.1 定义"></a>1.1 定义</h2><ul><li>JavaScript超集，提供了类型系统和对ES6的支持，由Microsoft开发</li></ul><h2 id="1-2-优势"><a href="#1-2-优势" class="headerlink" title="1.2 优势"></a>1.2 优势</h2><ul><li>增加代码的可读性和可维护性<ul><li>类型系统是很好的文档，看类型的定义我们就能够知道如何使用了</li><li>可以在编译阶段发现大部分错误，比运行时出错好很多</li><li>增强编辑器的功能，包括代码补全，接口提示，跳转到定义，重构等</li></ul></li><li>兼容性好<ul><li>js文件实际上是可以直接重命名为ts文件的</li><li>及时不显式定义类型，也能够自动做出类型推论  </li></ul></li></ul><h2 id="1-3-相对劣势"><a href="#1-3-相对劣势" class="headerlink" title="1.3 相对劣势"></a>1.3 相对劣势</h2><ul><li>学习成本 <ul><li>接口 </li><li>泛型</li><li>类</li></ul></li><li>短期增加开发成本，要多写一些类型的定义，但是对于需要长期维护的项目，TypeScript能够减少其维护成本</li><li>集成到构建流程当中需要一些工作量的 </li></ul><h1 id="2-基础知识"><a href="#2-基础知识" class="headerlink" title="2. 基础知识"></a>2. 基础知识</h1><h2 id="2-1-原始数据类型"><a href="#2-1-原始数据类型" class="headerlink" title="2.1 原始数据类型"></a>2.1 原始数据类型</h2><ul><li><p>布尔值 - boolean</p><pre><code>  let isSuccessful: boolean = true;  let createdByNewBoolean: boolean = new Boolean(1);  // Type &#39;Boolean&#39; is not assignable to type &#39;boolean&#39;.  // &#39;boolean&#39; is a primitive, but &#39;Boolean&#39; is a wrapper object. Prefer using &#39;boolean&#39; when possible.  let createdByNewBoolean: Boolean = new Boolean(1);  // when you new Boolean, it will create a Boolean - a wrapper object  let createdByBoolean: boolean = Boolean(1);   // create a boolean </code></pre></li></ul><ul><li><p>数值 - number</p><pre><code>  let decLiteral: number = 6;</code></pre></li><li><p>字符串 - string</p></li></ul><pre><code>    let myName: string = &#39;Tom&#39;;    let myAge: number = 25;    // 模板字符串  `用来定义模板字符串，${}用来在模板字符串中嵌入表达式    let sentence: string = `Hello, my name is ${myName}.    I&#39;ll be ${myAge + 1} years old next month.`;</code></pre><ul><li>null &amp; undefined<ul><li>null 和 undefined是所有类型的子类型</li><li>void类型的变量不能赋值给number类型的变量</li></ul></li><li>symbol</li></ul><h2 id="2-2-任意值-Any"><a href="#2-2-任意值-Any" class="headerlink" title="2.2 任意值 - Any"></a>2.2 任意值 - Any</h2><p>任意值用来表示允许赋值为任意类型。在Typescript当中，普通类型在复制过程中改变类型是不被允许的，但是如果是any类型，则允许被赋值为任意类型。</p><pre><code>    let myFavoriteNumber: any = &#39;seven&#39;;    myFavoriteNumber = 7;</code></pre><ul><li>任意值上访问任何属性都是允许的，也允许调用任何方法</li><li>返回的类型都是任意值</li><li>对于未声明类型的变量<ul><li>未指定类型，那么会被识别为任意值类型</li></ul></li></ul><h2 id="2-3-类型推论"><a href="#2-3-类型推论" class="headerlink" title="2.3 类型推论"></a>2.3 类型推论</h2><p>如果没有明确的指定类型，那么TypeScript会按照类型推论 - Type Inference的规则推断出一个类型。</p><pre><code>let myFavoriteNumber = &#39;seven&#39;;myFavoriteNumber = 7;// index.ts(2,1): error TS2322: Type &#39;number&#39; is not assignable to type &#39;string&#39;.  编译的时候出错，因为TS自动做了类型推论，并且认定其为一个string类型</code></pre><p>但是如果定义的时候没有赋值，那么不管接下来是否会赋值，都会被推断成any类型而完全不被类型检查</p><pre><code>let myFavoriteNumber;myFavoriteNumber = &#39;seven&#39;;myFavoriteNumber = 7;</code></pre><h2 id="2-4-联合类型-Union-Types"><a href="#2-4-联合类型-Union-Types" class="headerlink" title="2.4 联合类型 - Union Types"></a>2.4 联合类型 - Union Types</h2><pre><code>let myFavoriteNumber: string | number;myFavoriteNumber = &#39;seven&#39;;myFavoriteNumber = 7;</code></pre><p>联合类型当中使用 <code>|</code>来分割每个类型</p><h2 id="2-5-接口"><a href="#2-5-接口" class="headerlink" title="2.5 接口"></a>2.5 接口</h2><ul><li><p>在TypeScript当中，使用接口定义对象的类型，除了可以对类的一部分行为进行抽象以外，也chang’yo个与对 对象的形状进行描述。</p><p>  interface Person {</p><pre><code>  name: string;  age: number;</code></pre><p>  }</p><p>  let tom: Person = {</p><pre><code>  name: &#39;Tom&#39;,  age: 25</code></pre><p>  };</p></li></ul><p>在做赋值的时候，定义的变量需要和接口有一样的属性。</p><ul><li><p>对于我们想要可选择的匹配的属性，我们可以用可选属性的方式：</p><p>  interface Person {</p><pre><code>  name: string;  age?: number;</code></pre><p>  }</p><p>  let tom: Person = {</p><pre><code>  name: &#39;Tom&#39;</code></pre><p>  };</p></li><li><p>也可以配置，是的接口能够接任意的属性： – <code>[propName: string] : any</code></p><ul><li><p>需要注意的是一旦定义了任意属性，那么确定属性和可选属性的类型都必须是它的类型的子集 </p><p>interface Person {<br>  name: string;<br>  age?: number;<br>  [propName: string]: any;<br>}</p><p>let tom: Person = {<br>  name: ‘Tom’,<br>  gender: ‘male’<br>};</p></li></ul></li><li><p>只读属性</p><ul><li>有use case我们希望对象当中的一些字段只能在创建的时候被赋值，那么就可以通过使用readonly定义只读属性</li></ul></li></ul><h2 id="2-6-数组类型"><a href="#2-6-数组类型" class="headerlink" title="2.6 数组类型"></a>2.6 数组类型</h2><ul><li>使用类型+方括号来定义</li></ul><pre><code>let fibonacci: number[] = [1, 1, 2, 3, 5];</code></pre><ul><li>使用数组泛型来表示数组 – <code>Array&lt;elemType&gt;</code></li></ul><pre><code>let fibonacci: Array&lt;number&gt; = [1, 1, 2, 3, 5];</code></pre><ul><li>使用接口表示数组</li></ul><pre><code>interface NumberArray {    [index: number]: number;}let fibonacci: NumberArray = [1, 1, 2, 3, 5];</code></pre><h2 id="2-7-函数类型"><a href="#2-7-函数类型" class="headerlink" title="2.7 函数类型"></a>2.7 函数类型</h2><h3 id="2-7-1-函数声明"><a href="#2-7-1-函数声明" class="headerlink" title="2.7.1 函数声明"></a>2.7.1 函数声明</h3><pre><code>// 函数声明（Function Declaration）function sum(x, y) {    return x + y;}// 函数表达式（Function Expression）let mySum = function (x, y) {    return x + y;};// TypeScript下的函数声明function sum(x: number, y:number):number {    return x + y;}</code></pre><h3 id="2-7-2-函数表达式"><a href="#2-7-2-函数表达式" class="headerlink" title="2.7.2 函数表达式"></a>2.7.2 函数表达式</h3><pre><code>let mySum: (x: number, y: number) =&gt; number = function (x: number, y: number): number {    return x + y;};</code></pre><p>注意在上述代码当中，跟在mySum后面的是对于输入参数和输出参数的规定，中间用箭头来进行连接，这是TypeScript的规范。</p><p>另外我们也可以通过使用接口来定义函数的形状：</p><pre><code>interface SearchFunc {    (source: string, subString: string): boolean;}let mySearch: SearchFunc;mySearch = function(source: string, subString: string) {    return source.search(subString) !== -1;}</code></pre><h3 id="2-7-3-可选参数"><a href="#2-7-3-可选参数" class="headerlink" title="2.7.3 可选参数"></a>2.7.3 可选参数</h3><ul><li>使用问号跟在参数名字之后表示是可选的，注意可选参数需要在参数列表的末尾，其之后不能有必需参数了</li></ul><pre><code>function buildName(firstName: string, lastName?: string) {    if (lastName) {        return firstName + &#39; &#39; + lastName;    } else {        return firstName;    }}</code></pre><h3 id="2-7-4-参数默认与剩余参数"><a href="#2-7-4-参数默认与剩余参数" class="headerlink" title="2.7.4 参数默认与剩余参数"></a>2.7.4 参数默认与剩余参数</h3><pre><code>// 默认参数function buildName(firstName: string, lastName: string = &#39;Cat&#39;) {    return firstName + &#39; &#39; + lastName;}let tomcat = buildName(&#39;Tom&#39;, &#39;Cat&#39;);let tom = buildName(&#39;Tom&#39;);// 使用 ...来获取函数当中的剩余参数function push(array, ...items) {    items.forEach(function(item) {        array.push(item);    });}let a: any[] = [];push(a, 1, 2, 3);</code></pre><h2 id="2-8-声明文件"><a href="#2-8-声明文件" class="headerlink" title="2.8 声明文件"></a>2.8 声明文件</h2><p>当使用第三方库的时候，我们需要引用它的声明文件，以获得对应的代码补全，接口提示的功能</p><h3 id="2-8-1-声明语句"><a href="#2-8-1-声明语句" class="headerlink" title="2.8.1 声明语句"></a>2.8.1 声明语句</h3><p>比如我们想使用jquery，一般来说是加script标签，但是ts当中，我们需要使用declare var来定义其类型</p><pre><code>declare var jQuery: (selector: string) =&gt; any;jQuery(&#39;#foo&#39;);</code></pre><p>我们会将声明语句放到一个单独的文件当中，譬如对于上述的例子，就是放到jQuery.d.ts 当中<br>声明文件必须以<code>.d.ts</code>来结尾</p><p>ts会解析项目当中所有的*.ts文件，也包含了.d.ts结尾的文件，所以当我们定义.d.ts文件以后，里面的内容是会被整个项目共享的。</p><p>另外，我们可以通过@types 来统一管理第三方库的声明文件</p><h3 id="2-8-2-书写声明文件"><a href="#2-8-2-书写声明文件" class="headerlink" title="2.8.2 书写声明文件"></a>2.8.2 书写声明文件</h3><p>当第三方库没有提供声明文件的时候，我们就需要自己书写声明文件了。</p><p>库的使用场景主要有：</p><ul><li>全局变量 </li><li>npm包</li><li>UMD库</li><li>直接扩展全局变量</li></ul><p>详情看 <a href="https://ts.xcatliu.com/basics/declaration-files#xin-yu-fa-suo-yin" target="_blank" rel="noopener">link</a></p><h1 id="2-9-内置对象"><a href="#2-9-内置对象" class="headerlink" title="2.9 内置对象"></a>2.9 内置对象</h1><p><a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects" target="_blank" rel="noopener">ECMAScript 内置对象</a></p><p><a href="https://github.com/Microsoft/TypeScript/tree/master/src/lib" target="_blank" rel="noopener">DOM DOM 内置对象</a></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://ts.xcatliu.com/" target="_blank" rel="noopener">https://ts.xcatliu.com/</a></li><li><a href="https://es6.ruanyifeng.com/" target="_blank" rel="noopener">https://es6.ruanyifeng.com/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TypeScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于package-lock.json</title>
      <link href="/%E5%85%B3%E4%BA%8Epackage-lock-json/"/>
      <url>/%E5%85%B3%E4%BA%8Epackage-lock-json/</url>
      
        <content type="html"><![CDATA[<p>当我们将node package manager (npm) 升级到5.0以上的版本的时候，你会发现npm运行的时候会自动创建一个新文件 – package-lock.json。</p><p>里面包含的是我们的依赖关系，各种依赖的包和版本号。package-lock.json会在npm修改了node_modules 树或者修改了package.json之后自动生成。它精确的描述了整个生成的树，使得接下来任何一次的装配都可以生成完全一致的依赖树.这个生成的文件是需要commit 到remote branch上的，其目的在于：</p><ul><li>描述单个依赖树，使得其他人在做deploy的时候使用的是完全一致的依赖</li><li>使得使用人员有能力直接跳转回原先的依赖状态，而不需要将代码也回退到之前的版本</li><li>加强了依赖改变的阅读性，我们可以相对直观的看到每次的commit都有什么依赖被改变了</li><li>也可以通过是的npm跳过对于原先安装过的包的重复的元数据分析来优化整个安装的进程</li></ul><p>针对其特征，我们是应该将package-lock.json也提交上去的，这会给开发，同步带来不小的帮助。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://medium.com/coinmonks/everything-you-wanted-to-know-about-package-lock-json-b81911aa8ab8" target="_blank" rel="noopener">https://medium.com/coinmonks/everything-you-wanted-to-know-about-package-lock-json-b81911aa8ab8</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> npm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用户画像构建思路</title>
      <link href="/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F%E6%9E%84%E5%BB%BA%E6%80%9D%E8%B7%AF/"/>
      <url>/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F%E6%9E%84%E5%BB%BA%E6%80%9D%E8%B7%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>用户画像指的是系统通过用户自己上传的信息以及自己的分析，记录了用户的大量的信息，而后为了便于去给各个系统来使用，将这些信息进行沉淀加工，形成一个标签树的整个过程。</p><p>画像是由标签树及末级标签的标签值构成的，全面定量刻画用户的结构化信息产品。画像是标签的总成，用户标签是具体刻画用户的结构化信息，以下简称标签。</p><p>用户画像对于公司的运营，盈利都有很大的好处：</p><ol><li>可以用于统计，使得对产品，对用户有基本认知</li><li>用于定向营销和精细化运营</li><li>还可以用于算法当中，在搜索推荐，风控广告等策略防线，标签被作为用户特征得以提取和使用</li></ol><h1 id="2-构建标签树"><a href="#2-构建标签树" class="headerlink" title="2. 构建标签树"></a>2. 构建标签树</h1><p>一个好的标签树需要具有高概括性和强延展性，高概括性意味着结构体系能够很好的包含一个用户的<strong>基本属性</strong>和<strong>产品交互的相关行为</strong>，同时对于业务重点单独强调，没有遗漏；“强延展性”意味着结构全面的同时也有一定的抽象概括能力，保证新增的标签可以很好的找到对应的分类，整个体系不会过于收敛局限。</p><p>按照这个原则，画像可以从以下维度进行组织： </p><ul><li><p>基本属性</p><ul><li>指一个用户的基本社会属性和变更频率比较低的特征<ul><li>真实社会年龄</li><li>性别</li><li>婚姻状况</li><li>昵称</li><li>号码</li><li>账号</li><li>lbs </li></ul></li></ul></li><li><p>平台属性</p><ul><li>平台属性是用户在平台上表现出的基本属性特征，是利用用户行为进行算法挖掘，标识用户真实属性的标签</li><li>譬如平台年龄标签  面向例如年龄为20岁，但是心理年龄50岁，穿衣风格50岁的人；反之亦然</li><li>平台属性和基本属性的区别如下：<ul><li>数据源与计算逻辑<ul><li>基础属性是利用用户自行上传的存储在用户基础信息表里的数据，平台属性则利用客户端或者服务端埋点上报采集的用户行为数据进行挖掘计算生成的。</li><li>基本属性是典型的直采型标签，平台属性是典型的算法挖掘型标签</li></ul></li><li>末级标签和输出标签值<ul><li>平台属性代表用户在性别维度上的偏好概率，可以生成类似<code>性别_女_0.80</code>这样的标签，0.8代表了用户的倾向程度</li></ul></li><li>应用场景<ul><li>平台属性通过用户行为进行挖掘，更能代表用户的真实倾向，输出结果比基本属性准确率更高</li></ul></li></ul></li></ul></li><li><p>行为属性</p><ul><li>行为属性记录用户的所有单个点的行为</li><li>包括<ul><li>启动</li><li>登录</li><li>浏览</li><li>点击</li><li>加车</li><li>下单</li></ul></li><li>是可以和不同的产品，不同的模块进行交互的，而且可以在不同的时间窗口进行选取，行为会相对复杂</li><li>按照 产品 x 功能模块 x 用户单点行为 x 时间  这四个要素来进行组织  </li></ul></li><li><p>产品偏好</p><ul><li>对用户使用某些产品，产品核心功能或者其他渠道的偏好程度的刻画，属于挖掘性的标签</li><li>产品可以包括自己公司的，竞品的</li><li>功能渠道包括站内产品功能，包括push、短信、开屏、弹窗等几大运营和产品方式 </li></ul></li><li><p>兴趣偏好</p><ul><li>品牌偏好  nike</li><li>类目偏好  运动</li><li>标签偏好  跑步_0.7</li></ul></li><li><p>敏感度</p><ul><li>营销活动中，会注意到有些用户不需要优惠也会下单，而有些用户一定要通过优惠券刺激才能实现转化，优惠券的额度也会影响用户下单的金额</li><li>需要识别对优惠敏感的用户，发放合理的券额，保证优惠券不浪费，使得整个促销活动的ROI最大</li><li>构建用户的敏感度标签<ul><li>优惠促销敏感度</li><li>活动敏感度</li><li>新品敏感度</li><li>爆款敏感度 </li></ul></li></ul></li><li><p>消费属性</p><ul><li>消费频次</li><li>消费金额</li><li>最近消费时间</li><li>消费能力</li><li>消费意愿 </li></ul></li><li><p>用户生命周期</p><ul><li>新手</li><li>成长</li><li>成熟</li><li>衰退</li><li>流失 </li></ul></li><li><p>用户价值</p><ul><li>活跃度</li><li>裂变拉新等 </li></ul></li></ul><h1 id="3-用户画像的范例"><a href="#3-用户画像的范例" class="headerlink" title="3. 用户画像的范例"></a>3. 用户画像的范例</h1><p><img src="https://i.loli.net/2020/04/14/XnJYc3ejRrMwdul.png" alt="用户画像导图.png"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.infoq.cn/article/oUqJDlfstrYAmTBYzier?utm_source=rss&amp;utm_medium=article" target="_blank" rel="noopener">https://www.infoq.cn/article/oUqJDlfstrYAmTBYzier?utm_source=rss&amp;utm_medium=article</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 用户画像 </tag>
            
            <tag> 运营 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中台</title>
      <link href="/%E4%B8%AD%E5%8F%B0/"/>
      <url>/%E4%B8%AD%E5%8F%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是中台？"><a href="#1-什么是中台？" class="headerlink" title="1. 什么是中台？"></a>1. 什么是中台？</h1><p>看到几篇关于中台的博客，是国内提出的一个新的概念，稍微研究了下，很有意思的概念。</p><p>中台，在我看来，从业务上来讲，可以说是为了解决系统的复用性的问题而出现的。一个简单的例子，阿里刚刚开始的时候只有淘宝，但是后来出现了天猫，二者尽管顶层业务逻辑有不同，但是他们都是需要一套订单，商品，库存，仓储，物流的各种系统的。如果每次我们想做一个新的业务模块的时候，都要来实现这样一套系统，迭代速度会很慢，而且很容易在做改动的时候因为各个类似功能的系统的改动不一致产生错误。</p><p>因此，将这些公用的系统提升，做成–中台，统一来使得各个业务部门重复使用，将需要反复建设的功能和系统进行统一的规划和管理。</p><p>主要解决的问题实质上有两类： </p><ol><li>需要业务需求或者功能需求是高度类似的，通用化程度很高，但是由于没有专门的团队负责规划和开发，大量的系统重复开发、重复建设、导致复用性很低，效率低，研发资源被浪费，用户体验也不够统一</li><li>早起业务发展过程当中，为了解决当下的一些业务问题，垂直的个性化的业务逻辑与基础系统耦合太深，由于没有平台性质的规划，横向系统之间、上下游系统之间的交叉逻辑非常多，导致了在新业务新市场的拓展过程当中，市场没有办法直接复用，甚至没有办法快速迭代。</li></ol><h1 id="2-为什么要中台，为什么要平台化？"><a href="#2-为什么要中台，为什么要平台化？" class="headerlink" title="2. 为什么要中台，为什么要平台化？"></a>2. 为什么要中台，为什么要平台化？</h1><p>引述《白话中台战略》当中的内容，“因为在当今互联网时代，⽤户才是商业战场的中心，为了快速响应用户的需求，借助平台化的力量可以事半功倍”</p><blockquote><p>不断快速响应、探索、挖掘、引领⽤户的需求，才是企业得以⽣存和持续发展的关键因素。</p></blockquote><blockquote><p>那些真正尊重用户，甚⾄不惜调整⾃己颠覆⾃己来响应⽤户的企业将在这场以⽤户为中心的商业战争中得以⽣存和发展；⽽反之，那些在过去的成就上故步⾃封，存在侥幸⼼理希望⽤户会像之前一样继续追随⾃己的企业则会被用户淘汰。很残酷，但这就是这个时代最基本的企业⽣存法则。</p></blockquote><p>平台化能够赋予或加强企业在以用户为中心的现代商业战争当中最为核心的能力 –&gt; 用户响应力。 </p><p>中台，可以说是与前台，后台相对应的。</p><ul><li>前台<ul><li>由各类前台系统组成的前端平台。每个前台系统就是一个用户触点，即企业的最终用户直接使用或者交互的系统，是企业与最终用户的交点。</li></ul></li><li>后台<ul><li>后台系统组成的后端平台，宝具哦企业的核心资源 – 数据 + 计算 <ul><li>财务系统</li><li>产品系统</li><li>客户管理系统</li><li>仓库物流管理系统</li></ul></li></ul></li><li>中台<ul><li>因为企业后台往往不能很好的支撑前台快速创新，响应用户的需求</li><li>前台直接使用后台，会遇到处理复杂，迭代速度缓慢的问题</li><li>前台要处理的是快速响应用户的需求，但是后台拿着整个公司的数据，是需要越稳定越好的，随着公司的发展，按照对速度和稳定的追求的冲突会越来越多</li><li>有了中台以后就可以将前台系统当中的稳定通用业务能力沉降到中台层，恢复前台的响应力</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.infoq.cn/article/3tbJZ8aS5pYdWYX5bBfg?utm_source=rss&amp;utm_medium=article" target="_blank" rel="noopener">https://www.infoq.cn/article/3tbJZ8aS5pYdWYX5bBfg?utm_source=rss&amp;utm_medium=article</a></li><li><a href="https://mp.weixin.qq.com/s/yfhaEkO1DG_ihJMhwtkWjA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/yfhaEkO1DG_ihJMhwtkWjA</a></li><li><a href="https://www.infoq.cn/article/hfONAlDdhK3fD9JjduGR" target="_blank" rel="noopener">https://www.infoq.cn/article/hfONAlDdhK3fD9JjduGR</a></li><li><a href="https://www.zhihu.com/question/57717433" target="_blank" rel="noopener">https://www.zhihu.com/question/57717433</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 中台 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于抖音的一些分析</title>
      <link href="/%E5%85%B3%E4%BA%8E%E6%8A%96%E9%9F%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E5%88%86%E6%9E%90/"/>
      <url>/%E5%85%B3%E4%BA%8E%E6%8A%96%E9%9F%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><h2 id="1-1-外部环境背景"><a href="#1-1-外部环境背景" class="headerlink" title="1.1 外部环境背景"></a>1.1 外部环境背景</h2><p>短视频是当前超高速发展的赛道，流量持续迅猛增长，越来越多的公司进入这个赛道，头部的国内有抖音快手，主要着眼于1min以内的短视频，主要为UGC(User Generated Content)，少量PGC(Professional Generated Content)产出内容；美国有刚刚成立的quibi，着眼于制作10min左右的优质内容，完全走PGC的路线。</p><p>短视频的兴起是有一些需要的社会以及科技的基础背景的。 </p><ul><li>从经济发展角度<ul><li>经济的持续发展，刺激了人们的休闲娱乐的需求的增长</li></ul></li><li>从用户需求角度<ul><li>需要填补自己的碎片时间</li><li>需要更多的娱乐休闲</li><li>自我表达，自我实现，社会联结的需求</li><li>发泄情绪</li></ul></li><li>从用户使用习惯角度<ul><li>截止2019年6月<ul><li>全国手机网民数量达到8.47亿(根据第44次中国互联网发展状况统计报告)，互联网普及率达到61.2%</li><li>网络购物用户规模6.39亿 </li><li>手机网络购物用户规模6.22亿</li><li>网络视频用户7.59亿</li><li>移动互联网接入流量消费553.9亿GB 同比增长107.3% </li><li>网民平均每周上网时长 27.9小时</li><li>短视频时长占比 11.5%，使用高峰为12点以及21点左右  </li></ul></li></ul></li><li>从技术角度<ul><li>4G 5G兴起，高速网络建设</li><li>手机的广泛普及</li><li>云平台普及，企业架构的相对简化，成本的降低 </li></ul></li><li>政策影响<ul><li>推出《网络短视频平台管理规范》</li><li>推出《网络短视频内容审核标准细则》 </li></ul></li></ul><h2 id="1-2-时间线"><a href="#1-2-时间线" class="headerlink" title="1.2 时间线"></a>1.2 时间线</h2><ul><li>2016年9月上线 <ul><li>A.me 定位为音乐短视频社区 </li><li>年轻人的15秒音乐短视频社区 </li></ul></li><li>2016年11月<ul><li>查找通讯录，邀请QQ 微博好友</li></ul></li><li>2016年11月10日<ul><li>微博话题挑战</li><li>雇佣 召集大学生，舞蹈音乐达人，拍摄视频引流</li></ul></li><li>2016年12月10日<ul><li>抖音 – 音乐视频应用</li></ul></li><li>2016年12月22日<ul><li>推荐热门视频</li><li>捧红一部分人，再带动普通用户的理念 – 偏向于中心化的运营方式出现端倪    </li></ul></li><li>2017年3月<ul><li>邀请岳云鹏等诸多明星加入抖音</li><li>开始有大批用户从明星微博当中看到抖音水印，进入抖音平台</li></ul></li><li>2017年6月开始<ul><li>给视频创作者更多权限<ul><li>对评论的控制，删减</li></ul></li><li>附近 tab，增强社交属性</li><li>抖音故事<ul><li>可以设置只开放24小时，希望普通人可以在上面记录自己的生活</li></ul></li><li>可以绑定微博主页</li></ul></li><li>2017年8月<ul><li>Tik Tok出海</li><li>吴亦凡的抖音挑战</li><li>中国有嘻哈 官方推荐</li><li>抖音开始砸钱到各个节目，增加曝光度了</li></ul></li><li>2017年9月<ul><li>首次线下party，狂欢节</li><li>和汉堡王，摩拜单车等等公司展开合作，联名等</li><li>AR相机</li><li>开启信息流广告，开屏广告的尝试 </li></ul></li><li>2017年10月<ul><li>上线直播功能</li></ul></li><li>2017年11月<ul><li>全新滤镜</li><li>倒计时自动暂停</li><li>直播间优化，增加弹幕功能</li></ul></li><li>2017年12月<ul><li>全新尬舞机功能    </li></ul></li><li>2018年1月<ul><li>百万英雄</li><li>私信功能</li><li>优化举报 评论功能</li></ul></li><li>2018年3月<ul><li>大规模的广告接入和投放开始</li></ul></li><li>2018年8月  <ul><li>直达淘宝功能上线</li><li>反沉迷系统上线        </li><li>增加游戏贴纸</li></ul></li><li>2018年10月<ul><li>个人页背景设置，个性化主页</li></ul></li><li>2018年12月<ul><li>直播粉丝团任务体系</li></ul></li><li>2019年1月<ul><li>地点详情页上传视频图片，用抖音来记录生活</li><li>直播 礼物一键连送</li><li>随拍功能</li><li>春晚独家社交媒体传播平台，五亿现金分享</li></ul></li><li>2019年2月<ul><li>AR画笔功能</li></ul></li><li>2019年3月<ul><li>随拍支持发布纯文字内容</li><li>新增聚焦拍摄模式</li><li>私信可置顶</li><li>热血鼓手道具玩法</li><li>新增位置贴纸</li></ul></li><li>2019年4月   <ul><li>道具玩法 – 橙子脸 </li><li>道具玩法 – 漫画擦拭</li></ul></li><li>2019年5月<ul><li>道具玩法 - change face   </li><li>挡脸变男生</li><li>道具玩法 - LineDancer</li></ul></li><li>2019年6月<ul><li>合拍 测相似度</li><li>道具玩法 – 炫光衣服 </li><li>道具玩法 – 照片连拍</li></ul></li><li>2019年7月<ul><li>道具玩法 – 动感轮廓</li><li>道具玩法 – 擦拭隐身</li><li>增加文字功能，可以在视频上添加文字了</li></ul></li><li>2019年9月<ul><li>青少年模式</li><li>道具玩法 – 百变抖抖秀</li></ul></li><li>2019年10月<ul><li>新增贴纸</li><li>青少年模式优化</li><li>新增变声功能</li></ul></li><li>2020年1月 - 至今<ul><li>春节20亿现金等你拿  </li><li>新增贴纸</li><li>新增特效  <h1 id="2-平台分析"><a href="#2-平台分析" class="headerlink" title="2. 平台分析"></a>2. 平台分析</h1><h2 id="2-1-市场定位"><a href="#2-1-市场定位" class="headerlink" title="2.1 市场定位"></a>2.1 市场定位</h2>从1.1的整个时间轴，我们会发现整个抖音的发展很小步快跑，迅速迭代。刚开始出了产品原型，用初始用户群体开始迅速做迭代，在锚定自己的定位，目标人群之后，通过召集KOL，明星，通过微博，QQ微信引流，实现其迅速的增长。</li></ul></li></ul><p>抖音的slogan是<strong>记录美好生活</strong>，<strong>以一二线城市年轻潮人为目标用户，市场定位突出音乐与创意</strong>，是一个相对中心化的高热度高流量的聚集年轻人的音乐短视频平台。整体是以音乐为核心布局的，用户在拍摄视频前首先选择一首背景音乐，根据音乐内容进行动作编排和加工特效。</p><h2 id="2-2-产品设计"><a href="#2-2-产品设计" class="headerlink" title="2.2 产品设计"></a>2.2 产品设计</h2><h3 id="2-2-1-浏览体验"><a href="#2-2-1-浏览体验" class="headerlink" title="2.2.1 浏览体验"></a>2.2.1 浏览体验</h3><ul><li>整体以黑白灰三色为主，风格简洁，有潮流感</li><li>全屏沉浸式体验<ul><li>无限向下滑动</li></ul></li><li>竖屏播放 – 适用更多的场景(上班，通勤，吃饭，等等) – 也很符合于短视频碎片时间使用的定位</li><li>点击背景音乐会跳转到同款音乐其他的短视频集合</li><li>交互 任意位置双击点赞，上下滑浏览其他视频</li><li>长按 可以看到更多的一些选择<ul><li>不感兴趣</li><li>加到喜欢 </li></ul></li></ul><h3 id="2-2-2-拍摄"><a href="#2-2-2-拍摄" class="headerlink" title="2.2.2 拍摄"></a>2.2.2 拍摄</h3><p>抖音在拍摄方面下了很大功夫，从更新日志上也能很明显看出他在尝试着不断降低拍摄出高质量视频的门槛，通过大量的特效，各种道具，让短视频不至于单调，可以用比较简单的素材，加上特效，音乐，撑起来。</p><ul><li>多种类型音乐<ul><li>国风</li><li>流行</li><li>原创 </li><li>etc.</li></ul></li><li>视频制作的功能<ul><li>速度切换</li><li>多段混剪</li><li>贴纸道具</li><li>美化滤镜</li><li>特效滤镜<h3 id="2-2-3-特色功能"><a href="#2-2-3-特色功能" class="headerlink" title="2.2.3 特色功能"></a>2.2.3 特色功能</h3></li></ul></li><li>热搜榜</li><li>尬舞机</li><li>时间锁</li></ul><h2 id="2-3-内容生产与分发"><a href="#2-3-内容生产与分发" class="headerlink" title="2.3 内容生产与分发"></a>2.3 内容生产与分发</h2><h3 id="2-3-1-内容生产模式"><a href="#2-3-1-内容生产模式" class="headerlink" title="2.3.1 内容生产模式"></a>2.3.1 内容生产模式</h3><p>UGC + PGC模式</p><ul><li>UGC<ul><li>普通用户</li></ul></li><li>PGC<ul><li>明星</li><li>网红</li><li>专业垂直领域KOL</li></ul></li></ul><h3 id="2-3-2-内容分发模式"><a href="#2-3-2-内容分发模式" class="headerlink" title="2.3.2 内容分发模式"></a>2.3.2 内容分发模式</h3><ul><li>算法推荐+人工精选推荐<ul><li>根据用户的观看数据，计算用户内容标签，按照一定频率推送相似的视频内容 </li><li>推荐爆款内容，越优质的内容会得到越多的曝光机会</li><li>推荐机制不太在意内容的发布时间，只要足够精彩，可能<strong><em>已经发布了几个月的视频</em></strong>还会不断推给用户</li></ul></li></ul><h2 id="2-4-营销推广"><a href="#2-4-营销推广" class="headerlink" title="2.4 营销推广"></a>2.4 营销推广</h2><ul><li>开屏广告</li><li>信息流广告</li><li>定制挑战赛<ul><li>为品牌独家定制</li><li>保持剧情，自主拍摄权交给视频制作者</li></ul></li><li>聚合电商<ul><li>同淘宝的直接链接</li></ul></li></ul><h2 id="2-5-技术能力"><a href="#2-5-技术能力" class="headerlink" title="2.5 技术能力"></a>2.5 技术能力</h2><ul><li>监管<ul><li>人工为主，机器学习为辅 <ul><li>通过建立完善数据库，将用户上传的内容与数据库进行匹配，被识别为不良内容就予以直接删除</li></ul></li><li>用户举报  <ul><li><h1 id="3-Thoughts"><a href="#3-Thoughts" class="headerlink" title="3. Thoughts"></a>3. Thoughts</h1></li></ul></li></ul></li></ul><h2 id="3-1-用户的需求"><a href="#3-1-用户的需求" class="headerlink" title="3.1 用户的需求"></a>3.1 用户的需求</h2><p>用户参与到虚拟社区的动机，可以是基于：</p><ul><li>自我认知和需求的满足 </li><li>社会交往需求  – 抖音不太能满足</li><li>获取利益的需求 – 平台盘子的扩大会增大每个人的盘子</li><li>情感归属 – 指跟随自己的偶像，明星，希望获取更多相关的信息</li></ul><p>首先，感到大部分人不习惯自己去主动寻求信息的，或者说，是不太清楚自己应该主动获取什么样的信息，因此app的主动推送，人被选择适时而生。（IOC 容器了解一下,hhh）</p><p>每个App都有自己的味道，抖音的味道能够吸引来追逐潮流的年轻人。可以在这里看到<strong>和自己类似的人</strong>拍的视频，看到的<strong>美好的世界</strong>。</p><p>抖音一定程度上满足了用户的自我认知的需求，会觉得抖音和自己很搭(用户画像和自我认知的部分重合)。</p><p>但在社交方面，有点不尽如人意，这也和抖音的整体 – 偏中心化的音乐短视频平台的初始定位有关了。当大部分的高质内容产出出自PGC, MCN的时候，潜在的内容创作者很可能会因为成为热门的高门槛而放弃。大家看自己向往的生活，而不是自己的生活。</p><p>热门视频大部分是有趣的段子，以及同样的素材音乐下的小哥哥小姐姐的表现，同质化有点严重，同时离日常生活的距离着实有点远，这也致使了用户之间的关联感比较差。  </p><p>一个超漂亮的小姐姐在跳舞，你会“哇，太好看了”，但你不知道该回什么，才能够不太尬的认识。因为这些小姐姐可能离你的物理距离还很远是吧~ 可看没法约 </p><p>抖音其实现在有基于地理位置的模块，有种想两手抓的感觉，不知道后台流量如何，只是当用户对于一个平台的定位是 – 去看好玩的搞笑的，去看小哥哥小姐姐的时候，想改变既定的认知，难度不小。想在保持当前定位的同时，加上一个社交属性，好像有些部分是相互有冲突的。</p><p>看到新闻在灰度测试，陌生人视频聊天，增强社交属性，看来是太不活跃，并没有灰度上。不知道具体是怎么样的过程，有没有足够多的对话题的引导，这种带点“阅后即焚”性质的尝试，会不会一不小心跨过监管允许的限制，lol  拭目以待</p><h2 id="3-2-others"><a href="#3-2-others" class="headerlink" title="3.2 others"></a>3.2 others</h2><ul><li>用户集中于一二线城市<ul><li>如何向三四线城市扩张？<ul><li>囧妈 很酷</li><li>大量的广告，代言<ul><li>这种打法在一二线城市很好用，三四线城市呢，联想趣头条 – 我们要最实在的！请给我钱，lol</li></ul></li><li>内容上的倾斜<ul><li>如何生产更多的小镇青年感兴趣的内容？  </li></ul></li></ul></li></ul></li><li>视频创作的门槛与参与热情<ul><li>刺激计划</li><li>培训平台 <ul><li>2019年11月26日上线创作者学院 </li></ul></li></ul></li><li>内容同质化，低俗化<ul><li>当在娱乐化做到很极致的时候(请看抖音app的极快的迭代频率，以及层出不穷的新道具，新玩法)，需要做更加深度的内容么？ </li><li>当知识付费成为新风口，巫师财经，半佛仙人成功出圈以后，有机会将内容浓缩到1-5min的视频当中，来点先导知识，然后再成功引流到长视频网站上？ </li></ul></li><li>弱社交平台<ul><li>社交是保证一个平台用户粘性的护城河，当抖音选择了沉浸式的无限下滑的交互方式的时候，一定程度上，我们可以说是舍弃了社交的 （对比快手的下滑留评，左滑回退的操作）。</li><li>弱社交也可以从留评数据当中可以看出，尽管抖音的日活月活遥遥领先，但留评，点赞是快手占据优势的，互动率要高出很多</li><li>做不做社交？<ul><li>一直无限想做，先出自己的专属app，没做起来，现在直接放到抖音这个国民app里做了</li></ul></li><li>为什么想做？<ul><li>社交，粘性，带货，看看快手的带货数据，贼酷炫</li><li>社交 - 附近的人 - 一张美丽的类似美团的外卖带动基于地理位置的其他业务的美妙构想</li></ul></li><li>concern<ul><li>社交注定是需要带点“平均人” 的理念的，这不仅仅需要接口，路径，交互方式的改变，更是内容分发逻辑，视频创作方式上的改变。那问题来了，社交有多重要，重要到改变整个平台的现有定位，重要到可能会降低一些格调，少一些fancy，多点生活气息么？ </li></ul></li></ul></li><li>算法 信息茧房<ul><li>用户喜欢的信息和信息广度的tradeoff，算法的单个方向上的相对极致优化，会缩减用户能够接受到的信息范围的</li><li>依旧是平台算法优化的问题了，到底给用户留出多少自己的空间呢？ </li></ul></li><li>政策的限制/要求 - 娱乐属性，社会属性，深入的思考性的东西很少<ul><li>嗯，是这样的~  </li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="http://www.woshipm.com/evaluating/994454.html" target="_blank" rel="noopener">http://www.woshipm.com/evaluating/994454.html</a> </li><li><a href="https://tools.lancely.tech/apple/app-version/cn/1142110895" target="_blank" rel="noopener">https://tools.lancely.tech/apple/app-version/cn/1142110895</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thought </tag>
            
            <tag> 抖音 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>构建React的想法 - from sebmarkbage</title>
      <link href="/%E6%9E%84%E5%BB%BAReact%E7%9A%84%E6%83%B3%E6%B3%95-from-sebmarkbage/"/>
      <url>/%E6%9E%84%E5%BB%BAReact%E7%9A%84%E6%83%B3%E6%B3%95-from-sebmarkbage/</url>
      
        <content type="html"><![CDATA[<p>从github翻到的论述，是React设计者试图说明其构建React的整个逻辑。</p><h1 id="1-转换-Transformation"><a href="#1-转换-Transformation" class="headerlink" title="1. 转换 - Transformation"></a>1. 转换 - Transformation</h1><p>React的核心假定是UI层实际上是对数据的展现形式的一种转换。同样的输入会给出同样的输出结果，只是表现形式可能会有所区别。</p><pre><code>function NameBox(name) {  return { fontWeight: &#39;bold&#39;, labelContent: name };}&#39;Sebastian Markbåge&#39; -&gt;{ fontWeight: &#39;bold&#39;, labelContent: &#39;Sebastian Markbåge&#39; };</code></pre><h1 id="2-抽象-Abstraction"><a href="#2-抽象-Abstraction" class="headerlink" title="2. 抽象 - Abstraction"></a>2. 抽象 - Abstraction</h1><p>我们无法将一个复杂的UI放到一个方法当中的。将UI抽象到各个可以复用的组件当中就变得尤为重要。抽象成可复用的组件，并且隐藏实现的细节，是我们想要做的。</p><pre><code>function FancyUserBox(user) {  return {    borderStyle: &#39;1px solid blue&#39;,    childContent: [      &#39;Name: &#39;,      NameBox(user.firstName + &#39; &#39; + user.lastName)    ]  };}{ firstName: &#39;Sebastian&#39;, lastName: &#39;Markbåge&#39; } -&gt;{  borderStyle: &#39;1px solid blue&#39;,  childContent: [    &#39;Name: &#39;,    { fontWeight: &#39;bold&#39;, labelContent: &#39;Sebastian Markbåge&#39; }  ]};</code></pre><h1 id="3-组合-Composition"><a href="#3-组合-Composition" class="headerlink" title="3. 组合 - Composition"></a>3. 组合 - Composition</h1><p>为了实现真正可以复用的特性，仅仅使用细分的子功能，并且每次给他们构建容器是不太够的。我们需要能够建立中间层的抽象，即将几个子功能组件组合起来，形成另一层次的组件。这里的组合就是指将多个抽象融合成一个抽象的能力。</p><pre><code>function FancyBox(children) {  return {    borderStyle: &#39;1px solid blue&#39;,    children: children  };}function UserBox(user) {  return FancyBox([    &#39;Name: &#39;,    NameBox(user.firstName + &#39; &#39; + user.lastName)  ]);}</code></pre><h1 id="4-状态-State"><a href="#4-状态-State" class="headerlink" title="4. 状态 - State"></a>4. 状态 - State</h1><p>UI不仅仅是服务器以及商业逻辑的复制，实际上是有很多状态，是服务于特定的运行过程的。比如你在一个文本框输入内容，那么我们需要一些方式能够记录下这个文本框当前的状态，并且用这个状态去和后端进或者其他的方法进行交互。</p><p>我们希望我们的数据是immutable的</p><pre><code>function FancyNameBox(user, likes, onClick) {  return FancyBox([    &#39;Name: &#39;, NameBox(user.firstName + &#39; &#39; + user.lastName),    &#39;Likes: &#39;, LikeBox(likes),    LikeButton(onClick)  ]);}// Implementation Detailsvar likes = 0;function addOneMoreLike() {  likes++;  rerender();}// InitFancyNameBox(  { firstName: &#39;Sebastian&#39;, lastName: &#39;Markbåge&#39; },  likes,  addOneMoreLike);</code></pre><h1 id="5-记忆方法"><a href="#5-记忆方法" class="headerlink" title="5. 记忆方法"></a>5. 记忆方法</h1><p>如果我们知道这是个纯方法，并且还会重复的call它，那么我们可以设计一个记忆版本的方法，这样我们就不用在有相同的数据(输入)的时候还要重复执行了</p><pre><code>function memoize(fn) {  var cachedArg;  var cachedResult;  return function(arg) {    if (cachedArg === arg) {      return cachedResult;    }    cachedArg = arg;    cachedResult = fn(arg);    return cachedResult;  };}var MemoizedNameBox = memoize(NameBox);function NameAndAgeBox(user, currentTime) {  return FancyBox([    &#39;Name: &#39;,    MemoizedNameBox(user.firstName + &#39; &#39; + user.lastName),    &#39;Age in milliseconds: &#39;,    currentTime - user.dateOfBirth  ]);}// 我们同样可以不仅仅记一个值，也可以记一个mapfunction memoize(fn) {  return function(arg, memoizationCache) {    if (memoizationCache.arg === arg) {      return memoizationCache.result;    }    const result = fn(arg);    memoizationCache.arg = arg;    memoizationCache.result = result;    return result;  };}function FancyBoxWithState(  children,  stateMap,  updateState,  memoizationCache) {  return FancyBox(    children.map(child =&gt; child.continuation(      stateMap.get(child.key),      updateState,      memoizationCache.get(child.key)    ))  );}const MemoizedFancyNameBox = memoize(FancyNameBox);</code></pre><h1 id="6-列表"><a href="#6-列表" class="headerlink" title="6. 列表"></a>6. 列表</h1><p>大部分的UI都是一些形式的列表，然后为在列表中的每个元素产出不同的一系列的值。这就自然的产生了一个有层级的结构。</p><p>我们可以通过使用Map方法来管理每个列表当中的元素的状态。</p><pre><code>function UserList(users, likesPerUser, updateUserLikes) {  return users.map(user =&gt; FancyNameBox(    user,    likesPerUser.get(user.id),    () =&gt; updateUserLikes(user.id, likesPerUser.get(user.id) + 1)  ));}var likesPerUser = new Map();function updateUserLikes(id, likeCount) {  likesPerUser.set(id, likeCount);  rerender();}UserList(data.users, likesPerUser, updateUserLikes);</code></pre><h1 id="7-持续性"><a href="#7-持续性" class="headerlink" title="7. 持续性"></a>7. 持续性</h1><p>一些时候，我们在运行我们的核心商业逻辑的时候会大量的操作数据，这部分关于数据的操作会显得有些冗余，我们可以将其移出核心逻辑的代码块，比如使用bind，来绑定方法，在其他地方写具体的代码逻辑。</p><pre><code>function FancyUserList(users) {  return FancyBox(    UserList.bind(null, users)  );}const box = FancyUserList(data.users);const resolvedChildren = box.children(likesPerUser, updateUserLikes);const resolvedBox = {  ...box,  children: resolvedChildren};</code></pre><h1 id="8-状态Map"><a href="#8-状态Map" class="headerlink" title="8. 状态Map"></a>8. 状态Map</h1><p>我们可以用组合来将几个子组件放在一起来使用，同样的，对于他们需要的一些输入数据，我们可以通过state，来传到下层的方法处，供他们使用。</p><pre><code>function FancyBoxWithState(  children,  stateMap,  updateState) {  return FancyBox(    children.map(child =&gt; child.continuation(      stateMap.get(child.key),      updateState    ))  );}function UserList(users) {  return users.map(user =&gt; {    continuation: FancyNameBox.bind(null, user),    key: user.id  });}function FancyUserList(users) {  return FancyBoxWithState.bind(null,    UserList(users)  );}const continuation = FancyUserList(data.users);continuation(likesPerUser, updateUserLikes);</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://github.com/reactjs/react-basic" target="_blank" rel="noopener">https://github.com/reactjs/react-basic</a></p>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何知道用户是否在使用Adblocker</title>
      <link href="/%E5%A6%82%E4%BD%95%E7%9F%A5%E9%81%93%E7%94%A8%E6%88%B7%E6%98%AF%E5%90%A6%E5%9C%A8%E4%BD%BF%E7%94%A8Adblocker/"/>
      <url>/%E5%A6%82%E4%BD%95%E7%9F%A5%E9%81%93%E7%94%A8%E6%88%B7%E6%98%AF%E5%90%A6%E5%9C%A8%E4%BD%BF%E7%94%A8Adblocker/</url>
      
        <content type="html"><![CDATA[<p>广告监测和屏蔽是很好的功能，而Ad-blocker基本是市面上做屏蔽广告插件的翘楚了。根据GlobalWebIndex在2019年五月做的统计，现在有47% 的用户正在使用广告屏蔽的软件。</p><p>作为网站管理者，你可以做一个pop up 的信息框，希望用户能够停止对于广告的屏蔽，或者你可以直接不允许用户来访问页面，知道去除了广告屏蔽之后。</p><p>那么如何知道用户是否在使用AbBlocker呢，这里需要了解下adblocker的运行机制，广告屏蔽的运行依赖于过滤规则(filter rules)， adblock会将你正在访问的URL和过滤列表相比较，如果匹配，那么这个请求就会被屏蔽掉。</p><p>但是还有部分的广告是不会发起一个HTTP请求，相对应的，他们会使用<code>data:image/png</code>这种方式来加载广告，对于这种广告，AdBlock 在每个页面都会插入一个样式表，然后这个样式表包括选择器，来display:none 通过这种方式来隐藏页面上的广告</p><p>而这些屏蔽列表来自于一些过去的积累，譬如：</p><ul><li><a href="https://easylist.to/" target="_blank" rel="noopener">Easylist</a></li><li><a href="https://help.getadblock.com/support/solutions/articles/6000092027-why-am-i-suddenly-seeing-taboola-outbrain-and-google-ads-" target="_blank" rel="noopener">accesptable list</a></li></ul><p>除此以外，adblocker还会检测前端调用的js文件，如果还有ad关键词，也会直接屏蔽，所以我们可以直接使用命名，来做一个简单的判断。</p><pre><code>// 创建名为ads.js的文件isAdBlockActive = false;// 创建script.jsvar AdBlocker = (function () {    function showModal() {        $(&#39;#modal_ad_blocker&#39;).modal(); // show a message to the user when ads are blocked    }    setInterval(function () {        // Get the first AdSense ad unit on the page        var ad = document.querySelector(&quot;ins.adsbygoogle&quot;);        // If the ads.js or the Google ads are not loaded, show modal and track the event        if (typeof isAdBlockActive === &#39;undefined&#39;            || (ad &amp;&amp; ad.innerHTML.replace(/\s/g, &quot;&quot;).length === 0)) {            showModal();            if (typeof ga !== &#39;undefined&#39;) {                // Log an event in Universal Analytics                // but without affecting overall bounce rate                ga(&#39;send&#39;, &#39;event&#39;, &#39;Adblock&#39;, &#39;Yes&#39;, {&#39;nonInteraction&#39;: 1});            } else if (typeof _gaq !== &#39;undefined&#39;) {                // Log a non-interactive event in old Google Analytics                _gaq.push([&#39;_trackEvent&#39;, &#39;Adblock&#39;, &#39;Yes&#39;, undefined, undefined, true]);            }        }    }, 5000); // check every 5 seconds})();</code></pre><p>通过检测我们在ads.js当中定义的isAdBlockActive 是否能够被检测到(undefined or have some value)。我们就可以看出是否有adBlocker正在运行，然后根据检测结果我们可以给用户提醒，或者直接阻止访问。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://blog.rampatra.com/how-to-know-whether-a-user-is-using-an-adblocker" target="_blank" rel="noopener">https://blog.rampatra.com/how-to-know-whether-a-user-is-using-an-adblocker</a> </li><li><a href="https://help.getadblock.com/support/solutions/articles/6000087914-how-does-adblock-work-" target="_blank" rel="noopener">https://help.getadblock.com/support/solutions/articles/6000087914-how-does-adblock-work-</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tricks </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Log4j2 Tutorial </title>
      <link href="/Log4j2-Tutorial/"/>
      <url>/Log4j2-Tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Log4j2-overview"><a href="#1-Log4j2-overview" class="headerlink" title="1. Log4j2 overview"></a>1. Log4j2 overview</h1><h2 id="1-1-Why-log"><a href="#1-1-Why-log" class="headerlink" title="1.1 Why log?"></a>1.1 Why log?</h2><p>Logging is an important component of the development cycle. </p><ul><li>provides precise context about a run of the application </li><li>once inserted into code, the generation of logging output requires no human intervention </li><li>moreover, log output can be saved in persistent medium to be studied at a later time </li></ul><h2 id="1-2-Why-Log4j2"><a href="#1-2-Why-Log4j2" class="headerlink" title="1.2 Why Log4j2?"></a>1.2 Why Log4j2?</h2><ul><li>Designed to be usable as an audit logging framework , will not lose events while reconfiguring </li><li>Contains asynchrounous loggers, which is 10 times faster than log4j 1.x and logback </li><li>Garbage free for stand alone applications </li><li>Use a plugin system that makes it easy to extend the framework by adding new appenders, filters, layouts, lookups, and pattern converters</li><li>Support for custom log levels </li></ul><h2 id="1-3-Log4j-Architecture"><a href="#1-3-Log4j-Architecture" class="headerlink" title="1.3 Log4j Architecture"></a>1.3 Log4j Architecture</h2><p><img src="https://i.loli.net/2020/04/02/AsXomqJciUyPVKh.jpg" alt="Log4jClasses.jpg"> </p><p>Applications using the Log4j 2 API will request <strong>a Logger with a specific name from the LogManager</strong>. The LogManager will <strong>locate the appropriate LoggerContext</strong> and then obtain the Logger from it. If the Logger must be created it will <strong>be associated with the LoggerConfig</strong> that contains either a) the same name as the Logger, b) the name of a parent package, or c) the root LoggerConfig. LoggerConfig objects are created from Logger declarations in the configuration. The LoggerConfig is associated with the Appenders that actually deliver the LogEvents.</p><ul><li>Filter <ul><li>apply in different time point <ul><li>before control is passed to any loggerConfig</li><li>after control is passed to a LoggerConfig but before calling any Appenders</li><li>after control is passed to a LoggerConfig but before calling a specific Appender</li><li>on each Appender</li></ul></li></ul></li><li>Appender <ul><li>selectively enable or disable logging requests</li><li>allow logging requests to print to multiple destinations </li></ul></li><li>Layout <ul><li>Used to customize the output format </li><li>Associate a layout with an appender </li></ul></li></ul><h1 id="2-Migration-from-Log4j-to-Log4j2"><a href="#2-Migration-from-Log4j-to-Log4j2" class="headerlink" title="2. Migration from Log4j to Log4j2"></a>2. Migration from Log4j to Log4j2</h1><p>We usually use log4j/ log4j2 with Slf4j, Slf4j is kind of like a connecter, you could use slf4j as logging system, and slf4j could help you connect to logging framework you want to use: like logback, log4j2, commons-logging, etc. </p><p><a href="https://logging.apache.org/log4j/2.x/manual/migration.html" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/manual/migration.html</a> </p><p>Look at sample 1 in above link for how to set up basic configuration </p><p>For some tips: </p><ul><li>The main package in version 1 is org.apache.log4j, in version 2 it is org.apache.logging.log4j</li><li>Calls to org.apache.log4j.Logger.getLogger() must be modified to org.apache.logging.log4j.LogManager.getLogger().</li><li>Calls to org.apache.log4j.Logger.getRootLogger() or org.apache.log4j.LogManager.getRootLogger() must be replaced with org.apache.logging.log4j.LogManager.getRootLogger().</li><li>Calls to org.apache.log4j.Logger.getLogger that accept a LoggerFactory must remove the org.apache.log4j.spi.LoggerFactory and use one of Log4j 2’s other extension mechanisms.</li><li>Replace calls to org.apache.log4j.Logger.getEffectiveLevel() with org.apache.logging.log4j.Logger.getLevel().</li><li>Remove calls to org.apache.log4j.LogManager.shutdown(), they are not needed in version 2 because the Log4j Core now automatically adds a JVM shutdown hook on start up to perform any Core clean ups.<ul><li>Starting in Log4j 2.1, you can specify a custom ShutdownCallbackRegistry to override the default JVM shutdown hook strategy.</li><li>Starting in Log4j 2.6, you can now use org.apache.logging.log4j.LogManager.shutdown() to initiate shutdown manually.</li></ul></li><li>Calls to org.apache.log4j.Logger.setLevel() or similar methods are not supported in the API. Applications should remove these. Equivalent functionality is provided in the Log4j 2 implementation classes, see org.apache.logging.log4j.core.config.Configurator.setLevel(), but may leave the application susceptible to changes in Log4j 2 internals.</li><li>Where appropriate, applications should convert to use parameterized messages instead of String concatenation.</li><li>org.apache.log4j.MDC and org.apache.log4j.NDC have been replaced by the Thread Context.</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://logging.apache.org/log4j/2.x/manual/migration.html" target="_blank" rel="noopener">https://logging.apache.org/log4j/2.x/manual/migration.html</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Amazon RDS Onboard - MySQL </title>
      <link href="/Amazon-RDS-Onboard-MySQL/"/>
      <url>/Amazon-RDS-Onboard-MySQL/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>Amazon Relational Databazse Service </p><ul><li>provide cost efficient, resizable capacity for relational database and manage common database administration tasks </li><li>CPU, memory, storage, IOPS can be scaled independently </li><li>help you manage backups, software patching, automatic failure detection, and recovery </li><li>Automated backups </li><li>Can get high availability with a primary instance and synchronous secondary instance that you can fail over to when problems occur.</li><li>Integrate with IAM and VPC settings</li></ul><h2 id="1-1-How-does-amazon-help-you-do-the-setup"><a href="#1-1-How-does-amazon-help-you-do-the-setup" class="headerlink" title="1.1 How does amazon help you do the setup?"></a>1.1 How does amazon help you do the setup?</h2><p>Overall, you control your database by using DB instance, you could select different kind of host with different configuration, AWS will help you to deploy it in your selected region, and it will be automatically deployed to different AZ, to increase availability. Let’s go through it in detail. </p><h3 id="1-1-1-DB-Instances"><a href="#1-1-1-DB-Instances" class="headerlink" title="1.1.1 DB Instances"></a>1.1.1 DB Instances</h3><ul><li><p>An isolated database env in the AWS Cloud </p></li><li><p>One instance can contain multiple user-created databases </p></li><li><p>Each DB instance runs one DB engine, for DB engine, we mean MySQL, MariaDB, PostgreSQL, etc. </p></li><li><p>You could change your selected computation and memory capacity by using <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html" target="_blank" rel="noopener">DB instance class</a>.</p></li><li><p>You could choose to use multiple availability zones, AZ is engineered to be isolated from failures in other AZs, by launching instances in separate AZs, you can protect your applications from the failure of a single location</p><h3 id="1-1-2-Basic-setup"><a href="#1-1-2-Basic-setup" class="headerlink" title="1.1.2 Basic setup"></a>1.1.2 Basic setup</h3></li><li><p>AWS account </p></li><li><p>IAM user </p></li></ul><h1 id="2-MySQL-on-RDS"><a href="#2-MySQL-on-RDS" class="headerlink" title="2. MySQL on RDS"></a>2. MySQL on RDS</h1><h2 id="2-1-Manage-security-for-DB-instance"><a href="#2-1-Manage-security-for-DB-instance" class="headerlink" title="2.1 Manage security for DB instance"></a>2.1 Manage security for DB instance</h2><h3 id="2-1-1-Security-Overview"><a href="#2-1-1-Security-Overview" class="headerlink" title="2.1.1 Security Overview"></a>2.1.1 Security Overview</h3><ul><li>Run DB instance in a vertual private cloud based on the Amazon VPC service </li><li>Use AWS Identity and Access Management policies to assign permissions that determine who is allowed to manage Amazon RDS resrouces </li><li>Use security groups to control what IP addresses or Amazon EC2 instances can connect to your databases on a DB instance</li><li>Use SSL or TLS connections with DB instances <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html" target="_blank" rel="noopener">Instructions</a></li><li>Use Amazon RDS encryption to secure DB instances and snapshots at rest. It used AES-256 encryption algorithm to encrypt data on the server that hosts DB instance</li></ul><h3 id="2-1-2-Manage-access-with-Policies-resource-level"><a href="#2-1-2-Manage-access-with-Policies-resource-level" class="headerlink" title="2.1.2 Manage access with Policies - resource level"></a>2.1.2 Manage access with Policies - resource level</h3><ul><li>A poloicy is an object that associated with an identity or resource, defines their permissions. </li><li>An IAM administrator could use policies to specify who has access to AWS resources, and what actions they can perform on the resources </li></ul><h3 id="2-1-3-Access-control-in-DB-instance-level-security-group"><a href="#2-1-3-Access-control-in-DB-instance-level-security-group" class="headerlink" title="2.1.3 Access control in DB instance level - security group"></a>2.1.3 Access control in DB instance level - security group</h3><ul><li>Security groups control the access that traffic has in and out of a DB instance <ul><li>VPC security groups </li><li>DB security groups</li><li>EC2-classic security groups </li></ul></li><li>VPC security group<ul><li>enable a specific source to access a DB instance in a VPC in the security group </li><li>source could be: <ul><li>a range of addresses </li><li>another VPC security group </li></ul></li></ul></li><li>DB security group <ul><li>Used with DB instances that are not in a VPC and on the EC2 classic platform  </li><li>DB security group rules apply to inbound traffic only </li><li>You don’t need to specify port number or protocol when adding rules </li></ul></li></ul><h2 id="2-2-Connect-to-DB-instance"><a href="#2-2-Connect-to-DB-instance" class="headerlink" title="2.2 Connect to DB instance"></a>2.2 Connect to DB instance</h2><ul><li>Create DB instance as prerequisite </li><li>Use MySQL client application or utility to connect to the instance</li><li>Specify DNS address from the DB instance endpoint as the host parameter, specify the port number from DB instance endpoint as the port parameter </li><li>For endpoint, we could find in AWS console, on the “connectivity &amp; security” tab </li><li>To  connect from MySQL client, using command shown as below<ul><li><code>mysql -h mysql–instance1.123456789012.us-east-1.rds.amazonaws.com -P 3306 -u mymasteruser -p</code></li></ul></li><li>Amazon RDS creates an SSL certificate for your DB instance when the instance is created     + you could do it with native password or with IAM authentication <ul><li><code>mysql -h mysql–instance1.123456789012.us-east-1.rds.amazonaws.com --ssl-ca=rds-ca-2015-root.pem -p</code> </li></ul></li><li>we could also connect from MySQL workbench <ul><li>See instructions on <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ConnectToInstance.html" target="_blank" rel="noopener">Connnecting from MySQL Workbench</a> </li></ul></li></ul><h2 id="2-3-Configure-high-availability-for-a-production-DB-instance"><a href="#2-3-Configure-high-availability-for-a-production-DB-instance" class="headerlink" title="2.3 Configure high availability for a production DB instance"></a>2.3 Configure high availability for a production DB instance</h2><p>Amazon help you do this with Multi-AZ deployments. SQL server DB instances use SQL server Database Mirroring or Always On Availability Groups. </p><p>In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. The primary DB instance is synchronously replicated across Availability Zones to a standby replica to provide data redundancy, eliminate I/O freezes, and minimize latency spikes during system backups. Running a DB instance with high availability can enhance availability during planned system maintenance, and help protect your databases against DB instance failure and Availability Zone disruption.</p><p>The high availability feature is not scaling solution for read-only scenarios, you cannot use a standby replica to serve read traffic. </p><p>NOTICE – DB instances using Multi-AZ deployments can have increased write and commit latency compared to a Single-AZ depolyment, due to the synchrounous data replication that occurs. </p><p>In the event of a planned or unplanned outage of your DB instance, Amazon RDS automatically switches to a standby replica in another Availability Zone if you have enabled Multi-AZ. The time it takes for the failover to complete depends on the database activity and other conditions at the time the primary DB instance became unavailable. Failover times are typically 60–120 seconds. However, large transactions or a lengthy recovery process can increase failover time. When the failover is complete, it can take additional time for the RDS console to reflect the new Availability Zone.</p><h2 id="2-4-Configure-a-DB-instance-in-VPC"><a href="#2-4-Configure-a-DB-instance-in-VPC" class="headerlink" title="2.4 Configure a DB instance in VPC"></a>2.4 Configure a DB instance in VPC</h2><ul><li>VPC is a virtual network that is logically isolated from other virtual networks in the AWS cloud. Amazon VPC lets you launch AWS resources into a VPC. </li><li>VPC must have at least 2 subnets. And those subnets must be in two different AZs </li><li>If you want DB instance in the VPC to be publicly accessible, you must enable the VPC attributes DNS hostnames and DNS resolution </li></ul><h2 id="2-5-Configure-MySQL-database-parameters-and-features"><a href="#2-5-Configure-MySQL-database-parameters-and-features" class="headerlink" title="2.5 Configure MySQL database parameters and features"></a>2.5 Configure MySQL database parameters and features</h2><ul><li>Manage DB engine configuration by associating DB instances with parameter groups. A DB parameter group act as a container for engine configuration values that are applied to one or more DB instances </li><li>For MySQL, AWS has memcached support </li></ul><h2 id="2-6-Modify-a-DB-instance-running-the-MySQL-database-engine"><a href="#2-6-Modify-a-DB-instance-running-the-MySQL-database-engine" class="headerlink" title="2.6 Modify a DB instance running the MySQL database engine"></a>2.6 Modify a DB instance running the MySQL database engine</h2><ul><li>We could change the settings of a DB instance to add additional storage or changing the DB instance class </li><li>Notice: some cahnges will result in an outage because Amazon RDS must reboot DB instance for the change to take effect <ul><li>We could either modify through AWS console</li><li>Or through AWS CLI</li><li>Or through RDS API </li></ul></li><li>we could do settings as follow:<ul><li>Allocate storage </li><li>Auto minor version upgrade </li><li>Backup retention period <ul><li>number of days that automatic backups are retained </li></ul></li><li>Backup window </li><li>Certificate Authority </li><li>Database port </li><li>DB engine version </li><li>DB instance class </li><li>DB parameter group </li><li>Delete protection <ul><li>prevent your DB from being deleted  </li></ul></li><li>Enhanced Monitoring </li><li>IAM DB authentication </li><li>Kerberos authentication </li><li>License Model </li><li>Log Exports <ul><li>We could publish Database logs to Amazon Cloudwatch logs </li></ul></li><li>Maintenance window </li><li>Multi-AZ deployment </li><li>Performance Insight </li><li>Processor features </li><li>Provisioned IOPS </li><li>Storage auto scaling </li><li>Subnet group </li></ul></li></ul><h2 id="2-7-Configure-database-backup-and-restore"><a href="#2-7-Configure-database-backup-and-restore" class="headerlink" title="2.7 Configure database backup and restore"></a>2.7 Configure database backup and restore</h2><ul><li>Amazon RDS creates and saves automated backups of your DB instance</li><li>RDS creates a storage volume snapshot of DB instance, backing up entire DB instance </li><li>The first snapshot of a DB instance contains the data for the full DB instance. Subsequent snapshots of the same DB instance are incremental, which means that only the data that has changed after your most recent snapshot is saved.</li><li><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_CommonTasks.BackupRestore.html" target="_blank" rel="noopener">Guide for backup and restore an Amazon RDS DB instance</a></li></ul><h2 id="2-8-Monitor-a-MySQL-DB-instance"><a href="#2-8-Monitor-a-MySQL-DB-instance" class="headerlink" title="2.8 Monitor a MySQL DB instance"></a>2.8 Monitor a MySQL DB instance</h2><h3 id="2-8-1-Overview"><a href="#2-8-1-Overview" class="headerlink" title="2.8.1 Overview"></a>2.8.1 Overview</h3><ul><li><p>We should store historical monitoring data, the stored data will gove a baseline to compare against with current performance data</p></li><li><p>With Amazon RDS, you could monitor network throughput, I/O for read and write, metadata operations, client connections</p></li><li><p>Some adviced metrics </p><ul><li>High CPU or RAM consumption </li><li>Disk space consumption </li><li>Network traffic </li><li>Database connections </li><li>IOPS metrics </li></ul></li><li><p>Monitoring Tools </p><ul><li>Amazon RDS Events <ul><li>subscribe to events thus could be notified when changes occur with a DB instance </li></ul></li><li>Database log files</li><li>Amazon RDS Enhanced Monitoring<ul><li>Look at the metrics in real time for the operating system</li></ul></li><li>Amazon CloudWatch Metrics </li><li>Amazon CloudWatch Alarms</li><li>Amazon CloudWatch Logs </li><li>In RDS console, you could see: <ul><li>the number of connections to a DB instance </li><li>the amount of read and write operations to a DB instance </li><li>the amount of storage that a DB instance is currently utilizing </li><li>the amount of memory and CPU being utilized for a DB instance </li><li>the amount of network traffic to and from a DB instance </li></ul></li></ul></li><li><p>Amazon RDS Metrics </p><ul><li>CPUCreditUsage <ul><li>The number of CPU credits spent by the instance for CPU utilization. One CPU credit equals one vCPU running at 100 percent utilization for one minute or an equivalent combination of vCPUs, utilization, and time.</li></ul></li><li>DatabaseConnections</li><li>DiskQueueDepth <ul><li>the number of outstanding IOs waiting to access the disk</li></ul></li><li>FailedSQLServerAgentJobsCount <ul><li>the numebr of failed SQL server agent jobs during the last minute </li></ul></li><li>ReadIOPS <ul><li>the average number of disk read I/O operations per second</li></ul></li><li>ReadLatency <ul><li>the average amount to time taken per disk I/O operation  </li></ul></li></ul></li></ul><h3 id="2-8-2-Enhanced-Monitoring"><a href="#2-8-2-Enhanced-Monitoring" class="headerlink" title="2.8.2 Enhanced Monitoring"></a>2.8.2 Enhanced Monitoring</h3><p>Real time metrics for the operating system</p><p>CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance, and Enhanced Monitoring gathers its metrics from an agent on the instance. As a result, you might find differences between the measurements, because the hypervisor layer performs a small amount of work. The differences can be greater if your DB instances use smaller instance classes, because then there are likely more virtual machines (VMs) that are managed by the hypervisor layer on a single physical instance. Enhanced Monitoring metrics are useful when you want to see how different processes or threads on a DB instance use the CPU</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://docs.aws.amazon.com/AmazonRDS" target="_blank" rel="noopener">https://docs.aws.amazon.com/AmazonRDS</a> </li><li><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_MySQL.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_MySQL.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> RDS </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring @Transactional</title>
      <link href="/Spring-Transactional/"/>
      <url>/Spring-Transactional/</url>
      
        <content type="html"><![CDATA[<p>Spring的Transactional注解用来做事务管理</p><h1 id="1-使用方法"><a href="#1-使用方法" class="headerlink" title="1. 使用方法"></a>1. 使用方法</h1><p>首先我们需要在xml当中配置事务信息，定义transactionManager的bean，当然也可以使用注解来实现对于bean的定义，具体如下：</p><pre><code>&lt;tx:annotation-driven /&gt;&lt;bean id=&quot;transactionManager&quot;class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;&lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt;@EnableTransactionManagement</code></pre><p>而后，在具体的使用的时候，我们只需要将@Transactional注解添加到合适的方法当中，并且设置合适的属性信息</p><ul><li>name<ul><li>指定事务管理器</li></ul></li><li>propagation<ul><li>事务的传播行为，默认为REQUIRED</li></ul></li><li>isolation <ul><li>事务的隔离度，默认为DEFAULT</li></ul></li><li>timeout<ul><li>事务的超时时间，默认为-1，如果超过该时间限制但事务没有完成，就自动回滚</li></ul></li><li>read-only<ul><li>指定事务是否为只读事务，默认值为false</li><li>当要忽略那些不需要事务的方法的时候，可以设置read-only为true</li></ul></li><li>rollback-for<ul><li>指定能够触发事务回滚的异常类型，如果有多个异常类型需要指定，可以通过逗号来做分隔</li></ul></li><li>no-rollback-for<ul><li>对于在这里定义的exception，不回滚 </li></ul></li></ul><h1 id="2-Spring-注解方式的事务实现机制"><a href="#2-Spring-注解方式的事务实现机制" class="headerlink" title="2. Spring 注解方式的事务实现机制"></a>2. Spring 注解方式的事务实现机制</h1><p>在调用@Transactional的目标方法之后，Spring Framework会通过AOP代理，在代码运行时生成一个代理对象，根据注解的属性配置信息，决定该声明@Transactional的目标方法是否由拦截器 - TransactionInterceptor来拦截.</p><p>如果确定要被拦截，那么就会在目标方法开始执行之前创建并加入事务，并执行目标方法的逻辑，最后根据执行情况是否出现异常，利用抽象事务管理器提交或者回滚事务。</p><p><img src="https://i.loli.net/2020/03/25/cM5yEjbPAIogk1X.jpg" alt="Spring事务实现机制.jpg"></p><h1 id="3-Isolation-Level"><a href="#3-Isolation-Level" class="headerlink" title="3. Isolation Level"></a>3. Isolation Level</h1><p>Isolation是有不同的配置的，它主要是为了避免事务的一些副作用：</p><ul><li>脏读：读到同时进行的事务还没有提交上去的数据</li><li>不可重复的读：重复读的时候会读到不同的数据，因为有同时进行的事务对同一条数据进行了更新</li><li>幽灵读取：在做query的时候，再度执行拿到不同的行，因为有同时进行的事务在做更新</li></ul><p>针对不同级别的事务，Spring有如下的设置</p><ul><li>DEFAULT</li><li>READ_UNCOMMITTED<ul><li>最低的隔离水平 </li><li>允许大部分的同时的访问</li><li>有上述所有的弊端</li></ul></li><li>READ_COMMMITED<ul><li>阻止脏读 </li></ul></li><li>REPEATABLE_READ<ul><li>阻止脏读</li><li>阻止不可重复读取</li></ul></li><li>SERAILIZABLE<ul><li>最高程度的隔离</li><li>基本是单序列的执行</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/transaction/annotation/Transactional.html" target="_blank" rel="noopener">https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/transaction/annotation/Transactional.html</a></li><li><a href="https://dzone.com/articles/how-does-spring-transactional" target="_blank" rel="noopener">https://dzone.com/articles/how-does-spring-transactional</a></li><li><a href="https://www.ibm.com/developerworks/cn/java/j-master-spring-transactional-use/index.html" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/java/j-master-spring-transactional-use/index.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>团队能力构建手册-新人Ramp Up</title>
      <link href="/%E5%9B%A2%E9%98%9F%E8%83%BD%E5%8A%9B%E6%9E%84%E5%BB%BA%E6%89%8B%E5%86%8C-%E6%96%B0%E4%BA%BARamp-Up/"/>
      <url>/%E5%9B%A2%E9%98%9F%E8%83%BD%E5%8A%9B%E6%9E%84%E5%BB%BA%E6%89%8B%E5%86%8C-%E6%96%B0%E4%BA%BARamp-Up/</url>
      
        <content type="html"><![CDATA[<p>这篇博客引述了ThoughtWorks的<a href="https://insights.thoughtworks.cn/capacity-building-and-quality-assurance/" target="_blank" rel="noopener">capacity-building-and-quality-assurance</a>，里面讲得如何构建团队，如何让新人快速适应的方法指南非常实用。分享/ 思考/ 归纳如下。</p><p>自己所在的团队最近也经历了快速的增长，在带新人的过程当中，确实感觉到想一茬抓一茬是客观存在且经常性发生的事情，lol。需要一个更加清晰细致的上手指南，并把一些需要的前提条件先给到，然后给新人留下在正确的方向上足够的探索空间，这样大概才能加速他们的成长把。</p><p>我们当然需要每个个体的无上才能，但更需要一个好的平台，让他们能够专注的将自己的才能用在那个地方。而平台，意味着脚手架，意味着规则，意味着指南。</p><h1 id="1-常规新人成长方式-Mentor-Onboarding-Buddy"><a href="#1-常规新人成长方式-Mentor-Onboarding-Buddy" class="headerlink" title="1. 常规新人成长方式 Mentor/ Onboarding Buddy"></a>1. 常规新人成长方式 Mentor/ Onboarding Buddy</h1><p>为新人指派一名有经验的师傅，作为他的onboarding伙伴，平时可以做结对编程，在日常工作当中交换知识，学习并成长。新人onboarding的速度，取决于师傅的技能。</p><p>这么做当然有好处，一定比新人自己探索onboard要快的多，但是正如上面所说的那样，这种方式很依赖于师傅的能力，还有新人的沟通交流，搜集知识的能力。效果会因为每个成员的性格习惯能力等，有很大的不同。</p><h1 id="2-制定规则化的成长流程"><a href="#2-制定规则化的成长流程" class="headerlink" title="2. 制定规则化的成长流程"></a>2. 制定规则化的成长流程</h1><h2 id="2-1-CraftSkill-Map"><a href="#2-1-CraftSkill-Map" class="headerlink" title="2.1 CraftSkill Map"></a>2.1 CraftSkill Map</h2><p>能力地图是希望能够梳理完整的技术图谱，对技术人员需要掌握的能力进行可视化</p><p>新成员在加入项目的时候一般会有很多问题：</p><ul><li>这个项目是做什么的？ </li><li>这个项目是在解决什么样的问题？</li><li>这个项目使用了什么技术栈？</li><li>新成员应该从哪里开始？</li></ul><p>新人onboard，rampup需要的知识是可以分成可以自己学习的知识(通过各种文档，wiki, stackoverflow, etc.)以及需要老人的帮助的知识(需要上手实操的内容，比如设计原则，DRY,SOLID, LOD等等具体如何使用的问题)。</p><p>我们需要新人自己去探索，获取一些必要的前提性知识，也需要有人帮助，帮他迅速适应新的环境。</p><p>能力地图就是希望能够对所需要的知识，做一个清晰的梳理，形成一个脉络，能够使新人onboard的过程更有的放矢一些。</p><p><img src="https://i.loli.net/2020/03/24/JayeLmisObEpdTS.png" alt="craftskill map E.G.png"></p><h2 id="2-2-指定Onboarding流程"><a href="#2-2-指定Onboarding流程" class="headerlink" title="2.2 指定Onboarding流程"></a>2.2 指定Onboarding流程</h2><p>这里主要是要给一个比较详细的计划，告知新人每周要做的事情，更多的是时间上，任务上的安排。</p><p>根据任务，可以侧重学习前端，后端，或者QA方面的领域知识和技能，然后<strong>做一个meeting，将自己学到的完整的和组里的同事分享下，然后可以一起查漏补缺，完善新人的知识体系</strong>。</p><p>值得注意的是Onboarding的流程当中需要有里程碑和执行时间，由资深员工协助制定，然后就可以领取任务，保质保量的独立完成。</p><p>Onboard流程当中，关于自己看的知识，有很多方式可以来做，比如wiki，视频，甚至是音频，起到的作用就是更高速度的学习。这种相对来说比较被动，主动性的学习可以通过Unit test，将知识点转化成Unit test，然后通过单元测试迅速熟悉知识点。</p><h2 id="2-3-新成员状态看板"><a href="#2-3-新成员状态看板" class="headerlink" title="2.3 新成员状态看板"></a>2.3 新成员状态看板</h2><p>每周由mentor负责跟踪观察新人状态，会议追踪，确定新人是否能在一个月的ramp up以后自己独立负责一部分的任务。</p><h2 id="2-4-Case-by-case-针对性培训"><a href="#2-4-Case-by-case-针对性培训" class="headerlink" title="2.4 Case by case 针对性培训"></a>2.4 Case by case 针对性培训</h2><p>根据个人情况来探究如何做提高，是否可以提前交付项目，诸如此类。</p><p><a href="https://insights.thoughtworks.cn/capacity-building-and-quality-assurance/" target="_blank" rel="noopener">https://insights.thoughtworks.cn/capacity-building-and-quality-assurance/</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mentor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>迪米特法则 (LOD) — 高内聚，低耦合</title>
      <link href="/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99-LOD-%E2%80%94-%E9%AB%98%E5%86%85%E8%81%9A%EF%BC%8C%E4%BD%8E%E8%80%A6%E5%90%88/"/>
      <url>/%E8%BF%AA%E7%B1%B3%E7%89%B9%E6%B3%95%E5%88%99-LOD-%E2%80%94-%E9%AB%98%E5%86%85%E8%81%9A%EF%BC%8C%E4%BD%8E%E8%80%A6%E5%90%88/</url>
      
        <content type="html"><![CDATA[<p>高内聚 低耦合是比较通用的设计思想，可以用来指导不同的粒度的代码的设计和开发的工作，比如系统，模块，类，甚至是函数。也可以去使用到不同的开发场景当中，比如微服务，框架，组件，类库等等。</p><p>在这个原则当中，高内聚指的是类本身的设计，低耦合指的是类和类之间的依赖关系的设计。</p><p>迪米特法则，可以称之为The least knowledge principle.<br>Each unit should have only limited knowledge about other units: only units “closely” related to the current unit. Or: Each unit should only talk to its friends; Don’t talk to strangers.</p><h1 id="1-什么是高内聚？"><a href="#1-什么是高内聚？" class="headerlink" title="1. 什么是高内聚？"></a>1. 什么是高内聚？</h1><p>指的是相近的功能应该放到同一个类当中，不相近的功能不要放在同一类。代码集中相对来说就会更加容易维护了。</p><h1 id="2-什么是低耦合？"><a href="#2-什么是低耦合？" class="headerlink" title="2. 什么是低耦合？"></a>2. 什么是低耦合？</h1><p>类和类之间的依赖关系简单清晰，即尽管两个类之间有依赖关系。一个类的代码的改动不会或者很少导致依赖类的代码的改动。</p><h1 id="3-内聚和耦合的关系"><a href="#3-内聚和耦合的关系" class="headerlink" title="3. 内聚和耦合的关系"></a>3. 内聚和耦合的关系</h1><p><img src="https://i.loli.net/2020/03/23/yZVTqaQSgvbtE4l.png" alt="内聚耦合关系.png"></p><p>如图所示，左侧就是很好的高内聚低耦合的范例，我们将类最小化，即每个类只做一件事情，这样子其他依赖就会少很多。在修改或增加功能的时候，就不会对其他的类造成很大的影响。</p><h1 id="4-实战"><a href="#4-实战" class="headerlink" title="4. 实战"></a>4. 实战</h1><pre><code>public class NetworkTransporter {    // 存在问题，NetworkTransporter作为一个底层类，不应该依赖于HtmlRequest类；与之相反的，因为其实他需要的是string address，以及byte的数组，那我们应该直接提供这些primitive type的数据    public Byte[] send(HtmlRequest htmlRequest) {      //...    }}public class HtmlDownloader {  private NetworkTransporter transporter;//通过构造函数或IOC注入  public Html downloadHtml(String url) {  // 根据上面NetworkTransporter我们希望做的改动，这里传入的不应该是HtmlRequest类的实例了    Byte[] rawHtml = transporter.send(new HtmlRequest(url));    return new Html(rawHtml);  }}public class Document {  private Html html;  private String url;  public Document(String url) {    this.url = url;    // downloader.downloadHtml逻辑复杂，不应该放在构造函数当中，也会很不好测试    // 构造函数中使用new来做实例，违反了基于接口而非实现编程的原则    HtmlDownloader downloader = new HtmlDownloader();    this.html = downloader.downloadHtml(url);  }  //...}</code></pre><p>修改以后的代码： </p><pre><code>public class NetworkTransporter {    // 省略属性和其他方法...    public Byte[] send(String address, Byte[] data) {      //...    }}public class HtmlDownloader {  private NetworkTransporter transporter;//通过构造函数或IOC注入  // HtmlDownloader这里也要有相应的修改  public Html downloadHtml(String url) {    HtmlRequest htmlRequest = new HtmlRequest(url);    Byte[] rawHtml = transporter.send(      htmlRequest.getAddress(), htmlRequest.getContent().getBytes());    return new Html(rawHtml);  }}public class Document {  private Html html;  private String url;  public Document(String url, Html html) {    this.html = html;    this.url = url;  }  //...}// 通过一个工厂方法来创建Documentpublic class DocumentFactory {  private HtmlDownloader downloader;  public DocumentFactory(HtmlDownloader downloader) {    this.downloader = downloader;  }  public Document createDocument(String url) {    Html html = downloader.downloadHtml(url);    return new Document(url, html);  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高内聚 </tag>
            
            <tag> 低耦合 </tag>
            
            <tag> 迪米特 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DRY 原则</title>
      <link href="/DRY-%E5%8E%9F%E5%88%99/"/>
      <url>/DRY-%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<p>Don’t repeat yourself </p><h1 id="1-实现逻辑的重复"><a href="#1-实现逻辑的重复" class="headerlink" title="1. 实现逻辑的重复"></a>1. 实现逻辑的重复</h1><pre><code>public class UserAuthenticator {  public void authenticate(String username, String password) {    if (!isValidUsername(username)) {      // ...throw InvalidUsernameException...    }    if (!isValidPassword(password)) {      // ...throw InvalidPasswordException...    }    //...省略其他代码...  }  private boolean isValidUsername(String username) {    // check not null, not empty    if (StringUtils.isBlank(username)) {      return false;    }    // check length: 4~64    int length = username.length();    if (length &lt; 4 || length &gt; 64) {      return false;    }    // contains only lowcase characters    if (!StringUtils.isAllLowerCase(username)) {      return false;    }    // contains only a~z,0~9,dot    for (int i = 0; i &lt; length; ++i) {      char c = username.charAt(i);      if (!(c &gt;= &#39;a&#39; &amp;&amp; c &lt;= &#39;z&#39;) || (c &gt;= &#39;0&#39; &amp;&amp; c &lt;= &#39;9&#39;) || c == &#39;.&#39;) {        return false;      }    }    return true;  }  private boolean isValidPassword(String password) {    // check not null, not empty    if (StringUtils.isBlank(password)) {      return false;    }    // check length: 4~64    int length = password.length();    if (length &lt; 4 || length &gt; 64) {      return false;    }    // contains only lowcase characters    if (!StringUtils.isAllLowerCase(password)) {      return false;    }    // contains only a~z,0~9,dot    for (int i = 0; i &lt; length; ++i) {      char c = password.charAt(i);      if (!(c &gt;= &#39;a&#39; &amp;&amp; c &lt;= &#39;z&#39;) || (c &gt;= &#39;0&#39; &amp;&amp; c &lt;= &#39;9&#39;) || c == &#39;.&#39;) {        return false;      }    }    return true;  }}</code></pre><p>这里想强调的是不一定完全一样的代码就意味着他们是需要合并的，比如上述的代码当中，isValidPassword还有isValidUsername有着基本上相同的逻辑结构，但是他们本身代表的是不同的意思的，虽然一样的逻辑，但是我们无法保证在接下来的一段时间以内，他们还能这样子一致下去。</p><p>所以合并为isValidUserOrPassword是不可以的，逻辑上讲不通，但是我们可以将上面在这个函数内部调用的方法进行分割的方式，来复用一些代码。</p><p>其实有一些使用组合的味道在里面了。</p><h1 id="2-功能语义的重复"><a href="#2-功能语义的重复" class="headerlink" title="2. 功能语义的重复"></a>2. 功能语义的重复</h1><p>对于功能语义重复的理解，是指一个代码包里在多个地方为了实现同样的功能，设定了不同的方法体。这大部分情况下都是因为沟通等方面的问题，不管里面使用的方法有什么不同，如果他们都是为了达成一样的，那么我们认为其实违反了DRY原则的，是需要清除多余的方法体的。</p><h1 id="3-代码执行重复"><a href="#3-代码执行重复" class="headerlink" title="3. 代码执行重复"></a>3. 代码执行重复</h1><p>看代码的内部逻辑，减少多次重复调用的代码。</p><p>注意IO操作，因为IO非常费时…</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>KISS and YAGNI原则</title>
      <link href="/KISS-and-YAGNI%E5%8E%9F%E5%88%99/"/>
      <url>/KISS-and-YAGNI%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<h1 id="1-KISS"><a href="#1-KISS" class="headerlink" title="1. KISS"></a>1. KISS</h1><p>Keep it simple and stupid. </p><p>这个原则相对比较范范，其实着重在说的还是从代码的可读性和可维护性两个角度来衡量代码的质量。</p><pre><code>// 第一种实现方式: 使用正则表达式public boolean isValidIpAddressV1(String ipAddress) {  if (StringUtils.isBlank(ipAddress)) return false;  String regex = &quot;^(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|[1-9])\\.&quot;          + &quot;(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)\\.&quot;          + &quot;(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)\\.&quot;          + &quot;(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)$&quot;;  return ipAddress.matches(regex);}// 第二种实现方式: 使用现成的工具类public boolean isValidIpAddressV2(String ipAddress) {  if (StringUtils.isBlank(ipAddress)) return false;  String[] ipUnits = StringUtils.split(ipAddress, &#39;.&#39;);  if (ipUnits.length != 4) {    return false;  }  for (int i = 0; i &lt; 4; ++i) {    int ipUnitIntValue;    try {      ipUnitIntValue = Integer.parseInt(ipUnits[i]);    } catch (NumberFormatException e) {      return false;    }    if (ipUnitIntValue &lt; 0 || ipUnitIntValue &gt; 255) {      return false;    }    if (i == 0 &amp;&amp; ipUnitIntValue == 0) {      return false;    }  }  return true;}// 第三种实现方式: 不使用任何工具类public boolean isValidIpAddressV3(String ipAddress) {  char[] ipChars = ipAddress.toCharArray();  int length = ipChars.length;  int ipUnitIntValue = -1;  boolean isFirstUnit = true;  int unitsCount = 0;  for (int i = 0; i &lt; length; ++i) {    char c = ipChars[i];    if (c == &#39;.&#39;) {      if (ipUnitIntValue &lt; 0 || ipUnitIntValue &gt; 255) return false;      if (isFirstUnit &amp;&amp; ipUnitIntValue == 0) return false;      if (isFirstUnit) isFirstUnit = false;      ipUnitIntValue = -1;      unitsCount++;      continue;    }    if (c &lt; &#39;0&#39; || c &gt; &#39;9&#39;) {      return false;    }    if (ipUnitIntValue == -1) ipUnitIntValue = 0;    ipUnitIntValue = ipUnitIntValue * 10 + (c - &#39;0&#39;);  }  if (ipUnitIntValue &lt; 0 || ipUnitIntValue &gt; 255) return false;  if (unitsCount != 3) return false;  return true;}</code></pre><p>相对来说，第二种实现方式会更好一些，因为细节被封装在工具类当中，可读性相对强很多；方法一直接使用正则表达式，可读性会差很多；第三种自己来处理底层的逻辑，虽然执行起来相对会快一些，但是很容易出错。</p><h1 id="2-YAGNI"><a href="#2-YAGNI" class="headerlink" title="2. YAGNI"></a>2. YAGNI</h1><p>You ain’t gonna need it. </p><p>你不会需要它。深有感触，很多时候我们想写很优雅的代码，会疯狂向后考虑，比如对于不常用的功能，有的时候哪怕就一个方法，也想搞个接口供后面的扩展来使用。过度设计，反而增加了代码的阅读成本和维护成本。</p><p>我们不应当去设计当前用不到的功能，也不应该编写现在用不到的代码。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SOLID - 依赖反转原则</title>
      <link href="/SOLID-%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC%E5%8E%9F%E5%88%99/"/>
      <url>/SOLID-%E4%BE%9D%E8%B5%96%E5%8F%8D%E8%BD%AC%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<h1 id="1-控制反转-IOC-Inversion-of-Control"><a href="#1-控制反转-IOC-Inversion-of-Control" class="headerlink" title="1. 控制反转 IOC Inversion of Control"></a>1. 控制反转 IOC Inversion of Control</h1><pre><code>public class UserServiceTest {  public static boolean doTest() {    // ...   }  public static void main(String[] args) {//这部分逻辑可以放到框架中    if (doTest()) {      System.out.println(&quot;Test succeed.&quot;);    } else {      System.out.println(&quot;Test failed.&quot;);    }  }}</code></pre><p>上述代码程序员在自己控制整个代码的运行顺序和执行,可以看到如果我想增加test的话，就要在main函数里面添加，同时在UserServiceTest当中添加实例。而使用框架的话，代码就可以变成如下：</p><pre><code>public abstract class TestCase {  public void run() {    if (doTest()) {      System.out.println(&quot;Test succeed.&quot;);    } else {      System.out.println(&quot;Test failed.&quot;);    }  }  public abstract boolean doTest();}public class JunitApplication {  private static final List&lt;TestCase&gt; testCases = new ArrayList&lt;&gt;();  public static void register(TestCase testCase) {    testCases.add(testCase);  }  public static final void main(String[] args) {    for (TestCase case: testCases) {      case.run();    }  }</code></pre><p>上面的代码我们将测试的注册和运行都交给了JunitApplication了，然后我们要写新test，就让我们的concrete class extends TestCase类，来填充我们需要做的各种测试。</p><p>通过这种方式，我们实现了使用框架来控制整个代码的运转，我们使用框架来<strong>组装对象，管理整个执行流程</strong>。程序员利用框架进行开发的时候，只需要往预留的扩展点上，添加跟自己业务相关的代码，然后利用框架来驱动整个程序流程的执行。</p><p>控制反转是一种思想，有很多的具体的实现方式</p><h1 id="2-控制反转-–-依赖注入"><a href="#2-控制反转-–-依赖注入" class="headerlink" title="2. 控制反转 – 依赖注入"></a>2. 控制反转 – 依赖注入</h1><p>是控制反转的一种具体实现的方式，他的实际操作的指南是 – 不通过new（）的方式在类内部创建依赖类的对象，而是将依赖的类对象在外部创建好以后，通过构造函数，函数参数的方式传递进来给类使用。</p><pre><code>// 非依赖注入实现方式public class Notification {  private MessageSender messageSender;  public Notification() {    this.messageSender = new MessageSender(); //此处有点像hardcode  }  public void sendMessage(String cellphone, String message) {    //...省略校验逻辑等...    this.messageSender.send(cellphone, message);  }}public class MessageSender {  public void send(String cellphone, String message) {    //....  }}// 使用NotificationNotification notification = new Notification();// 依赖注入的实现方式public class Notification {  private MessageSender messageSender;  // 通过构造函数将messageSender传递进来  public Notification(MessageSender messageSender) {    this.messageSender = messageSender;  }  public void sendMessage(String cellphone, String message) {    //...省略校验逻辑等...    this.messageSender.send(cellphone, message);  }}//使用NotificationMessageSender messageSender = new MessageSender();Notification notification = new Notification(messageSender);</code></pre><p>使用依赖注入的最大好处就是，我们不需要在具体的类当中实例化其他的类，这样就实现了解耦，即他的具体实现我们可以在外部做其他方式的实例，这个时候多态也可以派上用场。可以想成我在类的内部占了个座，至于这个座具体要给谁坐，怎么坐，得等到节目要开始之前再来安排，这样我就可以举办不同的活动了。</p><pre><code>public class Notification {  private MessageSender messageSender;  public Notification(MessageSender messageSender) {    this.messageSender = messageSender;  }  public void sendMessage(String cellphone, String message) {    this.messageSender.send(cellphone, message);  }}public interface MessageSender {  void send(String cellphone, String message);}// 短信发送类public class SmsSender implements MessageSender {  @Override  public void send(String cellphone, String message) {    //....  }}// 站内信发送类public class InboxSender implements MessageSender {  @Override  public void send(String cellphone, String message) {    //....  }}//使用NotificationMessageSender messageSender = new SmsSender();Notification notification = new Notification(messageSender);</code></pre><h1 id="3-依赖反转原则"><a href="#3-依赖反转原则" class="headerlink" title="3. 依赖反转原则"></a>3. 依赖反转原则</h1><p>依赖反转 – Dependency Inversion Principle </p><blockquote><p>High-level modules shouldn’t depend on low-level modules. Both modules should depend on abstractions. In addition, abstractions shouldn’t depend on details. Details depend on abstractions.</p></blockquote><p>高层模块（high-level modules）不要依赖低层模块（low-level）。高层模块和低层模块应该通过抽象（abstractions）来互相依赖。除此之外，抽象（abstractions）不要依赖具体实现细节（details），具体实现细节（details）依赖抽象（abstractions）。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SOLID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOLID - 接口隔离原则</title>
      <link href="/SOLID-%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99/"/>
      <url>/SOLID-%E6%8E%A5%E5%8F%A3%E9%9A%94%E7%A6%BB%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<p>接口隔离原则 – interface segregation principle </p><p>客户端不应该强迫依赖它不需要的接口。</p><h1 id="1-将接口视为一组API接口的集合"><a href="#1-将接口视为一组API接口的集合" class="headerlink" title="1. 将接口视为一组API接口的集合"></a>1. 将接口视为一组API接口的集合</h1><pre><code>public interface UserService {  boolean register(String cellphone, String password);  boolean login(String cellphone, String password);  UserInfo getUserInfoById(long id);  UserInfo getUserInfoByCellphone(String cellphone);}public class UserServiceImpl implements UserService {  //...}</code></pre><p>当我们要实现删除操作的时候，最好不要直接在UserService里面加上这个方法，因为用户服务实质上不应该被默认直接具有删除的权限，相对应的，我们应该去创建一个新的接口，里面实现有删除相关的方法，实现接口的隔离。</p><pre><code>public interface UserService {  boolean register(String cellphone, String password);  boolean login(String cellphone, String password);  UserInfo getUserInfoById(long id);  UserInfo getUserInfoByCellphone(String cellphone);}public interface RestrictedUserService {  boolean deleteUserByCellphone(String cellphone);  boolean deleteUserById(long id);}public class UserServiceImpl implements UserService, RestrictedUserService {  // ...省略实现代码...}</code></pre><h1 id="2-将接口理解为单个API接口或者函数"><a href="#2-将接口理解为单个API接口或者函数" class="headerlink" title="2. 将接口理解为单个API接口或者函数"></a>2. 将接口理解为单个API接口或者函数</h1><p>函数的设计需要功能单一，不要将多个不同的功能逻辑放在一个函数当中实现。</p><pre><code>public class Statistics {  private Long max;  private Long min;  private Long average;  private Long sum;  private Long percentile99;  private Long percentile999;  //...省略constructor/getter/setter等方法...}public Statistics count(Collection&lt;Long&gt; dataSet) {  Statistics statistics = new Statistics();  //...省略计算逻辑...  return statistics;}</code></pre><p>count方法算了太多不同的指标，应该将其分割开的。</p><pre><code>public Long max(Collection&lt;Long&gt; dataSet) { //... }public Long min(Collection&lt;Long&gt; dataSet) { //... } public Long average(Colletion&lt;Long&gt; dataSet) { //... }// ...省略其他统计函数...</code></pre><h1 id="3-将接口理解为OOP中的接口的概念"><a href="#3-将接口理解为OOP中的接口的概念" class="headerlink" title="3. 将接口理解为OOP中的接口的概念"></a>3. 将接口理解为OOP中的接口的概念</h1><p>即在设计接口的时候尽量减少大而全的接口的设计，每个接口都只做一件事情，这样子类在implement interface的时候，我们通过接口名也可以很清晰的知道在做什么，会有什么功能，也很大程度上提升了代码的复用性。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SOLID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOLID - 里氏替换原则</title>
      <link href="/SOLID-%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%8E%9F%E5%88%99/"/>
      <url>/SOLID-%E9%87%8C%E6%B0%8F%E6%9B%BF%E6%8D%A2%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><p>里氏替代原则 - Liskov Substitution Principle </p><p>讲述的是子类对象需要能够替换程序当中父类对象出现的任何地方，并且保证原来程序的逻辑性为不变以及正确性不被破坏。</p><pre><code>public class Transporter {  private HttpClient httpClient;  public Transporter(HttpClient httpClient) {    this.httpClient = httpClient;  }  public Response sendRequest(Request request) {    // ...use httpClient to send request  }}public class SecurityTransporter extends Transporter {  private String appId;  private String appToken;  public SecurityTransporter(HttpClient httpClient, String appId, String appToken) {    super(httpClient);    this.appId = appId;    this.appToken = appToken;  }  @Override  public Response sendRequest(Request request) {    if (StringUtils.isNotBlank(appId) &amp;&amp; StringUtils.isNotBlank(appToken)) {      request.addPayload(&quot;app-id&quot;, appId);      request.addPayload(&quot;app-token&quot;, appToken);    }    return super.sendRequest(request);  }}public class Demo {      public void demoFunction(Transporter transporter) {        Reuqest request = new Request();    //...省略设置request中数据值的代码...    Response response = transporter.sendRequest(request);    //...省略其他逻辑...  }}// 里式替换原则Demo demo = new Demo();demo.demofunction(new SecurityTransporter(/*省略参数*/););</code></pre><h1 id="2-里氏替代原则-–-按照协议进行设计"><a href="#2-里氏替代原则-–-按照协议进行设计" class="headerlink" title="2. 里氏替代原则 – 按照协议进行设计"></a>2. 里氏替代原则 – 按照协议进行设计</h1><p>子类在设计的时候，应当遵守父类的行为约定。父类定义了函数的行为约定，那么子类可以改变函数的内部实现逻辑，但不能改变函数原有的行为约定。  </p><p>这里的行为约定指的是函数声明的要实现的功能；对于输入输出以及异常的约定</p><p>定义当中父类和子类之间的关系，也是可以替换成接口和实现类之间的关系的。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SOLID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOLID - 开闭原则</title>
      <link href="/SOLID-%E5%BC%80%E9%97%AD%E5%8E%9F%E5%88%99/"/>
      <url>/SOLID-%E5%BC%80%E9%97%AD%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<p>开闭原则说的是对扩展开放，对修改关闭。我们希望做到的是使得代码有着比较好的扩展性，但是同时也不会影响到他的可读性。</p><h1 id="1-如何理解-对扩展开放，对修改关闭？"><a href="#1-如何理解-对扩展开放，对修改关闭？" class="headerlink" title="1. 如何理解 对扩展开放，对修改关闭？"></a>1. 如何理解 对扩展开放，对修改关闭？</h1><p>Open closed principle, Software entities (modules, classes, functions, etc) should be open for extension, but closed for modification. </p><p>添加一个新的功能应该是在已有代码基础上扩展代码，而非修改已有的代码。</p><h1 id="2-实例解释"><a href="#2-实例解释" class="headerlink" title="2. 实例解释"></a>2. 实例解释</h1><p>代码实现的功能就是当TPS超过某个预设的最大值的时候，或者是错误的数量超过允许的最大值，那么就会触发警报<br>    public class Alert {<br>      private AlertRule rule;<br>      private Notification notification;</p><pre><code>  public Alert(AlertRule rule, Notification notification) {    this.rule = rule;    this.notification = notification;  }  public void check(String api, long requestCount, long errorCount, long durationOfSeconds) {    long tps = requestCount / durationOfSeconds;    if (tps &gt; rule.getMatchedRule(api).getMaxTps()) {      notification.notify(NotificationEmergencyLevel.URGENCY, &quot;...&quot;);    }    if (errorCount &gt; rule.getMatchedRule(api).getMaxErrorCount()) {      notification.notify(NotificationEmergencyLevel.SEVERE, &quot;...&quot;);    }  }}</code></pre><p>现在我们需要添加一个功能，当每秒钟请求数量超过某个阈值的时候，我们也要触发警告，发送通知。</p><p>如果直接在上述代码中进行修改的话，我们主要是需要在check函数当中，添加一个新的输入参数，timeoutCount，表示超时的请求数量，然后再check函数里面加上对应的逻辑</p><pre><code>public class Alert {  // ...省略AlertRule/Notification属性和构造函数...  // 改动一：添加参数timeoutCount  public void check(String api, long requestCount, long errorCount, long timeoutCount, long durationOfSeconds) {    long tps = requestCount / durationOfSeconds;    if (tps &gt; rule.getMatchedRule(api).getMaxTps()) {      notification.notify(NotificationEmergencyLevel.URGENCY, &quot;...&quot;);    }    if (errorCount &gt; rule.getMatchedRule(api).getMaxErrorCount()) {      notification.notify(NotificationEmergencyLevel.SEVERE, &quot;...&quot;);    }    // 改动二：添加接口超时处理逻辑    long timeoutTps = timeoutCount / durationOfSeconds;    if (timeoutTps &gt; rule.getMatchedRule(api).getMaxTimeoutTps()) {      notification.notify(NotificationEmergencyLevel.URGENCY, &quot;...&quot;);    }  }}</code></pre><p>这样的改动是有不少问题的，比如我们对于传入参数做了改动，那所有调用这个函数的地方都需要进行修改，这就是个不小的问题了；而且在修改了check函数以后，所有的单元测试都需要进行修改，会很麻烦的。</p><p>为了提高这整个类的拓展性，我们可以做以下的重构操作：</p><ul><li>将check函数的多个入参封装成ApiStatInfo类</li><li>引入handler的概念，将if判断逻辑分散到各个handler当中</li></ul><pre><code>public class Alert {  private List&lt;AlertHandler&gt; alertHandlers = new ArrayList&lt;&gt;();  public void addAlertHandler(AlertHandler alertHandler) {    this.alertHandlers.add(alertHandler);  }  public void check(ApiStatInfo apiStatInfo) {    for (AlertHandler handler : alertHandlers) {      handler.check(apiStatInfo);    }  }}public class ApiStatInfo {//省略constructor/getter/setter方法  private String api;  private long requestCount;  private long errorCount;  private long durationOfSeconds;}public abstract class AlertHandler {  protected AlertRule rule;  protected Notification notification;  public AlertHandler(AlertRule rule, Notification notification) {    this.rule = rule;    this.notification = notification;  }  public abstract void check(ApiStatInfo apiStatInfo);}public class TpsAlertHandler extends AlertHandler {  public TpsAlertHandler(AlertRule rule, Notification notification) {    super(rule, notification);  }  @Override  public void check(ApiStatInfo apiStatInfo) {    long tps = apiStatInfo.getRequestCount()/ apiStatInfo.getDurationOfSeconds();    if (tps &gt; rule.getMatchedRule(apiStatInfo.getApi()).getMaxTps()) {      notification.notify(NotificationEmergencyLevel.URGENCY, &quot;...&quot;);    }  }}public class ErrorAlertHandler extends AlertHandler {  public ErrorAlertHandler(AlertRule rule, Notification notification){    super(rule, notification);  }  @Override  public void check(ApiStatInfo apiStatInfo) {    if (apiStatInfo.getErrorCount() &gt; rule.getMatchedRule(apiStatInfo.getApi()).getMaxErrorCount()) {      notification.notify(NotificationEmergencyLevel.SEVERE, &quot;...&quot;);    }  }}</code></pre><p>在使用的时候，如下：</p><pre><code>public class ApplicationContext {  private AlertRule alertRule;  private Notification notification;  private Alert alert;  public void initializeBeans() {    alertRule = new AlertRule(/*.省略参数.*/); //省略一些初始化代码    notification = new Notification(/*.省略参数.*/); //省略一些初始化代码    alert = new Alert();    alert.addAlertHandler(new TpsAlertHandler(alertRule, notification));    alert.addAlertHandler(new ErrorAlertHandler(alertRule, notification));  }  public Alert getAlert() { return alert; }  // 饿汉式单例  private static final ApplicationContext instance = new ApplicationContext();  private ApplicationContext() {    instance.initializeBeans();  }  public static ApplicationContext getInstance() {    return instance;  }}public class Demo {  public static void main(String[] args) {    ApiStatInfo apiStatInfo = new ApiStatInfo();    // ...省略设置apiStatInfo数据值的代码    ApplicationContext.getInstance().getAlert().check(apiStatInfo);  }}</code></pre><p>需要修改的地方：</p><pre><code>public class Alert { // 代码未改动... }public class ApiStatInfo {//省略constructor/getter/setter方法  private String api;  private long requestCount;  private long errorCount;  private long durationOfSeconds;  private long timeoutCount; // 改动一：添加新字段}public abstract class AlertHandler { //代码未改动... }public class TpsAlertHandler extends AlertHandler {//代码未改动...}public class ErrorAlertHandler extends AlertHandler {//代码未改动...}// 改动二：添加新的handlerpublic class TimeoutAlertHandler extends AlertHandler {//省略代码...}public class ApplicationContext {  private AlertRule alertRule;  private Notification notification;  private Alert alert;  public void initializeBeans() {    alertRule = new AlertRule(/*.省略参数.*/); //省略一些初始化代码    notification = new Notification(/*.省略参数.*/); //省略一些初始化代码    alert = new Alert();    alert.addAlertHandler(new TpsAlertHandler(alertRule, notification));    alert.addAlertHandler(new ErrorAlertHandler(alertRule, notification));    // 改动三：注册handler    alert.addAlertHandler(new TimeoutAlertHandler(alertRule, notification));  }  //...省略其他未改动代码...}public class Demo {  public static void main(String[] args) {    ApiStatInfo apiStatInfo = new ApiStatInfo();    // ...省略apiStatInfo的set字段代码    apiStatInfo.setTimeoutCount(289); // 改动四：设置tiemoutCount值    ApplicationContext.getInstance().getAlert().check(apiStatInfo);}</code></pre><h1 id="3-一些思考"><a href="#3-一些思考" class="headerlink" title="3. 一些思考"></a>3. 一些思考</h1><ul><li><p>写代码的时候就需要想想有可能会有哪些需求上的变更，如何设计代码的结构，留好扩展点。</p></li><li><p>在识别出可变部分之后，要将可变部分封装起来，隔离变化，提供抽象化的不可变接口，给上层系统来使用。当具体的实现发生变化的时候，我们只需要基于相同的抽象接口，扩展一个新的实现，这样子上游的代码就几乎不需要修改了</p></li><li><p>基于接口而非实现的编程， 对扩展开放，对修改关闭</p><p>  // 这一部分体现了抽象意识<br>  public interface MessageQueue { //… }<br>  public class KafkaMessageQueue implements MessageQueue { //… }<br>  public class RocketMQMessageQueue implements MessageQueue {//…}</p><p>  public interface MessageFormatter { //… }<br>  public class JsonMessageFormatter implements MessageFormatter {//…}<br>  public class MessageFormatter implements MessageFormatter {//…}</p><p>  public class Demo {</p><pre><code>private MessageQueue msgQueue; // 基于接口而非实现编程public Demo(MessageQueue msgQueue) { // 依赖注入  this.msgQueue = msgQueue;}// msgFormatter：多态、依赖注入public void sendNotification(Notification notification, MessageFormatter msgFormatter) {  //...    }</code></pre><p>  }</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SOLID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SOLID - 单一职责原则</title>
      <link href="/SOLID-%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3%E5%8E%9F%E5%88%99/"/>
      <url>/SOLID-%E5%8D%95%E4%B8%80%E8%81%8C%E8%B4%A3%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><ul><li>Single Responsibility Principle - 单一职责原则<ul><li>我们希望对于一个类或者模块来说，他们都是只有一个职责的，即只完成一个功能</li><li>这个职责说的其实就是，不要设计大而全的类，应当设计粒度小，功能单一的类。</li><li>在同一个类当中的方法功能，应该是在同一个业务方向当中的</li></ul></li></ul><h1 id="2-如何判断类的职责是否单一"><a href="#2-如何判断类的职责是否单一" class="headerlink" title="2. 如何判断类的职责是否单一"></a>2. 如何判断类的职责是否单一</h1><ul><li><p>E.G</p><ul><li>如果一个类，既要处理和其他微服务的交互，又要到数据库query，那么这就是两个职责，我们就应该将这个类分割开，划分到两个不同的类当中去 </li></ul></li><li><p>E.G2</p></li></ul><pre><code>public class UserInfo {  private long userId;  private String username;  private String email;  private String telephone;  private long createTime;  private long lastLoginTime;  private String avatarUrl;  private String provinceOfAddress; // 省  private String cityOfAddress; // 市  private String regionOfAddress; // 区   private String detailedAddress; // 详细地址  // ...省略其他属性和方法...}</code></pre><p>对于上述UserInfo类来说，里面全是User的一些属性，但是其中有将近半数是关于地址的，我们有理由将其细分为UserAddress类以及UserInfo类，但是在实际应用场景当中，我们需要考虑我们到底是准备如何使用这些数据的。</p><p>如果应用场景就是拿出用户相关的信息，那放在一起无伤大雅，但是如果是要做物流，电商的场景，那么我们单独想拿出地址相关信息的场景就会比较多了，这种情况最好就分成两个不同的类了。</p><p>实际开发当中，实际上一般情况下都是先写一个粗粒度的类，以满足业务的需求，随着业务的发展，如果粗粒度的类越来越庞大，我们就可以将这个粗粒度的类拆分成几个更细粒度的类，即–持续重构。</p><h1 id="3-判断是否满足单一职责原则的判断准则"><a href="#3-判断是否满足单一职责原则的判断准则" class="headerlink" title="3. 判断是否满足单一职责原则的判断准则"></a>3. 判断是否满足单一职责原则的判断准则</h1><ul><li>类中代码的行数，函数或者属性过多，会影响代码的可读性和可维护性，需要考虑对类进行拆分了</li><li>类依赖的其他类过多，或者依赖类的其他类过多，不符合高内聚，低耦合的设计思想，我们需要对其考虑进行拆分</li><li>私有方法过多，我们需要考虑是否应该将私有方法独立到新的类当中，设置为public方法，供更多的类使用，从而提高代码的复用性</li><li>如果对于一个类，比较难取名字，只能用相对泛泛的名字，那很可能意味着这个类的职责有点过多了</li><li>类中的大量方法都是集中操作类中的某几个属性，那么就可以考虑将这几个属性和对应的方法拆分出来</li></ul><p>需要注意的一点是： 我们使用这些准则，亦或者是设计模式，最终的目的还是提高代码的可读性，可扩展性，复用性，可维护性等。这才应当是我们判断是否要采用SOLID准则，以及其他的原则的最终标准。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SOLID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于充血模型的DDD开发模型</title>
      <link href="/%E5%9F%BA%E4%BA%8E%E5%85%85%E8%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84DDD%E5%BC%80%E5%8F%91%E6%A8%A1%E5%9E%8B/"/>
      <url>/%E5%9F%BA%E4%BA%8E%E5%85%85%E8%A1%80%E6%A8%A1%E5%9E%8B%E7%9A%84DDD%E5%BC%80%E5%8F%91%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-传统基于MVC的开发模式"><a href="#1-传统基于MVC的开发模式" class="headerlink" title="1. 传统基于MVC的开发模式"></a>1. 传统基于MVC的开发模式</h1><p>MVC三层结构中的M表示Model，V表示View，C表示Controller。通过这三层将整个项目分为了三大部分，展示层，逻辑层，数据层</p><p>而贫血模型 - Anemic Domain Model，指的是我们将数据和操作分离，有专门的POJO类，即只包含数据的类，这实质上会破坏面向对象的封装特性，是一种面向过程的编程风格。</p><h1 id="2-基于充血模型的DDD开发模式"><a href="#2-基于充血模型的DDD开发模式" class="headerlink" title="2. 基于充血模型的DDD开发模式"></a>2. 基于充血模型的DDD开发模式</h1><p>充血模型 - rich domain model，旨在将数据和对应的业务逻辑封装在同一个类当中。</p><h1 id="3-实战-DDD-开发虚拟钱包系统"><a href="#3-实战-DDD-开发虚拟钱包系统" class="headerlink" title="3. 实战  DDD 开发虚拟钱包系统"></a>3. 实战  DDD 开发虚拟钱包系统</h1><h2 id="3-1-钱包业务背景介绍"><a href="#3-1-钱包业务背景介绍" class="headerlink" title="3.1 钱包业务背景介绍"></a>3.1 钱包业务背景介绍</h2><p>需要创建一个系统内的虚拟钱包账户，来支持用户的充值，提现，支付，冻结，透支，转赠，查询账户余额，查询交易流水等操作。</p><p>在这里，我们假定要去实现一个具备充值，提现, 支付，查询余额，还有查询交易流水五个功能的钱包。</p><p>其业务流程分别为：</p><ul><li>充值 <ul><li>用户通过第三方支付渠道，将自己银行卡里面的钱充值到虚拟钱包账号当中</li><li>操作流程<ul><li>从用户银行卡到应用的公共银行卡</li><li>用户虚拟钱包增加金额</li><li>记录刚刚这笔交易流水</li></ul></li></ul></li><li>支付<ul><li>实际上是一个转账的过程，从用户的虚拟钱包账户划钱到商家的虚拟钱包账户当中</li><li>记录流水信息</li></ul></li><li>提现<ul><li>用户虚拟钱包  减去对应的钱数</li><li>应用的公共银行卡 打钱 到用户的银行卡</li><li>记录交易</li></ul></li><li>查询余额<ul><li>看虚拟钱包的余额数字</li></ul></li><li>查询交易流水<ul><li>查询充值，支付，提现三种操作</li></ul></li></ul><h2 id="3-2-设计思路"><a href="#3-2-设计思路" class="headerlink" title="3.2 设计思路"></a>3.2 设计思路</h2><p>首先我们需要对系统进行解耦，即用相似特征和特性的功能放到同一个子系统当中。根据特性，我们可以分为虚拟钱包系统和三方支付系统两个部分。</p><ul><li>虚拟钱包<ul><li>用户虚拟钱包</li><li>商家虚拟钱包</li></ul></li><li>三方支付<ul><li>用户银行卡</li><li>商家银行卡</li><li>应用公共银行卡</li></ul></li></ul><p>虚拟钱包需要支持的操作基本上就是对于余额的加减，充值，提现，查询三种操作都是只涉及到一个账户的余额的加减操作；而支付功能涉及到两个账户的余额的加减操作。</p><p>而对于交易记录，应当记录的信息有：</p><ul><li>交易流水ID</li><li>交易时间</li><li>交易金额</li><li>交易类型<ul><li>充值</li><li>提现</li><li>支付</li></ul></li><li>入账钱包账号</li><li>出账钱包账号</li></ul><p>这么设计是有点浪费存储空间的，因为对于充值提现这种交易类型来说，我们只要记录一个钱包账户信息就好了。</p><p>另外一种方式就是在交易类型处，设计成支付和被支付两种类型，这样在对待转账的情况的时候，数据库写两条数据，来记录整个transaction。能够省空间，但是会有一些问题：</p><p>最重要的难点还是在数据的一致性方面，当我们在做转账操作的时候，我们必须保证加减两个操作要么都成功，要么都失败。如果一个成功，一个失败，那会完蛋的。关于钱的事情，发生一点错误就会对公司造成非常大的影响。</p><p>对于转账及类似的操作，合理的做法是在操作两个钱包的账户余额之前，先记录交易流水，并且标记为待执行，当两个钱包的加减金额都完成了之后，我们再回头将交易记录的状态标记为失败。然后我们通过后台的补漏job，拉取状态为失败或者长时间处于待执行状态的交易记录，重新执行或者人工介入处理。</p><p>另外一个点在我们会构建一个钱包系统，然后分出两个子系统，虚拟钱包还有第三方交易平台，那么我们的商业逻辑都应该放到钱包系统这一个层级上，我们希望我们的虚拟钱包还有交易平台尽量和我们的商业逻辑脱钩，更多的是事务上方法上的更泛化的东西。这样做的好处是我们的商业逻辑会经常发生变化，但是我们希望虚拟钱包，还有第三方交易平台两个模块不需要经常性的变动。这也是去做两个子系统的初衷之一。</p><h2 id="3-3-基于贫血模式的传统开发模式"><a href="#3-3-基于贫血模式的传统开发模式" class="headerlink" title="3.3 基于贫血模式的传统开发模式"></a>3.3 基于贫血模式的传统开发模式</h2><pre><code>public class VirtualWalletController {  // 通过构造函数或者IOC框架注入  private VirtualWalletService virtualWalletService;  public BigDecimal getBalance(Long walletId) { ... } //查询余额  public void debit(Long walletId, BigDecimal amount) { ... } //出账  public void credit(Long walletId, BigDecimal amount) { ... } //入账  public void transfer(Long fromWalletId, Long toWalletId, BigDecimal amount) { ...} //转账}public class VirtualWalletBo {//省略getter/setter/constructor方法  private Long id;  private Long createTime;  private BigDecimal balance;}public class VirtualWalletService {  // 通过构造函数或者IOC框架注入  private VirtualWalletRepository walletRepo;  private VirtualWalletTransactionRepository transactionRepo;  public VirtualWalletBo getVirtualWallet(Long walletId) {    VirtualWalletEntity walletEntity = walletRepo.getWalletEntity(walletId);    VirtualWalletBo walletBo = convert(walletEntity);    return walletBo;  }  public BigDecimal getBalance(Long walletId) {    return walletRepo.getBalance(walletId);  }  public void debit(Long walletId, BigDecimal amount) {    VirtualWalletEntity walletEntity = walletRepo.getWalletEntity(walletId);    BigDecimal balance = walletEntity.getBalance();    if (balance.compareTo(amount) &lt; 0) {      throw new NoSufficientBalanceException(...);    }    walletRepo.updateBalance(walletId, balance.subtract(amount));  }  public void credit(Long walletId, BigDecimal amount) {    VirtualWalletEntity walletEntity = walletRepo.getWalletEntity(walletId);    BigDecimal balance = walletEntity.getBalance();    walletRepo.updateBalance(walletId, balance.add(amount));  }  public void transfer(Long fromWalletId, Long toWalletId, BigDecimal amount) {    VirtualWalletTransactionEntity transactionEntity = new VirtualWalletTransactionEntity();    transactionEntity.setAmount(amount);    transactionEntity.setCreateTime(System.currentTimeMillis());    transactionEntity.setFromWalletId(fromWalletId);    transactionEntity.setToWalletId(toWalletId);    transactionEntity.setStatus(Status.TO_BE_EXECUTED);    Long transactionId = transactionRepo.saveTransaction(transactionEntity);    try {      debit(fromWalletId, amount);      credit(toWalletId, amount);    } catch (InsufficientBalanceException e) {      transactionRepo.updateStatus(transactionId, Status.CLOSED);      ...rethrow exception e...    } catch (Exception e) {      transactionRepo.updateStatus(transactionId, Status.FAILED);      ...rethrow exception e...    }    transactionRepo.updateStatus(transactionId, Status.EXECUTED);  }}</code></pre><h2 id="3-4-基于充血模式的DDD开发模式"><a href="#3-4-基于充血模式的DDD开发模式" class="headerlink" title="3.4 基于充血模式的DDD开发模式"></a>3.4 基于充血模式的DDD开发模式</h2><pre><code>public class VirtualWallet { // Domain领域模型(充血模型)  private Long id;  private Long createTime = System.currentTimeMillis();;  private BigDecimal balance = BigDecimal.ZERO;  public VirtualWallet(Long preAllocatedId) {    this.id = preAllocatedId;  }  public BigDecimal balance() {    return this.balance;  }  public void debit(BigDecimal amount) {    if (this.balance.compareTo(amount) &lt; 0) {      throw new InsufficientBalanceException(...);    }    this.balance.subtract(amount);  }  public void credit(BigDecimal amount) {    if (amount.compareTo(BigDecimal.ZERO) &lt; 0) {      throw new InvalidAmountException(...);    }    this.balance.add(amount);  }}public class VirtualWalletService {  // 通过构造函数或者IOC框架注入  private VirtualWalletRepository walletRepo;  private VirtualWalletTransactionRepository transactionRepo;  public VirtualWallet getVirtualWallet(Long walletId) {    VirtualWalletEntity walletEntity = walletRepo.getWalletEntity(walletId);    VirtualWallet wallet = convert(walletEntity);    return wallet;  }  public BigDecimal getBalance(Long walletId) {    return walletRepo.getBalance(walletId);  }  public void debit(Long walletId, BigDecimal amount) {    VirtualWalletEntity walletEntity = walletRepo.getWalletEntity(walletId);    VirtualWallet wallet = convert(walletEntity);    wallet.debit(amount);    walletRepo.updateBalance(walletId, wallet.balance());  }  public void credit(Long walletId, BigDecimal amount) {    VirtualWalletEntity walletEntity = walletRepo.getWalletEntity(walletId);    VirtualWallet wallet = convert(walletEntity);    wallet.credit(amount);    walletRepo.updateBalance(walletId, wallet.balance());  }  public void transfer(Long fromWalletId, Long toWalletId, BigDecimal amount) {    //...跟基于贫血模型的传统开发模式的代码一样...  }}</code></pre><p>一些思考： </p><ul><li>领域模型 希望其尽可能的独立，不包含任何其它层的代码，将流程性的代码逻辑和领域模型的业务逻辑解耦，让领域模型更加可以复用</li><li>Service类负责一些非功能性的和与第三方交互的工作 <ul><li>信息传送</li><li>metrics</li><li>日志</li></ul></li></ul><h1 id="4-实战-接口鉴权"><a href="#4-实战-接口鉴权" class="headerlink" title="4. 实战 - 接口鉴权"></a>4. 实战 - 接口鉴权</h1><p>目的是熟悉在拿到相对笼统的开发需求的时候，需要如何做需求分析，如何做职责划分，看需要定义哪些类，每个类应该具有哪些属性，方法；定义类和类的交互</p><h2 id="4-1-需求"><a href="#4-1-需求" class="headerlink" title="4.1 需求"></a>4.1 需求</h2><p>微服务系统，通过HTTP协议暴露接口给其他系统调用。需要实现一个接口鉴权系统，只有经过认证的系统才能调用我们的接口</p><ul><li>需求分析<ul><li>基础分析<ul><li>通过用户名加密码来做认证</li><li>每个允许访问的调用发都有应用ID还有秘钥，在做接口请求的时候，需要传进来应用ID和秘钥，然后我们在自己的服务器来进行验证比对。如果一致，说明认证成功，允许接口调用了否则，就拒绝</li></ul></li><li>二轮分析<ul><li>这种方式，明文传输，容易被拦截，并不安全</li><li>借助加密算法，对密码进行加密再传递到微服务端验证，同样不安全。因为还是可以被拦截，被拦截以后黑客可以直接拿着这个加密的密码加ID来假装是调用者向服务端发出请求</li><li>OAuth方式<ul><li>调用方生成token (id + appId + pwd)</li><li>调用方生成新的URL (id + appId + token)</li><li>Server解析出URL, appId, token</li><li>Server从数据库根据appId拿出pwd</li><li>Server利用Url，appId， pwd生成server端token</li><li>比较是否一致</li></ul></li></ul></li><li>三轮分析<ul><li>上述方式还是可能存在重放攻击，被拦截，然后来伪装成认证系统，调用这个URL对应的接口。</li><li>token生成过程加入时间戳，然后传递到微服务器端</li><li>微服务器收到这些数据之后，会验证当前时间戳跟传递过来的时间戳，是否在一定的时间窗口内。超过时间窗口，也会决绝请求</li></ul></li><li>四轮分析<ul><li>基本就是到这个程度，因为我们还要考虑性能方面的东西。这种方式对于性能的影响比较小，也考量到了安全性。</li><li>如何在微服务端存储每个授权调用方的appId和密码<ul><li>开发鉴权这种非业务功能，最好不要与具体的第三方系统有过度的耦合</li><li>最好能够支持多种不同的存储方式<ul><li>ZooKeeper</li><li>本地配置文件</li><li>自研配置中心</li><li>MySQL</li><li>Redis等</li></ul></li></ul></li></ul></li><li>最终需求的确定<ul><li>调用方进行接口请求的时候，将 URL、AppID、密码、时间戳拼接在一起，通过加密算法生成 token，并且将 token、AppID、时间戳拼接在 URL 中，一并发送到微服务端。</li><li>微服务端在接收到调用方的接口请求之后，从请求中拆解出 token、AppID、时间戳。</li><li>微服务端首先检查传递过来的时间戳跟当前时间，是否在 token 失效时间窗口内。如果已经超过失效时间，那就算接口调用鉴权失败，拒绝接口调用请求。</li><li>如果 token 验证没有过期失效，微服务端再从自己的存储中，取出 AppID 对应的密码，通过同样的 token 生成算法，生成另外一个 token，与调用方传递过来的 token 进行匹配；如果一致，则鉴权成功，允许接口调用，否则就拒绝接口调用。 </li></ul></li></ul></li></ul><h2 id="4-2-面向对象设计"><a href="#4-2-面向对象设计" class="headerlink" title="4.2 面向对象设计"></a>4.2 面向对象设计</h2><ul><li>进行职责划分，进而识别出都有哪些类<ul><li>将需求描述中的名词罗列出来，作为可能的候选类，然后进行筛选</li><li>或者根据需求描述，将其中涉及的功能点，一个一个罗列出来，然后再看哪些功能点职责相近，操作同样的属性，能否归到同一个类当中</li></ul></li><li>定义类，及其属性和方法</li><li>定义类和类之间的交互关系</li><li>将类组装起来并提供执行入口 </li></ul><ul><li>功能点列表<ul><li>把 URL、AppID、密码、时间戳拼接为一个字符串；</li><li>对字符串通过加密算法加密生成 token；</li><li>将 token、AppID、时间戳拼接到 URL 中，形成新的 URL；</li><li>解析 URL，得到 token、AppID、时间戳等信息；</li><li>从存储中取出 AppID 和对应的密码；</li><li>根据时间戳判断 token 是否过期失效；</li><li>验证两个 token 是否匹配； </li></ul></li></ul><p>从上面的功能列表中，我们发现，1、2、6、7 都是跟 token 有关，负责 token 的生成、验证；3、4 都是在处理 URL，负责 URL 的拼接、解析；5 是操作 AppID 和密码，负责从存储中读取 AppID 和密码。所以，我们可以粗略地得到三个核心的类：AuthToken、Url、CredentialStorage。AuthToken 负责实现 1、2、6、7 这四个操作；Url 负责 3、4 两个操作；CredentialStorage 负责 5 这个操作。</p><pre><code>// AuthToken类的实现private static final long DEFAULT_EXPIRED_TIME_INTERVAL = 1 * 60 * 1000;private String token;private long createTime;private long expiredTimeInterval = DEFAULT_EXPIRED_TIME_INTERVAL;public AuthToken(String token, long createTime);public AuthToken(String token, long createTime, long expredTImeInterval);public static AuthToken create(String baseUrl, long createTime, Map&lt;String, String&gt; params);public String getToken();public boolean isExpired();public boolean match(AuthToken authToken)</code></pre><ul><li>Tips<ul><li>并不是所有的需要的名词类的属性都会作为类的属性，有可能会作为方法的参数。选择的基准还是这个属性到底属不属于这个类，从这个角度来看的</li><li>我们有可能需要去挖掘一下在功能需求里面并没有体现的一些属性  还是需要从业务模型的角度上来看究竟需要怎么做才比较好</li></ul></li></ul><pre><code>public interface ApiAuthenticator {  void auth(String url);  void auth(ApiRequest apiRequest);}public class DefaultApiAuthenticatorImpl implements ApiAuthenticator {  private CredentialStorage credentialStorage;  public DefaultApiAuthenticator() {    this.credentialStorage = new MysqlCredentialStorage();  }  public DefaultApiAuthenticator(CredentialStorage credentialStorage) {    this.credentialStorage = credentialStorage;  }  @Override  public void auth(String url) {    ApiRequest apiRequest = ApiRequest.buildFromUrl(url);    auth(apiRequest);  }  @Override  public void auth(ApiRequest apiRequest) {    String appId = apiRequest.getAppId();    String token = apiRequest.getToken();    long timestamp = apiRequest.getTimestamp();    String originalUrl = apiRequest.getOriginalUrl();    AuthToken clientAuthToken = new AuthToken(token, timestamp);    if (clientAuthToken.isExpired()) {      throw new RuntimeException(&quot;Token is expired.&quot;);    }    String password = credentialStorage.getPasswordByAppId(appId);    AuthToken serverAuthToken = AuthToken.generate(originalUrl, appId, password, timestamp);    if (!serverAuthToken.match(clientAuthToken)) {      throw new RuntimeException(&quot;Token verfication failed.&quot;);    }  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>组合 vs 继承</title>
      <link href="/%E7%BB%84%E5%90%88-vs-%E7%BB%A7%E6%89%BF/"/>
      <url>/%E7%BB%84%E5%90%88-vs-%E7%BB%A7%E6%89%BF/</url>
      
        <content type="html"><![CDATA[<p>组合还有继承都是面向对象的很重要的特性，但是有一条非常重要的设计原则说 – 组合优于继承，想在这篇博文当中分析一下为什么认为组合优于继承，以及什么情况下我们仍然应该使用继承。</p><p>继承可以表示类之间的is-a的关系，可以一定程度上解决代码复用性的问题，但是继承层次过深，也会影响到代码的可维护性。</p><h1 id="1-继承的劣势"><a href="#1-继承的劣势" class="headerlink" title="1. 继承的劣势"></a>1. 继承的劣势</h1><p>譬如 我们现在要实现一个关于哺乳动物的类，我们首先需要将哺乳动物定义为一个抽象的类</p><pre><code>public class Mammal {    public void breathWithLung() {    }}</code></pre><p>此时我们就可以实例化Monkey，Whale等一系列哺乳动物了。但是对于哺乳动物来说，他的属，科，目门类很多，海陆空都有，假设我们按照他们的行为来进行分类的话。可以分成会飞的，会游的，还有会跑的。所以就可以写如下的代码：</p><pre><code>public class flyableMammal extends Mammal {    public void fly() {    }}public class underwaterMammal extends Mammal {    public void swim() {    }}public class onLandMammal extends Mammal {    public void run() {    }}</code></pre><p>这个时候我们已经有两层的继承了，而后我们可以实例化一些哺乳动物，譬如鲸鱼，海豚，狮子等等来创建真的对象。然后问题来了，我们现在想探究会飞的动物当中，夜行的类目，那就意味着我们需要再创建一个新的层级来进行研究了。</p><p>长此以往，整个层级就会变得很深。而深度的层级意味着每当我们想真真切切去研究到底这个类做了什么的时候，我们需要去他的父类，去他的父类的父类，追本溯源，一个一个看其中定义的属性和方法，才能完全理解他做了什么。</p><p>这样子来做，首先造成了代码的可读性变得非常差，而对于类本身而言，破坏了其封装特性，将父类的实现细节暴露给了子类。在这种情况下，一旦父类代码修改，就会影响所有子类的逻辑。</p><h1 id="2-组合的优势"><a href="#2-组合的优势" class="headerlink" title="2. 组合的优势"></a>2. 组合的优势</h1><p>对于上述的场景，我们完全可以用组合的方式来实现。通过设立多个功能接口，来表示当前类的属性，譬如flyable, runnable, swimmable, etc. 通过这种方式，我们让concrete class直接implements对应的接口，并override写出自己的实现。这样子就能够解决这个问题了。</p><p>除了使用接口之外，我们也可以使用委托的方式，即仍然定于对应的接口，但是还定义了实现了接口方法的实现类，在实际使用的时候，调用实现类的方法直接使用，例子如下</p><pre><code>public interface Flyable {  void fly()；}public class FlyAbility implements Flyable {  @Override  public void fly() { //... }}//省略Tweetable/TweetAbility/EggLayable/EggLayAbilitypublic class Ostrich implements Tweetable, EggLayable {//鸵鸟  private TweetAbility tweetAbility = new TweetAbility(); //组合  private EggLayAbility eggLayAbility = new EggLayAbility(); //组合  //... 省略其他属性和方法...  @Override  public void tweet() {    tweetAbility.tweet(); // 委托  }  @Override  public void layEgg() {    eggLayAbility.layEgg(); // 委托  }}</code></pre><h1 id="3-如何判断该使用继承还是组合？"><a href="#3-如何判断该使用继承还是组合？" class="headerlink" title="3. 如何判断该使用继承还是组合？"></a>3. 如何判断该使用继承还是组合？</h1><p>组合也并不完美，组合需要对类做更细度的拆分，要定义更多的类和接口，因此在实际开发的过程当中，我们还是要根据具体的情况，来具体选择该使用继承还是组合。</p><p>如果类之间的继承结构稳定 – 不会轻易改变，继承关系比较浅 – 譬如两层到三层的继承关系，那么我们可以直接使用继承。反之，对于系统不够稳定，继承层次会很深，且关系复杂的，我们就应该尽量使用组合来替代继承了。</p><p>或者当我们想要使用多态的特性的时候，我们就需要使用继承了。</p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Composition </tag>
            
            <tag> Inheritance </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 理解多态</title>
      <link href="/Java-%E7%90%86%E8%A7%A3%E5%A4%9A%E6%80%81/"/>
      <url>/Java-%E7%90%86%E8%A7%A3%E5%A4%9A%E6%80%81/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是多态？"><a href="#1-什么是多态？" class="headerlink" title="1. 什么是多态？"></a>1. 什么是多态？</h1><p>多态目的是为了分离做什么和怎么做，从而实现接口和实现的分离。通过多态，可以改善代码的组织结构和可读性，最重要的是能够创建可扩展的程序。</p><p>有继承关系的类，子类重写父类的方法，然后父类的引用指向子类。通过这种方式，就可以对于父类的声明指向子类的实际对象，</p><h1 id="2-为什么需要多态？"><a href="#2-为什么需要多态？" class="headerlink" title="2. 为什么需要多态？"></a>2. 为什么需要多态？</h1><p>多态的好处很多，令代码可扩展，解耦接口与实现，让代码对于改动封闭，对于扩展开放, etc. 如果直接从代码的角度来看，我们可以比较直观的看到他的优势</p><pre><code>public class Animal {    public void move() {        System.out.println(&quot;Animal move&quot;);    }}public class Cat extends Animal {    @Override    public void move() {        System.out.println(&quot;cat climb&quot;);    }}public calss Dog entends Animal {    @Override    public void move() {        System.out.println(&quot;dog run&quot;);    }}public static void main(String [] args) {    Animal animal = new Cat();    animal.move();    // output: cat climb}</code></pre><p>通过这种方式可以实现接口与实现的解耦。</p><h1 id="3-多态和继承的关系"><a href="#3-多态和继承的关系" class="headerlink" title="3. 多态和继承的关系"></a>3. 多态和继承的关系</h1><p>继承指在子类当中使用父类的数据和方法</p><p>多态指在子类当中改变父类的行为。</p><h1 id="4-构造器内部的多态方法的行为"><a href="#4-构造器内部的多态方法的行为" class="headerlink" title="4. 构造器内部的多态方法的行为"></a>4. 构造器内部的多态方法的行为</h1><p>如果在一个构造器的内部调用正在构造的对象的某个动态绑定的方法，会出现一些不可知的错误。</p><p>因为构造器内部的动态绑定意味着要用到方法被覆盖以后的定义，而这意味着被覆盖的方法在对象被完全构造之前就会被调用了，</p><pre><code>class Graph {    void draw() {        print(&quot;Graph draw()&quot;);    }    Graph() {        print(&quot;Graph() before draw()&quot;);        draw();        print(&quot;Graph() after draw()&quot;);    }}class RoundGraph extends Graph {    private int radius = 1;    RoundGraph(int r) {        radius = r;        print(&quot;RoundGraph.RoundGraph(), radius = &quot; + radius);    }    void draw() {        print(&quot;RoundGraph.draw(), radius = &quot; + radius);    }}public class PolyConstructors {    public static void main(String[] args) {        new RoundGraph(5);    }}// All output Graph() before draw()RoundGraph.draw(), radius = 0Graph() after draw()ROundGraph,RoundGraph(), radius = 5</code></pre><p>有这样的输出的原因是当我们实例化R欧尼的Graph的时候，会调用基类的构造器，在Graph类的构造器当中调用了draw()方法，这个时候动态绑定，是要去调用RoundGraph类的draw方法的，但是这个时候还在构建Graph 的实例，RoundGraph还没有构建好，所以就出现了返回的Radius刚开始值为0的问题了</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>Thinking in Java Ch.8 </li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Polymorphism </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>理解面向对象</title>
      <link href="/%E7%90%86%E8%A7%A3%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"/>
      <url>/%E7%90%86%E8%A7%A3%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/</url>
      
        <content type="html"><![CDATA[<p>这篇博文主要想说面向对象的几大特性：封装，抽象，继承，多态，以及我们究竟如何去使用。</p><h1 id="1-面向对象概述"><a href="#1-面向对象概述" class="headerlink" title="1. 面向对象概述"></a>1. 面向对象概述</h1><h2 id="1-1-面向对象编程"><a href="#1-1-面向对象编程" class="headerlink" title="1.1 面向对象编程"></a>1.1 面向对象编程</h2><p>一种编程范式/风格，以类或对象作为组织代码的基本单元，并将封装，抽象，继承，多态四个特性作为代码设计和实现的基石。</p><p>整个编程的过程：</p><ul><li>Object Oriented Analysis</li><li>Object Oriented Design</li><li>Object Oriented Programming </li></ul><h2 id="1-2-面向对象编程的四大特征"><a href="#1-2-面向对象编程的四大特征" class="headerlink" title="1.2 面向对象编程的四大特征"></a>1.2 面向对象编程的四大特征</h2><h3 id="1-2-1-封装-Encapsulation"><a href="#1-2-1-封装-Encapsulation" class="headerlink" title="1.2.1 封装 Encapsulation"></a>1.2.1 封装 Encapsulation</h3><pre><code>public class Wallet {  private String id;  private long createTime;  private BigDecimal balance;  private long balanceLastModifiedTime;  // ...省略其他属性...  public Wallet() {     this.id = IdGenerator.getInstance().generate();     this.createTime = System.currentTimeMillis();     this.balance = BigDecimal.ZERO;     this.balanceLastModifiedTime = System.currentTimeMillis();  }  // 注意：下面对get方法做了代码折叠，是为了减少代码所占文章的篇幅  public String getId() { return this.id; }  public long getCreateTime() { return this.createTime; }  public BigDecimal getBalance() { return this.balance; }  public long getBalanceLastModifiedTime() { return this.balanceLastModifiedTime;  }  public void increaseBalance(BigDecimal increasedAmount) {    if (increasedAmount.compareTo(BigDecimal.ZERO) &lt; 0) {      throw new InvalidAmountException(&quot;...&quot;);    }    this.balance.add(increasedAmount);    this.balanceLastModifiedTime = System.currentTimeMillis();  }  public void decreaseBalance(BigDecimal decreasedAmount) {    if (decreasedAmount.compareTo(BigDecimal.ZERO) &lt; 0) {      throw new InvalidAmountException(&quot;...&quot;);    }    if (decreasedAmount.compareTo(this.balance) &gt; 0) {      throw new InsufficientAmountException(&quot;...&quot;);    }    this.balance.subtract(decreasedAmount);    this.balanceLastModifiedTime = System.currentTimeMillis();  }}</code></pre><p>虚拟钱包，对于自身变量，用private来标注，然后通过对应的getter，setter方法允许外界来访问一部分变量，允许进行一定的修改。</p><p>没有封装则意味着不可控，即任何代码都可以被任何人访问，修改的代码可以遍布在包的任何角落，会影响代码的可读性，以及可维护性。只暴露出有限多的接口，供外界来使用。</p><p>总结： 封装是为了隐藏信息，保护数据</p><h3 id="1-2-2-继承-Inheritance"><a href="#1-2-2-继承-Inheritance" class="headerlink" title="1.2.2 继承 Inheritance"></a>1.2.2 继承 Inheritance</h3><p>用来表述is a的关系，java支持单继承。</p><p>继承最大的好处就是代码复用，比如两个子类的共同代码抽取到父类当中，然后父类来共同使用。</p><p>但是过度使用的话会容易导致层级数量太多，反而降低代码的可读性。</p><h3 id="1-2-3-多态-Polymorphism"><a href="#1-2-3-多态-Polymorphism" class="headerlink" title="1.2.3 多态 Polymorphism"></a>1.2.3 多态 Polymorphism</h3><ul><li>继承加方法重写实现</li></ul><pre><code>public class DynamicArray {  private static final int DEFAULT_CAPACITY = 10;  protected int size = 0;  protected int capacity = DEFAULT_CAPACITY;  protected Integer[] elements = new Integer[DEFAULT_CAPACITY];  public int size() { return this.size; }  public Integer get(int index) { return elements[index];}  //...省略n多方法...  public void add(Integer e) {    ensureCapacity();    elements[size++] = e;  }  protected void ensureCapacity() {    //...如果数组满了就扩容...代码省略...  }}public class SortedDynamicArray extends DynamicArray {  @Override  public void add(Integer e) {    ensureCapacity();    int i;    for (i = size-1; i&gt;=0; --i) { //保证数组中的数据有序      if (elements[i] &gt; e) {        elements[i+1] = elements[i];      } else {        break;      }    }    elements[i+1] = e;    ++size;  }}public class Example {  public static void test(DynamicArray dynamicArray) {    dynamicArray.add(5);    dynamicArray.add(1);    dynamicArray.add(3);    for (int i = 0; i &lt; dynamicArray.size(); ++i) {      System.out.println(dynamicArray.get(i));    }  }  public static void main(String args[]) {    DynamicArray dynamicArray = new SortedDynamicArray();    test(dynamicArray); // 打印结果：1、3、5  }}</code></pre><ul><li>利用接口类实现多态特性</li></ul><pre><code>public interface Iterator {  String hasNext();  String next();  String remove();}public class Array implements Iterator {  private String[] data;  public String hasNext() { ... }  public String next() { ... }  public String remove() { ... }  //...省略其他方法...}public class LinkedList implements Iterator {  private LinkedListNode head;  public String hasNext() { ... }  public String next() { ... }  public String remove() { ... }  //...省略其他方法... }public class Demo {  private static void print(Iterator iterator) {    while (iterator.hasNext()) {      System.out.println(iterator.next());    }  }  public static void main(String[] args) {    Iterator arrayIterator = new Array();    print(arrayIterator);    Iterator linkedListIterator = new LinkedList();    print(linkedListIterator);  }}</code></pre><p>多态可以很大程度上提高代码的可扩展性和复用性</p><h3 id="1-2-4-抽象-Abstraction"><a href="#1-2-4-抽象-Abstraction" class="headerlink" title="1.2.4 抽象 Abstraction"></a>1.2.4 抽象 Abstraction</h3><p>抽象，主要是为了隐藏方法的具体实现，让调用者只需要关心方法提供了哪些功能，并不需要知道这些方法具体是如何实现的。</p><pre><code>public interface IPictureStorage {  void savePicture(Picture picture);  Image getPicture(String pictureId);  void deletePicture(String pictureId);  void modifyMetaInfo(String pictureId, PictureMetaInfo metaInfo);}public class PictureStorage implements IPictureStorage {  // ...省略其他属性...  @Override  public void savePicture(Picture picture) { ... }  @Override  public Image getPicture(String pictureId) { ... }  @Override  public void deletePicture(String pictureId) { ... }  @Override  public void modifyMetaInfo(String pictureId, PictureMetaInfo metaInfo) { ... }}</code></pre><p>使用接口或者abstract class，然后调用者就只需要知道需要传入什么参数，传出什么参数，就可以试用了。</p><h1 id="2-面向对象-vs-面向过程"><a href="#2-面向对象-vs-面向过程" class="headerlink" title="2. 面向对象 vs 面向过程"></a>2. 面向对象 vs 面向过程</h1><p>需要对这两个概念有更深的理解，很多时候，我们是在用面向对象的语言写面向过程的代码，对于到底什么是面向对象，如何写真的面向对象的代码，我们还是有很多无法确定的地方。</p><p>面向过程的编程是一种编程范式，以过程(方法，函数，操作)作为组织代码的基本单元，以数据(可以理解为成员变量，属性)与方法相分离为最主要的特点。面向过程风格是一种流程化的编程风格，通过拼接一组顺序执行的方法来操作数据完成一项功能。</p><h2 id="2-1-面向对象编程的优势"><a href="#2-1-面向对象编程的优势" class="headerlink" title="2.1 面向对象编程的优势"></a>2.1 面向对象编程的优势</h2><h3 id="2-1-1-更能够应对大规模复杂程序的开发"><a href="#2-1-1-更能够应对大规模复杂程序的开发" class="headerlink" title="2.1.1 更能够应对大规模复杂程序的开发"></a>2.1.1 更能够应对大规模复杂程序的开发</h3><p>因为对于面向过程的编程风格来说，整个程序的处理流程会偏向于线性，流程化，但是实际应用场景中，关系错综复杂，会很难将程序拆解为一组顺序执行的方法。而面向对象的方式就可以比较好的解决这个问题了。</p><h3 id="2-1-2-更易复用，扩展和维护"><a href="#2-1-2-更易复用，扩展和维护" class="headerlink" title="2.1.2 更易复用，扩展和维护"></a>2.1.2 更易复用，扩展和维护</h3><p>面向对象通过类这种组织方式能够将数据和方法绑定在一起，通过访问权限控制，只允许外部调用者通过类暴露的有限方法访问数据，而不会像面向过程编程那样，数据可以被任意方法的随意修改</p><p>我们通过使用多态的特性，可以在需要修改一个功能实现的时候，通过实现一个新的子类的方式，在子类当中重写原来的功能逻辑，用子类替代父类。 —- 对修改关闭，对扩展开放。</p><h2 id="2-2-Warning-Bad-Smell-看似面向对象的面向过程的代码"><a href="#2-2-Warning-Bad-Smell-看似面向对象的面向过程的代码" class="headerlink" title="2.2 Warning/ Bad Smell - 看似面向对象的面向过程的代码"></a>2.2 Warning/ Bad Smell - 看似面向对象的面向过程的代码</h2><p>首先值得注意的是，这里提及的都是我们需要注意的地方，但并不是说我们完全不能这样子写。譬如util class，很多时候我们是需要的，因为确实可以不带数据的，只在input，output传递所有信息就够了。</p><h3 id="2-2-1-getter-setter方法的问题"><a href="#2-2-1-getter-setter方法的问题" class="headerlink" title="2.2.1 getter setter方法的问题"></a>2.2.1 getter setter方法的问题</h3><p>当我们习惯性的给所有的属性都加上getter， setter方法的时候，其实是破坏了Java的封装的特性的，我们使用private 标注属性，再适当的设置setter，getter方法是因为我们不想将对于代码/数据的控制权交给他人，而疯狂的getter，setter方法会让Java的封装优势荡然无存，只是从原来的直接访问属性变成通过getter，setter方法来访问。没有起到任何保障安全的作用。</p><p>注意如果是集合容器的话，要防范集合内部的数据被修改的危险。另外，setter方法的使用需要谨慎些，只有在必需的时候再用。</p><h3 id="2-2-2-全局变量和全局方法"><a href="#2-2-2-全局变量和全局方法" class="headerlink" title="2.2.2 全局变量和全局方法"></a>2.2.2 全局变量和全局方法</h3><p>常见的全局变量有：</p><ul><li>单例类对象</li><li>静态成员变量</li><li>常量</li></ul><p>常见的全局方法有：</p><ul><li>静态方法</li></ul><p>Constants类往往会越加越大，而且会很难维护。而且如果我们开发的其他项目需要复用这些constants，哪怕我们只使用一个，那么最终也会不得不将整个文件加载进去，没有必要，而且会变得非常的慢。我们可以将Constants类拆分为功能更加单一的多个类，或者直接将这些常量定义到对应的class当中。这也是个很好的选择。</p><h2 id="3-1-什么是接口？-什么是抽象类？"><a href="#3-1-什么是接口？-什么是抽象类？" class="headerlink" title="3.1 什么是接口？ 什么是抽象类？"></a>3.1 什么是接口？ 什么是抽象类？</h2><h3 id="3-1-1-抽象类定义"><a href="#3-1-1-抽象类定义" class="headerlink" title="3.1.1 抽象类定义"></a>3.1.1 抽象类定义</h3><p>下面是一个模板设计的实例，Logger被用来记录日志，FileLogger和MessageQueueLogger继承Logger，分别实现两种不同的日志记录方式</p><pre><code>// 抽象类public abstract class Logger {  private String name;  private boolean enabled;  private Level minPermittedLevel;  public Logger(String name, boolean enabled, Level minPermittedLevel) {    this.name = name;    this.enabled = enabled;    this.minPermittedLevel = minPermittedLevel;  }  public void log(Level level, String message) {    boolean loggable = enabled &amp;&amp; (minPermittedLevel.intValue() &lt;= level.intValue());    if (!loggable) return;    doLog(level, message);  }  protected abstract void doLog(Level level, String message);}// 抽象类的子类：输出日志到文件public class FileLogger extends Logger {  private Writer fileWriter;  public FileLogger(String name, boolean enabled,    Level minPermittedLevel, String filepath) {    super(name, enabled, minPermittedLevel);    this.fileWriter = new FileWriter(filepath);   }  @Override  public void doLog(Level level, String mesage) {    // 格式化level和message,输出到日志文件    fileWriter.write(...);  }}// 抽象类的子类: 输出日志到消息中间件(比如kafka)public class MessageQueueLogger extends Logger {  private MessageQueueClient msgQueueClient;  public MessageQueueLogger(String name, boolean enabled,    Level minPermittedLevel, MessageQueueClient msgQueueClient) {    super(name, enabled, minPermittedLevel);    this.msgQueueClient = msgQueueClient;  }  @Override  protected void doLog(Level level, String mesage) {    // 格式化level和message,输出到消息中间件    msgQueueClient.send(...);  }}</code></pre><p>抽象类的特性：</p><ul><li>抽象类不允许被实例化，只能被继承  </li><li>抽象类可以包含属性与方法，方法可以包含代码实现，也可以不包含，设计成抽象方法</li><li>子类继承抽象类，必须实现抽象类当中的所有抽象方法</li></ul><h3 id="3-1-2-接口定义"><a href="#3-1-2-接口定义" class="headerlink" title="3.1.2 接口定义"></a>3.1.2 接口定义</h3><pre><code>// 接口public interface Filter {  void doFilter(RpcRequest req) throws RpcException;}// 接口实现类：鉴权过滤器public class AuthencationFilter implements Filter {  @Override  public void doFilter(RpcRequest req) throws RpcException {    //...鉴权逻辑..  }}// 接口实现类：限流过滤器public class RateLimitFilter implements Filter {  @Override  public void doFilter(RpcRequest req) throws RpcException {    //...限流逻辑...  }}// 过滤器使用demopublic class Application {  // filters.add(new AuthencationFilter());  // filters.add(new RateLimitFilter());  private List&lt;Filter&gt; filters = new ArrayList&lt;&gt;();  public void handleRpcRequest(RpcRequest req) {    try {      for (Filter filter : fitlers) {        filter.doFilter(req);      }    } catch(RpcException e) {      // ...处理过滤结果...    }    // ...省略其他处理逻辑...  }}</code></pre><p>使用interface关键字实现一个Filter接口，AuthencationFilter和RatelimiterFilter分别实现对于RPC请求的鉴权和限流的过滤功能。</p><ul><li>接口不能包含属性</li><li>接口只能声明方法，方法不能包含代码实现</li><li>类实现接口的时候，必须实现接口当中声明的所有方法</li></ul><p>抽象类和继承类似，其实表征的是一种is-a的关系；而接口表征的是一种has-a的关系/ 协议，表示具有某些功能 </p><h2 id="3-2-区别-都能解决什么样的编程问题？"><a href="#3-2-区别-都能解决什么样的编程问题？" class="headerlink" title="3.2 区别/ 都能解决什么样的编程问题？"></a>3.2 区别/ 都能解决什么样的编程问题？</h2><h3 id="3-2-1-抽象类-存在的意义"><a href="#3-2-1-抽象类-存在的意义" class="headerlink" title="3.2.1 抽象类 存在的意义"></a>3.2.1 抽象类 存在的意义</h3><p>抽象类不能实例化，只能被继承。主要是用来解决代码复用的问题的。多个子类可以继承抽象类当中定义的属性和方法，避免在子类当中，重复编写相同的代码。</p><p>为什么必须是抽象类来做代码复用呢？ </p><ul><li>因为可以利用多态来做了</li><li>减少父类代码被错误的直接使用的风险</li><li>也可以增加代码的可读性</li></ul><h3 id="3-2-2-接口的存在意义"><a href="#3-2-2-接口的存在意义" class="headerlink" title="3.2.2 接口的存在意义"></a>3.2.2 接口的存在意义</h3><p>接口更侧重于解耦，接口是对行为的一种抽象，相当于一组协议或者契约。这样调用者只需要关注抽象的接口，不需要了解具体的实现</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/gdhucoder/Algorithms4/blob/master/designpattern/pic/umlcheatsheet.jpg" target="_blank" rel="noopener">https://github.com/gdhucoder/Algorithms4/blob/master/designpattern/pic/umlcheatsheet.jpg</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OOP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式概述</title>
      <link href="/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%A6%82%E8%BF%B0/"/>
      <url>/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-起源"><a href="#1-起源" class="headerlink" title="1. 起源"></a>1. 起源</h1><p>每个模式都描述了一个在我们的环境中不断出现的问题，然后描述了该问题的解决方案的核心，通过这种方式，我们可以无数次重用那些已有的成功的解决方案，无须再重复相同的工作。</p><p>软件模式(Software Patterns)是将模式的一般概念应用于软件开发领域，即软件开发的总体指导思路或参照样板。软件模式并非仅限于设计模式，还包括架构模式、分析模式和过程模式等，<strong><em>实际上，在软件开发生命周期的每一个阶段都存在着一些被认同的模式</em></strong>。</p><p>想要学习设计模式的原因，是因为感到自己的代码能力还是有点捉急，可以写出能用的代码，但很难写出好看的代码，如果每次写代码的时候都要一行一行的来构建，而没有一个组件一个组件的意识的话，那写好代码恐怕只能是天方夜谭了。我想设计模式对我来说，就是抽象，构建框架的过程，是真真切切能够在日常工作当中帮助到自己的。不仅仅在于代码质量，也在于组件化以后的开发速度，以及对于更加复杂的商业上的实际场景得以提供出更加匹配的解决方式的能力。</p><p>另外一个点是当前我的能力范畴还是仅仅在于根据需求写出代码，即停留在写业务代码的阶段，在这个阶段当中，自己并不需要具有很强的代码设计能力，理解业务就可以写出代码了。但是如果想要成长，还是需要具备写出<strong>和业务并不直接相关的更加通用的功能模块</strong>的能力的。</p><h1 id="2-软件模式的基础结构"><a href="#2-软件模式的基础结构" class="headerlink" title="2. 软件模式的基础结构"></a>2. 软件模式的基础结构</h1><ul><li>问题描述</li><li>前提条件</li><li>解法</li><li>效果</li></ul><h2 id="2-1-评价代码的一些维度"><a href="#2-1-评价代码的一些维度" class="headerlink" title="2.1 评价代码的一些维度"></a>2.1 评价代码的一些维度</h2><p>关于如何判断一段代码写的好坏，众说纷纭，每个人其实都有自己主观上的某些看法。但是在更高维度上来说，会有一些相对能达成共识的标准，是我们可以在平常写代码的时候更多的注意一下的。</p><h3 id="2-1-1-可维护性-maintainability"><a href="#2-1-1-可维护性-maintainability" class="headerlink" title="2.1.1 可维护性 maintainability"></a>2.1.1 可维护性 maintainability</h3><ul><li>在不破坏原有代码的设计，不引入新的bug的情况下，能够快速地修改或者添加代码</li><li>细拆分其实就有很多因素的协同作用了<ul><li>代码的可读性，简洁</li><li>代码分层清晰程度，模块化，高内聚低耦合</li><li>基于接口而非实现编程</li></ul></li></ul><h3 id="2-1-2-可读性-readability"><a href="#2-1-2-可读性-readability" class="headerlink" title="2.1.2 可读性 readability"></a>2.1.2 可读性 readability</h3><ul><li>命名</li><li>注释</li><li>函数的长短</li><li>模块的划分</li></ul><h3 id="2-1-3-可扩展性-extensibility"><a href="#2-1-3-可扩展性-extensibility" class="headerlink" title="2.1.3 可扩展性  extensibility"></a>2.1.3 可扩展性  extensibility</h3><p>表征的是我们的代码对未来需求变化进行应对的能力。</p><p>即代码预留了一些功能的扩展点，我们可以将新功能代码直接插入到扩展点上，而不需要因为添加一个功能而大动干戈，改动大量的原始代码。</p><h3 id="2-1-4-灵活性-flexibility"><a href="#2-1-4-灵活性-flexibility" class="headerlink" title="2.1.4 灵活性  flexibility"></a>2.1.4 灵活性  flexibility</h3><ul><li>比如预留好了扩展点给新的功能代码来使用</li><li>代码已经抽象出了很多底层可以复用的模块，类</li></ul><h3 id="2-1-5-简洁性-simplicity"><a href="#2-1-5-简洁性-simplicity" class="headerlink" title="2.1.5 简洁性   simplicity"></a>2.1.5 简洁性   simplicity</h3><p>Keep it simple, stupid. </p><h3 id="2-1-6-可复用性-reusability"><a href="#2-1-6-可复用性-reusability" class="headerlink" title="2.1.6 可复用性  reusability"></a>2.1.6 可复用性  reusability</h3><p>尽量减少重复代码的编写，复用已有的代码</p><h3 id="2-1-7-可测试性-testability"><a href="#2-1-7-可测试性-testability" class="headerlink" title="2.1.7 可测试性  testability"></a>2.1.7 可测试性  testability</h3><p>比较难写的单元测试往往意味着代码的设计是有问题的。</p><p>如果说上面的细节实在是太多，并不能一下子很快的掌握，个人感觉，去看别人的设计，别人的代码，和自己的比较，会是非常快的成长方式。除此以外，肯定还是要经过看山是山，不是山，还是山的阶段的。希望自己的代码最终能像一个故事一样，将一段逻辑讲述完整。</p><h1 id="3-设计模式"><a href="#3-设计模式" class="headerlink" title="3. 设计模式"></a>3. 设计模式</h1><blockquote><p>设计模式(Design Pattern)是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结，使用设计模式是为了可重用代码、让代码更容易被他人理解并且保证代码可靠性。</p></blockquote><p>整个设计模式系列将会分以下几个部分：</p><ol><li><p>概述</p></li><li><p>面向对象设计原则</p><ul><li>单一职责</li><li>开闭原则</li><li>里氏代换</li><li>依赖倒转</li><li>接口隔离</li><li>合成复用</li><li>迪米特</li></ul></li><li><p>创建型模式（描述如何创建对象）</p><ul><li>简单工厂模式</li><li>工厂方法模式</li><li>抽象工厂模式</li><li>单例模式</li><li>原型模式</li><li>建造者模式</li></ul></li><li><p>结构型模式（如何实现类或对象的组合）</p><ul><li>适配器模式</li><li>桥接模式</li><li>组合模式</li><li>装饰模式</li><li>外观模式</li><li>享元模式</li><li>代理模式</li></ul></li><li><p>行为型模式（类或者对象怎样交互以及怎样分配职责）（类是对一类事物的描述，抽象出来的；而对象是具体的描述。类是一群具有相同属性的对象的集合体）</p><ul><li>职责链模式</li><li>命令模式</li><li>解释器模式</li><li>迭代器模式</li><li>中介者模式</li><li>备忘录模式</li><li>观察者模式</li><li>状态模式</li><li>策略模式</li><li>模板方法模式</li><li>访问者模式</li></ul></li></ol><h1 id="4-面向对象，设计原则，设计模式，编程规范，代码重构"><a href="#4-面向对象，设计原则，设计模式，编程规范，代码重构" class="headerlink" title="4. 面向对象，设计原则，设计模式，编程规范，代码重构"></a>4. 面向对象，设计原则，设计模式，编程规范，代码重构</h1><h2 id="4-1-面向对象"><a href="#4-1-面向对象" class="headerlink" title="4.1 面向对象"></a>4.1 面向对象</h2><p>主流的编程范式有：</p><ul><li>面向过程</li><li>面向对象</li><li>函数式编程</li></ul><p>面向对象因为其具有的丰富的特性 - 封装，继承，抽象，多态。可以实现很多复杂的设计思路，是很多设计原则，设计模式的实现基础。</p><ul><li>知识点<ul><li>封装 继承 抽象 多态</li><li>面向对象与面向过程编程的区别与联系</li><li>面向对象的分析设计和编程</li><li>接口和抽象类的区别以及各自的应用场景</li><li>基于接口而非实现的编程设计思想</li><li>多用组合少用继承的设计思想</li><li>面向过程的贫血模型和面向对象的充血模型<h2 id="4-2-设计原则"><a href="#4-2-设计原则" class="headerlink" title="4.2 设计原则"></a>4.2 设计原则</h2></li></ul></li><li>设计原则<ul><li>单一职责原则</li><li>开闭原则</li><li>里氏替换原则</li><li>接口隔离原则</li><li>依赖导致原则</li><li>DRY</li><li>KISS</li><li>YAGNI</li><li>LOD</li></ul></li></ul><h2 id="4-3-设计模式"><a href="#4-3-设计模式" class="headerlink" title="4.3 设计模式"></a>4.3 设计模式</h2><ul><li>设计模式<ul><li>为了解决代码的可扩展性问题</li><li>需要掌握他们都解决了哪些问题，典型的应用场景，并且不能也不应该过度使用</li><li>创建型<ul><li>单例模式</li><li>工厂模式</li><li>建造者模式</li></ul></li><li>结构型<ul><li>代理模式</li><li>桥接模式</li><li>装饰者模式</li><li>适配器模式</li></ul></li><li>行为型<ul><li>观察者模式</li><li>模板模式</li><li>策略模式</li><li>职责链模式</li><li>迭代器模式</li><li>状态模式</li></ul></li></ul></li></ul><h2 id="4-4-编程规范"><a href="#4-4-编程规范" class="headerlink" title="4.4 编程规范"></a>4.4 编程规范</h2><p>主要为了解决代码的可读性问题，这些规范主要是记忆，熟悉，然后尽量多的去使用。书籍的话可以去看重构，代码大全，代码整洁之道这几本书。</p><h2 id="4-5-代码重构"><a href="#4-5-代码重构" class="headerlink" title="4.5 代码重构"></a>4.5 代码重构</h2><p>业务发展，规模扩大，原先的设计很可能无法支持现在的体量的应用场景，这种情况下就需要持续重构了。而是用的工具就是我们前面说的设计模式，编程规范等等。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design Pattern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PowerMock with EasyMock toturial</title>
      <link href="/Powermock-with-EasyMock-toturial/"/>
      <url>/Powermock-with-EasyMock-toturial/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro-with-an-example"><a href="#1-Intro-with-an-example" class="headerlink" title="1. Intro with an example"></a>1. Intro with an example</h1><p>We often find we need to do unit tests for final class, static method, which are not supported by Easymock, Mockito currently. Under such situation, we could use Powermock to help us mock the corresponding classes. </p><p>For detail introduction about powermock, refer to <a href="https://github.com/powermock/powermock" target="_blank" rel="noopener">PowerMock Github</a></p><p>Use example as followed to show how to integrate PowerMock with EasyMock: </p><pre><code>public final class FinalClassExample {    public String static doNothingStatic() {        return &quot;test&quot;;    }}@PowerMockIgnore(&quot;javax.management.*&quot;) // only need when see warning related with jmx or mbeans@RunWith(PowerMockRunner.class)  // necessary for powermock @PrepareForTest(FinalClassExample.class)  // necessary for powermock public class FinalClassExampleTest {    private IMocksControl control;    @Before    public void init() {        // do some initialization here         control = EasyMock.createControl();    }    @Test    public void test_example() {        PowerMock.mockStatic(FinalClassExample.class);        expect(FinalClassExample.doNothingStatic()).andReturn(&quot;test&quot;);        PowerMock.replay(FinalClassExample.class);        runYourTest();        PowerMock.verify(FinalClassExample.class);        // do some assertions here    }}</code></pre><h1 id="2-Other-APIs"><a href="#2-Other-APIs" class="headerlink" title="2. Other APIs"></a>2. Other APIs</h1><ul><li>mock final classes or methods <ul><li><code>@RunWith(PowerMockRunner.class)</code></li><li><code>@PrepareForTest(ClassWithFinal.class)</code></li><li><code>PowerMock.createMock(ClassWithFinal.class);</code></li><li><code>PowerMock.replay(mockObject)</code></li><li><code>PowerMock.verify(mockObject)</code></li></ul></li><li>mock private methods <ul><li><code>@RunWith(PowerMockRunner.class)</code></li><li><code>@PrepareForTest(ClassWithPrivateMethod.class)</code></li><li><code>PowerMock.createPartialMock(ClassWithPrivateMethod.class, &quot;nameOfTheMethodToMock&quot;)</code></li><li>Use <code>PowerMock.expectPrivate(mockObject, &quot;nameOfTheMethodToMock&quot;, argument1, argument2)</code> to expect the method call to <code>nameOfTheMethodToMock</code> with arguments <code>argument1</code> and <code>argument2</code></li><li><code>PowerMock.replay(mockObject)</code></li><li><code>PowerMock.verify(mockObject)</code></li></ul></li><li>mock construction of new objects <ul><li><code>@RunWith(PowerMockRunner.class)</code></li><li><code>@PrepareForTest(ClassThatCreatesTheNewInstance.class)</code> </li><li><code>PowerMock.createMock(NewInstanceClass.class)</code></li><li><code>PowerMock.expectNew(NewInstanceClass.class).andReturn(mockObject)</code></li><li><code>PowerMock.replay(mockObject, NewInstanceClass.class)</code></li><li><code>PowerMock.verify(mockObject, NewInstanceClass.class)</code></li></ul></li><li>mock partial <ul><li><code>@RunWith(PowerMockRunner.class)</code></li><li><code>@PrepareForTest(ClassToPartiallyMock.class)</code></li><li><code>PowerMock.createPartialMock(ClassToPartiallyMock.class, &quot;nameOfTheFirstMethodToMock&quot;, &quot;nameOfTheSecondMethodToMock&quot;)</code></li><li><code>PowerMock.replay(mockObject)</code></li><li><code>PowerMock.verify(mockObject)</code></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://github.com/powermock/powermock" target="_blank" rel="noopener">https://github.com/powermock/powermock</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Unit Test </tag>
            
            <tag> PowerMock </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工程师需要知道的latency 数字 </title>
      <link href="/%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84latency-%E6%95%B0%E5%AD%97/"/>
      <url>/%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%9A%84latency-%E6%95%B0%E5%AD%97/</url>
      
        <content type="html"><![CDATA[<p>看到一篇博客，叙述了当前内存对于数据的处理速度对于开发的影响，推而广之，找到了一些我们在做系统设计的时候需要熟知的一些数据。</p><p>首先处理器的处理速度和内存的处理速度是差距很大的，处理器的处理速度的增长速度要比内存的快很多。</p><p><img src="https://i.loli.net/2020/02/21/s8h6GTfi1PSYwpe.png" alt="处理器与内存的性能表现.png"></p><p>我们需要探究的是CPU从内存中随机提取数据以及获取连续数据的速度，这是很粗略的估计，只是希望能够有一个数量级上的感知。</p><pre><code>Latency Comparison Numbers (~2012)----------------------------------L1 cache reference                           0.5 nsBranch mispredict                            5   nsL2 cache reference                           7   ns                      14x L1 cacheMutex lock/unlock                           25   nsMain memory reference                      100   ns                      20x L2 cache, 200x L1 cacheCompress 1K bytes with Zippy             3,000   ns        3 usSend 1K bytes over 1 Gbps network       10,000   ns       10 usRead 4K randomly from SSD*             150,000   ns      150 us          ~1GB/sec SSDRead 1 MB sequentially from memory     250,000   ns      250 usRound trip within same datacenter      500,000   ns      500 usRead 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memoryDisk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtripRead 1 MB sequentially from disk    20,000,000   ns   20,000 us   20 ms  80x memory, 20X SSDSend packet CA-&gt;Netherlands-&gt;CA    150,000,000   ns  150,000 us  150 ms</code></pre><p>根据2020年StackOverflow上的回答，我们可以看到Core i7 Xeon 5500 的benchmark数据如下</p><pre><code>Core i7 Xeon 5500 Series Data Source Latency (approximate)               [Pg. 22]local  L1 CACHE hit,                              ~4 cycles (   2.1 -  1.2 ns )local  L2 CACHE hit,                             ~10 cycles (   5.3 -  3.0 ns )local  L3 CACHE hit, line unshared               ~40 cycles (  21.4 - 12.0 ns )local  L3 CACHE hit, shared line in another core ~65 cycles (  34.8 - 19.5 ns )local  L3 CACHE hit, modified in another core    ~75 cycles (  40.2 - 22.5 ns )remote L3 CACHE (Ref: Fig.1 [Pg. 5])        ~100-300 cycles ( 160.7 - 30.0 ns )local  DRAM                                                   ~60 nsremote DRAM                                                  ~100 ns</code></pre><p>而现在的cache的大小，根据wikiChip上的数据，对于Core i7-8700K</p><pre><code>Memory Bandwidth: 39.74 gigabytes per secondL1 cache: 192 kilobytes (32 KB per core)L2 cache: 1.5 megabytes (256 KB per core)L3 cache: 12 megabytes  (shared; 2 MB per core)</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.forrestthewoods.com/blog/memory-bandwidth-napkin-math/" target="_blank" rel="noopener">https://www.forrestthewoods.com/blog/memory-bandwidth-napkin-math/</a>?</li><li><a href="https://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory" target="_blank" rel="noopener">https://stackoverflow.com/questions/4087280/approximate-cost-to-access-various-caches-and-main-memory</a></li><li><a href="https://en.wikichip.org/wiki/intel/core_i7/i7-8700k" target="_blank" rel="noopener">https://en.wikichip.org/wiki/intel/core_i7/i7-8700k</a></li><li><a href="https://gist.github.com/jboner/2841832" target="_blank" rel="noopener">https://gist.github.com/jboner/2841832</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> latency </tag>
            
            <tag> system design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java8 Date Time API </title>
      <link href="/Java8-Date-Time-API/"/>
      <url>/Java8-Date-Time-API/</url>
      
        <content type="html"><![CDATA[<h1 id="1-为什么需要新的Date-API"><a href="#1-为什么需要新的Date-API" class="headerlink" title="1. 为什么需要新的Date API"></a>1. 为什么需要新的Date API</h1><p>Java8 的一大更新在于终于将Date Time一致化，这解决了在Java8以前我们观察到的非常多的问题：</p><p>譬如：</p><ul><li>Java Date Time类定义在不同的地方，比如在java.util &amp; java.sql里面都有，而样式和格式转化的类都定义在java.text的包里，比较混乱</li><li>java.util.Date包括date和time类，而java.sql.Date只包含date</li><li>并没有清晰定义的类用于处理time, timestamp, formatting, parsing </li><li>所有的Date类都是可变的，并不是线程安全的</li><li>Date类不支持全球化，没有时区的支持，在java8之前，为了显示当地时间，就得使用java.util.Calendar 还有 java.util.TimeZone,整个变得比较麻烦</li></ul><h1 id="2-Java8-Date-Time-API-详解"><a href="#2-Java8-Date-Time-API-详解" class="headerlink" title="2. Java8 Date Time API 详解"></a>2. Java8 Date Time API 详解</h1><h2 id="2-1-Packages"><a href="#2-1-Packages" class="headerlink" title="2.1 Packages"></a>2.1 Packages</h2><ul><li>java.time Package <ul><li>这是新的Date Time API的基础包，一些主要的基本类都在这里面，譬如LocalDate, LocalTime, LocalDateTime, Instant, Period, Duration  </li></ul></li><li>java.time.chrono <ul><li>定义了抽象的API接口，针对于非ISO标准的calendar 系统，我们可以通过extend AbstractChronology类来创建我们自己的calendar系统</li></ul></li><li>java.time.format <ul><li>包含用来Formatting还有parsing date time对象的类</li></ul></li><li>java.time.temporal <ul><li>包含一些时间对象，比如找到月份的第一天， 最后一天之类的</li></ul></li><li>java.time.zone<ul><li>支持不同的时区 </li></ul></li></ul><h2 id="2-2-LocalDate"><a href="#2-2-LocalDate" class="headerlink" title="2.2 LocalDate"></a>2.2 LocalDate</h2><ul><li>Immutable class </li><li>默认样式为 yyyy-MM-dd</li><li>我们可以使用<code>now()</code>方法来获得当前的日期</li><li>也可以通过提供年月日来创建localDate对象</li><li>我们同时也可以传入ZoneId来得到在特定的时区的日期</li></ul><pre><code>package com.journaldev.java8.time;import java.time.LocalDate;import java.time.Month;import java.time.ZoneId;/** * LocalDate Examples * @author pankaj * */public class LocalDateExample {    public static void main(String[] args) {        //Current Date        LocalDate today = LocalDate.now();        System.out.println(&quot;Current Date=&quot;+today);        //Creating LocalDate by providing input arguments        LocalDate firstDay_2014 = LocalDate.of(2014, Month.JANUARY, 1);        System.out.println(&quot;Specific Date=&quot;+firstDay_2014);        //Try creating date by providing invalid inputs        //LocalDate feb29_2014 = LocalDate.of(2014, Month.FEBRUARY, 29);        //Exception in thread &quot;main&quot; java.time.DateTimeException:         //Invalid date &#39;February 29&#39; as &#39;2014&#39; is not a leap year        //Current date in &quot;Asia/Kolkata&quot;, you can get it from ZoneId javadoc        LocalDate todayKolkata = LocalDate.now(ZoneId.of(&quot;Asia/Kolkata&quot;));        System.out.println(&quot;Current Date in IST=&quot;+todayKolkata);        //java.time.zone.ZoneRulesException: Unknown time-zone ID: IST        //LocalDate todayIST = LocalDate.now(ZoneId.of(&quot;IST&quot;));        //Getting date from the base date i.e 01/01/1970        LocalDate dateFromBase = LocalDate.ofEpochDay(365);        System.out.println(&quot;365th day from base date= &quot;+dateFromBase);        LocalDate hundredDay2014 = LocalDate.ofYearDay(2014, 100);        System.out.println(&quot;100th day of 2014=&quot;+hundredDay2014);    }}// output Current Date=2014-04-28Specific Date=2014-01-01Current Date in IST=2014-04-29365th day from base date= 1971-01-01100th day of 2014=2014-04-10</code></pre><h2 id="2-3-LocalTime"><a href="#2-3-LocalTime" class="headerlink" title="2.3 LocalTime"></a>2.3 LocalTime</h2><ul><li>Immutable Class </li><li>表示一个可读的时间 (vs Instant 基本不可读)</li><li>默认样式为 hh:mm:ss:zz</li><li>和LocalDate基本一致的用法，可以传入参数生成实例，支持时区</li></ul><pre><code>package com.journaldev.java8.time;import java.time.LocalTime;import java.time.ZoneId;/** * LocalTime Examples * @author pankaj * */public class LocalTimeExample {    public static void main(String[] args) {        //Current Time        LocalTime time = LocalTime.now();        System.out.println(&quot;Current Time=&quot;+time);        //Creating LocalTime by providing input arguments        LocalTime specificTime = LocalTime.of(12,20,25,40);        System.out.println(&quot;Specific Time of Day=&quot;+specificTime);        //Try creating time by providing invalid inputs        //LocalTime invalidTime = LocalTime.of(25,20);        //Exception in thread &quot;main&quot; java.time.DateTimeException:         //Invalid value for HourOfDay (valid values 0 - 23): 25        //Current date in &quot;Asia/Kolkata&quot;, you can get it from ZoneId javadoc        LocalTime timeKolkata = LocalTime.now(ZoneId.of(&quot;Asia/Kolkata&quot;));        System.out.println(&quot;Current Time in IST=&quot;+timeKolkata);        //java.time.zone.ZoneRulesException: Unknown time-zone ID: IST        //LocalTime todayIST = LocalTime.now(ZoneId.of(&quot;IST&quot;));        //Getting date from the base date i.e 01/01/1970        LocalTime specificSecondTime = LocalTime.ofSecondOfDay(10000);        System.out.println(&quot;10000th second time= &quot;+specificSecondTime);    }}// Output Current Time=15:51:45.240Specific Time of Day=12:20:25.000000040Current Time in IST=04:21:45.27610000th second time= 02:46:40</code></pre><h2 id="2-4-LocalDateTime"><a href="#2-4-LocalDateTime" class="headerlink" title="2.4 LocalDateTime"></a>2.4 LocalDateTime</h2><ul><li>Immutable date-time object </li><li>represent both date and time </li><li>default format at yyyy-MM-dd-HH-mm-ss.zzz </li><li>用工厂方法来拿到LocalDate和LocalTime的input 然后来创建LocalDateTime的实例</li></ul><pre><code>package com.journaldev.java8.time;import java.time.LocalDate;import java.time.LocalDateTime;import java.time.LocalTime;import java.time.Month;import java.time.ZoneId;import java.time.ZoneOffset;public class LocalDateTimeExample {    public static void main(String[] args) {        //Current Date        LocalDateTime today = LocalDateTime.now();        System.out.println(&quot;Current DateTime=&quot;+today);        //Current Date using LocalDate and LocalTime        today = LocalDateTime.of(LocalDate.now(), LocalTime.now());        System.out.println(&quot;Current DateTime=&quot;+today);        //Creating LocalDateTime by providing input arguments        LocalDateTime specificDate = LocalDateTime.of(2014, Month.JANUARY, 1, 10, 10, 30);        System.out.println(&quot;Specific Date=&quot;+specificDate);        //Try creating date by providing invalid inputs        //LocalDateTime feb29_2014 = LocalDateTime.of(2014, Month.FEBRUARY, 28, 25,1,1);        //Exception in thread &quot;main&quot; java.time.DateTimeException:         //Invalid value for HourOfDay (valid values 0 - 23): 25        //Current date in &quot;Asia/Kolkata&quot;, you can get it from ZoneId javadoc        LocalDateTime todayKolkata = LocalDateTime.now(ZoneId.of(&quot;Asia/Kolkata&quot;));        System.out.println(&quot;Current Date in IST=&quot;+todayKolkata);        //java.time.zone.ZoneRulesException: Unknown time-zone ID: IST        //LocalDateTime todayIST = LocalDateTime.now(ZoneId.of(&quot;IST&quot;));        //Getting date from the base date i.e 01/01/1970        LocalDateTime dateFromBase = LocalDateTime.ofEpochSecond(10000, 0, ZoneOffset.UTC);        System.out.println(&quot;10000th second time from 01/01/1970= &quot;+dateFromBase);    }}// OutputCurrent DateTime=2014-04-28T16:00:49.455Current DateTime=2014-04-28T16:00:49.493Specific Date=2014-01-01T10:10:30Current Date in IST=2014-04-29T04:30:49.49310000th second time from 01/01/1970= 1970-01-01T02:46:40</code></pre><h2 id="2-5-Instant"><a href="#2-5-Instant" class="headerlink" title="2.5 Instant"></a>2.5 Instant</h2><p>是为了生成机器阅读的时间格式，它会使用unix的时间戳来存储日期和时间</p><pre><code>package com.journaldev.java8.time;import java.time.Duration;import java.time.Instant;public class InstantExample {    public static void main(String[] args) {        //Current timestamp        Instant timestamp = Instant.now();        System.out.println(&quot;Current Timestamp = &quot;+timestamp);        //Instant from timestamp        Instant specificTime = Instant.ofEpochMilli(timestamp.toEpochMilli());        System.out.println(&quot;Specific Time = &quot;+specificTime);        //Duration example        Duration thirtyDay = Duration.ofDays(30);        System.out.println(thirtyDay);    }}// Output Current Timestamp = 2014-04-28T23:20:08.489ZSpecific Time = 2014-04-28T23:20:08.489ZPT720H</code></pre><h2 id="2-6-常用API"><a href="#2-6-常用API" class="headerlink" title="2.6 常用API"></a>2.6 常用API</h2><pre><code>package com.journaldev.java8.time;import java.time.LocalDate;import java.time.LocalTime;import java.time.Period;import java.time.temporal.TemporalAdjusters;public class DateAPIUtilities {    public static void main(String[] args) {        LocalDate today = LocalDate.now();        //得到年份，看是否为闰年        System.out.println(&quot;Year &quot;+today.getYear()+&quot; is Leap Year? &quot;+today.isLeapYear());        //比较两个时间的先后        System.out.println(&quot;Today is before 01/01/2015? &quot;+today.isBefore(LocalDate.of(2015,1,1)));        //从LocalDate创建LocalDateTime        System.out.println(&quot;Current Time=&quot;+today.atTime(LocalTime.now()));        //加减时间的操作        System.out.println(&quot;10 days after today will be &quot;+today.plusDays(10));        System.out.println(&quot;3 weeks after today will be &quot;+today.plusWeeks(3));        System.out.println(&quot;20 months after today will be &quot;+today.plusMonths(20));        System.out.println(&quot;10 days before today will be &quot;+today.minusDays(10));        System.out.println(&quot;3 weeks before today will be &quot;+today.minusWeeks(3));        System.out.println(&quot;20 months before today will be &quot;+today.minusMonths(20));        //时间上的加减        System.out.println(&quot;First date of this month= &quot;+today.with(TemporalAdjusters.firstDayOfMonth()));        LocalDate lastDayOfYear = today.with(TemporalAdjusters.lastDayOfYear());        System.out.println(&quot;Last date of this year= &quot;+lastDayOfYear);        Period period = today.until(lastDayOfYear);        System.out.println(&quot;Period Format= &quot;+period);        System.out.println(&quot;Months remaining in the year= &quot;+period.getMonths());            }}Year 2014 is Leap Year? falseToday is before 01/01/2015? trueCurrent Time=2014-04-28T16:23:53.15410 days after today will be 2014-05-083 weeks after today will be 2014-05-1920 months after today will be 2015-12-2810 days before today will be 2014-04-183 weeks before today will be 2014-04-0720 months before today will be 2012-08-28First date of this month= 2014-04-01Last date of this year= 2014-12-31Period Format= P8M3DMonths remaining in the year= 8</code></pre><h2 id="2-7-时间的Parsing-和-Formatting"><a href="#2-7-时间的Parsing-和-Formatting" class="headerlink" title="2.7 时间的Parsing 和 Formatting"></a>2.7 时间的Parsing 和 Formatting</h2><pre><code>package com.journaldev.java8.time;import java.time.Instant;import java.time.LocalDate;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;public class DateParseFormatExample {    public static void main(String[] args) {        //Format examples        LocalDate date = LocalDate.now();        //default format        System.out.println(&quot;Default format of LocalDate=&quot;+date);        //使用特定的Formatter        System.out.println(date.format(DateTimeFormatter.ofPattern(&quot;d::MMM::uuuu&quot;)));        System.out.println(date.format(DateTimeFormatter.BASIC_ISO_DATE));        LocalDateTime dateTime = LocalDateTime.now();        //default format        System.out.println(&quot;Default format of LocalDateTime=&quot;+dateTime);        //specific format        System.out.println(dateTime.format(DateTimeFormatter.ofPattern(&quot;d::MMM::uuuu HH::mm::ss&quot;)));        System.out.println(dateTime.format(DateTimeFormatter.BASIC_ISO_DATE));        Instant timestamp = Instant.now();        //default format        System.out.println(&quot;Default format of Instant=&quot;+timestamp);        //Parse examples        LocalDateTime dt = LocalDateTime.parse(&quot;27::Apr::2014 21::39::48&quot;,                DateTimeFormatter.ofPattern(&quot;d::MMM::uuuu HH::mm::ss&quot;));        System.out.println(&quot;Default format after parsing = &quot;+dt);    }}// OutputDefault format of LocalDate=2014-04-2828::Apr::201420140428Default format of LocalDateTime=2014-04-28T16:25:49.34128::Apr::2014 16::25::4920140428Default format of Instant=2014-04-28T23:25:49.342ZDefault format after parsing = 2014-04-27T21:39:48</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.journaldev.com/2800/java-8-date-localdate-localdatetime-instant" target="_blank" rel="noopener">https://www.journaldev.com/2800/java-8-date-localdate-localdatetime-instant</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(17)-红黑树</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-17-%E7%BA%A2%E9%BB%91%E6%A0%91/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-17-%E7%BA%A2%E9%BB%91%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="红黑树的实现"><a href="#红黑树的实现" class="headerlink" title="红黑树的实现"></a>红黑树的实现</h1><p>首先对于我们前面看到的二叉查找树，在相对理想的情况下，它的时间负责度为O(logn).但是在频繁的动态更新的过程中，可能会出现树的高度远远大于log2(n)的情况，导致各项操作的效率下降.</p><p>在极端情况下，二叉查找树会退化为一个链表，时间复杂度会退化到O(n).为了解决这个复杂度退化的问题，我们需要设计一种平衡二叉查找树</p><h1 id="1-什么是平衡二叉查找树？"><a href="#1-什么是平衡二叉查找树？" class="headerlink" title="1. 什么是平衡二叉查找树？"></a>1. 什么是平衡二叉查找树？</h1><blockquote><p>平衡二叉查找树定义 二叉树中任意一个节点的左右子树的高度相差不能大于1.</p></blockquote><p>平衡二叉查找树的初衷是解决普通二叉查找树在频繁的插入，出现时间复杂度退化的问题</p><p>红黑树并没有严格满足平衡二叉查找树的定义，即其左右子树的高度有时相差是会超过1 的。 </p><p>平衡二叉查找树中平衡的意思就是让整棵树看起来比较对称，不要出现左子树很高，右子树很矮的情况。这样就能让整棵树的高度相对来说低一些。</p><ul><li>最开始被发明的是AVL树，严格符合平衡二叉查找树的定义<ul><li>任何节点的左右子树高度相差不超过1</li><li>是一种高度平衡的二叉查找树</li></ul></li></ul><h1 id="2-如何定义一棵红黑树-Red-Black-Tree"><a href="#2-如何定义一棵红黑树-Red-Black-Tree" class="headerlink" title="2. 如何定义一棵红黑树 Red Black Tree"></a>2. 如何定义一棵红黑树 Red Black Tree</h1><p>是一种不严格的平衡二叉查找树。红黑树当中的节点，一类被标记为黑色，一类被标记为红色。</p><ul><li>根节点是黑色的</li><li>每个叶子节点都是黑色的空节点(NIL)，即叶子节点不存储数据</li><li>任何相邻的节点都不能同时为红色，即红色节点是被黑色节点分割开的</li><li>每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点</li></ul><p>二叉查找树的很多操作的性能都跟树的高度成正比，因此为了证明红黑树近似平衡，我们需要分析的问题可以转化为其高度是否能比较稳定的趋近log2(n)。红黑树的插入，删除，查找等各种操作性能都比较稳定</p><p>AVL是高度平衡的二叉树，查找效率非常高，但是每次插入删除都要对应做调整，所以会比较复杂耗时。红黑树只是做到近似平衡，在维护平衡的成本上，要比AVL要低。</p><h1 id="3-如何实现一个红黑树"><a href="#3-如何实现一个红黑树" class="headerlink" title="3. 如何实现一个红黑树"></a>3. 如何实现一个红黑树</h1><p>红黑树的平衡过程就是<strong>根据节点排布的特征来，遇到什么样的节点排布，我们就对应的去进行调整</strong>。</p><ul><li>重要操作<ul><li>左旋 rotate left<ul><li>将基准点的右子树绕x做逆时针旋转，是的x的右子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的特性仍然能够得到满足</li></ul></li><li>右旋 rotate right<ul><li>将x的左子树绕x顺时针旋转，使得x的左子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然能够满足</li></ul></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.cnblogs.com/carpenterlee/p/5503882.html">https://www.cnblogs.com/carpenterlee/p/5503882.html</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 红黑树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(16)-二叉树</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-16-%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-16-%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
      
        <content type="html"><![CDATA[<h1 id="1-树"><a href="#1-树" class="headerlink" title="1. 树"></a>1. 树</h1><ul><li>父节点<ul><li>上层的节点 </li></ul></li><li>兄弟节点<ul><li>父节点是同一个节点 </li></ul></li><li>叶节点<ul><li>没有子节点的节点</li></ul></li><li>高度<ul><li>节点到叶子节点的最长路径 </li></ul></li><li>深度<ul><li>根节点到这个节点所经历的边的个数 </li></ul></li><li>层<ul><li>节点的深度 + 1 </li></ul></li></ul><h1 id="2-二叉树"><a href="#2-二叉树" class="headerlink" title="2. 二叉树"></a>2. 二叉树</h1><p>每个节点最多有两个分叉的树，即最多有两个子节点</p><p><img src="https://i.loli.net/2020/02/10/r72vjaPlpfsHmuE.jpg" alt="fig1.jpg"><br>2 显示的是满二叉树，特点是叶子节点都在最底层，出了叶子节点之外，每个节点都有左右两个子节点</p><p>3 叶子节点都在最底下两层，并且出了最后一层，其他的层的节点数量都要达到最大，并且最后一层的节点都是靠左排列的，这种二叉树叫做完全二叉树。</p><h2 id="2-1-如何表示-存储一棵二叉树？"><a href="#2-1-如何表示-存储一棵二叉树？" class="headerlink" title="2.1 如何表示/ 存储一棵二叉树？"></a>2.1 如何表示/ 存储一棵二叉树？</h2><h3 id="2-1-1-基于指针或者引用的二叉链式存储法"><a href="#2-1-1-基于指针或者引用的二叉链式存储法" class="headerlink" title="2.1.1 基于指针或者引用的二叉链式存储法"></a>2.1.1 基于指针或者引用的二叉链式存储法</h3><p><img src="https://i.loli.net/2020/02/10/M1I6FkWJodTq3fX.jpg" alt="fig2.jpg"></p><p>每个节点都有三个字段，其中一个存储数据，另外两个指向左右子节点的指针。因此通过根节点，我们就可以通过左右子节点的指针将整棵树都串起来了。</p><h3 id="2-1-2-基于数组的顺序存储法"><a href="#2-1-2-基于数组的顺序存储法" class="headerlink" title="2.1.2 基于数组的顺序存储法"></a>2.1.2 基于数组的顺序存储法</h3><p><img src="https://i.loli.net/2020/02/10/P62NlH8EbY3LBXv.jpg" alt="fig3.jpg"><br>如果节点X存储在数组中下标为i的位置，下标为2<em>i的位置存储的是左子节点，下标为2</em>i + 1的位置存储的就是右子节点。下标为i/2的位置存储的就是它的父节点了。通过这种方式，我们只要知道根节点存储的位置，就可以通过下标计算，把整棵树都串起来。 不过对于一棵非完全二叉树而言，会浪费比较多的数组存储空间的。</p><h2 id="2-2-二叉树的遍历"><a href="#2-2-二叉树的遍历" class="headerlink" title="2.2 二叉树的遍历"></a>2.2 二叉树的遍历</h2><h3 id="2-2-0-递归公式"><a href="#2-2-0-递归公式" class="headerlink" title="2.2.0 递归公式"></a>2.2.0 递归公式</h3><p><img src="https://i.loli.net/2020/02/10/o1TLXDnalmgBzAQ.jpg" alt="fig4.jpg"></p><p>二叉树的遍历整体就是一个递归的过程</p><p>写递归代码的关键，就是看能不能写出一个递推公式。而递推公式的关键，就是如果要解决问题A，就假设子问题B,C都已经解决，然后再来看如何利用B，C来解决A</p><pre><code>前序遍历的递推公式：preOrder(r) = print r-&gt;preOrder(r-&gt;left)-&gt;preOrder(r-&gt;right)中序遍历的递推公式：inOrder(r) = inOrder(r-&gt;left)-&gt;print r-&gt;inOrder(r-&gt;right)后序遍历的递推公式：postOrder(r) = postOrder(r-&gt;left)-&gt;postOrder(r-&gt;right)-&gt;print r// 前序遍历void preOrder(Node* root) {  if (root == null) return;  print root // 此处为伪代码，表示打印root节点  preOrder(root-&gt;left);  preOrder(root-&gt;right);}// 中序遍历void inOrder(Node* root) {  if (root == null) return;  inOrder(root-&gt;left);  print root // 此处为伪代码，表示打印root节点  inOrder(root-&gt;right);}// 后序遍历void postOrder(Node* root) {  if (root == null) return;  postOrder(root-&gt;left);  postOrder(root-&gt;right);  print root // 此处为伪代码，表示打印root节点}</code></pre><h3 id="2-2-1-前序遍历"><a href="#2-2-1-前序遍历" class="headerlink" title="2.2.1 前序遍历"></a>2.2.1 前序遍历</h3><p>对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。</p><h3 id="2-2-2-中序遍历"><a href="#2-2-2-中序遍历" class="headerlink" title="2.2.2 中序遍历"></a>2.2.2 中序遍历</h3><p>对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树</p><h3 id="2-2-3-后序遍历"><a href="#2-2-3-后序遍历" class="headerlink" title="2.2.3 后序遍历"></a>2.2.3 后序遍历</h3><p>对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身</p><h1 id="3-二叉查找树"><a href="#3-二叉查找树" class="headerlink" title="3. 二叉查找树"></a>3. 二叉查找树</h1><p>支持动态数据集合的快速插入、删除、查找操作。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构与算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(15)-哈希算法</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-15-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-15-%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是哈希算法"><a href="#1-什么是哈希算法" class="headerlink" title="1. 什么是哈希算法"></a>1. 什么是哈希算法</h1><blockquote><p>将任意长度的二进制串映射为固定长度的二进制串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制串就是哈希值</p></blockquote><ul><li>哈希算法的要求<ul><li>从哈希值无法反向推导出原始数据</li><li>对输入数据非常敏感，哪怕原始数据只修改一个bit，最后得到的哈希值也会大不相同</li><li>散列冲突的概率很小，对于不同的原始数据，哈希值相同的概率非常小</li><li>哈希算法的效率要足够高，针对较长文本，也能快速计算出哈希值</li></ul></li></ul><h1 id="2-哈希算法的应用"><a href="#2-哈希算法的应用" class="headerlink" title="2. 哈希算法的应用"></a>2. 哈希算法的应用</h1><h2 id="2-1-安全加密"><a href="#2-1-安全加密" class="headerlink" title="2.1 安全加密"></a>2.1 安全加密</h2><ul><li>常用de加密算法<ul><li>MD5<ul><li>MD5 Message-Digest Algorithm </li><li>MD5信息摘要算法</li></ul></li><li>SHA <ul><li>Secure Hash Algorithm 安全散列算法</li></ul></li><li>DES <ul><li>Data Encryption Standard 数据加密标准</li></ul></li><li>AES <ul><li>Advanced Encryption Standard 高级加密标准</li></ul></li></ul></li></ul><h2 id="2-2-唯一标识"><a href="#2-2-唯一标识" class="headerlink" title="2.2 唯一标识"></a>2.2 唯一标识</h2><p>图片的标识，从图片的二进制串码的前中后各取出100字节，通过哈希算法得到一个哈希字符串，用它作为图片的唯一标识。然后通过这个唯一标识来判定图片是否在图库当中，通过这种方式来减少工作量。</p><h2 id="2-3-数据校验"><a href="#2-3-数据校验" class="headerlink" title="2.3 数据校验"></a>2.3 数据校验</h2><p>BT协议的数据校验，对每个文件块取哈希值，保存在种子文件当中。当文件块下载完成之后，我们通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值进行比对。如果不同，就说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。</p><h2 id="2-4-散列函数"><a href="#2-4-散列函数" class="headerlink" title="2.4 散列函数"></a>2.4 散列函数</h2><p>哈希表的散列函数，关注的是在做完哈希以后，是否能够平均的分布。一组数据能否均匀散列在各个槽中。 </p><p>另外一个点是其执行速度，散列函数对执行速度的要求会比较高一些。</p><h2 id="2-5-负载均衡"><a href="#2-5-负载均衡" class="headerlink" title="2.5 负载均衡"></a>2.5 负载均衡</h2><p>分布式系统当中需要解决的问题</p><ul><li>负载均衡的算法<ul><li>轮询</li><li>随机</li><li>加权轮询</li></ul></li></ul><p>但是我们需要实现一个会话粘滞的负载均衡算法(session sticky)。即我们需要在一个客户端上，在一次会话上的所有请求都路由到同一个服务器上。</p><p>通过哈希算法，对客户端IP地址或者会话的ID计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器的编号。</p><h2 id="2-6-数据分片"><a href="#2-6-数据分片" class="headerlink" title="2.6 数据分片"></a>2.6 数据分片</h2><h3 id="2-6-1-如何统计关键词搜索的次数"><a href="#2-6-1-如何统计关键词搜索的次数" class="headerlink" title="2.6.1 如何统计关键词搜索的次数"></a>2.6.1 如何统计关键词搜索的次数</h3><p>假设我们有1T的日志文件，里面记录了用户的关键词，我们想快速统计出来每个关键词被搜索的次数，该怎么做呢？ </p><ol><li>数据量太大的问题</li><li>处理时间太长的问题</li></ol><p>对数据进行分片，然后多台机器进行处理。用哈希算法，将哈希值相同的搜索关键词放到同一台机器上。然后最后做汇总</p><h3 id="2-6-2-如何快速判断图片是否在图库当中"><a href="#2-6-2-如何快速判断图片是否在图库当中" class="headerlink" title="2.6.2 如何快速判断图片是否在图库当中"></a>2.6.2 如何快速判断图片是否在图库当中</h3><p>为每个图片取唯一标识，然后构建散列表，但是当图片量很大的时候，在单台机器上构建散列表是行不通的。</p><p>因为在存储的时候，我们还是需要根据哈希算法取模来进行存储，然后在进行判断的时候，也是用同样的哈希算法，然后与机器个数n求余取模。然后根据得到的值到对应的机器上去进行查找。</p><h2 id="2-7-分布式存储"><a href="#2-7-分布式存储" class="headerlink" title="2.7 分布式存储"></a>2.7 分布式存储</h2><p>分布式存储需要解决的问题是，当我们已经在各个host上按照哈希算法保存了数据以后，再增减host的时候，我们不希望还需要对原先的host里面的数据做迁移。如果说缓存当中的数据会一下子全都失效的话，那么所有数据请求都要从数据库走，直接就压垮数据库了。</p><p>因此在分布式存储当中，我们需要采用<strong><em>一致性哈希算法</em></strong></p><p>假设我们有 k 个机器，数据的哈希值的范围是[0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 哈希算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(14)-散列表</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-14-%E6%95%A3%E5%88%97%E8%A1%A8/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-14-%E6%95%A3%E5%88%97%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><p>散列表 - Hash Table, 又被称为哈希表或者Hash表。散列表用的是数组支持按照下标来随机访问数据的特性，因此散列表实际上是数组的一种扩展，由数组演化而来。</p><p>散列的思想就是对于key值，通过hash function，对应到table上来进行存储</p><p><img src="https://i.loli.net/2020/02/10/pnWdbkoVjUE7aTw.jpg" alt="fig1.jpg"></p><h1 id="2-散列函数"><a href="#2-散列函数" class="headerlink" title="2. 散列函数"></a>2. 散列函数</h1><p>散列函数就是实现输入到存储的对应的函数，因为最终是要存储到数组当中，故而其基本要求有：</p><ol><li>散列函数计算得到的散列值是一个非负整数</li><li>如果Key1 = Key2,那么hash(key1) == hash(key2)</li><li>如果key1 != key2, 那么hash(key1) != hash(key2)</li></ol><p>条件3 即如何应对散列冲突的问题，首先本身是必须的，而且客观是存在散列冲突的情况的，针对于散列冲突，我们一般会使用开放寻址法和链表法。</p><h1 id="3-如何解决散列冲突"><a href="#3-如何解决散列冲突" class="headerlink" title="3. 如何解决散列冲突"></a>3. 如何解决散列冲突</h1><h2 id="3-1-开放寻址法"><a href="#3-1-开放寻址法" class="headerlink" title="3.1 开放寻址法"></a>3.1 开放寻址法</h2><ul><li>核心思想<ul><li>出现了散列冲突，就重新探测一个空闲位置，将其插入</li></ul></li><li>探测方法<ul><li>线性探测</li><li>二次探测<ul><li>探测步长为二次方的增长 </li></ul></li><li>双重散列<ul><li>使用第一个散列函数进行尝试</li><li>如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推直到找到空闲的存储位置</li></ul></li></ul></li><li>装载因子<ul><li>引入装在引资的概念来表示空位的多少</li><li><code>装载因子 = 填入表中的元素个数/散列表的长度</code></li></ul></li></ul><h2 id="3-2-链表法"><a href="#3-2-链表法" class="headerlink" title="3.2 链表法"></a>3.2 链表法</h2><p><img src="https://i.loli.net/2020/02/10/VAUezcR2phPlYjT.jpg" alt="fig2.jpg"></p><p>链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。我们来看这个图，在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。</p><h1 id="4-工程上使用的散列表"><a href="#4-工程上使用的散列表" class="headerlink" title="4. 工程上使用的散列表"></a>4. 工程上使用的散列表</h1><p>首先我们需要思考下实际应用场景当中的散列表，虽然我们说散列表的查询效率是O(1), 实质上他的真实数据时和散列函数，装载因子，散列冲突都有关系的。如果散列函数设计的不好，或者装载因子过高，都可能导致散列冲突发生的概率升高，从而导致查询的效率下降。</p><p>因此对于在工程上使用的散列表，首先要考虑的就是需要能够应对各种异常情况，来避免散列冲突的情况下散列表性能的急剧下降，并且需要能够抵抗散列碰撞攻击。</p><h2 id="4-1-如何设计散列函数"><a href="#4-1-如何设计散列函数" class="headerlink" title="4.1 如何设计散列函数"></a>4.1 如何设计散列函数</h2><ul><li>需求<ul><li>散列函数的设计不能太复杂 <ul><li>会消耗很多计算时间</li><li>即会影响到散列表的性能</li></ul></li><li>散列函数生成的值需要尽可能随机并且均匀分布</li></ul></li><li>如何解决装载因子过大的问题<ul><li>针对散列表，当装载因子过大的时候，我们也可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新的散列表当中。</li><li>同时也有装载因子太小的情况下，我们可以做动态缩容的工作</li></ul></li><li>如何避免低效扩容<ul><li>所谓低效的扩容指的是如果我们在装载因子超过阈值的时候一下子进行扩容，即数据的搬运和最终的新数据的插入，那针对这一个数据，其时间复杂度变成了O(n).</li><li>为了解决这个问题，我们在需要进行扩容的时候，将扩容的操作穿插在插入操作的过程当中，分批次来完成。当装载因子触达阈值的时候，只申请新空间，但是没有将老的数据搬移到新的散列表当中。</li><li>当有新数据插入的时候，就将新数据放到新的散列表当中，并且从老的散列表当中拿一个数据放到新的散列表当中</li><li>而查询操作，为了兼顾，我们会先从新的散列表当中查找，如果没有找到，再去老的散列表当中查找</li></ul></li></ul><h2 id="4-2-如何解决冲突？"><a href="#4-2-如何解决冲突？" class="headerlink" title="4.2 如何解决冲突？"></a>4.2 如何解决冲突？</h2><h3 id="4-2-1-开放寻址法"><a href="#4-2-1-开放寻址法" class="headerlink" title="4.2.1 开放寻址法"></a>4.2.1 开放寻址法</h3><ul><li>优势<ul><li>数据都存储在数组当中，可以有效利用CPU缓存加快查询速度</li><li>序列化比较简单</li></ul></li><li>缺陷<ul><li>删除数据比较麻烦，需要特殊标记已经删除的数据</li><li>冲突代价高，导致装载因子的上限不能太大</li></ul></li></ul><blockquote><p>当数据量比较小，装载因子小的时候，适合使用开放寻址法。</p></blockquote><h3 id="4-2-2-链表法"><a href="#4-2-2-链表法" class="headerlink" title="4.2.2 链表法"></a>4.2.2 链表法</h3><ul><li>优势<ul><li>对内存的利用率相对比较高，因为链表结点可以在需要的时候再创建，不需要提前申请好</li><li>可以允许很高的装载因子</li></ul></li><li>劣势<ul><li>因为要存储指针，对于小的对象的存储，是更加耗内存的</li><li>因为结点零散分布在内存当中，不是连续的，所以对CPU缓存不友好，对执行效率会造成一定的影响</li></ul></li></ul><h2 id="4-3-Java-HashMap举例"><a href="#4-3-Java-HashMap举例" class="headerlink" title="4.3 Java HashMap举例"></a>4.3 Java HashMap举例</h2><ul><li>初始大小 - 16<ul><li>如果大概知道数据量的大小，可以修改默认，来减少动态扩容的次数</li></ul></li><li>装载因子和动态扩容<ul><li>默认 load factor 0.75 </li><li>每次扩容大小变为两倍</li></ul></li><li>散列冲突解决方法<ul><li>采用链表法</li><li>1.8以后当链表长度超过8以后，链表就会自动转化为红黑树</li></ul></li><li>散列函数</li></ul><pre><code>int hash(Object key) {    int h = key.hashCode()；    return (h ^ (h &gt;&gt;&gt; 16)) &amp; (capicity -1); //capicity表示散列表的大小} </code></pre><p><code>&amp;(capacity - 1)</code> means <code>% capacity</code></p><p>因为hashcode本身是个32位的整型值，获得其hash值以后，将高16位移到低16位，就相当于拿到了高16位和低16位的feature。用自己的高半区和低半区做异或，为的是加大低位的随机性。这样子哪怕是高位的变化也可以反映到低位当中，保证了最终进bin的随机性</p><h1 id="5-散列表实际应用"><a href="#5-散列表实际应用" class="headerlink" title="5. 散列表实际应用"></a>5. 散列表实际应用</h1><p>散列表和链表经常是共同使用的,这一部分会walk through一些常用的场景，看看是如何来共同使用的。</p><h2 id="5-1-LRU缓存淘汰算法"><a href="#5-1-LRU缓存淘汰算法" class="headerlink" title="5.1 LRU缓存淘汰算法"></a>5.1 LRU缓存淘汰算法</h2><p>最基础的LRU实现，我们可以通过链表来做.维护一个按照访问时间从大到小有序排列的链表结构，因为缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，我们就直接将链表头部的结点删除。</p><p>我们可以选择使用散列表和双向链表一起来实现LRU cache。要实现的操作有：</p><ul><li>往缓存中加入数据</li><li>从缓存中删除数据</li><li>在缓存中查找数据</li></ul><p><img src="https://i.loli.net/2020/02/10/LIB2nkbZYudrq37.jpg" alt="fig3.jpg"></p><p>如图所示，我们相当于在维护两条链表，一条是在哈希表的每个entry上的链，在这上面的链是为了解决哈希冲突的；另外一个点，我们在使用的是维护LRU cache的链表。</p><p>链表当中的每个结点保存了：</p><ul><li>prev</li><li>next</li><li>data</li><li>hnext<ul><li>散列表上碰撞问题的解决的 </li></ul></li></ul><h2 id="5-2-Java-LinkedHashMap"><a href="#5-2-Java-LinkedHashMap" class="headerlink" title="5.2 Java LinkedHashMap"></a>5.2 Java LinkedHashMap</h2><p>LinkedHashMap能够实现按照数据的插入顺序来进行打印，是因为他也是通过散列表和链表组合在一起的方式实现的。它支持按照插入顺序遍历数据，还支持按照访问顺序来遍历数据</p><pre><code>// 10是初始大小，0.75是装载因子，true是表示按照访问时间排序HashMap&lt;Integer, Integer&gt; m = new LinkedHashMap&lt;&gt;(10, 0.75f, true);m.put(3, 11);m.put(1, 12);m.put(5, 23);m.put(2, 22);m.put(3, 26);m.get(5);for (Map.Entry e : m.entrySet()) {  System.out.println(e.getKey());}// print out: 1, 2, 3, 5</code></pre><p><img src="https://i.loli.net/2020/02/10/wxy1tumrZO3DXQz.jpg" alt="fig4.jpg"></p><p><img src="https://i.loli.net/2020/02/10/9phoBuRSI5gsJC4.jpg" alt="fig5.jpg"></p><p><img src="https://i.loli.net/2020/02/10/3KGVI15LDp4PSAZ.jpg" alt="fig6.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 散列表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(13)-跳表</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-13-%E8%B7%B3%E8%A1%A8/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-13-%E8%B7%B3%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h1><ul><li>跳表<ul><li>动态数据结构</li><li>可以支持快速的插入，删除，查找操作</li><li>写起来也不会很复杂</li></ul></li></ul><p>Redis当中的有序集合就是用跳表来实现的。</p><h1 id="2-如何理解跳表"><a href="#2-如何理解跳表" class="headerlink" title="2. 如何理解跳表"></a>2. 如何理解跳表</h1><p>对于一个单链表来说，即便链表当中存储的数据是有序的，如果我们想要从中查找某个数据，也只能从头到尾遍历链表，这样查找效率就会非常低，时间复杂度比较高，O(n)</p><p>为了解决这个问题，我们可以对链表建立一级索引，每几个结点就提取一个结点到上一级当中，抽出来的那一级我们就可以将其叫做索引或者索引层了。</p><p>通过增加索引的层级，来加快寻找节点的速度，这就是跳表 – 链表加上多级索引的结构</p><ul><li>时间复杂度非常理想 O(logn)</li><li>但是相对来说会更需要内存一些  空间复杂度为O(n)</li></ul><h1 id="3-高效的动态插入和删除操作"><a href="#3-高效的动态插入和删除操作" class="headerlink" title="3. 高效的动态插入和删除操作"></a>3. 高效的动态插入和删除操作</h1><p>其动态的插入和删除操作的时间复杂度为O(logn)</p><p><img src="https://i.loli.net/2020/02/10/f4vdSyzCEs2KWFY.jpg" alt="fig1.jpg"></p><p>删除操作，还是需要拿到删除节点的前驱节点，然后通过指针操作完成删除。</p><h2 id="4-跳表索引动态更新"><a href="#4-跳表索引动态更新" class="headerlink" title="4. 跳表索引动态更新"></a>4. 跳表索引动态更新</h2><p><img src="https://i.loli.net/2020/02/10/J5QxpXFgAeTCa2j.jpg" alt="fig2.jpg"></p><p>跳表是需要不断更新的，因为当我们不断向跳表里面插入数据的时候，如果我们不更新索引，就有可能出现两个索引节点之间数据非常多的情况。极端情况下，跳表就会退化成单链表。</p><ul><li>我们需要某种方式来维护索引与原始链表大小之间的平衡<ul><li>跳表是通过随机函数来维护平衡性的</li><li>当我们往跳表里面插入数据的时候，可以选择同时将这个数据插入到部分索引层当中。</li><li>根据随机函数来决定这个结点插入到哪几级索引当中。</li></ul></li></ul><p><img src="https://i.loli.net/2020/02/10/64FQnKPZ8uWlTCb.jpg" alt="fig3.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 跳表 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(12)-二分查找</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-12-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-12-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/</url>
      
        <content type="html"><![CDATA[<p>二分查找是一种针对于有序数据集合的查找算法，也叫折半查找算法。类似分治的思想，每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为0. 查找速度为O(logn)</p><p>思考题：1000万个整数数据，每个数据8字节，</p><h1 id="1-二分查找的基本实现"><a href="#1-二分查找的基本实现" class="headerlink" title="1. 二分查找的基本实现"></a>1. 二分查找的基本实现</h1><pre><code>public int bsearch(int[] a, int n, int value) {// 定基准点  int low = 0;  int high = n - 1;// 停止条件  while (low &lt;= high) {    // 定二分点    int mid = (low + high) / 2;    if (a[mid] == value) {      return mid;    } else if (a[mid] &lt; value) {     // 保证是活循环..       low = mid + 1;    } else {      high = mid - 1;    }  }  return -1;}// 二分查找的递归实现public int bsearch(int[] a, int n, int val) {  return bsearchInternally(a, 0, n - 1, val);}private int bsearchInternally(int[] a, int low, int high, int value) {  if (low &gt; high) return -1;  int mid =  low + ((high - low) &gt;&gt; 1);  if (a[mid] == value) {    return mid;  } else if (a[mid] &lt; value) {    return bsearchInternally(a, mid+1, high, value);  } else {    return bsearchInternally(a, low, mid-1, value);  }}</code></pre><ul><li>循环退出条件<ul><li>low &lt;= high </li></ul></li><li>mid取值<ul><li>mid = low + (high - low)/2</li><li>因为如果值太大的话，会溢出的</li></ul></li><li>low high的更新<ul><li>low = mid + 1</li><li>high = mid - 1 </li></ul></li></ul><h1 id="2-二分查找的应用场景局限性"><a href="#2-二分查找的应用场景局限性" class="headerlink" title="2. 二分查找的应用场景局限性"></a>2. 二分查找的应用场景局限性</h1><ul><li>二分查找以来的是顺序表结构  – 数组<ul><li>因为二分查找需要按照下标来随机访问元素</li></ul></li><li>针对的是有序数据 – 静态数据集<ul><li>更适用在插入，删除不频繁，一次排序多次查找的场景当中</li><li>针对动态变化的数据集合，二分查找就不再适用了</li></ul></li><li>数据量太小不需要适用二分查找</li><li>如果数据之间的比较非常耗时，我们需要尽力减少比较的次数，那么二分查找就是很好的方式了</li></ul><h1 id="3-二分查找的实际应用与变体"><a href="#3-二分查找的实际应用与变体" class="headerlink" title="3. 二分查找的实际应用与变体"></a>3. 二分查找的实际应用与变体</h1><h2 id="3-1-查找第一个值等于给定值的元素"><a href="#3-1-查找第一个值等于给定值的元素" class="headerlink" title="3.1 查找第一个值等于给定值的元素"></a>3.1 查找第一个值等于给定值的元素</h2><pre><code>public int bsearch(int[] a, int n, int value) {  int low = 0;  int high = n - 1;  while (low &lt;= high) {    int mid =  low + ((high - low) &gt;&gt; 1);    if (a[mid] &gt; value) {      high = mid - 1;    } else if (a[mid] &lt; value) {      low = mid + 1;    } else {      // 注意这里的判断，中止条件时mid为0 或者左一个的值和现在的值不相等       if ((mid == 0) || (a[mid - 1] != value)) return mid;      else high = mid - 1;    }  }  return -1;}</code></pre><ul><li>写二分相关的算法要注意的点有<ul><li>终止条件</li><li>区间上下界的更新方法</li><li>返回值的选择</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二分查找 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(11)-应用场景下的排序函数</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-11-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8E%92%E5%BA%8F%E5%87%BD%E6%95%B0/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-11-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E6%8E%92%E5%BA%8F%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<p>在日常开发当中，无论我们使用的语言是什么，他们几乎都会提供排序算法，本篇博文将尝试着对其进行分析，看看如何实现一个通用的，高性能的排序算法。</p><p>首先看看我们的现有排序算法库，看看我们的选择空间在哪里： </p><p><img src="https://i.loli.net/2020/02/10/2ga9UPTNkOcb8wr.jpg" alt="fig1.jpg"></p><p>如果对于小规模数据排序，可以选择O(n^2); 但是对于大规模的数据，时间复杂度为O(nlogn)的算法会高效很多。因此为了兼顾任意规模数据的排序，一般都会首选时间复杂度为O(nlogn)的排序算法来实现排序函数。</p><p>一般来说会选用堆排序或者快速排序来做。</p><p>因为在实际情况下内存的占用情况是非常关键的参数了，所以我们需要看待选算法的空间复杂度，最好是原地的，即不占用更多的空间。像归并排序，时间复杂度很合适但是空间复杂度为O(n)，那就完全不是一个好选择了</p><p>快速排序想要优化的话，主要的点在于要选准分区点，好的分区点是希望其两个分区数据的数量是差不多的才可以。我们可以随机取值，也可以多取几个随机点，然后求平均。</p><p>还有一点需要注意的是在实际情况当中, O(n^2)有可能会比O(nlogn)要快的，因为小规模数据集的时候首先常量就不能忽略掉了。在这种情况下，可能插入排序反而会更快。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 排序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(10)-排序(桶排序 计数排序 基数排序)</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-10-%E6%8E%92%E5%BA%8F-%E6%A1%B6%E6%8E%92%E5%BA%8F-%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F-%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-10-%E6%8E%92%E5%BA%8F-%E6%A1%B6%E6%8E%92%E5%BA%8F-%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F-%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<p>上述三种排序方法的时间复杂度均为线性，因此将其称为线性排序(Linear sort).之所以能做先线性的时间复杂度，是因为他们都不是基于比较的排序算法，并不涉及到元素之间的比较操作。</p><h1 id="1-桶排序-Bucket-Sort"><a href="#1-桶排序-Bucket-Sort" class="headerlink" title="1. 桶排序 Bucket Sort"></a>1. 桶排序 Bucket Sort</h1><ul><li>核心思想<ul><li>将排序的数据分到几个有序的桶当中，每个桶的数据再单独进行排序。桶内排完序之后，再将每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。</li></ul></li><li>分析<ul><li>如果要排序的数据为 n个，将其均匀分到m个桶当中，每个桶就有 k=n/m个元素。每个桶内部使用快排，时间复杂度为O(k*logk)</li><li>m个桶的时间复杂度就为O(n*log(n/m)) </li><li>当m的数量非常接近n的时候，那么log(n/m)就是一个非常小的常量，这时候桶排序的时间复杂度就接近O(n)了</li></ul></li><li>优劣势<ul><li>对数据本身要求比较苛刻</li><li>需要足够均匀，否则桶内排序就不是常量级的复杂度了</li></ul></li><li>桶排序  适合在外部排序当中<ul><li>指数据存储在外部磁盘当中，数据量比较大，内存有限，无法将数据全部加载到内存当中 </li><li>顺序进行划分，挨个顺次放到内存当中</li></ul></li></ul><h1 id="2-计数排序-Counting-Sort"><a href="#2-计数排序-Counting-Sort" class="headerlink" title="2. 计数排序 Counting Sort"></a>2. 计数排序 Counting Sort</h1><p>类似于桶排序，但是每个桶里面存储的只是个数</p><pre><code>// 计数排序，a是数组，n是数组大小。假设数组中存储的都是非负整数。public void countingSort(int[] a, int n) {  if (n &lt;= 1) return;  // 查找数组中数据的范围  int max = a[0];  for (int i = 1; i &lt; n; ++i) {    if (max &lt; a[i]) {      max = a[i];    }  }  int[] c = new int[max + 1]; // 申请一个计数数组c，下标大小[0,max]  for (int i = 0; i &lt;= max; ++i) {    c[i] = 0;  }  // 计算每个元素的个数，放入c中  for (int i = 0; i &lt; n; ++i) {    c[a[i]]++;  }  // 依次累加  for (int i = 1; i &lt;= max; ++i) {    c[i] = c[i-1] + c[i];  }  // 临时数组r，存储排序之后的结果  int[] r = new int[n];  // 计算排序的关键步骤，有点难理解  for (int i = n - 1; i &gt;= 0; --i) {    int index = c[a[i]]-1;    r[index] = a[i];    c[a[i]]--;  }  // 将结果拷贝给a数组  for (int i = 0; i &lt; n; ++i) {    a[i] = r[i];  }}</code></pre><h1 id="3-基数排序-Radix-Sort"><a href="#3-基数排序-Radix-Sort" class="headerlink" title="3. 基数排序 Radix Sort"></a>3. 基数排序 Radix Sort</h1><p>排10万个手机号码，从小到大来排序？ </p><p>按照位来排，需要选用稳定性的算法来做。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 排序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(9)-排序(归并 快排)</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-9-%E6%8E%92%E5%BA%8F-%E5%BD%92%E5%B9%B6-%E5%BF%AB%E6%8E%92/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-9-%E6%8E%92%E5%BA%8F-%E5%BD%92%E5%B9%B6-%E5%BF%AB%E6%8E%92/</url>
      
        <content type="html"><![CDATA[<p>这节主要讲归并排序和快速排序，二者其实都用了分治的思想，可以借鉴这个思想，来解决诸如“如何在O(n)的时间复杂度内查找一个无序数组中的第k大元素”这样的问题。</p><h1 id="1-归并排序"><a href="#1-归并排序" class="headerlink" title="1. 归并排序"></a>1. 归并排序</h1><p><img src="https://i.loli.net/2020/02/10/fVpOLyXAhjn2cKW.jpg" alt="fig1.jpg"></p><ul><li><p>归并排序</p><ul><li>分治思想</li><li>分治是一种解决问题的处理思想，递归是一种编程技巧</li><li>和递归的三要素很类似，先分析得出递推公式，然后找到终止条件，再将递推公式翻译成递归代码。</li></ul></li><li><p>注意是分成了分开和合并两个过程的，在合并的过程当中，需要遍历两个有序子集，相互比较大小，然后放置在另外一个空间当中</p></li></ul><pre><code>递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))终止条件：p &gt;= r 不用再继续分解// 归并排序算法, A 是数组，n 表示数组大小merge_sort(A, n) {  merge_sort_c(A, 0, n-1)}// 递归调用函数merge_sort_c(A, p, r) {  // 递归终止条件  if p &gt;= r  then return  // 取 p 到 r 之间的中间位置 q  q = (p+r) / 2  // 分治递归  merge_sort_c(A, p, q)  merge_sort_c(A, q+1, r)  // 将 A[p...q] 和 A[q+1...r] 合并为 A[p...r]  merge(A[p...r], A[p...q], A[q+1...r])}</code></pre><ul><li>稳定排序</li><li>时间复杂度为O(nlog(n))</li><li>需要借助额外空间，不是原地排序算法  空间复杂度 O(n) 每次搞完就会直接释放掉了</li></ul><h1 id="2-快速排序"><a href="#2-快速排序" class="headerlink" title="2. 快速排序"></a>2. 快速排序</h1><p><img src="https://i.loli.net/2020/02/10/J6wH1nKPtv9qIAm.jpg" alt="fig2.jpg"></p><ul><li>快排的思想<ul><li>如果要排序数组中下标从p到r之间的一组数据，我们选择p到r之间的任意一个数据作为pivot(分区点) </li><li>我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。</li><li>快速排序是一种不稳定的排序方法，因为要实现swap</li></ul></li></ul><pre><code>递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)终止条件：p &gt;= r// 快速排序，A 是数组，n 表示数组的大小quick_sort(A, n) {  quick_sort_c(A, 0, n-1)}// 快速排序递归函数，p,r 为下标quick_sort_c(A, p, r) {  if p &gt;= r then return  q = partition(A, p, r) // 获取分区点  quick_sort_c(A, p, q-1)  quick_sort_c(A, q+1, r)}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 排序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(8)-排序(冒泡 插入 选择)</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-8-%E6%8E%92%E5%BA%8F-%E5%86%92%E6%B3%A1-%E6%8F%92%E5%85%A5-%E9%80%89%E6%8B%A9/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-8-%E6%8E%92%E5%BA%8F-%E5%86%92%E6%B3%A1-%E6%8F%92%E5%85%A5-%E9%80%89%E6%8B%A9/</url>
      
        <content type="html"><![CDATA[<ul><li>这里介绍三大类型的排序<ul><li>冒泡，插入，选择  O(n^2)</li><li>快排，归并 O(nlogn)</li><li>桶，计数，基数</li></ul></li></ul><h1 id="1-如何分析一个排序算法？"><a href="#1-如何分析一个排序算法？" class="headerlink" title="1. 如何分析一个排序算法？"></a>1. 如何分析一个排序算法？</h1><h2 id="1-1-执行效率"><a href="#1-1-执行效率" class="headerlink" title="1.1 执行效率"></a>1.1 执行效率</h2><ul><li>最好情况，最坏情况，平均情况时间复杂度<ul><li>要知道针对于数据集的特征，需要采取哪一种排序算法 </li></ul></li><li>时间复杂度的系数，常数，低阶<ul><li>实际开发过程中，面对规模比较小的数据，我们可能需要将系数，常数，低阶都考虑进去才可以的 </li></ul></li><li>比较次数和交换次数<ul><li>对于基于比较的排序算法，会涉及到元素大小的比较以及元素的交换或者移动，因此当我们在分析排序算法的执行效率的时候，应该把比较次数和交换次数也考虑进去 </li></ul></li></ul><h2 id="1-2-排序算法的内存消耗"><a href="#1-2-排序算法的内存消耗" class="headerlink" title="1.2 排序算法的内存消耗"></a>1.2 排序算法的内存消耗</h2><p>内存消耗可以用空间复杂度来衡量，来看算法究竟消耗了多少内存空间</p><h2 id="1-3-排序算法的稳定性"><a href="#1-3-排序算法的稳定性" class="headerlink" title="1.3 排序算法的稳定性"></a>1.3 排序算法的稳定性</h2><p>如果待排序的序列中存在值相等的元素，经过排序以后，相等元素之间原有的先后顺序不变</p><p>稳定性很重要，表现在要对几个影响因素来按照步骤进行排序的情况。</p><h1 id="2-算法分析"><a href="#2-算法分析" class="headerlink" title="2. 算法分析"></a>2. 算法分析</h1><h2 id="2-1-冒泡排序"><a href="#2-1-冒泡排序" class="headerlink" title="2.1 冒泡排序"></a>2.1 冒泡排序</h2><ul><li>操作相邻的两个数据<ul><li>每次冒泡都会对相邻的两个元素进行比较，</li><li>看是否满足大小关系要求</li><li>如果不满足就让它倆互换，一次冒泡至少会让一个元素移动到它应该在的位置，重复n次，就完成了n个数据的排序工作</li></ul></li></ul><p><img src="https://i.loli.net/2020/02/10/zUxOmSFQJLiyGMD.jpg" alt="fig1.jpg"></p><p><img src="https://i.loli.net/2020/02/10/o8L1DHgENfb2su7.jpg" alt="fig2.jpg"></p><pre><code>// 冒泡排序，a 表示数组，n 表示数组大小public void bubbleSort(int[] a, int n) {  if (n &lt;= 1) return; for (int i = 0; i &lt; n; ++i) {    // 提前退出冒泡循环的标志位，如果没有冒泡，说明已经有序了，不用再进行下去了    boolean flag = false;    // -i是因为在进行第i轮次的时候，最末尾的是已经排好了的i个数    for (int j = 0; j &lt; n - i - 1; ++j) {      if (a[j] &gt; a[j+1]) { // 交换        int tmp = a[j];        a[j] = a[j+1];        a[j+1] = tmp;        flag = true;  // 表示有数据交换            }    }    if (!flag) break;  // 没有数据交换，提前退出  }}</code></pre><ul><li>冒泡排序是原地排序算法，空间复杂度为O(1)</li><li>冒泡排序是稳定的排序算法</li><li>时间复杂度<ul><li>最好情况 O(n)</li><li>最坏情况 O(n^2)</li></ul></li></ul><h2 id="2-2-插入排序"><a href="#2-2-插入排序" class="headerlink" title="2.2 插入排序"></a>2.2 插入排序</h2><p>对于一个有序的数组来说，我们往里面添加一个新的数据，就是要遍历数组，找到数据应该插入的位置并将其插入即可。</p><p><img src="https://i.loli.net/2020/02/10/GIRQpFxgunetcr7.jpg" alt="fig3.jpg"></p><ul><li>将数组中的数据分为两个区间，已排序空间和未排序空间</li><li>初始已排序空间有一个元素，即数组的第一个元素</li><li>插入算法的核心思想是取未排序区间当中的元素，在已排序空间中找到合适的插入位置将其插入，并保证已排序空间的数据一致都是有序的</li><li>重复这个过程直到未排序空间中的元素为空</li></ul><p><img src="https://i.loli.net/2020/02/10/r9yq3FfdKginlQI.jpg" alt="fig4.jpg"></p><pre><code>// 插入排序，a 表示数组，n 表示数组大小public void insertionSort(int[] a, int n) {  if (n &lt;= 1) return;  for (int i = 1; i &lt; n; ++i) {    int value = a[i];    int j = i - 1;    // 查找插入的位置    for (; j &gt;= 0; --j) {      if (a[j] &gt; value) {        a[j+1] = a[j];  // 数据移动      } else {        break;      }    }    // 这里注意循环当中j--了，所以这里是a[j+1]    a[j+1] = value; // 插入数据  }}</code></pre><ul><li>原地排序算法，空间复杂度为O(1)</li><li>稳定的排序算法</li><li>时间复杂度<ul><li>最好情况O(n)</li><li>最坏情况O(n^2)</li></ul></li></ul><h2 id="2-3-选择排序"><a href="#2-3-选择排序" class="headerlink" title="2.3 选择排序"></a>2.3 选择排序</h2><p>同样是分成已排序空间和未排序空间，但是选择排序每次都会从未排序空间当中找到最小的元素，将其放到已排序区间的末尾</p><p><img src="https://i.loli.net/2020/02/10/uZH8xBFPs247nCr.jpg" alt="fig5.jpg"></p><ul><li><p>原地排序算法</p></li><li><p>不稳定的，因为每次都要找剩余的未排序的元素当中的最小值，并和前面的元素交换位置</p><p>  public int[] selectSort(int arr[], int n) {</p><pre><code>for (int i = 0; i &lt; n; i++) {  int index = min(i+1, n);   swap(arr[index], arr[i]);}</code></pre></li></ul><pre><code>  return arr;}</code></pre><h1 id="3-冒泡-插入-选择排序的比较"><a href="#3-冒泡-插入-选择排序的比较" class="headerlink" title="3. 冒泡 插入 选择排序的比较"></a>3. 冒泡 插入 选择排序的比较</h1><p>三者的平均时间复杂度均为O(n^2)。但是实际上还是有不同的，冒泡不如插入优秀，因为在循环当中，冒泡有三个操作，而插入只有一个。在实际情况当中，插入会比冒泡快不少。而选择排序的问题是因为它的逻辑是在未选择的数列里面选择最小的，放到已排序的末端，这里是一定会有一个swap发生的，这导致排序不稳定，即对于有相同值的，排列顺序可能会发生变化。这会在实际应用中造成问题。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 排序 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(7)-递归</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-7-%E9%80%92%E5%BD%92/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-7-%E9%80%92%E5%BD%92/</url>
      
        <content type="html"><![CDATA[<h1 id="1-如何理解递归"><a href="#1-如何理解递归" class="headerlink" title="1.如何理解递归"></a>1.如何理解递归</h1><ul><li>递<ul><li>去的过程 </li></ul></li><li>归<ul><li>回来的过程</li></ul></li></ul><p>给我的感觉是先努力去溯源，拿到源数据以后就相当于多了一个信息，然后再依托多了一个的信息，来解决问题。</p><pre><code>f(n) = f(n-1) + 1 </code></pre><h1 id="2-递归的条件"><a href="#2-递归的条件" class="headerlink" title="2. 递归的条件"></a>2. 递归的条件</h1><ul><li>一个问题的解可以分解为几个子问题的解<ul><li>子问题指数据规模更小的解</li></ul></li><li>这个问题与分解之后的子问题，除了数据规模的不同，求解思路完全一样</li><li>存在递归终止条件</li></ul><h1 id="3-如何写递归代码"><a href="#3-如何写递归代码" class="headerlink" title="3. 如何写递归代码"></a>3. 如何写递归代码</h1><ul><li>写出递归公式</li><li>找到终止条件</li></ul><p>E.G </p><p>n个台阶，每次可以跨过1个或者2个，问一共多少种走法？ </p><ul><li>可以划分为子问题，即一共的走法等于我先走一步，剩下的n-1共同的走法和先走两步，剩下的n-1共同的走法的和。就有了一个递归公式：</li></ul><pre><code>f(n) = f(n-1) + f(n-2)</code></pre><p>终止条件，看最后几个corner case，只有一个台阶，只有两个台阶，然后用3，4来验证一下。</p><blockquote><p>写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲出终止条件，最终将递推公式和终止条件翻译成代码</p></blockquote><p>不要人为加大难度，遇到递归，抽象成一个递推公式，不再一层层的想其调用关系，不要试图用人脑去分解递归的步骤</p><p>分解子问题的时候，当我们将其分解成几个子问题B C D以后，我们要做的是在假设子问题 BCD都已经解决的前提下，思考如何解决问题A。这样子我们就可以思考问题A和子问题B,C,D两层之间的关系就可以了，不需要再一层一层往下思考更深的子问题之间的关系了。屏蔽掉递归的实现细节，我们理解起来就会容易很多了</p><h1 id="4-警惕堆栈溢出"><a href="#4-警惕堆栈溢出" class="headerlink" title="4. 警惕堆栈溢出"></a>4. 警惕堆栈溢出</h1><ul><li>递归容易堆栈溢出</li><li>函数调用会使用栈来保存临时变量，每调用一个函数，都会将临时变量封装为栈帧压入内存栈当中。等函数执行完成返回时，才出栈。</li><li>系统栈或者虚拟机栈空间都不大，如果递归层很多的话，那么就会有堆栈溢出的风险。</li><li>可以在代码中限制递归调用的最大深度来解决这个问题</li></ul><p>递归好处是表达能力强，很容易去理顺其想要表达的内容；坏处是空间复杂度会比较高，因为每次递归的时候都需要在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度的时候，是需要额外考虑这部分的开销的。</p><h1 id="5-重复计算问题"><a href="#5-重复计算问题" class="headerlink" title="5. 重复计算问题"></a>5. 重复计算问题</h1><p>子步骤会被计算了很多很多遍，为了避免这种重复计算，可以使用一些数据结构来保存已经求解过得f(k)。当递归调用到f(k)的时候，先看下是否已经求解过了</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 递归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(6)-队列</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-6-%E9%98%9F%E5%88%97/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-6-%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<p>CPU资源有限，任务的处理速度和线程个数并不是线性正相关的。相反的，过多的线程会导致CPU频繁切换，处理性能下降。因此，线程池的大小一般都是综合考虑要处理任务的特点和硬件环境，来事先设置的。</p><p>当我们向固定大小的线程池中请求一个线程的时候，如果线程池中没有空闲资源，如何处理这个请求呢？ —–&gt; 队列</p><p>操作受限的线性表。</p><h1 id="1-理解队列"><a href="#1-理解队列" class="headerlink" title="1. 理解队列"></a>1. 理解队列</h1><ul><li>基本操作<ul><li>入队 enqueue()   入栈 push()</li><li>出队 dequeue()   出栈 pop()</li></ul></li><li>操作受限的线性表数据结构</li><li>带有一些特性的队列<ul><li>循环队列</li><li>阻塞队列</li><li>并发队列</li><li>顺序队列 - 数组实现</li><li>链式队列 - 链式队列</li></ul></li></ul><p>在很多偏底层系统，框架，中间件的开发当中，起到关键性作用。比如高性能disruptor,Linux环形缓存，都用到了循环并发队列; Java Concurrent并发包利用ArrayBlockingQueue来实现公平锁。</p><pre><code>// 用数组实现的队列public class ArrayQueue {  // 数组：items，数组大小：n  private String[] items;  private int n = 0;  // head 表示队头下标，tail 表示队尾下标  private int head = 0;  private int tail = 0;  // 申请一个大小为 capacity 的数组  public ArrayQueue(int capacity) {    items = new String[capacity];    n = capacity;  }  // 入队  public boolean enqueue(String item) {    // 如果 tail == n 表示队列已经满了    if (tail == n) return false;    items[tail] = item;    ++tail;    return true;  }  // 出队  public String dequeue() {    // 如果 head == tail 表示队列为空    if (head == tail) return null;    // 为了让其他语言的同学看的更加明确，把 -- 操作放到单独一行来写了    String ret = items[head];    ++head;    return ret;  }}</code></pre><h1 id="2-基于链表的队列实现方法"><a href="#2-基于链表的队列实现方法" class="headerlink" title="2. 基于链表的队列实现方法"></a>2. 基于链表的队列实现方法</h1><ul><li>两个指针<ul><li>head指针 - 指向第一个结点</li><li>tail指针 - 指向最后一个结点</li></ul></li></ul><h1 id="3-循环队列"><a href="#3-循环队列" class="headerlink" title="3. 循环队列"></a>3. 循环队列</h1><p>用数组实现的队列，在tail = n的时候，会有数据搬移操作。这样入队性能就会受到影响。循环队列的可以解决这个问题。</p><ul><li>如何确认队空和队满<ul><li>队空 head == tail</li><li>队满 (tail+1)%n = head</li></ul></li></ul><pre><code>public class CircularQueue {  // 数组：items，数组大小：n  private String[] items;  private int n = 0;  // head 表示队头下标，tail 表示队尾下标  private int head = 0;  private int tail = 0;  // 申请一个大小为 capacity 的数组  public CircularQueue(int capacity) {    items = new String[capacity];    n = capacity;  }  // 入队  public boolean enqueue(String item) {    // 队列满了    if ((tail + 1) % n == head) return false;    items[tail] = item;    tail = (tail + 1) % n;    return true;  }  // 出队  public String dequeue() {    // 如果 head == tail 表示队列为空    if (head == tail) return null;    String ret = items[head];    head = (head + 1) % n;    return ret;  }}</code></pre><h1 id="4-阻塞队列和并发队列"><a href="#4-阻塞队列和并发队列" class="headerlink" title="4. 阻塞队列和并发队列"></a>4. 阻塞队列和并发队列</h1><ul><li>阻塞队列<ul><li>在队列基础上增加了阻塞操作</li><li>队列为空的时候，从队头取数据会被阻塞</li><li>如果队列已经满了，那么插入数据的操作会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回</li><li>生产者 消费者模型  相当于</li><li>基于阻塞队列，我们可以通过协调生产者和消费者的个数来提高数据的处理效率</li><li>我们可以通过配置多几个的消费者，来应对一个生产者</li></ul></li><li>并发队列<ul><li>实现方法<ul><li>在enquue()和dequeue()方法上加锁</li><li>基于CAS原子操作</li></ul></li></ul></li></ul><h1 id="5-对比基于数组和基于链表实现的队列"><a href="#5-对比基于数组和基于链表实现的队列" class="headerlink" title="5. 对比基于数组和基于链表实现的队列"></a>5. 对比基于数组和基于链表实现的队列</h1><ul><li>基于链表的实现方式<ul><li>可以实现一个支持无限排队的无界队列</li><li>可能会导致过多的请求排队等待</li><li>请求处理的响应时间会长很多</li><li>因此对于响应时间比较敏感的系统来说，基于链表实现的无限排队的线程池就不是很合适了</li></ul></li><li>基于数组实现的有界队列<ul><li>队列大小是有限的</li><li>超过一定数量以后，请求就会被拒绝</li><li>队列的大小设置就会是个trade off了</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(5)-栈</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-5-%E6%A0%88/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-5-%E6%A0%88/</url>
      
        <content type="html"><![CDATA[<p>大家都常用Chrome浏览器，你会发现在你做后退或者前进按钮时，浏览器的加载速度非常快，这里实际上是用的栈这个数据结构来进行处理的。</p><h1 id="1-对栈的理解"><a href="#1-对栈的理解" class="headerlink" title="1. 对栈的理解"></a>1. 对栈的理解</h1><ul><li>先进后出</li><li>操作受限的线性表，只允许在一端插入和删除数据</li><li>实质上栈的功能一定是可以被数组（顺序栈）或者链表（链式栈）来替代的，因为有拿第一个和最后一个的接口，或者说方式</li><li>用栈的好处是操作上的简单，更不容易出错一些</li><li>功能操作受限的线性表，栈可以通过数组或者链表来进行实现</li></ul><h1 id="2-支持动态扩容的顺序栈"><a href="#2-支持动态扩容的顺序栈" class="headerlink" title="2. 支持动态扩容的顺序栈"></a>2. 支持动态扩容的顺序栈</h1><ul><li>动态扩容 - load factor</li><li>顺序栈 - 数组</li></ul><p><img src="fig1.jpg" alt="fig1.jpg"></p><ul><li>注意动态扩容的顺序栈，出栈过程依然可以实现O(1)的时间复杂度，但是在入栈过程当中，如果空间不够了的话，那就需要实现整体的迁移，时间复杂度就变成了O(n)</li></ul><pre><code>// 基于数组实现的顺序栈public class ArrayStack {  private String[] items;  // 数组  private int count;       // 栈中元素个数  private int n;           //栈的大小  // 初始化数组，申请一个大小为n的数组空间  public ArrayStack(int n) {    this.items = new String[n];    this.n = n;    this.count = 0;  }  // 入栈操作  public boolean push(String item) {    // 数组空间不够了，直接返回false，入栈失败。    if (count == n) return false;    // 将item放到下标为count的位置，并且count加一    items[count] = item;    ++count;    return true;  }  // 出栈操作  public String pop() {    // 栈为空，则直接返回null    if (count == 0) return null;    // 返回下标为count-1的数组元素，并且栈中元素个数count减一    String tmp = items[count-1];    --count;    return tmp;  }}</code></pre><h1 id="3-栈的应用"><a href="#3-栈的应用" class="headerlink" title="3. 栈的应用"></a>3. 栈的应用</h1><ul><li>函数调用栈<ul><li>操作系统给每个线程分配一块独立的内存空间，这块内存被组织成栈这种结构，用来存储函数调用时的临时变量</li></ul></li><li>表达式求值<ul><li>计算机会用两个栈来实现</li><li>一个用来保存操作数</li><li>一个用来保存运算符<br>实际上，编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。<br><img src="fig2.jpg" alt="fig2.jpg"></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 栈 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(4)-链表</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-4-%E9%93%BE%E8%A1%A8/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-4-%E9%93%BE%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="1-链表结构"><a href="#1-链表结构" class="headerlink" title="1. 链表结构"></a>1. 链表结构</h1><ul><li><p>数组需要一块连续的内存空间来存储，对内存的要求比较高</p></li><li><p>链表，通过指针将一组<strong>零散的内存块</strong>串联起来使用</p></li><li><p>链表经典应用场景 - LRU缓存淘汰算法</p><ul><li>缓存是一种提高数据读取性能的技术<ul><li>CPU缓存</li><li>数据库缓存</li><li>浏览器缓存</li></ul></li></ul></li></ul><h2 id="1-1-单链表"><a href="#1-1-单链表" class="headerlink" title="1.1 单链表"></a>1.1 单链表</h2><p><img src="https://i.loli.net/2020/02/09/Q9fFlx6ap5B47Mj.jpg" alt="fig1.jpg"></p><ul><li><p>每个链表的节点 </p><ul><li>存储的数据</li><li>记录链的下一个结点的地址(后继指针next)</li></ul></li><li><p>头结点用来记录链表的<strong>基地址</strong></p></li><li><p>尾结点的指针指向一个<strong>空地址NULL</strong></p></li><li><p>插入和删除结点都非常快 O(1)</p></li><li><p>随机访问其中一个元素，比如按照顺序选第n个就是O(n)的复杂度</p></li></ul><p><img src="https://i.loli.net/2020/02/09/h6maNKWveQnfgGP.jpg" alt="fig2.jpg"></p><h2 id="1-2-双向链表"><a href="#1-2-双向链表" class="headerlink" title="1.2 双向链表"></a>1.2 双向链表</h2><p><img src="https://i.loli.net/2020/02/09/rYhNQ1Zwp5klgVn.jpg" alt="fig4.jpg"></p><ul><li>双向链表支持两个方向，每个节点不止有一个后继指针next指向后面的结点，还有一个前驱指针prev指向前面的结点。</li><li>双向链表可以支持O(1) 的时间复杂度的情况下找到前驱结点，这样就使得双向链表在某些情况下的插入、删除等操作都要比单链表简单高效。</li><li>其实就是无论单链表还是双向链表，在删除的时候都需要找到前驱结点，而单链表在这里想要找到前驱结点的话就得从头开始去找，时间复杂度还是O(n)，而双向链表就可以实现很快的找到对应的前驱节点了。</li><li>因为有prev next两个指针，它黄海军更占用内存的空间</li><li>Java的LinkedHashMap就是用双向链表来实现的</li><li>用空间换时间的设计思想<ul><li>当内存空间充足的时候，如果我们更追求代码的执行速度，那么我们就可以选择空间复杂度相对较高，但时间复杂度相对很低的算法或者数据结构。 </li></ul></li><li>对于有序链表来说，双向链表的按值查询效率也要比单链表高。因为我们可以通过记录上次查找的位置p，每次查询的时候，根据要查找的值和p的大小关系决定是往前还是往后来查找。</li></ul><h2 id="1-3-循环链表"><a href="#1-3-循环链表" class="headerlink" title="1.3 循环链表"></a>1.3 循环链表</h2><p><img src="https://i.loli.net/2020/02/09/BLOXWHUgpeJoQGh.jpg" alt="fig3.jpg"></p><ul><li>循环链表的尾结点指针是指向链表的头结点，像一个环一样首尾相连</li><li>当要处理的数据具有<strong>环形结构特点</strong>时，就特别适合采用循环链表。</li></ul><h1 id="2-链表数组性能对比"><a href="#2-链表数组性能对比" class="headerlink" title="2.链表数组性能对比"></a>2.链表数组性能对比</h1><table><thead><tr><th>时间复杂度</th><th>数组</th><th>链表</th></tr></thead><tbody><tr><td>插入删除</td><td>O(n)</td><td>O(1)</td></tr><tr><td>随机访问</td><td>O(1)</td><td>O(n)</td></tr></tbody></table><p>但是在实际应用开发当中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。</p><p>数组简单易用，在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读数组中的数据，所以访问效率更高。而链表因为不是连续内存存储，所以没办法有效预读。</p><p>数组大小固定，增大如果要做扩容拷贝是非常费时间的。链表本身没有大小的限制，天然支持<strong>动态扩容</strong>。</p><p>而且，如果代码对于内存的使用很苛刻，那数组会更加合适。因为链表中的每个结点都要消耗额外的存储空间去存储指针，所以内存的消耗会翻倍。而且，对链表进行频繁的插入，删除操作还会导致频繁的内存申请和释放，容易造成内存碎片。Java中就会导致频繁的garbage collection. </p><h1 id="3-写链表代码的技巧"><a href="#3-写链表代码的技巧" class="headerlink" title="3. 写链表代码的技巧"></a>3. 写链表代码的技巧</h1><h2 id="3-1-理解指针或者引用的含义"><a href="#3-1-理解指针或者引用的含义" class="headerlink" title="3.1 理解指针或者引用的含义"></a>3.1 理解指针或者引用的含义</h2><p>指针，是在像C语言这样的语言当中来使用的；对于Java这种面向对象的语言，是用引用来达成存储所指对象的内存地址的目的。</p><p>将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就可以找到这个变量了。</p><pre><code>// p结点的next指针里面存储了q结点的内存地址p-&gt;next = q// p 结点的next指针存储了p结点的下下个结点的内存地址p-&gt;next = p-&gt;next-&gt;next</code></pre><h2 id="3-2-警惕指针丢失和内存泄露"><a href="#3-2-警惕指针丢失和内存泄露" class="headerlink" title="3.2 警惕指针丢失和内存泄露"></a>3.2 警惕指针丢失和内存泄露</h2><p><img src="https://i.loli.net/2020/02/09/ASXEJ4ZYzf6lmrH.jpg" alt="fig5.jpg"></p><pre><code>x-&gt;next = p-&gt;next;  // 将 x 的结点的 next 指针指向 b 结点；p-&gt;next = x;  // 将 p 的 next 指针指向 x 结点；</code></pre><p>两行代码的顺序很重要，你需要先将p的next的地址赋给x的next的地址，然后再来改p的next，改变p的next指针</p><h2 id="3-3-利用哨兵"><a href="#3-3-利用哨兵" class="headerlink" title="3.3 利用哨兵"></a>3.3 利用哨兵</h2><p>对于链表当中的第一个结点和最后一个结点，其实现插入删除的逻辑和其他结点是不一样的。</p><p>利用哨兵结点可以简化整个实现，让针对于第一个结点和最后一个结点的处理和其他结点的处理方式一致。</p><p><img src="https://i.loli.net/2020/02/09/A43BtwNSuvhMy7n.jpg" alt="fig6.jpg"></p><h2 id="3-4-边界条件的思考与判定"><a href="#3-4-边界条件的思考与判定" class="headerlink" title="3.4 边界条件的思考与判定"></a>3.4 边界条件的思考与判定</h2><ul><li>链表为空</li><li>链表只包含一个结点</li><li>链表只包含两个结点</li><li>代码逻辑在处理头结点和尾结点的时候</li></ul><h1 id="4-实战"><a href="#4-实战" class="headerlink" title="4. 实战"></a>4. 实战</h1><h2 id="4-1-LC-206-Reversed-Linked-List"><a href="#4-1-LC-206-Reversed-Linked-List" class="headerlink" title="4.1 LC 206 Reversed Linked List"></a>4.1 LC 206 Reversed Linked List</h2><pre><code>// 遍历，重点在因为无法同时保存prev节点和next节点的信息，只有一个指针，所以需要建一个中间变量来记录class Solution {    public ListNode reverseList(ListNode head) {        ListNode cur = head;        ListNode prev = null;        while (cur != null) {            ListNode temp = cur.next;            cur.next = prev;            prev = cur;            cur = temp;        }        return prev;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LinkedList </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(3)-数组</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-3-%E6%95%B0%E7%BB%84/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-3-%E6%95%B0%E7%BB%84/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是数组"><a href="#1-什么是数组" class="headerlink" title="1. 什么是数组"></a>1. 什么是数组</h1><ul><li>是一种<strong>线性表</strong>数据结构，用一组<strong>连续的内存空间</strong>，来存储一组具有<strong>相同类型</strong>的数据</li><li>线性表<ul><li>数据排成了线性的结构</li><li>每个线性表上的数据只有前后两个方向</li><li>除了数组，链表、队列、栈等也是线性表结构</li></ul></li><li>非线性表<ul><li>比如说二叉树，堆，图等  他们的数据之间不是简单的前后关系了 </li></ul></li><li>连续内存空间与相同类型的数据<ul><li>正因为有这个特征其才可以进行随机访问</li><li>但是这也导致了想要在数组当中删除，插入一个数据，为了保证连续性，就需要做大量的数据搬移工作</li><li>数组非常适合根据下标来进行访问</li></ul></li><li>线性表 - 数组<ul><li>表中的数据只有前后两个方向</li><li>数组，链表，队列，栈都是线性表结构</li></ul></li><li>非线性表<ul><li>二叉树，堆，图</li><li>数据之间并不是简单的前后关系</li></ul></li></ul><h1 id="2-数组的插入，删除，随机访问"><a href="#2-数组的插入，删除，随机访问" class="headerlink" title="2. 数组的插入，删除，随机访问"></a>2. 数组的插入，删除，随机访问</h1><ul><li>插入，删除<ul><li>在k位置做操作，那么对于k位置之后的k - n都是需要做移位的 </li></ul></li><li>删除的优化<ul><li>避免每次删除都直接的搬移数据</li><li>先记录下已经删除的数据</li><li>每次删除操作并不是真正搬移数据，只是记录数据已经被删除了</li><li>当数组没有更多空间存储了以后，再触发执行一次真正的删除操作</li><li>通过这种方式大大减少了删除操作导致的数据搬移</li><li>—–&gt; JVM标记清除垃圾回收算法</li></ul></li></ul><h1 id="3-数组的访问越界问题"><a href="#3-数组的访问越界问题" class="headerlink" title="3. 数组的访问越界问题"></a>3. 数组的访问越界问题</h1><pre><code>int main(int argc, char* argv[]){    int i = 0;    int arr[3] = {0};    for(; i&lt;=3; i++){        arr[i] = 0;        printf(&quot;hello world\n&quot;);    }    return 0;}</code></pre><p>当i=3的时候，访问越界。在C语言当中，只要不是访问受限的内存，内存空间都是可以自由访问的。a[3]会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量i的内存地址，那么arr[3] = 0 就相当于 i=0，因此会导致代码无限循环。</p><p>对这里的无限循环的解释：函数体内的局部变量存在栈上，且是连续压栈。在Linux进程的内存布局中，栈区在高地址空间，从高向低增长。变量i和arr在相邻地址，且i比arr的地址大，所以arr越界正好访问到i。当然，前提是i和arr元素同类型，否则那段代码仍是未决行为。</p><p>数组越界是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。</p><p>Java做了封装，会判断出数组越界的行为，并throw exception。</p><h1 id="4-容器-vs-数组"><a href="#4-容器-vs-数组" class="headerlink" title="4. 容器 vs 数组"></a>4. 容器 vs 数组</h1><p>容器，譬如Java中的ArrayList，最大优势是可以将许多数组操作细节封装起来。另外，其支持动态扩容。动态扩容很耗时的，因为牵扯到内存申请，还有整体的数据搬移。因此如果能确定需要村塾的数据的大小，最好<strong>在创建Arraylist的时候事先指定好</strong></p><ul><li>使用数组的情况<ul><li>ArrayList 无法存储基本类型，需要封装，autoBoxing, unboxing本身是有一定的性能消耗的，如果特别关注性能，那么我们就需要用数组</li><li>如果数组大小已知，并且对数据的操作很简单。不需要使用ArrayList所提供的大部分的方法，那么我们可以直接使用数组</li><li>多维数组的表示会更为直观一些</li></ul></li></ul><h1 id="5-为什么数组要从0开始编号？"><a href="#5-为什么数组要从0开始编号？" class="headerlink" title="5. 为什么数组要从0开始编号？"></a>5. 为什么数组要从0开始编号？</h1><p>因为下标最确切的定义是偏移，offset。要算a[k]的内存地址的公式为：</p><pre><code>a[k]_address = base_address + k * type_size</code></pre><p>如果我们从1开始计数，那么我们计算位置的公式就会变成：</p><pre><code>a[k]_address = base_address + (k-1)*type_size</code></pre><p>这样每次访问都会多一次减法运算！！！对于CPU来说，就是多了一次减法指令。从0开始就是为了提高效率，当然这个效率的提升其实很小，也有一大部分是历史原因了，即不同语言的迁移之间的学习成本。</p><h1 id="6-算法实战"><a href="#6-算法实战" class="headerlink" title="6. 算法实战"></a>6. 算法实战</h1><h2 id="6-1-3Sum"><a href="#6-1-3Sum" class="headerlink" title="6.1 3Sum"></a>6.1 <a href="https://leetcode.com/problems/3sum/" target="_blank" rel="noopener">3Sum</a></h2><p>题目的详述见上方的连接，思路的话首先最直观的方式一定是三层循环，来确定出所有的解，brute force的方式很慢，O(n^3)谁受得了。</p><p>按照分治的观点，我们可以先思考下2Sum应该如何实现，有没有什么方便的办法。2Sum的话，我们可以选择先排序，然后选两个初始点，即最左(最小)和最右(最大)，根据每次得出的结果来更新两个坐标的位置，最终拿到结果，这样的大O复杂度为O(nlogn).按照这种思路的代码实现如下：</p><pre><code>class Solution {    public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) {        List&lt;List&lt;Integer&gt;&gt; ans = new ArrayList();        if (nums.length &lt; 3) {            return ans;        }        Arrays.sort(nums);        for (int i = 0; i &lt; nums.length -2; i ++) {            if (i == 0 || i != 0 &amp;&amp; nums[i] != nums[i - 1]) {                int low = i+1;                int high = nums.length - 1;                while (high &gt; low) {                    if (nums[i] + nums[low] + nums[high] &gt; 0) {                        high --;                    } else if (nums[i] + nums[low] + nums[high] &lt; 0) {                        low ++;                    } else {                        ans.add(Arrays.asList(nums[i], nums[low], nums[high]));                        while(low &lt; high &amp;&amp; nums[low] == nums[low+1]) low++;                        while(low &lt; high &amp;&amp; nums[high] == nums[high-1]) high--;                        low ++;                        high --;                    }                }            }        }        return ans;    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Array </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(2)-复杂度分析</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-2-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-2-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="1-为什么需要复杂度分析？"><a href="#1-为什么需要复杂度分析？" class="headerlink" title="1. 为什么需要复杂度分析？"></a>1. 为什么需要复杂度分析？</h1><p>通过统计和监控得到的算法执行时间的占用的内存的大小的方法称为事后统计法，这种方法有其局限性：</p><ul><li>测试结果非常依赖于测试环境</li><li>测试结果受数据规模的影响很大, 而且会和数据集本身的数据质量有关</li><li>—-&gt; 因此我们需要一个不用具体的测试数据来测试，就可以粗略估计算法的执行效率的方法</li></ul><h1 id="2-大O复杂度表示法"><a href="#2-大O复杂度表示法" class="headerlink" title="2. 大O复杂度表示法"></a>2. 大O复杂度表示法</h1><ul><li>假定每行代码执行时间都一样</li><li>并不表示具体的代码执行时间，而是表示执行时间随着数据规模增大的变化趋势，因此也叫做渐进时间复杂度。</li></ul><h1 id="3-如何分析代码的时间复杂度"><a href="#3-如何分析代码的时间复杂度" class="headerlink" title="3. 如何分析代码的时间复杂度"></a>3. 如何分析代码的时间复杂度</h1><ul><li>只关注循环执行次数最多的一段代码</li><li>加法原则：总复杂度等于量级最大的那段代码的复杂度</li><li>乘法法则： 嵌套代码的复杂度等于签到内外层代码复杂度的乘积</li></ul><h1 id="4-复杂度量级"><a href="#4-复杂度量级" class="headerlink" title="4. 复杂度量级"></a>4. 复杂度量级</h1><ul><li>常量阶 O(1)</li><li>对数阶 O(logn)</li><li>线性阶 O(n)<ul><li>O (m+n) 当我们不知道几个变量的大小的时候 </li></ul></li><li>线性对数阶 O(nlogn)</li><li>平方阶 O(n^2)<ul><li>O (m*n) 乘法关系，不知道参量之间的相对大小 </li></ul></li><li>k次方阶 O(n^k)</li><li>指数阶 O(2^n)</li><li>阶乘阶 O(n!)</li></ul><h1 id="5-空间复杂度分析"><a href="#5-空间复杂度分析" class="headerlink" title="5. 空间复杂度分析"></a>5. 空间复杂度分析</h1><p>空间复杂度的全程是渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。</p><p>大O时间复杂度，并不具体表示代码真正的执行时间，而是表示代码执行时间随着数据规模的增大的变化趋势。因此也叫做渐进时间复杂度，(asymptotic time complexity)</p><pre><code>T(n) = O(f(n))</code></pre><p>T(n) - 代码的执行时间<br>n - 数据规模的大小<br>f(n) - 每行代码执行的次数总和<br>O - 表示左右成正比</p><h2 id="5-1-Tips"><a href="#5-1-Tips" class="headerlink" title="5.1 Tips"></a>5.1 Tips</h2><ul><li>只关注循环执行次数最多的一段代码</li><li>总复杂度等于量级最大的那段代码的复杂度</li><li>嵌套代码的复杂度为嵌套内外代码复杂度的乘积</li></ul><h1 id="6-复杂度的分析"><a href="#6-复杂度的分析" class="headerlink" title="6. 复杂度的分析"></a>6. 复杂度的分析</h1><h2 id="6-1-时间复杂度分析"><a href="#6-1-时间复杂度分析" class="headerlink" title="6.1 时间复杂度分析"></a>6.1 时间复杂度分析</h2><h3 id="6-1-1-多项式量级"><a href="#6-1-1-多项式量级" class="headerlink" title="6.1.1 多项式量级"></a>6.1.1 多项式量级</h3><ul><li>O(1) <ul><li>常量级的代码，我们将其时间复杂度都记作O(1)</li></ul></li><li>O(logn)</li></ul><pre><code> i=1; while (i &lt;= n)  {   i = i * 2; }</code></pre><ul><li>O(nlogn)</li><li>O(m+n)</li><li>O(m*n)</li></ul><h3 id="6-1-2-非多项式量级"><a href="#6-1-2-非多项式量级" class="headerlink" title="6.1.2 非多项式量级"></a>6.1.2 非多项式量级</h3><p>非常低效，会随着n的增长急剧增长，因此我们应当尽量不选择有如下时间复杂度的算法</p><ul><li>O(2^n) </li><li>O(n!)</li></ul><h2 id="6-2-空间复杂度分析"><a href="#6-2-空间复杂度分析" class="headerlink" title="6.2 空间复杂度分析"></a>6.2 空间复杂度分析</h2><p>渐进空间复杂度，表示算法的存储空间和数据规模之间的增长关系。</p><p>一般来说在O(1), O(n), O(n^2)这几个可能性上面</p><h1 id="7-浅析最好、最坏、平均、均摊时间复杂度"><a href="#7-浅析最好、最坏、平均、均摊时间复杂度" class="headerlink" title="7. 浅析最好、最坏、平均、均摊时间复杂度"></a>7. 浅析最好、最坏、平均、均摊时间复杂度</h1><pre><code>// n 表示数组 array 的长度int find(int[] array, int n, int x) {  int i = 0;  int pos = -1;  for (; i &lt; n; ++i) {    if (array[i] == x) {       pos = i;       break;    }  }  return pos;}</code></pre><h2 id="7-1-最好情况时间复杂度-best-case-time-complexity"><a href="#7-1-最好情况时间复杂度-best-case-time-complexity" class="headerlink" title="7.1 最好情况时间复杂度(best case time complexity)"></a>7.1 最好情况时间复杂度(best case time complexity)</h2><p>上面这段代码，最好情况是O(1)</p><h2 id="7-2-最坏情况时间复杂度-worst-case-time-complexity"><a href="#7-2-最坏情况时间复杂度-worst-case-time-complexity" class="headerlink" title="7.2 最坏情况时间复杂度(worst case time complexity)"></a>7.2 最坏情况时间复杂度(worst case time complexity)</h2><p>上面这段代码，最坏情况是O(n)</p><h2 id="7-3-平均情况时间复杂度-average-case-time-complexity"><a href="#7-3-平均情况时间复杂度-average-case-time-complexity" class="headerlink" title="7.3 平均情况时间复杂度(average case time complexity)"></a>7.3 平均情况时间复杂度(average case time complexity)</h2><p>需要算上发生的概率</p><p>上述例子当中，因为要查找变量x在数组当中的位置，一共有n+1种情况，在数组的0 - n-1位置中和不在数组当中。将每种情况下，需要遍历的元素个数累加起来，再除以n+1,就可以得到需要遍历的元素个数的平均值了 </p><p>即</p><pre><code>(1+2+3+ ... + n + n) / (n+1) = n(n+3)/(2(n+1))</code></pre><p>故平均复杂度还是O(n)</p><p>然而还要考虑每种情况下 发生的概率实质上是不同的，需要将这个算上</p><h2 id="7-4-均摊时间复杂度-amortized-time-complexity"><a href="#7-4-均摊时间复杂度-amortized-time-complexity" class="headerlink" title="7.4 均摊时间复杂度(amortized time complexity)"></a>7.4 均摊时间复杂度(amortized time complexity)</h2><p>不是遍历case，而是有轮回的，因此算一个轮回里的时间就可以得出平均复杂度了</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 复杂度分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据结构与算法(1)-概述</title>
      <link href="/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-1-%E6%A6%82%E8%BF%B0/"/>
      <url>/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-1-%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-为什么要学习数据结构与算法？"><a href="#1-为什么要学习数据结构与算法？" class="headerlink" title="1. 为什么要学习数据结构与算法？"></a>1. 为什么要学习数据结构与算法？</h1><p>入职已经快1年的时间了，自己在这一年中确实有很多收获，涨了很多架构上的知识，对于工程上的代码流程有了更深一步的了解。不过愈发感觉到数据结构与算法的重要性，因为在服务出现bug的时候，除了业务逻辑上的问题，剩下的大部分都是数据结构操作上的一些问题，比如常见的Index out of bound，诸如此类。</p><p>我想与其说数据结构与算法是进入大厂的敲门砖，不如说二者是一个优秀工程师和一个CRUD 男孩的分水岭。很多时候，对于基础的理解决定了你的上限，要知道底层的知识是相通的，我们看到的很多现在的新兴技术，实际上底子上还是用的那些十年前，二十年前的理念。学习数据结构与算法，可以算得上是想要去掌握一把屠龙刀。无论遇到什么，庖丁解牛一般。</p><p>在工业界，讲道理对于业务工程师来说，大部分时间都在使用封装好的接口，类库，并翻译业务逻辑，很少需要自己实现数据结构和算法。但是，不用自己实现不代表不需要去了解。</p><p>依旧需要知道这背后的原理；需要懂得分析时间、空间的复杂度；需要能够分辨出几个相似的数据结构的不同；调用了某个函数之后，需要知道如何评估代码的性能和资源的消耗。</p><p>学习数据结构与算法，是为了让自己有能够成长起来的油/ 源。</p><h1 id="2-如何学习？"><a href="#2-如何学习？" class="headerlink" title="2. 如何学习？"></a>2. 如何学习？</h1><p>首先，数据结构与算法的关系是：数据结构为算法服务，而算法要作用在特定的数据结构之上。</p><p>数据结构是静态的，是组织数据的一种方式。我们需要在其基础上操作、构建算法，孤立存在的数据结构是没用的。</p><ul><li>复杂度分析<ul><li>数据结构与算法是解决如何更省，更快的存储和处理数据的问题</li><li>复杂度分析就是对应的考量效率和资源消耗的方法</li></ul></li></ul><p><img src="https://i.loli.net/2020/02/09/LTqyj9aMOQsXw8U.jpg" alt="fig1.png"></p><ul><li>数据结构算法树状图<ul><li>复杂度分析<ul><li>空间复杂度</li><li>时间复杂度<ul><li>最好</li><li>最坏</li><li>平均</li><li>均摊</li></ul></li></ul></li><li>基本算法思想<ul><li>贪心</li><li>分治</li><li>动态规划</li><li>回溯</li><li>枚举</li></ul></li><li>排序<ul><li>O(n^2)<ul><li>冒泡排序</li><li>插入排序</li><li>选择排序</li><li>希尔排序</li></ul></li><li>O(nlogn)<ul><li>归并排序</li><li>快速排序</li><li>堆排序</li></ul></li><li>O(n)<ul><li>计数排序</li><li>基数排序</li><li>桶排序</li></ul></li></ul></li><li>搜索<ul><li>深度优先搜索</li><li>广度优先搜索</li><li>A启发式搜索</li></ul></li><li>查找<ul><li>线性表查找</li><li>树结构查找</li><li>散列表查找</li></ul></li><li>字符串匹配<ul><li>朴素</li><li>KMP</li><li>Robin-Karp</li><li>Boyer-Moore</li><li>AC自动机</li><li>Trie</li><li>后缀数组</li></ul></li><li>图<ul><li>存储<ul><li>邻接矩阵</li><li>邻接表</li></ul></li><li>拓扑排序</li><li>最短路径</li><li>关键路径</li><li>最小生成树</li><li>二分图</li><li>最大流</li></ul></li><li>树<ul><li>二叉树<ul><li>平衡二叉树</li><li>二叉查找树</li><li>平衡二叉查找树<ul><li>AVL树</li><li>红黑树</li></ul></li><li>完全二叉树</li><li>满二叉树</li></ul></li><li>多路查找树<ul><li>B 树</li><li>B+ 树</li><li>2-3 树</li><li>2-3-4 树</li></ul></li><li>堆<ul><li>小顶堆</li><li>大顶堆</li><li>优先级队列</li><li>斐波那契堆</li><li>二项堆</li></ul></li><li>其他<ul><li>梨形数组</li><li>线段树</li></ul></li></ul></li><li>散列表<ul><li>散列函数</li><li>冲突解决<ul><li>链表法</li><li>开放寻址</li><li>其他</li></ul></li><li>动态扩容</li><li>位图</li></ul></li><li>线性表<ul><li>数组</li><li>链表<ul><li>单链表</li><li>双向链表</li><li>循环链表</li><li>双向循环链表</li><li>静态链表</li></ul></li><li>栈<ul><li>顺序栈</li><li>链式栈</li></ul></li><li>队列<ul><li>普通队列</li><li>双端队列</li><li>阻塞队列</li><li>并发队列</li><li>阻塞并发队列</li></ul></li></ul></li></ul></li></ul><h2 id="2-1-最常用的基础总结"><a href="#2-1-最常用的基础总结" class="headerlink" title="2.1 最常用的基础总结"></a>2.1 最常用的基础总结</h2><ul><li>数据结构<ul><li>数组</li><li>链表</li><li>栈</li><li>队列</li><li>散列表</li><li>二叉树</li><li>堆</li><li>跳表</li><li>图</li><li>Trie树</li></ul></li><li>算法<ul><li>递归</li><li>排序</li><li>二分查找</li><li>搜索</li><li>哈希算法</li><li>贪心算法</li><li>分治算法</li><li>回溯算法</li><li>动态规划</li><li>字符串匹配算法</li></ul></li></ul><p>对于数据结构和算法，要学习的是：</p><ul><li>其自身来历</li><li>特点</li><li>适合解决的问题</li><li>实际的应用场景</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>后端开发实践-项目模板</title>
      <link href="/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5-%E9%A1%B9%E7%9B%AE%E6%A8%A1%E6%9D%BF/"/>
      <url>/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E5%AE%9E%E8%B7%B5-%E9%A1%B9%E7%9B%AE%E6%A8%A1%E6%9D%BF/</url>
      
        <content type="html"><![CDATA[<p>整理出一套公共性的项目模板，旨在尽量多地包含日常开发所需，减少开发者的重复性工作以及提供一些最佳实践。</p><h1 id="1-从写好README开始"><a href="#1-从写好README开始" class="headerlink" title="1. 从写好README开始"></a>1. 从写好README开始</h1><p>一个好的README给人以项目概览，可以使新人快速上手项目，并降低沟通成本，建议包括：</p><ul><li>项目简介<ul><li>一两句话描述该项目实现的业务功能</li></ul></li><li>技术选型<ul><li>项目的技术栈，包括语言，框架，中间件等</li></ul></li><li>本地构建<ul><li>列出本地开发过程中所用到的工具命令</li></ul></li><li>领域模型<ul><li>核心的领域概念，针对于当前系统所在的领域</li></ul></li><li>测试策略<ul><li>自动化测试如何分类</li></ul></li><li>技术架构<ul><li>技术架构图</li></ul></li><li>部署架构<ul><li>部署架构图</li></ul></li><li>外部依赖<ul><li>项目运行时所以来的外部集成方</li></ul></li><li>环境信息<ul><li>各个环境的访问方式，数据库连接</li></ul></li><li>编码实践<ul><li>统一的编码实践，比如异常处理原则，分页封装等</li></ul></li><li>FAQ<ul><li>开发过程中常见问题的解答</li></ul></li></ul><p>注意保持README的持续更新，一些重要的架构决定可以通过示例代码的形式记录在代码块当中，新开发者可以通过直接阅读这些示例代码快速了解项目的通用实践方式以及架构选择</p><h1 id="2-一键式本地构建"><a href="#2-一键式本地构建" class="headerlink" title="2. 一键式本地构建"></a>2. 一键式本地构建</h1><p>写一个必需的script，自动化完成本地构建的过程</p><ul><li><code>run.sh</code> 进行本地调试或者必要的手动测试</li><li><code>local-build.sh</code>，完成本地构建</li></ul><h1 id="3-日志处理"><a href="#3-日志处理" class="headerlink" title="3. 日志处理"></a>3. 日志处理</h1><ul><li>在日志中加入请求标识，便于链路追踪。在处理一个请求的过程中有时会输出多条日志，如果每条日志都共享统一的请求ID，那么在日志追踪时会更加方便。此时，可以使用Logback原生提供的MDC(Mapped Diagnostic Context)功能，创建一个RequestIdMdcFilter</li></ul><pre><code>    protected void doFilterInternal(HttpServletRequest request,                                HttpServletResponse response,                                FilterChain filterChain)        throws ServletException, IOException {    //request id in header may come from Gateway, eg. Nginx    String headerRequestId = request.getHeader(HEADER_X_REQUEST_ID);    MDC.put(REQUEST_ID, isNullOrEmpty(headerRequestId) ? newUuid() : headerRequestId);    try {        filterChain.doFilter(request, response);    } finally {        clearMdc();    }}</code></pre><ul><li>集中式日志管理，在多节点部署的场景下，各个节点的日志是分散的，为此可以引入诸如ELK之类的工具将日志统一输出到ElasticSearch中。</li></ul><pre><code>&lt;appender name=&quot;REDIS&quot; class=&quot;com.cwbase.logback.RedisAppender&quot;&gt;&lt;tags&gt;ecommerce-order-backend-${ACTIVE_PROFILE}&lt;/tags&gt;&lt;host&gt;elk.yourdomain.com&lt;/host&gt;&lt;port&gt;6379&lt;/port&gt;&lt;password&gt;whatever&lt;/password&gt;&lt;key&gt;ecommerce-ordder-log&lt;/key&gt;&lt;mdc&gt;true&lt;/mdc&gt;&lt;type&gt;redis&lt;/type&gt;&lt;/appender&gt;</code></pre><h1 id="4-异常处理"><a href="#4-异常处理" class="headerlink" title="4. 异常处理"></a>4. 异常处理</h1><p>在设计异常处理的框架的时候，需要考虑到： </p><ul><li>向客户端提供格式统一的异常返回</li><li>异常信息中应该包含足够多的上下文信息，最好是结构化的数据以便于客户端解析</li><li>不同类型的异常应该包含唯一标识，以便客户端精确识别</li></ul><p>异常处理有两种处理形式，一种是层级式，即每种具体的异常都对应了一个异常类，这些类最终继承自某个父异常；另外一种是单一式，即整个程序中只有一个异常类，再以一个字段来区分不同的异常场景。层级式异常的好处能够显化异常的含义，但是如果设计不好可能会导致程序中大量的异常类。</p><p>使用层级式异常的范例：</p><pre><code>public abstract class AppException extends RuntimeException {    private final ErrorCode code;    private final Map&lt;String, Object&gt; data = newHashMap();}</code></pre><p>这里，ErrorCode枚举中包含了异常的唯一标识、HTTP状态码以及错误信息；而data字段表示各个异常的上下文信息。</p><pre><code>public class OrderNotFoundException extends AppException {    public OrderNotFoundException(OrderId orderId) {        super(ErrorCode.ORDER_NOT_FOUND, ImmutableMap.of(&quot;orderId&quot;, orderId.toString()));    }}</code></pre><p>在返回给客户端的时候，通过一个ErrorDetail类来统一异常格式：</p><pre><code>public final class ErrorDetail {    private final ErrorCode code;    private final int status;    private final String message;    private final String path;    private final Instant timestamp;    private final Map&lt;String, Object&gt; data = newHashMap();}</code></pre><p>最终返回给客户端的数据为：</p><pre><code>{  requestId: &quot;d008ef46bb4f4cf19c9081ad50df33bd&quot;,  error: {    code: &quot;ORDER_NOT_FOUND&quot;,    status: 404,    message: &quot;没有找到订单&quot;,    path: &quot;/order&quot;,    timestamp: 1555031270087,    data: {      orderId: &quot;123456789&quot;    }  }}</code></pre><h1 id="5-统一代码风格"><a href="#5-统一代码风格" class="headerlink" title="5. 统一代码风格"></a>5. 统一代码风格</h1><p>除了Checkstyle以外，项目中有些通用的公共编码实践方式也需要进行统一。</p><ul><li>客户端的请求数据类统一使用相同后缀，比如Command</li><li>返回给客户端的数据统一使用相同后缀，比如Represetation</li><li>统一对请求处理的流程框架，比如采用传统的3层架构或者DDD战术模式</li><li>提供一致的异常返回（请参考“异常处理”小节）</li><li>提供统一的分页结构类</li><li>明确测试分类以及统一的测试基础类（请参考“自动化测试分类”小节）<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1></li></ul><p><a href="https://insights.thoughtworks.cn/backend-development-iteration0/" target="_blank" rel="noopener">https://insights.thoughtworks.cn/backend-development-iteration0/</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 项目模板 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>XML与JSON的比较</title>
      <link href="/XML%E4%B8%8EJSON%E7%9A%84%E6%AF%94%E8%BE%83/"/>
      <url>/XML%E4%B8%8EJSON%E7%9A%84%E6%AF%94%E8%BE%83/</url>
      
        <content type="html"><![CDATA[<h1 id="1-JSON"><a href="#1-JSON" class="headerlink" title="1. JSON"></a>1. JSON</h1><p>JSON - JavaScript Object Notation, an open standard file format uses human-readable text to transmit data objects consisting of attribute–value pairs and array data types (or any other serializable value). It is a very common data format used for asynchronous browser–server communication, including as a replacement for XML in some AJAX-style systems.</p><p>The official Internet media type for JSON is <strong>application/json</strong>. </p><h1 id="2-XML"><a href="#2-XML" class="headerlink" title="2. XML"></a>2. XML</h1><p>JSON is promoted as a <strong>low-overhead alternative</strong> to XML as both of these formats have widespread support for creation, reading, and decoding in the real-world situations where they are commonly used.</p><p>XML has been used to <strong>describe structured data and to serialize objects</strong>. Various XML-based protocols exist to represent the same kind of data structures as JSON for the same kind of data interchange purposes. Data can be encoded in XML in several ways. The most expansive form <strong>using tag pairs results</strong> in a much larger representation than JSON, but if data is stored in attributes and ‘short tag’ form where the closing tag is replaced with ‘/&gt;’, the representation is often about the same size as JSON or just a little larger. If the data is compressed <strong>using an algorithm like gzip</strong>, there is little difference because compression is good at saving space when a pattern is repeated.</p><p>XML also has the concept of <strong>++schema++</strong>. <strong>This permits strong typing, user-defined types, predefined tags, and formal structure, allowing for formal validation of an XML stream in a portable way</strong>. Similarly, there is an IETF draft proposal for a schema system for JSON.[44]</p><p>XML supports comments, but JSON does not</p><h1 id="3-Differences"><a href="#3-Differences" class="headerlink" title="3. Differences"></a>3. Differences</h1><h1 id="3-1-XML-is-a-markup-language-whereas-JSON-is-a-way-of-representing-objects"><a href="#3-1-XML-is-a-markup-language-whereas-JSON-is-a-way-of-representing-objects" class="headerlink" title="3.1 XML is a markup language whereas JSON is a way of representing objects"></a>3.1 XML is a markup language whereas JSON is a way of representing objects</h1><p>A markup language is a way of adding extra information to free-flowing plain text </p><pre><code>&lt;Document&gt;    &lt;Paragraph Align=&quot;Center&quot;&gt;        Here &lt;Bold&gt;is&lt;/Bold&gt; some text.    &lt;/Paragraph&gt;&lt;/Document&gt;</code></pre><p>An object notation like JSON is not as flexible. But this is usually a good thing. When you’re representing objects, you simply don’t need the extra flexibility. To represent the above example in JSON, you’d actually have to solve some problems manually that XML solves for you.</p><pre><code>{    &quot;Paragraphs&quot;: [        {            &quot;align&quot;: &quot;center&quot;,            &quot;content&quot;: [                &quot;Here &quot;, {                    &quot;style&quot; : &quot;bold&quot;,                    &quot;content&quot;: [ &quot;is&quot; ]                },                &quot; some text.&quot;            ]        }    ]}</code></pre><p>JSON is better suited if you have typical a hierarchy of objects and you want to represent them in a stream. </p><pre><code>{    &quot;firstName&quot;: &quot;Homer&quot;,    &quot;lastName&quot;: &quot;Simpson&quot;,    &quot;relatives&quot;: [ &quot;Grandpa&quot;, &quot;Marge&quot;, &quot;The Boy&quot;, &quot;Lisa&quot;, &quot;I think that&#39;s all of them&quot; ]} </code></pre><p>Below is same expression in xml</p><pre><code>&lt;Person&gt;    &lt;FirstName&gt;Homer&lt;/FirstName&gt;    &lt;LastName&gt;Simpsons&lt;/LastName&gt;    &lt;Relatives&gt;        &lt;Relative&gt;Grandpa&lt;/Relative&gt;        &lt;Relative&gt;Marge&lt;/Relative&gt;        &lt;Relative&gt;The Boy&lt;/Relative&gt;        &lt;Relative&gt;Lisa&lt;/Relative&gt;        &lt;Relative&gt;I think that&#39;s all of them&lt;/Relative&gt;    &lt;/Relatives&gt;&lt;/Person&gt;</code></pre><h2 id="3-2-JSON-has-defined-ways-of-distinguishing-records"><a href="#3-2-JSON-has-defined-ways-of-distinguishing-records" class="headerlink" title="3.2 JSON has defined ways of distinguishing records"></a>3.2 JSON has defined ways of distinguishing records</h2><p>You can differenciate records directly in JSON. List and normal record have different expression; wheareas in XML, they look all same. </p><p>We need to use an external schema or extra user defined attributes in XML to express different expressions, or some limitations on it. While in JSON, it’s self describing by default. </p><p>-&gt; JSON should be the first choise for object notation, where XML should spot at document markup. </p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BackEnd </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>System.gc() and Runtime.gc()</title>
      <link href="/System-gc-and-Runtime-gc/"/>
      <url>/System-gc-and-Runtime-gc/</url>
      
        <content type="html"><![CDATA[<p>首先在Java中垃圾回收算法是首先遍历所有在堆中的非垃圾的对象，然后推断出那些一段时间内没有被访问的对象一定是垃圾了。call gc()方法不是强制垃圾回收发生的，相反的，它只是在建议JVM现在是不错的做垃圾回收的时间。</p><p>system.gc()是用来运行垃圾收集器的。call这个方法就意味着Java虚拟机正在努力去回收没有被使用的对象，使得他们现在占用的内存可以进行快速地再利用。整个垃圾回收在Java中是自动进行的。</p><p>system.gc()是个静态方法，但是手动调用它很有可能会让整个系统运行更慢的，一般为了加快整体的运行，会使用<code>-XX:+DisableExplicitGC</code>这条指令，这样子JVM就不会在你手动唤醒gc的时候直接call这个方法了。</p><p>runtime.gc()和system.gc()并没有什么区别，实质上system.gc()内部就call了runtime.gc()。 唯一的不同在于System.gc()是类的方法然而runtime.gc()是实例方法。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="http://net-informations.com/java/cjava/gc.htm" target="_blank" rel="noopener">http://net-informations.com/java/cjava/gc.htm</a> </li><li><a href="https://docs.oracle.com/javase/7/docs/api/java/lang/System.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/7/docs/api/java/lang/System.html</a> </li><li><a href="https://www.geeksforgeeks.org/garbage-collection-java/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/garbage-collection-java/</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ruby Totorial</title>
      <link href="/Ruby-Totorial/"/>
      <url>/Ruby-Totorial/</url>
      
        <content type="html"><![CDATA[<p>Met circumstances where need Ruby knowledge to resolve problems, thus need to do a quick touch on Ruby, at least know how to read ruby code. </p><p>Leran by doing, or we say, learn by satisfying current needs. </p><h1 id="1-Basics"><a href="#1-Basics" class="headerlink" title="1. Basics"></a>1. Basics</h1><ul><li>features <ul><li>object-oriented </li><li>server side scripting language </li><li>can be used to write common gateway interface(CGI) scripts</li></ul></li></ul><h2 id="1-1-Syntax-of-Ruby"><a href="#1-1-Syntax-of-Ruby" class="headerlink" title="1.1 Syntax of Ruby"></a>1.1 Syntax of Ruby</h2><ul><li>whitespace <ul><li>ignored in ruby code, except when they appear in strings. </li></ul></li><li>end of line<ul><li>you could use <ul><li>semicolons </li><li>newline characters as the ending of a statement </li></ul></li></ul></li><li>Ruby Identifiers<ul><li>case sensitive </li></ul></li><li>comments<ul><li><code>#</code></li><li><code>=begin</code> at beginning, <code>=end</code> at the end</li></ul></li></ul><pre><code>// Declares code to be called before the program run BEGIN {    code}// Declares code to be called at the end of the program END {    code}</code></pre><ul><li>classes and objects <ul><li>features<ul><li>data encapsulation </li><li>data abstraction </li><li>polymorphism</li><li>inheritance </li></ul></li></ul></li></ul><pre><code>// Class exampleClass Vehicle {   Number no_of_wheels   Number horsepower   Characters type_of_tank   Number Capacity   Function speeding {   }   Function driving {   }   Function halting {   }}</code></pre><h2 id="1-2-Class-and-Objects"><a href="#1-2-Class-and-Objects" class="headerlink" title="1.2 Class and Objects"></a>1.2 Class and Objects</h2><ul><li>Define a class in Ruby </li></ul><pre><code>// A class always starts with keyword class, followed by the name of the class. // Terminate a class by using the keyword end. class Customerend</code></pre><ul><li>Variables in a Ruby Class <ul><li>local variables <ul><li>defined in a method</li><li>begin with a lowercase letter or _. </li></ul></li><li>instance variables <ul><li>available across methods for any particular instance or object </li><li>instance variables change from object to object </li><li><code>@</code></li></ul></li><li>class variables <ul><li>available across different objects </li><li>belongs to the class and is a characteristic of a class </li><li><code>@@</code></li></ul></li><li>global variables <ul><li>Class variables are not available across classes, while global variables are.  </li><li><code>$</code></li></ul></li></ul></li></ul><pre><code>// Determine the number of objects that are being ccreated class Customer   @@no_of_customers = 0end</code></pre><ul><li>creating objects with <code>new</code> method<ul><li><code>object1 = Customer.new</code></li><li>object1 is object name</li><li>Customer is class</li><li>To instantiate a new object, you need to use class name followed by dot and new(keyword)</li></ul></li><li>custom method to create ruby objects (similar to constructor concept in Java)<ul><li>pass parameters to method new </li><li>when you plan to declare new method with parameters, you need to declare the method <strong>initialize</strong> at the time of the class creation </li></ul></li></ul><pre><code>class Customer   @@no_of_customers = 0   def initialize(id, name, addr)      @cust_id = id      @cust_name = name      @cust_addr = addr   endend// To create objects cust1 = Customer.new(&quot;1&quot;, &quot;John&quot;, &quot;Wisdom Apartments, Ludhiya&quot;)</code></pre><ul><li>member functions in class <ul><li>each method in a class starts with the keyword <code>def</code> followed by the method name </li></ul></li></ul><pre><code>class Sample    def function        statement 1        statement 2    endend// A full example #!/usr/bin/rubyclass Sample   def hello      puts &quot;Hello Ruby!&quot;   endend# Now using above class to create objectsobject = Sample. newobject.hello</code></pre><h2 id="1-3-Variables"><a href="#1-3-Variables" class="headerlink" title="1.3 Variables"></a>1.3 Variables</h2><ul><li>Global Variables <ul><li>begin with $ </li><li>uninitialized global variables have the value <code>nil</code> </li></ul></li></ul><pre><code>#!/usr/bin/ruby$global_variable = 10class Class1   def print_global      # In ruby, you can use HashTag to access any variables value       puts &quot;Global variable in Class1 is #$global_variable&quot;   endendclass Class2   def print_global      puts &quot;Global variable in Class2 is #$global_variable&quot;   endendclass1obj = Class1.newclass1obj.print_globalclass2obj = Class2.newclass2obj.print_global</code></pre><ul><li>Instance Variables <ul><li>begin with <code>@</code></li></ul></li></ul><pre><code>#!/usr/bin/rubyclass Customer   def initialize(id, name, addr)      @cust_id = id      @cust_name = name      @cust_addr = addr   end   def display_details()      puts &quot;Customer id #@cust_id&quot;      puts &quot;Customer name #@cust_name&quot;      puts &quot;Customer address #@cust_addr&quot;   endend# Create Objectscust1 = Customer.new(&quot;1&quot;, &quot;John&quot;, &quot;Wisdom Apartments, Ludhiya&quot;)cust2 = Customer.new(&quot;2&quot;, &quot;Poul&quot;, &quot;New Empire road, Khandala&quot;)# Call Methodscust1.display_details()cust2.display_details()</code></pre><ul><li>Class Variables <ul><li>begin with @@</li><li>must be initialized before they can be used in method definitions </li></ul></li></ul><pre><code>#!/usr/bin/rubyclass Customer   @@no_of_customers = 0   def initialize(id, name, addr)      @cust_id = id      @cust_name = name      @cust_addr = addr   end   def display_details()      puts &quot;Customer id #@cust_id&quot;      puts &quot;Customer name #@cust_name&quot;      puts &quot;Customer address #@cust_addr&quot;   end   def total_no_of_customers()      @@no_of_customers += 1      puts &quot;Total number of customers: #@@no_of_customers&quot;   endend# Create Objectscust1 = Customer.new(&quot;1&quot;, &quot;John&quot;, &quot;Wisdom Apartments, Ludhiya&quot;)cust2 = Customer.new(&quot;2&quot;, &quot;Poul&quot;, &quot;New Empire road, Khandala&quot;)# Call Methodscust1.total_no_of_customers()cust2.total_no_of_customers()</code></pre><ul><li><p>Local variables </p><ul><li>begin with a lowercase letter or <code>_</code></li><li>scope<ul><li>class</li><li>module</li><li>def</li><li>do to the corresponding end</li><li>block’s opening brace to its close brace </li></ul></li></ul></li><li><p>Constants</p><ul><li>Begin with an <strong>uppercase</strong> letter  </li><li>defined within a class or module </li></ul></li><li><p>Pseudo-variables </p><ul><li><p>self </p></li><li><p>true</p></li><li><p>false</p></li><li><p>nil </p><ul><li>Value representing undefined </li></ul></li><li><p><code>_FILE_</code></p><ul><li>the name of the current source file </li></ul></li><li><p><code>_LINE_</code></p><ul><li>the current line number in the source file <h2 id="1-4-Arrays"><a href="#1-4-Arrays" class="headerlink" title="1.4 Arrays"></a>1.4 Arrays</h2>Array are created by placing a comma-separated series of object references between the square brackets.</li></ul><p>#!/usr/bin/ruby</p><p>ary = [  “fred”, 10, 3.14, “This is a string”, “last element”, ]<br>ary.each do |i|<br> puts i<br>end</p></li></ul></li></ul><h2 id="1-5-Hashes"><a href="#1-5-Hashes" class="headerlink" title="1.5 Hashes"></a>1.5 Hashes</h2><p>Hash is created by placing a list of key/value pairs between braces, with either a comma or the sequence =&gt; between the key and the value. A trailing comma is ignored.</p><pre><code>#!/usr/bin/rubyhsh = colors = { &quot;red&quot; =&gt; 0xf00, &quot;green&quot; =&gt; 0x0f0, &quot;blue&quot; =&gt; 0x00f }hsh.each do |key, value|   print key, &quot; is &quot;, value, &quot;\n&quot;end</code></pre><h2 id="1-6-Ranges"><a href="#1-6-Ranges" class="headerlink" title="1.6 Ranges"></a>1.6 Ranges</h2><p>A Range represents an interval which is a set of values with a start and an end. Ranges may be constructed using the s..e and s…e literals, or with Range.new.</p><pre><code>#!/usr/bin/ruby(10..15).each do |n|    print n, &#39; &#39; end</code></pre><h2 id="1-7-Operators"><a href="#1-7-Operators" class="headerlink" title="1.7 Operators"></a>1.7 Operators</h2><ul><li><code>&lt;=&gt;</code><ul><li>ruturn 0 if first operand equals second</li><li>1 if first greater than second</li><li>-1 if first less than second </li></ul></li><li><code>.eql?</code><ul><li>true if the receiver and argument have both the same type and equal values</li></ul></li><li><code>equal?</code><ul><li>true if the receiver and argument have the same object id </li></ul></li><li><code>..</code><ul><li>1..10 creates a range from 1 to 10 inclusive</li></ul></li><li><code>...</code><ul><li>1…10 creates a range from 1 to 9  </li></ul></li><li>defined? operators<ul><li>takes the form of a method call to determine whether or not the passed expression is defined</li><li>returns a description string of the expression, or nil if the expression isn’t defined </li></ul></li><li>dot operators<ul><li></li></ul></li><li>double colon <code>::</code> operators<ul><li>You call a module method by preceding its name with the module’s name and a period, and you reference a constant using the module name and two colons. </li><li><code>::</code> us a unary operator that allows constants, instance methods and class methods defined within a class or module to be accessed from anywhere outside the class or module </li><li>*<em>Classes and methods are considered to be constants too *</em></li></ul></li></ul><h2 id="1-8-Conditions"><a href="#1-8-Conditions" class="headerlink" title="1.8 Conditions"></a>1.8 Conditions</h2><pre><code>// if else condition checkif condition    code..elsif condition2    codeelse     codeend// case #!/usr/bin/ruby$age =  5case $agewhen 0 .. 2   puts &quot;baby&quot;when 3 .. 6   puts &quot;little child&quot;when 7 .. 12   puts &quot;child&quot;when 13 .. 18   puts &quot;youth&quot;else   puts &quot;adult&quot;end</code></pre><h2 id="1-9-Loops"><a href="#1-9-Loops" class="headerlink" title="1.9 Loops"></a>1.9 Loops</h2><pre><code>while condition do     codeend</code></pre><p>Executes code while conditional is true </p><pre><code>$i = 0$num = 5begin     puts(&quot;123&quot;)    $i += 1end while $i &lt; $num // for loopfor i in 0..5    puts &quot;Value of local variable is #{i}&quot;end// subtitute way of for loop(expression).each do |variable|     codeend// E.G (0..5).each do |i|    puts &quot;Value of local variable is #{i}&quot;end </code></pre><ul><li><code>next</code><ul><li>jump to the next iteration of the most internal loop </li></ul></li><li><code>redo</code><ul><li>restarts this iteration of the most internal loop, without checking loop condition  </li></ul></li><li><code>retry</code></li><li><code>break</code><ul><li>terminate the most internal loop  </li></ul></li></ul><h2 id="1-10-Methods"><a href="#1-10-Methods" class="headerlink" title="1.10 Methods"></a>1.10 Methods</h2><ul><li><p>used to bundle one or more repeatable statements into a single unit </p></li><li><p>method name should begin with a lowercase lettter </p></li><li><p>method should be defined before calling them </p></li><li><p>call the method by direcly type in the method name <code>method_name</code></p></li><li><p>with parameters <code>method_name 25, 30</code></p></li><li><p>Ruby will return the value of lat statement by default </p></li><li><p>or use the return statement </p></li><li><p>method defined in the class definition are marked as <strong>public</strong> by default </p></li><li><p>a block is always invoked from a function with the same name as that of the block </p><p>  def method_name (var1, var2)</p><pre><code>  expr</code></pre><p>  end </p></li><li><p>variable number of parameters </p><ul><li><code>def sample (*test)</code>   </li></ul></li></ul><h2 id="1-11-Blocks"><a href="#1-11-Blocks" class="headerlink" title="1.11 Blocks"></a>1.11 Blocks</h2><ul><li>definition <ul><li>consists of chunks of code</li><li>assign a name to a block </li><li>code in the block is always enclosed within braces <code>{}</code> or <code>()</code></li><li>a block is always invoked from a function with the same name as that of the block</li><li>invoke a block by using the <code>yield</code> statement </li></ul></li><li>if the last argument of a method is preceded by &amp;, then you can pass a block to this method and this block will be assigned to the last parameter. </li></ul><pre><code>#!/usr/bin/rubydef test(&amp;block)   block.callendtest { puts &quot;Hello World!&quot;}</code></pre><h2 id="1-12-Modules-and-Mixins"><a href="#1-12-Modules-and-Mixins" class="headerlink" title="1.12 Modules and Mixins"></a>1.12 Modules and Mixins</h2><ul><li>Module<ul><li>way of grouping together methods, classes, and constants </li><li>provides namespace and prevent name clashes<ul><li>a sandbox  </li></ul></li><li>implement mixin facility </li></ul></li></ul><pre><code>// syntaxmodule Identifier    statement1    statement2end</code></pre><ul><li>call a module method by precedint its name with the module’s name and a period </li><li>reference a constant using the module name and two colons </li></ul><pre><code>#!/usr/bin/ruby# Module defined in trig.rb filemodule Trig   PI = 3.141592654   def Trig.sin(x)   # ..   end   def Trig.cos(x)   # ..   endend</code></pre><ul><li><p><code>require</code></p><ul><li>similar to import, include</li><li>if a third program wants to use any defined module, it can simply load the module files using the Ruby<code>require</code> statement </li></ul></li><li><p>mixin </p><ul><li>multiple inheratance </li></ul></li></ul><pre><code>module A   def a1   end   def a2   endendmodule B   def b1   end   def b2   endendclass Sampleinclude Ainclude B   def s1   endendsamp = Sample.newsamp.a1samp.a2samp.b1samp.b2samp.s1</code></pre><p>In this way, samp could call method defined in Module A and Module B</p><h2 id="1-13-Strings"><a href="#1-13-Strings" class="headerlink" title="1.13 Strings"></a>1.13 Strings</h2><ul><li>holds and manipulates an arbitrary sequence of one or more bytes</li></ul><h2 id="1-14-Array"><a href="#1-14-Array" class="headerlink" title="1.14 Array"></a>1.14 Array</h2><ul><li>ordered, integer indexed collections of any object</li><li>each element in an array is associated with and referred to by an index </li><li>creating arrays<ul><li><code>Array.new</code> </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ruby </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PATH and LD_LIBRARY_PATH</title>
      <link href="/PATH-and-LD-LIBRARY-PATH/"/>
      <url>/PATH-and-LD-LIBRARY-PATH/</url>
      
        <content type="html"><![CDATA[<h1 id="1-What-is-LD-LIBRARY-PATH"><a href="#1-What-is-LD-LIBRARY-PATH" class="headerlink" title="1. What is LD_LIBRARY_PATH?"></a>1. What is LD_LIBRARY_PATH?</h1><p>LD_LIBRARY_PATH is a variable in linux to provide a list of additional directories in which to search for dynamically linkable libraries. </p><p>Consulted at time of execution , not consulted at link time </p><h1 id="2-PATH"><a href="#2-PATH" class="headerlink" title="2. PATH"></a>2. PATH</h1><p>PATH environment variable specifies the search paths for commands</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Lombok</title>
      <link href="/Lombok/"/>
      <url>/Lombok/</url>
      
        <content type="html"><![CDATA[<p>Merely want to list all annotations here, and do some analysis. Lombok is a great tool to relieve java programmer from writing duplicate code. </p><h1 id="1-EqualsAndHashCode"><a href="#1-EqualsAndHashCode" class="headerlink" title="1. @EqualsAndHashCode"></a>1. @EqualsAndHashCode</h1><p>Generates hashCode and equals implementations from the fields of your object. </p><h2 id="1-1-What’s-hashCode-equals-use-for"><a href="#1-1-What’s-hashCode-equals-use-for" class="headerlink" title="1.1 What’s hashCode/ equals use for?"></a>1.1 What’s hashCode/ equals use for?</h2><p>Equals compare pass-in objects’ attributes, to see if they are the same. It compares all the field values to make judgement. </p><p>== compares whether two object references point to the same object</p><p>Use hashcode() method to optimize performance when comparing objects. <strong><em>Execute hashcode() returns a unique ID for each object in your program, which makes the task of comparing the whole state of the object much easier.</em></strong> </p><p>First run hashcode() method to judge if two objects are same, then run equals() method. </p><p>See <a href="https://www.javaworld.com/article/3305792/learn-java/java-challengers-4-comparing-java-objects-with-equals-and-hashcode.html" target="_blank" rel="noopener">Comparing Java objects with <code>equals()</code> and <code>hashcode()</code></a></p><h2 id="1-2-Implementation"><a href="#1-2-Implementation" class="headerlink" title="1.2 Implementation"></a>1.2 Implementation</h2><ol><li>By default, it uses all non-static and non-transient fields</li><li>Do modification by set <code>@EqualsAndHashCode.Include</code> or <code>@EqualsAndHashCode.Exclude</code></li></ol><h3 id="1-3-1-Apply-to-a-class-that-extends-another"><a href="#1-3-1-Apply-to-a-class-that-extends-another" class="headerlink" title="1.3.1 Apply to a class that extends another"></a>1.3.1 Apply to a class that extends another</h3><p>Normally, auto-generating an equals and hashCode method for such classes is a bad idea, as the superclass also defines fields, which also need equals/hashCode code but this code will not be generated. By setting callSuper to true, you can include the equals and hashCode methods of your superclass in the generated methods. For hashCode, the result of super.hashCode() is included in the hash algorithm, and forequals, the generated method will return false if the super implementation thinks it is not equal to the passed in object.  You can safely call your superclass equals if it, too, has a lombok-generated equals method.</p><p><code>callSuper</code>, set it to ture when you don’t extend anything is a compile time error. </p><pre><code> import lombok.EqualsAndHashCode;@EqualsAndHashCodepublic class EqualsAndHashCodeExample {  private transient int transientVar = 10;  private String name;  private double score;  @EqualsAndHashCode.Exclude private Shape shape = new Square(5, 10);  private String[] tags;  @EqualsAndHashCode.Exclude private int id;  public String getName() {    return this.name;  }  @EqualsAndHashCode(callSuper=true)  public static class Square extends Shape {    private final int width, height;    public Square(int width, int height) {      this.width = width;      this.height = height;    }  }}</code></pre><h1 id="2-NonNull"><a href="#2-NonNull" class="headerlink" title="2. @NonNull"></a>2. @NonNull</h1><p>Use this annotation on the parameter of a mothod or constructor to have lombok generate a null-check statement. </p><p>And a @NonNull on a primitive parameter results in a warning. </p><pre><code> import lombok.NonNull;public class NonNullExample extends Something {  private String name;  public NonNullExample(@NonNull Person person) {    super(&quot;Hello&quot;);    this.name = person.getName();  }}</code></pre><h1 id="3-Cleanup"><a href="#3-Cleanup" class="headerlink" title="3. @Cleanup"></a>3. @Cleanup</h1><p>It’s an antomatic resource management: call your close() methods safely with no hassle!</p><p>You can use @Cleanup to <strong><em>ensure a given resource is automatically cleaned up before the code execution path exits your current scope</em></strong>. </p><p>For example, you can use it like： </p><pre><code>@Cleanup InputStream in = new FileInputStream(&quot;some/file&quot;);</code></pre><p>As a result, at the end of the scope you are in, <code>in.close()</code> is called. The call is guaranteed to run by way of a try/ finally construct. </p><p>If the type of object you’d like to cleanup does not have a close method, you can specify the name of this method like:</p><pre><code>@Cleanup(&quot;dispose&quot;) org.eclipse.swt.widgets.CoolBar bar = new CoolBar(parent, 0); </code></pre><p>Notice: there should be no variables in the cleanup method. </p><pre><code> import lombok.Cleanup;import java.io.*;public class CleanupExample {  public static void main(String[] args) throws IOException {    @Cleanup InputStream in = new FileInputStream(args[0]);    @Cleanup OutputStream out = new FileOutputStream(args[1]);    byte[] b = new byte[10000];    while (true) {      int r = in.read(b);      if (r == -1) break;      out.write(b, 0, r);    }  }}</code></pre><h1 id="4-Getter-Setter"><a href="#4-Getter-Setter" class="headerlink" title="4. @Getter/ @Setter"></a>4. @Getter/ @Setter</h1><p>Annotate any field with Getter and Setter to let lombok generate the default getter/ setter automatically. </p><p>The generated getter/setter method will be public unless you explicitly specify an AccessLevel, as shown in the example below. Legal access levels are PUBLIC, PROTECTED, PACKAGE, and PRIVATE.</p><p>Also we can put the annotation on a class, in this way, it’s as if you annotate all the non-static fields in the class with annotation. </p><pre><code> import lombok.AccessLevel;import lombok.Getter;import lombok.Setter;public class GetterSetterExample {  /**   * Age of the person. Water is wet.   *    * @param age New value for this person&#39;s age. Sky is blue.   * @return The current value of this person&#39;s age. Circles are round.   */  @Getter @Setter private int age = 10;  /**   * Name of the person.   * -- SETTER --   * Changes the name of this person.   *    * @param name The new value.   */  @Setter(AccessLevel.PROTECTED) private String name;  @Override public String toString() {    return String.format(&quot;%s (age: %d)&quot;, name, age);  }}</code></pre><h1 id="5-ToString"><a href="#5-ToString" class="headerlink" title="5. @ToString"></a>5. @ToString</h1><p>No need to start a debugger to see your fields, lombok can generate a toString for you. </p><p>Any <strong><em>class</em></strong> can be annotated with @ToString to let lombok generate an implementation of the toString() method. </p><p>We can set: </p><ul><li><p>includeFieldNames </p><ul><li>Add some clarity to the output </li></ul></li><li><p>@ToString.Exclude </p></li><li><p>@ToString(onlyExplicitlyIncluded = true)</p><ul><li>specify exactly which fields you wish to be used  </li><li>then marking each field you want to include with <code>@ToString.Include</code></li></ul></li><li><p>Can also include non static methods that take no argument  -&gt; use <code>@ToString.Include</code></p><p>  import lombok.ToString;</p><p>  @ToString<br>  public class ToStringExample {</p><pre><code>private static final int STATIC_VAR = 10;private String name;private Shape shape = new Square(5, 10);private String[] tags;@ToString.Exclude private int id;public String getName() {  return this.name;}@ToString(callSuper=true, includeFieldNames=true)public static class Square extends Shape {  private final int width, height;  public Square(int width, int height) {    this.width = width;    this.height = height;  }}</code></pre><p>  }</p></li></ul><h1 id="6-NoArgsConstructor-RequiredArgsConstructor-AllArgsConstructor"><a href="#6-NoArgsConstructor-RequiredArgsConstructor-AllArgsConstructor" class="headerlink" title="6. @NoArgsConstructor, @RequiredArgsConstructor, @AllArgsConstructor"></a>6. @NoArgsConstructor, @RequiredArgsConstructor, @AllArgsConstructor</h1><p>Constructors: </p><ul><li>Generates constructors that take no arguments</li><li>Generates constructors that take one argument per final/ non-null field </li><li>Generates constructors that take one argument for every field</li></ul><h2 id="6-1-NoArgsConstructor"><a href="#6-1-NoArgsConstructor" class="headerlink" title="6.1 @NoArgsConstructor"></a>6.1 @NoArgsConstructor</h2><p>@NoArgsConstructor will generate a constructor with no parameters. </p><p>If it’s not possible(because of final fields), a compiler error will result, unless we use <code>@NoArgsConstructor(force = true)</code>. Then all final fields are initialized with 0/ false/ null </p><h2 id="6-2-RequiredArgsConstructor"><a href="#6-2-RequiredArgsConstructor" class="headerlink" title="6.2 @RequiredArgsConstructor"></a>6.2 @RequiredArgsConstructor</h2><p>@RequiredArgsConstructor  generates a constructor with 1 parameter for each field that requires special handling.  All <strong>non-initialized final fields</strong> get a parameter, as well as any fields that are marked as <strong>@NonNull</strong> that aren’t initialized where they are declared. For those fields marked with @NonNull, an explicit null check is also generated. The constructor will throw a NullPointerException if any of the parameters intended for the fields marked with @NonNull contain null. The order of the parameters match the order in which the fields appear in your class.</p><h2 id="6-3-AllArgsConstructor"><a href="#6-3-AllArgsConstructor" class="headerlink" title="6.3 @AllArgsConstructor"></a>6.3 @AllArgsConstructor</h2><p>@AllArgsConstructor generates a constructor with 1 parameter for each field in your class. Fields marked with @NonNull result in null checks on those parameters.</p><h1 id="7-Data"><a href="#7-Data" class="headerlink" title="7. @Data"></a>7. @Data</h1><p>All togerther: a shortcut for: </p><ul><li>@ToString,</li><li>@EqualsAndHashCode</li><li>@Getter on all fields</li><li>@Setter on all non-final fields</li><li>@RequiredArgsConstructor </li></ul><p>@Data generates all the boilerplate that is normally associated with simple POJOs (Plain Old Java Objects) and beans: getters for all fields, setters for all non-final fields, and appropriate toString, equals and hashCode implementations that involve the fields of the class, and a constructor that initializes all final fields, as well as all non-final fields with no initializer that have been marked with @NonNull, in order to ensure the field is never null.</p><p>All generated getters and setters will be public</p><p>All fields marked as transient will not be considered for hashCode and equals. All static fields will be skipped entirely. </p><pre><code> import lombok.AccessLevel;import lombok.Setter;import lombok.Data;import lombok.ToString;@Data public class DataExample {  private final String name;  @Setter(AccessLevel.PACKAGE) private int age;  private double score;  private String[] tags;  @ToString(includeFieldNames=true)  @Data(staticConstructor=&quot;of&quot;)  public static class Exercise&lt;T&gt; {    private final String name;    private final T value;  }}</code></pre><h1 id="8-Value"><a href="#8-Value" class="headerlink" title="8. @Value"></a>8. @Value</h1><p>@Value is the immutable variant of @Data. All fields are made private and final by default. setters are not generated at all. </p><p>The class itself is also made final by default, becuase immutability is not something that can be forced onto a sunclass.</p><p>Actually, @Value equals to <code>final @ToString @EqualsAndHashCode @AllArgsConstructor @FieldDefaults(makeFinal = true, level = AccessLevel.PRIVATE) @Getter</code></p><pre><code>import lombok.AccessLevel;import lombok.experimental.NonFinal;import lombok.experimental.Value;import lombok.experimental.Wither;import lombok.ToString;@Value public class ValueExample {  String name;  @Wither(AccessLevel.PACKAGE) @NonFinal int age;  double score;  protected String[] tags;  @ToString(includeFieldNames=true)  @Value(staticConstructor=&quot;of&quot;)  public static class Exercise&lt;T&gt; {    String name;    T value;  }}</code></pre><h1 id="9-Builder"><a href="#9-Builder" class="headerlink" title="9. @Builder"></a>9. @Builder</h1><p>The @Builder annotation produces complex builder APIs for your classes.</p><p>@Builder lets you automatically produce the code required to have your class be instantiable with code such as:<br>Person.builder().name(“Adam Savage”).city(“San Francisco”).job(“Mythbusters”).job(“Unchained Reaction”).build();</p><h1 id="10-Getter-lazy-true"><a href="#10-Getter-lazy-true" class="headerlink" title="10. @Getter(lazy = true)"></a>10. @Getter(lazy = true)</h1><p>You can let lombok generate a getter which will calculate a value once, the first time this getter is called, and cache it from then on. This can be useful if calculating the value takes a lot of CPU, or the value takes a lot of memory. To use this feature, create a private final variable, initialize it with the expression that’s expensive to run, and annotate your field with @Getter(lazy=true)</p><pre><code> import lombok.Getter;public class GetterLazyExample {  @Getter(lazy=true) private final double[] cached = expensive();  private double[] expensive() {    double[] result = new double[1000000];    for (int i = 0; i &lt; result.length; i++) {      result[i] = Math.asin(i);    }    return result;  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Annotation </tag>
            
            <tag> Lombok </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JSP Tutorial</title>
      <link href="/JSP-Tutorial/"/>
      <url>/JSP-Tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><h2 id="1-1-Intro"><a href="#1-1-Intro" class="headerlink" title="1.1 Intro"></a>1.1 Intro</h2><ul><li>JavaServer Pages <ul><li>develop webpages that support dynamic content </li><li>collect input from users through webpage forms</li><li>present records from a database or another source </li><li>creates webpage dynamically </li></ul></li></ul><h2 id="1-2-Architecture"><a href="#1-2-Architecture" class="headerlink" title="1.2 Architecture"></a>1.2 Architecture</h2><ul><li><p>JSP engine</p><ul><li>a container to process JSP pages  </li><li>responsible for intercepting requests for JSP pages </li></ul></li><li><p>JSP processing </p><ul><li>browser sends an HTTP request to the web server </li><li>web server recognizes that the HTTP request is for a JSP page and forwards it to a JSP engine. <ul><li>Finish by using the URL or JSP page which ends with .jsp instead of .html </li></ul></li><li>JSP engine loads the JSP page from disk and converts it into a servlet content. </li><li>JSP engine compiles the servlet into an executable class and forwards the original request to a servlet engine</li><li>A part of the web server called the servlet engine loads the Servlet class and executes it. During execution, the servlet produces an output in HTML format. The output is furthur passed on to the web server by the servlet engine inside an HTTP response.</li><li>The web server forwards the HTTP response to your browser in terms of static HTML content !!! Return static html directly </li><li>the web browser handles the dynamically generated HTML page inside the HTTP response exactly as if it were a static page </li></ul></li></ul><h2 id="1-3-Lifecycle"><a href="#1-3-Lifecycle" class="headerlink" title="1.3 Lifecycle"></a>1.3 Lifecycle</h2><p>A JSP life cycle is defined as the process from its creation till the destruction, Similar to a servlet life cycle with an additional step which is required to compile a JSP into servlet.</p><ul><li>compilation<ul><li>when a browser asks for a JSP, the JSP engine first checks to see whether it needs to compile the page </li><li>If the page has never been compiled, or if the JSP has been modified since it was last compiled, the JSP engine compiles the page</li><li>compile involves:<ul><li>parsing the JSP</li><li>turning the JSP into a servlet </li><li>compile the servlet </li></ul></li></ul></li><li>initialization<ul><li>invokes the jspInit() method before servicing any requests  </li></ul></li><li>execution<ul><li>represents all interactions with requests until the JSP is destroyed </li><li>Whenever a browser requests a JSP and the page has been loaded and initialized, the JSP engine invokes the _jspService() method in the JSP</li><li><code>void _jspService(HttpServletRequest request, HttpServletResponse response) {// Service handling code...}</code></li></ul></li><li>cleanup <ul><li>represents when a JSP is being removed from use by a container </li><li>The jspDestroy() method is the JSP equivalent of the destroy method for servlets. </li></ul></li></ul><h1 id="2-Syntax-Operations"><a href="#2-Syntax-Operations" class="headerlink" title="2. Syntax/ Operations"></a>2. Syntax/ Operations</h1><h2 id="2-1-Elements-of-JSP"><a href="#2-1-Elements-of-JSP" class="headerlink" title="2.1 Elements of JSP"></a>2.1 Elements of JSP</h2><h3 id="2-1-1-Scriptlet"><a href="#2-1-1-Scriptlet" class="headerlink" title="2.1.1 Scriptlet"></a>2.1.1 Scriptlet</h3><p>A scriptlet can contain any number of JAVA language statements, variable or method declarations, or expressions that are valid in the page scripting language. </p><p><code>&lt;%code fragment%&gt;</code></p><p>XML equivalent as follows: </p><pre><code>&lt;jsp:scriptlet&gt;   code fragment&lt;/jsp:scriptlet&gt;</code></pre><p>Any text, HTML tags, or JSP elements you write must be outside the scriptlet. </p><h3 id="2-1-2-JSP-Declarations"><a href="#2-1-2-JSP-Declarations" class="headerlink" title="2.1.2 JSP Declarations"></a>2.1.2 JSP Declarations</h3><p>A declaration declares one or more variables or methods that you can use in Java code later in the JSP file. You must declare the variable or method before you use it in the JSP file.</p><pre><code>&lt;%! declaration; [ declaration; ]+ ... %&gt;</code></pre><p>We can also write the XML equivalent of the above syntax as follows: </p><pre><code>&lt;jsp:declaration&gt;   code fragment&lt;/jsp:declaration&gt;</code></pre><h3 id="2-1-3-JSP-Expression"><a href="#2-1-3-JSP-Expression" class="headerlink" title="2.1.3 JSP Expression"></a>2.1.3 JSP Expression</h3><ul><li>Contains a scripting language expression that is evaluated, converted to a String, and inserted where the expression appears in the JSP file. </li><li>The expression element can contain any expression that is valid according to the Java Language Specification but you cannot use a semicolon to end an expression.</li></ul><pre><code>&lt;%= expression %&gt;&lt;jsp:expression&gt;    expression&lt;/jsp:expression&gt;</code></pre><h3 id="2-1-4-JSP-Comments"><a href="#2-1-4-JSP-Comments" class="headerlink" title="2.1.4 JSP Comments"></a>2.1.4 JSP Comments</h3><p>JSP comments marks text or statements that the JSP container should ignore. A JSP comment is useful when you want to hide or comment out. </p><p>&lt;%– This is JSP comment –%&gt;</p><h3 id="2-1-5-JSP-Directives"><a href="#2-1-5-JSP-Directives" class="headerlink" title="2.1.5 JSP Directives"></a>2.1.5 JSP Directives</h3><ul><li>A JSP directive affects the overall structure of the servlet class. </li></ul><pre><code>&lt;%@ directive attribute=&quot;value&quot; %&gt;</code></pre><ul><li><code>&lt;%@ page. attribute=.. %&gt;</code><ul><li>Defines page dependent attributes<ul><li>scripting language</li><li>error page</li><li>buffering requirements </li></ul></li><li>instructions to the current page </li><li>attributes list <ul><li>buffer </li><li>autoFlush </li><li>contentType</li><li>errorPage</li><li>isErrorPage</li><li>extends</li><li>import</li><li>info </li><li>isThreadSafe</li><li>language</li><li>session </li><li>isELignored </li><li>isScriptingEnabled</li></ul></li></ul></li><li><code>&lt;%@ include ... %&gt;</code><ul><li>include a file during the translation phase  </li><li>tells the container to merge the content of other external files with the current JSP during the translation phase.</li></ul></li><li><code>&lt;%@ taglib ... %&gt;</code><ul><li>declares a tag library, containing custom actions, used in the page  </li></ul></li></ul><h3 id="2-1-6-JSP-Actions"><a href="#2-1-6-JSP-Actions" class="headerlink" title="2.1.6 JSP Actions"></a>2.1.6 JSP Actions</h3><p>JSP actions use contructs in XML syntax to control the behavior of the servlet engine</p><p>You can dynamically insert a file, reuse javaBeans components, forward the user to another page, or generate HTML for the java plugin </p><pre><code>&lt;jsp:action_name  attribute=&quot;value&gt;</code></pre><ul><li>jsp:include </li><li>jsp:useBean </li><li>jsp:setProperty</li><li>jsp:forward <ul><li>forward the requester to a new page </li></ul></li><li>jsp:plugin<ul><li>generates browser-specific code that makes an OBJECT or EMBED tag for the java plugin</li></ul></li><li>jsp:element <ul><li>defines XML elements dynamically </li></ul></li><li>jsp:attribute <ul><li>defines dynamically defined XML element’s attribute</li></ul></li><li>jsp:body<ul><li>Defines dynamically-defined XML element’s body.</li></ul></li><li>jsp:text <ul><li>write template text in JSP pages and documents </li></ul></li></ul><h2 id="2-2-JSP-Implicit-Objects"><a href="#2-2-JSP-Implicit-Objects" class="headerlink" title="2.2 JSP Implicit Objects"></a>2.2 JSP Implicit Objects</h2><p>JSP supports some automatically defined variables</p><ul><li>request <ul><li>HttpServletRequest object </li></ul></li><li>response <ul><li>HttpServletResponse object </li></ul></li><li>out <ul><li>send output  to the client </li></ul></li><li>session <ul><li>HttpSession object associated with the request </li></ul></li><li>application <ul><li>The servletContext object associated with the application context </li></ul></li><li>config <ul><li>servletConfig object associated with the page </li></ul></li><li>pageContext<ul><li>This encapsulates use of server-specific features like higher performance JspWriters.</li></ul></li><li>page<ul><li>This is simply a synonym for this, and is used to call the methods defined by the translated servlet class.</li></ul></li><li>exception <ul><li>The Exception object allows the exception data to be accessed by designated JSP. </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JSP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JMX - Tutorials</title>
      <link href="/JMX-Tutorials/"/>
      <url>/JMX-Tutorials/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><ul><li>JMX - Java Management extensions<ul><li>export standard metrics and custom metrics using MBeans to a monitoring system </li><li>understand how your application is performing <ul><li>memory </li><li>cpu</li><li>threads </li><li>API calls in a REST endpoint</li></ul></li></ul></li></ul><h1 id="2-Why-need-this"><a href="#2-Why-need-this" class="headerlink" title="2. Why need this?"></a>2. Why need this?</h1><ul><li>Large scale java applications <ul><li>gather performance information <ul><li>number of users connected </li></ul></li></ul></li><li>could provide a monitoring interface </li><li>any class that exports data to JMX is called a Managed Bean(MBean). These MBeans publish their metrics to a MBean Server provided by the Java platform. </li></ul><h1 id="3-Components"><a href="#3-Components" class="headerlink" title="3. Components"></a>3. Components</h1><h2 id="3-1-MBean"><a href="#3-1-MBean" class="headerlink" title="3.1 MBean"></a>3.1 MBean</h2><ul><li>Objects with methods that return information and export the information via the MBeanServer</li><li>Mainly have 4 types <ul><li>Standard MBean <ul><li>create an interface with getter  </li></ul></li><li>Dynamic MBean <ul><li>implements getters and setters to retrieve or modify the metric that can be auto discovered by implementing the javax.management.DynamicMBean interface </li></ul></li><li>Model MBean<ul><li>Generic, dynamic in runtime to instrument the resources  </li></ul></li><li>Open MBean<ul><li>Using a predefined set of java classes</li></ul></li></ul></li></ul><h1 id="4-Example"><a href="#4-Example" class="headerlink" title="4. Example"></a>4. Example</h1><pre><code>// Create an interface that the MBeanServer will retrieve information public interface SystemStatusMBean {   Integer getNumberOfSecondsRunning();   String getProgramName();   Long getNumberOfUnixSecondsRunning();   Boolean getSwitchStatus();}</code></pre><p>Actual Implementation </p><pre><code>    public class SystemStatus implements SystemStatusMBean {   private Integer numberOfSecondsRunning;   private String programName;   private Long numberOfUnixSecondsRunning;   private Boolean switchStatus;   private Thread backgroundThread;   public SystemStatus(String programName) {       // First we initialize all the metrics       this.backgroundThread = new Thread();       this.programName = programName;       this.numberOfSecondsRunning = 0;       this.numberOfUnixSecondsRunning = System.currentTimeMillis() / 1000L;       this.switchStatus = false;       // We will use a background thread to update the metrics       this.backgroundThread = new Thread(() -&gt; {           try {               while (true) {                   // Every second we update the metrics                   numberOfSecondsRunning += 1;                   numberOfUnixSecondsRunning += 1;                   switchStatus = !switchStatus;                   Thread.sleep(1000L);               }           } catch (Exception e) {               e.printStackTrace();           }       });       this.backgroundThread.setName(&quot;backgroundThread&quot;);       this.backgroundThread.start();   }</code></pre><h1 id="5-Operations-and-attributes"><a href="#5-Operations-and-attributes" class="headerlink" title="5. Operations and attributes"></a>5. Operations and attributes</h1><p>Class properties exported through MBeans are called attributes, and methods exported through MBeans are called operations.</p><ul><li>TotalCompilationTime <ul><li>Total time spent doing in JIT compilation  </li></ul></li><li>Garbage Collector - CollectionCount <ul><li>Number of garbage collection events fired since the JVM launch</li></ul></li><li>Garbage Collector - CollectionTime </li><li>FreePyhsicalMemorySize </li><li>CommitedVirtualMemorySize<ul><li>The amount of memory that is guaranteed to be available for use by JVM  </li></ul></li><li>ProcessCpuTime <ul><li>Time CPU has spent running the process  </li></ul></li><li>PeakThreadCount <ul><li>maximum number of threads being executed at the same time since the JVM was started or the peak was reset  </li></ul></li><li>ThreadCount <ul><li>the number of threads running at the current moment </li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://sysdig.com/blog/jmx-monitoring-custom-metrics/" target="_blank" rel="noopener">https://sysdig.com/blog/jmx-monitoring-custom-metrics/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> JMX </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java是如何工作的</title>
      <link href="/Java%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84/"/>
      <url>/Java%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84/</url>
      
        <content type="html"><![CDATA[<h1 id="1-编程语言是如何工作的"><a href="#1-编程语言是如何工作的" class="headerlink" title="1. 编程语言是如何工作的"></a>1. 编程语言是如何工作的</h1><p>我们可以把编程语言按照与底层实现的接近程度来划分层次，更加高层次的编程语言会让我们写起来更像自然语言一些，比如Java, C++。而低层次的语言，更贴近机器语言，即在描述底层是如何实现的。</p><p>对于大部分编程语言来说，工作的整个过程是从编译 - 链接 - 执行。就是从源代码开始，编译器会运行源代码，将其转化为贴近机器语言的状态，我们将其称为<code>Object</code> 文件。一系列的<code>Object</code>文件可以被链接起来，并创建一个可执行文件。操作系统可以加载这个可执行文件到内存中，并运行程序。</p><p>还有一部分语言是解释性的，比如Lisp, Schema。他会针对每一个高层次的语句来做低层次的翻译，然后顺序执行他们。这个过程相当于我遇到一个语句，翻译成计算机能看懂的语言以后，再看下一句…</p><h1 id="2-Java是如何工作的"><a href="#2-Java是如何工作的" class="headerlink" title="2. Java是如何工作的"></a>2. Java是如何工作的</h1><p>Java是个平台独立的语言，那他是怎么做到的呢？</p><p>首先我们要理解一下什么叫做平台独立？</p><blockquote><p>对于很多编程语言来说，编译器会生成可以在特定计算机上执行的代码。比如你在windows机器上编译一段c++代码，那么生成的可执行文件可以在任何其他的windows电脑上运行，但无法在Mac或者Linux机器上运行。</p></blockquote><p>对于早期的语言来说，设计者需要针对每一个平台专门设计一个编译器。而作为一个程序员，如果你想自己的代码在多个平台上都可以工作，你也需要针对性的做很多修改。</p><p>Java重新组织了编译-链接-执行这个循环，它将和平台相关的代码给抽象出来，和其他代码分开。这样子，编译的时候不会生成一个Object文件，反之，会生成字节码文件，这个字节码文件是平台独立的，即它可以在任何平台运行。那么刚才说的和平台相关的代码放到哪里了呢？为了执行字节码，我们需要唤醒java解释器。每个平台都会有自己的解释器，来解决和平台相关的问题。</p><p>对于其他语言来说，执行的过程是 编译，链接然后执行。对于Java来说，更应该说是编译然后链接，执行。</p><h1 id="3-Compile-vs-Runtime"><a href="#3-Compile-vs-Runtime" class="headerlink" title="3. Compile vs Runtime"></a>3. Compile vs Runtime</h1><p>整个代码的lifecycle,程序员先写源码，通过源码定义了程序是比如和工作的。这些源码必须要编译成机器码(java里面等效为字节码)，然后变成可执行文件。这个编译的过程称之为compile time.</p><p>一个编译过的文件是可以打开并且运行的，当一个应用正在运行的时候，我们就叫他处在runtime当中。</p><p>compile error一般是在编译的过程中由编译器报的错，告诉我们哪一行出了什么问题。运行时候的错误就叫做runtime error，这往往是一些逻辑错误，系统崩溃，流量过大等原因造成的。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="http://www.cs.cmu.edu/~jcarroll/15-100-s05/supps/basics/history.html" target="_blank" rel="noopener">CMU Class Notes</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java Unit Test - Junit5</title>
      <link href="/Java-Unit-Test-Junit5/"/>
      <url>/Java-Unit-Test-Junit5/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Writing-Tests"><a href="#1-Writing-Tests" class="headerlink" title="1. Writing Tests"></a>1. Writing Tests</h1><p>JUnit5 = Junit Platform + Junit Jupiter + Junit Vintage </p><p>First test cases: </p><pre><code>import static org.junit.jupiter.api.Assertions.assertEquals;import example.util.Calculator;import org.junit.jupiter.api.Test;class MyFirstJUnitJupiterTests {    private final Calculator calculator = new Calculator();    @Test    void addition() {        assertEquals(2, calculator.add(1, 1));    }}</code></pre><h2 id="1-1-Annotations"><a href="#1-1-Annotations" class="headerlink" title="1.1 Annotations"></a>1.1 Annotations</h2><ul><li>@Test <ul><li>Denotes that a method is a test method. This annotation does not declare any attributes</li></ul></li><li>@ParameterizedTest <ul><li>Denote a method is a parameterized test </li><li>Make it possible to run a test multiple times with different arguments </li><li>Must declare at least one source that will provide the arguments for each invocation and then consume the arguments in teh test method </li></ul></li><li>@RepeatedTest <ul><li>denotes a method is a test template for a repeated test </li><li>Provides ability to repeat a test a specific number of times by annotating a method with <code>@RepeatedTest</code> and specify the total number of repetitions desired. </li></ul></li><li>@TestFactory <ul><li>denotes a method is a test factory for dynamic tests</li><li>dynamic test generated at runtime by a factory method that is annotated with @TestFactory </li><li>a factory for test case </li></ul></li><li>@TestTemplate<ul><li>denotes that a method is a template for test cases designed to be invoked multiple times depending on the number of invocation contexts returned by the registered providers. </li></ul></li><li>@TestMethodOrder <ul><li>Configure the test method execution order </li></ul></li><li>@TestInstance<ul><li>Used to configure the test instance lifecycle for the annotated test class.  </li></ul></li><li>@DisplayName<ul><li>Declares a custom display name for the test class or test method.</li></ul></li><li>@BeforeEach<ul><li>Denotes that the annotated method should be executed before each @Test, @RepeatedTest, @ParameterizedTest, or @TestFactory method in the current class; analogous to JUnit 4’s @Before. </li></ul></li><li>@AfterEach <ul><li>Denotes that the annotated method should be executed after each @Test, @RepeatedTest, @ParameterizedTest, or @TestFactory method in the current class; analogous to JUnit 4’s @After</li></ul></li><li>@BeforeAll <ul><li>Denotes that the annotated method should be executed before all @Test, @RepeatedTest, @ParameterizedTest, and @TestFactory methods in the current class; analogous to JUnit 4’s @BeforeClass. Such methods are inherited (unless they are hidden or overridden) and must be static (unless the “per-class” test instance lifecycle is used).</li></ul></li><li>@AfterAll <ul><li>Denotes that the annotated method should be executed after all @Test, @RepeatedTest, @ParameterizedTest, and @TestFactory methods in the current class; analogous to JUnit 4’s @AfterClass. Such methods are inherited (unless they are hidden or overridden) and must be static</li></ul></li><li>@Nested <ul><li>Denotes that the annotated class is a non-static nested test class. @BeforeAll and @AfterAll methods cannot be used directly in a @Nested test class unless the “per-class” test instance lifecycle is used.</li></ul></li><li>@Tag<ul><li>Used to declare tags for filtering tests, either at the class or method level; analogous to test groups in TestNG or Categories in JUnit 4. Such annotations are inherited at the class level but not at the method level.</li></ul></li><li>@Disabled <ul><li>Used to disable a test class or test method; analogous to JUnit 4’s @Ignore. Such annotations are not inherited.</li></ul></li><li>@ExtendWith<ul><li>Used to register extensions declaratively </li></ul></li><li>@RegisterExtension<ul><li>Used to register extensions programmatically via fields.</li></ul></li><li>@TempDir<ul><li>Used to supply a temporary directory via field injection or parameter injection in a lifecycle method or test method </li></ul></li></ul><h2 id="1-2-Test-classes-and-methods"><a href="#1-2-Test-classes-and-methods" class="headerlink" title="1.2 Test classes and methods"></a>1.2 Test classes and methods</h2><ul><li>Test classes must not be abstract and mush have a single constructor</li><li>Test method: any instance method that is directly annotated or meta-annotated with @Test, @RepeatedTest, @ParameterizedTest, @TestFactory, or @TestTemplate</li><li>Lifecycle Method: any method that is directly annotated or meta-annotated with @BeforeAll, @AfterAll, @BeforeEach, or @AfterEach</li></ul><p>A standard unit test class: </p><pre><code>import static org.junit.jupiter.api.Assertions.fail;import static org.junit.jupiter.api.Assumptions.assumeTrue;import org.junit.jupiter.api.AfterAll;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.BeforeAll;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.Disabled;import org.junit.jupiter.api.Test;class StandardTests {    @BeforeAll    static void initAll() {    }    @BeforeEach    void init() {    }    @Test    void succeedingTest() {    }    @Test    void failingTest() {        fail(&quot;a failing test&quot;);    }    @Test    @Disabled(&quot;for demonstration purposes&quot;)    void skippedTest() {        // not executed    }    @Test    void abortedTest() {        assumeTrue(&quot;abc&quot;.contains(&quot;Z&quot;));        fail(&quot;test should have been aborted&quot;);    }    @AfterEach    void tearDown() {    }    @AfterAll    static void tearDownAll() {    }}</code></pre><h2 id="1-3-Assertions"><a href="#1-3-Assertions" class="headerlink" title="1.3 Assertions"></a>1.3 Assertions</h2><p>All assertions are static methods in org.junit.jupiter.api.Assertions class.</p><p>See <a href="https://junit.org/junit5/docs/current/api/org/junit/jupiter/api/Assertions.html" target="_blank" rel="noopener">API doc</a> for detail: </p><ul><li>assertAll()</li><li>assertArrayEquals()</li><li>assertArrauEqualsString()</li><li>assertEquals()</li><li>assertNotEquals()</li><li>assertTimeout()</li><li>assertTimeoutPreemptively()</li><li>assertTure()</li><li>fail()</li></ul><pre><code>@Test    void dependentAssertions() {        // Within a code block, if an assertion fails the        // subsequent code in the same block will be skipped.        assertAll(&quot;properties&quot;,            () -&gt; {                String firstName = person.getFirstName();                assertNotNull(firstName);                // Executed only if the previous assertion is valid.                assertAll(&quot;first name&quot;,                    () -&gt; assertTrue(firstName.startsWith(&quot;J&quot;)),                    () -&gt; assertTrue(firstName.endsWith(&quot;e&quot;))                );            },            () -&gt; {                // Grouped assertion, so processed independently                // of results of first name assertions.                String lastName = person.getLastName();                assertNotNull(lastName);                // Executed only if the previous assertion is valid.                assertAll(&quot;last name&quot;,                    () -&gt; assertTrue(lastName.startsWith(&quot;D&quot;)),                    () -&gt; assertTrue(lastName.endsWith(&quot;e&quot;))                );            }        );    }</code></pre><h2 id="1-4-Assumptions"><a href="#1-4-Assumptions" class="headerlink" title="1.4 Assumptions"></a>1.4 Assumptions</h2><p>Assumptions is a collection of utility methods that support conditional test execution based on assumptions.In direct contrast to failed assertions, failed assumptions do not result in a test failure; rather, a failed assumption results in a <strong>test being aborted</strong>.</p><ul><li><p>assumeFalse()</p></li><li><p>assumeTrue()</p></li><li><p>assumingThat(boolean assumption, Executable executable)</p><p>   @Test</p><pre><code>  void testOnlyOnDeveloperWorkstation() {      assumeTrue(&quot;DEV&quot;.equals(System.getenv(&quot;ENV&quot;)),          () -&gt; &quot;Aborting test: not on developer workstation&quot;);      // remainder of test  }  @Test  void testInAllEnvironments() {      assumingThat(&quot;CI&quot;.equals(System.getenv(&quot;ENV&quot;)),          () -&gt; {              // perform these assertions only on the CI server              assertEquals(2, calculator.divide(4, 2));          });      // perform these assertions in all environments      assertEquals(42, calculator.multiply(6, 7));  }</code></pre></li></ul><h2 id="1-5-Test-Instance-Lifecycle"><a href="#1-5-Test-Instance-Lifecycle" class="headerlink" title="1.5 Test Instance Lifecycle"></a>1.5 Test Instance Lifecycle</h2><p>In order to allow individual test methods to be executed in isolation and to avoid unexpected side effects due to mutable test instance state, <strong>JUnit creates a new instance of each test class before executing each test method</strong></p><p>You can annotate your test class with <code>@TestInstance(Lifecycle.PER_CLASS)</code> if you <strong>prefer to execute all test methods on the same test instance</strong>. And if your test mothods rely on state stored in instance variables, may need to reset the state in @BeforeEach or @AfterEach methods. </p><p>The “per-class” mode has some additional benefits over the default “per-method” mode. Specifically, with the “per-class” mode it becomes possible to declare @BeforeAll and @AfterAll on non-static methods as well as on interface default methods. The “per-class” mode therefore also makes it possible to use @BeforeAll and @AfterAll methods in @Nested test classes.</p><pre><code>@TestInstance(Lifecycle.PER_CLASS)interface TestLifecycleLogger {    static final Logger logger = Logger.getLogger(TestLifecycleLogger.class.getName());    @BeforeAll    default void beforeAllTests() {        logger.info(&quot;Before all tests&quot;);    }    @AfterAll    default void afterAllTests() {        logger.info(&quot;After all tests&quot;);    }    @BeforeEach    default void beforeEachTest(TestInfo testInfo) {        logger.info(() -&gt; String.format(&quot;About to execute [%s]&quot;,            testInfo.getDisplayName()));    }    @AfterEach    default void afterEachTest(TestInfo testInfo) {        logger.info(() -&gt; String.format(&quot;Finished executing [%s]&quot;,            testInfo.getDisplayName()));    }}</code></pre><h2 id="1-6-Repeated-Test"><a href="#1-6-Repeated-Test" class="headerlink" title="1.6 Repeated Test"></a>1.6 Repeated Test</h2><pre><code>import static org.junit.jupiter.api.Assertions.assertEquals;import java.util.logging.Logger;import org.junit.jupiter.api.BeforeEach;import org.junit.jupiter.api.DisplayName;import org.junit.jupiter.api.RepeatedTest;import org.junit.jupiter.api.RepetitionInfo;import org.junit.jupiter.api.TestInfo;class RepeatedTestsDemo {    private Logger logger = // ...    @BeforeEach    void beforeEach(TestInfo testInfo, RepetitionInfo repetitionInfo) {        int currentRepetition = repetitionInfo.getCurrentRepetition();        int totalRepetitions = repetitionInfo.getTotalRepetitions();        String methodName = testInfo.getTestMethod().get().getName();        logger.info(String.format(&quot;About to execute repetition %d of %d for %s&quot;, //            currentRepetition, totalRepetitions, methodName));    }    @RepeatedTest(10)    void repeatedTest() {        // ...    }    @RepeatedTest(5)    void repeatedTestWithRepetitionInfo(RepetitionInfo repetitionInfo) {        assertEquals(5, repetitionInfo.getTotalRepetitions());    }    @RepeatedTest(value = 1, name = &quot;{displayName} {currentRepetition}/{totalRepetitions}&quot;)    @DisplayName(&quot;Repeat!&quot;)    void customDisplayName(TestInfo testInfo) {        assertEquals(&quot;Repeat! 1/1&quot;, testInfo.getDisplayName());    }    @RepeatedTest(value = 1, name = RepeatedTest.LONG_DISPLAY_NAME)    @DisplayName(&quot;Details...&quot;)    void customDisplayNameWithLongPattern(TestInfo testInfo) {        assertEquals(&quot;Details... :: repetition 1 of 1&quot;, testInfo.getDisplayName());    }    @RepeatedTest(value = 5, name = &quot;Wiederholung {currentRepetition} von {totalRepetitions}&quot;)    void repeatedTestInGerman() {        // ...    }}</code></pre><h2 id="1-7-Parameterized-Tests"><a href="#1-7-Parameterized-Tests" class="headerlink" title="1.7 Parameterized Tests"></a>1.7 Parameterized Tests</h2><p>With parameterized, we could run a test multiple times with different arguments. And we must declare at least one source that will provide the arguments for each invocation and then consume the arguments in the test method. </p><pre><code>@ParameterizedTest@ValueSource(strings = { &quot;racecar&quot;, &quot;radar&quot;, &quot;able was I ere I saw elba&quot; })void palindromes(String candidate) {    assertTrue(StringUtils.isPalindrome(candidate));}</code></pre><h3 id="1-7-1-Annotations-used-in-parameterized-tests"><a href="#1-7-1-Annotations-used-in-parameterized-tests" class="headerlink" title="1.7.1 Annotations used in parameterized tests"></a>1.7.1 Annotations used in parameterized tests</h3><ul><li>@ValueSource<ul><li>specify a single array of literal values </li></ul></li><li>@NullSource<ul><li>provides a single null argument to the annotated @ParameterizedTest method.</li></ul></li><li>@EmptySource<ul><li>provides a single empty argument to the annotated @ParameterizedTest method for parameters of the following types: java.lang.String, java.util.List, java.util.Set, java.util.Map, primitive arrays (e.g., int[], char[][], etc.), object arrays (e.g.,String[], Integer[][], etc.).</li></ul></li><li>@NullAndEmptySource: <ul><li>a composed annotation that combines the functionality of @NullSource and @EmptySource.</li></ul></li></ul><pre><code>@ParameterizedTest@NullAndEmptySource@ValueSource(strings = { &quot; &quot;, &quot;   &quot;, &quot;\t&quot;, &quot;\n&quot; })void nullEmptyAndBlankStrings(String text) {    assertTrue(text == null || text.trim().isEmpty());}</code></pre><ul><li>@EnumSource<ul><li>provides a convenient way to use Enum constants. </li><li>also provides an optional names parameter that lets you specify which constants shall be used </li></ul></li></ul><pre><code>@ParameterizedTest@EnumSource(value = TimeUnit.class, names = { &quot;DAYS&quot;, &quot;HOURS&quot; })void testWithEnumSourceInclude(TimeUnit timeUnit) {    assertTrue(EnumSet.of(TimeUnit.DAYS, TimeUnit.HOURS).contains(timeUnit));}@ParameterizedTest@EnumSource(value = TimeUnit.class, mode = EXCLUDE, names = { &quot;DAYS&quot;, &quot;HOURS&quot; })void testWithEnumSourceExclude(TimeUnit timeUnit) {    assertFalse(EnumSet.of(TimeUnit.DAYS, TimeUnit.HOURS).contains(timeUnit));    assertTrue(timeUnit.name().length() &gt; 5);}</code></pre><ul><li>@MethodSource<ul><li>Allow you to refer to one or more factory methods of the test class or external classes </li><li>Each factory method must generate a stream of arguments</li></ul></li></ul><pre><code>@ParameterizedTest@MethodSource(&quot;stringProvider&quot;)void testWithExplicitLocalMethodSource(String argument) {    assertNotNull(argument);}static Stream&lt;String&gt; stringProvider() {    return Stream.of(&quot;apple&quot;, &quot;banana&quot;);}</code></pre><ul><li>@CsvSource </li><li>@CsvFileSource</li><li>@ArgumentsSource <ul><li>can be used to specify a custom resuable ArgumentsProvider </li><li>An implementation of ArgumentsProvider mush be declared as either a top-level class or as a static nested class. </li></ul></li></ul><pre><code>@ParameterizedTest@ArgumentsSource(MyArgumentsProvider.class)void testWithArgumentsSource(String argument) {    assertNotNull(argument);}public class MyArgumentsProvider implements ArgumentsProvider {    @Override    public Stream&lt;? extends Arguments&gt; provideArguments(ExtensionContext context) {        return Stream.of(&quot;apple&quot;, &quot;banana&quot;).map(Arguments::of);    }}</code></pre><h3 id="1-7-2-Lifecycle-and-Interoperability"><a href="#1-7-2-Lifecycle-and-Interoperability" class="headerlink" title="1.7.2 Lifecycle and Interoperability"></a>1.7.2 Lifecycle and Interoperability</h3><p>Each invocation of a parameterized test has the same lifecycle </p><h2 id="1-8-Test-Templates"><a href="#1-8-Test-Templates" class="headerlink" title="1.8 Test Templates"></a>1.8 Test Templates</h2><p>A @TestTemplate method is not a regular test case but rather a template for test cases. It is designed to be invoked multiple times depending on the number of invocation contexts returned by the registerd providers. </p><p>Thus, it must be used in conjunction with a registered TestTemplateInvocationContextProvider extension. Each invocation of a test template method behaves like the execution of a regular @Test method with full support for the same lifecycle callbacks and extensions.</p><h2 id="1-9-Dynamic-Tests"><a href="#1-9-Dynamic-Tests" class="headerlink" title="1.9 Dynamic Tests"></a>1.9 Dynamic Tests</h2><p> @Test describe methods that implement test cases. These test cases are static in the sense that they are fully specified at compile time, and their behavior cannot be changed by anything happening at runtime.</p><p> This new kind of test is a dynamic test which is generated at runtime by a factory method that is annotated with @TestFactory</p><p> In contrast to @Test methods, a @TestFactory method is not itself a test case but rather a factory for test cases. Thus, a dynamic test is the product of a factory. Technically speaking, a @TestFactory method must return a single DynamicNode or a Stream, Collection, Iterable, Iterator, or array of DynamicNode instances. Instantiable subclasses of DynamicNode are DynamicContainer and </p><p> DynamicContainer instances are composed of <strong>a display name</strong> and <strong>a list of dynamic child nodes</strong>, enabling the creation of arbitrarily nested hierarchies of dynamic nodes. DynamicTest instances will be executed lazily, enabling dynamic and even non-deterministic generation of test cases.</p><h3 id="1-9-1-Dynamic-test-lifecycle"><a href="#1-9-1-Dynamic-test-lifecycle" class="headerlink" title="1.9.1 Dynamic test lifecycle"></a>1.9.1 Dynamic test lifecycle</h3><p>The execution lifecycle of a dynamic test is quite different than it is for a standard @Test case. Specifically, there are <strong>no lifecycle callbacks for individual dynamic tests</strong>. This means that @BeforeEach and @AfterEach methods and their corresponding extension callbacks are** executed for the @TestFactory method** but not for each dynamic test. In other words, if you access fields from the test instance within a lambda expression for a dynamic test, those fields will not be reset by callback methods or extensions between the execution of individual dynamic tests generated by the same @TestFactory method.</p><h2 id="1-10-Parallel-Execution"><a href="#1-10-Parallel-Execution" class="headerlink" title="1.10 Parallel Execution"></a>1.10 Parallel Execution</h2><h3 id="1-10-1-Mode"><a href="#1-10-1-Mode" class="headerlink" title="1.10.1 Mode"></a>1.10.1 Mode</h3><p>Offers two mode: </p><ul><li>SAME_THREAD<ul><li>Force execution in the same thread used by the parent. For example, when used on a test method, the test method will be executed in the same thread as any @BeforeAll or @AfterAll methods of the containing test class. </li></ul></li><li>CONCURRENT<ul><li>Execute concurrently unless a resource lock forces execution in the same thread.</li></ul></li></ul><p>Alternatively, you can use the @Execution annotation to change the execution mode for the annotated element and its subelements (if any) which allows you to activate parallel execution for individual test classes, one by one.</p><h3 id="1-10-2-Synchronization"><a href="#1-10-2-Synchronization" class="headerlink" title="1.10.2 Synchronization"></a>1.10.2 Synchronization</h3><p>The @ResourceLock annotation allows you to declare that a test class or method uses a specific shared resource that requires synchronized access to ensure reliable test execution. </p><pre><code>@Execution(CONCURRENT)class SharedResourcesDemo {    private Properties backup;    @BeforeEach    void backup() {        backup = new Properties();        backup.putAll(System.getProperties());    }    @AfterEach    void restore() {        System.setProperties(backup);    }    @Test    @ResourceLock(value = SYSTEM_PROPERTIES, mode = READ)    void customPropertyIsNotSetByDefault() {        assertNull(System.getProperty(&quot;my.prop&quot;));    }    @Test    @ResourceLock(value = SYSTEM_PROPERTIES, mode = READ_WRITE)    void canSetCustomPropertyToApple() {        System.setProperty(&quot;my.prop&quot;, &quot;apple&quot;);        assertEquals(&quot;apple&quot;, System.getProperty(&quot;my.prop&quot;));    }    @Test    @ResourceLock(value = SYSTEM_PROPERTIES, mode = READ_WRITE)    void canSetCustomPropertyToBanana() {        System.setProperty(&quot;my.prop&quot;, &quot;banana&quot;);        assertEquals(&quot;banana&quot;, System.getProperty(&quot;my.prop&quot;));    }}</code></pre><h1 id="2-Extension-Model"><a href="#2-Extension-Model" class="headerlink" title="2. Extension Model"></a>2. Extension Model</h1><p>In contrast to Runner, TestRule and MethodRule extension points in JUnit4, the JUnit Jupiter extension model consists of a single, coherent concept – Extension API. </p><h2 id="2-1-Registering-Extensions"><a href="#2-1-Registering-Extensions" class="headerlink" title="2.1 Registering Extensions"></a>2.1 Registering Extensions</h2><p>Extensions can be registered declaraticely via @ExtendWith, programmatically via @RegisterExtension, or automatically via Java’s ServiceLoader mechanism. </p><h3 id="2-1-1-Declarative-Extension-Registration"><a href="#2-1-1-Declarative-Extension-Registration" class="headerlink" title="2.1.1 Declarative Extension Registration"></a>2.1.1 Declarative Extension Registration</h3><pre><code>@ExtendWith(RandomParametersExtension.class)@Testvoid test(@Random int i) {    // ...}</code></pre><p>Notice: we could annotate it in class level to register an extension for all tests in this specific class. </p><p>We can also register multiple extensions: </p><pre><code>@ExtendWith({ DatabaseExtension.class, WebServerExtension.class })class MyFirstTests {    // ...}</code></pre><h3 id="2-1-2-Programmatic-Extension-Registration"><a href="#2-1-2-Programmatic-Extension-Registration" class="headerlink" title="2.1.2 Programmatic Extension Registration"></a>2.1.2 Programmatic Extension Registration</h3><p>Register extensions programmatically by annotating fields in test classes with @RegisterExtension </p><p>When an extension is registered declaratively via @ExtendWith, it can typically only be configured via annotations. In contrast, when an extension is registered via @RegisterExtension, it can be <strong>configured programmatically</strong> - for example, in order to pass arguments to the extension’s constructor, a static factory method, or a builder API.</p><p>If a @RegisterExtension field is static, the extension will be registered after extensions that are registered at the class level via @ExtendWith. Such static extensions are not limited in which extension APIs they can implement. Extensions registered via static fields may therefore implement class-level and instance-level extension APIs such as BeforeAllCallback, AfterAllCallback, and TestInstancePostProcessor as well as method-level extension APIs such as BeforeEachCallback, etc.</p><pre><code>class WebServerDemo {    @RegisterExtension    static WebServerExtension server = WebServerExtension.builder()        .enableSecurity(false)        .build();    @Test    void getProductList() {        WebClient webClient = new WebClient();        String serverUrl = server.getServerUrl();        // Use WebClient to connect to web server using serverUrl and verify response        assertEquals(200, webClient.get(serverUrl + &quot;/products&quot;).getResponseStatus());    }}</code></pre><ul><li><p>For a non-static field with @RegisterExtension, it will be registered after the test class has been instantiated </p></li><li><p>By default, an instance extension will be registered after extensions that are registered at the method level via @ExtendWith </p></li><li><p>If the class is configured with @TestInstance(Lifecycle.PER_CLASS) semantics, an instance extension will be registered at the method level via @ExtendWith.</p><p>  class DocumentationDemo {</p><pre><code>  static Path lookUpDocsDir() {      // return path to docs dir  }  // The configured DocumentationExtension will be automatically registered as an extension at the method level.  @RegisterExtension  DocumentationExtension docs = DocumentationExtension.forPath(lookUpDocsDir());  @Test  void generateDocumentation() {      // use this.docs ...  }</code></pre><p>  }</p></li></ul><h3 id="2-1-3-Automatic-Extension-Registration"><a href="#2-1-3-Automatic-Extension-Registration" class="headerlink" title="2.1.3 Automatic Extension Registration"></a>2.1.3 Automatic Extension Registration</h3><p>JUnit Jupiter also supports global extension registration via Java’s java.util.ServiceLoader mechanism, allowing third-party extensions to be *<em>auto-detected and automatically registered *</em>based on what is available in the classpath.</p><h2 id="2-2-Conditional-Test-Execution"><a href="#2-2-Conditional-Test-Execution" class="headerlink" title="2.2 Conditional Test Execution"></a>2.2 Conditional Test Execution</h2><p>Used to define conditional test execution. </p><p>An ExecutionCondition is evaluated for each container (e.g., a test class) to determine if all the tests it contains should be executed based on the supplied ExtensionContext</p><h2 id="2-3-Execution-Order-of-User-Code-and-Extensions"><a href="#2-3-Execution-Order-of-User-Code-and-Extensions" class="headerlink" title="2.3 Execution Order of User Code and Extensions"></a>2.3 Execution Order of User Code and Extensions</h2><p>When executing a test class that contains one or more test methods, a number of extension callbacks are called in addition to the user-supplied test and lifecycle methods.</p><p><img src="https://i.loli.net/2020/02/09/9OkZPCtrFL8RfYM.png" alt="fig1.png"></p><p>JUnit Jupiter always guarantees wrapping behavior for multiple registered extensions that implement lifecycle callbacks such as BeforeAllCallback, AfterAllCallback, BeforeEachCallback, AfterEachCallback, BeforeTestExecutionCallback, and AfterTestExecutionCallback.</p><p>That means that, given two extensions Extension1 and Extension2 with Extension1 registered before Extension2, <strong>any “before” callbacks implemented by Extension1 are guaranteed to execute before any “before” callbacks implemented by Extension2</strong>.</p><pre><code>import static example.callbacks.Logger.afterAllMethod;import static example.callbacks.Logger.afterEachMethod;import static example.callbacks.Logger.beforeAllMethod;import static example.callbacks.Logger.beforeEachMethod;import org.junit.jupiter.api.AfterAll;import org.junit.jupiter.api.AfterEach;import org.junit.jupiter.api.BeforeAll;import org.junit.jupiter.api.BeforeEach;/** * Abstract base class for tests that use the database. */abstract class AbstractDatabaseTests {    @BeforeAll    static void createDatabase() {        beforeAllMethod(AbstractDatabaseTests.class.getSimpleName() + &quot;.createDatabase()&quot;);    }    @BeforeEach    void connectToDatabase() {        beforeEachMethod(AbstractDatabaseTests.class.getSimpleName() + &quot;.connectToDatabase()&quot;);    }    @AfterEach    void disconnectFromDatabase() {        afterEachMethod(AbstractDatabaseTests.class.getSimpleName() + &quot;.disconnectFromDatabase()&quot;);    }    @AfterAll    static void destroyDatabase() {        afterAllMethod(AbstractDatabaseTests.class.getSimpleName() + &quot;.destroyDatabase()&quot;);    }}</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://junit.org/junit5/docs/current/user-guide/" target="_blank" rel="noopener">https://junit.org/junit5/docs/current/user-guide/</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Unit Test </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java日志管理 - slf4j + log4j - 探究Distribute system 的threadContext复用的问题</title>
      <link href="/Java%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86-slf4j-log4j-%E6%8E%A2%E7%A9%B6Distribute-system-%E7%9A%84threadContext%E5%A4%8D%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/Java%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86-slf4j-log4j-%E6%8E%A2%E7%A9%B6Distribute-system-%E7%9A%84threadContext%E5%A4%8D%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-常用日志系统介绍"><a href="#1-常用日志系统介绍" class="headerlink" title="1. 常用日志系统介绍"></a>1. 常用日志系统介绍</h1><ul><li>日志门面<ul><li>jcl - jakarta common logging  <ul><li>日志接口，支持运行时动态加载日志组件的实现 </li></ul></li><li>slf4j<ul><li>日志接口</li><li>在log层和代码层之间起到门面作用，对于用户来说只要使用SLF4J的接口，就可以隐藏日志的具体实现，其提供的核心API是一些接口和一个LoggerFactory的工厂类，用户只需要按照其提供的日志接口进行使用，最终日志的格式，记录级别，输出方式等都可以通过具体日志系统的配置来实现</li></ul></li></ul></li><li>日志框架<ul><li>jul - java.util.logging </li><li>log4j</li><li>log4j2</li><li>logback<ul><li>slf4j的实现 </li><li>是log4j的升级版</li></ul></li></ul></li></ul><h1 id="2-日志级别"><a href="#2-日志级别" class="headerlink" title="2. 日志级别"></a>2. 日志级别</h1><ul><li>severe</li><li>warning </li><li>info</li><li>config</li><li>fine </li><li>finer </li></ul><h1 id="3-常见使用方式"><a href="#3-常见使用方式" class="headerlink" title="3. 常见使用方式"></a>3. 常见使用方式</h1><p>一般工程上会选择一个日志门面，加日志框架，常用的门面基本上还是SLF4J比较多，框架的选择很多，主要是需要注意工程上分布式系统的多线程方面的支持。</p><h1 id="4-Log4j2-ThreadContext复用的问题"><a href="#4-Log4j2-ThreadContext复用的问题" class="headerlink" title="4. Log4j2 ThreadContext复用的问题"></a>4. Log4j2 ThreadContext复用的问题</h1><p>ThreadContext出现的背景主要是因为现代系统基本上都需要都是和多个client打交道，在一个典型的多线程的应用系统当中，不同的线程就需要和不同的client打交道.为了能够分辨出同一个client发出的不同log请求，我们就需要给每个请求一个id，来做标记。</p><p>Log4j2使用Thread Context Map和Thread Context Stack来进行标记。常用Map，因为键值对更容易进行添加和处理</p><p>使用Stack: </p><pre><code>ThreadContext.push(UUID.randomUUID().toString()); // Add the fishtag;logger.debug(&quot;Message 1&quot;);...logger.debug(&quot;Message 2&quot;);..ThreadContext.pop();</code></pre><p>使用Map: </p><pre><code>ThreadContext.put(&quot;id&quot;, UUID.randomUUID().toString()); // Add the fishtag;ThreadContext.put(&quot;ipAddress&quot;, request.getRemoteAddr());ThreadContext.put(&quot;loginId&quot;, session.getAttribute(&quot;loginId&quot;));ThreadContext.put(&quot;hostName&quot;, request.getServerName());.logger.debug(&quot;Message 1&quot;);..logger.debug(&quot;Message 2&quot;);..ThreadContext.clear();</code></pre><p>问题来了，如果我们使用Executor.execute(new CachedThreadPool())的话，因为线程的复用，（所有使用完的线程会归还到线程池当中），那么ThreadContext里面的东西必须要进行手动清除，才能防止原先记录的这个线程的东西被复用掉。比如一般会记录的[Client][API]此类信息。</p><p>这个时候需要使用getContext()和cloneStack()来使得子线程获得父线程的信息。</p><pre><code>ThreadContext.clearAll();ThreadContext.putAll(preSavedThreadContextMap);ThreadContext.setStack(preSavedThreadContextStack);</code></pre>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java基础知识</title>
      <link href="/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
      <url>/Java%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<p>给自己搭个脚手架，建个基础知识的小字典，查遗用(持续更新)：</p><h1 id="1-Java平台"><a href="#1-Java平台" class="headerlink" title="1.Java平台"></a>1.Java平台</h1><h2 id="1-1-Java解释执行？"><a href="#1-1-Java解释执行？" class="headerlink" title="1.1 Java解释执行？"></a>1.1 Java解释执行？</h2><p>Java源代码，通过javac编译成字节码，运行时通过JVM内嵌的解释器将字节码转换为机器码。但是大部分JVM都提供了JIT(just in time),即动态编译器，它能够在运行时将热点代码编成机器码，这种情况下热点代码就属于编译执行。</p><h2 id="1-2-Java类加载机制"><a href="#1-2-Java类加载机制" class="headerlink" title="1.2 Java类加载机制"></a>1.2 Java类加载机制</h2><p>类加载大致过程：加载-验证-链接-初始化</p><h2 id="1-3-Java反射机制"><a href="#1-3-Java反射机制" class="headerlink" title="1.3 Java反射机制"></a>1.3 Java反射机制</h2><h2 id="1-4-面向对象编程SOLID原则"><a href="#1-4-面向对象编程SOLID原则" class="headerlink" title="1.4 面向对象编程SOLID原则"></a>1.4 面向对象编程SOLID原则</h2><ol><li>Single Responsibility </li><li>Open for extension, close for modification </li><li>Liskov Substitution </li><li>Interface Segragation </li><li>Dependency Injection </li></ol><p>E.G</p><pre><code>public class VIPCenter {  void serviceVIP(T extend User user&gt;) {     if (user instanceof SlumDogVIP) {        // 穷 X VIP，活动抢的那种        // do somthing      } else if(user instanceof RealVIP) {        // do somthing      }      // ...  }</code></pre><p>增加其扩展性：</p><pre><code>public class VIPCenter {   private Map&lt;User.TYPE, ServiceProvider&gt; providers;   void serviceVIP(T extend User user） {      providers.get(user.getType()).service(user);   } } interface ServiceProvider{   void service(T extend User user) ; } class SlumDogVIPServiceProvider implements ServiceProvider{   void service(T extend User user){     // do somthing   } } class RealVIPServiceProvider implements ServiceProvider{   void service(T extend User user) {     // do something   } } </code></pre><p>在另一篇博文里，有对SOLID的详细描述，详情见<a href="https://www.llchen60.com/2018/11/12/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/">面向对象设计原则</a></p><h2 id="1-5-类加载过程"><a href="#1-5-类加载过程" class="headerlink" title="1.5 类加载过程"></a>1.5 类加载过程</h2><p>load-link-initialize</p><ul><li>load </li></ul><p>首先是加载阶段（Loading），它是 Java 将字节码数据从不同的数据源读取到 JVM 中，并映射为 JVM 认可的数据结构（Class 对象），这里的数据源可能是各种各样的形态，如 jar 文件、class 文件，甚至是网络数据源等；如果输入数据不是 ClassFile 的结构，则会抛出 ClassFormatError。</p><ul><li>link </li></ul><p>第二阶段是链接（Linking），这是核心的步骤，简单说是把原始的类定义信息平滑地转化入 JVM 运行的过程中。这里可进一步细分为三个步骤：</p><ol><li>验证， JVM需要验证字节信息是符合Java虚拟机规范的，否则会被认为是Verify Error</li><li>准备 创建类或接口中的静态变量，并初始化静态变量的初始值，侧重点在分配所需要的内存空间，不会去执行更进一步的JVM指令</li><li>解析。将常量池中的符号引用替换为直接引用。</li></ol><p>再来谈谈双亲委派模型，简单说就是当类加载器（Class-Loader）试图加载某个类型的时候，除非父加载器找不到相应类型，否则尽量将这个任务代理给当前加载器的父加载器去做。使用委派模型的目的是避免重复加载 Java 类型。</p><h1 id="2-Java语言特性"><a href="#2-Java语言特性" class="headerlink" title="2. Java语言特性"></a>2. Java语言特性</h1><h2 id="2-1-泛型"><a href="#2-1-泛型" class="headerlink" title="2.1 泛型"></a>2.1 泛型</h2><h2 id="2-2-Lambda"><a href="#2-2-Lambda" class="headerlink" title="2.2 Lambda"></a>2.2 Lambda</h2><h2 id="2-3-Exception-Error"><a href="#2-3-Exception-Error" class="headerlink" title="2.3 Exception/ Error"></a>2.3 Exception/ Error</h2><h3 id="2-3-1-定义"><a href="#2-3-1-定义" class="headerlink" title="2.3.1 定义"></a>2.3.1 定义</h3><blockquote><p>Exception: 程序正常运行中可以预料到的意外情况，可能并且应该被捕获，进行相应处理</p></blockquote><blockquote><p>Error: 在正常情况下，不应该出现的情况。绝大部分的Error都会导致程序比如JVM自身处于非正常的、不可恢复的状态</p></blockquote><p>Throwable分类图！！！！！</p><p>异常之所以很强大，在调试方面，在于其回答了以下三个问题：</p><ol><li>什么出了错？    异常类型</li><li>在哪出了错？    异常堆栈跟踪位置</li><li>为什么出错？    异常信息</li></ol><h3 id="2-3-2-Tips"><a href="#2-3-2-Tips" class="headerlink" title="2.3.2 Tips"></a>2.3.2 Tips</h3><ol><li>不捕获通用异常，写自己的Exception，方便Debug</li><li>不要生吞异常，不知道怎么处理了可以继续向外层抛出</li><li>提早抛出，延迟捕获！ </li><li>把异常处理的责任往调用链的上游传递的方法就是在方法的throws子句声明异常。<a href="https://www.zhihu.com/question/28254987" target="_blank" rel="noopener">(如何优雅的处理异常？)</a></li></ol><h3 id="2-3-3-性能角度分析"><a href="#2-3-3-性能角度分析" class="headerlink" title="2.3.3 性能角度分析"></a>2.3.3 性能角度分析</h3><ol><li>try-catch代码段会产生额外的性能开销，往往会影响JVM对代码进行优化，因此应该仅捕获有必要的代码，尽量不要使用一个大的try包住整段代码</li><li>Java每实例化一个Exception，都会对<strong>当时的栈进行快照</strong>，这是个比较重的操作。</li></ol><h2 id="2-4-引用"><a href="#2-4-引用" class="headerlink" title="2.4 引用"></a>2.4 引用</h2><p>Java中除了原始数据类型的变量其他所有都是引用类型，指向不同的对象。理解引用，以理解Java对象的生命周期和JVM内部的相关机制。</p><p>不同的引用类型，主要体现在对象的不同的可达性状态和对垃圾收集的影响。</p><h3 id="2-4-1-强引用"><a href="#2-4-1-强引用" class="headerlink" title="2.4.1 强引用"></a>2.4.1 强引用</h3><p>Strong Reference, 即普通对象引用。只要还有强引用指向一个对象，那么垃圾收集器就不会碰。</p><h3 id="2-4-2-弱引用"><a href="#2-4-2-弱引用" class="headerlink" title="2.4.2 弱引用"></a>2.4.2 弱引用</h3><p>不能使对象豁免垃圾收集，提供一种访问在弱引用装天下对象的途径</p><p>使用weak reference类来实现的</p><h3 id="2-4-3-软引用"><a href="#2-4-3-软引用" class="headerlink" title="2.4.3 软引用"></a>2.4.3 软引用</h3><p>Soft Reference. 相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当JVM认为内存不足时，才会去试图回收软引用指向的对象。</p><p>使用soft reference类实现的</p><h3 id="2-4-4-幻象引用"><a href="#2-4-4-幻象引用" class="headerlink" title="2.4.4 幻象引用"></a>2.4.4 幻象引用</h3><p>虚引用，提供一种确保对象被finalize以后，做某些事情的机制。</p><p>通过PhantomReference类来实现的</p><h2 id="2-5-String-vs-StringBuffer-vs-StringBuilder"><a href="#2-5-String-vs-StringBuffer-vs-StringBuilder" class="headerlink" title="2.5 String vs. StringBuffer vs. StringBuilder"></a>2.5 String vs. StringBuffer vs. StringBuilder</h2><ul><li><p>字符串缓存，放在对重，后来放在metaSpace当中，可以通过JVM调参来修改大小</p><p>  -XX:+PrintStringTableStatistics<br>  -XX:StringTableSize=N</p></li><li><p>String 压缩</p></li></ul><p>从使用Char到使用Byte + 标志编码位。紧凑字符串带来了很大优势，更小的内存占用，更快的操作速度。</p><h3 id="2-5-1-String"><a href="#2-5-1-String" class="headerlink" title="2.5.1 String"></a>2.5.1 String</h3><p>Immutable类，声明为final class,所有属性也都是final的。</p><p>java引入了字符创常量池，创建一个字符串，首先看常量池里面有没有值相同的字符串，如果有直接到池里拿对应的对象引用，如果没有就创建新的，并放到池里去。</p><pre><code>String str1 = &quot;123&quot;;// 放入常量池String str2 = new String(&quot;123&quot;); // 不放入常量池</code></pre><h3 id="2-5-2-StringBuffer"><a href="#2-5-2-StringBuffer" class="headerlink" title="2.5.2 StringBuffer"></a>2.5.2 StringBuffer</h3><p>为了解决String拼接产生太多中间对象的问题，本质上是一个线程安全的可修改字符序列。保证了线程安全，但是也带来了额外的性能开销。</p><p>线程安全是通过在各种修改数据的方法上加<code>synchronized</code>关键字来实现的。</p><p>底层使用char/ byte数组，继承了AbstractStringBuilder</p><h3 id="2-5-3-StringBuilder"><a href="#2-5-3-StringBuilder" class="headerlink" title="2.5.3 StringBuilder"></a>2.5.3 StringBuilder</h3><p>与StringBuffer类似，去掉了线程安全的部分，有效减少了开销</p><p>底层使用char/ byte数组，继承了AbstractStringBuilder。</p><h2 id="2-6-Abstract-and-Interface"><a href="#2-6-Abstract-and-Interface" class="headerlink" title="2.6 Abstract and Interface"></a>2.6 Abstract and Interface</h2><h3 id="2-6-1-接口"><a href="#2-6-1-接口" class="headerlink" title="2.6.1 接口"></a>2.6.1 接口</h3><p>接口是对行为的抽象，是抽象方法的集合，利用接口可以达到API定义和实现分离的目的。接口不能实例化，不能包含任何非常量成员，任何field都是隐含着public static final的意义的。同时，没有非静态方法的实现。要么是静态方法，要么是抽象方法。</p><p>接口可以多继承！类只可以单继承</p><h3 id="2-6-2-抽象类"><a href="#2-6-2-抽象类" class="headerlink" title="2.6.2 抽象类"></a>2.6.2 抽象类</h3><p>不能实例化的类，用abstract关键字来修饰，其目的主要是代码重用。抽象类大多用于抽取相关Java类的公用方法实现或者是共同成员变量，然后通过继承达到代码复用的目的。Java标准库中，比如Collection框架，很多通用部分就抽象成了抽象类来使用。</p><h1 id="3-Java基础类库"><a href="#3-Java基础类库" class="headerlink" title="3. Java基础类库"></a>3. Java基础类库</h1><h2 id="3-1-集合"><a href="#3-1-集合" class="headerlink" title="3.1 集合"></a>3.1 集合</h2><h3 id="3-1-1-Vector-vs-ArrayList-vs-LinkedList"><a href="#3-1-1-Vector-vs-ArrayList-vs-LinkedList" class="headerlink" title="3.1.1 Vector vs. ArrayList vs.LinkedList"></a>3.1.1 Vector vs. ArrayList vs.LinkedList</h3><p>三者都是集合框架中的List，根据位置有定位，添加或者删除的操作。Vector是Java早期提供的线程安全的动态数组。ArrayList动态数组，不是线程安全的，ArrayList扩容时会增加50%。LinkedList双向链表，不是线程安全的。</p><p>Vector, arrayList作为动态数组，非常适合随机访问的场合，插入删除元素性能会比较差，因为要移动后续的所有元素。LinkedList进行节点插入，删除会很高效，但是随机访问性能很差。</p><h3 id="3-1-2-Hashtable-vs-HashMap-vs-TreeMap"><a href="#3-1-2-Hashtable-vs-HashMap-vs-TreeMap" class="headerlink" title="3.1.2 Hashtable vs. HashMap vs. TreeMap"></a>3.1.2 Hashtable vs. HashMap vs. TreeMap</h3><p>Hashtable是同步的，性能开销大</p><p>HashMap 非同步的，性能开销小，put，get操作能达到常数时间的性能</p><p>TreeMap是基于红黑树的一种提供顺序访问的Map，和Hashmap不同，它的get\put\remove之类的操作都是O(log(n))的时间复杂度。</p><h2 id="3-2-IO-NIO"><a href="#3-2-IO-NIO" class="headerlink" title="3.2 IO/NIO"></a>3.2 IO/NIO</h2><h3 id="3-2-1-IO"><a href="#3-2-1-IO" class="headerlink" title="3.2.1 IO"></a>3.2.1 IO</h3><p>java.io包，基于流模型实现，提供了我们最熟知的一些IO功能，比如File抽象、输入输出流等。交互方式是同步、阻塞的方式。也就是说，在读取输入流或者写入输出流时，在读写动作之前，线程会一直阻塞在那里，他们之间的调用是可靠的线性顺序。</p><h3 id="3-2-2-NIO"><a href="#3-2-2-NIO" class="headerlink" title="3.2.2 NIO"></a>3.2.2 NIO</h3><p>NIO框架，提供Channel, selector, Buffer等新的抽象，可以构建<strong>多路复用，同步非阻塞IO程序</strong>，同时提供了更接近操作系统底层的高性能数据操作方式。</p><ul><li>Channel </li><li>Buffer</li><li>Selector </li></ul><h2 id="3-3-网络"><a href="#3-3-网络" class="headerlink" title="3.3 网络"></a>3.3 网络</h2><h2 id="3-4-并发"><a href="#3-4-并发" class="headerlink" title="3.4 并发"></a>3.4 并发</h2><h3 id="3-4-1-synchronized"><a href="#3-4-1-synchronized" class="headerlink" title="3.4.1 synchronized"></a>3.4.1 synchronized</h3><ul><li>概念</li></ul><p>是java内部的同步机制，也称为intrinsic locking, 提供了互斥的语义和可见性，当一个线程已经获取当前锁时，其他试图获取的线程只能等待或者阻塞在那里了。</p><p>在 Java 5 以前，synchronized 是仅有的同步手段，在代码中， synchronized 可以用来修饰方法，也可以使用在特定的代码块儿上，本质上** synchronized 方法等同于把方法全部语句用 synchronized 块包起来**。</p><ul><li>底层实现</li></ul><p>synchronized代码块是由一对<code>monitorenter/ moniterexit</code>指令来实现的，Monitor对象是同步的基本实现单元。</p><p>在 Java 6 之前，Monitor 的实现完全是依靠操作系统内部的互斥锁，因为需要进行用户态到内核态的切换，所以同步操作是一个无差别的重量级操作。现代的（Oracle）JDK 中，JVM 对此进行了大刀阔斧地改进，提供了三种不同的 Monitor 实现，也就是常说的三种不同的锁：偏斜锁（Biased Locking）、轻量级锁和重量级锁，大大改进了其性能。</p><p>所谓锁的升级、降级，就是 JVM 优化 synchronized 运行的机制，当 JVM 检测到不同的竞争状况时，会自动切换到适合的锁实现，这种切换就是锁的升级、降级。</p><p>没有竞争的时候，默认使用偏斜锁。JVM会利用CAS操作，在对象头上的Mark Word部分设置线程ID，以表示这个对象偏向于当前线程，所以并不涉及真正的互斥锁。如果有另外的线程试图锁定某个已经被偏斜过的对象，JVM就需要撤销偏斜锁，并切换到轻量锁的实现。</p><h3 id="3-4-2-ReeantrantLock"><a href="#3-4-2-ReeantrantLock" class="headerlink" title="3.4.2 ReeantrantLock"></a>3.4.2 ReeantrantLock</h3><ul><li>ReentrantLock 再入锁</li></ul><p>再入锁通过代码直接调用lock()方法来获取，是表示当一个线程试图获取一个它已经获取的锁时，这个获取动作就自动成功。这是多锁获取粒度上的一个区分，锁的持有是以线程为单位而不是基于调用次数了，java锁实现强调再入性是为了和pthread的行为进行区分。</p><p>再入锁可以设置公平性：</p><pre><code>ReentrantLock fairLock = new ReetrantLock(true);</code></pre><p>这里所谓的公平性是指在竞争场景中，当公平性为真时，会倾向于将锁赋予等待时间最久的线程。公平性是减少线程“饥饿”（个别线程长期等待锁，但始终无法获取）情况发生的一个办法。</p><p>使用synchronized我们无法进行公平性的选择，其永远是不公平的，这也是主流操作系统线程调度的选择。通用场景中，公平性未必有想象中的那么重要，Java 默认的调度策略很少会导致 “饥饿”发生。与此同时，若要保证公平性则会引入额外开销，自然会导致一定的吞吐量下降。</p><h3 id="3-4-3-死锁"><a href="#3-4-3-死锁" class="headerlink" title="3.4.3 死锁"></a>3.4.3 死锁</h3><h2 id="3-5-安全"><a href="#3-5-安全" class="headerlink" title="3.5 安全"></a>3.5 安全</h2><h1 id="4-JVM基础概念和机制"><a href="#4-JVM基础概念和机制" class="headerlink" title="4. JVM基础概念和机制"></a>4. JVM基础概念和机制</h1><h2 id="4-1-类加载机制"><a href="#4-1-类加载机制" class="headerlink" title="4.1 类加载机制"></a>4.1 类加载机制</h2><h2 id="4-2-常见的垃圾收集器"><a href="#4-2-常见的垃圾收集器" class="headerlink" title="4.2 常见的垃圾收集器"></a>4.2 常见的垃圾收集器</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.zhihu.com/question/28254987" target="_blank" rel="noopener">如何优雅的处理异常？</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Javadoc tutorial</title>
      <link href="/Javadoc-tutorial/"/>
      <url>/Javadoc-tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="1-What-is-javadoc"><a href="#1-What-is-javadoc" class="headerlink" title="1. What is javadoc"></a>1. What is javadoc</h1><p>A tool comes with JDK and used for generating Java code documentation in <strong>HTML format from Java source code</strong>, which requires documentation in a predefined format </p><h1 id="2-Javadoc-tags"><a href="#2-Javadoc-tags" class="headerlink" title="2. Javadoc tags"></a>2. Javadoc tags</h1><ul><li>@author</li><li>{@code}<ul><li>Displays text in code font without interpreting the text as HTML markup or nested javadoc tags.</li></ul></li><li>{@docRoot}<ul><li>Represents the relative path to the generated document’s root directory from any generated page.</li></ul></li><li>@deprecated</li><li>@exception<ul><li>Adds a Throws subheading to the generated documentation, with the classname and description text.</li></ul></li><li>{@inheritDoc}<ul><li>Inherits a comment from the nearest inheritable class or implementable interface.</li></ul></li><li>{@link}<ul><li>Inserts an in-line link with the visible text label that points to the documentation for the specified package, class, or member name of a referenced class. </li></ul></li><li>@param</li><li>@return</li><li>@see</li><li>@serial</li><li>@serialData <ul><li>Documents the data written by the writeObject( ) or writeExternal( ) methods.</li></ul></li><li>@serialField<ul><li>Documents an ObjectStreamField component.</li></ul></li><li>@since <ul><li>Adds a since heading with the specified since text to the generated documentation</li></ul></li><li>@throws </li><li>{@value}<ul><li>When {@value} is used in the doc comment of a static field, it displays the value of that constant. </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 继承与组合</title>
      <link href="/Java-%E7%BB%A7%E6%89%BF%E4%B8%8E%E7%BB%84%E5%90%88/"/>
      <url>/Java-%E7%BB%A7%E6%89%BF%E4%B8%8E%E7%BB%84%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是组合？"><a href="#1-什么是组合？" class="headerlink" title="1. 什么是组合？"></a>1. 什么是组合？</h1><p>组合将类定义为各个部分的集合</p><pre><code>public class MerchantListHelper {    // TODO     void addToDDB (ListEntry entry) {    }    void removeFromDDB(DDBRecord record) {    }    List&lt;ListEntry&gt; getFromDDB() {    }}public class MerchantBlacklistBizLogic {    private MerchantListHelper merchantListHelper;    merchantListHelper.addToDDB(blabla..);    merchantListHelper.removeFromDDB(blabla..)}</code></pre><h1 id="2-什么是继承？"><a href="#2-什么是继承？" class="headerlink" title="2. 什么是继承？"></a>2. 什么是继承？</h1><p>将父类和子类通过集成关系紧密联系在一起 （紧耦合）。但与之相对的是继承会允许再利用类的方法以及其他的属性，会很便捷。</p><p>使用super()方法来直接访问父类的方法，构造器，属性等。</p><pre><code>public Abstract class MerchantListHelper {    // TODO     abstract void addToDDB (ListEntry entry);    abstract void removeFromDDB(DDBRecord record);    abstract List&lt;ListEntry&gt; getFromDDB();}public class MerchantBlacklistBizLogic {    private MerchantListHelper merchantListHelper;    @Override    void addToDDB(ListEntry entry) {        // TODO    }    @Override    void removeFromDDB(DDBRecord record) {        // TODO    }    ...}</code></pre><h1 id="3-Use-cases"><a href="#3-Use-cases" class="headerlink" title="3. Use cases"></a>3. Use cases</h1><p>组合和继承都可以将子对象放到新的类当中，组合一般是当你想要在这个新类当中使用一个已经存在的类的特征的时候。这意味着，通过这种方式你可以嵌入一个对象，并将其放在新的类当中。 继承表示的是一种is-a的关系，组合表达的含有某种功能。</p><p>如何判断是否需要继承或者组合 -&gt; 看是否需要从你的新类到基本类进行向上转型。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="http://thedeanbear.com/2012/09/24/composition_vs_inheritance/" target="_blank" rel="noopener">http://thedeanbear.com/2012/09/24/composition_vs_inheritance/</a></li><li>Java Challengers #7: Debugging Java inheritance </li><li>javaworld.com/article/3409071/java-challenger-7-debugging-java-inheritance.html</li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Composition </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 反射机制</title>
      <link href="/Java-%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/"/>
      <url>/Java-%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>Java反射机制是在运行时用来判定或者修改方法，类，接口的行为的API。</p><ul><li><p>反射可以告诉我们类和对象之间的信息，以及我们可以用类的哪些方法来使用这个对象</p></li><li><p>通过反射，我们就可以在运行的时候赋予类一个新的对象</p></li><li><p>有用的连接</p><ul><li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/reflection/index.html" target="_blank" rel="noopener">Reflection API</a></li><li><a href="https://docs.oracle.com/javase/tutorial/reflect/index.html" target="_blank" rel="noopener">Reflection Tutorial</a></li><li><a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Class.html" target="_blank" rel="noopener">Class类的方法</a><h1 id="2-使用范例"><a href="#2-使用范例" class="headerlink" title="2. 使用范例"></a>2. 使用范例</h1>反射可以用来获取关于类，构造器和方法的信息：</li></ul></li><li><p>class: getClass()方法可以用来获取对象属于的类的名字</p></li><li><p>Constructors: getConstructor()可以用来获取对象属于的类的public的构造器</p></li><li><p>getMethods() 可以用来获取对象属于的类的public的方法</p><p>  // A simple Java program to demonstrate the use of reflection<br>  import java.lang.reflect.Method;<br>  import java.lang.reflect.Field;<br>  import java.lang.reflect.Constructor; </p><p>  // class whose object is to be created<br>  class Test<br>  { </p><pre><code>  // creating a private field   private String s;   // creating a public constructor   public Test() { s = &quot;GeeksforGeeks&quot;; }   // Creating a public method with no arguments   public void method1() {       System.out.println(&quot;The string is &quot; + s);   }   // Creating a public method with int as argument   public void method2(int n) {       System.out.println(&quot;The number is &quot; + n);   }   // creating a private method   private void method3() {       System.out.println(&quot;Private method invoked&quot;);   } </code></pre><p>  } </p><p>  class Demo<br>  { </p><pre><code>  public static void main(String args[]) throws Exception   {       // Creating object whose property is to be checked       Test obj = new Test();           // 构建类的对象      // getclass method       Class cls = obj.getClass();       System.out.println(&quot;The name of class is &quot; +                           cls.getName());       // Getting the constructor of the class through the       // object of the class       Constructor constructor = cls.getConstructor();       System.out.println(&quot;The name of constructor is &quot; +                           constructor.getName());       System.out.println(&quot;The public methods of class are : &quot;);       // Getting methods of the class through the object       // of the class by using getMethods       Method[] methods = cls.getMethods();       // Printing method names       for (Method method:methods)           System.out.println(method.getName());       // creates object of desired method by providing the       // method name and parameter class as arguments to       // the getDeclaredMethod        // 这里是通过方法的名字和输入变量来获取对应的方法      Method methodcall1 = cls.getDeclaredMethod(&quot;method2&quot;,                                               int.class);       // invokes the method at runtime       // 这里是在运行时执行这个方法       methodcall1.invoke(obj, 19);       // creates object of the desired field by providing       // the name of field as argument to the       // getDeclaredField method       // 运行时获取对应的private的变量      Field field = cls.getDeclaredField(&quot;s&quot;);       // allows the object to access the field irrespective       // of the access specifier used with the field       // 将这个变量设成可以获取的      field.setAccessible(true);       // takes object and the new value to be assigned       // to the field as arguments       field.set(obj, &quot;JAVA&quot;);       // Creates object of desired method by providing the       // method name as argument to the getDeclaredMethod       Method methodcall2 = cls.getDeclaredMethod(&quot;method1&quot;);       // invokes the method at runtime       methodcall2.invoke(obj);       // Creates object of the desired method by providing       // the name of method as argument to the       // getDeclaredMethod method       Method methodcall3 = cls.getDeclaredMethod(&quot;method3&quot;);       // allows the object to access the method irrespective       // of the access specifier used with the method       methodcall3.setAccessible(true);       // invokes the method at runtime       methodcall3.invoke(obj);   } </code></pre><p>  } </p></li></ul><h1 id="3-详细分析"><a href="#3-详细分析" class="headerlink" title="3. 详细分析"></a>3. 详细分析</h1><p>反射一言以蔽之，即在运行时拿到class，并创建类对应的对象的方式。这种好处是更具灵活性，劣势是会慢很多，代码会相对难理解些。</p><p>从代码本身的角度来讲，是指一部分代码有能力去观察/检查另一部分代码。用已知的部分合理推断出未知的部分，这未知的部分其实是指还不知道的信息。</p><p>一般来说在Java里我们都是和注解一起来使用反射的，</p><p>值得注意的一个点是反射是通过方法签名来确定方法的，<code>getClass().getDeclaredMethod(&quot;age&quot;, Integer.class).invoke(this, 36);</code> 方法签名指的是<code>getDeclaredMethod()</code></p><h1 id="4-优劣势"><a href="#4-优劣势" class="headerlink" title="4. 优劣势"></a>4. 优劣势</h1><ul><li>好处<ul><li>反射是什么呢？当我们的程序在运行时，需要动态的加载一些类这些类可能之前用不到所以不用加载到jvm，而是在运行时根据需要才加载，这样的好处对于服务器来说不言而喻，举个例子我们的项目底层有时是用mysql，有时用oracle，<strong>需要动态地根据实际情况加载驱动类，这个时候反射就有用了</strong>，假设 <code>com.java.dbtest.myqlConnection</code>，<code>com.java.dbtest.oracleConnection</code>这两个类我们要用，这时候我们的程序就写得比较动态化，通过<code>Class tc = Class.forName(&quot;com.java.dbtest.TestConnection&quot;);</code>通过类的全类名让jvm在服务器中找到并加载这个类，而如果是oracle则传入的参数就变成另一个了。这时候就可以看到反射的好处了，这个动态性就体现出java的特性了！</li><li>更具拓展性，可以在运行时获取信息</li><li>获取一些private的域的值方便debug</li></ul></li><li>劣势<ul><li>更慢，有延时</li><li>会暴露一些接口</li><li>反射会要求运行的许可，当在secure manager下来运行可能不被允许</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://stackoverflow.com/questions/37628/what-is-reflection-and-why-is-it-useful" target="_blank" rel="noopener">https://stackoverflow.com/questions/37628/what-is-reflection-and-why-is-it-useful</a></li><li><a href="https://docs.oracle.com/javase/tutorial/reflect/index.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/tutorial/reflect/index.html</a></li><li><a href="https://docs.oracle.com/javase/tutorial/reflect/class/index.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/tutorial/reflect/class/index.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Reflection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java - serialization</title>
      <link href="/java-serialization/"/>
      <url>/java-serialization/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>An object is eligible for serialization if and only if its class implements the <strong>java.io.Serializable</strong> interface. Serializable is a marker interface (contains no methods) that tell the Java Virtual Machine (JVM) that the objects of this class is ready for being written to and read from a persistent storage or over the network.</p><h1 id="2-Why-we-need-serialization"><a href="#2-Why-we-need-serialization" class="headerlink" title="2. Why we need serialization?"></a>2. Why we need serialization?</h1><p>It’s used when the need arises to send data/ object over network or stored in files.</p><p>The thing is network and hard disk are hardware component that understand bits and bytes but not Java Objects. </p><p>Serialization is the translation of your Java object’s values/states to bytes to send it over network or save it.</p><p>Also used to store into database. </p><h1 id="3-Implementation"><a href="#3-Implementation" class="headerlink" title="3. Implementation"></a>3. Implementation</h1><p>Ways for serialize/ deserialize  – xml JSON </p><p>Serialization process is instance independent. </p><ul><li>ObjectInputStream <ul><li>extends java.io.InputStream </li></ul></li></ul><pre><code>public final Object readObject() throws IOException, ClassNotFoundException;</code></pre><ul><li>ObjectOutputStream <ul><li>extends java.io.OutputStream</li></ul></li></ul><pre><code>public final void writeObject(Object o) throws IOException;</code></pre><h2 id="3-1-Example"><a href="#3-1-Example" class="headerlink" title="3.1 Example"></a>3.1 Example</h2><pre><code>public class Person implements Serializable {    private static final long serialVersionUID = 1L;    static String country = &quot;ITALY&quot;;    private int age;    private String name;    transient int height;    // getters and setters}@Testpublic void whenSerializingAndDeserializing_ThenObjectIsTheSame() ()   throws IOException, ClassNotFoundException {     Person person = new Person();    person.setAge(20);    person.setName(&quot;Joe&quot;);    FileOutputStream fileOutputStream      = new FileOutputStream(&quot;yourfile.txt&quot;);    ObjectOutputStream objectOutputStream       = new ObjectOutputStream(fileOutputStream);    objectOutputStream.writeObject(person);    objectOutputStream.flush();    objectOutputStream.close();    FileInputStream fileInputStream      = new FileInputStream(&quot;yourfile.txt&quot;);    ObjectInputStream objectInputStream      = new ObjectInputStream(fileInputStream);    Person p2 = (Person) objectInputStream.readObject();    objectInputStream.close();     assertTrue(p2.getAge() == p.getAge());    assertTrue(p2.getName().equals(p.getName()));}</code></pre><h1 id="4-Caveats"><a href="#4-Caveats" class="headerlink" title="4. Caveats"></a>4. Caveats</h1><ol><li>When a class implements the java.io.Serializable interface, all <strong>its sub-classes are serializable as well</strong>.</li><li>when an object has a reference to another object, these objects must implement the Serializable interface separately, or else a NotSerializableException will be thrown</li><li>JVM associates a version number with each serializable class. </li></ol><p>Reference</p><ol><li><a href="https://www.codejava.net/java-se/file-io/why-do-we-need-serialization-in-java" target="_blank" rel="noopener">https://www.codejava.net/java-se/file-io/why-do-we-need-serialization-in-java</a></li><li><a href="https://www.baeldung.com/java-serialization" target="_blank" rel="noopener">https://www.baeldung.com/java-serialization</a></li><li><a href="https://www.geeksforgeeks.org/serialization-in-java/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/serialization-in-java/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java Pattern Regex表达式</title>
      <link href="/Java-Pattern-Regex%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
      <url>/Java-Pattern-Regex%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-为什么要使用Pattern？"><a href="#1-为什么要使用Pattern？" class="headerlink" title="1. 为什么要使用Pattern？"></a>1. 为什么要使用Pattern？</h1><p>一般来说如果我们要对String做某个范式下的替换时，我们需要使用</p><pre><code>stringEG.replaceAll(&quot;(?i)@gmail\\.com$&quot;, &quot;&quot;);</code></pre><p>上面这行代码是将stringEG最后的@gmail.com给替换掉，通过这种方式来获得用户名。</p><p>这种Replace操作我们会经常使用，但是上述有一个问题，即每次运行都要执行一遍Regex操作，这样很费时间，每次都要进行编译，Pattern可以帮助我们解决这个问题。</p><p>通过设置static的变量，我们可以将Compile完的结果存起来，然后在需要的时候直接使用这个结果即可。</p><p>使用方法如下所示:</p><pre><code>private static final Pattern USER_NAME_PATTERN = Pattern.compile(&quot;(?i)@gmail\\.com$);final String username =  USER_NAME_PATTERN.matcher(stringEG.replace(&quot;&quot;));</code></pre><h1 id="2-如何使用Pattern？"><a href="#2-如何使用Pattern？" class="headerlink" title="2. 如何使用Pattern？"></a>2. 如何使用Pattern？</h1><p>使用Java Pattern，重点在于对于正则表达式的使用，可以看一下文章 - <a href="https://llchen60.com/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/" target="_blank" rel="noopener">正则表达式</a>, 里面有对正则的详细介绍。</p><p>Pattern对象是一个已经编译过的正则表达式的表达，Pattern类没有public的构造器，想要创建一个Pattern，我们需要首先调用其静态的compile()方法，通过这个方法会得到一个Pattern对象。</p><p>Matcher 对象用来解释正则表达式然后根据表达式来找符合规则的相关表达，同样没有public的构造器，通过调用matcher() 方法来作比较</p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Regex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java map() 与 flatMap()的比较</title>
      <link href="/Java-map-%E4%B8%8E-flatMap-%E7%9A%84%E6%AF%94%E8%BE%83/"/>
      <url>/Java-map-%E4%B8%8E-flatMap-%E7%9A%84%E6%AF%94%E8%BE%83/</url>
      
        <content type="html"><![CDATA[<p><code>map()</code>和<code>flatMap()</code>方法都来自于functional languages. 在Java8当中，我们可以在Optional, Stream还有CompletableFuture当中找到他们。</p><p>Stream代表一些列的对象，而Optional代表一个存在或者空的值。<code>map()</code>和<code>flatmap()</code>都是聚合方法，尽管其有着相同的返回类型，但是实际上他们有很多的不同。下面我们通过例子来逐一展现。</p><h1 id="1-在Optionals当中"><a href="#1-在Optionals当中" class="headerlink" title="1. 在Optionals当中"></a>1. 在Optionals当中</h1><pre><code>// map()Optional&lt;String&gt; s = Optional.of(&quot;Test&quot;);assertEquals(Optional.of(&quot;TEST&quot;), s.map(String::toUpperCase));// 如果情况更为复杂，变成Optional&lt;Optional&lt;String&gt;&gt;assertEquals(Optional.of(Optional.of(&quot;STRING&quot;)),     Optional.of(&quot;string&quot;).map(s -&gt; Optional.of(&quot;STRING&quot;)));// 同样的代码用flatmap来表示assertEquals(Optional.of(&quot;STRING&quot;), Optional.of(&quot;string&quot;).flatMap(s -&gt; Optional.of(&quot;STRING&quot;)));</code></pre><h1 id="2-在Streams当中"><a href="#2-在Streams当中" class="headerlink" title="2. 在Streams当中"></a>2. 在Streams当中</h1><p>map方法只能做一层的序列化，但是flatmap可以做多层的，来解决Stream&lt;Stream<R>&gt;的这种结构的问题。</p><pre><code>// 对于这种多层架构的, map()方法就显得力有未逮了List&lt;List&lt;String&gt;&gt; list = Arrays.asList(  Arrays.asList(&quot;a&quot;),  Arrays.asList(&quot;b&quot;));System.out.println(list);// flatmap可以很好的解决System.out.println(list.stream().flatMap(Collection::stream).collect(Collectors.toList()));</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.baeldung.com/java-difference-map-and-flatmap" target="_blank" rel="noopener">https://www.baeldung.com/java-difference-map-and-flatmap</a></li><li><a href="https://www.mkyong.com/java8/java-8-flatmap-example/" target="_blank" rel="noopener">https://www.mkyong.com/java8/java-8-flatmap-example/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Map </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java - ExecutorService</title>
      <link href="/Java-ExecutorService/"/>
      <url>/Java-ExecutorService/</url>
      
        <content type="html"><![CDATA[<p>ExecutorService is a framework provided by the JDK which simplifies the execution of tasks in <strong><em>asynchronous</em></strong> mode. ExecutorService automatically provides a pool of threads and API for assigning tasks to it. </p><h1 id="1-Instantiation"><a href="#1-Instantiation" class="headerlink" title="1. Instantiation"></a>1. Instantiation</h1><h2 id="1-1-Factory-methods-of-Executors-class"><a href="#1-1-Factory-methods-of-Executors-class" class="headerlink" title="1.1 Factory methods of Executors class"></a>1.1 Factory methods of Executors class</h2><p>Use its factory methods of the Executors class to create ExecutorService. </p><pre><code>ExecutorService executor = Executors.newFixedThreadPool(10);</code></pre><h2 id="1-2-Directly-create"><a href="#1-2-Directly-create" class="headerlink" title="1.2 Directly create"></a>1.2 Directly create</h2><pre><code>ExecutorService executorService =   new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS,     new LinkedBlockingQueue&lt;Runnable&gt;());</code></pre><h1 id="2-Assigning-Tasks"><a href="#2-Assigning-Tasks" class="headerlink" title="2. Assigning Tasks"></a>2. Assigning Tasks</h1><p>ExecutorService can execute Runnable and Callable tasks. </p><pre><code>Runnable runnableTask = () -&gt; {    try {        TimeUnit.MILLISECONDS.sleep(300);    } catch (InterruptedException e) {        e.printStackTrace();    }};Callable&lt;String&gt; callableTask = () -&gt; {    TimeUnit.MILLISECONDS.sleep(300);    return &quot;Task&#39;s execution&quot;;};List&lt;Callable&lt;String&gt;&gt; callableTasks = new ArrayList&lt;&gt;();callableTasks.add(callableTask);callableTasks.add(callableTask);callableTasks.add(callableTask);</code></pre><h2 id="2-1-execute"><a href="#2-1-execute" class="headerlink" title="2.1 execute()"></a>2.1 execute()</h2><p>The execute() method is void, and it doesn’t give any possibility to get the result of task’s execution or to check the task’s status (is it running or executed).</p><pre><code>executerService.execute(runnableTask);</code></pre><h2 id="2-2-submit"><a href="#2-2-submit" class="headerlink" title="2.2 submit()"></a>2.2 submit()</h2><p>submit() submits a Callable or a Runnable task to an ExecutorService and returns a result of type Future.</p><pre><code>Future&lt;String&gt; future = executorService.submit(callableTask);</code></pre><h2 id="2-3-invokeAny"><a href="#2-3-invokeAny" class="headerlink" title="2.3 invokeAny()"></a>2.3 invokeAny()</h2><p>invokeAny() assigns a collection of tasks to an ExecutorService, causing each to be executed, and returns the result of a successful execution of one task (if there was a successful execution).</p><pre><code>String result = executorService.invokeAny(callableTasks);</code></pre><h2 id="2-4-invokeAll"><a href="#2-4-invokeAll" class="headerlink" title="2.4 invokeAll()"></a>2.4 invokeAll()</h2><p>invokeAll() assigns a collection of tasks to an ExecutorService, causing each to be executed, and returns the result of all task executions in the form of a list of objects of type Future.</p><pre><code>List&lt;Future&lt;String&gt;&gt; futures = executorService.invokeAll(callableTasks);</code></pre><h1 id="3-Shutdown"><a href="#3-Shutdown" class="headerlink" title="3. Shutdown"></a>3. Shutdown</h1><p>In general, the ExecutorService will not be automatically destroyed when there is not task to process. It will stay alive and wait for new work to do.</p><p>In some cases this is very helpful; for example, if an app needs to process tasks which appear on an irregular basis or the quantity of these tasks is not known at compile time.</p><p>On the other hand, an app could reach its end, but it will not be stopped because a waiting ExecutorService will cause the JVM to keep running.</p><h2 id="3-1-shutdown"><a href="#3-1-shutdown" class="headerlink" title="3.1 shutdown()"></a>3.1 shutdown()</h2><p>The shutdown() method doesn’t cause an immediate destruction of the ExecutorService. It will make the ExecutorService stop accepting new tasks and shut down after all running threads finish their current work.</p><pre><code>executorService.shutdown();</code></pre><h2 id="3-2-shutdownNow"><a href="#3-2-shutdownNow" class="headerlink" title="3.2 shutdownNow()"></a>3.2 shutdownNow()</h2><p>The shutdownNow() method tries to destroy the ExecutorService immediately, but it doesn’t guarantee that all the running threads will be stopped at the same time. This method returns a list of tasks which are waiting to be processed. It is up to the developer to decide what to do with these tasks.</p><pre><code>List&lt;Runnable&gt; notExecutedTasks = executorService.shutDownNow();</code></pre><h2 id="3-3-best-behavior"><a href="#3-3-best-behavior" class="headerlink" title="3.3 best behavior"></a>3.3 best behavior</h2><pre><code>executorService.shutdown();try {    if (!executorService.awaitTermination(800, TimeUnit.MILLISECONDS)) {        executorService.shutdownNow();    } } catch (InterruptedException e) {    executorService.shutdownNow();}</code></pre><h1 id="4-Future-interface"><a href="#4-Future-interface" class="headerlink" title="4. Future interface"></a>4. Future interface</h1><p>Future interface provides a <code>get()</code> which returns an actual result of the Callable task’s execution or null in the case of Runnable task. Calling the get() method while the task is still running will cause execution to block until the task is properly executed and the result is available.</p><pre><code>Future&lt;String&gt; future = executorService.submit(callableTask);String result = null;try {    result = future.get();} catch (InterruptedException | ExecutionException e) {    e.printStackTrace();}</code></pre><p>With very long blocking caused by the get() method, an application’s performance can degrade. If the resulting data is not crucial, it is possible to avoid such a problem by using timeouts:</p><pre><code>String result = future.get(200, TimeUnit.MILLISECONDS);</code></pre><p>some other methods provided:</p><pre><code>cancel()isCancelled()isDone() </code></pre><h1 id="5-How-to-sync-the-value-across-different-threads"><a href="#5-How-to-sync-the-value-across-different-threads" class="headerlink" title="5. How to sync the value across different threads?"></a>5. How to sync the value across different threads?</h1><p>Suppose we have i++ in several threads, and they all perform such operations. To make the i computed properly, we need to make it atomic. </p><p>Use <code>AtomicInteger</code> or <code>synchronized</code> to get the final correct result. </p><p>Notice, <code>volatile</code> cannot make sure the final result is correct. It mainly makes sure the visibility of newest value, but there is possibility that we mound and switch to other thread before the new value being recorded. </p><p>AtomicInteger class uses CAS(Compare and swap) low level CPU operations. They allow you to modify a particular variable only if the present value is equal to something else (and is returned successfully).</p><h1 id="6-Executor-execute-and-ExecutorService-submit-differences"><a href="#6-Executor-execute-and-ExecutorService-submit-differences" class="headerlink" title="6. Executor.execute() and ExecutorService.submit() differences"></a>6. Executor.execute() and ExecutorService.submit() differences</h1><ol><li>execute(Runnable) does not return anything; while submit(Callable<T>) returns a Future object which allows a way to programatically cancel the running thread and get the return result. </li><li>submit() can accept both Runnable and Callable task but execute() can only accept the Runnable task</li><li>submit() return a Future object while execute() has no return</li><li>get() is a blocking call, which will take some time</li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Executor Service </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java - callback</title>
      <link href="/Java-callback/"/>
      <url>/Java-callback/</url>
      
        <content type="html"><![CDATA[<p>In C/ C++, callback refers to the mechanism of calling a function from another function. Memory address of a function is represented as function pointer here. SO the callback is achieved by passing the pointer of func1() to func2().</p><p>However, in java, there is no function pointer existing. And we use a callback object or a callback interface, and the interface is passed that refers to the location of a function. </p><p>Below is an example to compute tax by state tax and fedaral tax. Suppose federal tax keeps same while state tax vary by state. We can build interface and implements interface to realize it.<br>    // Java program to demonstrate callback mechanism<br>    // using interface is Java </p><pre><code>// Create interface import java.util.Scanner; interface STax {     double stateTax(); } // Implementation class of Punjab state tax class Punjab implements STax {     public double stateTax()     {         return 3000.0;     } } // Implementation class of Himachal Pardesh state tax class HP implements STax {     public double stateTax()     {         return 1000.0;     } } class TAX {     public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException     {         Scanner sc = new Scanner(System.in);         System.out.println(&quot;Enter the state name&quot;);         String state = sc.next(); // name of the state         // The state name is then stored in an object c         Class c = Class.forName(state);         // Create the new object of the class whose name is in c         // Stax interface reference is now referencing that new object         STax ref = (STax)c.newInstance();         /*Call the method to calculate total tax         and pass interface reference - this is callback .         Here, ref may refer to stateTax() of Punjab or HP classes         depending on the class for which the object is created         in the previous step         */        calculateTax(ref);     }     static void calculateTax(STax t)     {         // calculate central tax         double ct = 2000.0;         // calculate state tax         double st = t.stateTax();         double totaltax = st + ct;         // display total tax         System.out.println(&quot;Total tax =&quot; + totaltax);     } } </code></pre>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Callback </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java Annotations 注解详解</title>
      <link href="/Java-Annotations-%E6%B3%A8%E8%A7%A3%E8%AF%A6%E8%A7%A3/"/>
      <url>/Java-Annotations-%E6%B3%A8%E8%A7%A3%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>Java annotation很有用，这篇博客会带着大家去理解Annotation的语法以及用法，希望能有所裨益。</p><h1 id="1-Annotation架构"><a href="#1-Annotation架构" class="headerlink" title="1. Annotation架构"></a>1. Annotation架构</h1><h2 id="1-0-Annotation的介绍"><a href="#1-0-Annotation的介绍" class="headerlink" title="1.0 Annotation的介绍"></a>1.0 Annotation的介绍</h2><p>用一句话来解释Annotation的话，我想可以称其为Metadata(元数据) - 即数据的数据。</p><p>举个例子，比如这里我使用了@Override：</p><pre><code>@Overridepublic String toString() {return &quot;This is String Representation of current object.&quot;;}</code></pre><p>通过注解的方式，我告诉编译器我重写了这个toString()的方法。但其实就算我没有加这个注解，代码仍然是可以有效运行的，那么用注解的好处有哪些呢？为什么我们需要使用注解呢？？？ </p><p>上述的注解告诉编译器我重写了父类里面的一个方法，然后编译器会去父类检查看这个方法是否存在，如果不存在的话，那就会扔出一个编译错误。通过这种方式我们可以减少错误的发生，并且提高整个代码的可读性，给我们带来一些便利。</p><p>其实就像上面说的那样，注解是一种携带元数据的方式，我们实际上在注解之前是用XML来做元数据的存储的。二者各有自己的适用场景。对于XML来说，如果你写的应用有大量的常数，参量，用XML会更好，因为我们可以将这些常量和代码完全解耦，这样在改变常量值的时候会方便很多。如果你想对外暴露一些方法来做服务，那注解会是更好的选择。因为这种情形下元数据最好和方法紧密相连，让开发者意识到这个方法的一些特征。</p><p>另外注解提供了一个标准的在代码中定义元数据的方式，在注解之前工程师常会自己定义，比如注释，接口，等等。注解将这个过程做了标准化。</p><h2 id="1-1-Annotation-组成部分"><a href="#1-1-Annotation-组成部分" class="headerlink" title="1.1 Annotation 组成部分"></a>1.1 Annotation 组成部分</h2><p><img src="fig1.jpg" alt="fig1.jpg"></p><ul><li>Annotation<ul><li>1 RetentionPolicy 每一个注解对象都会有唯一的RetentionPolicy属性</li><li>1 - n ElementType  每个注解对象都可以有若干个ElementType属性</li><li>Annotation有多个实现类，包括<ul><li>Deprecated </li><li>Documented</li><li>Inherited </li><li>Override </li><li>Retention </li><li>Target </li></ul></li></ul></li></ul><p>第一个很重要的观念，就是<strong><em>注解只是元数据，它不包括任何真正的代码逻辑</em></strong>。</p><p>第二个很重要的观念，建立在第一个的基础之上，即如果注解不包括代码逻辑，那么就一定有针对注解的消费者，来读取注解提供的信息，并且执行对应的代码逻辑。</p><p>比如以@override为例，这里JVM就是这个注解的消费者，并且在字节码的水平利用注解信息。</p><h3 id="1-1-1-Annotation-java"><a href="#1-1-1-Annotation-java" class="headerlink" title="1.1.1 Annotation.java"></a>1.1.1 Annotation.java</h3><pre><code>package java.lang.annotation;public interface Annotation {    boolean equals(Object obj);    int hashCode();    String toString();    Class&lt;? extends Annotation&gt; annotationType();}</code></pre><p>一个接口</p><h3 id="1-1-2-ElementType-java"><a href="#1-1-2-ElementType-java" class="headerlink" title="1.1.2 ElementType.java"></a>1.1.2 ElementType.java</h3><pre><code>package java.lang.annotation;public enum ElementType {    TYPE,               /* 类、接口（包括注释类型）或枚举声明  */    FIELD,              /* 字段声明（包括枚举常量）  */    METHOD,             /* 方法声明  */    PARAMETER,          /* 参数声明  */    CONSTRUCTOR,        /* 构造方法声明  */    LOCAL_VARIABLE,     /* 局部变量声明  */    ANNOTATION_TYPE,    /* 注释类型声明  */    PACKAGE             /* 包声明  */}</code></pre><p>枚举类型，用来指定Annotation的类型。就是这个注解对象是用来修饰什么的，是方法，是变量，还是其他的各种…</p><h3 id="1-1-3-RetentionPolicy-java"><a href="#1-1-3-RetentionPolicy-java" class="headerlink" title="1.1.3 RetentionPolicy.java"></a>1.1.3 RetentionPolicy.java</h3><pre><code>package java.lang.annotation;public enum RetentionPolicy {    SOURCE,            /* Annotation信息仅存在于编译器处理期间，编译器处理完之后就没有该Annotation信息了  */    CLASS,             /* 编译器将Annotation存储于类对应的.class文件中。默认行为  */    RUNTIME            /* 编译器将Annotation存储于class文件中，并且可由JVM读入 */}</code></pre><p>RetentionPolicy是Enum枚举类型，每个都有其对应的行为。</p><p><strong>RetentionPolicy.SOURCE</strong> – Discard during the compile. These annotations don’t make any sense after the compile has completed, so they aren’t written to the bytecode. Examples @Override, @SuppressWarnings</p><p><strong>RetentionPolicy.CLASS</strong> – Discard during class load. Useful when doing bytecode-level post-processing. Somewhat surprisingly, this is the default.</p><p><strong>RetentionPolicy.RUNTIME</strong> – Do not discard. The annotation should be available for reflection at runtime. This is what we generally use for our custom annotations.</p><h2 id="1-2-通用定义"><a href="#1-2-通用定义" class="headerlink" title="1.2 通用定义"></a>1.2 通用定义</h2><pre><code>@Documented@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotation1 {}</code></pre><h3 id="1-2-1-interface"><a href="#1-2-1-interface" class="headerlink" title="1.2.1 @interface"></a>1.2.1 @interface</h3><p>意味着实现了java.lang.annotation.Annotation接口，即该注解就是一个Annotation。Annotation接口的实现细节都由编译器来完成的，通过@interface定义注解吼，该注解不能继承其他的注解或接口。</p><h3 id="1-2-2-Documented"><a href="#1-2-2-Documented" class="headerlink" title="1.2.2 @Documented"></a>1.2.2 @Documented</h3><p>类和方法的Annotation在缺省情况下是不出现在javadoc中的。如果使用@Documented修饰该Annotation，则表示它可以出现在javadoc中。</p><h3 id="1-2-3-Target-ElementType-TYPE"><a href="#1-2-3-Target-ElementType-TYPE" class="headerlink" title="1.2.3 @Target(ElementType.TYPE)"></a>1.2.3 @Target(ElementType.TYPE)</h3><p>ElementType是Annotation的类型属性，而@Target的作用，就是来指定类型属性的</p><p>有@Target，则该Annotation只能用于其所指定的地方；若没有，则该Annotation可以用于任何地方</p><h3 id="1-2-4-Retention-RetentionPolicy-RUNTIME"><a href="#1-2-4-Retention-RetentionPolicy-RUNTIME" class="headerlink" title="1.2.4 @Retention(RetentionPolicy.RUNTIME)"></a>1.2.4 @Retention(RetentionPolicy.RUNTIME)</h3><p>RetentionPolicy是Annotation的策略属性，</p><h2 id="1-3-常用Annotation"><a href="#1-3-常用Annotation" class="headerlink" title="1.3 常用Annotation"></a>1.3 常用Annotation</h2><h3 id="1-3-1-Deprecated"><a href="#1-3-1-Deprecated" class="headerlink" title="1.3.1 @Deprecated"></a>1.3.1 @Deprecated</h3><pre><code>@Documented@Retention(RetentionPolicy.RUNTIME)public @interface Deprecated {}</code></pre><ol><li>@interface – 它的用来修饰Deprecated，意味着Deprecated实现了java.lang.annotation.Annotation接口；即Deprecated就是一个注解。</li><li>@Documented – 它的作用是说明该注解能出现在javadoc中。</li><li>@Retention(RetentionPolicy.RUNTIME) – 它的作用是指定Deprecated的策略是RetentionPolicy.RUNTIME。这就意味着，编译器会将Deprecated的信息保留在.class文件中，并且能被虚拟机读取。</li><li>@Deprecated 所标注内容，不再被建议使用。<h3 id="1-3-2-Override"><a href="#1-3-2-Override" class="headerlink" title="1.3.2 @Override"></a>1.3.2 @Override</h3></li></ol><h3 id="1-3-3-Documented"><a href="#1-3-3-Documented" class="headerlink" title="1.3.3 @Documented"></a>1.3.3 @Documented</h3><h3 id="1-3-4-Inherited"><a href="#1-3-4-Inherited" class="headerlink" title="1.3.4 @Inherited"></a>1.3.4 @Inherited</h3><p>用来标注Annotation类型，所标注的Annotation具有继承性</p><pre><code>@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Inherited {}</code></pre><ol><li>@interface – 它的用来修饰Inherited，意味着Inherited实现了java.lang.annotation.Annotation接口；即Inherited就是一个注解。</li><li>@Documented – 它的作用是说明该注解能出现在javadoc中。</li><li>@Retention(RetentionPolicy.RUNTIME) – 它的作用是指定Inherited的策略是RetentionPolicy.RUNTIME。这就意味着，编译器会将Inherited的信息保留在.class文件中，并且能被虚拟机读取。</li><li>@Target(ElementType.ANNOTATION_TYPE) – 它的作用是指定Inherited的类型是ANNOTATION_TYPE。这就意味着，@Inherited只能被用来标注“Annotation类型”。</li></ol><h3 id="1-3-5-Retention"><a href="#1-3-5-Retention" class="headerlink" title="1.3.5 @Retention"></a>1.3.5 @Retention</h3><p>用来标注Annotation类型，用来指定RetentionPolicy属性</p><h3 id="1-3-6-Target"><a href="#1-3-6-Target" class="headerlink" title="1.3.6 @Target"></a>1.3.6 @Target</h3><p>@Target只能被用来标注“Annotation类型”，而且它被用来指定Annotation的ElementType属性。</p><h3 id="1-3-7-SuppressWarnings"><a href="#1-3-7-SuppressWarnings" class="headerlink" title="1.3.7 @SuppressWarnings"></a>1.3.7 @SuppressWarnings</h3><p>@SuppressWarnings 所标注内容产生的警告，编译器会对这些警告保持静默。</p><pre><code>@Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE})@Retention(RetentionPolicy.SOURCE)public @interface SuppressWarnings {    String[] value();}</code></pre><ol><li>@interface – 它的用来修饰SuppressWarnings，意味着SuppressWarnings实现了java.lang.annotation.Annotation接口；即SuppressWarnings就是一个注解。</li><li>@Retention(RetentionPolicy.SOURCE) – 它的作用是指定SuppressWarnings的策略是RetentionPolicy.SOURCE。这就意味着，SuppressWarnings信息仅存在于编译器处理期间，编译器处理完之后SuppressWarnings就没有作用了。</li><li>@Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) – 它的作用是指定SuppressWarnings的类型同时包括TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE。</li></ol><ul><li>TYPE意味着，它能标注“类、接口（包括注释类型）或枚举声明”。</li><li>FIELD意味着，它能标注“字段声明”。</li><li>METHOD意味着，它能标注“方法”。</li><li>PARAMETER意味着，它能标注“参数”。</li><li>CONSTRUCTOR意味着，它能标注“构造方法”。</li><li>LOCAL_VARIABLE意味着，它能标注“局部变量”。</li></ul><ol start="4"><li>String[] value(); 意味着，SuppressWarnings能指定参数</li><li>SuppressWarnings 的作用是，让编译器对“它所标注的内容”的某些警告保持静默。例如，”@SuppressWarnings(value={“deprecation”, “unchecked”})” 表示对“它所标注的内容”中的 “SuppressWarnings不再建议使用警告”和“未检查的转换时的警告”保持沉默。<h1 id="2-创建自己的Annotation"><a href="#2-创建自己的Annotation" class="headerlink" title="2. 创建自己的Annotation"></a>2. 创建自己的Annotation</h1></li></ol><p>注解只支持基本类型，String，还有Enum。所有的注解的属性都被定义为方法，default的值也会在方法里提供。</p><pre><code>@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@interface Todo {public enum Priority {LOW, MEDIUM, HIGH}public enum Status {STARTED, NOT_STARTED}String author() default &quot;Yash&quot;;Priority priority() default Priority.LOW;Status status() default Status.NOT_STARTED;}</code></pre><p>这里我们创建了一个新的注解，@Todo</p><pre><code>@Todo(priority = Todo.Priority.MEDIUM, author = &quot;Yashwant&quot;, status = Todo.Status.STARTED)public void incompleteMethod1() {    //一些业务逻辑}</code></pre><p>值得注意的一点，如果注解只有一个属性，那么它应该被命名为value,在使用它的时候不用使用具体的变量名了。</p><pre><code>@interface Author{String value();}@Author(&quot;Yashwant&quot;)public void someMethod() {}</code></pre><p>定义好注解以后，我们需要写注解的消费者，使用反射。</p><pre><code>Class businessLogicClass = BusinessLogic.class;for(Method method : businessLogicClass.getMethods()) {    Todo todoAnnotation = (Todo)method.getAnnotation(Todo.class);    if(todoAnnotation != null) {    System.out.println(&quot; Method Name : &quot; + method.getName());    System.out.println(&quot; Author : &quot; + todoAnnotation.author());    System.out.println(&quot; Priority : &quot; + todoAnnotation.priority());    System.out.println(&quot; Status : &quot; + todoAnnotation.status());    }}</code></pre><h1 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3. Reference"></a>3. Reference</h1><ol><li><a href="https://www.cnblogs.com/skywang12345/p/3344137.html" target="_blank" rel="noopener">https://www.cnblogs.com/skywang12345/p/3344137.html</a> </li><li><a href="https://dzone.com/articles/how-annotations-work-java" target="_blank" rel="noopener">https://dzone.com/articles/how-annotations-work-java</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Annotations </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jackson  java-json parser</title>
      <link href="/Jackson-java-json-parser/"/>
      <url>/Jackson-java-json-parser/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><ul><li>JSON <ul><li>JavaScript Object Notation </li><li>Data exchange format between browsers and web servers </li></ul></li><li>Jackson <ul><li>2 main parsers <ul><li>ObjectMapper <ul><li>parse JSON into custom Java objects, or into a jackson specific tree structure </li></ul></li><li>JsonParser <ul><li>JSON pull parser, parsing JSON one token at a time </li></ul></li></ul></li><li>2 main JSON generator<ul><li>ObjectMapper </li><li>JsonGenerator<ul><li>generate JSON one token at a time </li></ul></li></ul></li><li>3 main packages <ul><li>Jackson Core</li><li>Jackson Annotations</li><li>Jackson Databind </li></ul></li></ul></li></ul><h1 id="2-Parsers-JSON-to-Java-Object"><a href="#2-Parsers-JSON-to-Java-Object" class="headerlink" title="2. Parsers - JSON to Java Object"></a>2. Parsers - JSON to Java Object</h1><pre><code>ObjectMapper objectMapper = new ObjectMapper();String lakers = &quot;{ \&quot;SuperStar\&quot;:\&quot;Kobe Bryant\&quot;}&quot;;try {    Lakers lakers = objectMapper.readValue(lakers, Lakers.class);} catch (IOException e) {    log.error(e);}@Datapublic class Lakers {    private String superStar;}</code></pre><h2 id="2-1-How-Jackson-ObjectMapper-matches-JSON-fields-to-Java-Fields"><a href="#2-1-How-Jackson-ObjectMapper-matches-JSON-fields-to-Java-Fields" class="headerlink" title="2.1 How Jackson ObjectMapper matches JSON fields to Java Fields?"></a>2.1 How Jackson ObjectMapper matches JSON fields to Java Fields?</h2><p>By default, Jackson maps the fields of a JSON object to fields in a Java object by matching the names of the JSON field to the getter and setter methods in the Java object.<br>Jackson removes the “get” and “set” part of the names of the getter and setter methods, and converts the first character of the remaining name to lowercase.</p><p>If you want to customize the parsing process, you may want to use a custom serializer and deserializer, or use Jackson Annotations </p><h2 id="2-2-Fail-on-Null-for-primitive-types"><a href="#2-2-Fail-on-Null-for-primitive-types" class="headerlink" title="2.2 Fail on Null for primitive types"></a>2.2 Fail on Null for primitive types</h2><p>We could configure the Jackson ObjectMapper to fail if a JSON string contains a field with its value set to null. </p><pre><code>ObjectMapper objectMapper = new ObjectMapper();objectMapper.configure(DeserializationFeature.FAIL_ON_NULL_FOR_PRIMITIVES, true);</code></pre><h2 id="2-3-Jackson-JsonParser"><a href="#2-3-Jackson-JsonParser" class="headerlink" title="2.3 Jackson JsonParser"></a>2.3 Jackson JsonParser</h2><ul><li><p>lower level than the ObjectMapper </p><ul><li>faster than the ObjectMapper</li></ul></li><li><p>Create a JsonParser </p><ul><li><code>JsonFactory factory = new JsonFactory();</code></li><li><code>JsonParser parser = factory.createParser(carJson);</code></li></ul></li><li><p>Parsing Json with JsonParser</p><ul><li>break the JSON up into a sequence of tokens which you can iterate one by one </li></ul></li></ul><pre><code>String carJson =        &quot;{ \&quot;brand\&quot; : \&quot;Mercedes\&quot;, \&quot;doors\&quot; : 5 }&quot;;JsonFactory factory = new JsonFactory();JsonParser  parser  = factory.createParser(carJson);while(!parser.isClosed()){    JsonToken jsonToken = parser.nextToken();    System.out.println(&quot;jsonToken = &quot; + jsonToken);}</code></pre><h1 id="3-Generators-Java-Object-to-JSON"><a href="#3-Generators-Java-Object-to-JSON" class="headerlink" title="3. Generators - Java Object to JSON"></a>3. Generators - Java Object to JSON</h1><ul><li>ObjectMapper<ul><li>writeValue()</li><li>writeValueAsString()</li><li>writeValueAsBytes()</li></ul></li></ul><h2 id="3-1-Jackson-JsonGenerator"><a href="#3-1-Jackson-JsonGenerator" class="headerlink" title="3.1 Jackson JsonGenerator"></a>3.1 Jackson JsonGenerator</h2><ul><li>used to generate JSON from java objects </li></ul><pre><code>JsonFactory factory = new JsonFactory();JsonGenerator generator = factory.createGenerator(    new File(&quot;blabla&quot;), JsonEncoding.UTF8);</code></pre><h1 id="4-Jackson-JSON-Tree-Model"><a href="#4-Jackson-JSON-Tree-Model" class="headerlink" title="4. Jackson JSON Tree Model"></a>4. Jackson JSON Tree Model</h1><ul><li>A built-in tree model: used to represent a JSON object </li><li>Represented by the JsonNode class <ul><li>use the ObjectMapper to parse JSON into a JsonNode tree model</li></ul></li><li>JsonNode class lets you navigate the JSOn as a Java object in a quite flexible and dynamic way </li></ul><pre><code>String carJson =        &quot;{ \&quot;brand\&quot; : \&quot;Mercedes\&quot;, \&quot;doors\&quot; : 5 }&quot;;ObjectMapper objectMapper = new ObjectMapper();try {    JsonNode jsonNode = objectMapper.readValue(carJson, JsonNode.class);} catch (IOException e) {    e.printStackTrace();}// ways on how to access JSON fields, arrays and nested objects String carJson =    &quot;{ \&quot;brand\&quot; : \&quot;Mercedes\&quot;, \&quot;doors\&quot; : 5,&quot; +    &quot;  \&quot;owners\&quot; : [\&quot;John\&quot;, \&quot;Jack\&quot;, \&quot;Jill\&quot;],&quot; +    &quot;  \&quot;nestedObject\&quot; : { \&quot;field\&quot; : \&quot;value\&quot; } }&quot;;ObjectMapper objectMapper = new ObjectMapper();try {    JsonNode jsonNode = objectMapper.readValue(carJson, JsonNode.class);    // we could always use get() to get the node     JsonNode brandNode = jsonNode.get(&quot;brand&quot;);    String brand = brandNode.asText();    System.out.println(&quot;brand = &quot; + brand);    JsonNode doorsNode = jsonNode.get(&quot;doors&quot;);    int doors = doorsNode.asInt();    System.out.println(&quot;doors = &quot; + doors);    JsonNode array = jsonNode.get(&quot;owners&quot;);    JsonNode jsonNode = array.get(0);    String john = jsonNode.asText();    System.out.println(&quot;john  = &quot; + john);    JsonNode child = jsonNode.get(&quot;nestedObject&quot;);    JsonNode childField = child.get(&quot;field&quot;);    String field = childField.asText();    System.out.println(&quot;field = &quot; + field);} catch (IOException e) {    e.printStackTrace();}</code></pre><h2 id="4-1-Read-JsonNode-from-JSON"><a href="#4-1-Read-JsonNode-from-JSON" class="headerlink" title="4.1 Read JsonNode from JSON"></a>4.1 Read JsonNode from JSON</h2><pre><code>String jsonStr = blablabla;ObjectMapper objectMapper = new ObjectMapper();JsonNode jsonNode = objectMapper.readTree(json);</code></pre><h2 id="4-2-Write-JsonNode-to-JSON"><a href="#4-2-Write-JsonNode-to-JSON" class="headerlink" title="4.2 Write JsonNode to JSON"></a>4.2 Write JsonNode to JSON</h2><pre><code>ObjectMapper objectMapper = new ObjectMapper();JsonNode jsonNode = readJsonIntoJsonNode();String json = objectMapper.writeValueAsString(jsonNode);</code></pre><h1 id="5-JsonAnnotation"><a href="#5-JsonAnnotation" class="headerlink" title="5. JsonAnnotation"></a>5. JsonAnnotation</h1><ul><li>@JsonIgnore</li><li>@JsonIgnoreProperties<ul><li>specify a list of properties of a class to ignore </li></ul></li><li>@JsonIgnoreType</li><li>@JsonAutoDetect </li><li>@JsonSetter </li><li>@JsonCreator</li><li>@JsonProperty </li><li>@JsonInclude<ul><li>tells Jackson only to include properties under certain circumstances</li></ul></li><li>@JsonGetter <ul><li>tell Jackson that a certain field value should be obtained from calling a getter method instead of via direct field access </li></ul></li><li>@JsonPropertyOrder<ul><li>specify in what order the fields of your java object should be serialized into JSON</li></ul></li><li>@JsonValue<ul><li>tells jackson that it should not attempt to serialize the obejct itself, but rather call a method on the object which serialize the object to a JSON string </li></ul></li><li>@JsonSerialize <ul><li>specify a custom serializer for a field in a Java object  </li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="http://tutorials.jenkov.com/java-json/jackson-objectmapper.html" target="_blank" rel="noopener">http://tutorials.jenkov.com/java-json/jackson-objectmapper.html</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Jackson </tag>
            
            <tag> Serialization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HashMap在Java中是如何工作的</title>
      <link href="/HashMap%E5%9C%A8Java%E4%B8%AD%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84/"/>
      <url>/HashMap%E5%9C%A8Java%E4%B8%AD%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84/</url>
      
        <content type="html"><![CDATA[<p>HashMap是存储以及获取数据的一种简单有效的方式，本文探究Java的HashMap的内部实现。</p><h1 id="1-内部存储"><a href="#1-内部存储" class="headerlink" title="1. 内部存储"></a>1. 内部存储</h1><p>Java的HashMap Class implements <code>Map&lt;K,V&gt;</code> 接口。这个接口的主要方法有：</p><ul><li>put(K key, V value)</li><li>get(Object key)</li><li>remove(Object key)</li><li>Boolean containsKey(Object key)</li></ul><p>HashMap在内部用键值对来进行存储，但是还包含两份其他数据，分别为：</p><ul><li>一个到其他的Entry的reference，这样子HashMap就可以像存单向链表一样来存Entries</li><li>一个代表key的哈希值的值。将这个值存储来避免每次hashMap需要的时候都要重新计算。</li></ul><h2 id="1-1-Java-的Entry的实现"><a href="#1-1-Java-的Entry的实现" class="headerlink" title="1.1 Java 的Entry的实现"></a>1.1 Java 的Entry的实现</h2><pre><code>static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {    final K key;    V value;    Entry&lt;K,V&gt; next;    int hash;}</code></pre><p>一个HashMap存储在多个单向链表中，每个单向链表称为Buckets或者bins. 所有的链表都注册在一个数组中，数组元素为<code>Entry&lt;K,V&gt;</code>. 默认的数组大小是16.<br><img src="https://i.loli.net/2020/02/05/yORJs9NVWXPt75p.jpg" alt="fig1.jpg"></p><p>所有有相同哈希值的key值会存在同一个单向链表当中， 当使用者用put或者get方法的时候，程序会计算需要分配搭配哪个链表(数组的位置)，然后会在链表里用equal方法去找entry中有相同key的entry(针对get方法而言)</p><p>值得注意的是当调用put方法时，如果找到了同样的key，会将value进行替换。</p><p>链表的序号(在数组中的位置)由以下三步来生成：</p><ul><li>得到key的哈希值</li><li>rehash哈希值，来避免不佳的哈希函数把所有数据都放到了一个单向链表当中</li><li>用rehash的哈希值和数组的大小做位掩码， </li></ul><pre><code>// the &quot;rehash&quot; function in JAVA 7 that takes the hashcode of the keystatic int hash(int h) {    h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);    return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);}// the &quot;rehash&quot; function in JAVA 8 that directly takes the keystatic final int hash(Object key) {    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);    }// the function that returns the index from the rehashed hashstatic int indexFor(int h, int length) {    return h &amp; (length-1);}</code></pre><h2 id="1-2-自动重置大小"><a href="#1-2-自动重置大小" class="headerlink" title="1.2 自动重置大小"></a>1.2 自动重置大小</h2><p>在得到在数组中的位置以后，假设要寻找一个key值，我们需要遍历整个单向链表，来找到这个key值。如果array的size固定的话，单个链表的大小可能会非常大，会使整个查找效率变得很低，因此我们需要自动更新整个数组的大小来保证查找效率。</p><p>当我们创建一个HashMap的时候，我们可以定义初始数组的大小和加载参数(Load Factor).如果你不自行定义，那默认的数组大小是16，加载参数是0.75.</p><pre><code>public HashMap(int initialCapacity, float loadFactor)</code></pre><p>当你调用put方法尝试往HashMap里加新的entry的时候，函数会检测是否需要去增加整个数组的大小。HashMap会存储两个数据：</p><ol><li>HashMap的大小：代表了HashMap中的entry的数量</li><li>Threshold = 数组当下的大小 * load factor. </li></ol><p>当调用put方法的时候，会先检测现在的数组的大小是否超过了定义的阈值(Threshold)，如果超过，就会将当前数组的大小进行加倍处理。值得注意的是，当数组大小发生变化的时候，哈希值和数组大小减一的位操作的值会发生变化，也就是说原先的entry会按照现在的数组大小进行重新的分配，将现存的所有entry分配到不同的bucket里面。</p><p>这样做的目的就是减小每个数组元素- 单向链表的大小，让put, remove, get操作所需要的时间在合理的范围内。</p><p><img src="https://i.loli.net/2020/02/05/xk4JnhHSFTPupgQ.jpg" alt="fig2.jpg"></p><h1 id="2-线程安全？"><a href="#2-线程安全？" class="headerlink" title="2. 线程安全？"></a>2. 线程安全？</h1><p>HashMap不是线程安全的，是因为假设现在到了设的阈值，需要进行HashMap内部数组的resize。这个时候新的entry可能是用原先的哈希函数来做bucket的分配的，这样子就会造成整个数据的不同步。</p><h1 id="3-键值的不可变性"><a href="#3-键值的不可变性" class="headerlink" title="3. 键值的不可变性"></a>3. 键值的不可变性</h1><p>String和Integer是很好的键值选项，因为他们本身就是不可变的。如果你创建自己的键值类，而且这个键值类是可变的，那么我们也许就会在HashMap中丢失数据。</p><p>因为旧哈希值是被存储在Array中的，作为分配到特定bucket的基准，你改变了键值，也就是改变了传入的哈希值，这时候这是全新的一条数据，无法回到原来的bucket，也无法对其进行覆盖了。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="http://coding-geek.com/how-does-a-hashmap-work-in-java/" target="_blank" rel="noopener">Coding Geek</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> HashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Handling overload effectively with load balancers</title>
      <link href="/Handling-overload-effectively-with-load-balancers/"/>
      <url>/Handling-overload-effectively-with-load-balancers/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Fail-Smarter"><a href="#1-Fail-Smarter" class="headerlink" title="1. Fail Smarter"></a>1. Fail Smarter</h1><ul><li>Average latency has a spike, availability down</li><li>reasons <ul><li>dependencies </li><li>cascading effect </li><li>client change   peak </li></ul></li></ul><h1 id="2-Load-balancers"><a href="#2-Load-balancers" class="headerlink" title="2. Load balancers"></a>2. Load balancers</h1><ul><li>clients - load balancers - servers </li><li>hardware devices </li><li>multi tenant - use VIP - for efficiency </li><li>used for (features)<ul><li>scaling </li><li>even traffic distribution </li><li>overload protection</li></ul></li><li>how<ul><li>how to pick a server <ul><li>random dice </li><li>round robin </li><li>least conns </li></ul></li><li>desired algorithm - we use least conns <ul><li>simple </li><li>reliable </li><li>even </li></ul></li><li>max conns? </li><li>how to deal with overload? <ul><li>attributes <ul><li>cheap </li><li>local </li><li>buffering - having capacity soon </li><li>priority </li></ul></li><li>reject requests  - spillover - choose! <ul><li>close the TCP connection </li><li>no buffer </li></ul></li><li>hang on, wait in a queue - surge queue <ul><li>may mkes it take longer</li></ul></li></ul></li></ul></li><li>some default we set - maxConns - perhost setting <ul><li>little’s law <ul><li>arrival rate * time shopping = people in the store </li></ul></li><li>see load balancers how many services we have </li><li>fleet-wide concurrent requests / host count = <strong>avg conns</strong></li></ul></li></ul><ul><li>metrics matter <ul><li>latency netwrok latency + 25% <ul><li>client side </li><li>server side </li></ul></li><li>request rate </li></ul></li><li>coral server <ul><li>concurrent requests - outstanding request - in one host </li></ul></li><li>33% overhead room - dependency failures </li></ul><h1 id="3-Actual-behave"><a href="#3-Actual-behave" class="headerlink" title="3. Actual behave"></a>3. Actual behave</h1><ul><li>increase load to see average latency </li><li>run actual test </li><li>generate graph with outstanding requests <ul><li>see the cross of client timeout and p99 </li></ul></li></ul><h1 id="4-Abnormal-cases"><a href="#4-Abnormal-cases" class="headerlink" title="4. Abnormal cases"></a>4. Abnormal cases</h1><ul><li>dependency latency, timeout </li><li>network  packet loss </li></ul><ul><li>let server decide what’s the maxCon should be </li><li>coral has<ul><li>connection </li><li>worker  work thread </li></ul></li><li>classify requests <ul><li>importance <ul><li>droppable </li></ul></li><li>priority <ul><li>order  </li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Load Balancers </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Google Dagger Tutorial</title>
      <link href="/Google-Dagger-Tutorial/"/>
      <url>/Google-Dagger-Tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Comparisons"><a href="#1-Comparisons" class="headerlink" title="1. Comparisons"></a>1. Comparisons</h1><p>Spring is a giant collection of libraries and utilities. with a lot of integration, an XML configuration, runtime/ reflective bindings. Application already using Spring can use its dependency injection smoothly. </p><p>Dependency is only a small part of it. Guice and Dagger is lightweight and only a dependency injection framework</p><p>Dagger is very lightweight framework with very few integrations, java interface/ annotation configuration, and compile-time code generated bindings. </p><p>For dependency injection and IOC container, there is <a href="https://llchen60.com/IOC%E5%AE%B9%E5%99%A8%E5%92%8CDependency-Injection%E6%A8%A1%E5%BC%8F/" target="_blank" rel="noopener">a post in Chinese</a> wrote last year.</p><p>Also a big difference between those DI framework is when does the injection happen, compile time or runtime? </p><p>Run-time DI is <strong>based on reflection</strong> which is simpler to use but slower at run-time —- Spring, Guice </p><p>Compile-time DI is <strong>based on code generation</strong>. This means that all the heavy-weight operations are performed during compilation. It adds complexity but generally performs faster</p><h1 id="2-Implementation"><a href="#2-Implementation" class="headerlink" title="2. Implementation"></a>2. Implementation</h1><ul><li>POJO</li><li>Module<ul><li>a class provides or builds the objects’ dependencies </li></ul></li><li>Component<ul><li>an interface used to generate the injector </li></ul></li></ul><h2 id="2-1-POJO"><a href="#2-1-POJO" class="headerlink" title="2.1 POJO"></a>2.1 POJO</h2><pre><code>public class Car {    private Engine engine;    private Brand brand;    @Inject    public Car(Engine engine, Brand brand) {        this.engine = engine;        this.brand = brand;    }    // getters and setters}</code></pre><h2 id="2-2-Module"><a href="#2-2-Module" class="headerlink" title="2.2 Module"></a>2.2 Module</h2><pre><code>@Module // similar to @Controller  @Service public class VehiclesModule {    @Provides // similar to @Bean     public Engine provideEngine() {        return new Engine();    }    @Provides    @Singleton    public Brand provideBrand() {         return new Brand(&quot;lol&quot;);     }}</code></pre><h2 id="2-3-Component"><a href="#2-3-Component" class="headerlink" title="2.3 Component"></a>2.3 Component</h2><p>here we could return the real object we want to be the starting point of the whole mechanism:</p><p>Dagger will start from here, go through all the @Inject and satisfy those dependencies. In our example, will create engine and brand object. </p><pre><code>@Singleton@Component(modules = VehiclesModule.class)public interface VehiclesComponent {    Car buildCar();}</code></pre><h2 id="2-4-client-side"><a href="#2-4-client-side" class="headerlink" title="2.4 client side"></a>2.4 client side</h2><p>Notice: <code>DaggerVehiclesComponent</code> is created by dagger automatically. </p><pre><code>VehiclesComponent component = DaggerVehiclesComponent.create();Car eg = component.buildCar();</code></pre><h1 id="3-Dagger-User-Guide"><a href="#3-Dagger-User-Guide" class="headerlink" title="3. Dagger User Guide"></a>3. Dagger User Guide</h1><h2 id="3-1-Declaring-Dependencies"><a href="#3-1-Declaring-Dependencies" class="headerlink" title="3.1 Declaring Dependencies"></a>3.1 Declaring Dependencies</h2><p>Dagger constructs instances of application classes and satisfies their dependencies. It uses @Inject annotation to identify which constructors and fields it is interested in. </p><h2 id="3-2-Satisfying-Dependencies"><a href="#3-2-Satisfying-Dependencies" class="headerlink" title="3.2 Satisfying Dependencies"></a>3.2 Satisfying Dependencies</h2><p>By default, Dagger satisfies each dependency by constructing an instance of the requested type. It call <code>new SomeObject()</code> and setting its injectable fields. </p><ul><li>@Inject <ul><li>interfaces cannot be constructed </li><li>third party classes cannot be annotated </li><li>configurable objects must be configured </li></ul></li><li>Instead, use @provides <ul><li>all @provides methods should be named with a provide prefix and module classes are named with a Module suffix </li></ul></li></ul><h2 id="3-3-Building-the-Graph"><a href="#3-3-Building-the-Graph" class="headerlink" title="3.3 Building the Graph"></a>3.3 Building the Graph</h2><p>The @Inject and @Provides annotated classes form a graph of objects, linked by their dependencies. Build the application by <strong>an interface with methods that have no arguments and return the desired type</strong>. </p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://stackoverflow.com/questions/39688830/why-use-develop-guice-when-you-have-spring-and-dagger" target="_blank" rel="noopener">https://stackoverflow.com/questions/39688830/why-use-develop-guice-when-you-have-spring-and-dagger</a></li><li><a href="https://www.baeldung.com/dagger-2" target="_blank" rel="noopener">https://www.baeldung.com/dagger-2</a></li><li><a href="https://rskupnik.github.io/dependency-injection-in-pet-project-dagger2" target="_blank" rel="noopener">https://rskupnik.github.io/dependency-injection-in-pet-project-dagger2</a></li><li><a href="https://dagger.dev/" target="_blank" rel="noopener">https://dagger.dev/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Dagger </tag>
            
            <tag> DI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Executor, ExecutorService and Executors</title>
      <link href="/Executor-ExecutorService-and-Executors/"/>
      <url>/Executor-ExecutorService-and-Executors/</url>
      
        <content type="html"><![CDATA[<p>Executor, ExecutorService and Executors, they are all part of Java’s Executor framework, this framework offers a threadpool. Thus we don’t need to manage threads on our own, the pool can help us manage themselves. </p><p>A thread pool which is created when an application is a startup solves both of these problems. It has <strong>ready threads</strong> to serve clients when needed and it also has a bound on how many threads to create under load.</p><h1 id="1-Executor"><a href="#1-Executor" class="headerlink" title="1. Executor"></a>1. Executor</h1><p><strong>the core interface</strong> which is an abstraction for parallel execution</p><p>It separates task from execution, this is different from java.lang.Thread class which <strong>combines both task and its execution</strong>. </p><h1 id="2-ExecutorService"><a href="#2-ExecutorService" class="headerlink" title="2. ExecutorService"></a>2. ExecutorService</h1><p>ExecutorService is an extension of Executor interface and provides a facility for returning a Future object and terminate, or shut down the thread pool. Once the shutdown is called, the thread pool will not accept new task but complete any pending task. It also provides a submit() method which extends Executor.execute() method and returns a Future.</p><p>The Future object provides the facility of asynchronous execution, which means you don’t need to wait until the execution finishes, you can just submit the task and go around, come back and check if Future object has the result, if execution is completed then it would have result which you can access by using the Future.get() method. Just remember that this method is a <strong>blocking method</strong> i.e. it will wait until execution finish and the result is available if it’s not finished already.</p><p>By using the Future object returned by ExecutorService.submit() method, you can also cancel the execution if you are not interested anymore. It provides cancel() method to cancel any pending execution.</p><h1 id="3-Executors"><a href="#3-Executors" class="headerlink" title="3. Executors"></a>3. Executors</h1><p>Third one Executors is a utility class similar to Collections, which provides <strong>factory methods</strong> to create different types of thread pools e.g. fixed and cached thread pools. Let’s see some more difference between these three classes.</p><h1 id="4-Difference"><a href="#4-Difference" class="headerlink" title="4. Difference"></a>4. Difference</h1><p>1) One of the key difference between Executor and ExecutorService interface is that <strong>former is a parent interface while ExecutorService extends Executor</strong> i.e. it’s a sub-interface of Executor.</p><p>2) Another important difference between ExecutorService and Executor is that Executor defines execute() method which accepts an object of the Runnable interface, while submit() method can accept objects of both Runnable and Callable interfaces.</p><p>3) The third difference between Executor and ExecutorService interface is that execute() method doesn’t return any result, its return type is void but submit() method returns the result of computation via a Future object. This is also the key difference between submit() and execute() method, which is one of the frequently asked Java concurrency interview questions.</p><p>4) The fourth difference between ExecutorService and Executor interface is that apart from allowing a client to submit a task, <strong>ExecutorService also provides methods to control the thread pool</strong> e.g. terminate the thread pool by calling the shutDown() method. You should also read “Java Concurrency in Practice” to learn more about the graceful shutdown of a thread-pool and how to handle pending tasks.</p><p>5) Executors class provides factory methods to create different kinds of thread pools e.g. newSingleThreadExecutor() creates a thread pool of just one thread, newFixedThreadPool(int numOfThreads) creates a thread pool of fixed number of threads and newCachedThreadPool() creates new threads when needed but reuse the existing threads if they are available.</p><h1 id="5-Differences-between-Executor-and-Thread"><a href="#5-Differences-between-Executor-and-Thread" class="headerlink" title="5. Differences between Executor and Thread"></a>5. Differences between Executor and Thread</h1><ol><li>Executor provides a thread pool in java, while Thread not. </li><li>java.lang.Thread is a class in Java while java.util.concurrent.Executor is an interface.</li><li>The Executor concept is actually an abstraction over parallel computation. It allows concurrent code to be run in managed way. On the other hand, Thread is a concrete way to run the code in parallel.</li><li>Executor decouples a task (the code which needs to be executed in parallel) from execution, while in the case of a Thread, both task and execution are tightly coupled.</li><li>The Executor concept allows your task is to be executed by a worker thread from the thread pool, while Thread itself execute your task</li><li>a Thread can only execute one Runnable task but an Executor can execute any number of Runnable task.</li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EnumMap vs HashMap</title>
      <link href="/EnumMap-vs-HashMap/"/>
      <url>/EnumMap-vs-HashMap/</url>
      
        <content type="html"><![CDATA[<h1 id="1-EnumMap"><a href="#1-EnumMap" class="headerlink" title="1. EnumMap"></a>1. EnumMap</h1><ul><li>Can only be used with <strong>enum type</strong> keys </li><li>It’s specialized implementation of Map Interface for use with enum type keys</li><li>Internally using <strong>arrays</strong> </li><li>stored in <strong>natural order</strong></li><li>not possible for collision </li><li>much efficient compared with HashMap </li></ul><h1 id="2-HashMap"><a href="#2-HashMap" class="headerlink" title="2. HashMap"></a>2. HashMap</h1><ul><li>Extends AbstrctMap and implement Map interface </li><li>Internally using hashTable</li><li>Possible for collision </li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.geeksforgeeks.org/enummap-class-java-example/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/enummap-class-java-example/</a> </li><li><a href="https://walkingtechie.blogspot.com/2017/03/difference-between-enummap-and-hashmap.html" target="_blank" rel="noopener">https://walkingtechie.blogspot.com/2017/03/difference-between-enummap-and-hashmap.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Effective Java</title>
      <link href="/Effective-Java/"/>
      <url>/Effective-Java/</url>
      
        <content type="html"><![CDATA[<h1 id="1-General-Programming"><a href="#1-General-Programming" class="headerlink" title="1. General Programming"></a>1. General Programming</h1><h2 id="1-1-Scope-of-Local-variables"><a href="#1-1-Scope-of-Local-variables" class="headerlink" title="1.1 Scope of Local variables"></a>1.1 Scope of Local variables</h2><pre><code>for (Iterator&lt;Element&gt; i = c.iterator(); i.hasNext(); ) {    Element e = i.next();    ... // Do something with e and i}// code with bugIterator&lt;Element&gt; i2 = c2.iterator();while (i.hasNext()) {    Element e2 = i2.next();    ... // Do something with e2 and i2}</code></pre><p>i - i2. causing a runtime bug. This bug can be caught at compile time if you <strong>use local variable with minimal scope</strong>. </p><ol><li>Declare the scope of a local variable where it is first used </li><li>initialize every local variable</li><li>prefer for loops to while loops </li><li>keep methods small and focused on a single task </li></ol><h2 id="1-2-Use-library"><a href="#1-2-Use-library" class="headerlink" title="1.2 Use library"></a>1.2 Use library</h2><p>Use library will give you some advantages:</p><ul><li>The knowledge of experts who implemented it and the experience of others who used it before you. </li><li>Better performance that is implemented by experts.</li><li>New features that are added to the libraries in every major release. </li></ul><h2 id="1-3-Float-Double-and-Exact-Calculations"><a href="#1-3-Float-Double-and-Exact-Calculations" class="headerlink" title="1.3 Float, Double and Exact Calculations"></a>1.3 Float, Double and Exact Calculations</h2><pre><code>int getPossibleBoughtItems() {    double dollarFunds = 1.0;    int numItems = 0;    for (double price = 0.10; dollarFunds &gt;= price; price += 0.10) {        dollarFunds -= price;        numItems++;    }    return numItems;}</code></pre><p>We should use BigDecimal, int or long for exact calculations. We should avoid using float and double for exact calculations because they are carefully designed for accurate approximations in scientific and engineering calculations. </p><p>Note that the first method above will return 3, which is wrong, with funds left of $0.3999999999999999. The correct return should be 4, with funds left 0 (see the second implementation).</p><h2 id="1-4-Primitive-Types-and-Boxed-Primitives"><a href="#1-4-Primitive-Types-and-Boxed-Primitives" class="headerlink" title="1.4 Primitive Types and Boxed Primitives"></a>1.4 Primitive Types and Boxed Primitives</h2><p>When possible, you should use primitives, instead of boxed primitives, because: </p><ol><li>Unnecessary use of boxed primitives may result in a hideously slow program because of repeated boxed and unboxed operations. </li><li>whenboxes primitives are used, applying <code>==</code> operator is almost always wrong and can lead to deadly bugs that are difficult to discover. </li></ol><h2 id="1-5-Use-of-Strings-and-Other-Types"><a href="#1-5-Use-of-Strings-and-Other-Types" class="headerlink" title="1.5 Use of Strings and Other Types"></a>1.5 Use of Strings and Other Types</h2><pre><code>// goodpublic final class ThreadLocal&lt;T&gt; {    public ThreadLocal() {};    public void set (T value) {...};    public T get() {...};}// not good public final class ThreadLocal {    private ThreadLocal() {};    public static void set (String key, Object value) {...};    public static Object get(String key) {...};}</code></pre><p>We should avoid using String, because it is poor substitutes for other value types, or aggregate types, or capacity types. It is cumbersome, slower, error-prone and inflexible than other types. </p><h2 id="1-6-String-Builder-and-String-Concatenation"><a href="#1-6-String-Builder-and-String-Concatenation" class="headerlink" title="1.6 String Builder and String Concatenation"></a>1.6 String Builder and String Concatenation</h2><p>Use String Builder instead of String Concatenation, due to its poor performance. </p><pre><code>// Good public String firstNamesToString(List&lt;Person&gt; members) {    StringBuilder sb = new StringBuilder();    for (Person p : members) {        sb.append(&quot;[&quot;);        sb.append(p.firstName);        sb.append(&quot;]&quot;);    }    return sb.toString();}// Bad public String firstNamesToString(List&lt;Person&gt; members) {    String s = &quot;&quot;;    for (Person p : members) {        s += &quot;[&quot; + p.firstName + &quot;]&quot;;    }    return s;}</code></pre><h2 id="1-7-Interface-and-Class-reference"><a href="#1-7-Interface-and-Class-reference" class="headerlink" title="1.7 Interface and Class reference"></a>1.7 Interface and Class reference</h2><p>Use of interface reference </p><pre><code>public List&lt;Person&gt; getPeopleByFirstName(List&lt;Person&gt; members, String firstName) {}</code></pre><p>It would be desirable, more flexible and more backward-compatible to use interface types to refer to parameters, return values, variables and fields if appropriate interface types exist. If appropriate interface types do not exist, use least specific class types to refer to parameters, return values, variables and fields if appropriate interface types do not exist. </p><h1 id="2-Objects"><a href="#2-Objects" class="headerlink" title="2. Objects"></a>2. Objects</h1><h2 id="2-1-Static-Factory-Methods-and-Constructors"><a href="#2-1-Static-Factory-Methods-and-Constructors" class="headerlink" title="2.1 Static Factory Methods and Constructors"></a>2.1 Static Factory Methods and Constructors</h2><p>You are designing a class such as Date and you want to allow a client to obtain an instance of the class, given some input such as instant.</p><p>We should use static factory methods because Factory method has following advantages: </p><ol><li>have names </li><li>not required to create a new object each time invoked </li><li>can return an object of any subtype of their return type </li><li>decouple service provider frameworks </li></ol><h2 id="2-2-Builders-and-Constructors"><a href="#2-2-Builders-and-Constructors" class="headerlink" title="2.2 Builders and Constructors"></a>2.2 Builders and Constructors</h2><p>Use builders since it makes code easier for reading</p><h2 id="2-3-Singleton"><a href="#2-3-Singleton" class="headerlink" title="2.3 Singleton"></a>2.3 Singleton</h2><h3 id="2-3-1-Use-of-enum"><a href="#2-3-1-Use-of-enum" class="headerlink" title="2.3.1 Use of enum"></a>2.3.1 Use of enum</h3><pre><code>public enum MySingleton {    INSTANCE;    public void getDataByMarketplaceId(MarketplaceId id) { ... }}</code></pre><h3 id="2-3-2-Use-of-static-factory"><a href="#2-3-2-Use-of-static-factory" class="headerlink" title="2.3.2 Use of static factory"></a>2.3.2 Use of static factory</h3><pre><code>public class MySingleton {    private static final MySingleton INSTANCE = new MySingleton();    private MySingleton() { ... }    public static MySingleton getInstance() { return INSTANCE; }    public void getDataByMarketplaceId(MarketplaceId id) { ... }}</code></pre><h2 id="2-4-Reusable-Objects"><a href="#2-4-Reusable-Objects" class="headerlink" title="2.4 Reusable Objects"></a>2.4 Reusable Objects</h2><pre><code>public class RomanNumber {    private static Pattern ROMAN = Pattern.compile(&quot;^(?=.)M*(C[MD]|D?C{0,3})(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$&quot;);    static boolean isRomanNumber(String s) {        return ROMAN.matcher(s).matches();    }}</code></pre><p>Reuse the expensive objects(here is Pattern), in performace critical situations. </p><h1 id="3-Classes"><a href="#3-Classes" class="headerlink" title="3. Classes"></a>3. Classes</h1><h2 id="3-1-Accessibility-of-Classes-and-Members"><a href="#3-1-Accessibility-of-Classes-and-Members" class="headerlink" title="3.1 Accessibility of Classes and Members"></a>3.1 Accessibility of Classes and Members</h2><p>Avoid using a public array because a nonzero length array is always mutable, and thus clients will be able to modify the elements of the array. </p><h2 id="3-2-Mutability"><a href="#3-2-Mutability" class="headerlink" title="3.2 Mutability"></a>3.2 Mutability</h2><p>In general, classes should be immutable unless there’s a very good reason to make them mutable; and if so, you should minimize mutability when designing and implementing classes. Rules to make a class immutable: </p><ol><li>Don’t provide methods that modify the state of objects that you want to be immutable. </li><li>Ensure that the class cann’t be extended.</li><li>Make all fields final to express your intent clearly</li><li>Make all fields private to prevent clients from obtaining access to mutable objects </li><li>Ensure exclusive access to any mutable components</li></ol><p>Try to use more immutability, since it offers benefits byu nature: </p><ol><li>Immutable objects are simple: providing failure atomicity </li><li>Inherently thread-safe, require no synchronization </li><li>Can share immutable objects freely</li><li>Immutable objects make great building blocks for other objects. </li></ol><h2 id="3-3-Interfaces-and-Abstract-Classes"><a href="#3-3-Interfaces-and-Abstract-Classes" class="headerlink" title="3.3 Interfaces and Abstract Classes"></a>3.3 Interfaces and Abstract Classes</h2><p>In general, use of interfaces is the best way to define a type that permits multiple implementations because a class can implement multiple interfaces whereas it cannot extend multiple abstract classes. </p><h2 id="3-4-Static-Member-Classes"><a href="#3-4-Static-Member-Classes" class="headerlink" title="3.4 Static Member Classes"></a>3.4 Static Member Classes</h2><pre><code>public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable {    ...    static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {        final int hash;        final K key;        V value;        Node&lt;K,V&gt; next;        ...        public final K getKey()        { return key; }        public final V getValue()      { return value; }        ...    }}</code></pre><p>A nested class is a class defined within another class, the former should exist only to serve the latter. If you declare a member class that doesn’t require access to its enclosing instance then always put static modifier in its declaration. </p><p>If you omit this modifier then each instance will have a hidden extraneous reference to its enclosing instance, and storing this reference takes time and space. More seriously, it can result in the enclosing instance being retained when it would be otherwise be eligible for garbage collection, causing catastrophic memory leak.</p><h1 id="4-Methods-and-Generics"><a href="#4-Methods-and-Generics" class="headerlink" title="4. Methods and Generics"></a>4. Methods and Generics</h1><h2 id="4-1-Empty-and-Null-returns"><a href="#4-1-Empty-and-Null-returns" class="headerlink" title="4.1 Empty and Null returns"></a>4.1 Empty and Null returns</h2><p>Never return null in place of an empty array or collection because it will require clients to check null return for all method calls, ugly!</p><h2 id="4-2-Optional-Returns"><a href="#4-2-Optional-Returns" class="headerlink" title="4.2 Optional Returns"></a>4.2 Optional Returns</h2><pre><code>public static &lt;E extends Comparable&lt;E&gt;&gt; Optional&lt;E&gt; max(Collection&lt;E&gt; c) {    if (c.isEmpty()) {        return Optional.empty();    }    E result = null;    for (E e : c) {        if (result == null || e.compareTo(result) &gt; 0) {            result = Objects.requireNonNull(e);        }    }    return Optional.of(result);}</code></pre><p>Since Java 8, an Optional-returning method is possible, more flexible, and easier to use than one that throws an exception; it is also less error-prone than one that returns  null . Here are some best practices when using   Optional :</p><ul><li>Never return a null value from an optinal-returning method because doing so defeats the entire purpose of the facility.</li><li>Use helpers provided by the facility</li></ul><pre><code> String lastWordInLexicon = max(words).orElse(&quot;No words...&quot;); ,   Toy myToy = max(toys).orElseThrow(ToyException::new); </code></pre><ul><li>Container types, including collections, maps, streams, arrays, and optionals, should not be wrapped in optionals, because they have already provided facility to handle empty values.</li><li>Never return an optional of a boxed primitive type, with possible exception of  Boolean ,  Byte ,   Character ,  Short ,  Float . For other boxed primitive types, use  OptionalInt ,   OptionalLong ,  OptionalDouble  instead.</li></ul><h2 id="4-3-Generics-and-Unchecked-Warnings"><a href="#4-3-Generics-and-Unchecked-Warnings" class="headerlink" title="4.3 Generics and Unchecked Warnings"></a>4.3 Generics and Unchecked Warnings</h2><pre><code>public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt;        implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable {    ...    public &lt;T&gt; T[] toArray(T[] a) {        if (a.length &lt; size) {            @SuppressWarnings(&quot;unchecked&quot;) T[] result = (T[]) Arrays.copyOf(elementData, size, a.getClass());            return result;        }        System.arraycopy(elementData, 0, a, 0, size);        if (a.length &gt; size) {            a[size] = null;        }        return a;    }    ...} </code></pre><p>Unchecked warnings are important; don’t ignore them because every unchecked warning has the potential to throw a   ClassCastException  at runtime. You should do your best to eliminate as many of them as possible. If you can’t, however, get rid of an unchecked warning, but you can prove that the code that provoke it is typesafe then suppress it with the corresponding annotation in the <strong>narrowest possible scope</strong>.</p><p>@SupressWarning: An anotation to surpress compile warnings about unchecked generic operations. </p><h2 id="4-4-Generics-and-Wildcards"><a href="#4-4-Generics-and-Wildcards" class="headerlink" title="4.4 Generics and Wildcards"></a>4.4 Generics and Wildcards</h2><pre><code>public class Stack&lt;E&gt; {    ...    public Stack() { ... }    public void push(E e) { ... }    public E pop() { ... }    public boolean isEmpty { ... }    public void pushAll(Iterable&lt;? extends E&gt; src) {        for (E e : src) {            push(e);        }    }    public void popAll(Collection&lt;? super E&gt; dst) {        while (!isEmpty()) {            dst.add(pop());        }    }}</code></pre><p>It is clear that for maximum flexibility you should use wildcard types on input parameters that represent producers or consumers.</p><ul><li>Remember PECS, which stands for <strong>Producer-Extends and Consumer-Super</strong>. Note that  Comparable  and   Comparator  are always consumers.</li></ul><h1 id="5-Exceptions"><a href="#5-Exceptions" class="headerlink" title="5. Exceptions"></a>5. Exceptions</h1><h2 id="5-1-Checked-Exceptions-and-Unchecked-Exceptions"><a href="#5-1-Checked-Exceptions-and-Unchecked-Exceptions" class="headerlink" title="5.1 Checked Exceptions and Unchecked Exceptions"></a>5.1 Checked Exceptions and Unchecked Exceptions</h2><pre><code>/** * Returns MarketplaceInfo of a given marketplace. * @throws NotFoundException if marketplaceId is not found; do not retry. * @throws ServiceUnavailableException if MarketplaceService does not respond after 3 retries. */public MarketplaceInfo getMarketplaceInfoById(MarketplaceId marketplaceId) {    try {        return getMarketplaceInfoByIdFromLocalCache(marketplaceId);    } catch (IOException e) {        try {            MarketplaceInfo info = getMarketplaceInfoByIdFromRemoteCache(marketplaceId);            putMarketplaceInfoToLocalCache(marketplaceId, info);            return info;        } catch (IOException e) {            for (int numRetries = 0; numRetries &lt; 3; numRetries++) {                try {                    // Call dependent service to get marketplace info                    MarketplaceInfo info = marketplaceService.getMarketplaceInfoById(marketplaceId);                    putMarketplaceInfoToLocalCache(marketplaceId, info);                    putMarketplaceInfoToRemoteCache(marketplaceId, info);                                    return info;                } catch (ServiceUnavailableException e) {                    sleep(5); // sleep 5 seconds before retry                } catch (NotFoundException e) {                    LOG.error(&quot;Unable to get marketplace info because marketplace id {} is not found.&quot;, marketplaceId);                    throw e;                }            }            throw new ServiceUnavailableException(&quot;Unable to get marketplace info after 3 retries.&quot;);        }    }}</code></pre><p>We should: </p><ul><li>throw checked exceptions, a subclass of Exception <ul><li>for recoverable conditions</li></ul></li><li>throw unchecked exceptions, a subclass of runtimeException <ul><li>for programming errors </li></ul></li></ul><p>When in doubt, throw unchecked exceptions. When throwing checked exceptions, add methods to aid in recovery for clients. </p><p>You should declare checked exceptions individually and document precisely the conditions under which each exception is thrown, by using Javadoc  @throws  tag. If the same exception is thrown by many methods in a class for the same reason then you can document it in the class’s documentation comment. In addition, it is particularly important to document unchecked exceptions of methods in interfaces they may throw</p><h2 id="5-2-Exception-Implementation"><a href="#5-2-Exception-Implementation" class="headerlink" title="5.2 Exception Implementation"></a>5.2 Exception Implementation</h2><ul><li>Provide detail as much as possible</li><li>detail msg should contain the values of all parameters and fields that have contributed to the exception </li><li>No sensitive information contained </li></ul><h1 id="6-Lambdas-and-Streams"><a href="#6-Lambdas-and-Streams" class="headerlink" title="6. Lambdas and Streams"></a>6. Lambdas and Streams</h1><h2 id="6-1-Method-references"><a href="#6-1-Method-references" class="headerlink" title="6.1 Method references"></a>6.1 Method references</h2><ul><li><code>Integer::parseInt</code> -&gt; a static method reference for <code>str -&gt; Integer.parseInt(str)</code></li><li><code>Instant.now()::isAfter</code> -&gt; a bound method reference for <code>Instance i = Instant.now(); t -&gt; i.isAfter(t)</code></li><li><code>String::toLowerCase</code> -&gt; an unbound method reference for <code>str -&gt; str.toLowerCase()</code></li><li><code>TreeMap&lt;K, V&gt;::new</code> -&gt; A class constructor for <code>() -&gt; new TreeMap&lt;K, V&gt;</code></li></ul><h1 id="7-Concurrency"><a href="#7-Concurrency" class="headerlink" title="7. Concurrency"></a>7. Concurrency</h1><h2 id="7-1-Synchronize-Access-to-Sharable-Mutable-Data"><a href="#7-1-Synchronize-Access-to-Sharable-Mutable-Data" class="headerlink" title="7.1 Synchronize Access to Sharable Mutable Data"></a>7.1 Synchronize Access to Sharable Mutable Data</h2><p>When multiple threads share mutable data, each thread that reads or writes the data must <strong>perform synchronization</strong>, otherwise there is no guarantee that one thread’s changes of the data will be visible to other threads, and therefore may cause liveness and safety failures. These failures are among the most difficult to debug.<br><code>var ++</code><br>It performs two operations on var : (1) it reads the value, (2) it writes back a new value that is equal to the old value plus one. If a second thread reads the field between the time the first thread reads the old value and writes back the new one, then both threads will see the same value and thus return the same serial number, OUCH; this is a safety failure.</p><p>Note that the best way to avoid safety failure is <strong>not to share mutable data</strong>, meaning share only immutable data or don’t share at all — confine mutable data to a single thread. If you adopt this policy then you should document it carefully, so that the policy is maintained as your program evolves. It is also crucial to have a deep understanding of the frameworks and libraries you’re using because they may introduce threads that you are unaware of.</p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cost of abstraction</title>
      <link href="/Cost-of-abstraction/"/>
      <url>/Cost-of-abstraction/</url>
      
        <content type="html"><![CDATA[<p>Duplicate is definitely something we are trying to get rid of, however, what’s the cost of abstraction? It seems some problem we could think for a while. </p><p>We should think of the tradeoff between code duplication and increased level of abstraction. </p><h1 id="1-Definition-cost-of-abstraction"><a href="#1-Definition-cost-of-abstraction" class="headerlink" title="1. Definition - cost of abstraction"></a>1. Definition - cost of abstraction</h1><ul><li>An abstraction is adding to the cognitive load of whoever works with the code </li><li>The main cost of abstraction: separating the implementation from the specification. Or we say separate the letter of function from the spirit of the function</li><li>The former being what the function does, the latter being what everybody believes it should do </li><li>Should involve everybody to consider what the code does, or we say what the function does </li></ul><h1 id="2-Thought"><a href="#2-Thought" class="headerlink" title="2. Thought"></a>2. Thought</h1><ul><li>The decision about creating an abstraction should not be taken lightly.</li><li>There’s a large social cost to every abstraction, may lead the project to be unmaintainable.</li><li>lambda is also a way to reduce the abstraction layers in some way </li><li>Abstraction is a good way to get rid of verbose code, but itself may bring uncertainty to some extent. Only implement <strong><em>necessary</em></strong> abstraction. </li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CacheLoader 教程</title>
      <link href="/CacheLoader-%E6%95%99%E7%A8%8B/"/>
      <url>/CacheLoader-%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-LoadingCache"><a href="#1-LoadingCache" class="headerlink" title="1. LoadingCache"></a>1. LoadingCache</h1><p>LoadingCache是指用CacheLoader建立的缓存。想要使用LoadingCache的话，就是使用方法<code>get(K)</code>。如果不在LoadingCache里面的话，就会使用CacheLoader做一次加载；如果有的话就直接拿回结果了。</p><h1 id="2-使用CacheLoader以及LoadingCache"><a href="#2-使用CacheLoader以及LoadingCache" class="headerlink" title="2. 使用CacheLoader以及LoadingCache"></a>2. 使用CacheLoader以及LoadingCache</h1><pre><code>LoadingCache&lt;String, String&gt; loadingCache = CacheBuilder.newBuilder()    .build(new CacheLoader&lt;String, String&gt;() {        @Override        public String load(final String s) throws Exception {            return response;        }    });</code></pre><ul><li>CacheLoader在使用newBuilder()创造新实例的时候还可以做很多的设置，比如<ul><li><code>expireAfterAccess(long duration, TimeUnit unit)</code><ul><li>在每个entry被创建以后，经过一段固定的时间做自动移除操作</li></ul></li><li><code>maximumSize(long size)</code><ul><li>定义cache能有的最大entry数量 </li></ul></li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.baeldung.com/guava-cacheloader" target="_blank" rel="noopener">https://www.baeldung.com/guava-cacheloader</a> </li><li><a href="https://stackoverflow.com/questions/43993731/what-is-a-loadingcache" target="_blank" rel="noopener">https://stackoverflow.com/questions/43993731/what-is-a-loadingcache</a></li><li><a href="https://guava.dev/releases/21.0/api/docs/com/google/common/cache/LoadingCache.html" target="_blank" rel="noopener">https://guava.dev/releases/21.0/api/docs/com/google/common/cache/LoadingCache.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Cache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Apache-Ant</title>
      <link href="/Apache-Ant/"/>
      <url>/Apache-Ant/</url>
      
        <content type="html"><![CDATA[<p>Apache Ant is a Java-based build tool. A java library and command line tool, which aims to drive processes described in build files as targets and extension points dependent upon each other. </p><p>Main usage: build java applications. It can pilot any type of processes which can be described <strong>in terms of targets and tasks.</strong></p><h1 id="1-Writing-a-Simple-BuildFile"><a href="#1-Writing-a-Simple-BuildFile" class="headerlink" title="1. Writing a Simple BuildFile"></a>1. Writing a Simple BuildFile</h1><h2 id="1-1-Intro"><a href="#1-1-Intro" class="headerlink" title="1.1 Intro"></a>1.1 Intro</h2><p>Ant’s buildfile are written in XML. Each buildfile contains one project and as least one target. Targets contain task elements. Each task element of the build file can have an id attribute and can later be referred to by the value supplied to this. </p><p>The structure comes to be: </p><ul><li>project </li><li>target<ul><li>task elements<ul><li>id attribute </li></ul></li></ul></li></ul><h2 id="1-2-Projects"><a href="#1-2-Projects" class="headerlink" title="1.2 Projects"></a>1.2 Projects</h2><p>A project has three attributes: </p><ul><li>name <ul><li>the name of project</li></ul></li><li>default<ul><li>the default target to use when no target is supplied </li></ul></li><li>basedir<ul><li>the base directory from which all path calculations are done. A relative path is resolved relative to the directory containing the buildfile. </li><li>defaults to the parent directory of the buildfile </li></ul></li></ul><h2 id="1-3-Targets"><a href="#1-3-Targets" class="headerlink" title="1.3 Targets"></a>1.3 <a href="https://ant.apache.org/manual/targets.html" target="_blank" rel="noopener">Targets</a></h2><p>It’s a container of tasks that cooperate to reach a desired state during the build process. </p><p>A target can depend on other targets. **You might have a target for compiling, for example, and a target for creating a distributable. You can only build a distributable when you have compiled first, so the “distribute” target depends on the “compile” target. Ant resolves these dependencies</p><pre><code>&lt;target name=&quot;A&quot;/&gt;&lt;target name=&quot;B&quot; depends=&quot;A&quot;/&gt;&lt;target name=&quot;C&quot; depends=&quot;B&quot;/&gt;&lt;target name=&quot;D&quot; depends=&quot;C,B,A&quot;/&gt;</code></pre><p>Suppose we want to execute target D. From its depends attribute, you might think that first target C, then B and then A is executed. Wrong! C depends on B, and B depends on A, so first A is executed, then B, then C, and finally D.</p><p>A target also has the ability to perform its execution if(or unless) a property has been set. </p><pre><code>&lt;target name=&quot;myTarget&quot; depends=&quot;myTarget.check&quot; if=&quot;myTarget.run&quot;&gt;    &lt;echo&gt;Files foo.txt and bar.txt are present.&lt;/echo&gt;&lt;/target&gt;&lt;target name=&quot;myTarget.check&quot;&gt;    &lt;condition property=&quot;myTarget.run&quot;&gt;        &lt;and&gt;            &lt;available file=&quot;foo.txt&quot;/&gt;            &lt;available file=&quot;bar.txt&quot;/&gt;        &lt;/and&gt;    &lt;/condition&gt;&lt;/target&gt;</code></pre><h2 id="1-4-Tasks"><a href="#1-4-Tasks" class="headerlink" title="1.4 Tasks"></a>1.4 Tasks</h2><h3 id="1-4-1-Intro"><a href="#1-4-1-Intro" class="headerlink" title="1.4.1 Intro"></a>1.4.1 Intro</h3><p>Task is a piece of code that can be executed. </p><p>A task can have multiple attributes. The value of an attribute might contain reference to a property. These references will be resolved before the task is executed. </p><p>Task has a common structure: </p><pre><code>&lt;name attribute1=&quot;value1&quot; attribute2=&quot;value2&quot; ... /&gt;</code></pre><p>where name is the name of the task, attributeN is the attribute name, and valueN is the value for this attribute.</p><p>All tasks can have a name attribute, which will be used in the logging messages generated by Ant. </p><h3 id="1-4-2-Built-in-tasks"><a href="#1-4-2-Built-in-tasks" class="headerlink" title="1.4.2 Built-in tasks"></a>1.4.2 Built-in tasks</h3><p><a href="https://ant.apache.org/manual/tasklist.html" target="_blank" rel="noopener">https://ant.apache.org/manual/tasklist.html</a> </p><h3 id="1-4-3-Write-your-own-tasks"><a href="#1-4-3-Write-your-own-tasks" class="headerlink" title="1.4.3 Write your own tasks"></a>1.4.3 Write your own tasks</h3><p><a href="https://ant.apache.org/manual/develop.html#writingowntask" target="_blank" rel="noopener">https://ant.apache.org/manual/develop.html#writingowntask</a></p><h2 id="1-5-Properties"><a href="#1-5-Properties" class="headerlink" title="1.5 Properties"></a>1.5 <a href="https://ant.apache.org/manual/properties.html#if+unless" target="_blank" rel="noopener">Properties</a></h2><p>Properties are an important way to customize a build process or to just provide shortcuts for strings that are used repeatedly inside a buildfile.</p><p>In its most simple form properties are defined in the buildfile (for example by the property task) or might be set outside Ant. <strong>A property has a name and a value</strong>; the name is case-sensitive. Properties may be used in the value of task attributes or in the nested text of tasks that support them. This is done by <strong>placing the property name between “${“ and “}” in the attribute value</strong>. For example, if there is a builddir property with the value “build”, then this could be used in an attribute like this: ${builddir}/classes. This is resolved at run-time as build/classes.</p><pre><code>&lt;project name=&quot;MyProject&quot; default=&quot;dist&quot; basedir=&quot;.&quot;&gt;  &lt;description&gt;    simple example build file  &lt;/description&gt;  &lt;!-- set global properties for this build --&gt;  &lt;property name=&quot;src&quot; location=&quot;src&quot;/&gt;  &lt;property name=&quot;build&quot; location=&quot;build&quot;/&gt;  &lt;property name=&quot;dist&quot; location=&quot;dist&quot;/&gt;  &lt;target name=&quot;init&quot;&gt;    &lt;!-- Create the time stamp --&gt;    &lt;tstamp/&gt;    &lt;!-- Create the build directory structure used by compile --&gt;    &lt;mkdir dir=&quot;${build}&quot;/&gt;  &lt;/target&gt;  &lt;target name=&quot;compile&quot; depends=&quot;init&quot;        description=&quot;compile the source&quot;&gt;    &lt;!-- Compile the Java code from ${src} into ${build} --&gt;    &lt;javac srcdir=&quot;${src}&quot; destdir=&quot;${build}&quot;/&gt;  &lt;/target&gt;  &lt;target name=&quot;dist&quot; depends=&quot;compile&quot;        description=&quot;generate the distribution&quot;&gt;    &lt;!-- Create the distribution directory --&gt;    &lt;mkdir dir=&quot;${dist}/lib&quot;/&gt;    &lt;!-- Put everything in ${build} into the MyProject-${DSTAMP}.jar file --&gt;    &lt;jar jarfile=&quot;${dist}/lib/MyProject-${DSTAMP}.jar&quot; basedir=&quot;${build}&quot;/&gt;  &lt;/target&gt;  &lt;target name=&quot;clean&quot;        description=&quot;clean up&quot;&gt;    &lt;!-- Delete the ${build} and ${dist} directory trees --&gt;    &lt;delete dir=&quot;${build}&quot;/&gt;    &lt;delete dir=&quot;${dist}&quot;/&gt;  &lt;/target&gt;&lt;/project&gt;</code></pre><p>Properties are key-value pair where Apache Ant tries to expand ${key} to value at run time.  In general properties are of global scope, i.e., once they have been defined they are available for any task or target invoked subsequently—it is not possible to set a property in a child build process created via the ant, antcall or subant tasks and make it available to the calling build process, though. </p><h3 id="1-5-2-Built-in-Properties"><a href="#1-5-2-Built-in-Properties" class="headerlink" title="1.5.2 Built-in Properties"></a>1.5.2 Built-in Properties</h3><p>Ant provides access to all system properties as if they had been defined using a <property> task. </p><ul><li>javadoc of <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/System.html#getProperties--" target="_blank" rel="noopener">System.getProperties</a></li><li>basedir: the absolute path of the project’s basedir </li><li>ant.file: the absolute path of the buildfile</li><li>ant.version</li><li>ant.project.name </li></ul><h1 id="2-Concepts-and-Types"><a href="#2-Concepts-and-Types" class="headerlink" title="2. Concepts and Types"></a>2. Concepts and Types</h1><h2 id="2-1-Concepts"><a href="#2-1-Concepts" class="headerlink" title="2.1 Concepts"></a>2.1 Concepts</h2><ul><li>targets and Extension-points </li><li>Properties and PropertyHelpers</li></ul><h2 id="2-2-List-of-Types"><a href="#2-2-List-of-Types" class="headerlink" title="2.2 List of Types"></a>2.2 List of Types</h2><p><a href="https://ant.apache.org/manual/index.html" target="_blank" rel="noopener">https://ant.apache.org/manual/index.html</a> </p><ul><li>Class Fileset </li><li>Description Type </li><li>Directory based Tasks</li><li>Dirset</li><li>Extension Package </li><li>Set of Extension Packages</li><li>FileList</li><li>FileSet </li><li>File Mappers </li><li>FilterChains and FilterReaders</li><li>FilterSet </li><li>MultiRootFileSet </li><li>PatternSet </li><li>Path-like Structures</li><li>Permissions</li><li>PropertySet </li><li>I/O redirectors </li><li>Regexp</li><li>Resources </li><li>Resource Collections </li><li>Selectors </li><li>TarFileSet </li><li>XMLCatalog </li><li>ZipFileSet </li></ul>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Apache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编程范式系列-面向对象编程</title>
      <link href="/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E7%B3%BB%E5%88%97-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B/"/>
      <url>/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E7%B3%BB%E5%88%97-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-函数式编程-vs-面向对象编程"><a href="#1-函数式编程-vs-面向对象编程" class="headerlink" title="1. 函数式编程 vs 面向对象编程"></a>1. 函数式编程 vs 面向对象编程</h1><p>函数式编程主要是把一些功能或逻辑代码通过函数的拼装方式来组织。尽量无状态，但是状态总归是需要一些地方来存放的。</p><p>对于状态和数据的处理，常用面向对象编程这个范式。</p><p>面向对象编程三大特性： </p><ul><li>封装</li><li>继承</li><li>多态</li></ul><h1 id="2-面向对象编程"><a href="#2-面向对象编程" class="headerlink" title="2. 面向对象编程"></a>2. 面向对象编程</h1><p>对象是类的实例，将对象作为程序的基本单元。对象里的程序可以访问及修改对象相关联的数据。</p><p>在程序中包含各种独立又相互调用的对象的思想。面向对象设计中的每一个对象都应该能够<strong>接受数据，处理数据并将数据传达给其它对象</strong>。</p><h2 id="2-1-面向对象的核心理念"><a href="#2-1-面向对象的核心理念" class="headerlink" title="2.1 面向对象的核心理念"></a>2.1 面向对象的核心理念</h2><ol><li>Program to an interface, not an implementation </li></ol><ul><li>使用者不需要知道数据类型，结构，算法的细节</li><li>使用者不需要知道实现细节，只需要知道提供的接口</li><li>利于抽象、封装、动态绑定、多态</li></ul><ol start="2"><li>Favor object composition over class inheritance <ul><li>继承需要给子类暴露一些父类的设计和实现细节</li><li>父类的改变会造成子类也需要改变</li><li>继承更多是为了多态</li></ul></li></ol><h2 id="2-2-tips"><a href="#2-2-tips" class="headerlink" title="2.2 tips"></a>2.2 tips</h2><ol><li>使用接口实现具体类</li><li>其他类耦合的是接口而不是实现类。这就是多态，其增加了程序的可扩展性</li><li>接口编程</li></ol><h2 id="2-3-缺点"><a href="#2-3-缺点" class="headerlink" title="2.3 缺点"></a>2.3 缺点</h2><p>超级重的代码粘合层，大量的封装</p><h1 id="3-控制反转"><a href="#3-控制反转" class="headerlink" title="3. 控制反转"></a>3. 控制反转</h1><p>Ioc—Inversion of Control，即“控制反转”，不是什么技术，而是一种设计思想。在Java开发中，Ioc意味着将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。</p><p>传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对象的创建；IoC容器控制了对象；主要控制了外部资源获取。</p><p>有了IoC容器后，把创建和查找依赖对象的控制权交给了容器，由容器进行注入组合对象，所以对象与对象之间是松散耦合，这样也方便测试，利于功能复用，更重要的是使得程序的整个体系结构变得非常灵活。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程范式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编程范式系列-泛型编程</title>
      <link href="/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E7%B3%BB%E5%88%97-%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/"/>
      <url>/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E7%B3%BB%E5%88%97-%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-起源"><a href="#1-起源" class="headerlink" title="1. 起源"></a>1. 起源</h1><p>编程范式, programming paradigm，是一类典型的编程风格。</p><p>将主流编程语言分为三部分，加上对于编程本质的理解。共四篇文章。</p><ul><li>泛型编程</li><li>函数式编程</li><li>面向对象编程</li><li>编程本质和逻辑编程</li></ul><h1 id="1-1-C语言"><a href="#1-1-C语言" class="headerlink" title="1.1 C语言"></a>1.1 C语言</h1><ul><li>几乎现行的所有编程语言都是从c语言拓展来的，简述c语言的特性：</li></ul><ol><li>静态弱类型语言，使用变量时需要声明变量类型，但类型之间有隐式转换</li><li>typedef 定义类型的别名，达到变量类型的抽象</li><li>不同变量类型可以用结构体组合在一起</li></ol><ul><li>c语言的类型抽象带来的复杂度的提升： </li></ul><pre><code>void swap(void* x, void* y, size_t size){     char tmp[size];     memcpy(tmp, y, size);     memcpy(y, x, size);     memcpy(x, tmp, size);}</code></pre><ul><li>利用宏定义来做泛型</li></ul><pre><code>#define swap(x, y, size) {\    char temp[size]; \    memcpy(temp, &amp;y, size); \    memcpy(&amp;y,   &amp;x, size); \    memcpy(&amp;x, temp, size); \}</code></pre><ul><li>比较大小的宏定义</li></ul><pre><code>#define min(x, y)  （(x)&gt;(y) ? (y) : (x)）</code></pre><p>这里如果比较<code>min(x++, y++)</code>的话，各自会加两次</p><ul><li>小结<br>如果说程序 = 算法 + 数据， C语言会有这几个问题</li></ul><ol><li>一个通用的算法，需要对所处理的数据的数据类型进行适配。但在适配数据类型的过程中，C 语言只能使用 <code>void *</code> 或宏替换的方式。这两种方式导致了类型过于宽松，并带来很多其它问题。</li><li>适配数据类型，需要 C 语言在泛型中加入一个类型的 size，这是因为我们识别不了被泛型后的数据类型，而 C 语言没有运行时的类型识别，所以，只能将这个工作抛给调用泛型算法的程序员来做了</li><li>算法其实是在操作数据结构，而数据则是放到数据结构中的。所以，真正的泛型除了适配数据类型外，还要适配数据结构。最后这个事情导致泛型算法的复杂急剧上升。比如容器内存的分配和释放，不同的数据体可能有非常不一样的内存分配和释放模型，再比如对象之间的复制，要把它存进来我需要有一个复制，这其中又涉及到是深拷贝，还是浅拷贝。</li><li>最后，在实现泛型算法的时候，你会发现自己在纠结哪些东西应该抛给调用者处理，哪些又是可以封装起来。如何平衡和选择，并没有定论，也不好解决。</li></ol><p>比如 C 语言就是过程式的编程语言，像C语言这样的过程式编程语言优点是底层灵活而且高效，特别适合开发运行较快且对系统资源利用率要求较高的程序，但我上面抛出的问题它在后来也没有试图去解决，因为<strong>编程范式</strong>的选择基本已经决定了它的“命运”。</p><h1 id="2-泛型编程"><a href="#2-泛型编程" class="headerlink" title="2. 泛型编程"></a>2. 泛型编程</h1><h2 id="2-1-C-语言"><a href="#2-1-C-语言" class="headerlink" title="2.1 C++ 语言"></a>2.1 C++ 语言</h2><p>C++ 很大程度上是来解决C语言中的各种问题和各种不方便。</p><ul><li>用引用来解决指针的问题。</li><li>用 namespace 来解决名字空间冲突的问题。</li><li>通过 try-catch 来解决检查返回值编程的问题。</li><li>用 class 来解决对象的创建、复制、销毁的问题，从而可以达到在结构体嵌套时可以深度复制的内存安全问题。</li><li>通过重载操作符来达到操作上的泛型</li><li>通过模板 template 和虚函数的多态以及运行时识别来达到更高层次的泛型和多态。</li><li>用 RAII、智能指针的方式，解决了 C 语言中因为需要释放资源而出现的那些非常 ugly 也很容易出错的代码的问题。</li><li>用 STL 解决了 C 语言中算法和数据结构的 N 多种坑。</li></ul><h2 id="2-2-C-语言的泛型编程"><a href="#2-2-C-语言的泛型编程" class="headerlink" title="2.2 C++ 语言的泛型编程"></a>2.2 C++ 语言的泛型编程</h2><p>理想情况下，算法应该与数据结构和类型无关的。各种特殊的数据结构应该能自己做好泛型处理，算法是一个标准的实现。</p><p>对于泛型的抽象，<strong>需要回答的问题是： 如果我们的数据类型符合通用算法，那么对数据类型的最小需求是什么？？？</strong></p><h3 id="2-2-1-C-如何解决泛型问题的？"><a href="#2-2-1-C-如何解决泛型问题的？" class="headerlink" title="2.2.1 C++ 如何解决泛型问题的？"></a>2.2.1 C++ 如何解决泛型问题的？</h3><ol><li>通过类的方式解决</li></ol><ul><li>类里面会有构造函数、析构函数表示这个类的分配和释放。</li><li>还有它的拷贝构造函数，表示了对内存的复制。</li><li>还有重载操作符，像我们要去比较大于、等于、不等于。</li></ul><ol start="2"><li>通过模板达到类型和算法的妥协</li></ol><ul><li>模板有点像 DSL，模板的特化会根据使用者的类型在编译时期生成那个模板的代码。</li><li>模板可以通过一个虚拟类型来做类型绑定，这样不会导致类型转换时的问题。</li></ul><ol start="3"><li>通过虚函数和运行时类识别</li></ol><ul><li>虚函数带来的多态在语义上可以让“同一类”的类型进行泛型。</li><li>运行时类型识别技术可以做到在泛型时对具体类型的特殊处理。</li></ul><p>一个良好的泛型编程需要解决 1） 算法的泛型 2） 类型的泛型  3） 数据结构的泛型</p><h3 id="2-2-2-泛型编程实例"><a href="#2-2-2-泛型编程实例" class="headerlink" title="2.2.2 泛型编程实例"></a>2.2.2 泛型编程实例</h3><ol><li>Search 函数</li></ol><p>不是所有的数据结构都是顺序型的，不能用 <code>for(int i = 0; i &lt; len; i++)</code> 来做抽象的，比如hashtable，二叉树，图就是非顺序型的。这种写法对他们来说没有意义。</p><pre><code>template&lt;typename T, typename Iter&gt; Iter search(Iter pStart, Iter pEnd, T target) {    for(Iter p = pStart; p != pEnd; p++) {        if ( *p == target )             return p;    }    return NULL;}</code></pre><p>可以看到： </p><ul><li>使用 <code>typename T</code> 抽象了数据结构中存储数据的类型</li><li>使用 <code>typename Iter</code>，让不同的数据结构实现自己的迭代器，用这种方式抽象掉了不同类型的数据结构。</li><li>然后，我们对数据容器的遍历使用了Iter中的++方法，这是数据容器需要重载的操作符，这样通过操作符重载也就泛型掉了遍历。</li><li>使用<code>*Iter</code>来取得指针的内容，这也是通过重载*取值操作符来达到的泛型。</li><li>tips: <code>Iter</code> 在实际代码中，是类似于<code>vector&lt;int&gt;::iterator</code> <code>map&lt;int, String&gt;::iterator</code>。是由相应的数据容器来实现和提供的。</li></ul><ol start="2"><li>迭代器</li></ol><pre><code>template &lt;class T&gt;class container {public:    class iterator {    public:        typedef iterator self_type;        typedef T   value_type;        typedef T*  pointer;        typedef T&amp;     reference;        reference operator*();        pointer operator-&gt;();        bool operator==(const self_type&amp; rhs)；        bool operator!=(const self_type&amp; rhs)；        self_type operator++() { self_type i = *this; ptr_++; return i; }        self_type operator++(int junk) { ptr_++; return *this; }        ...        ...    private:        pointer _ptr;    };    iterator begin();    iterator end();    ...    ...};</code></pre><ul><li>一个迭代器需要与一个容器在一起，因为里面是对这个容器的具体的代码实现</li><li>需要重载一些操作符</li><li>需要typedef一些类型，搞死容器内的数据的实际类型是什么样子的</li><li>begin() end()基本操作</li></ul><ol start="3"><li>Sum（）</li></ol><pre><code>template &lt;class Iter&gt; typename Iter::value_type sum(Iter start, Iter end, T init) {    typename Iter::value_type result = init;    while (start != end) {        result = result + *start;        start++;    }    return result;}</code></pre><ol start="4"><li>reduce()</li></ol><pre><code>template&lt;class Iter, class T, class Op&gt; T reduce (Iter start, Iter end, T init, Op op) {    T result = init;    while ( start != end ) {        result = op( result, *start );        start++;    }    return result;}</code></pre><h2 id="2-2-动态类型语言的泛型编程"><a href="#2-2-动态类型语言的泛型编程" class="headerlink" title="2.2 动态类型语言的泛型编程"></a>2.2 动态类型语言的泛型编程</h2><p>在编程世界，我们需要处理好两件事情： </p><ol><li>编程语言中的类型问题</li><li>对真实世界中业务代码的抽象、重用和拼装</li></ol><h3 id="2-2-1-类型系统"><a href="#2-2-1-类型系统" class="headerlink" title="2.2.1 类型系统"></a>2.2.1 类型系统</h3><p>在计算机科学中，类型系统用于定义如何将编程语言中的数值和表达式归类为许多不同的类型，以及如何操作这些类型，还有这些类型如何互相作用。类型可以确认一个值或者一组值具有特定的意义和目的。</p><p>类型系统在各种语言之间很不同，存在于编译时期的语法，以及运行时期的操作实现方式。</p><p>程序语言的类型系统主要提供如下功能： </p><ul><li>程序语言的安全性</li></ul><p>使用类型可以让编译器侦测一些代码的错误。例如：可以识别出一个错误无效的表达式。如：<code>“Hello, World” + 3</code>这样的不同数据类型间操作的问题。强类型语言提供更多的安全性，但是并不能保证绝对的安全。</p><ul><li>利于编译器的优化</li></ul><p>静态类型语言的类型声明，可以让编译器明确地知道程序员的意图。因此，编译器就可以利用这一信息做很多代码优化工作。例如：如果我们指定一个类型是int,那么编译就知道，这个类型会以4个字节的倍数进行对齐，编译器就可以非常有效地利用更有效率的机器指令。 </p><ul><li>代码的可读性</li></ul><p>有类型的编程语言，可以让代码更易读和更易维护。代码的语义也更清楚，代码模块的接口（如函数）也更丰富和更清楚。</p><ul><li>抽象化</li></ul><p>类型允许程序设计者对程序以较高层次的方式思考，而不是烦人的低层次实现。例如，我们使用整型或是浮点型来取代底层的字节实现，我们可以将字符串设计成一个值，而不是底层的字节的数组。从高层上来说，类型可以用来定义不同模块间的交互协议，比如函数的入参类型和返回类型，从而可以让接口更有语义，而且不同的模块数据交换更为直观和易懂。</p><p>在动态语言中，一个变量的类型是由运行时的解释器来动态标记的，这样就可以动态地和底层的计算机指令或内存布局对应起来。</p><h1 id="3-泛型的本质"><a href="#3-泛型的本质" class="headerlink" title="3. 泛型的本质"></a>3. 泛型的本质</h1><ul><li>类型是对内存的一种抽象。不同的类型，会有不同的内存布局和内存分配的策略。</li><li>不同的类型，有不同的操作。所以，对于特定的类型，也有特定的一组操作。</li></ul><blockquote><p>Generic programming centers around the idea of abstracting from concrete, efficient algorithms to obtain generic algorithms that can be combined with different data representations to produce a wide variety of useful software.</p></blockquote><p>屏蔽掉数据和操作数据的细节，让算法更为通用，让编程者更多地关注算法结构，而不是在算法中处理不同的数据类型。</p><p>要做到泛型，我们需要： </p><ul><li>标准化掉类型的内存分配、释放和访问。</li><li>标准化掉类型的操作。比如：比较操作，I/O 操作，复制操作……</li><li>标准化掉数据容器的操作。比如：查找算法、过滤算法、聚合算法……</li><li>标准化掉类型上特有的操作。需要有标准化的接口来回调不同类型的具体操作……</li></ul><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><p><a href="https://time.geekbang.org/column/48" target="_blank" rel="noopener">左耳听风的极客时间专栏</a></p><p><a href="https://blog.csdn.net/Hackbuteer1/article/details/7558868" target="_blank" rel="noopener">虚函数</a></p><p><a href="https://lxwei.github.io/posts/262.html" target="_blank" rel="noopener">从源代码到可执行文件</a></p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程范式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编程范式系列-基于原型的编程</title>
      <link href="/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E7%B3%BB%E5%88%97-%E5%9F%BA%E4%BA%8E%E5%8E%9F%E5%9E%8B%E7%9A%84%E7%BC%96%E7%A8%8B/"/>
      <url>/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E7%B3%BB%E5%88%97-%E5%9F%BA%E4%BA%8E%E5%8E%9F%E5%9E%8B%E7%9A%84%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>基于原型的编程，是指没有class化，直接使用对象的编程方式。又叫做基于实例的编程，主流语言是JavaScript。 </p><h1 id="1-与传统面向对象编程的比较"><a href="#1-与传统面向对象编程的比较" class="headerlink" title="1. 与传统面向对象编程的比较"></a>1. 与传统面向对象编程的比较</h1><h2 id="1-1-关注对象实例行为，而后对类进行划分"><a href="#1-1-关注对象实例行为，而后对类进行划分" class="headerlink" title="1.1 关注对象实例行为，而后对类进行划分"></a>1.1 关注对象实例行为，而后对类进行划分</h2><p>在基于类的编程当中，对象总共有两种类型。</p><ol><li>类</li></ol><p>定义了对象的基本布局，函数特性。—-&gt; 是行为和结构的集合，对所有的接口来说这些类的行为和结构都是相同的。</p><ol start="2"><li>接口</li></ol><p>是可以使用的对象,定义了一些行为，基于特定类的样式。</p><p>在这种模式下，类的划分是基于行为和结构，而不是状态。原型编程的主张者提倡关注一系列对象实例的行为，而后关注将其划分到使用方式相似的原型对象。实际上说，不同之处在于对于状态的看重程度。</p><h2 id="1-2-创建实例的时间"><a href="#1-2-创建实例的时间" class="headerlink" title="1.2 创建实例的时间"></a>1.2 创建实例的时间</h2><p>对于基于类的系统，新的实例是通过类构造器以及参数来构造，实例是由类的行为和结构来定义的。</p><p>对于基于原型的系统，可以通过复制已有的对象或者通过扩展空对象来创建，是在<strong>运行时</strong>对原型进行修改的。</p><h1 id="2-JavaScript-原型的概念"><a href="#2-JavaScript-原型的概念" class="headerlink" title="2. JavaScript 原型的概念"></a>2. JavaScript 原型的概念</h1><pre><code>var foo = {name: &quot;foo&quot;, one: 1, two: 2};var bar = {three: 3};bar.__proto__ = foo; // foo is...// If we try to access foo&#39;s properties from bar // from now on, we&#39;ll succeed. bar.one // Resolves to 1.// The child object&#39;s properties are also accessible.bar.three // Resolves to 3.// Own properties shadow prototype propertiesbar.name = &quot;bar&quot;;foo.name; // unaffected, resolves to &quot;foo&quot;bar.name; // Resolves to &quot;bar&quot;</code></pre><p>每个对象都有个<code>_proto_</code>属性，通过赋值操作，bar的原型现在是foo了。因此我们可以在bar里面访问foo的属性。</p><h2 id="2-1-区分-proto-以及prototype"><a href="#2-1-区分-proto-以及prototype" class="headerlink" title="2.1 区分_proto_以及prototype"></a>2.1 区分<code>_proto_</code>以及<code>prototype</code></h2><ul><li><p><code>_proto_</code><br>主要安放在一个实际的对象当中，用它来产生一个链接，用于寻找方法名或属性。用于链接原型的一个指针。</p></li><li><p><code>prototype</code><br>当用new来构造一个新的对象的时候构造<code>_proto_</code>的时候用的，是构造函数的一个属性。</p></li></ul><h2 id="2-2-对象的表现形式"><a href="#2-2-对象的表现形式" class="headerlink" title="2.2 对象的表现形式"></a>2.2 对象的表现形式</h2><ul><li>Object </li><li>Function </li></ul><h1 id="3-Conclusion"><a href="#3-Conclusion" class="headerlink" title="3. Conclusion"></a>3. Conclusion</h1><p>其实是一种委托方式，通过一个序列的指针来定位属性，寻找数据。可以带来运行时的灵活性，数据方法都可以进行修改了。 </p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程范式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>编程范式系列-函数式编程</title>
      <link href="/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E7%B3%BB%E5%88%97-%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"/>
      <url>/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E7%B3%BB%E5%88%97-%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-从c-到函数式编程"><a href="#1-从c-到函数式编程" class="headerlink" title="1. 从c++到函数式编程"></a>1. 从c++到函数式编程</h1><p>C++很大程度上解决了C语言中的各种问题和不便，尤其是通过类、模板、虚函数和运行时识别，解决了C语言的泛型编程问题。函数式编程 -&gt; 更为抽象的泛型。</p><h1 id="2-函数式编程"><a href="#2-函数式编程" class="headerlink" title="2. 函数式编程"></a>2. 函数式编程</h1><h2 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h2><p>函数式编程只关心**定义的输入数据和输出数据相关的关系，数学表达式里面其实是在做一种映射(mapping)，输入的数据和输出的数据关系是什么样子的，是用函数来定义的。</p><h2 id="2-2-特征"><a href="#2-2-特征" class="headerlink" title="2.2 特征"></a>2.2 特征</h2><h3 id="2-2-1-优势"><a href="#2-2-1-优势" class="headerlink" title="2.2.1 优势"></a>2.2.1 优势</h3><ul><li>stateless </li></ul><p>不维护任何状态，给数据，我做处理，然后给你处理完的数据，中间的过程量用完就没了</p><p>无状态的话并行执行无害了，重构代码无伤害</p><ul><li>immutable</li></ul><p>输入数据动了，输出数据也会变，意味着新的数据集会被返回</p><ul><li>惰性求值</li></ul><p>表达式不在它被绑定到变量之后立即求值，而是在该值被取用的时候求值。</p><ul><li><p>确定性</p><p>f(x)=y, 这个函数无论在什么场景下，都会得到同样的结果，这个我们称之为函数的确定性。而不是像程序中的很多函数那样，同一个参数，却会在不同的场景下计算出不同的结果。所谓不同的场景，就是我们的函数会根据运行中的状态信息的不同而发生变化。</p><h3 id="2-2-2-劣势"><a href="#2-2-2-劣势" class="headerlink" title="2.2.2 劣势"></a>2.2.2 劣势</h3><ul><li>数据复制很严重</li><li>函数式编程抽象度更高，实现方式上，函数套函数，函数返回函数，函数里定义函数… </li></ul></li></ul><h2 id="2-3-函数式编程用到的技术"><a href="#2-3-函数式编程用到的技术" class="headerlink" title="2.3 函数式编程用到的技术"></a>2.3 函数式编程用到的技术</h2><ul><li>first class function 头等函数</li></ul><p>把函数当成变量来使用。可以像变量一样被创建、修改，并当成变量一样传递、返回，或者是在函数中嵌套函数 </p><ul><li>tail recursion optimization 尾递归优化</li></ul><p>如果递归很深的话，stack受不了，会导致性能大幅度下降。因此我们使用尾递归优化技术，每次递归的时候都会重用stack</p><ul><li><p>map &amp; reduce</p></li><li><p>pipeline </p></li></ul><p>将函数实例成一个个action，然后将一组action放到一个数组或列表中，再把数据传给这个action list，数据就被各个函数所操作，最终得到我们想要的结果。</p><ul><li>recursing</li></ul><p>将复杂问题用简单的代码描述出来。</p><ul><li>currying 颗粒化</li></ul><p>将一个函数的多个参数分解成多个函数，然后将函数多层封装起来，每层函数都返回一个函数去接收下一个参数，这可以简化函数的多个参数。</p><ul><li>higher order function 高阶函数</li></ul><p>函数当参数，把传入的函数做一个封装，然后返回这个封装函数</p><h2 id="2-4-函数式编程的理念"><a href="#2-4-函数式编程的理念" class="headerlink" title="2.4 函数式编程的理念"></a>2.4 函数式编程的理念</h2><pre><code>// 非函数式，有状态的int cnt;void increment() {    cnt ++;}// 函数式， 无状态的int increment(int cnt) {    return cnt + 1;}</code></pre><ul><li>把函数当成变量来用，关注描述问题而不是怎么实现的，可以让代码更易读</li><li>因为函数返回里面的这个函数，所以函数关注的是表达式，关注的是描述这个问题，而不是如何实现的</li></ul><h3 id="2-4-1-函数式编程例子"><a href="#2-4-1-函数式编程例子" class="headerlink" title="2.4.1  函数式编程例子"></a>2.4.1  函数式编程例子</h3><p>下面我们看一下相关的示例。比如，我们有 3 辆车比赛，简单起见，我们分别给这 3 辆车有 70% 的概率可以往前走一步，一共有 5 次机会，然后打出每一次这 3 辆车的前行状态。</p><pre><code>// Imperative Programming from random import randomtime = 5car_positions = [1, 1, 1]while time:    # decrease time    time -= 1    print &#39;&#39;    for i in range(len(car_positions)):        # move car        if random() &gt; 0.3:            car_positions[i] += 1        # draw car        print &#39;-&#39; * car_positions[i]</code></pre><p>下面这个例子是将循环分成了几个小函数，但是相互之间的参数是共享的，函数是有状态的。</p><pre><code>// make it to some function model from random import randomdef move_cars():    for i, _ in enumerate(car_positions):        if random() &gt; 0.3:            car_positions[i] += 1def draw_car(car_position):    print &#39;-&#39; * car_positiondef run_step_of_race():    global time    time -= 1    move_cars()def draw():    print &#39;&#39;    for car_position in car_positions:        draw_car(car_position)time = 5car_positions = [1, 1, 1]while time:    run_step_of_race()    draw()</code></pre><p>函数式写法</p><pre><code>from random import randomdef move_cars(car_positions):    return map(lambda x: x + 1 if random() &gt; 0.3 else x, car_positions)def output_car(car_position):    return &#39;-&#39; * car_positiondef run_step_of_race(state):    return {&#39;time&#39;: state[&#39;time&#39;] - 1, &#39;car_positions&#39;: move_cars(state[&#39;car_positions&#39;])}def draw(state):    print &#39;&#39;    print &#39;\n&#39;.join(map(output_car, state[&#39;car_positions&#39;]))def race(state):    draw(state)    if state[&#39;time&#39;]:        race(run_step_of_race(state))race({&#39;time&#39;: 5,      &#39;car_positions&#39;: [1, 1, 1]})</code></pre><p>上面的代码依然把程序的逻辑分成了函数。不过这些函数都是函数式的，它们有三个特点：它们之间没有共享的变量；函数间通过参数和返回值来传递数据；在函数里没有临时变量。</p><h2 id="2-5-函数式语言常用函数"><a href="#2-5-函数式语言常用函数" class="headerlink" title="2.5 函数式语言常用函数"></a>2.5 函数式语言常用函数</h2><ol><li>map()</li><li>reduce()</li><li>filter()</li></ol><p>好处： </p><ol><li>数据集、对数据的操作和返回值都放在了一起。</li><li>没有了循环体，就可以少了些临时用来控制程序执行逻辑的变量，也少了把数据倒来倒去的控制逻辑。</li><li>代码变成了在描述你要干什么，而不是怎么干</li></ol><h3 id="2-5-1-E-G"><a href="#2-5-1-E-G" class="headerlink" title="2.5.1 E.G"></a>2.5.1 E.G</h3><p>process: </p><ol><li>找出偶数</li><li>乘3</li><li>转成字符串</li></ol><pre><code>def process(num):# filter out non-evensif num % 2 != 0:    returnnum = num * 3num = &#39;The Number: %s&#39; % numreturn numnums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]for num in nums:    print process(num)# 输出：# None# The Number: 6# None# The Number: 12# None# The Number: 18# None# The Number: 24# None# The Number: 30</code></pre><p>pipeline way</p><p>使用了yield关键字，返回generator，一个可迭代对象 ，并没有真正的执行函数。意味着只有其返回的迭代对象被迭代时，yield函数才会真正运行</p><pre><code>def even_filter(nums):for num in nums:    if num % 2 == 0:        yield numdef multiply_by_three(nums):    for num in nums:        yield num * 3def convert_to_string(nums):    for num in nums:        yield &#39;The Number: %s&#39; % numnums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]pipeline = convert_to_string(multiply_by_three(even_filter(nums)))for num in pipeline:    print num# 输出：# The Number: 6# The Number: 12# The Number: 18# The Number: 24# The Number: 30</code></pre><p>使用map &amp; reduce</p><pre><code>def even_filter(nums):return filter(lambda x: x%2==0, nums)def multiply_by_three(nums):    return map(lambda x: x*3, nums)def convert_to_string(nums):    return map(lambda x: &#39;The Number: %s&#39; % x,  nums)nums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]pipeline = convert_to_string(               multiply_by_three(                   even_filter(nums)               )            )for num in pipeline:    print num</code></pre><p>pipeline model </p><pre><code>class Pipe(object):def __init__(self, func):    self.func = funcdef __ror__(self, other):    def generator():        for obj in other:            if obj is not None:                yield self.func(obj)    return generator()@Pipedef even_filter(num):    return num if num % 2 == 0 else None@Pipedef multiply_by_three(num):    return num*3@Pipedef convert_to_string(num):    return &#39;The Number: %s&#39; % num@Pipedef echo(item):    print item    return itemdef force(sqs):    for item in sqs: passnums = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]force(nums | even_filter | multiply_by_three | convert_to_string | echo)</code></pre><h2 id="3-修饰器模式-decorator"><a href="#3-修饰器模式-decorator" class="headerlink" title="3. 修饰器模式 decorator"></a>3. 修饰器模式 decorator</h2><p>Python 用一个函数来构造另一个函数</p><pre><code>def hello(fn):    def wrapper():        print &quot;hello, %s&quot; % fn.__name__        fn()        print &quot;goodbye, %s&quot; % fn.__name__    return wrapper@hellodef Hao():    print &quot;i am Hao Chen&quot;Hao()// code result:$ python hello.pyhello, Haoi am Hao Chengoodbye, Hao</code></pre><p>Hello 注解就是我们前面定义的hello函数，hello函数中需要一个参数fn，用来做回调，hello函数中返回了一个inner函数wrapper，回调了传进来的fn</p><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><p>函数式编程，将运算过程尽量写成一系列嵌套的函数调用，关注的是做什么而不是怎么做，被称为声明式编程。以stateless和immutable为主要特点。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 编程范式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>笔记 - 领域驱动设计 by Eric Evans</title>
      <link href="/%E7%AC%94%E8%AE%B0-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1-by-Eric-Evans/"/>
      <url>/%E7%AC%94%E8%AE%B0-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1-by-Eric-Evans/</url>
      
        <content type="html"><![CDATA[<p>在看博文的时候看到了关于DDD的内容，确实发现在工程上碰到了一些些问题，关于核心领域，关于领域驱动，毕竟技术是为了解决实际问题的，只有在对某个领域有着较深的理解的前提下，才能做出更有利于维护，更容易扩展的软件。</p><p>本书想说的就是在大规模工程上，如何来控制整体的复杂性，我们需要有一个良好的领域模型，不仅仅停留在领域的表面，而是要透过表象抓住领域的实质结构，从而为软件开发人员提供他们所需要的支持。</p><p>软件的负责性并不仅仅在技术上，而是来自领域本身，用户的活动或业务。这种复杂性我们需要在设计上考虑到的。</p><p>领域涉及的前提： </p><ol><li>在大多数软件项目当中，主要的焦点应该是领域和领域逻辑</li><li>复杂的领域设计应该基于模型</li></ol><p>领域驱动设计的实质是<strong>消化吸收大量知识，最后产生一个反映深层次领域知识并聚焦于关键概念的模型</strong></p><h1 id="1-让领域模型发挥作用-领域驱动开发的基本目标"><a href="#1-让领域模型发挥作用-领域驱动开发的基本目标" class="headerlink" title="1. 让领域模型发挥作用 - 领域驱动开发的基本目标"></a>1. 让领域模型发挥作用 - 领域驱动开发的基本目标</h1><h2 id="1-1-几个基本问题"><a href="#1-1-几个基本问题" class="headerlink" title="1.1 几个基本问题"></a>1.1 几个基本问题</h2><ul><li>什么是模型？ <ul><li>模型是一种简化，是对现实的解释，并把与解决问题密切相关的方面抽象出来，而忽略无关的细节。  </li><li>模型是为了解决信息超载问题的工具</li><li>模型是一种知识形式，它对知识进行有选择的简化和有目的的结构化 </li></ul></li><li>如何界定领域？<ul><li>每个软件程序的目的都是为了执行某项活动，或者满足用户的某种需求。用户会将软件程序应用在某个主题区域当中，这个区域就叫做软件的领域。</li></ul></li><li>软件的核心是什么？ <ul><li>用户解决领域相关的问题的能力 </li></ul></li></ul><h2 id="1-2-如何有效消化知识？"><a href="#1-2-如何有效消化知识？" class="headerlink" title="1.2 如何有效消化知识？"></a>1.2 如何有效消化知识？</h2><h3 id="1-2-1-有效建模的要素"><a href="#1-2-1-有效建模的要素" class="headerlink" title="1.2.1 有效建模的要素"></a>1.2.1 有效建模的要素</h3><ul><li>模型与实现的绑定  <ul><li>在模型与实现之间建立早期连接，在后续的所有迭代当中维护该原型</li></ul></li><li>获得一种基于模型的语言<ul><li>业务和技术上的对应的模型的熟悉，对于名词的意思达成一致</li></ul></li><li>开发一个蕴含丰富知识的模型</li><li>提炼模型 - 保证模型整体结构的精炼</li></ul><h3 id="1-2-2-知识消化"><a href="#1-2-2-知识消化" class="headerlink" title="1.2.2 知识消化"></a>1.2.2 知识消化</h3><p>在大量信息当中探寻有用的部分，由开发人员和领域专家组成的团队共同协作，收集信息并寻找对信息有意义的简化视图。</p><p>在你的架构当中应当本身就有领域的特征，即某部分需要能够清晰的反应商业上的可能需求和可能的拓展。这种东西如果在刚刚开始的时候就能被研究到，那以后就会很方便了。</p><p>开发出来的软件是需要能够反应出领域专家的思考方式的，我们用自己的技术来解决他们的问题，用代码构建他们的思维体系。</p><h2 id="1-3-语言的交流和使用"><a href="#1-3-语言的交流和使用" class="headerlink" title="1.3 语言的交流和使用"></a>1.3 语言的交流和使用</h2><ul><li>模型 <ul><li>头脑中形成的与项目有关的概念集合，用术语和关系反映了领域的深层含义。这些术语和关系提供了模型语言的语义</li><li>不仅仅限于UML图，需要充分利用各种交流手段，以提高代码本身和测试的沟通能力</li></ul></li></ul><h3 id="1-3-1-模式：-Ubiquitous-Language"><a href="#1-3-1-模式：-Ubiquitous-Language" class="headerlink" title="1.3.1 模式： Ubiquitous Language"></a>1.3.1 模式： Ubiquitous Language</h3><p>需要一种通用的，共享的团队语言，这种语言应该是时刻进行检验的。语言上的鸿沟，即我们对同样的词语是没有同样的认识的，这就导致了当我们对某个领域不够熟悉的时候，对于各种概念的理解是有很大量的欠缺的。而各类人在工作的时候也很容易为了方便创建小范围达成共识的语言，但是在这个小范围之外是没有人知道和了解这究竟是什么意思的。</p><ul><li>为什么需要这种公共语言？<ul><li>将团队的沟通和软件实现紧密联系起来</li><li>避免因为对于概念不同理解带来的交流沟通成本陡增的问题</li></ul></li><li>词汇表<ul><li>类名称</li><li>主要操作</li><li>术语 <ul><li>讨论模型当中已经明确的规则</li><li>或者是模型上的高级组织原则</li></ul></li></ul></li><li>tips<ul><li>模型作为语言的中心，确保团队在所有交流活动和代码中坚持使用这种语言</li><li>通过尝试不同的表示方法来消除难点，然后重构代码，并对类、方法和模块重新命名，以便与新模型一致。</li><li>需要对各种词语，无论是在工程上的，还是在商业上的，都有更好的理解</li><li>要认识到Uniquitous Language当中的更改就是对模型的更改。</li></ul></li></ul><h3 id="1-3-2-文档和图"><a href="#1-3-2-文档和图" class="headerlink" title="1.3.2 文档和图"></a>1.3.2 文档和图</h3><ul><li>UML图有用，但是会容易是你陷入细节当中</li><li>图应该是一种直观的给你综合概念和视角的工具，而不是落于细节当中。</li><li>设计的重要细节应该在代码当中体现出来</li></ul><ul><li>书面设计文档<ul><li>提供稳定和共享的交流</li><li>文档应该作为代码和口头交流的补充</li></ul></li><li>解释性模型<ul><li>没有UML 没有类</li><li>就是单纯的用图来描述商业上的使用案例</li></ul></li></ul><h1 id="2-模型驱动设计的构造块-阐述核心最佳实践"><a href="#2-模型驱动设计的构造块-阐述核心最佳实践" class="headerlink" title="2. 模型驱动设计的构造块 - 阐述核心最佳实践"></a>2. 模型驱动设计的构造块 - 阐述核心最佳实践</h1><h1 id="3-通过重构加深理解-如何将构造块装配为实用的模型"><a href="#3-通过重构加深理解-如何将构造块装配为实用的模型" class="headerlink" title="3. 通过重构加深理解 - 如何将构造块装配为实用的模型"></a>3. 通过重构加深理解 - 如何将构造块装配为实用的模型</h1><h1 id="4-战略设计-讨论在复杂系统交互中的情况"><a href="#4-战略设计-讨论在复杂系统交互中的情况" class="headerlink" title="4. 战略设计 - 讨论在复杂系统交互中的情况"></a>4. 战略设计 - 讨论在复杂系统交互中的情况</h1>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System Design </tag>
            
            <tag> BackEnd </tag>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习-高性能架构模式</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E9%AB%98%E6%80%A7%E8%83%BD%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E9%AB%98%E6%80%A7%E8%83%BD%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>高性能架构模式，本文会总结业界相对比较成熟的各种架构模式，大部分情况下，我们会基于这些已有的成熟模式，结合业务和团队的具体情况来进行一定的优化或调整。</p><p>很多情况下高性能的设计最核心的部分就是关系数据库的设计。单个数据库在当前情况下是很难满足业务需求的了，必须考虑<strong>数据库集群</strong>的方式来提升性能。高性能架构，其关键点就在于数据库层如何实现高性能，有很多种方式，先来介绍读写分离原理。</p><h1 id="1-高性能数据库集群-读写分离"><a href="#1-高性能数据库集群-读写分离" class="headerlink" title="1. 高性能数据库集群 - 读写分离"></a>1. 高性能数据库集群 - 读写分离</h1><p>读写分离的基本原理就是将数据库读写操作分散到不同的节点上。<br><img src="https://i.loli.net/2020/02/04/DHT92UafyWt4hZx.png" alt="fig1.png"></p><h2 id="1-1-基本实现-主从集群"><a href="#1-1-基本实现-主从集群" class="headerlink" title="1.1 基本实现 - 主从集群"></a>1.1 基本实现 - 主从集群</h2><ul><li>数据库服务器搭建主从集群，一主一从到一主多从皆可。</li><li>数据库主机负责读写操作，从机只负责读操作</li><li>数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了所有的业务数据</li><li>业务服务器将写操作发给数据库主机，将读操作发给数据库从机</li></ul><p>注意这里实现的主从集群，而不是主备集群，主从，从属的还是要接收请求的，主备中的备是完全的备用目的，基本不会有流量。</p><h2 id="1-2-主从复制延迟"><a href="#1-2-主从复制延迟" class="headerlink" title="1.2 主从复制延迟"></a>1.2 主从复制延迟</h2><p>以 MySQL 为例，主从复制延迟可能达到 1 秒，如果有大量数据同步，延迟 1 分钟也是有可能的。主从复制延迟会带来一个问题：如果业务服务器将数据写入到数据库主服务器后立刻（1 秒内）进行读取，此时读操作访问的是从机，主机还没有将数据复制过来，到从机读取数据是读不到最新数据的，业务上就可能出现问题。例如，用户刚注册完后立刻登录，业务服务器会提示他“你还没有注册”，而用户明明刚才已经注册成功了。</p><p>解决复制延迟的常见方法：</p><ul><li>写操作以后的读操作指定发给数据库主服务器<ul><li>和业务强绑定，容易发生bug</li></ul></li><li>读从机失败之后再读一次主机<ul><li>二次读取和业务无绑定，只需要对底层数据库访问的API进行封装即可，实现代价小</li><li>不足之处是如果有大量二次读取，那么主机压力会很大，可能会导致崩溃</li><li>关键业务读写操作全部指向主机，非关键业务采用读写分离</li></ul></li></ul><h2 id="1-3-分配机制-如何区分读写操作，访问不同的数据库服务器"><a href="#1-3-分配机制-如何区分读写操作，访问不同的数据库服务器" class="headerlink" title="1.3 分配机制 - 如何区分读写操作，访问不同的数据库服务器"></a>1.3 分配机制 - 如何区分读写操作，访问不同的数据库服务器</h2><h3 id="1-3-1-程序代码封装"><a href="#1-3-1-程序代码封装" class="headerlink" title="1.3.1 程序代码封装"></a>1.3.1 程序代码封装</h3><p>指在代码中抽象出一个数据访问层，实现读写分离的操作和数据库服务器的连接管理。例如基于Hibernate进行简单封装</p><p><img src="https://i.loli.net/2020/02/04/MjT7sUolRfiI1x4.png" alt="fig2.png"></p><ul><li>实现简单，可以根据业务做较多的定制化功能</li><li>每个编程语言都要自己实现一次，没法通用，如果一个业务包含多个编程语言的多个子系统，那么重复开发工作量比较大</li><li>故障情况下，如果主从切换，那么所有系统都很可能需要修改配置并重启</li></ul><h3 id="1-3-2-中间件封装"><a href="#1-3-2-中间件封装" class="headerlink" title="1.3.2 中间件封装"></a>1.3.2 中间件封装</h3><p>指独立出一套系统来，实现读写操作分离和数据库服务器连接的管理。中间件对业务服务器提供SQL兼容的协议，业务服务器无须自己进行读写分离。对于业务服务器来说，访问中间件</p><p><img src="https://i.loli.net/2020/02/04/26cDtZv1Ia5rSye.png" alt="fig3.png"></p><ul><li>能够支持多种编程语言，因为中间件对业务服务器提供的是标准SQL接口</li><li>中间件要支持完整的SQL语法和数据库服务器的协议，实现复杂，bug会比较多，需要较长时间才可以稳定下来</li><li>中间件自己不执行读写，但是所有数据库的操作请求都要经过中间件，所以对于性能有很高的要求</li><li>数据库主从切换对业务服务器无感知，数据库中间件可以探测数据库服务器的主从状态</li></ul><p>现在市面上有的中间件，MySQL Router, Atlas </p><h1 id="2-分库分表"><a href="#2-分库分表" class="headerlink" title="2. 分库分表"></a>2. 分库分表</h1><p>读写分离可以分散数据库读写操作的压力，但没有分散存储压力，当数据量达到千万级别的时候，单台数据库服务器的存储能力会成为系统的瓶颈, 这体现在：</p><ul><li>数据量过大，读写性能会下降；即使有索引，索引也会变大，性能同样会下降</li><li>数据文件会变得很大，数据库北非和恢复需要耗费很长时间</li><li>数据文件越大，极端情况下丢失数据的风险就越高</li></ul><p>基于上述原因，单个数据库服务器存储的数据量不能太大，需要控制在一定的范围内。将存储分散到多台数据库服务器上。</p><h2 id="2-1-业务分库"><a href="#2-1-业务分库" class="headerlink" title="2.1 业务分库"></a>2.1 业务分库</h2><blockquote><p>业务分库指的是按照业务模块将数据分散到不同的数据库服务器。</p></blockquote><p>譬如一个电商网站，将用户数据，商品数据，订单数据分开放到三台不同的数据库服务器上。虽然业务分库能够分散存储和访问的压力，但是也带来了新的问题。</p><h3 id="2-1-1-join操作问题"><a href="#2-1-1-join操作问题" class="headerlink" title="2.1.1 join操作问题"></a>2.1.1 join操作问题</h3><p>原先在一个表里的数据现在分散到了多个表当中，这就导致无法使用SQL的join来进行查询了。</p><h3 id="2-1-2-事务问题"><a href="#2-1-2-事务问题" class="headerlink" title="2.1.2 事务问题"></a>2.1.2 事务问题</h3><p>原本在同一个数据库中不同的表可以在同一个事务中修改，业务分库以后，表分散到了不同的数据库当中，无法通过事务统一修改。 尽管有一个分布式事务的解决方案，但性能太低，与高性能的存储的目标是相违背的。</p><h3 id="2-1-3-成本问题"><a href="#2-1-3-成本问题" class="headerlink" title="2.1.3 成本问题"></a>2.1.3 成本问题</h3><p>一台变多台</p><h2 id="2-2-业务分表"><a href="#2-2-业务分表" class="headerlink" title="2.2 业务分表"></a>2.2 业务分表</h2><p>将不同业务数据分散存储到不同的数据库服务器，能够支撑百万甚至千万用户规模的业务，但如果业务继续发展，同一业务的单表数据也会达到单台数据库服务器的处理瓶颈。例如，淘宝的几亿用户数据，如果全部存放在一台数据库服务器的一张表中，肯定是无法满足性能要求的，此时就需要对单表数据进行拆分。</p><p>单表数据的拆分有两种方式： 垂直分表和水平分表</p><h3 id="2-2-1-垂直分表"><a href="#2-2-1-垂直分表" class="headerlink" title="2.2.1 垂直分表"></a>2.2.1 垂直分表</h3><p>原先比如是id, name, age, sex, nickname, 垂直分表以后可以变成</p><ul><li>id, name, age</li><li>id, sex, nickname </li></ul><p>也会带来复杂性，即表操作的数量要增加，原来的一次查询现在要变成多次查询了</p><h3 id="2-2-2-水平分表"><a href="#2-2-2-水平分表" class="headerlink" title="2.2.2 水平分表"></a>2.2.2 水平分表</h3><p>用2.2.1的例子来说明的话，会包含一样的attributes，只是总共行数变le</p><p>水平分表以后，某条数据具体属于哪个切分以后的子表，需要依靠路由算法来进行计算</p><ul><li>范围路由<ul><li>使用用户ID等分段</li><li>好处<ul><li>随数据增加平滑的扩充新表</li></ul></li><li>坏处<ul><li>分布不均</li></ul></li></ul></li><li>Hash路由<ul><li>选取某个列的值进行Hash运算，然后根据Hash结果分散到不同的数据表当中</li><li>复杂点<ul><li>初始表的数量选取，太多维护麻烦，太少可能会让单表性能存在问题</li><li>用了Hash以后重Hash(增加表数量)会非常麻烦</li></ul></li><li>好处  分布均匀</li></ul></li><li>配置路由<ul><li>路由表，用独立的表来记录路由信息 </li><li>缺点就是会多查询一次，先看了一眼路由表嘛</li></ul></li></ul><h1 id="3-高性能NoSQL"><a href="#3-高性能NoSQL" class="headerlink" title="3. 高性能NoSQL"></a>3. 高性能NoSQL</h1><p>关系型数据库存在问题：</p><ul><li>关系数据库存储的是行记录，无法存储数据结构</li><li>关系数据库的schema扩展不方便<ul><li>schema是强约束的，操作不存在的列会报错，业务变化时扩充列也会比较麻烦，需要执行DDL (data definition language  create, alter, drop等) 语句修改，而且修改时可能会长时间锁表</li></ul></li><li>关系数据库在大数据场景下I/O较高<ul><li>对于每一行数据量都很大的表做统计之类的运算的时候I/O会很高，因为即使只针对其中某一列进行运算，关系数据库也会将整行数据从存储设备读入内存。 </li></ul></li><li>关系数据库的全文搜索功能比较弱</li></ul><p>针对上面的问题，产生了不同的NoSQL解决方案，在某一方面会有更好的表现。此外，NoSQL的方案带来的优势，本质上是牺牲ACID中的某个或者某几个特性，因此我们不能盲目地迷信NoSQL是银弹，应该将NoSQl作为SQL的一个有力补充。</p><p>常见NoSQL分类：</p><ul><li>K-V 存储: 解决SQL无法存储数据结构的问题</li><li>文档数据库：解决SQL强schema约束的问题</li><li>列式数据库：解决SQL大数据场景下的I/O问题，以HBase为代表</li><li>全文搜索引擎：解决关系数据库的全文搜索性能问题， ElasticSearch </li></ul><h2 id="3-1-Key-Value存储"><a href="#3-1-Key-Value存储" class="headerlink" title="3.1 Key - Value存储"></a>3.1 Key - Value存储</h2><p>Redis 是 K-V 存储的典型代表，它是一款开源（基于 BSD 许可）的高性能 K-V 缓存和存储系统。Redis 的 Value 是具体的数据结构，包括 string、hash、list、set、sorted set、bitmap 和 hyperloglog，所以常常被称为数据结构服务器。</p><p>更灵活的对数据的操作：</p><ul><li>LPOP key 从队列的左边出队一个元素。</li><li>LINDEX key index 获取一个元素，通过其索引列表。</li><li>LLEN key 获得队列（List）的长度。</li></ul><p>Redis 的缺点主要体现在并不支持完整的 ACID 事务，Redis 虽然提供事务功能，但 Redis 的事务和关系数据库的事务不可同日而语，Redis 的事务只能保证隔离性和一致性（I 和 C），无法保证原子性和持久性（A 和 D）。</p><h2 id="3-2-文档数据库"><a href="#3-2-文档数据库" class="headerlink" title="3.2 文档数据库"></a>3.2 文档数据库</h2><p>最大特点是no-schema，可以存储和读取任意的数据。带来优势：</p><ul><li>新增字段简单</li><li>历史数据不会出错</li><li>可以很容易存储复杂数据</li></ul><p>缺陷</p><ul><li>事务</li><li>没有join操作</li></ul><h2 id="3-3-列式数据库"><a href="#3-3-列式数据库" class="headerlink" title="3.3 列式数据库"></a>3.3 列式数据库</h2><p>按照列来存储数据，典型场景海量数据统计，只需要其中的一两列的数据即可。I/O相对低一些。</p><p>列式存储有更高的存储压缩比，因为单个列的数据相似度一般来说比行更高，能够达到更高的压缩率。</p><p>一般将其用在离线的大数据分析和统计的场景当中，因为这种场景经常是针对部分单列来进行操作的，数据写入以后无须更新删除。</p><h2 id="3-4-全文搜索引擎"><a href="#3-4-全文搜索引擎" class="headerlink" title="3.4 全文搜索引擎"></a>3.4 全文搜索引擎</h2><ul><li>全文搜索的条件可以随意排列组合，如果通过索引来满足，则索引的数量会非常多</li><li>全文搜索的模糊匹配方式，索引无法满足，只能用like，而like是整表扫描，很慢</li></ul><h3 id="3-4-1-基本原理"><a href="#3-4-1-基本原理" class="headerlink" title="3.4.1 基本原理"></a>3.4.1 基本原理</h3><ul><li>倒排索引/ 反向索引<ul><li>建立单词到文档的索引 </li><li>即用关键词来查，显示出出现的地方</li></ul></li></ul><h3 id="3-4-2-使用方式"><a href="#3-4-2-使用方式" class="headerlink" title="3.4.2 使用方式"></a>3.4.2 使用方式</h3><p>将数据库里面的内容转成JSON格式，然后输入全文搜索引擎进行搜索。 ES能够以实时化的方式，存储和检索复杂的数据结构，并令每个字段都默认可以被索引。</p><h1 id="4-高性能缓存结构"><a href="#4-高性能缓存结构" class="headerlink" title="4. 高性能缓存结构"></a>4. 高性能缓存结构</h1><p>存储系统的能力有的时候并不够用，比如</p><ul><li>需要经过复杂运算得出的数据  – 比如实时在线人数</li><li>读多写少的数据</li></ul><p>缓存就是为了弥补存储系统在这些复杂业务场景下的不足，其基本原理就是将可能重复使用的数据放到内存当中，一次生成，多次使用，避免每次使用都去访问存储系统。</p><p>缓存能够带来性能的大幅提升，以memcache为例，单台就可以达到TPS50000以上，基本架构就是第一次从数据库拿数据，第二次及以后就可以从memcached中来取得数据了。</p><h2 id="4-1-缓存穿透"><a href="#4-1-缓存穿透" class="headerlink" title="4.1 缓存穿透"></a>4.1 缓存穿透</h2><p>指缓存没有发挥作用，虽然去查询了缓存数据，但是不在那里面，业务系统就需要再次去存储系统查询数据，这种情况的出现通常是因为：</p><ul><li>存储数据不存在</li></ul><p>黑客攻击，故意大量访问某些读取不存在数据的业务。解决方案就是设置一个默认值，放到缓存里面，这样第二次读取缓存的时候就会获取默认值，而不会继续访问存储系统。</p><ul><li>缓存数据生成耗费大量的时间或者资源</li></ul><p>第二种情况是存储系统中存在数据，但生成缓存数据需要耗费较长时间或者耗费大量资源。如果刚好在业务访问的时候缓存失效了，那么也会出现缓存没有发挥作用，访问压力全部集中在存储系统上的情况。</p><p>典型的就是电商的商品分页，假设我们在某个电商平台上选择“手机”这个类别查看，由于数据巨大，不能把所有数据都缓存起来，只能按照分页来进行缓存，由于难以预测用户到底会访问哪些分页，因此业务上最简单的就是每次点击分页的时候按分页计算和生成缓存。通常情况下这样实现是基本满足要求的，但是如果被竞争对手用爬虫来遍历的时候，系统性能就可能出现问题。</p><h2 id="4-2-缓存雪崩"><a href="#4-2-缓存雪崩" class="headerlink" title="4.2 缓存雪崩"></a>4.2 缓存雪崩</h2><p>是指当缓存失效（过期）后引起系统性能急剧下降的情况。当缓存过期被清除后，业务系统需要重新生成缓存，因此需要再次访问存储系统，再次进行运算，这个处理步骤耗时几十毫秒甚至上百毫秒。而对于一个高并发的业务系统来说，几百毫秒内可能会接到几百上千个请求。由于旧的缓存已经被清除，新的缓存还未生成，并且处理这些请求的线程都不知道另外有一个线程正在生成缓存，因此所有的请求都会去重新生成缓存，都会去访问存储系统，从而对存储系统造成巨大的性能压力。这些压力又会拖慢整个系统，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。</p><p>为了解决，通常可以采用两种方案： 更新锁机制和后台更新机制。</p><h3 id="4-2-1-更新锁"><a href="#4-2-1-更新锁" class="headerlink" title="4.2.1 更新锁"></a>4.2.1 更新锁</h3><p>对缓存更新操作进行加锁保护，保证只有一个线程能够进行缓存更新，未能获取更新锁的线程要么等待锁释放以后重新读取缓存，要么就返回空值或者默认值。</p><p>对于采用分布式集群的业务系统，由于存在几十上百台服务器，即使单台服务器只有一个线程更新缓存，但几十上百台服务器一起算下来也会有几十上百个线程同时来更新缓存，同样存在雪崩的问题。因此分布式集群的业务系统要实现更新锁机制，需要用到分布式锁，如 ZooKeeper。</p><h3 id="4-2-2-后台更新"><a href="#4-2-2-后台更新" class="headerlink" title="4.2.2 后台更新"></a>4.2.2 后台更新</h3><p>由后台线程来更新缓存，而不是业务线程。缓存本身的有效期设置为永久，后台线程定时更新缓存。</p><p>后台定时机制需要考虑一种特殊的场景，当缓存系统内存不够时，会“踢掉”一些缓存数据，从缓存被“踢掉”到下一次定时更新缓存的这段时间内，业务线程读取缓存返回空值，而业务线程本身又不会去更新缓存，因此业务上看到的现象就是数据丢了。解决的方式有两种：</p><ul><li>后台线程除了定时更新缓存，还要频繁地去读取缓存（例如，1 秒或者 100 毫秒读取一次），如果发现缓存被“踢了”就立刻更新缓存，这种方式实现简单，但读取时间间隔不能设置太长，因为如果缓存被踢了，缓存读取间隔时间又太长，这段时间内业务访问都拿不到真正的数据而是一个空的缓存值，用户体验一般。</li><li>业务线程发现缓存失效后，通过消息队列发送一条消息通知后台线程更新缓存。可能会出现多个业务线程都发送了缓存更新消息，但其实对后台线程没有影响，后台线程收到消息后更新缓存前可以判断缓存是否存在，存在就不执行更新操作。这种方式实现依赖消息队列，复杂度会高一些，但缓存更新更及时，用户体验更好。</li></ul><h2 id="4-3-缓存热点"><a href="#4-3-缓存热点" class="headerlink" title="4.3 缓存热点"></a>4.3 缓存热点</h2><p>复制多份缓存副本，将请求分散到多个缓存服务器上，减轻缓存热点导致的单台缓存服务器的压力。</p><p>注意不同的缓存副本不要设置统一的过期时间，否则会出现所有缓存副本同时生成同时失效的情况，从而引发缓存雪崩效应。正确的做法是设定一个过期的时间范围，不同的缓存副本的过期时间是指定范围内的随机值。</p><h1 id="5-单服务器高性能模式-并发模型"><a href="#5-单服务器高性能模式-并发模型" class="headerlink" title="5. 单服务器高性能模式 - 并发模型"></a>5. 单服务器高性能模式 - 并发模型</h1><ul><li>影响高性能效果的因素<ul><li>磁盘</li><li>操作系统</li><li>CPU</li><li>内存</li><li>缓存</li><li>网络</li><li>编程语言</li><li>架构</li></ul></li></ul><p>高性能架构设计主要集中在两个方面：</p><ul><li>尽量提升单服务器的性能，将单服务器的性能发挥到极致</li><li>如果单服务器无法支撑性能，设计服务器集群方案</li></ul><ul><li><p>关键设计点</p><ul><li>服务器如何管理连接</li><li>服务器如何处理请求</li></ul></li><li><p>常见分类</p><ul><li>海量连接海量请求：双十一</li><li>常量连接海量请求：中间件</li><li>海量连接常量请求：门户网站</li><li>常量连接常量请求：内部运营系统，管理系统<br>这两个设计点都和操作系统的I/O模型以及进程模型相关。</li></ul></li><li><p>BIO: 一个线程处理一个请求</p></li><li><p>NIO：利用多路复用技术，通过少量的线程处理大量的请求</p></li><li><p>I/O 模型</p><ul><li>阻塞</li><li>非阻塞</li><li>同步</li><li>异步</li></ul></li><li><p>进程模型</p><ul><li>单进程</li><li>多进程</li><li>多线程</li></ul></li></ul><h2 id="5-1-PPC-Process-Per-Connection"><a href="#5-1-PPC-Process-Per-Connection" class="headerlink" title="5.1 PPC - Process Per Connection"></a>5.1 PPC - Process Per Connection</h2><p>每次有新的连接就新建一个进程去专门处理这个连接的请求，这也是传统的UNIX网络服务器锁采用的模型。</p><p><img src="https://i.loli.net/2020/02/04/NDdUCRi3klst8qM.png" alt="fig4.png"></p><ul><li>父进程接受连接</li><li>父进程fork子进程</li><li>子进程处理连接的读写请求</li><li>子进程关闭连接</li></ul><p>PPC 模式实现简单，比较适合服务器的连接数没那么多的情况，例如数据库服务器。对于普通的业务服务器，在互联网兴起之前，由于服务器的访问量和并发量并没有那么大，这种模式其实运作得也挺好，世界上第一个 web 服务器 CERN httpd 就采用了这种模式。但随着互联网星期，服务器的并发量和访问量都有了很大的提高，这种方法就涌现出了不少弊端</p><ul><li>fork代价比较高，要分配很多内核资源，需要将内存映像从父进程复制到子进程。</li><li>父子进程通信复杂，父进程fork子进程时，文件描述符可以通过内存映像复制从父进程传到子进程，但fork完成之后，父子进程通信就比较麻烦了，需要采用IPC(Interprocess Communication)之类的进程通信方案。</li><li>支持的并发连接数量有限，如果每个连接存活时间比较长，而且新的连接又源源不断的来，则进程数量会越来越多，操作系统进程调度和切换的频率也会越来越高，系统的压力也会越来越大。一般来说，PPC方案最大的并发连接数就几百的样子。</li></ul><h2 id="5-2-prefork-提前创建进程"><a href="#5-2-prefork-提前创建进程" class="headerlink" title="5.2 prefork 提前创建进程"></a>5.2 prefork 提前创建进程</h2><p>在启动的时候就预先创建好进程，然后开始接受用户的请求。当有新的连接进来的时候，就可以省去fork进程的操作，让用户访问更快，体验更好。</p><p><img src="https://i.loli.net/2020/02/04/2ukZmRXP8cWyolE.jpg" alt="fig5.jpg"></p><p>实现关键点在多个子进程都accept同一个socket，当有新的连接接入时，操作系统保证只有一个进程能最后accept成功。</p><p>prefork还是和PPC一样，存在父子进程通信复杂，支持的并发连接数量有限的问题。</p><h2 id="5-3-TPC-Thread-Per-Connection"><a href="#5-3-TPC-Thread-Per-Connection" class="headerlink" title="5.3 TPC - Thread Per Connection"></a>5.3 TPC - Thread Per Connection</h2><p>每次有新的连接，就建立一个新的线程去专门处理这个连接的请求。与进程相比，线程更轻量级，创建线程的消耗比进程要少得多；同时因为多线程共享进程内存空间，就可以简化线程之间通信的复杂程度。</p><p><img src="https://i.loli.net/2020/02/04/3qdx1ofOb8sLW4k.png" alt="fig6.png"></p><ul><li>父进程接受连接</li><li>父进程创建子线程</li><li>子线程处理连接的读写请求</li><li>子线程关闭连接</li></ul><p>和PPC相比，主进程不用close了，原因是子线程是共享主进程的进程空间的，连接的文件描述符并没有被复制，因此只需要一次close即可。</p><p>TPC引入了新的问题：</p><ul><li>创建线程依然有耗损，性能问题</li><li>线程间的互斥和共享的复杂度</li><li>多线程会互相影响，某个线程出现异常的时候，可能导致整个进程的退出</li></ul><p>在并发几百的情况下，还是会更多采用PPC的方案，因为无死锁的风险，也不会有多进程之间的相互影响，稳定性更高。</p><h2 id="5-4-prethread"><a href="#5-4-prethread" class="headerlink" title="5.4 prethread"></a>5.4 prethread</h2><p>预先创建线程，然后才开始接受用户的请求，当有新的连接进来的时候，就可以省去创建线程的操作，让用户感觉更快。常用的实现方式：</p><ul><li>主进程accept，然后将连接交给某个线程处理</li><li>子线程都尝试去accept，最终只有一个线程accept成功</li></ul><p><img src="https://i.loli.net/2020/02/04/8GsTH1Fokv2PLYf.jpg" alt="fig7.jpg"></p><h2 id="5-5-Reactor"><a href="#5-5-Reactor" class="headerlink" title="5.5 Reactor"></a>5.5 Reactor</h2><p>PPC模式的问题是每个连接都要创建进程，连接结束进程就被销毁了。为了解决这个问题，瞄准资源复用，即不再单独为每个连接创建进程，而是创建一个进程池，将连接分配给进程，一个进程可以处理多个连接的业务。</p><blockquote><p>一个进程处理多个连接的业务</p></blockquote><p>引入资源池的处理方式后，会引出一个新的问题：进程如何才能高效地处理多个连接的业务？当一个连接一个进程时，进程可以采用“read -&gt; 业务处理 -&gt; write”的处理流程，如果当前连接没有数据可以读，则进程就阻塞在 read 操作上。这种阻塞的方式在一个连接一个进程的场景下没有问题，但如果一个进程处理多个连接，进程阻塞在某个连接的 read 操作上，此时即使其他连接有数据可读，进程也无法去处理，很显然这样是无法做到高性能的。</p><p>为了解决这个问题，可以将read操作改为非阻塞的，然后进程不断轮询多个连接。但是这样做，不好的地方在于轮询耗费CPU资源；其次，如果一个进程处理成千上万的连接，轮询的效率是很低的。</p><blockquote><p>更好的解决办法，只有当连接上有数据的时候进程才去处理，这就是I/O多路复用的技术的来源</p></blockquote><ul><li>当多条连接共用一个阻塞对象后，进程只需要在一个阻塞对象上等待，而无须再轮询所有连接，常见的连接方式有select\epoll\kqueue等。</li><li>当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理</li></ul><p>I/O多路复用结合线程池，就是我们说的Reactor了，即事件反应的意思</p><p>Reactor会根据事件类型来调用相应的代码进行处理，也成为dispatcher模式，指的是I/O多路复用统一监听事件，收到事件后分配给某个进程的过程。 </p><ul><li>Reactor模式的benefits<ul><li>reactor数量可以变化</li><li>资源池的数量可以变化: 以进程为例，可以是单进程的，也可以是多个进程的</li></ul></li></ul><ul><li>常见的使用方式<ul><li>单 Reactor 单进程 / 线程。</li><li>单 Reactor 多线程。</li><li>多 Reactor 多进程 / 线程。</li></ul></li></ul><p>上述方案选择进程还是线程，更多和平台以及编程语言相关。例如Java一般使用线程 - Netty, Nginx选择进程</p><h3 id="5-5-1-单Reactor-单进程-线程"><a href="#5-5-1-单Reactor-单进程-线程" class="headerlink" title="5.5.1 单Reactor 单进程/ 线程"></a>5.5.1 单Reactor 单进程/ 线程</h3><p><img src="https://i.loli.net/2020/02/04/YW2N7ZBcuirMUAb.png" alt="fig8.png"></p><ul><li>select, accept, read, send是标准的网络编程API</li><li>dispatch和业务处理是需要完成的操作</li><li>Reactor对象通过select监控连接时间，收到事件以后通过dispatch来进行转发</li><li>如果是连接建立事件，就交给Acceptor，来接受连接，并创建一个Handler来处理接下来的各种事件</li><li>如果不是连接事件，就会用上面已经建好的handler来处理请求，做出响应</li><li>Handler会完成read - 业务处理 -send的完整业务流程</li></ul><ul><li>Benefits<ul><li>无进程间通信</li><li>无进程竞争</li></ul></li><li>Weakness<ul><li>只有一个进程，无法发挥出多核CPU的性能</li><li>handler在处理某个连接上的业务时，整个进程就无法处理</li></ul></li></ul><p>只适用于业务处理非常快速的场景，目前比较著名的使用这个的开源软件是Redis</p><h3 id="5-5-2-单Reactor-多线程"><a href="#5-5-2-单Reactor-多线程" class="headerlink" title="5.5.2 单Reactor 多线程"></a>5.5.2 单Reactor 多线程</h3><p><img src="https://i.loli.net/2020/02/04/GlJTpkZ4DojR9HN.png" alt="fig9.png"></p><ul><li>主线程当中，Reactor对象通过select监控连接时间，收到事件后通过dispatch进行分发</li><li>blabla… similar to above</li><li>Handler只负责响应事件，不进行业务处理；Handler通过read读取到数据后，会发给processor进行业务处理</li><li>Processor会在独立的子线程当中完成真正的业务处理，然后将响应结果发给主进程的Handler处理；Handler收到响应以后通过send将响应结果返回给client </li><li>Benefits<ul><li>能够充分利用多核多CPU的处理能力</li></ul></li><li>Weakness<ul><li>多线程数据共享和访问比较复杂</li><li>reactor承担所有事件的监听和响应，只在主线程中进行，瞬间高并发会成为性能瓶颈</li></ul></li></ul><h3 id="5-5-3-多Reactor-多进程-线程"><a href="#5-5-3-多Reactor-多进程-线程" class="headerlink" title="5.5.3 多Reactor 多进程/ 线程"></a>5.5.3 多Reactor 多进程/ 线程</h3><p><img src="https://i.loli.net/2020/02/04/wfyzTL47eUjQaBY.png" alt="fig10.png"></p><ul><li>父进程中mainReactor对象通过select监控连接建立事件，收到事件后通过Acceptor接收，将新的连接分配给某个子进程。</li><li>子进程的subReactor将mainReactor分配的连接加入连接队列进行监听，并创建一个Handler用于处理连接的各种事件</li><li>当有新的事件发生时，subReactor会调用连接对应的handler来进行响应</li><li>handler完成read - 业务处理 -send的流程</li><li>Benefits<ul><li>父进程和子进程的职责非常明确，父进程只负责接收新连接，子进程负责完成后续的业务处理。</li><li>父进程和子进程的交互很简单，父进程只需要把新连接传给子进程，子进程无须返回数据。</li><li>子进程之间是互相独立的，无须同步共享之类的处理（这里仅限于网络模型相关的 select、read、send 等无须同步共享，“业务处理”还是有可能需要同步共享的）。</li></ul></li></ul><h2 id="5-6-Proactor"><a href="#5-6-Proactor" class="headerlink" title="5.6 Proactor"></a>5.6 Proactor</h2><p>Reactor是非阻塞同步网络模型，因为真正的read和send操作都需要用户进程同步操作，proactor将其异步化，</p><p><img src="https://i.loli.net/2020/02/04/gV6YdJM3CLloBiA.png" alt="fig11.png"></p><ul><li>Proactor Initiator 负责创建 Proactor 和 Handler，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核。</li><li>Asynchronous Operation Processor 负责处理注册请求，并完成 I/O 操作。</li><li>Asynchronous Operation Processor 完成 I/O 操作后通知 Proactor。</li><li>Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理。</li><li>Handler 完成业务处理，Handler 也可以注册新的 Handler 到内核进程。</li></ul><h2 id="5-7-同步阻塞IO-vs-同步非阻塞IO-vs-异步非阻塞IO"><a href="#5-7-同步阻塞IO-vs-同步非阻塞IO-vs-异步非阻塞IO" class="headerlink" title="5.7 同步阻塞IO vs 同步非阻塞IO vs 异步非阻塞IO"></a>5.7 同步阻塞IO vs 同步非阻塞IO vs 异步非阻塞IO</h2><table><thead><tr><th>-</th><th>等待数据准备好的阶段（读到内核缓存）</th><th>将数据从内核读到用户空间</th></tr></thead><tbody><tr><td>同步阻塞IO</td><td>阻塞</td><td>阻塞</td></tr><tr><td>同步非阻塞IO</td><td>非阻塞</td><td>阻塞</td></tr><tr><td>异步非阻塞IO</td><td>非阻塞</td><td>非阻塞</td></tr></tbody></table><h1 id="6-高性能负载均衡-分类及架构-高性能集群"><a href="#6-高性能负载均衡-分类及架构-高性能集群" class="headerlink" title="6. 高性能负载均衡 - 分类及架构 - 高性能集群"></a>6. 高性能负载均衡 - 分类及架构 - 高性能集群</h1><p>高性能集群的本质： 通过增加更多的服务器来提升系统整体的计算能力。</p><p>由于计算本身的特点，即同样的输入数据和逻辑，无论在哪台服务器上执行，都应该得到相同的输出。因此高性能集群设计的复杂度主要体现在<strong>任务分配</strong>这部分，需要设计合理的任务分配策略，将计算任务分配到多台服务器上来执行。</p><p>即复杂性主要体现在需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法。</p><ul><li>任务分配算法的考虑因素<ul><li>计算单元的负载均衡</li><li>基于负载考虑</li><li>基于性能(吞吐量、响应时间)考虑</li><li>基于业务考虑</li></ul></li></ul><h2 id="6-1-负载均衡分类"><a href="#6-1-负载均衡分类" class="headerlink" title="6.1 负载均衡分类"></a>6.1 负载均衡分类</h2><h3 id="6-1-1-DNS负载均衡"><a href="#6-1-1-DNS负载均衡" class="headerlink" title="6.1.1 DNS负载均衡"></a>6.1.1 DNS负载均衡</h3><p>用于实现地理级别的均衡，其原理是DNS解析同一个域名，可以返回不同的IP地址。<br><img src="https://i.loli.net/2020/02/04/9Srot2PfYW35pux.jpg" alt="fig12.jpg"></p><ul><li>Benefits <ul><li>简单，成本低</li><li>负载均衡工作交给DNS服务器来处理，无须自己开发或者维护负载均衡设备</li><li>就近访问，提升访问速度</li></ul></li><li>weakness<ul><li>更新不及时，DNS缓存时间比较长，更新缓存以后，还有很多用户会访问修改前的IP，这样的访问会失败的</li><li>扩展性差，DNS负载均衡控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和特性的拓展</li><li>分配策略比较简单: DNS负载均衡的支持算法少，不能区分服务器的差异(不能根据系统与服务的状态来判断负载)，也无法感知后端服务器的状态。</li></ul></li></ul><h3 id="6-1-2-硬件负载均衡"><a href="#6-1-2-硬件负载均衡" class="headerlink" title="6.1.2 硬件负载均衡"></a>6.1.2 硬件负载均衡</h3><p>指通过单独的硬件设备来实现负载均衡的功能，类似路由器交换机，可以理解为一个用于负载均衡的基础网络设备。</p><ul><li><p>benefits </p><ul><li>功能强大，支持各层级负载均衡</li><li>性能强大，100万以上的并发</li><li>稳定性高</li><li>支持安全防护  DDos</li></ul></li><li><p>weakness</p><ul><li>价格昂贵</li><li>扩展能力差</li></ul></li></ul><h3 id="6-1-3-软件负载均衡"><a href="#6-1-3-软件负载均衡" class="headerlink" title="6.1.3 软件负载均衡"></a>6.1.3 软件负载均衡</h3><p>通过负载均衡软件来实现负载均衡的功能，常见的有Nginx - 软件的7层负载均衡和LVS - Linux内核的4层负载均衡。</p><p>Nginx支持HTTP，Email协议; 而LVS是4层负载均衡，和协议无关，几乎所有的应用都可以做。</p><p>软硬件最主要的区别在于性能，硬件负载均衡性能要远远高于软件的复杂均衡性能，但是软件的会便宜很多。</p><p><img src="https://i.loli.net/2020/02/04/3of7nFr6Ou1XsHg.jpg" alt="fig13.jpg"></p><ul><li>benefits<ul><li>部署维护简单</li><li>便宜</li><li>灵活，可扩展</li></ul></li></ul><h3 id="6-1-4-负载均衡的典型架构"><a href="#6-1-4-负载均衡的典型架构" class="headerlink" title="6.1.4 负载均衡的典型架构"></a>6.1.4 负载均衡的典型架构</h3><p>是结合起来一起用的，DNS负载均衡用于实现地理级别的负载均衡，硬件负载均衡用于实现集群级别的负载均衡，软件负载均衡用于实现机器级别的负载均衡。</p><p>整个系统的负载均衡分为三层：</p><ul><li>地理级别负载均衡</li><li>集群级别负载均衡  用硬件设备来做平均</li><li>机器级别的负载均衡  用nginx，收到用户的请求之后，将用户的请求发送给集群里面的某台服务器，服务器处理用户的业务请求并返回业务响应</li></ul><h2 id="6-2-高性能负载均衡-算法"><a href="#6-2-高性能负载均衡-算法" class="headerlink" title="6.2 高性能负载均衡 - 算法"></a>6.2 高性能负载均衡 - 算法</h2><h3 id="6-2-1-分类"><a href="#6-2-1-分类" class="headerlink" title="6.2.1 分类"></a>6.2.1 分类</h3><ul><li>任务平分类：负载均衡系统将收到的任务平均分配给服务器进行处理，这里的“平均”可以是绝对数量的平均，也可以是比例或者权重上的平均。</li><li>负载均衡类：负载均衡系统根据服务器的负载来进行分配，这里的负载并不一定是通常意义上我们说的“CPU 负载”，而是系统当前的压力，可以用 CPU 负载来衡量，也可以用连接数、I/O 使用率、网卡吞吐量等来衡量系统的压力。</li><li>性能最优类：负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器。</li><li>Hash 类：负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上。常见的有源地址 Hash、目标地址 Hash、session id hash、用户 ID Hash 等。</li></ul><h3 id="6-2-2-轮询"><a href="#6-2-2-轮询" class="headerlink" title="6.2.2 轮询"></a>6.2.2 轮询</h3><p>负载均衡系统收到请求后，按照顺序轮流分配到服务器上。</p><p>需要注意的是负载均衡系统无须关注“服务器本身状态”，这里的关键词是“本身”。也就是说，只要服务器在运行，运行状态是不关注的。但如果服务器直接宕机了，或者服务器和负载均衡系统断连了，这时负载均衡系统是能够感知的，也需要做出相应的处理。例如，将服务器从可分配服务器列表中删除，否则就会出现服务器都宕机了，任务还不断地分配给它，这明显是不合理的。</p><h3 id="6-2-3-加权轮询"><a href="#6-2-3-加权轮询" class="headerlink" title="6.2.3 加权轮询"></a>6.2.3 加权轮询</h3><p>负载均衡系统根据服务器权重进行任务分配，这里的权重一般是根据硬件配置进行静态配置的，采用动态的方式计算会更加契合业务，但复杂度也会更高。加权轮询主要为了解决不同服务器的处理能力有差异的问题。</p><h3 id="6-2-4-负载最低优先"><a href="#6-2-4-负载最低优先" class="headerlink" title="6.2.4 负载最低优先"></a>6.2.4 负载最低优先</h3><p>从服务器的角度出发来看如何进行负载分配</p><p>负载均衡系统将任务分配给当前负载最低的服务器，这里的负载根据不同的任务类型和业务场景，可以用不同的指标来衡量。例如：</p><ul><li>LVS 这种 4 层网络负载均衡设备，可以以“连接数”来判断服务器的状态，服务器连接数越大，表明服务器压力越大。</li><li>Nginx 这种 7 层网络负载系统，可以以“HTTP 请求数”来判断服务器状态（Nginx 内置的负载均衡算法不支持这种方式，需要进行扩展）。</li><li>如果我们自己开发负载均衡系统，可以根据业务特点来选择指标衡量系统压力。如果是 CPU 密集型，可以以“CPU 负载”来衡量系统压力；如果是 I/O 密集型，可以以“I/O 负载”来衡量系统压力。</li></ul><p>负载最低优先算法解决了轮询算法中无法感知服务器状态的问题，但复杂度会增加很多。</p><ul><li>最少连接数优先的算法要求负载均衡系统统计每个服务器当前建立的连接，其应用场景仅限于负载均衡接收的任何连接请求都会转发给服务器进行处理，否则如果负载均衡系统和服务器之间是固定的连接池方式，就不适合采取这种算法。例如，LVS 可以采取这种算法进行负载均衡，而一个通过连接池的方式连接 MySQL 集群的负载均衡系统就不适合采取这种算法进行负载均衡。</li><li>CPU 负载最低优先的算法要求负载均衡系统以某种方式收集每个服务器的 CPU 负载，而且要确定是以 1 分钟的负载为标准，还是以 15 分钟的负载为标准，不存在 1 分钟肯定比 15 分钟要好或者差。不同业务最优的时间间隔是不一样的，时间间隔太短容易造成频繁波动，时间间隔太长又可能造成峰值来临时响应缓慢。</li></ul><h3 id="6-2-5-性能最优类"><a href="#6-2-5-性能最优类" class="headerlink" title="6.2.5 性能最优类"></a>6.2.5 性能最优类</h3><p>从客户端的角度，和负载最低优先类算法类似，性能最优优先类算法本质上也是感知了服务器的状态，只是通过响应时间这个外部标准来衡量服务器状态而已。因此性能最优优先类算法存在的问题和负载最低优先类算法类似，复杂度都很高，主要体现在：</p><ul><li>负载均衡系统需要收集和分析每个服务器每个任务的响应时间，在大量任务处理的场景下，这种收集和统计本身也会消耗较多的性能。</li><li>为了减少这种统计上的消耗，可以采取采样的方式来统计，即不统计所有任务的响应时间，而是抽样统计部分任务的响应时间来估算整体任务的响应时间。采样统计虽然能够减少性能消耗，但使得复杂度进一步上升，因为要确定合适的采样率</li><li>采样周期，要10s性能最优还是1min性能最优</li></ul><h3 id="6-2-6-Hash类"><a href="#6-2-6-Hash类" class="headerlink" title="6.2.6 Hash类"></a>6.2.6 Hash类</h3><p>负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上，这样做的目的主要是为了满足特定的业务需求。</p><ul><li>源地址Hash<ul><li>将来源于同一个源 IP 地址的任务分配给同一个服务器进行处理，适合于存在事务、会话的业务。例如，当我们通过浏览器登录网上银行时，会生成一个会话信息，这个会话是临时的，关闭浏览器后就失效。网上银行后台无须持久化会话信息，只需要在某台服务器上临时保存这个会话就可以了，但需要保证用户在会话存在期间，每次都能访问到同一个服务器，这种业务场景就可以用源地址 Hash 来实现。</li></ul></li><li>ID Hash<ul><li>将某个 ID 标识的业务分配到同一个服务器中进行处理，这里的 ID 一般是临时性数据的 ID（如 session id）。例如，上述的网上银行登录的例子，用 session id hash 同样可以实现同一个会话期间，用户每次都是访问到同一台服务器的目的。 </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习-高可用架构模式</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-CAP-原理"><a href="#1-CAP-原理" class="headerlink" title="1. CAP 原理"></a>1. CAP 原理</h1><p>CAP原理讨论得是对于数据的读写操作，并不是在讨论整个系统的各个方面的功能。并且讨论得是在互联和分享数据过程当中出现的问题</p><ul><li>Consistency  一致性<ul><li>where all nodes see the same data at the same time </li><li>a read is guaranteed to return the most recent write for a given client </li></ul></li><li>Availability 可用性<ul><li>guarantee that every request receives a response about whether it succeed or fail </li><li>a non-faling node will return a reasonable response within a reasonable amount of time (no error or timeout)</li></ul></li><li>Partition tolerance  分区容错性 <ul><li>the system continues to operate even if any one part of the system is lost or fails  </li><li>the system will continue to function when network partitions occur </li></ul></li></ul><h2 id="1-1-CAP的选择"><a href="#1-1-CAP的选择" class="headerlink" title="1.1. CAP的选择"></a>1.1. CAP的选择</h2><p>分布式系统理论上来说无法选择CA架构，因为P是客观存在的，当网络分区发生的时候，为了保证C，那么只能回报错误给Client，这实质上就违反了A了。</p><h3 id="1-1-1-CP架构"><a href="#1-1-1-CP架构" class="headerlink" title="1.1.1 CP架构"></a>1.1.1 CP架构</h3><p>如下图所示，为了保证一致性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 需要返回 Error，提示客户端 C“系统现在发生了错误”，这种处理方式违背了可用性（Availability）的要求，因此 CAP 三者只能满足 CP。</p><p><img src="https://i.loli.net/2020/02/04/xXwWelYMtLu2hVv.png" alt="fig1.png"></p><h3 id="1-1-2-AP架构"><a href="#1-1-2-AP架构" class="headerlink" title="1.1.2 AP架构"></a>1.1.2 AP架构</h3><p>为了保证可用性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 将当前自己拥有的数据 x 返回给客户端 C 了，而实际上当前最新的数据已经是 y 了，这就不满足一致性（Consistency）的要求了，因此 CAP 三者只能满足 AP。注意：这里 N2 节点返回 x，虽然不是一个“正确”的结果，但是一个“合理”的结果，因为 x 是旧的数据，并不是一个错乱的值，只是不是最新的数据而已。</p><h2 id="1-2-CAP-细节"><a href="#1-2-CAP-细节" class="headerlink" title="1.2 CAP 细节"></a>1.2 CAP 细节</h2><h3 id="1-2-1-关注粒度-数据"><a href="#1-2-1-关注粒度-数据" class="headerlink" title="1.2.1 关注粒度 - 数据"></a>1.2.1 关注粒度 - 数据</h3><p>每个系统都不可能只处理一种数据，而是包含多种类型的数据，有的数据必须选择CP，有的数据必须选择AP。如果我们从整个系统的角度上去选择CP还是AP，很容易顾此失彼，无论怎么做都有问题。</p><p>比如用户管理系统，那么用户账户数据会选择CP，而用户信息数据会选择AP。因为在真的对CAP做应用的时候，我们需要将系统内的数据按照不同的应用场景和要求来进行分类，每类数据选择不同的策略，而不是限定整个系统的所有数据都是同一个策略。</p><h3 id="1-2-2-CAP是忽略网络延迟的"><a href="#1-2-2-CAP是忽略网络延迟的" class="headerlink" title="1.2.2 CAP是忽略网络延迟的"></a>1.2.2 CAP是忽略网络延迟的</h3><p>从节点A到节点B的复制，一定是需要花费一定的时间的，从几毫秒到几十毫秒不等。这意味着，CAP的理论当中的C在实践中是不可能完美实现的。</p><p>因此对于和金钱相关的，或者是和抢购相关的商品库存，技术上是无法做到分布式场景下完美的一致性的。而业务上又必须要求一致性，因此单个用户的余额，商品库存等只能单点写入，然后让其他节点做备份，无法做到分布式情况下的多点写入。</p><p><img src="https://i.loli.net/2020/02/04/FkRpQHwIXcj5hCW.png" alt="fig3.png"></p><p>这种设计的问题在于某个节点故障的时候，这个节点上的用户就无法进行读写操作了，但站在整体上来看，这种设计可以降低故障时受影响的用户的数量和范围。</p><h3 id="1-2-3-分区处理"><a href="#1-2-3-分区处理" class="headerlink" title="1.2.3 分区处理"></a>1.2.3 分区处理</h3><p>如果出现了分区，那么就需要在分区期间记录足够多的日志，当分区故障解决之后，系统根据日志进行数据恢复，使得重新达到CA的状态</p><h2 id="1-3-BASE"><a href="#1-3-BASE" class="headerlink" title="1.3 BASE"></a>1.3 BASE</h2><ul><li>basically available 基本可用<ul><li>出现故障的时候，允许损失部分可用性，即保证核心可用</li></ul></li><li>soft state 软状态<ul><li>允许系统存在中间状态，而该中间状态不会影响系统的整体可用性。这里的中间状态是CAP理论中的数据不一致 </li></ul></li><li>eventual consistency  最终一致性 <ul><li>系统的所有数据副本经过一定时间之后，最终能够达到一致的状态。</li></ul></li></ul><h2 id="2-3-FMEA分析表"><a href="#2-3-FMEA分析表" class="headerlink" title="2.3 FMEA分析表"></a>2.3 FMEA分析表</h2><h3 id="2-3-1-功能点"><a href="#2-3-1-功能点" class="headerlink" title="2.3.1 功能点"></a>2.3.1 功能点</h3><ul><li>从用户角度看涉及到的功能点<ul><li>用户角度，即登录注册这种功能</li><li>而不是数据库缓存这种</li></ul></li></ul><h3 id="2-3-2-故障模式"><a href="#2-3-2-故障模式" class="headerlink" title="2.3.2 故障模式"></a>2.3.2 故障模式</h3><ul><li>系统会出现什么样的故障<ul><li>包括故障点</li><li>故障模式<ul><li>假设某种故障现象即可</li></ul></li></ul></li><li>故障模式的描述要尽量精确，多使用量化的值来进行描述，避免泛化的方式。比如说慢，慢到3秒比说单纯的慢要好得多。</li></ul><h3 id="2-3-3-故障影响"><a href="#2-3-3-故障影响" class="headerlink" title="2.3.3 故障影响"></a>2.3.3 故障影响</h3><p>当发生故障模式中描述的故障时，功能点具体会受到什么影响。常见的影响有：</p><ul><li>功能点完全不可用</li><li>部分不可用</li><li>响应缓慢</li><li>功能出错</li></ul><p>故障影响也应该尽量准确描述，比如可能影响20%的用户之类的。</p><h3 id="2-3-4-严重程度"><a href="#2-3-4-严重程度" class="headerlink" title="2.3.4 严重程度"></a>2.3.4 严重程度</h3><p>站在业务的角度来看故障的影响程度，一般分为致命/ 高/ 中/ 低/ 无 五个档次。</p><p>严重程度 = 功能点重要程度 x 故障影响范围 x 功能点受损程度</p><h3 id="2-3-5-故障原因"><a href="#2-3-5-故障原因" class="headerlink" title="2.3.5 故障原因"></a>2.3.5 故障原因</h3><p>列出故障原因，是为了</p><ul><li>故障原因都具有不同的概率，这会影响我们的解决方案</li><li>不同故障原因检测手段不同</li><li>处理措施不同</li></ul><h3 id="2-3-6-故障概率"><a href="#2-3-6-故障概率" class="headerlink" title="2.3.6 故障概率"></a>2.3.6 故障概率</h3><ul><li>硬件</li><li>开源系统</li><li>自研系统</li></ul><h3 id="2-3-7-风险程度"><a href="#2-3-7-风险程度" class="headerlink" title="2.3.7 风险程度"></a>2.3.7 风险程度</h3><p>风险程度 = 严重程度 x 故障概率</p><h3 id="2-3-8-已有措施"><a href="#2-3-8-已有措施" class="headerlink" title="2.3.8 已有措施"></a>2.3.8 已有措施</h3><ul><li>检测告警<ul><li>检测故障，告警，人工干预</li></ul></li><li>容错<ul><li>系统通过备份手段来应对</li></ul></li><li>自恢复<ul><li>检测到故障以后，系统能够自动恢复。比如，Hadoop检测到某台机器故障之后，将存储在这台机器的副本重新分配到别的机器上。 </li></ul></li></ul><h3 id="2-3-9-规避措施"><a href="#2-3-9-规避措施" class="headerlink" title="2.3.9 规避措施"></a>2.3.9 规避措施</h3><ul><li>技术手段<ul><li>冗余备份等 </li></ul></li><li>管理手段<ul><li>硬件定期更新 </li></ul></li></ul><h3 id="2-3-10-解决措施"><a href="#2-3-10-解决措施" class="headerlink" title="2.3.10 解决措施"></a>2.3.10 解决措施</h3><p>为了能够解决问题而给出的方案，往往是技术手段</p><h3 id="2-3-11-后续规划"><a href="#2-3-11-后续规划" class="headerlink" title="2.3.11 后续规划"></a>2.3.11 后续规划</h3><p>综合前面的分析，就可以看出哪些故障我们目前还缺乏对应的措施，哪些已有措施还不够，针对这些不足的地方，再结合风险程度进行排序，给出后续的改进规划。这些规划既可以是技术手段，也可以是管理手段；可以是规避措施，也可以是解决措施。同时需要考虑资源的投入情况，优先将风险程度高的系统隐患解决。</p><h1 id="3-高可用存储架构"><a href="#3-高可用存储架构" class="headerlink" title="3. 高可用存储架构"></a>3. 高可用存储架构</h1><p>存储高可用方案 – 本质 – <strong><em>将数据复制到多个存储设备当中，通过数据冗余的方式来实现高可用</em></strong>， 其复杂性主要体现在如何应对复制延迟和中断导致的数据不一致的问题。因此，对任何一个高可用存储方案，我们需要考虑以下几个问题：</p><ul><li>数据如何复制的</li><li>各个节点的职责是什么</li><li>如何应对复制延迟</li><li>如何应对复制中断</li></ul><h2 id="3-1-双机架构"><a href="#3-1-双机架构" class="headerlink" title="3.1 双机架构"></a>3.1 双机架构</h2><h3 id="3-1-1-主备复制"><a href="#3-1-1-主备复制" class="headerlink" title="3.1.1 主备复制"></a>3.1.1 主备复制</h3><p><img src="https://i.loli.net/2020/02/04/CgcTbUFLiJDKE6u.jpg" alt="fig4.jpg"></p><p>主备架构的备机起到一个备份的作用，并不承担实际的业务读写操作，如果将备机改为主机，是需要进行人工操作的。</p><ul><li>优势<ul><li>足够简单</li><li>对于客户端来说，不需要感知备机的存在</li><li>对于主备之间，只需要进行数据复制，无须进行状态判断和主备切换这类复杂操作</li></ul></li><li>劣势<ul><li>备份无读写的流量，因此硬件成本上是有浪费的</li><li>故障之后需要人工干预，无法做自动恢复</li></ul></li></ul><h3 id="3-1-2-主从复制"><a href="#3-1-2-主从复制" class="headerlink" title="3.1.2 主从复制"></a>3.1.2 主从复制</h3><p><img src="https://i.loli.net/2020/02/04/JyKOIvYmc78Ut2Q.jpg" alt="fig5.jpg"></p><ul><li>优势<ul><li>主从复制在主机故障时，读操作相关的业务可以继续运行</li><li>主从复制架构的从机提供读操作，发挥了硬件的性能</li></ul></li><li>劣势<ul><li>主从复制当中，客户端需要感知主从关系，并将不同的操作发给不同的机器进行处理，复杂度比主备的要高</li><li>主从复制架构当中，从机提供读业务，如果主从复制延迟比较大，业务会因为数据不一致出现问题</li><li>故障时需要人工干预</li></ul></li></ul><h3 id="3-1-3-主备-主从切换"><a href="#3-1-3-主备-主从切换" class="headerlink" title="3.1.3 主备/ 主从切换"></a>3.1.3 主备/ 主从切换</h3><p>系统自动决定主机角色，并完成角色的切换。</p><p>以主备为例，需要考虑的问题有：</p><h4 id="3-1-3-1-主备间状态判断"><a href="#3-1-3-1-主备间状态判断" class="headerlink" title="3.1.3.1 主备间状态判断"></a>3.1.3.1 主备间状态判断</h4><ul><li>状态传递渠道<ul><li>相互之间的连接</li><li>第三方仲裁</li></ul></li><li>状态检测的内容<ul><li>机器是否掉电</li><li>进程是否存在</li><li>响应是否缓慢</li></ul></li></ul><h4 id="3-1-3-2-切换决策"><a href="#3-1-3-2-切换决策" class="headerlink" title="3.1.3.2 切换决策"></a>3.1.3.2 切换决策</h4><ul><li>切换时机</li><li>切换策略</li><li>自动程度</li></ul><h4 id="3-1-3-3-数据冲突解决"><a href="#3-1-3-3-数据冲突解决" class="headerlink" title="3.1.3.3 数据冲突解决"></a>3.1.3.3 数据冲突解决</h4><ul><li>需要做具体的应用场景的具体分析了</li></ul><h4 id="3-1-3-4-常见主备切换架构"><a href="#3-1-3-4-常见主备切换架构" class="headerlink" title="3.1.3.4 常见主备切换架构"></a>3.1.3.4 常见主备切换架构</h4><ul><li>互连式<ul><li>主备之间进行状态传递</li><li>缺点<ul><li>状态传递通道本身存在问题的话，备机也会自动升级为主机，造成有两个主机的结果</li></ul></li></ul></li><li>中介式<ul><li>引入第三方中介，主备间不直接连接，而是去连接中介，并且通过中介来传递状态信息</li><li>连接管理以及状态决策都更简单一些了</li></ul></li><li>模拟式<ul><li>主备之间不传递任何状态数据，而是备机模拟成一个客户端，向主机发起模拟的读写操作，根据读写操作的响应情况来判断主机的状态。 </li></ul></li></ul><h3 id="3-1-4-主主复制"><a href="#3-1-4-主主复制" class="headerlink" title="3.1.4 主主复制"></a>3.1.4 主主复制</h3><p><img src="https://i.loli.net/2020/02/04/o8ZKUvW4VEeY1nQ.png" alt="fig6.png"></p><ul><li>两台都是主机，不存在切换的概念</li><li>客户端无须区分不同角色的主机，随便讲读写操作发送给哪台主机都是可以的</li><li>双向复制本身的难以实现<ul><li>比如数据库同步，ID如何做更新等</li><li>一般适合于临时性，可丢失，可覆盖的数据场景</li></ul></li></ul><h2 id="3-2-集群和分区"><a href="#3-2-集群和分区" class="headerlink" title="3.2 集群和分区"></a>3.2 集群和分区</h2><h3 id="3-2-1-数据集群"><a href="#3-2-1-数据集群" class="headerlink" title="3.2.1 数据集群"></a>3.2.1 数据集群</h3><p>主备，主从，主主都有一个隐含的假设，主机能够存储所有数据。但是在实际场景当中，一台主机的存储和处理能力都是十分有限的，单台服务器一定是无法存储和处理的，我们必须使用多台服务器来存储数据，实现一个数据集群架构。</p><p>数据集群又可以分为数据集中集群，数据分散集群</p><h4 id="3-2-1-1-数据集中集群"><a href="#3-2-1-1-数据集中集群" class="headerlink" title="3.2.1.1 数据集中集群"></a>3.2.1.1 数据集中集群</h4><p><img src="https://i.loli.net/2020/02/04/93XQRrAHzuItK86.png" alt="fig7.png"></p><p> 客户端与主机进行交流，主机进行数据复制到各个备机上去。Zookeeper解决了大部分数据集中集群中会出现的问题。</p><ul><li>多条复制通道，会增大主机复制的压力，需要考虑如何降低主机复制压力</li><li>多条复制通道会导致多个备机之间数据不一致，我们需要对备机之间的数据一致性进行检查和修正</li><li>备机如何检查主机的状态，如何处理不同备机对主机状态的不同判断</li><li>主机故障以后，如何决定新的主机</li></ul><h4 id="3-2-1-2-数据分散集群"><a href="#3-2-1-2-数据分散集群" class="headerlink" title="3.2.1.2 数据分散集群"></a>3.2.1.2 数据分散集群</h4><ul><li><p>多个服务器组成一个集群，每台服务器都会负责存储一部分数据；同时为了提升硬件利用率，每台服务器又会备份一部分数据。</p></li><li><p>数据分配算法需要考虑到：</p><ul><li>均衡性 – 数据分区，数据容量基本上相同</li><li>容错性 – 当服务器故障时，算法需要将原来分配给故障服务器的数据分区分配给其他服务器</li><li>可伸缩性 – 集群容量不够，扩充了新的服务器之后，算法能够自动将部分数据分区迁移到新服务器上，并保证扩容后所有服务器的均衡性</li></ul></li><li><p>需要有一台机器来执行数据分配算法</p></li></ul><h3 id="3-2-2-数据分区"><a href="#3-2-2-数据分区" class="headerlink" title="3.2.2 数据分区"></a>3.2.2 数据分区</h3><p>针对于影响很大的事故或者灾难来说，有可能会使得所有硬件全部故障。数据分区指的是按照一定规则进行分区，分布到不同的地理位置上，每个分区存储一部分数据，通过这种方式来规避地理级别的故障所造成的的影响。</p><ul><li>数据分区的考虑因素<ul><li>数据量</li><li>分区规则</li><li>复制规则<ul><li>集中式<ul><li>总的备份中心，所有分区将数据备份到备份中心</li><li>设计简单，可互不影响</li><li>扩展容易</li><li>成本较高，需要建立一个独立的备份中心</li></ul></li><li>互备式<ul><li>每个分区备份另外一个分区的数据</li><li>复杂度高，相互之间强关联</li><li>成本低</li></ul></li><li>独立式<ul><li>每个分区都有自己的独立的备份中心</li><li>扩展容易，设计简单</li><li>成本很高</li></ul></li></ul></li></ul></li></ul><h1 id="4-计算高可用架构"><a href="#4-计算高可用架构" class="headerlink" title="4. 计算高可用架构"></a>4. 计算高可用架构</h1><p>当部分硬件损坏时，计算任务能够继续正常运行。因此计算高可用的本质是通过冗余来规避部分故障的风险。即通过增加更多的服务器来达到计算高可用。</p><p>设计复杂度主要体现在任务管理上，即当任务在某台服务器上执行失败以后，如何将任务重新分配到新的服务器进行执行。</p><h2 id="4-1-哪些服务器可以执行任务"><a href="#4-1-哪些服务器可以执行任务" class="headerlink" title="4.1 哪些服务器可以执行任务"></a>4.1 哪些服务器可以执行任务</h2><ul><li>特定服务器</li><li>每个服务器</li></ul><h2 id="4-2-任务如何重新执行"><a href="#4-2-任务如何重新执行" class="headerlink" title="4.2 任务如何重新执行"></a>4.2 任务如何重新执行</h2><ul><li>对已经分配的任务即使执行失败也不做任何处理，系统只需要保证新的任务能够分配到其他非故障的服务器上执行即可</li><li>设计一个任务管理器来管理需要执行的计算任务，服务器执行任务后，需要向任务管理器反馈任务执行的结果，任务管理器根据任务执行结果来决定是否需要将任务重新分配到另外的服务器上执行。</li></ul><h2 id="4-3-常见的计算高可用架构"><a href="#4-3-常见的计算高可用架构" class="headerlink" title="4.3 常见的计算高可用架构"></a>4.3 常见的计算高可用架构</h2><h3 id="4-3-1-主备"><a href="#4-3-1-主备" class="headerlink" title="4.3.1 主备"></a>4.3.1 主备</h3><p><img src="https://i.loli.net/2020/02/04/mGLY492oBbOqitu.png" alt="fig8.png"></p><ul><li>和存储高可用类似，不过更简单，因为不需要做数据复制的</li><li>主机执行所有计算任务</li><li>主机故障，任务分配器不会自动将计算任务发给备机，系统此时是不可用状态</li><li>如果主机恢复(人工或自动)，任务分配器继续将任务发送给主机</li><li>如果主机不能够恢复，则需要人工操作，将备机升为主机，然后让任务分配器将任务发送给新的主机</li></ul><h3 id="4-3-2-主从"><a href="#4-3-2-主从" class="headerlink" title="4.3.2 主从"></a>4.3.2 主从</h3><p><img src="https://i.loli.net/2020/02/04/Z4yh5EUqFCBPokT.png" alt="fig9.png"></p><ul><li>主机执行部分计算任务，备机也执行一部分</li><li>主机故障时，任务分配器还是会发给主机</li><li>不能恢复，人工操作，备机变主机，增加新的备机</li><li>好处是从机执行任务，发挥了硬件性能；缺点是需要将任务分类，任务分配器会复杂一些</li></ul><h3 id="4-3-3-集群"><a href="#4-3-3-集群" class="headerlink" title="4.3.3 集群"></a>4.3.3 集群</h3><p>系统需要能够自动完成切换操作，这是高可用集群方案。根据节点的角色，可以分成对称集群，集群内的每个服务器都有一样的角色，都可以执行所有的任务；另一类是非对称集群，集群中服务器分为多个不同角色，执行不同的任务。</p><h4 id="4-3-3-1-对称集群-负载均衡集群"><a href="#4-3-3-1-对称集群-负载均衡集群" class="headerlink" title="4.3.3.1 对称集群 - 负载均衡集群"></a>4.3.3.1 对称集群 - 负载均衡集群</h4><p><img src="https://i.loli.net/2020/02/04/hIbCsuAmKclkiqT.png" alt="fig10.png"></p><ul><li>任务分配器采取某种策略(随机、轮询等)将计算任务分配给集群当中的不同服务器</li><li>当集群中的某台服务器出现故障以后，任务分配器不再将任务分配给它，而是将任务分配给其他服务器执行</li><li>当故障的服务器恢复之后，任务分配器重新将任务分配给它执行</li></ul><ul><li>难点<ul><li>分配策略<ul><li>轮询</li><li>随机</li></ul></li><li>检测服务器状态<ul><li>服务器本身状态<ul><li>是否宕机</li><li>网络是否正常</li></ul></li><li>任务执行状态<ul><li>任务卡死</li><li>执行时间过长等</li></ul></li><li>一般来说是通过在任务分配器和服务器之间通过心跳来传递信息，包括服务器信息和任务信息，然后根据实际情况来确定状态，判断条件</li></ul></li></ul></li></ul><h4 id="4-3-3-2-非对称集群"><a href="#4-3-3-2-非对称集群" class="headerlink" title="4.3.3.2 非对称集群"></a>4.3.3.2 非对称集群</h4><ul><li>集群通过某种方式来区分不同的服务器角色<ul><li>ZAB 算法</li></ul></li><li>当指定类型的服务器故障时，需要重新分配角色 </li><li>比均衡负载更复杂<ul><li>任务分配策略更加复杂 - 需要将任务划分为不同类型并分配给不同角色的集群节点</li><li>角色分配策略实现更复杂      </li></ul></li></ul><h1 id="5-异地多活架构"><a href="#5-异地多活架构" class="headerlink" title="5. 异地多活架构"></a>5. 异地多活架构</h1><ul><li>异地 - 地理位置上的不同</li><li>多活 - 不同地理位置上的系统都能提供业务服务</li><li>异地多活标准<ul><li>用户无论访问哪一个地点的业务系统，都能够得到正确的业务服务</li><li>某个地方业务异常的时候，用户访问其他地方正常的业务系统，能够得到正确的业务服务</li></ul></li><li>异地多活实现代价非常高<ul><li>系统复杂度显著上升</li><li>成本上升</li></ul></li><li>需要异地多活的场景<ul><li>滴滴</li><li>微信</li><li>支付宝等</li></ul></li></ul><h2 id="5-1-架构模式"><a href="#5-1-架构模式" class="headerlink" title="5.1 架构模式"></a>5.1 架构模式</h2><h3 id="5-1-1-同城异区"><a href="#5-1-1-同城异区" class="headerlink" title="5.1.1 同城异区"></a>5.1.1 同城异区</h3><p>将业务部署在同一个城市不同区的多个机房当中。虽然还是无法在地震海啸等大灾害面前存活，但是同城异区通过光纤的设定，可以实现几乎和同一个机房相同的网络传输速度。这样尽管是多个机房，但我们可以将其作为一个机房来看待。</p><p>还是个看概率的问题，和地震海啸相比，机房火灾停电这种事情更有可能发生，对于此类故障，同城异区架构都可以很好地解决。</p><h3 id="5-1-2-跨城异地"><a href="#5-1-2-跨城异地" class="headerlink" title="5.1.2 跨城异地"></a>5.1.2 跨城异地</h3><p>将业务部署在不同城市的多个机房当中。距离要足够远，以应对极端灾难事件。但是与之相对的是，两个机房就几乎无法实现同步了。</p><p>正因为无法同步，所以对于十分敏感的数据，比如说账户余额这类，就不会使用跨城异地这种方式了。</p><h3 id="5-1-3-跨国异地"><a href="#5-1-3-跨国异地" class="headerlink" title="5.1.3 跨国异地"></a>5.1.3 跨国异地</h3><ul><li>主要为了为不同地区的用户提供服务</li><li>或者是只读类业务做多活</li></ul><h2 id="5-2-异地多活设计技巧"><a href="#5-2-异地多活设计技巧" class="headerlink" title="5.2 异地多活设计技巧"></a>5.2 异地多活设计技巧</h2><h3 id="5-2-1-保证核心业务的异地多活"><a href="#5-2-1-保证核心业务的异地多活" class="headerlink" title="5.2.1 保证核心业务的异地多活"></a>5.2.1 保证核心业务的异地多活</h3><p>因为保证所有业务的异地多活是不现实的，比如注册，登录，用户信息都要保持同步。注册不应该保持异地多活，因为一般都有单个手机号的限制，如果异地服务器，就无法检测是否已经注册过了，这是一个商业逻辑上的很大的悖论了，不可以这样做。</p><p>同理对于用户信息也是，根据更新时间的激活和识别也很可能会因为不同的机器时间的问题，而导致最终是不准确的，会带来很不好的用户体验。</p><p>登录才是最最需要保证异地多活的功能。</p><h3 id="5-2-2-保证核心数据最终一致性"><a href="#5-2-2-保证核心数据最终一致性" class="headerlink" title="5.2.2 保证核心数据最终一致性"></a>5.2.2 保证核心数据最终一致性</h3><p>异地多活本质上是通过异地的数据冗余，来保证在极端的异常情况下，业务也能正常提供给用户。即需要实现<strong>数据的快速同步</strong>。</p><ul><li>尽量减少异地多活机房的距离，搭建高速网络</li><li>尽量减少数据同步，只同步核心业务相关的数据</li><li>保证最终一致性，不保证实时的</li></ul><h2 id="5-3-如何应对接口级的故障"><a href="#5-3-如何应对接口级的故障" class="headerlink" title="5.3 如何应对接口级的故障"></a>5.3 如何应对接口级的故障</h2><p>接口级故障的典型表现就是系统并没有宕机，网络也没中断，但业务却出现了问题。例如：</p><ul><li>业务响应缓慢</li><li>访问大量超时</li><li>大量访问出现异常</li></ul><p>这类问题的主要原因在于系统压力太大，负载太高，导致无法快速处理业务请求，由此引发了更多的后续问题。常见的比如说数据库慢查询，将数据库的服务器资源耗尽了，导致读写超时，业务读写数据库要么超时，无法连接；从用户的角度来说，就是访问很慢，或者抛出异常。 </p><h3 id="5-3-1-接口级故障的原因"><a href="#5-3-1-接口级故障的原因" class="headerlink" title="5.3.1 接口级故障的原因"></a>5.3.1 接口级故障的原因</h3><ul><li>内部原因<ul><li>程序bug导致死循环</li><li>某个接口导致数据库慢查询</li><li>程序逻辑不完善导致耗尽内存</li></ul></li><li>外部原因<ul><li>黑客攻击</li><li>促销，抢购引入远超平时的用户</li><li>第三方系统大量请求</li><li>第三方系统响应缓慢</li></ul></li><li>解决的核心思想<ul><li>优先保证核心业务</li><li>优先保证绝大部分用户</li></ul></li></ul><h3 id="5-3-2-降级"><a href="#5-3-2-降级" class="headerlink" title="5.3.2 降级"></a>5.3.2 降级</h3><p>系统将某些业务或者接口的功能降低，只提供部分功能或者完全停掉所有功能</p><ul><li>系统后门降级<ul><li>比如提供一个降级URL，当访问这个URL的时候，就相当于提供了一个降级操作</li></ul></li><li>独立降级系统<ul><li>独立出系统，实现权限管理批量操作等功能。</li></ul></li></ul><h3 id="5-3-3-熔断"><a href="#5-3-3-熔断" class="headerlink" title="5.3.3 熔断"></a>5.3.3 熔断</h3><ul><li>和降级做对比<ul><li>降级是用来处理系统自身的故障</li><li>熔断是应对依赖的外部系统的故障的情况</li></ul></li><li>熔断机制的关键在于一个统一的API调用层，由API调用层来进行采样或者统计</li><li>另一个关键是阈值的设计，一般是根据分析确定阈值，然后上线观察效果，再进行调优</li></ul><h3 id="5-3-4-限流"><a href="#5-3-4-限流" class="headerlink" title="5.3.4 限流"></a>5.3.4 限流</h3><p>从用户访问压力的角度来考虑，只允许系统能够承载的访问量来访问，超出系统访问能力的请求将被丢弃。</p><ul><li>基于请求限流<ul><li>常用方式<ul><li>限制总量<ul><li>比如限制总用户的上限 </li></ul></li><li>限制时间量<ul><li>限制一段时间内某个指标的上限  比如请求tps</li></ul></li></ul></li><li>这种方式更多是英语业务功能比较简单的系统，因为很可能阈值需要不断调整的</li></ul></li><li>基于资源限流<ul><li>找到系统内部影响性能的关键资源，对其使用上限进行限制<ul><li>连接数</li><li>文件句柄</li><li>线程数</li><li>请求队列</li></ul></li></ul></li></ul><h3 id="5-3-5-排队"><a href="#5-3-5-排队" class="headerlink" title="5.3.5 排队"></a>5.3.5 排队</h3><ul><li>不直接扔掉请求，排队</li><li>排队模块<ul><li>将请求以先进先出的方式保存下来</li></ul></li><li>调度模块<ul><li>负责排队模块到服务模块的动态调度</li></ul></li><li>服务模块<ul><li>调用真正业务来处理服务，并返回处理结果，调用排队模块的接口回写处理结果。 </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> CAP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习-架构设计流程</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-识别复杂度"><a href="#1-识别复杂度" class="headerlink" title="1. 识别复杂度"></a>1. 识别复杂度</h1><p>具体情况需要具体分析，即这个系统的复杂度体现在哪一个方面。一个系统的复杂度主要来源于高性能，高可用，可扩展这几个方面。</p><p>正确的做法是将主要的复杂度问题列出来，然后根据业务、技术、团队等综合情况进行排序，优先解决当前面临的最主要的复杂问题。</p><p>多个系统之间的强耦合，可以通过信息队列来解耦。要注意从高可用，高性能，可扩展几个维度对其进行分析，看整个架构调整的复杂度在哪里，然后做针对性的提升。</p><p>平均TPS， QPS，峰值TPS (average x 3)，</p><h1 id="2-设计备选方案"><a href="#2-设计备选方案" class="headerlink" title="2. 设计备选方案"></a>2. 设计备选方案</h1><p>架构师需要对已经存在的技术非常熟悉，对已经经过验证的架构模式烂熟于心，然后根据自己对于业务的理解，挑选合适的架构模式进行组合，再对组合之后的方案进行修改和调整。</p><p>目前，只要明确了应用场景，复杂度上的限制因素，我们往往能找到相对成熟的技术来直接使用。例如</p><ul><li>高可用主备方案</li><li>集群方案</li><li>高性能负载均衡</li><li>多路复用</li><li>可拓展的分层</li><li>插件化技术</li></ul><p>设计备选方案的tips</p><ul><li>多设计几个备选方法，3-5个为宜</li><li>方案之间的差异要比较明显</li><li>备选方案的技术不要只局限于已经熟悉的技术</li><li>备选方案不需要太过于详细的，关注的是技术选型，而不是技术细节</li></ul><p>对于高性能写入</p><ul><li>集群</li><li>直接写入一台正常的服务器即可<br>高可用存储</li><li>已经写入的信息在单台服务器宕机的情况下不丢失</li><li>使用MySQL的主备复制功能<br>高可用读取</li><li>要求已经写入的消息在单台服务器宕机的情况下可以继续读取</li><li>服务器的主备方案</li></ul><h1 id="3-评估和选择备选方案"><a href="#3-评估和选择备选方案" class="headerlink" title="3. 评估和选择备选方案"></a>3. 评估和选择备选方案</h1><ul><li>多角度环评<ul><li>列出需要关注的质量属性点</li><li>分别从这些质量属性的维度去评估每个方案，再综合挑选适合当时情况的最优方案</li></ul></li><li>方案质量属性点<ul><li>性能</li><li>可用性</li><li>硬件成本</li><li>项目投入</li><li>复杂度</li><li>安全性</li><li>可拓展性</li></ul></li><li>对于需要评估未来业务发展的规模时，一般可以将当前的业务规模乘以2-4 即可。</li><li>将质量属性按照优先级排序</li></ul><h1 id="4-详细方案设计"><a href="#4-详细方案设计" class="headerlink" title="4. 详细方案设计"></a>4. 详细方案设计</h1><p>将方案涉及的关键技术细节给确定下来。</p><ul><li>假如我们确定使用 Elasticsearch 来做全文搜索，那么就需要确定 Elasticsearch 的索引是按照业务划分，还是一个大索引就可以了；副本数量是 2 个、3 个还是 4 个，集群节点数量是 3 个还是 6 个等。</li><li>假如我们确定使用 MySQL 分库分表，那么就需要确定哪些表要分库分表，按照什么维度来分库分表，分库分表后联合查询怎么处理等。</li><li>假如我们确定引入 Nginx 来做负载均衡，那么 Nginx 的主备怎么做，Nginx 的负载均衡策略用哪个（权重分配？轮询？ip_hash？）等。<ul><li>轮询</li><li>加权轮询 - 后端服务器性能不均</li><li>ip_hash - 每个方可固定访问同一个后端服务器，解决session的问题</li><li>fair - 按照响应时间来分配请求，响应时间短的优先分配，能够最大化平衡各后端服务器的压力，可以适用于后端服务器性能不均衡的情况</li><li>url_hash - 每个url定向到同一个后端服务器，适用于后端服务器能够将url的响应结果缓存的情况</li></ul></li></ul><ul><li>通过分步骤，分阶段，分系统等方式，尽量降低方案的复杂度。</li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习 - 架构设计文档模板</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%E6%A8%A1%E6%9D%BF/</url>
      
        <content type="html"><![CDATA[<p>整个流程应当是在刚开始的时候有几个方案，然后在经过讨论和分析以后整理出唯一可以的方案，然后再创建架构设计的详细文档，这个时候理论上应该</p><h1 id="1-备选方案模板"><a href="#1-备选方案模板" class="headerlink" title="1. 备选方案模板"></a>1. 备选方案模板</h1><h2 id="1-1-需求介绍"><a href="#1-1-需求介绍" class="headerlink" title="1.1 需求介绍"></a>1.1 需求介绍</h2><ul><li>需求的背景</li><li>需求的目标</li><li>需求的范围</li></ul><h2 id="1-2-需求分析"><a href="#1-2-需求分析" class="headerlink" title="1.2 需求分析"></a>1.2 需求分析</h2><h3 id="1-2-1-5W"><a href="#1-2-1-5W" class="headerlink" title="1.2.1 5W"></a>1.2.1 5W</h3><ul><li>Who 开发者 使用者 购买者 决策者等</li><li>When 需求使用时间，包括季节，时间，里程碑等</li><li>What 需求的产出是什么，包括系统，数据，文件，开发库，平台等</li><li>Where  需求的应用场景，包括国家，地点，环境等</li><li>Why  需求需要解决的问题，通常和需求背景相关</li></ul><h3 id="1-2-2-1H"><a href="#1-2-2-1H" class="headerlink" title="1.2.2 1H"></a>1.2.2 1H</h3><p>How指的是关键业务流程</p><h3 id="1-2-3-8C"><a href="#1-2-3-8C" class="headerlink" title="1.2.3 8C"></a>1.2.3 8C</h3><p>8个约束和限制，包括</p><ul><li>performance</li><li>cost</li><li>time</li><li>reliability</li><li>security</li><li>compliance</li><li>technology</li><li>compatibility</li></ul><h2 id="1-3-复杂度分析"><a href="#1-3-复杂度分析" class="headerlink" title="1.3 复杂度分析"></a>1.3 复杂度分析</h2><h3 id="1-3-1-高可用"><a href="#1-3-1-高可用" class="headerlink" title="1.3.1 高可用"></a>1.3.1 高可用</h3><h3 id="1-3-2-高性能"><a href="#1-3-2-高性能" class="headerlink" title="1.3.2 高性能"></a>1.3.2 高性能</h3><h3 id="1-3-3-可扩展"><a href="#1-3-3-可扩展" class="headerlink" title="1.3.3 可扩展"></a>1.3.3 可扩展</h3><h2 id="1-4-其他备选方案及评估"><a href="#1-4-其他备选方案及评估" class="headerlink" title="1.4 其他备选方案及评估"></a>1.4 其他备选方案及评估</h2><h1 id="2-架构设计模板"><a href="#2-架构设计模板" class="headerlink" title="2. 架构设计模板"></a>2. 架构设计模板</h1><h2 id="2-1-总体方案"><a href="#2-1-总体方案" class="headerlink" title="2.1 总体方案"></a>2.1 总体方案</h2><p>整体描述方案的结构，架构图，以及针对架构图的描述，包括模块或者子系统的职责描述，核心流程</p><h2 id="2-2-架构总览"><a href="#2-2-架构总览" class="headerlink" title="2.2 架构总览"></a>2.2 架构总览</h2><p>架构图以及架构的描述</p><h2 id="2-3-核心流程"><a href="#2-3-核心流程" class="headerlink" title="2.3 核心流程"></a>2.3 核心流程</h2><h2 id="2-4-详细设计"><a href="#2-4-详细设计" class="headerlink" title="2.4 详细设计"></a>2.4 详细设计</h2><h3 id="2-4-1-高可用设计"><a href="#2-4-1-高可用设计" class="headerlink" title="2.4.1 高可用设计"></a>2.4.1 高可用设计</h3><h3 id="2-4-2-高性能设计"><a href="#2-4-2-高性能设计" class="headerlink" title="2.4.2 高性能设计"></a>2.4.2 高性能设计</h3><h3 id="2-4-3-可扩展设计"><a href="#2-4-3-可扩展设计" class="headerlink" title="2.4.3 可扩展设计"></a>2.4.3 可扩展设计</h3><h3 id="2-4-4-安全设计"><a href="#2-4-4-安全设计" class="headerlink" title="2.4.4 安全设计"></a>2.4.4 安全设计</h3><h2 id="2-5-部署方案"><a href="#2-5-部署方案" class="headerlink" title="2.5 部署方案"></a>2.5 部署方案</h2><ul><li>硬件要求</li><li>服务器部署方式</li><li>组网方式</li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习 - 实战</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%AE%9E%E6%88%98/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-技术演进的动力-企业发展"><a href="#1-技术演进的动力-企业发展" class="headerlink" title="1. 技术演进的动力 - 企业发展"></a>1. 技术演进的动力 - 企业发展</h1><h2 id="1-1-业务和技术之间的关系"><a href="#1-1-业务和技术之间的关系" class="headerlink" title="1.1 业务和技术之间的关系"></a>1.1 业务和技术之间的关系</h2><ul><li>产品类<ul><li>技术创新推动业务发展 </li><li>用户选择产品的根本驱动力是功能</li></ul></li><li>服务类<ul><li>业务发展推动技术创新 </li><li>用户选择服务的根本驱动力是规模</li></ul></li></ul><h1 id="2-技术演进的模式-（复杂性，用户规模）"><a href="#2-技术演进的模式-（复杂性，用户规模）" class="headerlink" title="2. 技术演进的模式 （复杂性，用户规模）"></a>2. 技术演进的模式 （复杂性，用户规模）</h1><ul><li>业务时期分类<ul><li>初创期</li><li>发展期</li><li>竞争期</li><li>成熟期</li></ul></li></ul><h2 id="2-1-初创期"><a href="#2-1-初创期" class="headerlink" title="2.1 初创期"></a>2.1 初创期</h2><p>创新出新的理念，通过用户使用，快速迭代，不断完善。对于业务的要求就是快。</p><h2 id="2-2-发展期"><a href="#2-2-发展期" class="headerlink" title="2.2 发展期"></a>2.2 发展期</h2><p>大量加入功能，技术方面的核心工作就是快速实现各种需求。</p><ul><li>堆功能</li><li>优化 vs 重新架构</li><li>架构期 - 拆分</li></ul><h2 id="2-3-竞争期"><a href="#2-3-竞争期" class="headerlink" title="2.3 竞争期"></a>2.3 竞争期</h2><p>更迅速的发展，但是很容易出现重复造轮子，以及系统交互很乱等问题</p><p>因此一般都是做平台化以及服务化的操作。</p><ul><li>平台化<ul><li>存储平台化</li><li>数据库平台化</li><li>缓存平台化</li></ul></li></ul><h2 id="2-4-成熟期"><a href="#2-4-成熟期" class="headerlink" title="2.4 成熟期"></a>2.4 成熟期</h2><p>系统性的针对性优化</p><h1 id="3-General"><a href="#3-General" class="headerlink" title="3. General"></a>3. General</h1><p><img src="https://i.loli.net/2020/02/04/ViqLHs2aExQUAru.png" alt="fig1.png"></p><ul><li>纵向排列<ul><li>测试平台</li><li>运维平台</li><li>数据平台</li><li>管理平台</li></ul></li><li>横向<ul><li>业务层</li><li>用户层<ul><li>用户管理</li><li>消息推送</li><li>存储云</li><li>图片云</li></ul></li><li>网络层<ul><li>负载均衡</li><li>CDN</li></ul></li><li>服务层<ul><li>配置中心</li><li>服务中心</li><li>消息队列</li></ul></li><li>开发层<ul><li>开发框架</li><li>服务器</li><li>容器</li></ul></li><li>存储层<ul><li>SQL</li><li>NoSQL</li><li>小文件</li><li>大文件</li></ul></li></ul></li></ul><h1 id="4-存储层技术"><a href="#4-存储层技术" class="headerlink" title="4. 存储层技术"></a>4. 存储层技术</h1><h2 id="4-1-SQL"><a href="#4-1-SQL" class="headerlink" title="4.1 SQL"></a>4.1 SQL</h2><ul><li>NoSQL - Not only SQL </li><li>数据库拆分满足性能要求，但是会带来复杂度问题<ul><li>数据如何拆分</li><li>数据如何组合</li></ul></li><li>当业务发展到一定阶段之后，会将这部分功能独立成中间件</li><li>而后在SQL集群上构建SQL存储平台，以对业务透明的形式提供资源分配、数据备份、迁移、容灾、读写分离、分库分表等一系列服务</li></ul><h2 id="4-2-NoSQL"><a href="#4-2-NoSQL" class="headerlink" title="4.2 NoSQL"></a>4.2 NoSQL</h2><p>在NoSQL集群的基础上实现统一的存储平台，实现以下的功能：</p><ul><li>资源按需动态分配</li><li>资源自动化管理</li><li>故障自动化管理</li></ul><h2 id="4-3-小文件存储"><a href="#4-3-小文件存储" class="headerlink" title="4.3 小文件存储"></a>4.3 小文件存储</h2><p>展示性质的数据，比如商品图片，商品描述；特征是数据小，但数量巨大</p><h2 id="4-4-大文件存储"><a href="#4-4-大文件存储" class="headerlink" title="4.4 大文件存储"></a>4.4 大文件存储</h2><ul><li>业务上的大数据<ul><li>youtube的视频</li><li>电影</li></ul></li><li>海量日志数据<ul><li>访问日志</li><li>操作日志</li><li>用户轨迹日志</li></ul></li></ul><p>几个开源方案</p><ul><li>Hadoop</li><li>HBase</li><li>Storm</li><li>Hive</li></ul><h1 id="5-开发层技术"><a href="#5-开发层技术" class="headerlink" title="5. 开发层技术"></a>5. 开发层技术</h1><h2 id="5-1-开发框架"><a href="#5-1-开发框架" class="headerlink" title="5.1 开发框架"></a>5.1 开发框架</h2><p>整个公司使用同样的框架和技术可以解决组和组之间沟通的问题，大大提升组织和团队的开发效率。</p><p>对于框架，应该选择成熟的框架，避免盲目追逐新技术。</p><ul><li>java<ul><li>SSH</li><li>SpringMVC</li><li>Play </li></ul></li><li>Ruby<ul><li>Ruby on Rails</li></ul></li><li>PHP<ul><li>ThinkPHP</li></ul></li><li>Python <ul><li>Django </li></ul></li></ul><h2 id="5-2-Web服务器"><a href="#5-2-Web服务器" class="headerlink" title="5.2 Web服务器"></a>5.2 Web服务器</h2><ul><li>Java<ul><li>Tomcat</li><li>JBoss </li><li>Besin </li></ul></li><li>PHP/ Python <ul><li>Nginx</li></ul></li><li>Apache </li></ul><h2 id="5-3-容器"><a href="#5-3-容器" class="headerlink" title="5.3 容器"></a>5.3 容器</h2><p>Docker技术，不跨平台，但是启动快，几乎不占资源</p><p>可以基于Docker打造自动化运维</p><h1 id="6-服务层技术"><a href="#6-服务层技术" class="headerlink" title="6. 服务层技术"></a>6. 服务层技术</h1><p>服务层的主要目标就是降低系统间相互关联的复杂度。</p><h2 id="6-1-配置中心"><a href="#6-1-配置中心" class="headerlink" title="6.1 配置中心"></a>6.1 配置中心</h2><ul><li>集中管理各个系统的配置</li><li>各系统管理自己的配置会带来一些问题<ul><li>需要多个系统配合的时候，配置分散，则配置检查和沟通协调都会比较费时间</li><li>处理线上问题，需要查询多个配置文件，相互比较，很麻烦</li><li>各系统自己配置，往往用文本方式，没有自动的校验机制，就比较容易出现错误</li></ul></li><li>配置中心，做成通用系统，给所有系统来使用<ul><li>集中配置</li><li>程序化的规则检查，避免常见错误，可以用正则表达式来检查</li><li>备份了系统的配置，便于快速搭建系统和恢复业务</li></ul></li></ul><h2 id="6-2-服务中心"><a href="#6-2-服务中心" class="headerlink" title="6.2 服务中心"></a>6.2 服务中心</h2><p>服务中心是用来解决跨系统依赖的配置和调度问题的。</p><h3 id="6-2-1-服务名字系统-–-Service-Name-System"><a href="#6-2-1-服务名字系统-–-Service-Name-System" class="headerlink" title="6.2.1 服务名字系统 – Service Name System"></a>6.2.1 服务名字系统 – Service Name System</h3><p>将Service的名称解析为<code>host+port+接口名称</code></p><p><img src="https://i.loli.net/2020/02/04/HqVy9UlC35ceauY.png" alt="fig2.png"></p><h3 id="6-2-2-服务总线系统-–-Service-Bus-System"><a href="#6-2-2-服务总线系统-–-Service-Bus-System" class="headerlink" title="6.2.2 服务总线系统 – Service Bus System"></a>6.2.2 服务总线系统 – Service Bus System</h3><p>有总线系统完成调用，服务请求方不需要直接和服务提供方进行交互了。</p><p><img src="https://i.loli.net/2020/02/04/G2UmVfZCIBpcLSD.png" alt="fig3.png"></p><p><img src="https://i.loli.net/2020/02/04/D5QZEIuiFAWoN1s.png" alt="fig4.png"></p><h2 id="6-3-消息队列"><a href="#6-3-消息队列" class="headerlink" title="6.3 消息队列"></a>6.3 消息队列</h2><p>很多业务处理需要采用异步的方式，消息队列就是为了实现这种跨系统异步通知的中间件系统。</p><h1 id="7-网络层技术"><a href="#7-网络层技术" class="headerlink" title="7. 网络层技术"></a>7. 网络层技术</h1><h2 id="7-1-负载均衡"><a href="#7-1-负载均衡" class="headerlink" title="7.1 负载均衡"></a>7.1 负载均衡</h2><ul><li>DNS<ul><li>地理级别的负载均衡 </li></ul></li><li>Nginx, LVS, F5 <ul><li>同一个地点内机器级别的负载均衡</li></ul></li><li>CDN<h2 id="7-2-多机房-跨国多机房"><a href="#7-2-多机房-跨国多机房" class="headerlink" title="7.2 多机房 + 跨国多机房"></a>7.2 多机房 + 跨国多机房</h2><h2 id="7-3-多中心"><a href="#7-3-多中心" class="headerlink" title="7.3 多中心"></a>7.3 多中心</h2></li></ul><p>每个中心都可以对外提供服务，且业务可以自动在多中心之间切换。</p><h1 id="8-用户层技术"><a href="#8-用户层技术" class="headerlink" title="8. 用户层技术"></a>8. 用户层技术</h1><h2 id="8-1-用户管理"><a href="#8-1-用户管理" class="headerlink" title="8.1 用户管理"></a>8.1 用户管理</h2><ul><li>单点登录 (SSO) - 统一登录<ul><li>cookie</li><li>Json</li><li>token </li><li>CAS </li></ul></li></ul><p><img src="https://i.loli.net/2020/02/04/y9ScKCkWZvTomLY.png" alt="fig5.png"></p><ul><li>授权登录<ul><li>OAuth 2.0</li></ul></li></ul><h2 id="8-2-消息推送"><a href="#8-2-消息推送" class="headerlink" title="8.2 消息推送"></a>8.2 消息推送</h2><ul><li>根据途径<ul><li>短信</li><li>邮件</li><li>站内信</li><li>App推送</li></ul></li><li>消息推送的功能<ul><li>设备管理<ul><li>唯一标识</li><li>注册</li><li>注销</li></ul></li><li>连接管理</li><li>消息管理</li></ul></li></ul><p>技术上的挑战：</p><ul><li><p>海量设备和用户管理</p><ul><li>需要将用户和设备关联起来</li><li>提取用户特征对用户进行分类或者打标签</li></ul></li><li><p>连接保活</p><ul><li>想推送消息必须有连接通道</li><li>但是手机等终端都会限制后台应用的运行</li><li>应用找厂商拉白名单，hhhh</li></ul></li><li><p>消息管理</p><ul><li>根据用户的特征，选择一些用户进行消息推送</li><li>这部分的逻辑的设计必须十分灵活<h2 id="8-3-存储云，图片云"><a href="#8-3-存储云，图片云" class="headerlink" title="8.3 存储云，图片云"></a>8.3 存储云，图片云</h2></li></ul></li><li><p>小文件存储</p></li></ul><h1 id="9-业务层技术"><a href="#9-业务层技术" class="headerlink" title="9. 业务层技术"></a>9. 业务层技术</h1><p>主要是随着发展业务层变得越来越大了，需要做的最主要的就是拆分了，将整体复杂性分散到多个子业务或者子系统当中。</p><p>当子系统太多的时候，再做高内聚，低耦合的操作，即将职责关联比较强的子系统合成一个虚拟业务域，然后通过网关对外统一呈现。</p><h1 id="10-平台技术"><a href="#10-平台技术" class="headerlink" title="10. 平台技术"></a>10. 平台技术</h1><h2 id="10-1-运维平台"><a href="#10-1-运维平台" class="headerlink" title="10.1 运维平台"></a>10.1 运维平台</h2><ul><li>配置<ul><li>主要负责资源的管理<ul><li>机器管理</li><li>IP地址管理</li><li>虚拟机管理</li></ul></li></ul></li><li>部署<ul><li>主要负责将系统发布到线上<ul><li>包管理</li><li>灰度发布管理</li><li>回滚</li></ul></li></ul></li><li>监控<ul><li>主要负责收集系统上线运行之后的相关数据并进行监控，以便及时发现问题 </li></ul></li><li>应急<ul><li>主要负责系统出故障以后的处理<ul><li>停止程序</li><li>下线故障机器</li><li>切换IP</li></ul></li></ul></li></ul><h2 id="10-2-测试平台"><a href="#10-2-测试平台" class="headerlink" title="10.2 测试平台"></a>10.2 测试平台</h2><ul><li>单元测试</li><li>集成测试</li><li>接口测试</li><li>性能测试</li></ul><p>重点就是自动化测试，使测试用例能够重复执行，无须人工参与，以提高测试效率。</p><h3 id="10-2-1-用例管理"><a href="#10-2-1-用例管理" class="headerlink" title="10.2.1 用例管理"></a>10.2.1 用例管理</h3><p>测试自动化的主要手段就是通过脚本或者代码来进行测试，为了重复执行此类代码，测试平台需要将用例进行管理，管理的维度有业务、系统、测试类型、用例代码。例如网购业务的订单系统的接口测试用例。</p><h3 id="10-2-2-资源管理"><a href="#10-2-2-资源管理" class="headerlink" title="10.2.2 资源管理"></a>10.2.2 资源管理</h3><p>具体的运行环境的配置，包括</p><ul><li>硬件<ul><li>服务器</li><li>手机</li><li>平板</li></ul></li><li>软件<ul><li>操作系统</li><li>数据库</li><li>Java虚拟机</li></ul></li><li>业务系统</li></ul><h3 id="10-2-3-任务管理"><a href="#10-2-3-任务管理" class="headerlink" title="10.2.3 任务管理"></a>10.2.3 任务管理</h3><p>将测试用例分配到具体的资源上来执行，跟踪任务的执行情况。任务管理是测试平台设计的核心，其将测试平台的各个部分串联起来从而完成自动化测试</p><h3 id="10-2-4-数据管理"><a href="#10-2-4-数据管理" class="headerlink" title="10.2.4 数据管理"></a>10.2.4 数据管理</h3><p>记录各种相关的数据</p><ul><li>执行时间</li><li>执行结果</li><li>用例执行期间的CPU，内存占用情况</li></ul><h2 id="10-3-数据平台"><a href="#10-3-数据平台" class="headerlink" title="10.3 数据平台"></a>10.3 数据平台</h2><ul><li>数据管理<ul><li>数据采集<ul><li>日志</li><li>用户行为</li><li>业务数据</li></ul></li><li>数据存储<ul><li>将从业务系统采集的数据存储到数据平台，用于后续数据分析 </li></ul></li><li>数据访问<ul><li>负责对外提供各种协议用于读写数据 </li></ul></li><li>数据安全</li></ul></li><li>数据分析<ul><li>数据统计</li><li>数据挖掘</li><li>机器学习</li><li>深度学习</li></ul></li><li>数据应用</li></ul><h2 id="10-4-管理平台"><a href="#10-4-管理平台" class="headerlink" title="10.4 管理平台"></a>10.4 管理平台</h2><p>管理平台的核心职责就是权限管理，要做身份认证以及权限控制。</p><ul><li>身份认证<ul><li>确定当前的操作人员身份，防止非法人员进入系统</li></ul></li><li>权限控制<ul><li>根据身份确定权限 </li></ul></li></ul><h1 id="11-Some-tips"><a href="#11-Some-tips" class="headerlink" title="11. Some tips"></a>11. Some tips</h1><h2 id="11-1-如何选择开源项目"><a href="#11-1-如何选择开源项目" class="headerlink" title="11.1 如何选择开源项目"></a>11.1 如何选择开源项目</h2><ul><li>不要重复造轮子</li><li>但要找到合适的轮子</li></ul><h3 id="11-1-1-选择方法"><a href="#11-1-1-选择方法" class="headerlink" title="11.1.1 选择方法"></a>11.1.1 选择方法</h3><ul><li>聚焦于是否满足业务，而不是聚焦于开源项目本身是否足够优秀</li><li>聚焦于该项目是否足够成熟<ul><li>版本号</li><li>使用的公司数量</li><li>社区活跃程度</li></ul></li><li>聚焦于运维能力<ul><li>开源项目日志是否齐全</li><li>是否有命令行，管理控制台等维护工具</li><li>是否有故障检测和恢复的能力，例如告警，切换等</li></ul></li></ul><h3 id="11-1-2-如何深入了解一个开源项目"><a href="#11-1-2-如何深入了解一个开源项目" class="headerlink" title="11.1.2 如何深入了解一个开源项目"></a>11.1.2 如何深入了解一个开源项目</h3><ul><li>通读开源项目的设计文档，白皮书，了解其设计原理</li><li>核对每个配置项的作用和影响，识别出关键配置项</li><li>进行多种场景的性能测试</li><li>进行压力测试，观察CPU、内存、磁盘I/O等关键指标</li><li>进行故障测试</li></ul><h3 id="11-1-3-如何基于开源项目做二次开发"><a href="#11-1-3-如何基于开源项目做二次开发" class="headerlink" title="11.1.3 如何基于开源项目做二次开发"></a>11.1.3 如何基于开源项目做二次开发</h3><ul><li>不改动原系统，因为还要要能够合并，与原来的能够兼容就再好不过了</li><li>开发辅助系统<ul><li>监控</li><li>报警</li><li>负载均衡</li><li>管理</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习-复杂度来源</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9D%A5%E6%BA%90/</url>
      
        <content type="html"><![CDATA[<p>架构设计的主要目的是为了解决软件系统复杂度带来的问题，那么复杂度的来源到底在哪里呢？ </p><h1 id="1-高性能"><a href="#1-高性能" class="headerlink" title="1. 高性能"></a>1. 高性能</h1><h2 id="1-1-单机复杂度"><a href="#1-1-单机复杂度" class="headerlink" title="1.1 单机复杂度"></a>1.1 单机复杂度</h2><p>操作系统 - 是将硬件性能充分发挥出来的关键。</p><ul><li>最初是只有输入计算以及输出功能</li><li>批处理 - 将要执行的指令预先写下来，形成一个指令清单，然后将任务交给计算机执行，读取任务中的指令清单并进行处理</li><li>进程 - 进程对应任务，都有自己的内存空间，进程间互不相关</li><li>进程间的通信<ul><li>管道</li><li>消息队列</li><li>信号量</li><li>共享存储</li></ul></li><li>线程<ul><li>进程内部的子任务，都共享同一份进程数据。为保证数据的正确性，有了互斥锁机制。有了多线程以后，操作系统调度的最小单位就变成了线程，而进程变成了操作系统分配资源的最小单位。</li></ul></li><li>多个CPU真正同时执行计算任务<ul><li>SMP symmetric multi processor </li><li>NUMA  Non uniform memory access </li><li>MPP  Massive Parallel Processing </li></ul></li></ul><h2 id="1-2-集群复杂度"><a href="#1-2-集群复杂度" class="headerlink" title="1.2 集群复杂度"></a>1.2 集群复杂度</h2><p>突然发现双十一峰值，支付宝能到每秒12万笔；红包能达到76万。通过大量机器来提升性能，并不仅仅是增加机器这么简单，让多台机器来配合达到高性能的目的，是一个复杂的任务，复杂在于：</p><ul><li>任务分配<ul><li>任务分配器<ul><li>硬件网络设备 交换机</li><li>软件网络设备  LVS</li><li>负载均衡软件  Nginix  HAProxy</li><li>分配算法<ul><li>轮询</li><li>按权重分配</li><li>按负载分配</li></ul></li></ul></li><li>任务分配器和业务服务器的连接<ul><li>选择合适的连接方式</li><li>管理连接<ul><li>连接建立，检测，中断后的处理 </li></ul></li></ul></li><li>继续拓展 -&gt; 任务分配器也要变成多台了<ul><li>此时需要将不同的用户分配到不同的任务分配器上<ul><li>DNS轮询，CDN， GSLB(Global Server Load Balance)</li></ul></li><li>任务分配器和业务服务器，多对多的网状结构</li></ul></li></ul></li><li>任务分解<ul><li>任务分配到不同的机器上带来的帮助会递减的，因为当业务越来越复杂，单台机器的性能不够用了，所以就需要进行任务分解来做优化</li><li>可以从逻辑上将各个子业务进行拆分，将一整个业务系统拆分成小而简单，但是需要多个系统配合的业务系统</li><li>为什么能提升性能？ 代码还是那些代码哇？<ul><li>简单的系统更容易分析出瓶颈，更容易做到高性能</li><li>可以针对单个任务进行拓展</li><li>当然不能划分的太细，因为网络的调用性能远比系统内的函数调用要低</li></ul></li></ul></li></ul><h1 id="2-高可用"><a href="#2-高可用" class="headerlink" title="2. 高可用"></a>2. 高可用</h1><blockquote><p>系统无中断地执行其功能的能力，代表系统的可用性程度</p></blockquote><blockquote><p>通过冗余来实现高可用，与高性能的区别在于，高性能增加机器的目的在于扩展处理性能；高可用增加机器的目的在于冗余处理单元</p></blockquote><h2 id="2-1-计算高可用"><a href="#2-1-计算高可用" class="headerlink" title="2.1 计算高可用"></a>2.1 计算高可用</h2><p>多台服务器时主备的选择，具体采用什么方式，主备分别的个数，结合实际业务需求来分析和判断。</p><h2 id="2-2-存储高可用"><a href="#2-2-存储高可用" class="headerlink" title="2.2 存储高可用"></a>2.2 存储高可用</h2><p>高可用设计的关键点就在于存储高可用了，区别在于将数据从一台机器搬到另一台机器，需要经过线路进行传输</p><p>无论是正常情况下的传输延迟，还是异常情况下的传输中断，都会导致系统的数据在某个时间点或者时间段是不一致的，而数据的不一致又会导致业务问题；存储高可用的难点不在于如何备份数据，而在于如何减少或者规避数据不一致对业务造成的影响。</p><p>分布式领域的CAP定理，存储高可用性不可能同时满足一致性，可用性，分区容错性，最多满足其中两个，这就要求我们在做架构设计的时候结合业务进行取舍。</p><h2 id="2-3-高可用状态决策"><a href="#2-3-高可用状态决策" class="headerlink" title="2.3 高可用状态决策"></a>2.3 高可用状态决策</h2><p>无论是计算高可用还是存储高可用，其基础都是状态决策，即系统需要能够判断当前的状态是正常还是异常的，如果出现异常就要采取行动来保证高可用。但一个矛盾点在于： </p><p><strong>通过冗余实现的高可用，状态决策本质上就不可能做到完全正确</strong></p><p>常见的决策方式：</p><ul><li>独裁式<ul><li>只有一个决策者</li><li>n个上报者</li><li>不会出现决策混乱，但是决策者本身故障的时候，系统就崩了</li></ul></li><li>协商式<ul><li>两个独立的个体通过交流信息，根据规则进行决策</li><li>主备决策</li><li>2台服务器启动时都是备机</li><li>建立连接</li><li>交换状态信息</li><li>某1台服务器做出决策，成为主机；另一台继续保持备机身份</li><li>协商式 当连接出问题的时候，采用哪个？ 两主？ 多连接？ 仍然存在问题的</li></ul></li><li>民主式<ul><li>多个独立个体通过投票的方式进行状态决策</li><li>ZooKeeper集群在选举leader时就采用这种方式</li><li>对于连接断开，可能出现多个leader的问题的解决<ul><li>投票节点数必须超过系统总结点数的一半的规则 </li></ul></li></ul></li></ul><h1 id="3-可拓展性"><a href="#3-可拓展性" class="headerlink" title="3. 可拓展性"></a>3. 可拓展性</h1><ul><li>可拓展性指系统为了应对将来的需求变化而提供的一种扩展能力，当有新的需求出现的时候，系统不需要或者仅仅需要少量修改就可以支持，无须整个系统的重构或者重建。</li><li>面向对象的思想以及设计模式的诞生与演化，都是在努力提升代码的可拓展性</li><li>设计具备良好可拓展性的系统的基本条件<ul><li>正确预测变化<ul><li>不能每个点都考虑可拓展性</li><li>不能完全不考虑可拓展性</li><li>所有的预测都存在出错的可能性</li></ul></li><li>完美封装变化<ul><li>一般来说会将变化封装在一个变化层，将不变的部分封装在一个独立的稳定层</li><li>或者提炼出一个抽象层和一个实现层</li></ul></li></ul></li></ul><h1 id="4-低成本，安全，规模"><a href="#4-低成本，安全，规模" class="headerlink" title="4. 低成本，安全，规模"></a>4. 低成本，安全，规模</h1><ul><li>低成本<ul><li>通过减少服务器的数量来达成低成本的目标</li><li>首先指定一个成本目标，当我们根据高性能、高可用的要求设计出方案时，评估一下方案能否满足成本目标，如果不行，就要重新设计架构</li><li>通过引入新技术来达到目标<ul><li>NoSQL 解决关系型数据库无法应对高并发情况下的访问压力的问题</li><li>全文搜索引擎是为了解决关系型数据库like搜索的低效的问题</li><li>Hadoop的出现是为了解决传统文件体统无法应对海量数据存储和计算的问题</li></ul></li></ul></li><li>安全<ul><li>功能安全<ul><li>XSS攻击</li><li>CSRF攻击</li><li>SQL注入</li><li>Windows漏洞</li><li>密码破解</li></ul></li><li>架构安全<ul><li>防火墙<ul><li>隔离网络</li><li>通过将网络划分成不同的区域，制定出不同区域之间的访问控制策略来控制不同信任程度区域间传送的数据流</li><li>太贵，很难实现</li></ul></li><li>一般还是靠运营商或者云服务商强大的带宽和流量清洗能力</li></ul></li></ul></li><li>规模<ul><li>规模带来的复杂度 - 量变带来的质变</li><li>功能越来越多，复杂度指数级增加</li><li>数据越来越多</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习-可扩展架构模式</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%8F%AF%E6%89%A9%E5%B1%95%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%8F%AF%E6%89%A9%E5%B1%95%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-可扩展架构的基本思想和模式"><a href="#1-可扩展架构的基本思想和模式" class="headerlink" title="1. 可扩展架构的基本思想和模式"></a>1. 可扩展架构的基本思想和模式</h1><p>软件系统与硬件/建筑系统最大的差异在于软件是可扩展的，会不断更新，不断发展。如何避免扩展时改动范围太大，是软件架构可扩展性设计的主要思考点。</p><h2 id="1-1-基本思想-拆分"><a href="#1-1-基本思想-拆分" class="headerlink" title="1.1 基本思想 - 拆分"></a>1.1 基本思想 - 拆分</h2><p>将大系统细分为小系统，扩展时只是修改其中一部分即可，无须整个系统到处都改，通过这种方式来减少改动范围，降低改动风险。</p><p>不同的拆分方式，本质上决定了系统的扩展方式</p><h3 id="1-1-1-面向流程拆分-分层架构"><a href="#1-1-1-面向流程拆分-分层架构" class="headerlink" title="1.1.1 面向流程拆分 - 分层架构"></a>1.1.1 面向流程拆分 - 分层架构</h3><p>将整个业务流程分为几个阶段，每个阶段作为一部分</p><p>扩展时大部分情况只需要修改一层，或者相关联的两层，不会出现所有层都需要修改的情况的。</p><h3 id="1-1-2-面向服务拆分-SOA，微服务"><a href="#1-1-2-面向服务拆分-SOA，微服务" class="headerlink" title="1.1.2 面向服务拆分 - SOA，微服务"></a>1.1.2 面向服务拆分 - SOA，微服务</h3><p>将系统提供的服务拆分，每个服务作为一部分</p><p>扩展时只需要扩展相关服务即可。</p><h3 id="1-1-3-面向功能拆分-微内核架构"><a href="#1-1-3-面向功能拆分-微内核架构" class="headerlink" title="1.1.3 面向功能拆分 - 微内核架构"></a>1.1.3 面向功能拆分 - 微内核架构</h3><p>将系统提供的功能拆分，每个功能作为一部分</p><p>扩展时只需要扩展相关功能即可</p><h1 id="2-分层架构"><a href="#2-分层架构" class="headerlink" title="2. 分层架构"></a>2. 分层架构</h1><p>N层架构，逻辑上的分层</p><h2 id="2-1-C-S-B-S架构"><a href="#2-1-C-S-B-S架构" class="headerlink" title="2.1 C/S, B/S架构"></a>2.1 C/S, B/S架构</h2><p>划分的对象是整个业务系统，划分的维度是用户交互，将和用户交互的部分独立为一层，支撑用户交互的后台作为另外一层。 </p><h2 id="2-2-MVC-MVP架构"><a href="#2-2-MVC-MVP架构" class="headerlink" title="2.2 MVC, MVP架构"></a>2.2 MVC, MVP架构</h2><p>划分的对象是单个业务子系统，划分的维度是职责，将不同的职责划分到独立层，但各层的依赖关系会相对比较灵活。</p><h2 id="2-3-逻辑分层架构"><a href="#2-3-逻辑分层架构" class="headerlink" title="2.3 逻辑分层架构"></a>2.3 逻辑分层架构</h2><p>划分的对象可以是单个业务子系统，也可以是整个业务系统，划分的维度也是职责。虽然都是基于职责划分，但是不同点在于逻辑分层架构中的层是自顶向下依赖的。</p><h2 id="2-4-分层架构的核心"><a href="#2-4-分层架构的核心" class="headerlink" title="2.4 分层架构的核心"></a>2.4 分层架构的核心</h2><p>保证各层之间的差异足够清晰，边界足够明显，让人看到架构图之后就能看懂整个架构。</p><p>分层架构能够较好支撑系统扩展的本质在于<strong>隔离关注点</strong>，即每层的组件只会处理本层的逻辑，这样可以支撑系统在某层上快速扩展。</p><p>要保证层与层之间的依赖是稳定的。</p><p>分层结构的另外一个特点是层层传递，即一旦分层确定，整个业务流程就会按照层进行依次传递，不能在层之间进行跳跃。</p><h1 id="3-SOA-amp-微服务"><a href="#3-SOA-amp-微服务" class="headerlink" title="3. SOA &amp; 微服务"></a>3. SOA &amp; 微服务</h1><h2 id="3-1-SOA-Service-Oriented-Architecture-面向服务的架构"><a href="#3-1-SOA-Service-Oriented-Architecture-面向服务的架构" class="headerlink" title="3.1 SOA - Service Oriented Architecture - 面向服务的架构"></a>3.1 SOA - Service Oriented Architecture - 面向服务的架构</h2><p>提出的背景是企业内部的IT系统重复建设并且效率极低的问题，SOA提出了几个关键概念</p><h3 id="3-1-1-服务"><a href="#3-1-1-服务" class="headerlink" title="3.1.1 服务"></a>3.1.1 服务</h3><p>所有业务功能都是一项服务，意味着要对外提供开放的能力，当其他系统需要使用这项功能时，不需要做定制化开发。</p><h3 id="3-1-2-ESB"><a href="#3-1-2-ESB" class="headerlink" title="3.1.2 ESB"></a>3.1.2 ESB</h3><p>Enterprise Service Bus - 企业服务总线. 屏蔽异构系统对外提供各种不同的接口方式，以此达到服务间高效的互联互通。</p><p>ESB功能强大，但是现实中的协议种类很多，如JMS，WS，HTTP，RPC等，数据格式也多种多样，转换的过程是需要耗费大量计算性能的，当ESB承载的消息太多时，ESB本身会成为整个系统的性能瓶颈。</p><h3 id="3-1-3-松耦合"><a href="#3-1-3-松耦合" class="headerlink" title="3.1.3 松耦合"></a>3.1.3 松耦合</h3><p>减少各个服务间的依赖和互相影响。</p><h2 id="3-2-MicroService-微服务"><a href="#3-2-MicroService-微服务" class="headerlink" title="3.2 MicroService - 微服务"></a>3.2 MicroService - 微服务</h2><h3 id="3-2-1-微服务与SOA的关系"><a href="#3-2-1-微服务与SOA的关系" class="headerlink" title="3.2.1 微服务与SOA的关系"></a>3.2.1 微服务与SOA的关系</h3><p><img src="https://i.loli.net/2020/02/04/VgmIHRSsCUL2b6u.png" alt="fig1.png"></p><ul><li>微服务与SOA相似但是本质上并不相同<ul><li>是否有ESB<ul><li>微服务推荐使用同一的协议和格式<ul><li>例如RESTful协议， RPC协议 </li></ul></li></ul></li><li>服务的粒度<ul><li>微服务的服务粒度相对较细 </li></ul></li><li>服务交付<ul><li>微服务架构理念是快速交付，相应的就要求采取自动化测试，持续集成，自动化部署等敏捷开发相关的最佳实践。 </li></ul></li><li>应用场景<ul><li>SOA更适合于庞大、复杂、异构的企业化系统</li><li>微服务更适合于快速，轻量级，基于Web的互联网系统</li></ul></li></ul></li></ul><h3 id="3-2-2-微服务的陷阱"><a href="#3-2-2-微服务的陷阱" class="headerlink" title="3.2.2 微服务的陷阱"></a>3.2.2 微服务的陷阱</h3><ul><li>服务划分过细，服务间关系复杂</li><li>服务数量太多，团队效率急剧下降</li><li>调用链太长，性能下降<ul><li>一般线上的业务接口之间的调用，平均响应时间大约为50毫秒</li></ul></li><li>调用链太长，问题定位困难</li><li>需要自动化的支撑以实现快速交付</li></ul><h1 id="4-微服务架构最佳实践"><a href="#4-微服务架构最佳实践" class="headerlink" title="4. 微服务架构最佳实践"></a>4. 微服务架构最佳实践</h1><h2 id="4-1-方法论"><a href="#4-1-方法论" class="headerlink" title="4.1 方法论"></a>4.1 方法论</h2><h3 id="4-1-1-人员分配"><a href="#4-1-1-人员分配" class="headerlink" title="4.1.1 人员分配"></a>4.1.1 人员分配</h3><ul><li>3个人负责一个微服务</li></ul><h3 id="4-1-2-拆分逻辑的方法"><a href="#4-1-2-拆分逻辑的方法" class="headerlink" title="4.1.2 拆分逻辑的方法"></a>4.1.2 拆分逻辑的方法</h3><ul><li>基于业务逻辑拆分<ul><li>将业务模块按照职责范围识别出来，每个单独的业务模块拆分为一个独立的服务</li><li>拆分粒度的考虑 - 看人数最好 </li></ul></li><li>基于可扩展拆分<ul><li>将系统中的业务模块按照稳定性排序<ul><li>稳定服务</li><li>变动服务</li></ul></li><li>这样做的目的是为了提升项目快速迭代的效率，避免在开发的时候，不小心影响了已有的成熟功能导致线上的问题。</li></ul></li><li>基于可靠性拆分<ul><li>将业务模块按照优先级顺序排序，将可靠性要求高的核心服务和可靠性要求低的非核心服务拆分，然后重点保证核心服务的高可用</li></ul></li><li>基于性能拆分<ul><li>将性能要求高或者性能压力大的模块拆分出来，避免影响其他服务器<h2 id="4-2-基础设施"><a href="#4-2-基础设施" class="headerlink" title="4.2 基础设施"></a>4.2 基础设施</h2></li></ul></li></ul><p><img src="https://i.loli.net/2020/02/04/wVulTOvkeKRjpH4.jpg" alt="fig2.jpg"></p><ul><li>服务发现、服务路由、服务容错</li><li>接口框架、API网关</li><li>自动化部署、自动化测试、配置中心</li><li>服务监控、服务跟踪、服务安全</li></ul><h3 id="4-2-1-自动化测试"><a href="#4-2-1-自动化测试" class="headerlink" title="4.2.1 自动化测试"></a>4.2.1 自动化测试</h3><ul><li>代码级的单元测试</li><li>单个系统级的集成测试</li><li>系统间的接口测试</li></ul><h3 id="4-2-2-自动化部署"><a href="#4-2-2-自动化部署" class="headerlink" title="4.2.2 自动化部署"></a>4.2.2 自动化部署</h3><ul><li>版本管理</li><li>资源管理</li><li>部署操作</li><li>回退操作</li></ul><h3 id="4-2-3-配置中心"><a href="#4-2-3-配置中心" class="headerlink" title="4.2.3 配置中心"></a>4.2.3 配置中心</h3><ul><li>统一的配置中心来管理所有微服务节点的配置</li><li>配置中心包括<ul><li>版本管理</li><li>增删改查配置</li><li>结点管理</li><li>配置同步</li><li>配置推送</li></ul></li></ul><h3 id="4-2-4-接口框架"><a href="#4-2-4-接口框架" class="headerlink" title="4.2.4 接口框架"></a>4.2.4 接口框架</h3><p>除了统一接口协议，还要统一接口传递的数据格式</p><h3 id="4-2-5-API网关"><a href="#4-2-5-API网关" class="headerlink" title="4.2.5 API网关"></a>4.2.5 API网关</h3><p>内部微服务是相互连通的，相互访问都是点对点的。如果外部系统想调用系统的某个功能，也采取点对点的方式，那么外部系统会很崩，因为其无法理解这么多微服务的职责分工和边界，它只会关注其所需要的能力，而不会关注这个能力应该由哪个微服务提供。</p><p>====》 微服务需要一个统一的API网关，负责外部系统的访问操作</p><p>API网关是外部系统访问的接口，所有的外部系统接入系统都需要通过API网关，主要包括：</p><ul><li>接入鉴权 - 是否允许接入</li><li>权限控制 - 可以访问哪些功能</li><li>传输加密 </li><li>请求路由</li><li>流量控制</li></ul><h3 id="4-2-6-服务发现"><a href="#4-2-6-服务发现" class="headerlink" title="4.2.6 服务发现"></a>4.2.6 服务发现</h3><ul><li>自理式结构<ul><li>每个微服务自己完成服务发现</li></ul></li><li>代理式<ul><li>微服务之间有一个负载均衡系统，有负载均衡系统来完成微服务之间的服务发现 </li></ul></li></ul><p><img src="https://i.loli.net/2020/02/04/PWs5h1L2EFHizZn.png" alt="fig3.png"></p><p><img src="https://i.loli.net/2020/02/04/hmHp54yirJAWPgQ.png" alt="fig4.png"></p><h3 id="4-2-7-服务容错"><a href="#4-2-7-服务容错" class="headerlink" title="4.2.7 服务容错"></a>4.2.7 服务容错</h3><ul><li>请求重试</li><li>流量控制</li><li>服务隔离</li></ul><h3 id="4-2-8-服务监控"><a href="#4-2-8-服务监控" class="headerlink" title="4.2.8 服务监控"></a>4.2.8 服务监控</h3><ul><li>实时搜集信息并进行分析，避免故障后再来分析，减少了处理时间</li><li>在实时分析的基础上进行预警，在问题萌芽的阶段发觉并预警，降低问题的影响范围和影响时间</li></ul><h3 id="4-2-9-服务跟踪"><a href="#4-2-9-服务跟踪" class="headerlink" title="4.2.9 服务跟踪"></a>4.2.9 服务跟踪</h3><p>对于单个请求的完整跟踪，记录单个请求的发起时间，响应时间，响应错误码，请求参数，返回的JSON对象等信息。</p><h3 id="4-2-10-服务安全"><a href="#4-2-10-服务安全" class="headerlink" title="4.2.10 服务安全"></a>4.2.10 服务安全</h3><ul><li>接入安全</li><li>数据安全</li><li>传输安全</li></ul><h1 id="5-微内核架构"><a href="#5-微内核架构" class="headerlink" title="5. 微内核架构"></a>5. 微内核架构</h1><p>也被称为插件化架构(Plug-in Architecture), 是一种面向功能进行拆分的可扩展性架构。</p><h2 id="5-1-基本架构"><a href="#5-1-基本架构" class="headerlink" title="5.1 基本架构"></a>5.1 基本架构</h2><ul><li>核心系统<ul><li>负责和具体业务功能无关的通用功能，例如模块加载，模块间通信 </li></ul></li><li>插件模块<ul><li>负责实现具体的业务逻辑</li></ul></li></ul><p><img src="https://i.loli.net/2020/02/04/kz3Wg4ehDEc2xqv.png" alt="fig5.png"></p><p>微内核架构本质就是将变化的部分封装在插件里面，从而达到快速灵活扩展的目的，而又不会影响整体系统的稳定。</p><h2 id="5-2-设计关键点"><a href="#5-2-设计关键点" class="headerlink" title="5.2 设计关键点"></a>5.2 设计关键点</h2><h3 id="5-2-1-插件管理"><a href="#5-2-1-插件管理" class="headerlink" title="5.2.1 插件管理"></a>5.2.1 插件管理</h3><p>通过插件注册表，来知道当前有哪些插件，如何加载以及何时加载。插件注册表含有每个插件模块的信息，包括其名字，位置，加载时机等。</p><h3 id="5-2-2-插件连接"><a href="#5-2-2-插件连接" class="headerlink" title="5.2.2 插件连接"></a>5.2.2 插件连接</h3><p>插件是如何连接到核心系统的。</p><p>常见连接机制：</p><ul><li>OSGi </li><li>消息模式</li><li>依赖注入</li><li>分布式协议  RPC， HTTP</li></ul><h3 id="5-2-3-插件通信"><a href="#5-2-3-插件通信" class="headerlink" title="5.2.3 插件通信"></a>5.2.3 插件通信</h3><p>实际应用当中会出现某个业务流程需要多个插件协作，这就要求两个插件之间进行通信。由于插件之间没有直接的联系，通信必须通过核心系统，因此核心系统需要提供插件通信机制。</p><h2 id="5-3-OSGi框架"><a href="#5-3-OSGi框架" class="headerlink" title="5.3 OSGi框架"></a>5.3 OSGi框架</h2><p><img src="https://i.loli.net/2020/02/04/QBtP6Gqxea5bV1Z.png" alt="fig6.png"></p><p>该框架为通过网络向设备提供服务建立开发的标准。该框架的初始目标是构建一个在广域网和局域网或设备上展开业务的基础平台，但因为其的动态化，热拔插，高可复用性的特点，成为了首选的插件化标准。</p><h3 id="5-3-1-模块层-Module"><a href="#5-3-1-模块层-Module" class="headerlink" title="5.3.1 模块层 (Module)"></a>5.3.1 模块层 (Module)</h3><p>模块层实现插件管理功能，插件被称为Bundle，每个Bundle是一个Java的JAR文件。模块层里含有所有的插件。</p><h3 id="5-3-2-生命周期层-Lifecycle"><a href="#5-3-2-生命周期层-Lifecycle" class="headerlink" title="5.3.2 生命周期层 (Lifecycle)"></a>5.3.2 生命周期层 (Lifecycle)</h3><p>实现插件连接功能，提供了执行时的模块管理，模块对底层OSGi框架的访问。生命周期层精确定义了Bundle生命周期的操作(安装、更新、启动、停止、卸载)，Bundle必须按照规范实现各个操作。</p><h3 id="5-3-3-服务层-Service"><a href="#5-3-3-服务层-Service" class="headerlink" title="5.3.3 服务层 (Service)"></a>5.3.3 服务层 (Service)</h3><p>服务层实现插件通信的功能。OSGi提供了一个服务注册的功能，用于插件将自己能提供的服务注册到OSGi核心的服务注册中心当中，如果某个服务想用其他服务，则直接在服务注册中心搜索可用服务中心即可。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习-原则</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%8E%9F%E5%88%99/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<p>程序员和架构师之间的区别：如何处理不确定性的。对于程序员来说，编程本身不能存在不确定性，执行结果需要是确定的。但是对于架构设计来说，本质上是不确定的，同样的一个系统，可能AB两家公司做出的架构差异很大，但是都能正确运转。<strong>架构设计常常面对多种可能性来进行选择</strong>。</p><p>太多的选择，需要一些框架来更好的做出决定。</p><h1 id="1-合适原则-合适优于业界领先"><a href="#1-合适原则-合适优于业界领先" class="headerlink" title="1. 合适原则 - 合适优于业界领先"></a>1. 合适原则 - 合适优于业界领先</h1><p>需不需要？有没有那么多人力？有没有足够的应用场景？ </p><h1 id="2-简单原则"><a href="#2-简单原则" class="headerlink" title="2. 简单原则"></a>2. 简单原则</h1><p>简单优于复杂的，复杂在软件工程领域“可能”意味着问题。因为我们需要持续在上面改进的。</p><ul><li>复杂性体现在<ul><li>结构的复杂性<ul><li>组件数量多</li><li>组件之间的关系更为复杂</li><li>某个组件的改动，会影响关联的所有组件</li><li>定位一个复杂系统当中的问题总是比简单系统的更加困难</li></ul></li><li>逻辑的复杂性<ul><li>一个组件承担太多功能会对开发维护都造成很大的困扰</li><li></li></ul></li></ul></li></ul><h1 id="3-演化原则"><a href="#3-演化原则" class="headerlink" title="3. 演化原则"></a>3. 演化原则</h1><p>演化优于一步到位，因为软件的更新，架构的变化非常快。软件的架构需要根据业务的发展不断变化。</p><ul><li>设计出来的架构要满足当时的业务需要</li><li>架构要不断地在实际应用过程当中迭代，保留优秀的设计，修复有缺陷的设计，逐渐完善架构</li><li>当业务发生变化的时候，架构要扩展，重构甚至重写</li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>架构学习-general</title>
      <link href="/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-general/"/>
      <url>/%E6%9E%B6%E6%9E%84%E5%AD%A6%E4%B9%A0-general/</url>
      
        <content type="html"><![CDATA[<h1 id="1-架构Intro"><a href="#1-架构Intro" class="headerlink" title="1. 架构Intro"></a>1. 架构Intro</h1><ul><li>架构设计的关键思维是<strong>判断和取舍</strong>，程序设计的关键思维是<strong>逻辑和实现</strong>。</li></ul><h2 id="1-1-架构世界的历史背景"><a href="#1-1-架构世界的历史背景" class="headerlink" title="1.1 架构世界的历史背景"></a>1.1 架构世界的历史背景</h2><ul><li>机器语言 <ul><li>01书写</li><li>难读，难写，难改</li></ul></li><li>汇编语言<ul><li>用地址符号或标号代替指令或操作数的地址</li><li>面向机器的语言，不够友好</li></ul></li><li>高级语言<ul><li>Fortran 公式翻译器</li><li>LISP 枚举处理器</li><li>Cobol 通用商业导向语言</li></ul></li></ul><h1 id="2-概念梳理"><a href="#2-概念梳理" class="headerlink" title="2. 概念梳理"></a>2. 概念梳理</h1><h2 id="2-1-系统与子系统"><a href="#2-1-系统与子系统" class="headerlink" title="2.1 系统与子系统"></a>2.1 系统与子系统</h2><blockquote><p>系统泛指由一群有关联的个体组成，根据某种规则运作，能完成个别元件不能单独完成的工作的群体</p></blockquote><ul><li>系统<ul><li>关联：相互之间有关联</li><li>规则：按照指定的规则运作</li><li>能力：产生了新的个体不具备的能力</li></ul></li><li>子系统<ul><li>更大系统的一部分</li></ul></li></ul><p>划分系统的时候一般是按照业务系统来划分的，可能一个子系统里面会有服务层，数据层，blabla. </p><h2 id="2-2-模块与组件"><a href="#2-2-模块与组件" class="headerlink" title="2.2 模块与组件"></a>2.2 模块与组件</h2><ul><li><p>模块</p><ul><li>互相有紧密关联的软件组织</li><li>程序和数据结构两部分</li><li>模块作为合成的单位</li><li>模块的接口表达了由该模块提供的功能和调用它所需的元素</li><li>模块是可以分开来编写的单位</li></ul></li><li><p>组件</p><ul><li>自包含的，可编程的，可重用的与语言无关的软件单元</li></ul></li><li><p>Summary</p><ul><li>模块和组件都是系统的组成部分，只是从不同角度来拆分了系统</li><li>逻辑角度拆分系统，得到的就是模块；划分模块的主要目的是职责分离</li><li>划分组件的主要目的是单元复用</li></ul></li><li><p>E.G</p><ul><li>一个信息管理系统，逻辑角度，可以划分成登录注册模块，个人信息模块，个人成绩模块</li><li>物理角度，Nginx，Web服务器，Mysql</li></ul></li></ul><h2 id="2-3-框架与架构"><a href="#2-3-框架与架构" class="headerlink" title="2.3 框架与架构"></a>2.3 框架与架构</h2><ul><li>框架<ul><li>为了实现某个业界标准或完成特定的基本任务的软件组件规范，也指为了实现某个软件组件规范时，提供规范锁要求的基础功能的软件产品</li><li>框架是组件规范 - MVC MVVM J2EE</li><li>提供基础功能的产品</li><li>面向编程或配置的半成品</li></ul></li></ul><blockquote><p>架构指软件系统的基础结构，创造这些基础结构的准则以及对这些结构的描述</p></blockquote><ul><li>软件架构指软件系统的顶层结构<ul><li>系统是一群关联个体组成，可以使子系统，模块，组件等</li><li>系统中的个体需要根据某种规则运作</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简单工厂模式</title>
      <link href="/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>静态/简单工厂模式是工厂模式中最简单的一种实现，但是它实现了工厂模式的精髓，即将对象的创建和使用分离开，客户端通过调用工厂来创建具体的产品类。</p><h1 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h1><pre><code>class Chart {    private String type; //图表类型    public Chart(Object[][] data, String type) {        this.type = type;        if (type.equalsIgnoreCase(&quot;histogram&quot;)) {            //初始化柱状图        }        else if (type.equalsIgnoreCase(&quot;pie&quot;)) {            //初始化饼状图        }        else if (type.equalsIgnoreCase(&quot;line&quot;)) {            //初始化折线图        }    }    public void display() {        if (this.type.equalsIgnoreCase(&quot;histogram&quot;)) {            //显示柱状图        }        else if (this.type.equalsIgnoreCase(&quot;pie&quot;)) {            //显示饼状图        }        else if (this.type.equalsIgnoreCase(&quot;line&quot;)) {            //显示折线图        }        }}</code></pre><p>问题：</p><ol><li>冗长</li><li>职责太重</li><li>Constructor构建会非常耗时</li></ol><h1 id="2-简单工程模式概述"><a href="#2-简单工程模式概述" class="headerlink" title="2. 简单工程模式概述"></a>2. 简单工程模式概述</h1><h2 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h2><p>首先将需要创建的各种不同对象（例如各种不同的Chart对象）的相关代码封装到不同的类中，这些类称为具体产品类，而将它们公共的代码进行抽象和提取后封装在一个抽象产品类中，每一个具体产品类都是抽象产品类的子类；然后提供一个工厂类用于创建各种产品，在工厂类中提供一个创建产品的工厂方法，该方法可以根据所传入的参数不同创建不同的具体产品对象；客户端只需调用工厂类的工厂方法并传入相应的参数即可得到一个产品对象。</p><ul><li>具体产品类</li><li>抽象产品类</li><li>工厂类 - 创建产品，工厂方法</li><li>客户端 调用工厂类的工厂方法得到产品对象</li></ul><blockquote><p>简单工厂模式(Simple Factory Pattern)：定义一个工厂类，它可以根据参数的不同返回不同类的实例，被创建的实例通常都具有共同的父类。因为在简单工厂模式中用于创建实例的方法是<strong>静态(static)<em>方法</em></strong>，因此简单工厂模式又被称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。</p></blockquote><h2 id="2-2-结构"><a href="#2-2-结构" class="headerlink" title="2.2 结构"></a>2.2 结构</h2><p><img src="https://i.loli.net/2020/02/04/N5tmV9o1EPlgFLr.jpg" alt="sf1.jpeg"></p><ul><li>Factory</li></ul><p>工厂角色即工厂类，它是简单工厂模式的核心，负责实现创建所有产品实例的内部逻辑；工厂类可以被外界直接调用，创建所需的产品对象；在工厂类中提供了静态的工厂方法factoryMethod()，它的返回类型为抽象产品类型Product。</p><ul><li>Product 抽象产品</li></ul><p>它是工厂类所创建的所有对象的父类，封装了各种产品对象的公有方法，它的引入将提高系统的灵活性，使得在工厂类中只需定义一个通用的工厂方法，因为所有创建的具体产品对象都是其子类对象。</p><ul><li>ConcreteProduct 具体产品</li></ul><p>它是简单工厂模式的创建目标，所有被创建的对象都充当这个角色的某个具体类的实例。每一个具体产品角色都继承了抽象产品角色，需要实现在抽象产品中声明的抽象方法。</p><h1 id="3-代码实现"><a href="#3-代码实现" class="headerlink" title="3 代码实现"></a>3 代码实现</h1><pre><code>abstract class Product {    //所有产品类的公共业务方法    public void methodSame() {        //公共方法的实现    }    //声明抽象业务方法    public abstract void methodDiff();}class ConcreteProduct extends Product {//实现业务方法    public void methodDiff() {    //业务方法的实现    }}class Factory {    //静态工厂方法    public static Product getProduct(String arg) {        Product product = null;        if (arg.equalsIgnoreCase(&quot;A&quot;)) {            product = new ConcreteProductA();            //初始化设置product        }        else if (arg.equalsIgnoreCase(&quot;B&quot;)) {            product = new ConcreteProductB();            //初始化设置product        }        return product;    }}//客户端代码，直接调用工厂类的工厂方法来得到产品对象class Client {    public static void main(String args[]) {        Product product;         product = Factory.getProduct(&quot;A&quot;); //通过工厂类创建产品对象        product.methodSame();        product.methodDiff();    }}</code></pre><h2 id="3-1-结构图"><a href="#3-1-结构图" class="headerlink" title="3.1 结构图"></a>3.1 结构图</h2><p><img src="https://i.loli.net/2020/02/04/FdsgZtQ27rE1NTU.jpg" alt="sf2.jpeg"></p><h2 id="3-2-完整方案"><a href="#3-2-完整方案" class="headerlink" title="3.2 完整方案"></a>3.2 完整方案</h2><pre><code>//抽象图表接口：抽象产品类interface Chart {    public void display();}//柱状图类：具体产品类class HistogramChart implements Chart {    public HistogramChart() {        System.out.println(&quot;创建柱状图！&quot;);    }    public void display() {        System.out.println(&quot;显示柱状图！&quot;);    }}//饼状图类：具体产品类class PieChart implements Chart {    public PieChart() {        System.out.println(&quot;创建饼状图！&quot;);    }    public void display() {        System.out.println(&quot;显示饼状图！&quot;);    }}//折线图类：具体产品类class LineChart implements Chart {    public LineChart() {        System.out.println(&quot;创建折线图！&quot;);    }    public void display() {        System.out.println(&quot;显示折线图！&quot;);    }}//图表工厂类：工厂类class ChartFactory {    //静态工厂方法    public static Chart getChart(String type) {        Chart chart = null;        if (type.equalsIgnoreCase(&quot;histogram&quot;)) {            chart = new HistogramChart();            System.out.println(&quot;初始化设置柱状图！&quot;);        }        else if (type.equalsIgnoreCase(&quot;pie&quot;)) {            chart = new PieChart();            System.out.println(&quot;初始化设置饼状图！&quot;);        }        else if (type.equalsIgnoreCase(&quot;line&quot;)) {            chart = new LineChart();            System.out.println(&quot;初始化设置折线图！&quot;);                    }        return chart;    }}</code></pre><h2 id="3-3-改进"><a href="#3-3-改进" class="headerlink" title="3.3 改进"></a>3.3 改进</h2><p>将选择具体的chart类的代码封装到xml文件里，然后写一个相应的方法去读取XML参数。</p><pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;&lt;config&gt;    &lt;chartType&gt;histogram&lt;/chartType&gt;&lt;/config&gt;</code></pre><p>写一个工具类，来获取XML文件里的参数</p><pre><code>import javax.xml.parsers.*;import org.w3c.dom.*;import org.xml.sax.SAXException;import java.io.*;public class XMLUtil {    //该方法用于从XML配置文件中提取图表类型，并返回类型名    public static String getChartType() {        try {            //创建文档对象            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();            DocumentBuilder builder = dFactory.newDocumentBuilder();            Document doc;                                        doc = builder.parse(new File(&quot;config.xml&quot;));             //获取包含图表类型的文本节点            NodeList nl = doc.getElementsByTagName(&quot;chartType&quot;);            Node classNode = nl.item(0).getFirstChild();            String chartType = classNode.getNodeValue().trim();            return chartType;        }              catch(Exception e) {               e.printStackTrace();            return null;        }    }}</code></pre><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4.总结"></a>4.总结</h1><p><img src="https://i.loli.net/2020/02/04/aSZD7Iv5A1wsN2C.jpg" alt="sf3.jpeg"></p><h2 id="4-1-优势"><a href="#4-1-优势" class="headerlink" title="4.1 优势"></a>4.1 优势</h2><ol><li>将对象的创建和使用分离</li><li>客户端不再直接创建产品对象，仅仅消费产品</li><li>配置文件，提高系统灵活性</li></ol><h2 id="4-2-缺陷"><a href="#4-2-缺陷" class="headerlink" title="4.2 缺陷"></a>4.2 缺陷</h2><ol><li>工厂类集中了所有的创建逻辑，职责太重。一旦不能正常工作，整个系统都要受影响。</li><li>势必增加类的个数，引入新的工厂类，增加了系统的复杂度和理解程度</li><li>系统扩展困难！！！一旦添加新产品就必须修改工厂逻辑</li><li>使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构</li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design Pattern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>抽象工厂模式</title>
      <link href="/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>工厂方法模式通过引入工厂等级结构，解决了简单工厂模式中工厂类职责太重的问题，但是由于工厂方法模式中的每一个工厂只生产一类产品，可能会导致系统中存在大量的工厂类，势必会增加系统的开销。我们可以考虑<strong>将一些相关的产品组成一个产品族，由同一个工厂来统一生产</strong>。</p><h1 id="1-初始设计"><a href="#1-初始设计" class="headerlink" title="1. 初始设计"></a>1. 初始设计</h1><p>  Sunny软件公司欲开发一套界面皮肤库，可以对Java桌面软件进行界面美化。为了保护版权，该皮肤库源代码不打算公开，而只向用户提供已打包为jar文件的class字节码文件。用户在使用时可以通过菜单来选择皮肤，不同的皮肤将提供视觉效果不同的按钮、文本框、组合框等界面元素，<br><img src="https://i.loli.net/2020/02/04/RnYfcDpNqtkuCPj.jpg" alt="fm1.jpg"></p><p>  采用工厂模式进行系统设计的结构图如下：</p><p><img src="https://i.loli.net/2020/02/04/UAnaQOVXW4vZiSY.jpg" alt="fm2.jpg"></p><h2 id="1-1-存在的问题"><a href="#1-1-存在的问题" class="headerlink" title="1.1 存在的问题"></a>1.1 存在的问题</h2><ol><li>当需要增加新的皮肤时，虽然不要修改现有代码，但是需要增加大量类，针对每一个新增具体组件都需要增加一个具体工厂，<strong><em>类的个数成对增加，这无疑会导致系统越来越庞大，增加系统的维护成本和运行开销</em></strong>；</li><li>由于同一种风格的具体界面组件通常要一起显示，因此需要为每个组件都选择一个具体工厂，用户在使用时必须逐个进行设置，如果某个具体工厂选择失误将会导致界面显示混乱，虽然我们可以适当增加一些约束语句，但客户端代码和配置文件都较为复杂。</li></ol><h1 id="2-产品等级结构"><a href="#2-产品等级结构" class="headerlink" title="2. 产品等级结构"></a>2. 产品等级结构</h1><p>在工厂方法模式中具体工厂负责生产具体的产品，每一个<strong><em>具体工厂</em></strong>对应一种具体产品，工厂方法具有唯一性，一般情况下，一个具体工厂中只有一个或者一组重载的工厂方法。<strong><em>但是有时候我们希望一个工厂可以提供多个产品对象，而不是单一的产品对象</em></strong>，如一个电器工厂，它可以生产电视机、电冰箱、空调等多种电器，而不是只生产某一种电器。</p><h2 id="2-1-概念"><a href="#2-1-概念" class="headerlink" title="2.1 概念"></a>2.1 概念</h2><ol><li>产品等级结构</li></ol><p>即产品的继承结构</p><ol start="2"><li>产品族</li></ol><p>指由同一个工厂生产的，位于不同产品等级结构中的一组产品</p><p><img src="https://i.loli.net/2020/02/04/qJn7UsTMcC9tzw3.jpg" alt="fm3.jpg"></p><p><img src="https://i.loli.net/2020/02/04/n8ezWVCKOUSmN7p.jpg" alt="fm4.jpg"></p><p>当系统所提供的工厂生产的具体产品不是一个简单的对象，而是多个位于不同产品等级结构，属于不同类型的具体产品。</p><p>抽象工厂模式是所有形式的工厂模式中最为抽象和最具一般性的一种形式。抽象工厂模式与工厂方法模式最大的区别在于，工厂方法模式针对的是一个产品等级结构，而抽象工厂模式需要面对多个产品等级结构，一个工厂等级结构可以负责多个不同产品等级结构中的产品对象的创建。当一个工厂等级结构可以创建出分属于不同产品等级结构的一个产品族中的所有对象时，抽象工厂模式比工厂方法模式更为简单、更有效率。</p><h1 id="3-抽象工厂模式概述"><a href="#3-抽象工厂模式概述" class="headerlink" title="3. 抽象工厂模式概述"></a>3. 抽象工厂模式概述</h1><p>为创建一组对象提供了一种解决方案，与工厂方法模式相比，抽象工厂模式中的具体工厂不只是创建一种产品，它负责创建一族产品：</p><blockquote><p>抽象工厂模式(Abstract Factory Pattern)：提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。抽象工厂模式又称为Kit模式，它是一种对象创建型模式。</p></blockquote><p> 在抽象工厂模式中，每一个具体工厂都提供了多个工厂方法用于产生多种不同类型的产品，这些产品构成了一个产品族</p><h2 id="3-1-包含的角色"><a href="#3-1-包含的角色" class="headerlink" title="3.1 包含的角色"></a>3.1 包含的角色</h2><ol><li>Abstract Factory 抽象工厂</li></ol><p>声明了一组用于创建一族产品的方法，每一个方法对应一种产品</p><ol start="2"><li>Concrete Factory 具体工厂</li></ol><p>实现了在抽象工厂中声明的创建产品的方法，生成一组具体的产品，这些产品构成了一个产品族</p><ol start="3"><li>Abstract Product 抽象产品</li></ol><p>为每种产品声明接口，在抽象产品中声明了产品所具有的业务方法</p><ol start="4"><li>Concrete Product 具体产品</li></ol><p>定义具体工厂产生的具体产品对象，实现抽象产品接口中声明的业务方法。</p><h2 id="3-2-具体实现"><a href="#3-2-具体实现" class="headerlink" title="3.2 具体实现"></a>3.2 具体实现</h2><p>在抽象工厂中声明了多个工厂方法，用于创建不同类型的产品，抽象工厂可以是接口，也可以是抽象类或者具体类，</p><pre><code>abstract class AbstractFactory {    public abstract AbstractProductA createProductA(); //工厂方法一    public abstract AbstractProductB createProductB(); //工厂方法二……}</code></pre><p>具体工厂实现了抽象工厂，每一个具体的工厂方法可以返回一个特定的产品对象，而同一个具体工厂所创建的产品对象构成了一个产品族。</p><pre><code>class ConcreteFactory1 extends AbstractFactory {    //工厂方法一    public AbstractProductA createProductA() {        return new ConcreteProductA1();    }    //工厂方法二    public AbstractProductB createProductB() {        return new ConcreteProductB1();    }……}</code></pre><h1 id="4-完整方案"><a href="#4-完整方案" class="headerlink" title="4. 完整方案"></a>4. 完整方案</h1><p><img src="https://i.loli.net/2020/02/04/628fTVDd9QaOrxm.jpg" alt="fm5.jpg"></p><p><img src="https://i.loli.net/2020/02/04/vJZSa3Ddi8olf6g.jpg" alt="fm6.jpg"></p><p>SkinFactory接口充当抽象工厂，其子类SpringSkinFactory和SummerSkinFactory充当具体工厂，接口Button、TextField和ComboBox充当抽象产品，其子类SpringButton、SpringTextField、SpringComboBox和SummerButton、SummerTextField、SummerComboBox充当具体产品。</p><p>//在本实例中我们对代码进行了大量简化，实际使用时，界面组件的初始化代码较为复杂，还需要使用JDK中一些已有类，为了突出核心代码，在此只提供框架代码和演示输出。<br>    //按钮接口：抽象产品<br>    interface Button {<br>        public void display();<br>    }</p><pre><code>//Spring按钮类：具体产品class SpringButton implements Button {    public void display() {        System.out.println(&quot;显示浅绿色按钮。&quot;);    }}//Summer按钮类：具体产品class SummerButton implements Button {    public void display() {        System.out.println(&quot;显示浅蓝色按钮。&quot;);    }    }//文本框接口：抽象产品interface TextField {    public void display();}//Spring文本框类：具体产品class SpringTextField implements TextField {    public void display() {        System.out.println(&quot;显示绿色边框文本框。&quot;);    }}//Summer文本框类：具体产品class SummerTextField implements TextField {    public void display() {        System.out.println(&quot;显示蓝色边框文本框。&quot;);    }    }//组合框接口：抽象产品interface ComboBox {    public void display();}//Spring组合框类：具体产品class SpringComboBox implements ComboBox {    public void display() {        System.out.println(&quot;显示绿色边框组合框。&quot;);    }}//Summer组合框类：具体产品class SummerComboBox implements ComboBox {    public void display() {        System.out.println(&quot;显示蓝色边框组合框。&quot;);    }    }//界面皮肤工厂接口：抽象工厂interface SkinFactory {    public Button createButton();    public TextField createTextField();    public ComboBox createComboBox();}//Spring皮肤工厂：具体工厂class SpringSkinFactory implements SkinFactory {    public Button createButton() {        return new SpringButton();    }    public TextField createTextField() {        return new SpringTextField();    }    public ComboBox createComboBox() {        return new SpringComboBox();    }}//Summer皮肤工厂：具体工厂class SummerSkinFactory implements SkinFactory {    public Button createButton() {        return new SummerButton();    }    public TextField createTextField() {        return new SummerTextField();    }    public ComboBox createComboBox() {        return new SummerComboBox();    }}</code></pre><p>引入工具类和配置文件，增强系统的灵活性和可扩展性</p><pre><code>import javax.xml.parsers.*;import org.w3c.dom.*;import org.xml.sax.SAXException;import java.io.*;public class XMLUtil {//该方法用于从XML配置文件中提取具体类类名，并返回一个实例对象    public static Object getBean() {        try {            //创建文档对象            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();            DocumentBuilder builder = dFactory.newDocumentBuilder();            Document doc;                                        doc = builder.parse(new File(&quot;config.xml&quot;));             //获取包含类名的文本节点            NodeList nl = doc.getElementsByTagName(&quot;className&quot;);            Node classNode=nl.item(0).getFirstChild();            String cName=classNode.getNodeValue();            //通过类名生成实例对象并将其返回            Class c=Class.forName(cName);              Object obj=c.newInstance();            return obj;        }           catch(Exception e) {               e.printStackTrace();               return null;           }    }}</code></pre><p>配置文件config.xml中存储具体工厂类的类名</p><pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;&lt;config&gt;    &lt;className&gt;SpringSkinFactory&lt;/className&gt;&lt;/config&gt;</code></pre><h1 id="5-开闭原则的倾斜性"><a href="#5-开闭原则的倾斜性" class="headerlink" title="5. 开闭原则的倾斜性"></a>5. 开闭原则的倾斜性</h1><p>Sunny公司使用抽象工厂模式设计了界面皮肤库，该皮肤库可以较为方便地增加新的皮肤，但是现在遇到一个非常严重的问题：由于设计时考虑不全面，忘记为单选按钮(RadioButton)提供不同皮肤的风格化显示，导致无论选择哪种皮肤，单选按钮都显得那么“格格不入”。Sunny公司的设计人员决定向系统中增加单选按钮，但是发现原有系统居然不能够在符合“开闭原则”的前提下增加新的组件，原因是抽象工厂SkinFactory中根本没有提供创建单选按钮的方法，如果需要增加单选按钮，首先需要修改抽象工厂接口SkinFactory，在其中新增声明创建单选按钮的方法，然后逐个修改具体工厂类，增加相应方法以实现在不同的皮肤中创建单选按钮，此外还需要修改客户端，否则单选按钮无法应用于现有系统。</p><p>抽象工厂模式无法解决这个问题。在本模式中，增加新的产品族很方便，但是增加新的产品等级结构很麻烦。</p><ol><li>增加产品族</li></ol><p>对于增加新的产品族，抽象工厂模式很好地支持了“开闭原则”，只需要增加具体产品并对应增加一个新的具体工厂，对已有代码无须做任何修改。</p><ol start="2"><li>增加产品等级结构</li></ol><p>对于增加新的产品族，抽象工厂模式很好地支持了“开闭原则”，只需要增加具体产品并对应增加一个新的具体工厂，对已有代码无须做任何修改。</p><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h1><h2 id="6-1-优势"><a href="#6-1-优势" class="headerlink" title="6.1 优势"></a>6.1 优势</h2><ol><li>隔离了具体类的生成，使得更换具体工厂变得容易。所有的具体工厂都实现了抽象工厂中定义的那些公共接口，因此只需要改变具体工厂的实例，就可以在某种程度上改变整个软件系统的行为。</li><li>当一个产品族中的多个对象被设计成一起工作时，它能够保证客户端始终只使用同一个产品族中的对象。</li></ol><h2 id="6-2-劣势"><a href="#6-2-劣势" class="headerlink" title="6.2 劣势"></a>6.2 劣势</h2><ol><li>增加新的产品等级结构麻烦，需要对原有系统进行较大的修改，甚至需要修改抽象层代码，这显然会带来较大的不便，违背了“开闭原则”。</li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design Pattern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微信红包高并发架构设计</title>
      <link href="/%E5%BE%AE%E4%BF%A1%E7%BA%A2%E5%8C%85%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"/>
      <url>/%E5%BE%AE%E4%BF%A1%E7%BA%A2%E5%8C%85%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-微信红包业务特点以及技术难点"><a href="#1-微信红包业务特点以及技术难点" class="headerlink" title="1. 微信红包业务特点以及技术难点"></a>1. 微信红包业务特点以及技术难点</h1><h2 id="1-1-业务特点"><a href="#1-1-业务特点" class="headerlink" title="1.1 业务特点"></a>1.1 业务特点</h2><p>类似于线上的秒杀，海量的并发请求；更严格的安全级别，因为牵扯到资金交易，所以就不可以有像用秒杀活动当中的那种超卖的方式。</p><h2 id="1-2-流程"><a href="#1-2-流程" class="headerlink" title="1.2 流程"></a>1.2 流程</h2><ul><li><p>proxy</p><ul><li>处理请求接入 </li></ul></li><li><p>server</p><ul><li>主要业务逻辑 </li></ul></li><li><p>DB</p><ul><li>数据持久化 </li><li>事务级别的完成 - 完全执行或者完全不执行<ul><li>锁库存<ul><li>为了避免并发请求时出现超卖情况</li><li>技术难点，当大量用户同时做秒杀操作的时候，第一个到达DB的请求锁住了这行库存记录。在第一个事务完成提交之前这个锁一直被第一个请求占用。——&gt; 技术难点，并发请求抢锁</li></ul></li><li>插入秒杀记录</li><li>更新库存</li></ul></li></ul></li><li><p>Cache </p><ul><li>缓存库存数量 </li></ul></li></ul><h1 id="2-微信红包系统的高并发解决方案"><a href="#2-微信红包系统的高并发解决方案" class="headerlink" title="2. 微信红包系统的高并发解决方案"></a>2. 微信红包系统的高并发解决方案</h1><h2 id="2-1-高并发问题常用方案"><a href="#2-1-高并发问题常用方案" class="headerlink" title="2.1 高并发问题常用方案"></a>2.1 高并发问题常用方案</h2><h3 id="2-1-1-使用内存操作替代实时的DB事务操作"><a href="#2-1-1-使用内存操作替代实时的DB事务操作" class="headerlink" title="2.1.1 使用内存操作替代实时的DB事务操作"></a>2.1.1 使用内存操作替代实时的DB事务操作</h3><p>server 到内存Cache，做扣库存的操作，然后内存Cache异步持久化到数据库。但是如果内存Cache炸了，或者内存Cache更新，但是DDB没有更新，都会很崩。多个服务器之间的同步也会是一个不小的问题。</p><h3 id="2-1-2-使用乐观锁-instead-of-悲观锁"><a href="#2-1-2-使用乐观锁-instead-of-悲观锁" class="headerlink" title="2.1.2 使用乐观锁 instead of 悲观锁"></a>2.1.2 使用乐观锁 instead of 悲观锁</h3><ul><li>乐观锁<ul><li>假设多用户并发的事务处理时不会相互影响。在提交数据更新之前，每个事务会检查在该事务读取数据之后，有没有其他事务又修改了数据。如果其他事务用更新的话，正在提交的事务会进行回滚。</li></ul></li><li>悲观锁<ul><li>阻止一个事务以影响其他用户的方式来修改数据</li></ul></li></ul><p>对于微信红包的使用场景，即需要在DB里维护一个版本号，在更新库存的操作进行之前，先去DB获取当前版本号，然后在更新库存的事务提交的时候，检查是否被修改。</p><p>这么做的问题在于：</p><ul><li>乐观锁，多个用户同时抢红包，那势必只有一个成功，另外的都会显示失败 - 报错，这就用户体验很差劲了</li><li>而且会造成刚开始可能失败，后面因为并发小了，有成功的案例的可能性</li><li>大量无效请求，回滚，给DB带来很大压力</li></ul><h2 id="2-2-微信红包系统的解决方案"><a href="#2-2-微信红包系统的解决方案" class="headerlink" title="2.2 微信红包系统的解决方案"></a>2.2 微信红包系统的解决方案</h2><ul><li>系统垂直SET化<ul><li>生成ID作为红包的唯一标识</li><li>红包系统根据ID做垂直切分，一个垂直逻辑链条上的Server和DB们叫做一个SET</li><li>各个SET相互独立，且解耦，每个红包ID的所有请求都会在同一个SET当中来处理<ul><li>看起来像是需要主备两台服务器，备用服务器平常没有流量，完全用来在主服务器出问题的时候，直接转备用</li></ul></li></ul></li><li>逻辑Server层将请求排队，解决DB并发问题<ul><li>将拆红包的事务操作做串行处理，在Server层做FIFO的排队处理</li></ul></li><li>memcached控制并发<ul><li>利用CAS原子累增操作，控制同时进入DB拆红包的请求数，超过预定值就直接拒绝服务，通过这种方式来做DB负载过高时的降级体验</li></ul></li><li>双维度库存表设计<ul><li>TTL </li><li>冷热数据分离</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>建造者模式</title>
      <link href="/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>建造者模式，又称为生成器模式，为客户端返回一个由多个部件组成的复杂产品。</p><h1 id="1-建造者模式概述"><a href="#1-建造者模式概述" class="headerlink" title="1. 建造者模式概述"></a>1. 建造者模式概述</h1><p>小例子，设计游戏角色病可以快速生成。对于各种角色来说，创建步骤相对比较类似，逐步创建其组成部分，再将各组成部分装配成一个完整的游戏角色。</p><p>建造者模式将客户端和包含各个组成部分的复杂对象的创建过程分离，客户端无须知道复杂对象的内部组成部分与装配方式，只需要知道所需建造者的类型即可。</p><blockquote><p>建造者模式，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式是一种对象创建型模式。</p></blockquote><h2 id="1-1-建造者模式结构"><a href="#1-1-建造者模式结构" class="headerlink" title="1.1 建造者模式结构"></a>1.1 建造者模式结构</h2><p><img src="https://i.loli.net/2020/02/04/Tl4oLzhx16i9Uvq.gif" alt="1.gif"><br>建造者模式结构图</p><h2 id="1-2-建造者模式角色"><a href="#1-2-建造者模式角色" class="headerlink" title="1.2 建造者模式角色"></a>1.2 建造者模式角色</h2><ol><li>Builder(抽象建造者)</li></ol><p>为创建一个产品Product对象的各个部件指定抽象接口，包含两类方法。一是buildPart()， 二是getResult()方法</p><ol start="2"><li>ConcreteBuilder(具体建造者)</li></ol><p>实现了Builder接口，实现各个部件的具体构造和装配方法，定义并明确其所创建的复杂对象。</p><ol start="3"><li>Product(产品角色)</li></ol><p>是被构建的复杂对象，包含多个组成部件，具体建造者创建该产品，并定义其装配过程</p><ol start="4"><li>Director(指挥者)</li></ol><p>指挥者又称为导演类，它负责安排<strong>复杂对象的建造次序</strong>，指挥者与抽象建造者之间存在关联关系，可以在其construct()建造方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造。客户端一般只需要与指挥者进行交互，在客户端确定具体建造者的类型，并实例化具体建造者对象（也可以通过配置文件和反射机制），然后通过指挥者类的构造函数或者Setter方法将该对象传入指挥者类中。</p><p>在建造者模式的结构中还引入了一个指挥者类Director，该类主要有两个作用：一方面它隔离了客户与创建过程；另一方面它控制产品的创建过程，包括某个buildPartX()方法是否被调用以及多个buildPartX()方法调用的先后次序等。指挥者针对抽象建造者编程，客户端只需要知道具体建造者的类型，即可通过指挥者类调用建造者的相关方法，返回一个完整的产品对象。</p><h1 id="2-游戏角色创建解决方案"><a href="#2-游戏角色创建解决方案" class="headerlink" title="2. 游戏角色创建解决方案"></a>2. 游戏角色创建解决方案</h1><p><img src="https://i.loli.net/2020/02/04/R7D3qoj6ugxTIiQ.gif" alt="2.gif"><br>角色创建结构图</p><p>Actor角色类</p><pre><code>// import lombok@Dataclass Actor{    private String type;    private String sex;    private String face;    private String costume;    private String hairstyle;}</code></pre><p>角色建造起：抽象建造者</p><pre><code>abstract class ActorBuilder {    public void buildType() {        actor.setType(&quot;Charm&quot;);    }}</code></pre><p>指挥者类<br>    class ActorController {<br>        public Actor construct(ActorBuilder ab) {<br>            Actor actor;<br>            ab.buildType();<br>            ab.buildSex();<br>            …<br>            actor = ab.createActor();<br>            return actor;<br>        }<br>    }</p><h1 id="3-关于Director的讨论"><a href="#3-关于Director的讨论" class="headerlink" title="3. 关于Director的讨论"></a>3. 关于Director的讨论</h1><h2 id="3-1-省略Director"><a href="#3-1-省略Director" class="headerlink" title="3.1 省略Director"></a>3.1 省略Director</h2><p>将Director和抽象建造者Builder进行合并，在Builder中提供逐步构建复杂产品对象的construct()方法，控制调用的先后次序。</p><pre><code>abstract class ActorBuilder{       protected static Actor actor = new  Actor();       public  abstract void buildType();       public  abstract void buildSex();       public  abstract void buildFace();       public  abstract void buildCostume();       public  abstract void buildHairstyle();       public static Actor  construct(ActorBuilder ab)       {              ab.buildType();              ab.buildSex();              ab.buildFace();              ab.buildCostume();              ab.buildHairstyle();              return actor;       }}</code></pre><h2 id="3-2-设值钩子方法"><a href="#3-2-设值钩子方法" class="headerlink" title="3.2 设值钩子方法"></a>3.2 设值钩子方法</h2><p>来控制对BuilderPart的调用</p><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><h2 id="4-1-优点"><a href="#4-1-优点" class="headerlink" title="4.1 优点"></a>4.1 优点</h2><ol><li>产品本身与创建过程解耦</li><li>具体建造者之间相对独立</li></ol><h2 id="4-2-缺点"><a href="#4-2-缺点" class="headerlink" title="4.2 缺点"></a>4.2 缺点</h2><ol><li>同一个Builder建的很类似啊，需要产品本身相似程度比较高，否则会很受限</li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design Pattern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工厂方法模式</title>
      <link href="/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<blockquote><p>简单工厂模式虽然简单，但存在一个很严重的问题。当系统中需要引入新产品时，由于静态工厂方法通过所传入参数的不同来创建不同的产品，这必定要修改工厂类的源代码，将违背“开闭原则”，如何实现增加新产品而不影响已有代码？工厂方法模式应运而生，本文将介绍第二种工厂模式——工厂方法模式。</p></blockquote><h1 id="1-日志记录器的设计"><a href="#1-日志记录器的设计" class="headerlink" title="1. 日志记录器的设计"></a>1. 日志记录器的设计</h1><p>Sunny软件公司欲开发一个系统运行日志记录器(Logger)，该记录器可以通过多种途径保存系统的运行日志，如通过文件记录或数据库记录，用户可以通过修改配置文件灵活地更换日志记录方式。在设计各类日志记录器时，Sunny公司的开发人员发现需要对日志记录器进行一些初始化工作，初始化参数的设置过程较为复杂，而且某些参数的设置有严格的先后次序，否则可能会发生记录失败。如何封装记录器的初始化过程并保证多种记录器切换的灵活性是Sunny公司开发人员面临的一个难题。</p><h2 id="1-1-设计要点"><a href="#1-1-设计要点" class="headerlink" title="1.1 设计要点"></a>1.1 设计要点</h2><ol><li>需要封装日志记录器的初始化过程，这些初始化工作较为复杂，例如需要初始化其他相关的类，还有可能需要读取配置文件（例如连接数据库或创建文件），导致代码较长，如果将它们都写在构造函数中，会导致构造函数庞大，不利于代码的修改和维护</li><li>用户可能需要更换日志记录方式，在客户端代码中需要提供一种灵活的方式来选择日志记录器，尽量在不修改源代码的基础上更换或者增加日志记录方式。</li></ol><p><img src="https://i.loli.net/2020/02/03/7ArHEvCctiokB4U.jpg" alt="gc1.jpeg"></p><p>用简单工厂模式来做系统设计，LoggerFactory来创建具体的logger，抽象类logger被几个具体的logger类实现，客户端通过调用LoggerFactory来生成具体的logger对象。</p><pre><code>//日志记录器工厂class LoggerFactory {    //静态工厂方法    public static Logger createLogger(String args) {        if(args.equalsIgnoreCase(&quot;db&quot;)) {            //连接数据库，代码省略            //创建数据库日志记录器对象            Logger logger = new DatabaseLogger();             //初始化数据库日志记录器，代码省略            return logger;        }        else if(args.equalsIgnoreCase(&quot;file&quot;)) {            //创建日志文件            //创建文件日志记录器对象            Logger logger = new FileLogger();             //初始化文件日志记录器，代码省略            return logger;                    }        else {            return null;        }    }}</code></pre><p>通过这种模式，我们将日志记录器的创建和使用分离，客户端只需使用由工厂类创建的日志记录器对象即可。但仍存在一些问题：</p><ol><li>工厂类过于庞大，包含了大量的if…else…代码，导致维护和测试难度增大</li><li>系统扩展不灵活，如果增加新类型的日志记录器，必须修改静态工厂方法的业务逻辑，违反了“开闭原则”。</li></ol><h1 id="2-工厂方法模式概述"><a href="#2-工厂方法模式概述" class="headerlink" title="2. 工厂方法模式概述"></a>2. 工厂方法模式概述</h1><p>简单工厂模式只提供了一个工厂类，该工厂类处于对产品类进行实例化的中心位置，它需要知道每一个产品对象的创建细节，并决定何时实例化哪一个产品类。简单工厂模式最大的缺点是<strong>当有新产品要加入到系统中时，必须修改工厂类，需要在其中加入必要的业务逻辑，这违背了“开闭原则”</strong>。 此外，在简单工厂模式中，所有的产品都由同一个工厂创建，工厂类职责较重，业务逻辑较为复杂，具体产品与工厂类之间的耦合度高，严重影响了系统的灵活性和扩展性，而工厂方法模式则可以很好地解决这一问题。</p><h2 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h2><blockquote><p>工厂方法模式不再提供一个统一的工厂类来创建所有的产品对象，而是针对不同的产品提供不同的工厂，系统提供一个与产品等级结构对应的工厂等级结构。</p></blockquote><blockquote><p>工厂方法模式(Factory Method Pattern)：<strong><em>定义一个用于创建对象的接口，让子类决定将哪一个类实例化</em></strong>。工厂方法模式让一个类的实例化延迟到其子类。工厂方法模式又简称为工厂模式(Factory Pattern)，又可称作虚拟构造器模式(Virtual Constructor Pattern)或多态工厂模式(Polymorphic Factory Pattern)。工厂方法模式是一种类创建型模式。</p></blockquote><p><img src="https://i.loli.net/2020/02/03/lFQLbIy2eUzV8Nu.jpg" alt="gc2.jpeg"></p><h2 id="2-2-组成"><a href="#2-2-组成" class="headerlink" title="2.2 组成"></a>2.2 组成</h2><p>工厂方法模式包含以下几个组成部分：</p><ul><li>Product 抽象产品</li></ul><p>它是定义产品的接口，是工厂方法模式所创建对象的超类型，也就是产品对象的公共父类。</p><ul><li>Concrete Product 具体产品</li></ul><p>它实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，具体工厂和具体产品之间一一对应。</p><ul><li>Factory 抽象工厂</li></ul><p>在抽象工厂类中，声明了工厂方法(Factory Method)，用于返回一个产品。抽象工厂是工厂方法模式的核心，所有创建对象的工厂类都必须实现该接口。</p><ul><li>Concrete Factory 具体工厂</li></ul><p>它是抽象工厂类的子类，实现了抽象工厂中定义的工厂方法，并可由客户端调用，返回一个具体产品类的实例。</p><h2 id="2-3-实现"><a href="#2-3-实现" class="headerlink" title="2.3 实现"></a>2.3 实现</h2><p>抽象工厂，可以使接口，或者是抽象类</p><pre><code>interface Factory {    public Product factoryMethod();}</code></pre><p>抽象工厂声明了工厂方法但是并未实现工厂方法，具体产品对象的创建由其子类负责，客户端针对抽象工厂编程，<strong><em>运行时再指定具体工厂类</em></strong>。不同的具体工厂可以创建不同的具体产品。</p><pre><code>class ConcreteFactory implements Factory {    public Product factoryMethod() {        return new ConcreteProduct();    }}</code></pre><p> 在实际使用时，具体工厂类在实现工厂方法时除了创建具体产品对象之外，还可以负责产品对象的初始化工作以及一些资源和环境配置工作，例如连接数据库、创建文件等。</p><p> 在客户端代码中，只需关注工厂类即可，不同的具体工厂可以创建不同的产品。</p><pre><code> ……Factory factory;factory = new ConcreteFactory(); //可通过配置文件实现Product product;product = factory.factoryMethod();……</code></pre><h2 id="2-4-完整解决方案"><a href="#2-4-完整解决方案" class="headerlink" title="2.4 完整解决方案"></a>2.4 完整解决方案</h2><p><img src="https://i.loli.net/2020/02/03/f6Stw3NPsXAiyC4.jpg" alt="gc3.jpeg"></p><p>Logger是抽象产品， 其子类FileLogger和DatabaseLogger充当具体产品，LoggerFactory接口充当抽象工厂，其子类FileLoggerFactory和DatabaseLoggerFactory充当具体工厂。</p><pre><code>//日志记录器接口：抽象产品interface Logger {    public void writeLog();}//数据库日志记录器：具体产品class DatabaseLogger implements Logger {    public void writeLog() {        System.out.println(&quot;数据库日志记录。&quot;);    }}//文件日志记录器：具体产品class FileLogger implements Logger {    public void writeLog() {        System.out.println(&quot;文件日志记录。&quot;);    }}//日志记录器工厂接口：抽象工厂interface LoggerFactory {    public Logger createLogger();}//数据库日志记录器工厂类：具体工厂class DatabaseLoggerFactory implements LoggerFactory {    public Logger createLogger() {            //连接数据库，代码省略            //创建数据库日志记录器对象            Logger logger = new DatabaseLogger();             //初始化数据库日志记录器，代码省略            return logger;    }    }//文件日志记录器工厂类：具体工厂class FileLoggerFactory implements LoggerFactory {    public Logger createLogger() {            //创建文件日志记录器对象            Logger logger = new FileLogger();             //创建文件，代码省略            return logger;    }    }</code></pre><p>客户端测试代码：</p><pre><code>class Client {    public static void main(String args[]) {        LoggerFactory factory;        Logger logger;        factory = new FileLoggerFactory(); //可引入配置文件实现        logger = factory.createLogger();        logger.writeLog();    }}</code></pre><h2 id="2-5-反射与配置文件"><a href="#2-5-反射与配置文件" class="headerlink" title="2.5 反射与配置文件"></a>2.5 反射与配置文件</h2><p><strong><em>如何在不修改任何客户端代码的基础上更新或增加新的日志记录方式？</em></strong></p><p>在客户端代码中将不再使用new关键字来创建工厂对象，而是将具体工厂类的类名存储在配置文件（如XML文件）中，<strong>通过读取配置文件获取类名字符串</strong>，再使用<strong>Java的反射机制</strong>，根据类名字符串生成对象。在整个实现过程中需要用到两个技术：Java反射机制与配置文件读取。</p><blockquote><p>Java反射机制</p></blockquote><p>是指在程序运行时获取已知名称的类或已有对象的相关信息的一种机制，包括类的方法、属性、父类等信息，还包括实例的创建和实例类型的判断等。在反射中使用最多的类是<strong>Class，Class类的实例表示正在运行的Java应用程序中的类和接口</strong>，其forName(String className)方法可以返回与带有给定字符串名的类或接口相关联的 Class对象，再通过Class对象的newInstance()方法创建此对象所表示的类的一个新实例，即通过一个类名字符串得到类的实例。</p><pre><code>   //通过类名生成实例对象并将其返回   Class c=Class.forName(&quot;String&quot;);   Object obj=c.newInstance();   return obj;</code></pre><p>而后使用XML格式的配置文件config.xml用于存储具体日志记录器工厂类类名：</p><pre><code>&lt;!— config.xml --&gt;&lt;?xml version=&quot;1.0&quot;?&gt;&lt;config&gt;    &lt;className&gt;FileLoggerFactory&lt;/className&gt;&lt;/config&gt;</code></pre><p>然后用一个名为XMLUtil的工具类来获取xml文件定义的类，<strong>并且生成实例对象</strong>。 </p><pre><code>//工具类XMLUtil.javaimport javax.xml.parsers.*;import org.w3c.dom.*;import org.xml.sax.SAXException;import java.io.*;public class XMLUtil {//该方法用于从XML配置文件中提取具体类类名，并返回一个实例对象    public static Object getBean() {        try {            //创建DOM文档对象            DocumentBuilderFactory dFactory = DocumentBuilderFactory.newInstance();            DocumentBuilder builder = dFactory.newDocumentBuilder();            Document doc;                                        doc = builder.parse(new File(&quot;config.xml&quot;));             //获取包含类名的文本节点            NodeList nl = doc.getElementsByTagName(&quot;className&quot;);            Node classNode=nl.item(0).getFirstChild();            String cName=classNode.getNodeValue();            //通过类名生成实例对象并将其返回            Class c=Class.forName(cName);              Object obj=c.newInstance();            return obj;        }           catch(Exception e) {               e.printStackTrace();               return null;         }    }}</code></pre><p>而后客户端不需要再使用new关键字来创建具体的工厂类了，可以将具体工厂类的类名存储在XML文件中，再通过XMLUtil类的静态工厂方法getBean()进行对象的实例化</p><pre><code>class Client {    public static void main(String args[]) {        LoggerFactory factory;        Logger logger;        factory = (LoggerFactory)XMLUtil.getBean(); //getBean()的返回类型为Object，需要进行强制类型转换        logger = factory.createLogger();        logger.writeLog();    }}</code></pre><p>引入了Util和XML配置文件之后，如果要增加新的日志记录方式，只需要：</p><ol><li>新的日志记录器需要继承抽象日志记录器Logger</li><li>对应增加一个新的具体日志记录器工厂，继承抽象日志记录器工厂LoggerFactory，并实现其中的工厂方法createLogger()，设置好初始化参数和环境变量，返回具体日志记录器对象；</li><li>修改配置文件config.xml，将新增的具体日志记录器工厂类的类名字符串替换原有工厂类类名字符串</li><li>编译新增的具体日志记录器类和具体日志记录器工厂类，运行客户端测试类即可使用新的日志记录方式，而原有类库代码无须做任何修改，完全符合“开闭原则”。</li></ol><h2 id="2-6-重载的工厂方法"><a href="#2-6-重载的工厂方法" class="headerlink" title="2.6 重载的工厂方法"></a>2.6 重载的工厂方法</h2><p>发现可以通过多种方式来初始化日志记录器，例如可以为各种日志记录器提供默认实现；还可以为数据库日志记录器提供数据库连接字符串，为文件日志记录器提供文件路径；也可以将参数封装在一个Object类型的对象中，通过Object对象将配置参数传入工厂类。此时，可以提供一组重载的工厂方法，以不同的方式对产品对象进行创建。当然，对于同一个具体工厂而言，无论使用哪个工厂方法，创建的产品类型均要相同。</p><p><img src="https://i.loli.net/2020/02/03/l8TdOYBKXeCmqbD.jpg" alt="gc4.jpeg"></p><p>引入重载方法后，抽象工厂LoggerFactory的代码修改如下：</p><pre><code>interface LoggerFactory {    public Logger createLogger();    public Logger createLogger(String args);    public Logger createLogger(Object obj);}</code></pre><p>具体工厂类DatabaseLoggerFactory代码修改如下：</p><pre><code>class DatabaseLoggerFactory implements LoggerFactory {    public Logger createLogger() {            //使用默认方式连接数据库，代码省略            Logger logger = new DatabaseLogger();             //初始化数据库日志记录器，代码省略            return logger;    }    public Logger createLogger(String args) {            //使用参数args作为连接字符串来连接数据库，代码省略            Logger logger = new DatabaseLogger();             //初始化数据库日志记录器，代码省略            return logger;    }        public Logger createLogger(Object obj) {            //使用封装在参数obj中的连接字符串来连接数据库，代码省略            Logger logger = new DatabaseLogger();             //使用封装在参数obj中的数据来初始化数据库日志记录器，代码省略            return logger;    }    }//其他具体工厂类代码省略</code></pre><p>在抽象工厂中定义多个重载的工厂方法，在具体工厂中实现了这些工厂方法，这些方法可以包含不同的业务逻辑，以满足对不同产品对象的需求。</p><h2 id="2-7-工厂方法的隐藏"><a href="#2-7-工厂方法的隐藏" class="headerlink" title="2.7 工厂方法的隐藏"></a>2.7 工厂方法的隐藏</h2><p> 有时候，为了进一步简化客户端的使用，还可以对客户端隐藏工厂方法，此时，在工厂类中将直接调用产品类的业务方法，客户端无须调用工厂方法创建产品，直接通过工厂即可使用所创建的对象中的业务方法。</p><p><img src="gc5.jpeg" alt="gc5.jpeg"></p><p>就是抽象工厂类从接口变成abstract类，并且在这个抽象类里面实现产品类的业务方法。</p><pre><code>//改为抽象类abstract class LoggerFactory {    //在工厂类中直接调用日志记录器类的业务方法writeLog()    public void writeLog() {        Logger logger = this.createLogger();        logger.writeLog();    }    public abstract Logger createLogger();    }</code></pre><p>客户端代码修改成：</p><pre><code>class Client {    public static void main(String args[]) {        LoggerFactory factory;        factory = (LoggerFactory)XMLUtil.getBean();        factory.writeLog(); //直接使用工厂对象来调用产品对象的业务方法    }}</code></pre><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><h2 id="3-1-优势"><a href="#3-1-优势" class="headerlink" title="3.1 优势"></a>3.1 优势</h2><ol><li>工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，<strong>用户只需要关心所需产品对应的工厂，无须关心创建细节，甚至无须知道具体产品类的类名</strong>。</li><li>基于工厂角色和产品角色的<strong>多态性设计</strong>是工厂方法模式的关键。它能够让工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，就正是因为所有的具体工厂类都具有同一抽象父类。</li><li>使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，<strong>而只要添加一个具体工厂和具体产品就可以了</strong>，这样，系统的可扩展性也就变得非常好，完全符合“开闭原则”。</li></ol><h2 id="3-2-劣势"><a href="#3-2-劣势" class="headerlink" title="3.2 劣势"></a>3.2 劣势</h2><ol><li>在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要编译和运行，会给系统带来一些额外的开销。</li><li>由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。</li></ol><h1 id="4-Reference"><a href="#4-Reference" class="headerlink" title="4. Reference"></a>4. Reference</h1><p><a href="https://blog.csdn.net/lovelion/article/details/9306457" target="_blank" rel="noopener">1. CSDN Liuwei</a></p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design Pattern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何确定一个服务器的最大连接数</title>
      <link href="/%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0/"/>
      <url>/%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E4%B8%80%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9C%80%E5%A4%A7%E8%BF%9E%E6%8E%A5%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-连接数定义"><a href="#1-连接数定义" class="headerlink" title="1. 连接数定义"></a>1. 连接数定义</h1><p>对于给定的一个服务器而言，在任意时刻能够同时处理的最大连接数。</p><h1 id="2-Tips"><a href="#2-Tips" class="headerlink" title="2. Tips"></a>2. Tips</h1><h2 id="2-1-如果超过了会怎么样"><a href="#2-1-如果超过了会怎么样" class="headerlink" title="2.1 如果超过了会怎么样"></a>2.1 如果超过了会怎么样</h2><ul><li>如果使用了Spillover的feature，额外的请求会被放置到队列里</li><li>如果没使用，那么HTTP 503会返回，对于TCP连接，会被重置掉</li></ul><h2 id="2-2-如果得出准确的允许的最大连接数？"><a href="#2-2-如果得出准确的允许的最大连接数？" class="headerlink" title="2.2 如果得出准确的允许的最大连接数？"></a>2.2 如果得出准确的允许的最大连接数？</h2><p>没有办法直接得出，因为运行的代码本身，机器本身都会对结果产生影响的，最好的方式依旧是做测试，即不停更改最大连接数，单独测试一个host在不同连接数的情况下的metrics，譬如延时问题，有没有fatals, etc. 以此来得到针对实际情况的正确地值。</p><h2 id="2-3-General-公式"><a href="#2-3-General-公式" class="headerlink" title="2.3 General 公式"></a>2.3 General 公式</h2><ul><li>需要使用的CPU时间 (local resource)</li><li>远端，网路延时 （remote latency）</li><li>CPU 核心数量</li></ul><p>参考公式</p><pre><code>maxConns = ((local + remote) / local) * cores</code></pre>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>原型模式</title>
      <link href="/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-原型模式概述"><a href="#1-原型模式概述" class="headerlink" title="1. 原型模式概述"></a>1. 原型模式概述</h1><p>原型模式指：通过一个原型对象克隆出多个一模一样的对象。</p><p>在使用原型模式时，首先需要创建一个原型对象，再通过复制这个原型对象来创建更多同类型的对象。</p><blockquote><p>使用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。原型模式时一种对象创建型模式。</p></blockquote><h2 id="1-1-工作原理"><a href="#1-1-工作原理" class="headerlink" title="1.1 工作原理"></a>1.1 工作原理</h2><p>将一个原型对象传给要发动创建的对象，这个要发动创建的对象通过请求原型对象拷贝自己来实现创建过程。</p><p>通过克隆方法所创建的对象是全新的，在内存中有新的地址，对克隆对象所产生的对象进行修改不会对原型对象产生任何影响。</p><h2 id="1-2-包含角色"><a href="#1-2-包含角色" class="headerlink" title="1.2 包含角色"></a>1.2 包含角色</h2><p><img src="https://i.loli.net/2020/02/03/NSa3iLpPcvoCfIq.gif" alt="1.gif"></p><ul><li>Prototype (抽象原型类)</li></ul><p>是声明克隆方法的接口，是所有具体类型类的公共父类。抽象类/ 接口/ 具体实现类</p><ul><li>ConcretePrototype (具体原型类)</li></ul><p>实现了抽象原型类中声明的克隆方法，在克隆方法中返回一个自己的克隆对象</p><ul><li>Client</li></ul><p>让一个原型对象克隆自身，从而创建一个新的对象。客户类针对抽象原型类Prototype编程，因此用户可以根据需要选择具体原型类，扩展性加强了。</p><h1 id="2-原型模式的实现"><a href="#2-原型模式的实现" class="headerlink" title="2. 原型模式的实现"></a>2. 原型模式的实现</h1><h2 id="2-1-通用实现方法"><a href="#2-1-通用实现方法" class="headerlink" title="2.1 通用实现方法"></a>2.1 通用实现方法</h2><pre><code>class ConcretePrototype implements Prototype {    private String attr; //成员属性    public void setAttr(String attr) {        this.attr = attr;    }    public String getAttr() {        return this.attr;    }    public Prototype clone() //克隆方法    {        Prototype prototype = new ConcretePrototype(); //创建新对象        prototype.setAttr(this.attr);        return prototype;    }}</code></pre><h2 id="2-2-Java提供的clone-方法"><a href="#2-2-Java提供的clone-方法" class="headerlink" title="2.2 Java提供的clone()方法"></a>2.2 Java提供的clone()方法</h2><p>所有的Java类都继承自java.lang.Object。事实上，Object提供了clone()方法，可以将一个Java对象复制一份。可以直接使用这个方法来实现克隆的。</p><pre><code>class ConcretePrototype implements Cloneable {    public Prototype clone() {    　　Object object = null;    　　try {    　　　　　object = super.clone();    　　} catch (CloneNotSupportedException exception) {    　　　　　System.err.println(&quot;Not support cloneable&quot;);    　　}    　　return (Prototype )object;    }}</code></pre><p>Java中的clone()满足：</p><ol><li>对于任何对象，都有<code>x.clone() != x</code>，即克隆方法创建了新的对象</li><li>对于任何对象，都有<code>x.clone().getClass() == x.getClass()</code>，即克隆对象与原型对象的类型一样</li><li>派生类需要实现Cloneable接口</li></ol><h1 id="3-原型模式实现工作周报快速创建"><a href="#3-原型模式实现工作周报快速创建" class="headerlink" title="3. 原型模式实现工作周报快速创建"></a>3. 原型模式实现工作周报快速创建</h1><p><img src="https://i.loli.net/2020/02/03/Ci24JYEqs6z8GgX.gif" alt="2.gif"></p><p>快速创建周报结构图</p><p>//工作周报WeeklyLog：具体原型类，考虑到代码的可读性和易理解性，只列出部分与模式相关的核心代码</p><pre><code>class WeeklyLog implements Cloneable{    private String name;    private String date;    private String content;    public  void setName(String name) {        this.name  = name;    }    public  void setDate(String date) {        this.date  = date;    }    public  void setContent(String content) {        this.content  = content;    }    public  String getName() {        return  (this.name);    }    public  String getDate() {        return  (this.date);    }    public  String getContent() {        return  (this.content);    }     //克隆方法clone()，此处使用Java语言提供的克隆机制    public WeeklyLog clone()    {        Object obj = null;        try {        obj = super.clone();        return (WeeklyLog)obj;      } catch(CloneNotSupportedException e) {        System.out.println(&quot;不支持复制！&quot;);        return null;        }    }}</code></pre><p>测试代码:</p><pre><code>class Client{    public  static void main(String args[])    {              WeeklyLog log_previous = new WeeklyLog();  //创建原型对象              log_previous.setName(&quot;张无忌&quot;);              log_previous.setDate(&quot;第12周&quot;);              log_previous.setContent(&quot;这周工作很忙，每天加班！&quot;);              System.out.println(&quot;****周报****&quot;);              System.out.println(&quot;周次：&quot; +  log_previous.getDate());              System.out.println(&quot;姓名：&quot; +  log_previous.getName());              System.out.println(&quot;内容：&quot; +  log_previous.getContent());              System.out.println(&quot;--------------------------------&quot;);              WeeklyLog  log_new;              log_new  = log_previous.clone(); //调用克隆方法创建克隆对象              log_new.setDate(&quot;第13周&quot;);              System.out.println(&quot;****周报****&quot;);              System.out.println(&quot;周次：&quot; + log_new.getDate());              System.out.println(&quot;姓名：&quot; + log_new.getName());              System.out.println(&quot;内容：&quot; + log_new.getContent());       }}</code></pre><h1 id="4-浅克隆与深克隆"><a href="#4-浅克隆与深克隆" class="headerlink" title="4. 浅克隆与深克隆"></a>4. 浅克隆与深克隆</h1><p>在java中，数据类型分为值类型和引用类型，值类型包括int,double, byte, boolean, char等，引用类型包括类，接口，数组等。浅克隆与深克隆的区别在于是否支持引用类型的成员变量的复制。</p><h2 id="4-1-浅克隆"><a href="#4-1-浅克隆" class="headerlink" title="4.1 浅克隆"></a>4.1 浅克隆</h2><p><img src="https://i.loli.net/2020/02/03/xbMHXnZEd3NJlgh.gif" alt="3.gif"><br>浅克隆示意图</p><p>如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象，也就是说二者的成员变量指向了相同的内存地址。<strong><em>在浅克隆中，当对象被复制时只复制它本身和其中包含的值类型的成员变量，而引用类型的成员对象并没有复制</em></strong>。</p><p><img src="https://i.loli.net/2020/02/03/KiLnFxBw2ODJvuI.gif" alt="4.gif"><br>带附件的周报结构图</p><p>附件类代码：</p><pre><code>//附件类class Attachment{    private String name; //附件名    public void setName(String name) {        this.name = name;    }    public String getName() {        return this.name;    }    public void download() {        System.out.println(&quot;下载附件，文件名为&quot; + name);    }}</code></pre><p>工作周报类代码</p><pre><code>//工作周报WeeklyLogclass WeeklyLog implements Cloneable{     //为了简化设计和实现，假设一份工作周报中只有一个附件对象，实际情况中可以包含多个附件，可以通过List等集合对象来实现       private Attachment attachment;       private String name;       private  String date;       private  String content;       public void setAttachment(Attachment  attachment) {              this.attachment = attachment;       }       public  void setName(String name) {              this.name  = name;       }       public  void setDate(String date) {              this.date  = date;       }       public  void setContent(String content) {              this.content  = content;       }       public Attachment  getAttachment(){              return (this.attachment);       }       public  String getName() {              return  (this.name);       }       public  String getDate() {              return  (this.date);       }       public  String getContent() {              return  (this.content);       }     //使用clone()方法实现浅克隆       public WeeklyLog clone()       {              Object obj = null;              try              {                     obj = super.clone();                     return (WeeklyLog)obj;              }              catch(CloneNotSupportedException  e)              {                System.out.println(&quot;不支持复制！&quot;);                     return null;              }       }}</code></pre><p>客户端代码：</p><pre><code>class Client{       public  static void main(String args[])       {              WeeklyLog  log_previous, log_new;              log_previous  = new WeeklyLog(); //创建原型对象              Attachment  attachment = new Attachment(); //创建附件对象              log_previous.setAttachment(attachment);  //将附件添加到周报中              log_new  = log_previous.clone(); //调用克隆方法创建克隆对象              //比较周报              System.out.println(&quot;周报是否相同？ &quot; + (log_previous ==  log_new));              //比较附件              System.out.println(&quot;附件是否相同？ &quot; +  (log_previous.getAttachment() == log_new.getAttachment()));       }}</code></pre><h2 id="4-2-深克隆"><a href="#4-2-深克隆" class="headerlink" title="4.2 深克隆"></a>4.2 深克隆</h2><p>无论原型对象的成员变量是值类型还是引用类型，都将复制一份给克隆对象。即深克隆中，除了对象本身被复制外，对象所包含的所有成员变量也将复制。</p><p><img src="https://i.loli.net/2020/02/03/6QblH4gmPvqx2FN.gif" alt="5.gif"><br>深克隆示意图</p><p>如果要实现深克隆，在Java中可以通过序列化Serialization等方式来实现。</p><p>序列化，将对象写到流里，通过序列化的拷贝不仅可以复制对象本身，也可以复制其引用的成员对象。因此通过序列化将对象写到一个流中，再从流里将其读出来，可以实现深克隆。需要注意的是能够实现序列化的对象其类必须实现<strong>Serializable接口</strong>，否则无法实现序列化操作。</p><p><img src="https://i.loli.net/2020/02/03/1vYLodkxTpSJ5q2.gif" alt="6.gif"><br>带附件的周报结构图</p><p>附件类：</p><p>import  java.io.*;</p><p>//附件类</p><pre><code>class  Attachment implements Serializable{       private  String name; //附件名       public  void setName(String name)       {              this.name  = name;       }       public  String getName()       {              return  this.name;       }     public void download()     {            System.out.println(&quot;下载附件，文件名为&quot; + name);     }}</code></pre><p>工作周报类代码实现：</p><pre><code>import  java.io.*;//工作周报类class  WeeklyLog implements Serializable{       private  Attachment attachment;       private  String name;       private  String date;       private  String content;       public  void setAttachment(Attachment attachment) {              this.attachment  = attachment;       }       public  void setName(String name) {              this.name  = name       }       public  void setDate(String date) {              this.date  = date;       }       public  void setContent(String content) {              this.content  = content;       }       public  Attachment getAttachment(){              return  (this.attachment);       }       public  String getName() {              return  (this.name);       }       public  String getDate() {              return  (this.date);       }       public  String getContent() {              return  (this.content);       }   //使用序列化技术实现深克隆       public WeeklyLog deepClone() throws  IOException, ClassNotFoundException, OptionalDataException       {              //将对象写入流中              ByteArrayOutputStream bao=new  ByteArrayOutputStream();              ObjectOutputStream oos=new  ObjectOutputStream(bao);              oos.writeObject(this);              //将对象从流中取出              ByteArrayInputStream bis=new  ByteArrayInputStream(bao.toByteArray());              ObjectInputStream ois=new  ObjectInputStream(bis);              return  (WeeklyLog)ois.readObject();       }}</code></pre><p>客户端代码：</p><pre><code>class Client{       public  static void main(String args[])       {              WeeklyLog  log_previous, log_new = null;              log_previous  = new WeeklyLog(); //创建原型对象              Attachment  attachment = new Attachment(); //创建附件对象              log_previous.setAttachment(attachment);  //将附件添加到周报中              try              {                     log_new =  log_previous.deepClone(); //调用深克隆方法创建克隆对象                                }              catch(Exception e)              {                  System.err.println(&quot;克隆失败！&quot;);              }              //比较周报              System.out.println(&quot;周报是否相同？ &quot; + (log_previous ==  log_new));              //比较附件              System.out.println(&quot;附件是否相同？ &quot; +  (log_previous.getAttachment() == log_new.getAttachment()));       }}</code></pre><blockquote><p>Tips: java中的Cloneable和Serializable接口的代码很简单，都是空接口，也成为标识接口，其中没有任何方法的定义，其作用是告诉JRE这些接口的实现类是否具有某个功能。</p></blockquote><h2 id="4-3-Java中实现深克隆的方法浅析"><a href="#4-3-Java中实现深克隆的方法浅析" class="headerlink" title="4.3 Java中实现深克隆的方法浅析"></a>4.3 Java中实现深克隆的方法浅析</h2><h3 id="4-3-1-Apache-Commons-Lang"><a href="#4-3-1-Apache-Commons-Lang" class="headerlink" title="4.3.1 Apache Commons Lang"></a>4.3.1 Apache Commons Lang</h3><p>SerializationUtils#clone, will perform a deep copy when all classes in the object graph implement the serializable interface. </p><h3 id="4-3-2-Json-Serialization-with-Gson"><a href="#4-3-2-Json-Serialization-with-Gson" class="headerlink" title="4.3.2 Json Serialization with Gson"></a>4.3.2 Json Serialization with Gson</h3><p>No need for Serializable interface</p><pre><code>gson.fromJson(gson.toJson(userA), User.class);</code></pre><h3 id="4-3-3-constructor"><a href="#4-3-3-constructor" class="headerlink" title="4.3.3 constructor"></a>4.3.3 constructor</h3><p>直接handmade, 用constructor生成一个新的想要的对象。</p><h1 id="5-原型管理器"><a href="#5-原型管理器" class="headerlink" title="5. 原型管理器"></a>5. 原型管理器</h1><p>原型管理器(Prototype Manager)是将多个原型对象存储在一个集合中供客户端使用，它是一个专门负责克隆对象的工厂，其中定义了一个集合用于存储原型对象，如果需要某个原型对象的一个克隆，可以通过复制集合中对应的原型对象来获得。在原型管理器中针对抽象原型类进行编程，以便扩展。</p><p><img src="https://i.loli.net/2020/02/03/9UmnSAyI7az4kjl.gif" alt="7.gif"><br>带原型管理器的原型模式图 </p><h2 id="5-1-实例-公文管理器"><a href="#5-1-实例-公文管理器" class="headerlink" title="5.1 实例-公文管理器"></a>5.1 实例-公文管理器</h2><p><img src="https://i.loli.net/2020/02/03/zE3ahLk6lvKfw4J.gif" alt="8.gif"><br>公文管理器结构图</p><p>代码实现： </p><pre><code>import java.util.*;//抽象公文接口，也可定义为抽象类，提供clone()方法的实现，将业务方法声明为抽象方法interface OfficialDocument extends  Cloneable{       public  OfficialDocument clone();       public  void display();}//可行性分析报告(Feasibility Analysis Report)类class FAR implements OfficialDocument{       public  OfficialDocument clone()      {              OfficialDocument  far = null;              try              {                     far  = (OfficialDocument)super.clone();              }              catch(CloneNotSupportedException  e)              {                  System.out.println(&quot;不支持复制！&quot;);              }              return  far;       }       public  void display()       {         System.out.println(&quot;《可行性分析报告》&quot;);       }}//软件需求规格说明书(Software Requirements Specification)类class SRS implements OfficialDocument{       public  OfficialDocument clone()       {              OfficialDocument  srs = null;              try              {                     srs  = (OfficialDocument)super.clone();              }              catch(CloneNotSupportedException  e)              {                 System.out.println(&quot;不支持复制！&quot;);              }              return  srs;       }       public  void display()       {             System.out.println(&quot;《软件需求规格说明书》&quot;);       }}//原型管理器（使用饿汉式单例实现）class  PrototypeManager{       //定义一个Hashtable，用于存储原型对象       private Hashtable ht=new Hashtable();       private static PrototypeManager pm =  new PrototypeManager();       //为Hashtable增加公文对象        private  PrototypeManager()     {              ht.put(&quot;far&quot;,new  FAR());              ht.put(&quot;srs&quot;,new  SRS());                    }     //增加新的公文对象       public void addOfficialDocument(String  key,OfficialDocument doc)       {              ht.put(key,doc);       }       //通过浅克隆获取新的公文对象       public OfficialDocument  getOfficialDocument(String key)       {              return  ((OfficialDocument)ht.get(key)).clone();       }       public static PrototypeManager  getPrototypeManager()       {              return pm;       }}</code></pre><p>客户端代码如下： </p><pre><code>class Client{       public  static void main(String args[])       {              //获取原型管理器对象              PrototypeManager pm =  PrototypeManager.getPrototypeManager();                OfficialDocument  doc1,doc2,doc3,doc4;              doc1  = pm.getOfficialDocument(&quot;far&quot;);              doc1.display();              doc2  = pm.getOfficialDocument(&quot;far&quot;);              doc2.display();              System.out.println(doc1  == doc2);              doc3  = pm.getOfficialDocument(&quot;srs&quot;);              doc3.display();              doc4  = pm.getOfficialDocument(&quot;srs&quot;);              doc4.display();              System.out.println(doc3  == doc4);       }}</code></pre><p> 在PrototypeManager中定义了一个Hashtable类型的集合对象，使用“键值对”来存储原型对象，客户端可以通过Key（如“far”或“srs”）来获取对应原型对象的克隆对象。PrototypeManager类提供了类似工厂方法的getOfficialDocument()方法用于返回一个克隆对象。</p><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h1><h2 id="6-1-优点"><a href="#6-1-优点" class="headerlink" title="6.1 优点"></a>6.1 优点</h2><ol><li>简化对象的创建过程</li><li>客户端可以针对抽象原型类进行编程，具体原型类写在配置文件中</li><li>技工简化的创建结构</li></ol><h2 id="6-2-缺点"><a href="#6-2-缺点" class="headerlink" title="6.2 缺点"></a>6.2 缺点</h2><ol><li>每一个类有自己的克隆方法，且位于一个类的内部，对已有类进行改造的时候，需要修改源代码</li><li>深克隆复杂</li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design Pattern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>观察者模式</title>
      <link href="/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-定义"><a href="#1-定义" class="headerlink" title="1. 定义"></a>1. 定义</h1><p>观察者模式旨在描述如下行为：即一个对象的状态或者行为的变化将导致其他对象的状态或者行为也发生变化，他们之间将产生联动。为了更好地描述对象之间这种一对多(一对一)的联动，观察者模式应运而生，其定义了对象之间一种一对多的依赖关系，让一个对象的改变能够影响其他对象。</p><ul><li>Publish/ subscribe</li><li>Model/ View</li><li>Source/ Listener </li></ul><h1 id="2-概述"><a href="#2-概述" class="headerlink" title="2. 概述"></a>2. 概述</h1><p><img src="https://i.loli.net/2020/02/03/M6poTJ5PChWrReB.jpg" alt="fig1.jpg"></p><ul><li>subject<ul><li>被观察的对象</li><li>在subject当中定义了一个观察者的集合</li><li>一个观察目标可以接受任意数量的观察者来观察</li><li>定义了通知方法notify() </li></ul></li><li>concreteSubject <ul><li>具体目标，目标类的子类</li><li>通常包含<strong>经常发生改变的数据</strong>，当其状态发生改变的时候，向它的各个观察者发出通知；同时它还实现了在目标类当中定义的抽象业务逻辑方法。</li></ul></li><li>observer<ul><li>观察者将对观察目标的改变做出反应，观察者一般定义为接口，该接口声明了更新数据的方法update()</li></ul></li><li>concreteObserver<ul><li>在具体观察者中维护一个指向具体目标的对象的引用，存储具体观察者的有关状态。这些状态需要和具体目标的状态保持一致，实现了update()方法。</li></ul></li></ul><pre><code>import java.util.*;abstract class Subject {    //定义一个观察者集合用于存储所有观察者对象    protected ArrayList&lt;Observer&gt; observers= new ArrayList();    //注册方法，用于向观察者集合中增加一个观察者    public void attach(Observer observer) {        observers.add(observer);    }    //注销方法，用于在观察者集合中删除一个观察者    public void detach(Observer observer) {        observers.remove(observer);    }    //声明抽象通知方法    public abstract void notify();}class ConcreteSubject extends Subject {    //实现通知方法    public void notify() {        //遍历观察者集合，调用每一个观察者的响应方法        for(Object obs:observers) {            ((Observer)obs).update();        }    }    }interface Observer {    //声明响应方法    public void update();}class ConcreteObserver implements Observer {    //实现响应方法    public void update() {        //具体响应代码    }}</code></pre><h1 id="3-JDK对观察者模式的支持"><a href="#3-JDK对观察者模式的支持" class="headerlink" title="3. JDK对观察者模式的支持"></a>3. JDK对观察者模式的支持</h1><p><img src="https://i.loli.net/2020/02/03/tv5Zh68AQiSfIXC.jpg" alt="fig2.jpg"></p><ul><li>Observable 类<ul><li>定义了一个List来存储观察者对象</li><li>addObserver(Observer o)</li><li>deleteObserver(Observer o)</li><li>notifyObservers()</li><li>deleteObservers()</li><li>setChanged()</li><li>clearChanged()</li><li>hasChanged()</li><li>countObservers()</li></ul></li></ul><p>Observer接口还有Observable类可以直接作为观察者模式的抽象层，再自定义具体观察者类和具体的观察目标类。</p><h1 id="4-Review"><a href="#4-Review" class="headerlink" title="4. Review"></a>4. Review</h1><ul><li>优点<ul><li>实现表示层和数据逻辑层的分离，定义了稳定的消息更新传递机制，并抽象了更新接口</li><li>在观察目标和观察者之间建立一个抽象的耦合</li><li>观察目标只需要维持一个抽象观察者的集合，无须了解其具体的观察者</li></ul></li><li>缺陷<ul><li>太多观察者，都通知很耗时的</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://blog.csdn.net/lovelion/article/details/7720232" target="_blank" rel="noopener">https://blog.csdn.net/lovelion/article/details/7720232</a></li><li><a href="https://blog.csdn.net/LoveLion/article/details/7720490" target="_blank" rel="noopener">https://blog.csdn.net/LoveLion/article/details/7720490</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Design Pattern </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何设计一个秒杀系统</title>
      <link href="/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
      <url>/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><h2 id="1-1-并发读写"><a href="#1-1-并发读写" class="headerlink" title="1.1 并发读写"></a>1.1 并发读写</h2><p>秒杀要解决的主要问题是：并发读与并发写。</p><p>并发读的优化理念是尽量减少用户到服务端来读数据，或者让他们读更少的数据；并发写的处理原则一样，要求我们在数据库层面独立出一个库，做特殊的处理。</p><p>其次，还需要针对秒杀系统做一些保护，针对意料之外的情况设计兜底方案，以防止最坏的情况发生。</p><h2 id="1-2-API设计原则"><a href="#1-2-API设计原则" class="headerlink" title="1.2 API设计原则"></a>1.2 API设计原则</h2><p>值得注意的地方是：如果想打造并维护一个超大流量并发读写、高性能、高可用的系统，在整个用户请求路径上从浏览器到服务端我们要遵循几个原则，就是保证<strong><em>用户请求的数据尽量少、请求数尽量少、路径尽量短、依赖尽量少，不要有单点</em></strong></p><h2 id="1-3-秒杀架构原则"><a href="#1-3-秒杀架构原则" class="headerlink" title="1.3 秒杀架构原则"></a>1.3 秒杀架构原则</h2><h3 id="1-3-1-高可用"><a href="#1-3-1-高可用" class="headerlink" title="1.3.1 高可用"></a>1.3.1 高可用</h3><p>整个系统架构需要满足高可用性，流量符合预期的时候肯定要稳定，就是超出预期也同样不能掉链子，保证秒杀产品顺利卖出。</p><h3 id="1-3-2-一致性"><a href="#1-3-2-一致性" class="headerlink" title="1.3.2 一致性"></a>1.3.2 一致性</h3><p>数据必须一致，即成交总量必须和设定的数量一致。</p><h3 id="1-3-3-高可用"><a href="#1-3-3-高可用" class="headerlink" title="1.3.3 高可用"></a>1.3.3 高可用</h3><p>系统的性能要足够强，支撑足够大的流量，不仅是服务端要做极致的性能优化，而且在整个请求链路上都要做协同的优化，每个地方都要快一点，整个系统就完美了。</p><p>本文将从这三个原则上来分别进行详细说明。</p><h1 id="2-架构原则"><a href="#2-架构原则" class="headerlink" title="2. 架构原则"></a>2. 架构原则</h1><p>秒杀系统本质上是一个满足大并发、高性能和高可用的分布式系统。</p><h2 id="2-1-数据尽量少"><a href="#2-1-数据尽量少" class="headerlink" title="2.1 数据尽量少"></a>2.1 数据尽量少</h2><p>用户请求的数据能少就少，请求的数据包括上传给系统的数据和系统返回给用户的数据。</p><p>因为这些数据在网络上传输需要时间，其次不管是请求数据还是返回数据都需要服务器处理，而服务器在写网络的时候通常都要做压缩和字符编码，这些都非常消耗CPU，所以减少传输的数据量可以显著减少CPU的使用。</p><p>同样，数据尽量少还要求系统依赖的数据能少就少，包括系统完成某些业务逻辑需要读取和保存的数据，这些数据一般是和后台服务以及数据库打交道的。调用其他服务会涉及数据的序列化和反序列化，这也是CPU的一大杀手，同样也会增加延时。而且数据库本身也很容易成为瓶颈，因此越少和数据库打交道越好。</p><h2 id="2-2-请求数尽量少"><a href="#2-2-请求数尽量少" class="headerlink" title="2.2 请求数尽量少"></a>2.2 请求数尽量少</h2><p>用户请求的页面返回后，浏览器渲染这个页面还要包含其他的额外请求，比如说，这个页面依赖的 CSS/JavaScript、图片，以及 Ajax 请求等等都定义为“额外请求”，这些额外请求应该尽量少。因为浏览器每发出一个请求都多少会有一些消耗，例如建立连接要做三次握手，有的时候有页面依赖或者连接数限制，一些请求（例如 JavaScript）还需要串行加载等。另外，如果不同请求的域名不一样的话，还涉及这些域名的 DNS 解析，可能会耗时更久。所以你要记住的是，减少请求数可以显著减少以上这些因素导致的资源消耗。</p><p>例如，减少请求数最常用的一个实践就是合并 CSS 和 JavaScript 文件，把多个 JavaScript 文件合并成一个文件，在 URL 中用逗号隔开（<code>https://g.xxx.com/tm/xx-b/4.0.94/mods/??module-preview/index.xtpl.js,module-jhs/index.xtpl.js,module-focus/index.xtpl.js</code>）。这种方式在服务端仍然是单个文件各自存放，只是服务端会有一个组件解析这个 URL，然后动态把这些文件合并起来一起返回。</p><h2 id="2-3-路径要尽量短"><a href="#2-3-路径要尽量短" class="headerlink" title="2.3 路径要尽量短"></a>2.3 路径要尽量短</h2><p>路径指的是用户发出请求到返回数据这个过程中需要经过的中间节点的数量。</p><p>通常，这些节点可以表示为一个系统或者一个新的 Socket 连接（比如代理服务器只是创建一个新的 Socket 连接来转发请求）。每经过一个节点，一般都会产生一个新的 Socket 连接。</p><p>然而，每增加一个连接都会增加新的不确定性。从概率统计上来说，假如一次请求经过 5 个节点，每个节点的可用性是 99.9% 的话，那么整个请求的可用性是：99.9% 的 5 次方，约等于 99.5%。</p><p>所以缩短请求路径不仅可以增加可用性，同样可以有效提升性能（减少中间节点可以减少数据的序列化与反序列化），并减少延时（可以减少网络传输耗时）。</p><p>要缩短访问路径可以将多个相互有强依赖的应用合并部署在一起，将远程过程调用变成JVM内部的方法调用。</p><h2 id="2-4-依赖要尽量少"><a href="#2-4-依赖要尽量少" class="headerlink" title="2.4 依赖要尽量少"></a>2.4 依赖要尽量少</h2><p>所谓依赖，指的是要完成一次用户请求必须依赖的系统或者服务。 </p><p>举个例子，比如说你要展示秒杀页面，而这个页面必须强依赖商品信息、用户信息，还有其他如优惠券、成交列表等这些对秒杀不是非要不可的信息（弱依赖），这些弱依赖在紧急情况下就可以去掉。</p><p>要减少依赖，我们可以给系统进行分级，比如 0 级系统、1 级系统、2 级系统、3 级系统，0 级系统如果是最重要的系统，那么 0 级系统强依赖的系统也同样是最重要的系统，以此类推。</p><p>注意，0 级系统要尽量减少对 1 级系统的强依赖，防止重要的系统被不重要的系统拖垮。例如支付系统是 0 级系统，而优惠券是 1 级系统的话，在极端情况下可以把优惠券给降级，防止支付系统被优惠券这个 1 级系统给拖垮。</p><h2 id="2-5-不要有单点"><a href="#2-5-不要有单点" class="headerlink" title="2.5 不要有单点"></a>2.5 不要有单点</h2><p>不能有单点，因为单点意味着没有备份，风险不可控，设计分布式系统的一个最重要的原则就是消除单点。</p><p>如何避免单点？ —-&gt; 避免将服务的状态和机器绑定，即把服务无状态化，这样服务就可以在机器中随意移动了。 </p><p>如何那把服务的状态和机器解耦呢？这里也有很多实现方式。例如把和机器相关的配置动态化，这些参数可以通过配置中心来动态推送，在服务启动时动态拉取下来，我们在这些配置中心设置一些规则来方便地改变这些映射关系。</p><p>应用无状态化是有效避免单点的一种方式，但是像存储服务本身很难无状态化，因为数据要存储在磁盘上，本身就要和机器绑定，那么这种场景一般要通过冗余多个备份的方式来解决单点问题。</p><h1 id="3-不同场景下的不同架构案例"><a href="#3-不同场景下的不同架构案例" class="headerlink" title="3. 不同场景下的不同架构案例"></a>3. 不同场景下的不同架构案例</h1><p>如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面增加一个“定时上架”功能，仅在秒杀开始时才让用户看到购买按钮，当商品的库存卖完了也就结束了。这就是当时第一个版本的秒杀系统实现方式。</p><p>但随着请求量的加大（比如从 1w/s 到了 10w/s 的量级），这个简单的架构很快就遇到了瓶颈，因此需要做架构改造来提升系统性能。这些架构改造包括：</p><ol><li>把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化，例如这个独立出来的系统就减少了店铺装修的功能，减少了页面的复杂度；</li><li>在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；</li><li>将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；</li><li>增加秒杀答题，防止有秒杀器抢单。</li></ol><p>此时秒杀已经成为了一个独立的新系统，另外核心的一些数据放到了缓存当中，其他的关联系统也都以独立集群的方式进行部署。</p><p><img src="https://i.loli.net/2020/02/03/9RJsCGFtgbcyrhZ.jpg" alt="fig1.jpg"></p><p>但是这个架构仍然无法支持超过100w/s的请求量，因此为了进一步提高秒杀系统的性能，又对架构做了进一步的升级，比如：</p><ol><li>对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少；</li><li>在服务端对秒杀商品进行本地缓存，不需要再调用依赖系统的后台服务获取数据，甚至不需要去公共的缓存集群中查询数据，这样不仅可以减少系统调用，而且能够避免压垮公共缓存集群。</li><li>增加系统限流保护，防止最坏的情况发生</li></ol><p>此时整个系统架构变成了这个样子，已经对页面进行了进一步的静态化，秒杀过程当中就不需要刷新整个页面了，只需要向服务端请求很少的动态数据。而且最关键的详情和交易系统都增加了本地缓存，来提前缓存秒杀商品的信息，热点数据库也做了独立部署。</p><p><img src="https://i.loli.net/2020/02/03/46cK3CdURO8Yngp.jpg" alt="fig2.jpg"></p><p>从前面的几次升级来看，其实越到后面需要定制的地方越多，也就是越“不通用”。例如，把秒杀商品缓存在每台机器的内存中，这种方式显然不适合太多的商品同时进行秒杀的情况，因为单机的内存始终有限。所以要取得极致的性能，就要在其他地方（比如，通用性、易用性、成本等方面）有所牺牲。</p><h1 id="4-动静分离的方案"><a href="#4-动静分离的方案" class="headerlink" title="4. 动静分离的方案"></a>4. 动静分离的方案</h1><p>秒杀系统需要让请求效率足够高 - 提高单次请求的效率，减少没必要的请求。</p><h2 id="4-1-何为动静数据"><a href="#4-1-何为动静数据" class="headerlink" title="4.1 何为动静数据"></a>4.1 何为动静数据</h2><p>将用户请求的数据（如HTML）划分为动态数据和静态数据。而动态静态数据的划分，在于看页面中输出的数据是否和URL，浏览者，时间，地域相关，以及是否含有Cookie等私密数据。</p><ol><li>对很多媒体类的网站来说，无论谁来看文章，展示的数据都是一样的，那么哪怕这是个动态页面，它仍然是个典型的静态数据。</li><li>访问淘宝的首页，每个人看到的页面可能都是不一样的，其中包含了很多根据访问者个人信息进行的推荐，这些个性化的数据就称为动态数据。</li></ol><p>这里再强调一下，我们所说的静态数据，不能仅仅理解为传统意义上完全存在磁盘上的 HTML 页面，它也可能是经过 Java 系统产生的页面，但是它输出的页面本身不包含上面所说的那些因素。也就是所谓“动态”还是“静态”，并不是说数据本身是否动静，而是数据中是否含有和访问者相关的个性化数据。</p><p>这样做动静分离的时候，我们就可以对分离出来的静态数据做缓存，有了缓存以后，静态数据的访问效率肯定就提高了。</p><h2 id="4-2-如何对静态数据做缓存？"><a href="#4-2-如何对静态数据做缓存？" class="headerlink" title="4.2 如何对静态数据做缓存？"></a>4.2 如何对静态数据做缓存？</h2><h3 id="4-2-1-距离用户最近"><a href="#4-2-1-距离用户最近" class="headerlink" title="4.2.1 距离用户最近"></a>4.2.1 距离用户最近</h3><p>将静态数据缓存到离用户最近的地方。静态数据就是那些相对不会变化的数据，因此可以做缓存。常见的，我们可以缓存在：</p><ol><li>用户浏览器</li><li>CDN上</li><li>服务端的Cache中</li></ol><h3 id="4-2-2-静态化改造要直接缓存HTTP连接"><a href="#4-2-2-静态化改造要直接缓存HTTP连接" class="headerlink" title="4.2.2 静态化改造要直接缓存HTTP连接"></a>4.2.2 静态化改造要直接缓存HTTP连接</h3><p>系统的静态化改造是直接缓存HTTP连接而不仅仅是数据了。如下图所示，Web代理服务器根据请求URL直接去除对应的HTTP响应头和响应体然后直接返回，这个响应过程连HTTP协议都不用重新组装，甚至连HTTP请求头也不需要解析。</p><p><img src="https://i.loli.net/2020/02/03/ydBbWKCeip8jGm5.jpg" alt="fig3.jpg"></p><h3 id="4-2-3-缓存语言"><a href="#4-2-3-缓存语言" class="headerlink" title="4.2.3 缓存语言"></a>4.2.3 缓存语言</h3><p>不同语言写的cache软件处理缓存数据的效率也各不相同。以Java为例，Java不擅长处理大量连接请求，每个连接消耗的内存会比较多，Servlet容器解析HTTP协议比较慢。所以可以不在Java层做缓存，而是直接在Web服务器层上做，这样就可以屏蔽Java的一些弱点；而相比起来，Web服务器(Nginx, Apache, Varnish)会更加擅长处理大并发的静态文件请求。</p><h2 id="4-3-静态数据处理方案"><a href="#4-3-静态数据处理方案" class="headerlink" title="4.3 静态数据处理方案"></a>4.3 静态数据处理方案</h2><p>以商品详情页为例：</p><h3 id="4-3-1-URL唯一化"><a href="#4-3-1-URL唯一化" class="headerlink" title="4.3.1 URL唯一化"></a>4.3.1 URL唯一化</h3><p>要缓存整个HTTP连接，以URL作为缓存的key</p><h3 id="4-3-2-分离浏览者相关的因素"><a href="#4-3-2-分离浏览者相关的因素" class="headerlink" title="4.3.2 分离浏览者相关的因素"></a>4.3.2 分离浏览者相关的因素</h3><p>分离用户的相关信息，是否登录以及登录身份等等。</p><h3 id="4-3-3-分离时间因素"><a href="#4-3-3-分离时间因素" class="headerlink" title="4.3.3 分离时间因素"></a>4.3.3 分离时间因素</h3><p>服务端输出的是哪也通过动态请求获取</p><h3 id="4-3-4-异步化地域因素"><a href="#4-3-4-异步化地域因素" class="headerlink" title="4.3.4 异步化地域因素"></a>4.3.4 异步化地域因素</h3><p>详情页面上与地域相关的因素做成异步获取的方式</p><h3 id="4-3-5-去掉Cookie"><a href="#4-3-5-去掉Cookie" class="headerlink" title="4.3.5 去掉Cookie"></a>4.3.5 去掉Cookie</h3><p>服务端输出的页面包含的 Cookie 可以通过代码软件来删除，如 Web 服务器 Varnish 可以通过 unset req.http.cookie 命令去掉 Cookie。注意，这里说的去掉 Cookie 并不是用户端收到的页面就不含 Cookie 了，而是说，在缓存的静态数据中不含有 Cookie。</p><h2 id="4-4-动态数据处理方案"><a href="#4-4-动态数据处理方案" class="headerlink" title="4.4 动态数据处理方案"></a>4.4 动态数据处理方案</h2><h3 id="4-4-1-ESI-Edge-Side-Includes"><a href="#4-4-1-ESI-Edge-Side-Includes" class="headerlink" title="4.4.1 ESI (Edge Side Includes)"></a>4.4.1 ESI (Edge Side Includes)</h3><p>在Web代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。对服务端性能有影响，但是用户体验会比较好</p><h3 id="4-4-2-CSI-Client-Side-Include"><a href="#4-4-2-CSI-Client-Side-Include" class="headerlink" title="4.4.2 CSI (Client Side Include)"></a>4.4.2 CSI (Client Side Include)</h3><p>单独发出异步Javascript请求，向服务端获取动态内容。这种方式服务端性能更好，但是用户端可能会有延时，体验会差一些</p><h2 id="4-5-动静分离架构方案"><a href="#4-5-动静分离架构方案" class="headerlink" title="4.5 动静分离架构方案"></a>4.5 动静分离架构方案</h2><h3 id="4-5-1-实体机单机部署"><a href="#4-5-1-实体机单机部署" class="headerlink" title="4.5.1 实体机单机部署"></a>4.5.1 实体机单机部署</h3><p>这种方案是将虚拟机改为实体机，以增大 Cache 的容量，并且采用了一致性 Hash 分组的方式来提升命中率。这里将 Cache 分成若干组，是希望能达到命中率和访问热点的平衡。Hash 分组越少，缓存的命中率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致 Cache 被击穿，所以我们应该适当增加多个相同的分组，来平衡访问热点和命中率的问题。</p><p>Nginx+Cache+Java结构实体机单机部署<br><img src="https://i.loli.net/2020/02/03/m6GuWRPxrk4hvK8.jpg" alt="fig4.jpg"></p><p>这种部署方式有以下几个优点：</p><ol><li>没有网络瓶颈，而且能使用大内存；</li><li>既能提升命中率，又能减少 Gzip 压缩；</li><li>减少 Cache 失效压力，因为采用定时失效方式，例如只缓存 3 秒钟，过期即自动失效。</li></ol><p>这个方案中，虽然把通常只需要虚拟机或者容器运行的 Java 应用换成实体机，优势很明显，它会增加单机的内存容量，但是一定程度上也造成了 CPU 的浪费，因为单个的 Java 进程很难用完整个实体机的 CPU。</p><p>另外就是，一个实体机上部署了 Java 应用又作为 Cache 来使用，这造成了运维上的高复杂度，所以这是一个折中的方案。如果你的公司里，没有更多的系统有类似需求，那么这样做也比较合适，如果你们有多个业务系统都有静态化改造的需求，那还是建议把 Cache 层单独抽出来公用比较合理，如下面的方案 2 所示。</p><h3 id="4-5-2-统一Cache层"><a href="#4-5-2-统一Cache层" class="headerlink" title="4.5.2 统一Cache层"></a>4.5.2 统一Cache层</h3><p>所谓统一 Cache 层，就是将单机的 Cache 统一分离出来，形成一个单独的 Cache 集群。统一 Cache 层是个更理想的可推广方案，该方案的结构图如下：</p><p><img src="https://i.loli.net/2020/02/03/oJjRUqAkN8PVGaM.jpg" alt="fig5.jpg"></p><p>统一Cache层，可以减少运维成本，也方便接入其他静态化系统，还有以下优点：</p><ol><li>单独一个 Cache 层，可以减少多个应用接入时使用 Cache 的成本。这样接入的应用只要维护自己的 Java 系统就好，不需要单独维护 Cache，而只关心如何使用即可。</li><li>统一 Cache 的方案更易于维护，如后面加强监控、配置的自动化，只需要一套解决方案就行，统一起来维护升级也比较方便。</li><li>可以共享内存，最大化利用内存，不同系统之间的内存可以动态切换，从而能够有效应对各种攻击。</li></ol><p>这种方案也会带来一些问题。比如：</p><ol><li>Cache 层内部交换网络成为瓶颈；</li><li>缓存服务器的网卡也会是瓶颈；</li><li>机器少风险较大，挂掉一台就会影响很大一部分缓存数据。</li></ol><p>要解决上面这些问题，可以再对 Cache 做 Hash 分组，即一组 Cache 缓存的内容相同，这样能够避免热点数据过度集中导致新的瓶颈产生。</p><h3 id="4-5-3-使用CDN"><a href="#4-5-3-使用CDN" class="headerlink" title="4.5.3 使用CDN"></a>4.5.3 使用CDN</h3><p>在将整个系统做动静分离后，我们自然会想到更进一步的方案，就是将 Cache 进一步前移到 CDN 上，因为 CDN 离用户最近，效果会更好。</p><p>有几个问题需要解决： </p><ol><li>失效问题</li></ol><p>前面我们也有提到过缓存时效的问题，不知道你有没有理解，我再来解释一下。谈到静态数据时，我说过一个关键词叫“相对不变”，它的言外之意是“可能会变化”。比如一篇文章，现在不变，但如果你发现个错别字，是不是就会变化了？如果你的缓存时效很长，那用户端在很长一段时间内看到的都是错的。所以，这个方案中也是，我们需要保证 CDN 可以在秒级时间内，让分布在全国各地的 Cache 同时失效，这对 CDN 的失效系统要求很高。</p><ol start="2"><li>命中率问题</li></ol><p>Cache 最重要的一个衡量指标就是“高命中率”，不然 Cache 的存在就失去了意义。同样，如果将数据全部放到全国的 CDN 上，必然导致 Cache 分散，而 Cache 分散又会导致访问请求命中同一个 Cache 的可能性降低，那么命中率就成为一个问题。</p><ol start="3"><li>发布更新问题</li></ol><p>如果一个业务系统每周都有日常业务需要发布，那么发布系统必须足够简洁高效，而且你还要考虑有问题时快速回滚和排查问题的简便性。</p><p>从前面的分析来看，将商品详情系统放到全国的所有 CDN 节点上是不太现实的，因为存在失效问题、命中率问题以及系统的发布更新问题。那么是否可以选择若干个节点来尝试实施呢？答案是“可以”，但是这样的节点需要满足几个条件：</p><ol><li>靠近访问量比较集中的地区</li><li>离主站相对较远</li><li>节点到主站间的网络比较好，比较稳定</li><li>节点容量大，不会占用其他CDN太多的资源</li></ol><p>基于上面几个因素，选择 CDN 的二级 Cache 比较合适，因为二级 Cache 数量偏少，容量也更大，让用户的请求先回源的 CDN 的二级 Cache 中，如果没命中再回源站获取数据，部署方式如下图所示：</p><p><img src="https://i.loli.net/2020/02/03/Eu5q7bATK4xFkSW.jpg" alt="fig6.jpg"></p><p>使用 CDN 的二级 Cache 作为缓存，可以达到和当前服务端静态化 Cache 类似的命中率，因为节点数不多，Cache 不是很分散，访问量也比较集中，这样也就解决了命中率问题，同时能够给用户最好的访问体验，是当前比较理想的一种 CDN 化方案。</p><h1 id="5-如何处理热点数据"><a href="#5-如何处理热点数据" class="headerlink" title="5. 如何处理热点数据"></a>5. 如何处理热点数据</h1><p>有一部分数据是会被大量用户访问的热卖商品，这部分商品是需要特殊关注的，因为其会对系统产生一系列的影响。</p><p>首先，热点请求会大量占用服务器处理资源，虽然这个热点可能占总量的很小的一部分，然而却可能抢占90%以上的服务器资源，如果这个热点请求还是没有价值的无效请求，那么对系统资源来说完全是浪费。</p><h2 id="5-1-什么是热点"><a href="#5-1-什么是热点" class="headerlink" title="5.1 什么是热点"></a>5.1 什么是热点</h2><h3 id="5-1-1-热点操作"><a href="#5-1-1-热点操作" class="headerlink" title="5.1.1 热点操作"></a>5.1.1 热点操作</h3><p>例如大量的刷新页面，大量添加购物车，零点大量的下单等。这些操作可以抽象为“读请求”和“写请求”，这两种请求的处理方式大相径庭，读请求的优化空间比较大，而写请求的瓶颈一般都在存储层，优化的思路就是根据CAP理论做平衡。</p><h3 id="5-1-2-热点数据"><a href="#5-1-2-热点数据" class="headerlink" title="5.1.2 热点数据"></a>5.1.2 热点数据</h3><p>热点数据就是用户的热点请求对应的数据，又可以分为静态热点数据和动态热点数据。</p><p>静态热点数据，就是能够提前预测的热点数据。动态热点数据，就是不能被提前预测到的，系统在运行过程中临时产生的热点。</p><h2 id="5-2-发现热点数据"><a href="#5-2-发现热点数据" class="headerlink" title="5.2 发现热点数据"></a>5.2 发现热点数据</h2><h3 id="5-2-1-发现静态热点数据"><a href="#5-2-1-发现静态热点数据" class="headerlink" title="5.2.1 发现静态热点数据"></a>5.2.1 发现静态热点数据</h3><p>如前面讲的，静态热点数据可以通过商业手段，例如强制让卖家通过报名参加的方式提前把热点商品筛选出来，实现方式是通过一个运营系统，把参加活动的商品数据进行打标，然后通过一个后台系统对这些热点商品进行预处理，如提前进行缓存。但是这种通过报名提前筛选的方式也会带来新的问题，即增加卖家的使用成本，而且实时性较差，也不太灵活。</p><p>不过，除了提前报名筛选这种方式，你还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，我们可以认为这些 TOP N 的商品就是热点商品。</p><h3 id="5-2-2-发现动态热点数据"><a href="#5-2-2-发现动态热点数据" class="headerlink" title="5.2.2 发现动态热点数据"></a>5.2.2 发现动态热点数据</h3><p>具体实现</p><ol><li>构建异步系统，用来收集交易链路上各个环节中的中间件产品的热点Key，例如Nginx、缓存、RPC服务框架</li><li>建立一个热点上报和可以按照需求订阅的热点服务的下发规范。因为交易链路上各个系统(包括详情，购物车，交易，优惠，库存等等)会有访问上的时间差，需要将上游已经发现的热点透传给下游系统，提前做好保护。例如，对于大促高峰期，详情系统是最早知道的。</li><li>将上游系统收集的热点数据发送到热点服务台，让下游系统提前知道信息，做热电保护</li></ol><p><img src="https://i.loli.net/2020/02/03/hGd5HWVLaEKAwZS.jpg" alt="fig7.jpg"></p><p>我们通过部署在每台机器上的 Agent 把日志汇总到聚合和分析集群中，然后把符合一定规则的热点数据，通过订阅分发系统再推送到相应的系统中。你可以是把热点数据填充到 Cache 中，或者直接推送到应用服务器的内存中，还可以对这些数据进行拦截，总之下游系统可以订阅这些数据，然后根据自己的需求决定如何处理这些数据。</p><p>Tips:</p><ol><li>热点服务的后台抓取热点数据日志的方式最好采用异步的方式；可以保证通过性，不会影响业务系统和中间件产品的主流程。</li><li>热点服务和中间件自身需要有热电保护模块，每个中间件和应用和需要保护自己</li><li>热点发现需要接近实时，因为只有接近实时才有意义，能及时对下游系统提供保护</li></ol><h2 id="5-3-如何处理热点数据"><a href="#5-3-如何处理热点数据" class="headerlink" title="5.3 如何处理热点数据"></a>5.3 如何处理热点数据</h2><h3 id="5-3-1-优化"><a href="#5-3-1-优化" class="headerlink" title="5.3.1 优化"></a>5.3.1 优化</h3><p>缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。</p><h3 id="5-3-2-限制"><a href="#5-3-2-限制" class="headerlink" title="5.3.2 限制"></a>5.3.2 限制</h3><p>保护机制，比如对商品的ASIN做一致性hash，然后根据hash做分桶，每个分桶处置一个处理队列，通过这种方式将热点商品限制在一个请求队列当中，防止因为某些热点商品占用太多的服务器资源，而使得其他请求始终得不到服务器的处理资源。 </p><h3 id="5-3-3-隔离"><a href="#5-3-3-隔离" class="headerlink" title="5.3.3 隔离"></a>5.3.3 隔离</h3><p>将热点数据隔离出来，针对热点数据可以再做优化</p><ol><li>业务隔离 - 商业逻辑上运行上的隔离</li><li>系统隔离 - 运行时的隔离</li><li>数据隔离 - 单独数据库 Cache集群</li></ol><h1 id="6-流量削峰"><a href="#6-流量削峰" class="headerlink" title="6. 流量削峰"></a>6. 流量削峰</h1><p>秒杀请求在时间上是高度集中于某一特定的时间点的，这样一来会有一个特别高的流量峰值，它对资源的消耗是瞬时的。</p><p>但是对于秒杀这个场景来说，最终能够抢到的商品的人数是固定的，并发读越高，无效请求也就越多了。</p><p>从业务角度上来说，秒杀希望更多的人能够参与进来，更多的人来刷新页面，但是真正开始下单的时候，秒杀请求就不是越多越好了，可以设计一些规则，让并发的请求更多的延缓，甚至我们可以过滤掉一些无效请求。</p><h2 id="6-1-削峰的原因"><a href="#6-1-削峰的原因" class="headerlink" title="6.1 削峰的原因"></a>6.1 削峰的原因</h2><p>我们知道服务器的处理资源是恒定的，你用或者不用它的处理能力都是一样的，所以出现峰值的话，很容易导致忙到处理不过来，闲的时候却又没有什么要处理。但是由于要保证服务质量，我们的很多处理资源只能按照忙的时候来预估，而这会导致资源的一个浪费。</p><p>削峰主要是为了能够让服务端处理变得更加平稳，也为了能够节省服务器的资源成本。从秒杀这个场景来说，就是更多延缓用户请求的发出，以便减少或者过滤掉一些无效请求，遵从请求数要尽量少的原则。</p><h2 id="6-2-无损削峰方式"><a href="#6-2-无损削峰方式" class="headerlink" title="6.2 无损削峰方式"></a>6.2 无损削峰方式</h2><h3 id="6-2-1-排队"><a href="#6-2-1-排队" class="headerlink" title="6.2.1 排队"></a>6.2.1 排队</h3><p>用消息队列缓冲瞬时流量，将同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另外一端平滑地将信息推送出去。</p><p><img src="https://i.loli.net/2020/02/03/dyp5UfOgsSHC3hi.jpg" alt="fig8.jpg"></p><p>但是如果流量峰值持续一段时间，超过了消息队列的处理上限，还是会被压垮的。</p><p>其他常见的排队方式有：</p><ol><li>利用线程池加锁等待</li><li>先进先出、先进后出等常用的内存排队算法的实现</li><li>将请求序列化到文件当中，然后再顺序读文件</li></ol><h3 id="6-2-2-答题"><a href="#6-2-2-答题" class="headerlink" title="6.2.2 答题"></a>6.2.2 答题</h3><p>第一个目的是防止部分买家使用秒杀器在参加秒杀时作弊。2011 年秒杀非常火的时候，秒杀器也比较猖獗，因而没有达到全民参与和营销的目的，所以系统增加了答题来限制秒杀器。增加答题后，下单的时间基本控制在 2s 后，秒杀器的下单比例也大大下降。</p><p>第二个目的其实就是延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰。这个重要的功能就是把峰值的下单请求拉长，从以前的 1s 之内延长到 2s~10s。这样一来，请求峰值基于时间分片了。这个时间的分片对服务端处理并发非常重要，会大大减轻压力。而且，由于请求具有先后顺序，靠后的请求到来时自然也就没有库存了，因此根本到不了最后的下单步骤，所以真正的并发写就非常有限了。这种设计思路目前用得非常普遍，如当年支付宝的“咻一咻”、微信的“摇一摇”都是类似的方式。</p><h3 id="6-2-3-分层过滤"><a href="#6-2-3-分层过滤" class="headerlink" title="6.2.3 分层过滤"></a>6.2.3 分层过滤</h3><p>采用漏斗式的设计</p><p><img src="https://i.loli.net/2020/02/03/GCXLQ2UsIqElavZ.jpg" alt="fig9.jpg"></p><p>假如请求分别经过 CDN、前台读系统（如商品详情系统）、后台系统（如交易系统）和数据库这几层，那么：</p><ul><li>大部分数据和流量在用户浏览器或者 CDN 上获取，这一层可以拦截大部分数据的读取</li><li>经过第二层（即前台系统）时数据（包括强一致性的数据）尽量得走 Cache，过滤一些无效的请求</li><li>再到第三层后台系统，主要做数据的二次检验，对系统做好保护和限流，这样数据量和请求就进一步减少</li><li>最后在数据层完成数据的强一致性校验</li></ul><p>分层过滤的核心思想是：在不同的层次尽可能地过滤掉无效请求，让漏斗最末端的才是有效的请求。而达到这种效果，我们就必须对数据做分层的校验。</p><p>分层校验的基本原则有：</p><ol><li>将动态请求的读数据缓存在Web端，过滤掉无效的数据读</li><li>对读数据不做强一致性校验，减少因为一致性校验产生的瓶颈问题</li><li>对写数据进行基于时间的合理分片，过滤掉过期的失效请求</li><li>对写请求做限流保护，将超出系统承载能力的请求过滤掉</li><li>对写数据进行强一致性校验，只保留最后有效的数据</li></ol><p>分层校验的目的是：在读系统中，尽量减少由于一致性校验带来的系统瓶颈，但是尽量将不影响性能的检查条件提前，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求、营销等价物是否充足等；在写数据系统中，主要对写的数据（如“库存”）做一致性检查，最后在数据库层保证数据的最终准确性（如“库存”不能减为负数）。</p><h1 id="7-影响性能的因素"><a href="#7-影响性能的因素" class="headerlink" title="7. 影响性能的因素"></a>7. 影响性能的因素</h1><h2 id="7-1-性能的定义"><a href="#7-1-性能的定义" class="headerlink" title="7.1 性能的定义"></a>7.1 性能的定义</h2><p>服务设备的不同对于性能的定义也是不一样的，例如CPU主要看主频，磁盘主要看IOPS(Input/ output Operations Per Second, 即每秒进行读写操作的次数)。</p><p>关于秒杀，我们主要讨论系统服务端的性能，一般使用QPS来衡量，还有一个影响和QPS息息相关，即响应时间(Response Time, RT)，可以理解为服务器处理响应的耗时。</p><p>正常情况下响应时间越短，一秒钟处理的请求数就会越多，这在单线程处理的情况下看起来是线性关系，即我们只要把每个请求的响应时间降到最低，那么性能就会最高。而在多线程当中，总QPS = （1000ms/ 响应时间）x 线程数，从这个角度上来看，性能和两个因素相关，一个是一次响应的服务端的耗时，一个是处理请求的线程数。</p><h3 id="7-1-1-响应时间"><a href="#7-1-1-响应时间" class="headerlink" title="7.1.1 响应时间"></a>7.1.1 响应时间</h3><p>对于大部分的Web系统而言，响应时间一般是由CPU执行时间和线程等待时间组成的，即服务器在处理一个请求时，一部分是CPU本身在做运算，还有一部分是各种等待。</p><p>理解了服务器处理请求的逻辑，估计你会说为什么我们不去减少这种等待时间。很遗憾，根据我们实际的测试发现，减少线程等待时间对提升性能的影响没有我们想象得那么大，它并不是线性的提升关系，这点在很多代理服务器（Proxy）上可以做验证。</p><p>如果代理服务器本身没有CPU消耗，我们在每次给代理服务器代理的请求加个延时，即增加响应时间，但是这对代理服务器本身的吞吐量并没有多大的影响，因为代理服务器本身的资源并没有被消耗，可以通过增加代理服务器的处理线程数，来弥补响应时间对代理服务器的 QPS 的影响。</p><p>其实，真正对性能有影响的是 CPU 的执行时间。这也很好理解，因为 CPU 的执行真正消耗了服务器的资源。经过实际的测试，如果减少 CPU 一半的执行时间，就可以增加一倍的 QPS。</p><h3 id="7-1-2-线程数"><a href="#7-1-2-线程数" class="headerlink" title="7.1.2 线程数"></a>7.1.2 线程数</h3><p>并不是线程数越多越好，总QPS就会越大，因为线程本身也消耗资源，会受到其他因素的制约。例如，线程越多系统的线程切换成本就会越高，而且每个线程都会耗费一定的内存。</p><p>默认的配置一般为：</p><blockquote><p>线程数 = 2 x CPU核数 + 1</p></blockquote><p>还有一个根据最佳实践得出来的公式为：</p><blockquote><p>线程数 = [(线程等待时间 + 线程CPU时间) / 线程CPU时间] x CPU数量</p></blockquote><p>因此要提升性能，我们就要减少CPU的执行时间，另外就是要设置一个合理的并发线程数量，通过这两方面来显著提升服务器的性能。</p><h2 id="7-2-如何发现瓶颈"><a href="#7-2-如何发现瓶颈" class="headerlink" title="7.2 如何发现瓶颈"></a>7.2 如何发现瓶颈</h2><p>服务器会出现瓶颈的地方很多，例如CPU， 内存， 磁盘以及网络等可能都会导致瓶颈。另外不同的系统对于瓶颈的关注度不一样，例如对缓存系统来说，制约的是内存，而对存储型的系统来说I/O 更容易出现瓶颈。</p><p>而对于秒杀，瓶颈更容易发生在CPU上。</p><p>那么，如何发现 CPU 的瓶颈呢？其实有很多 CPU 诊断工具可以发现 CPU 的消耗，最常用的就是 JProfiler 和 Yourkit 这两个工具，它们可以列出整个请求中每个函数的 CPU 执行时间，可以发现哪个函数消耗的 CPU 时间最多，以便你有针对性地做优化。</p><p>当然还有一些办法也可以近似地统计 CPU 的耗时，例如通过 jstack 定时地打印调用栈，如果某些函数调用频繁或者耗时较多，那么那些函数就会多次出现在系统调用栈里，这样相当于采样的方式也能够发现耗时较多的函数。</p><p>虽说秒杀系统的瓶颈大部分在 CPU，但这并不表示其他方面就一定不出现瓶颈。例如，如果海量请求涌过来，你的页面又比较大，那么网络就有可能出现瓶颈。</p><p>怎样简单地判断 CPU 是不是瓶颈呢？一个办法就是看当 QPS 达到极限时，你的服务器的 CPU 使用率是不是超过了 95%，如果没有超过，那么表示 CPU 还有提升的空间，要么是有锁限制，要么是有过多的本地 I/O 等待发生。</p><h2 id="7-3-如何优化系统"><a href="#7-3-如何优化系统" class="headerlink" title="7.3 如何优化系统"></a>7.3 如何优化系统</h2><p>针对Java来说的：</p><h3 id="7-3-1-减少编码"><a href="#7-3-1-减少编码" class="headerlink" title="7.3.1 减少编码"></a>7.3.1 减少编码</h3><p>Java的编码运行比较慢，在很多场景下，只要涉及字符串的操作都会比较消耗CPU资源，不管是磁盘IO还是网络IO，因为都需要将字符转换成字节，这个转换必须编码。</p><p>每个字符的编码都需要查表，而这种查表的操作非常耗资源，所以减少字符到字节或者相反的转换、减少字符编码会非常有成效。减少编码就可以大大提升性能。</p><p>那么如何才能减少编码呢？例如，网页输出是可以直接进行流输出的，即用 resp.getOutputStream() 函数写数据，把一些静态的数据提前转化成字节，等到真正往外写的时候再直接用 OutputStream() 函数写，就可以减少静态数据的编码转换。</p><h3 id="7-3-2-减少序列化"><a href="#7-3-2-减少序列化" class="headerlink" title="7.3.2 减少序列化"></a>7.3.2 减少序列化</h3><p>序列化也是Java性能的一大天敌，减少Java当中的序列化操作也能大大提升性能。又因为序列化往往是和编码同时发生的，所以减少序列化也就减少了编码。</p><p>序列化大部分是在 RPC 中发生的，因此避免或者减少 RPC 就可以减少序列化，当然当前的序列化协议也已经做了很多优化来提升性能。有一种新的方案，就是可以将多个关联性比较强的应用进行“合并部署”，而减少不同应用之间的 RPC 也可以减少序列化的消耗。</p><p>所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个 Tomcat 容器中，且不能走本机的 Socket，这样才能避免序列化的产生。</p><h3 id="7-3-3-Java-秒杀场景的针对性优化"><a href="#7-3-3-Java-秒杀场景的针对性优化" class="headerlink" title="7.3.3 Java 秒杀场景的针对性优化"></a>7.3.3 Java 秒杀场景的针对性优化</h3><p>Java 和通用的 Web 服务器（如 Nginx 或 Apache 服务器）相比，在处理大并发的 HTTP 请求时要弱一点，所以一般我们都会对大流量的 Web 系统做静态化改造，让大部分请求和数据直接在 Nginx 服务器或者 Web 代理服务器（如 Varnish、Squid 等）上直接返回（这样可以减少数据的序列化与反序列化），而 Java 层只需处理少量数据的动态请求。针对这些请求，我们可以使用以下手段进行优化：</p><ul><li>直接使用 Servlet 处理请求。避免使用传统的 MVC 框架，这样可以绕过一大堆复杂且用处不大的处理逻辑，节省 1ms 时间（具体取决于你对 MVC 框架的依赖程度）。</li><li>直接输出流数据。使用 resp.getOutputStream() 而不是 resp.getWriter() 函数，可以省掉一些不变字符数据的编码，从而提升性能；数据输出时推荐使用 JSON 而不是模板引擎（一般都是解释执行）来输出页面。</li></ul><h3 id="7-3-4-并发读优化"><a href="#7-3-4-并发读优化" class="headerlink" title="7.3.4 并发读优化"></a>7.3.4 并发读优化</h3><p>也许有读者会觉得这个问题很容易解决，无非就是放到 Tair 缓存里面。集中式缓存为了保证命中率一般都会采用一致性 Hash，所以同一个 key 会落到同一台机器上。虽然单台缓存机器也能支撑 30w/s 的请求，但还是远不足以应对像“大秒”这种级别的热点商品。那么，该如何彻底解决单点的瓶颈呢？</p><p>答案是采用应用层的 LocalCache，即在秒杀系统的单机上缓存商品相关的数据。</p><p>那么，又如何缓存（Cache）数据呢？你需要划分成动态数据和静态数据分别进行处理：</p><ul><li>像商品中的“标题”和“描述”这些本身不变的数据，会在秒杀开始之前全量推送到秒杀机器上，并一直缓存到秒杀结束；</li><li>像库存这类动态数据，会采用“被动失效”的方式缓存一定时间（一般是数秒），失效后再去缓存拉取最新的数据。</li></ul><p>还有关于一致性的问题，因为库存是在不断更新的，这就要用到前面介绍的读数据的分层校验原则了，读的场景可以允许一定的脏数据，因为这里的误判只会导致少量原本无库存的下单请求被误认为有库存，可以等到真正写数据时再保证最终的一致性，通过在数据的高可用性和一致性之间的平衡，来解决高并发的数据读取问题。</p><h1 id="8-减库存设计的核心逻辑"><a href="#8-减库存设计的核心逻辑" class="headerlink" title="8. 减库存设计的核心逻辑"></a>8. 减库存设计的核心逻辑</h1><p>不超卖是秒杀系统的前提。减库存到底应该是在下单阶段还是付款阶段呢？ </p><h2 id="8-1-减库存的方式"><a href="#8-1-减库存的方式" class="headerlink" title="8.1 减库存的方式"></a>8.1 减库存的方式</h2><h3 id="8-1-1-下单减库存"><a href="#8-1-1-下单减库存" class="headerlink" title="8.1.1 下单减库存"></a>8.1.1 下单减库存</h3><p>即当买家下单之后，在商品的总库存中减去买家购买的数量。这种方式控制最精确，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的现象。但是有些人下完单以后并不会付款。</p><h3 id="8-1-2-付款减库存"><a href="#8-1-2-付款减库存" class="headerlink" title="8.1.2 付款减库存"></a>8.1.2 付款减库存</h3><p>即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。</p><h3 id="8-1-3-预扣库存"><a href="#8-1-3-预扣库存" class="headerlink" title="8.1.3 预扣库存"></a>8.1.3 预扣库存</h3><p>这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 10 分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。</p><h2 id="8-2-可能存在的问题"><a href="#8-2-可能存在的问题" class="headerlink" title="8.2 可能存在的问题"></a>8.2 可能存在的问题</h2><p>假如我们采用“下单减库存”的方式，即用户下单后就减去库存，正常情况下，买家下单后付款的概率会很高，所以不会有太大问题。但是有一种场景例外，就是当卖家参加某个活动时，此时活动的有效时间是商品的黄金售卖时间，如果有竞争对手通过恶意下单的方式将该卖家的商品全部下单，让这款商品的库存减为零，那么这款商品就不能正常售卖了。要知道，这些恶意下单的人是不会真正付款的，这正是“下单减库存”方式的不足之处。</p><p>既然“下单减库存”可能导致恶意下单，从而影响卖家的商品销售，那么有没有办法解决呢？你可能会想，采用“付款减库存”的方式是不是就可以了？的确可以。但是，“付款减库存”又会导致另外一个问题：库存超卖。</p><p>假如有 100 件商品，就可能出现 300 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。这样一来，就会导致很多买家下单成功但是付不了款，买家的购物体验自然比较差。</p><p>那么，既然“下单减库存”和“付款减库存”都有缺点，我们能否把两者相结合，将两次操作进行前后关联起来，下单时先预扣，在规定时间内不付款再释放库存，即采用“预扣库存”这种方式呢？</p><p>这种方案确实可以在一定程度上缓解上面的问题。但是否就彻底解决了呢？其实没有！针对恶意下单这种情况，虽然把有效的付款时间设置为 10 分钟，但是恶意买家完全可以在 10 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。</p><p>例如，给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买 3 件），以及对重复下单不付款的操作进行次数限制等。</p><p>针对“库存超卖”这种情况，在 10 分钟时间内下单的数量仍然有可能超过库存数量，遇到这种情况我们只能区别对待：对普通的商品下单数量超过库存数量的情况，可以通过补货来解决；但是有些卖家完全不允许库存为负数的情况，那只能在买家付款时提示库存不足。</p><h2 id="8-3-大型秒杀中如何减库存"><a href="#8-3-大型秒杀中如何减库存" class="headerlink" title="8.3 大型秒杀中如何减库存"></a>8.3 大型秒杀中如何减库存</h2><p>对于一般业务系统而言，一般是预扣库存的方案，超出有效付款时间订单就会自动释放。而对于秒杀场景，一般采用下单减库存。</p><p>“下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种解决方案：一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错；再有一种就是使用 CASE WHEN 判断语句，例如这样的 SQL 语句：</p><pre><code>UPDATE item SET inventory = CASE WHEN inventory &gt;= xxx THEN inventory-xxx ELSE inventory END</code></pre><p>秒杀商品和普通商品的减库存还是有些差异的，例如商品数量比较少，交易时间段也比较短，因此这里有一个大胆的假设，即能否把秒杀商品减库存直接放到缓存系统中实现，也就是直接在缓存中减库存或者在一个带有持久化功能的缓存系统（如 Redis）中完成呢？</p><p>如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU 库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。</p><p>由于 MySQL 存储数据的特点，同一数据在数据库里肯定是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁，而并发度越高时等待线程会越多，TPS（Transaction Per Second，即每秒处理的消息数）会下降，响应时间（RT）会上升，数据库的吞吐量就会严重受影响。</p><p>这就可能引发一个问题，就是单个热点商品会影响整个数据库的性能， 导致 0.01% 的商品影响 99.99% 的商品的售卖，这是我们不愿意看到的情况。一个解决思路是遵循前面介绍的原则进行隔离，把热点商品放到单独的热点库中。但是这无疑会带来维护上的麻烦，比如要做热点数据的动态迁移以及单独的数据库等。</p><p>而分离热点商品到单独的数据库还是没有解决并发锁的问题，我们应该怎么办呢？要解决并发锁的问题，有两种办法：</p><ol><li>应用层排队</li></ol><p>按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。</p><ol start="2"><li>数据库排队</li></ol><p>应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。阿里的数据库团队开发了针对这种 MySQL 的 InnoDB 层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。</p><h1 id="9-如何设计兜底方案？"><a href="#9-如何设计兜底方案？" class="headerlink" title="9. 如何设计兜底方案？"></a>9. 如何设计兜底方案？</h1><h2 id="9-1-高可用建设应该从哪里着手？"><a href="#9-1-高可用建设应该从哪里着手？" class="headerlink" title="9.1 高可用建设应该从哪里着手？"></a>9.1 高可用建设应该从哪里着手？</h2><p><img src="https://i.loli.net/2020/02/03/pJX2oIyCGUVY7H5.jpg" alt="fig10.jpg"></p><ol><li>架构阶段 - 考虑系统的可扩展性和容错性，要避免出现单点问题。例如多机房单元化部署，即使某个城市的某个机房出现整体故障，仍然不会影响整体网站的运转。</li><li>编码阶段 - 保证代码的健壮性，例如涉及到远程调用的问题的时候，要设置合理的超时退出机制，防止被其他系统拖垮，也要对调用的返回结果集有预期，防止返回的结果超出程序处理的范围。即对错误异常进行捕获，对无法预料的错误要有默认处理结果。</li><li>测试阶段 - 测试主要是保证测试用例的覆盖度，保证最坏情况发生的时候，我们也有相应的处理流程。</li><li>发布阶段 - 要有紧急的回滚机制</li><li>运行阶段 - 运行态是常态，重要的是对系统的监控要准确及时，发现问题能够准确报警并且报警数据要准确详细，以便于排查问题。</li><li>故障发生 - 及时止损，例如由于程序问题导致商品价格错误，就要及时下架商品或者关闭购买链接，防止造成重大资产损失。</li></ol><p>为什么系统的高可用建设要放到整个生命周期中全面考虑？因为我们在每个环节中都可能犯错，而有些环节犯的错，你在后面是无法弥补的。例如在架构阶段，你没有消除单点问题，那么系统上线后，遇到突发流量把单点给挂了，你就只能干瞪眼，有时候想加机器都加不进去。所以高可用建设是一个系统工程，必须在每个环节都做好。</p><p>那么针对秒杀系统，我们重点介绍在遇到大流量时，应该从哪些方面来保障系统的稳定运行，所以更多的是看如何针对运行阶段进行处理，这就引出了接下来的内容：降级、限流和拒绝服务。</p><h2 id="9-2-降级"><a href="#9-2-降级" class="headerlink" title="9.2 降级"></a>9.2 降级</h2><p>所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务。它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。</p><p>降级方案可以这样设计：当秒杀流量达到 5w/s 时，把成交记录的获取从展示 20 条降级到只展示 5 条。“从 20 改到 5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。</p><p>这里，我给出开关系统的示意图。它分为两部分，一部分是开关控制台，它保存了开关的具体配置信息，以及具体执行开关所对应的机器列表；另一部分是执行下发开关数据的 Agent，主要任务就是保证开关被正确执行，即使系统重启后也会生效。</p><p><img src="https://i.loli.net/2020/02/03/MsuI54DXOFAKU7G.jpg" alt="fig11.jpg"></p><h2 id="9-3-限流"><a href="#9-3-限流" class="headerlink" title="9.3 限流"></a>9.3 限流</h2><p>如果说降级是牺牲了一部分次要的功能和用户的体验效果，那么限流就是更极端的一种保护措施了。限流就是当系统容量达到瓶颈时，我们需要通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施。</p><p>这里，我同样给出了限流系统的示意图。总体来说，限流既可以是在客户端限流，也可以是在服务端限流。此外，限流的实现方式既要支持 URL 以及方法级别的限流，也要支持基于 QPS 和线程的限流。</p><ul><li>客户端限流</li></ul><p>好处可以限制请求的发出，通过减少发出无用请求从而减少对系统的消耗。缺点就是当客户端比较分散时，没法设置合理的限流阈值：如果阈值设的太小，会导致服务端没有达到瓶颈时客户端已经被限制；而如果设的太大，则起不到限制的作用。</p><ul><li>服务端限流</li></ul><p>好处是可以根据服务端的性能设置合理的阈值，而缺点就是被限制的请求都是无效的请求，处理这些无效的请求本身也会消耗服务器资源。</p><p><img src="https://i.loli.net/2020/02/03/zm8P6fRyoUsclSj.jpg" alt="fig12.jpg"></p><p>在限流的实现手段上来讲，基于 QPS 和线程数的限流应用最多，最大 QPS 很容易通过压测提前获取，例如我们的系统最高支持 1w QPS 时，可以设置 8000 来进行限流保护。线程数限流在客户端比较有效，例如在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃。</p><p>限流无疑会影响用户的正常请求，所以必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能 fast fail（快速失败）而拖垮系统。</p><h2 id="9-4-拒绝服务"><a href="#9-4-拒绝服务" class="headerlink" title="9.4 拒绝服务"></a>9.4 拒绝服务</h2><p>当系统负载达到一定阈值时，例如 CPU 使用率达到 90% 或者系统 load 值达到 2*CPU 核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。例如秒杀系统，我们在如下几个环节设计过载保护：</p><p>在最前端的 Nginx 上设置过载保护，当机器负载达到某个值时直接拒绝 HTTP 请求并返回 503 错误码，在 Java 层同样也可以设计过载保护。</p><p>拒绝服务可以说是一种不得已的兜底方案，用以防止最坏情况发生，防止因把服务器压跨而长时间彻底无法提供服务。像这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。</p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 秒杀 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面向对象设计原则</title>
      <link href="/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/"/>
      <url>/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<h1 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h1><p>支持可维护性，提高系统的可复用性</p><h1 id="2-设计原则"><a href="#2-设计原则" class="headerlink" title="2.设计原则"></a>2.设计原则</h1><h2 id="2-1-单一职责原则-Single-Responsibility-Principle"><a href="#2-1-单一职责原则-Single-Responsibility-Principle" class="headerlink" title="2.1 单一职责原则 Single Responsibility Principle"></a>2.1 单一职责原则 Single Responsibility Principle</h2><p>一个类只负责一个功能领域中的相应职责，只负责一个功能领域中的相应职责。</p><p>承担的责任越多，那被复用的可能性就越小。多职责意味着是把多个类耦合了起来</p><p><img src="https://i.loli.net/2020/02/03/jKXMsxyiB6z3uac.jpg" alt="单一职责1.jpg"><br>CustomerDataChart类包含了与数据库的连接，查询客户信息和创建显示图标三大方面的功能，应该将其分为三个类，分别进行处理</p><p><img src="https://i.loli.net/2020/02/03/X4Z1TfBRzkMLSNW.jpg" alt="单一职责2.jpg"><br>DBUtil  负责连接数据库<br>CustomerDao 负责操作数据库中的Customer表<br>CustomerDataChart 负责图表的生成的显示</p><h2 id="2-2-开闭原则-Open-Closed-Principle"><a href="#2-2-开闭原则-Open-Closed-Principle" class="headerlink" title="2.2 开闭原则 Open-Closed Principle"></a>2.2 开闭原则 Open-Closed Principle</h2><p>软件实体应对拓展开放，而对修改关闭。<strong><em>软件实体应该尽量在不修改原有代码的情况下进行扩展。</em></strong></p><p>为了满足开闭原则，需要对系统进行抽象化设计！！！为系统定义一个相对稳定的抽象层，而后将不同的实现行为移至具体的实现层中完成。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。</p><p><img src="https://i.loli.net/2020/02/03/6SEFzrxNtTgMPQK.jpg" alt="开闭原则1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/bM73ZsD4UkdJ9QP.jpg" alt="开闭原则2.jpg"></p><p>加一个抽象类，每一种Chart可以extends这个抽象类，然后做具体的实现。在ChartDisplay类中，可以实例化Chart类，调用其display()方法来显示对应的图表。当要改变的时候，加一个实现类，在客户端注入这个对象即可。</p><h2 id="2-3-里氏代换原则-Liskov-Substitution-Principle"><a href="#2-3-里氏代换原则-Liskov-Substitution-Principle" class="headerlink" title="2.3 里氏代换原则 Liskov Substitution Principle"></a>2.3 里氏代换原则 Liskov Substitution Principle</h2><p>所有引用基类对象的地方能够透明地使用其子类的对象</p><p>在软件中，将一个基类的对象替换成其子类对象，程序将不会产生任何错误和异常，反过来则不成立。</p><p>里氏代换原则是实现开闭原则的重要方式之一。由于使用基类对象的地方都可以使用子类，因此<strong><em>在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。</em></strong></p><h3 id="2-3-1-注意事项"><a href="#2-3-1-注意事项" class="headerlink" title="2.3.1 注意事项"></a>2.3.1 注意事项</h3><ol><li>子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。</li><li>我们在运用里氏代换原则时，尽量把父类设计为<strong>抽象类或者接口</strong>，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。</li></ol><p><img src="https://i.loli.net/2020/02/03/OXI4TrtJ1j3gzVa.jpg" alt="里氏原则1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/4PuoLXtib6SQCKH.jpg" alt="里氏原则2.jpg"></p><p>通过增加抽象类，让子类来替换父类的方式来进行编程，增强代码的复用性。</p><h2 id="2-4-依赖倒转原则-Dependence-Inversion-Principle"><a href="#2-4-依赖倒转原则-Dependence-Inversion-Principle" class="headerlink" title="2.4 依赖倒转原则 Dependence Inversion Principle"></a>2.4 依赖倒转原则 Dependence Inversion Principle</h2><p>抽象不应该依赖于细节，细节应该依赖于抽象</p><blockquote><p>针对接口编程，而不是针对实现编程。</p></blockquote><p>在程序代码中传递参数时或者在关联关系中，尽量引用层次高的抽象层类，即，使用接口和抽象类进行变量类型声明、参数类型声明、方法返回类型声明，以及数据类型的转换等，而不要用具体类来做这些事情。</p><p>为了确保该原则的应用，<strong><em>一个具体类应当只实现接口或抽象类中声明过的方法，而不要给出多余的方法，否则将无法调用到在子类中增加的新方法。</em></strong></p><p>在实现依赖倒转原则时，我们需要针对抽象层编程，而将具体类的对象通过依赖注入(DependencyInjection, DI)的方式注入到其他对象中，依赖注入是指当一个对象要与其他对象发生依赖关系时，通过抽象来注入所依赖的对象。常用的注入方式有三种，分别是：</p><ul><li>构造注入</li></ul><p>构造注入是指通过构造函数来传入具体类的对象</p><ul><li>设值注入（Setter注入）</li></ul><p>设值注入是指通过Setter方法来传入具体类的对象</p><ul><li>接口注入</li></ul><p>而接口注入是指通过在接口中声明的业务方法来传入具体类的对象。</p><p><strong>这些方法在定义时使用的是抽象类型，在运行时再传入具体类型的对象，由子类对象来覆盖父类对象。</strong></p><p>加了一个抽象的DataConvertor，面向它来进行编程，然后在Config里面定义到底需要哪一个Convertor的具体实现类</p><p><img src="https://i.loli.net/2020/02/03/n4DwgFpP91Ua2vX.jpg" alt="依赖倒转1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/vq8aUZGpfMWhiAN.jpg" alt="依赖倒转2.jpg"></p><h2 id="2-5-接口隔离原则-Interface-Segragation-Principle"><a href="#2-5-接口隔离原则-Interface-Segragation-Principle" class="headerlink" title="2.5 接口隔离原则 Interface Segragation Principle"></a>2.5 接口隔离原则 Interface Segragation Principle</h2><p>使用多个专门接口，而不使用单一的总接口。即客户端不应该依赖那些它不需要的接口。</p><p><strong><em>每个接口应该承担一种相对独立的角色</em></strong> </p><p>尽量提供窄接口，根据不同的职责分别放在不同的小接口当中</p><p> 在使用接口隔离原则时，我们需要注意控制接口的粒度，接口不能太小，如果太小会导致系统中接口泛滥，不利于维护；接口也不能太大，太大的接口将违背接口隔离原则，灵活性较差，使用起来很不方便。一般而言，接口中仅包含为某一类用户定制的方法即可，不应该强迫客户依赖于那些它们不用的方法。</p><p><img src="https://i.loli.net/2020/02/03/aEnKRgm2THM8L6c.jpg" alt="接口隔离1.jpg"><br><img src="https://i.loli.net/2020/02/03/K1iNF5jB2aGHoVc.jpg" alt="接口隔离2.jpg"></p><h2 id="2-6-合成复用原则-Composite-Reuse-Principle"><a href="#2-6-合成复用原则-Composite-Reuse-Principle" class="headerlink" title="2.6 合成复用原则 Composite Reuse Principle"></a>2.6 合成复用原则 Composite Reuse Principle</h2><p>尽量使用对象组合，而不是继承来达到复用的目的</p><p>在一个新的对象里，通过关联关系（组合关系和聚合关系）来使用一些已有对象，使之成为新对象的一部分。新对象通过委派调用已有对象的方法达到复用功能的目的。</p><blockquote><p>先考虑组合，再考虑继承</p></blockquote><p>组合/聚合可以使系统更加灵活，降低类与类之间的耦合度，一个类的变化对其他类造成的影响相对较少；其次才考虑继承，在使用继承时，需要严格遵循里氏代换原则，有效使用继承会有助于对问题的理解，降低复杂度，而滥用继承反而会增加系统构建和维护的难度以及系统的复杂度，因此需要慎重使用继承复用</p><p>继承复用会破坏系统的封装性，因为继承会将基类的实现细节暴露给子类——&gt; <strong>白箱复用</strong>。如果基类发生改变，子类的实现也必须改变。这样子做没有足够的灵活性。</p><p>组合或者聚合关系是将已有对象纳入到新对象当中，使之成为新对象的一部分。新对象可以调用已有对象的功能，但是具体实现是对其不可见的。合成复用可以在运行时动态进行，新对象可以动态的引用与成员对象类型相同的其他对象。</p><blockquote><p>对于”Has A”关系，使用合成复用，对于”Is A”关系，使用继承</p></blockquote><p><img src="https://i.loli.net/2020/02/03/iQuJD2VyKEzNB8P.jpg" alt="合成复用1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/HUb5O1qjXk7BYKu.jpg" alt="合成复用2.jpg"></p><h2 id="2-7-迪米特法则-Law-of-Demeter"><a href="#2-7-迪米特法则-Law-of-Demeter" class="headerlink" title="2.7 迪米特法则 Law of Demeter"></a>2.7 迪米特法则 Law of Demeter</h2><p>一个软件实体应当尽可能少地与其他实体发生相互作用，这是对软件实体之间通信的限制。</p><p>当其中一个模块发生修改时，会尽量少地影响其他模块，扩展会相对容易。</p><p>只与直接的朋友通信，包括：</p><ol><li>当前对象本身</li><li>以参数形式传入到当前对象方法中的对象</li><li>当前对象的成员对象</li><li>当前对象所创建的对象</li></ol><p>如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。</p><p>！！！ 通过引入中间件来降低整体的耦合度</p><p><img src="https://i.loli.net/2020/02/03/6CxEVeahFjcQ9AN.jpg" alt="迪米特1.jpg"></p><p><img src="https://i.loli.net/2020/02/03/KHX1vnuDbTewQaY.jpg" alt="迪米特2.jpg"></p><h1 id="3-Reference"><a href="#3-Reference" class="headerlink" title="3. Reference"></a>3. Reference</h1><p><a href="https://blog.csdn.net/lovelion/article/details/7536532" target="_blank" rel="noopener">LiuWei’s CSDN</a></p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System Design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>混沌工程</title>
      <link href="/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/"/>
      <url>/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="1-微服务架构的挑战"><a href="#1-微服务架构的挑战" class="headerlink" title="1. 微服务架构的挑战"></a>1. 微服务架构的挑战</h1><p>当前的趋势就是微服务架构，将原有系统拆分为更加灵活、有业务边界、上下文、松散耦合、可独立部署的服务来应对快速变化的消费市场。</p><p>通常情况下，对于复杂业务或遗留系统，我们可以通过领域驱动设计(DDD:Domain-Driven Design)有效的解决限界上下文划分、服务边界定义以及组织结构调整等问题。除了这些，我们的开发团队还面临着其他的挑战：复杂的分布式系统、数据一致性、容错设计、限流设计、舱壁设计等问题。那么如此复杂的系统如何来保证系统“质量”呢？</p><p>长久以来，“测试金字塔”都是敏捷开发团队保证项目交付质量的守则，而“测试金字塔”也确实从不同的维度涵盖了方法调用、业务逻辑、用户行为等方面。</p><p>End2End test -&gt; API test -&gt; Unit test</p><p>除此以外，我们可以利用契约测试来保证调用方与提供方的一致性，然而七月测试只能覆盖到业务逻辑的维度，需要更深入的了解微服务特性以期更好的开发与改造。</p><p>譬如微服务系统的客户端负载均衡、微服务容错保护、API服务网关、分布式链路跟踪就无法被契约测试测试。</p><p>既然我们没有办法避免灾难的发生，最好的办法就是“探索系统故障边界，验证系统灾难恢复能力”。以往的“机房”时代的一些故障演练一般通过断网、断电模拟单点故障，来测试系统的恢复能力，而新型的分布式服务时代消除了单点故障，但也引入了更多复杂的问题，我们需要可靠性更强、容错性和扩容性更高的系统。一种解决方案就是，我们需要一种有策略的、有方法的实践方案对系统进行一定程度的“随机破坏”，通过让系统”感染“，来提升系统的”免疫力“。</p><h1 id="2-混沌工程"><a href="#2-混沌工程" class="headerlink" title="2. 混沌工程"></a>2. 混沌工程</h1><p>混沌工程是一种可试验的、基于系统的方法来处理大规模分布式系统中的混乱问题。通过不断试验，了解系统的实际能承受的韧性边界并建立信心，通过不同的试验方法和目的，观察分布式系统的行为和反应。一句话——以试验的方法尽早揭露系统弱点。</p><p>混沌工程类似于“故障演练”，不局限于测试，而更像是工程实践。为什么这么说，通常的测试用例会有“期望结果”和“实际结果”，通过将两个结果比较，或者对用户行为的预期，来判断测试通过或失败。而混沌试验类似于”<strong>探索性测试</strong>“，试验本身没有明确是输入和预期结果，通过对系统和服务的干预，来观察系统的”反应“。我们将混沌工程原则融入在试验过程中：在生产环境小规模模拟系统故障并定期自动化执行试验，通过试验结果与正常结果进行比对，观察系统”边界“。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://insights.thoughtworks.cn/microservice-architecture-chaotic-engineering/#utm_source=rss&amp;utm_medium=rss" target="_blank" rel="noopener">https://insights.thoughtworks.cn/microservice-architecture-chaotic-engineering/#utm_source=rss&amp;utm_medium=rss</a>   </p>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> BackEnd </tag>
            
            <tag> 混沌工程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IOC容器和Dependency Injection模式</title>
      <link href="/IOC%E5%AE%B9%E5%99%A8%E5%92%8CDependency-Injection%E6%A8%A1%E5%BC%8F/"/>
      <url>/IOC%E5%AE%B9%E5%99%A8%E5%92%8CDependency-Injection%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>Martin Fowler的文章，在文中深入探索控制反转的的工作原理，给它一个更能描述其特点的名字——”依赖注入”（Dependency Injection），并将其与”服务定位器”（Service Locator）模式作一个比较。探讨了异同。最最重要的，也是每个程序员都应该注意的是：应该将服务的配置和应用程序内部对服务的使用分离开。这也是控制反转以及服务定位器一直在做的。</p><h1 id="1-问题"><a href="#1-问题" class="headerlink" title="1. 问题"></a>1. 问题</h1><p>J2EE开发者常遇到的一个问题就是<strong><em>如何组装不同的程序元素</em></strong>：如果web控制器体系结构和数据库接口是由不同的团队所开发的，彼此几乎一无所知，你应该如何让它们配合工作？很多框架尝试过解决这个问题，有几个框架索性朝这个方向发展，提供了更通用的”组装各层组件”的方案。这样的框架通常被称为”轻量级容器”，PicoContainer和Spring都在此列中。</p><h2 id="2-实例"><a href="#2-实例" class="headerlink" title="2.实例"></a>2.实例</h2><p>有一个提供一份电影清单的组件，清单上列出有一位特定导演执导的影片</p><pre><code>class MovieLister...public Movie[] moviesDirectedBy(String arg){    List allMovies = finder.findAll();    for (Iterator it = allMovies.iterator(); it.hasNext();)    {        Movie movie = (Movie) it.next();        if (!movie.getDirector().equals(arg))        {            it.remove();        }    }    return (Movie[]) allMovies.toArray(new Movie[allMovies.size()]);}</code></pre><p>这个功能的实现极其简单：moviesDirectedBy方法首先请求finder（影片搜寻者）对象（我们稍后会谈到这个对象）返回后者所知道的所有影片，然后遍历finder对象返回的清单，并返回其中由特定的某个导演执导的影片。非常简单，不过不必担心，这只是整个例子的脚手架罢了。<strong><em>我们真正想要考察的是finder对象，或者说，如何将MovieLister对象与特定的finder对象连接起来</em></strong>。为什么我们对这个问题特别感兴趣？因为<strong><em>我希望上面这个漂亮的moviesDirectedBy方法完全不依赖于影片的实际存储方式。</em></strong>所以，这个方法只能引用一个finder对象，而finder对象则必须知道如何对findAll 方法作出回应。为了帮助读者更清楚地理解，我给finder定义了一个接口：</p><pre><code>public interface MovieFinder{    List findAll();}</code></pre><p>现在，两个对象之间没有什么耦合关系。但是，当我要实际寻找影片时，就必须涉及到MovieFinder的某个具体子类。在这里，<em>我把涉及具体子类的代码放在MovieLister类的构造函数中</em>。</p><pre><code>class MovieLister...private MovieFinder finder;public MovieLister(){    finder = new ColonDelimitedMovieFinder(&quot;movies1.txt&quot;);}</code></pre><p>这个实现类的名字就说明：我将要从一个逗号分隔的文本文件中获得影片列表。你不必操心具体的实现细节，只要设想这样一个实现类就可以了。如果这个类只由我自己使用，一切都没问题。但是，如果我的朋友叹服于这个精彩的功能，也想使用我的程序，那又会怎么样呢？如果他们也把影片清单保存在一个逗号分隔的文本文件中，并且也把这个文件命名为” movie1.txt “，那么一切还是没问题。如果他们只是给这个文件改改名，我也可以从一个配置文件获得文件名，这也很容易。<strong>但是，如果他们用完全不同的方式——例如SQL 数据库、XML 文件、web service，或者另一种格式的文本文件——来存储影片清单呢？</strong>在这种情况下，我们需要用另一个类来获取数据。由于已经定义了MovieFinder接口，我可以不用修改moviesDirectedBy方法。但是，我<strong><em>仍然需要通过某种途径获得合适的MovieFinder实现类的实例</em></strong>。</p><p><img src="https://i.loli.net/2020/02/03/B2Nf9MX6VIL4oKP.gif" alt="figure1.gif"></p><p>MovieLister类既依赖于MovieFinder接口，也依赖于具体的实现类。我们当然希望MovieLister类只依赖于接口，但我们要如何获得一个MovieFinder子类的实例呢？</p><p>在Patterns of Enterprise Application Architecture一书中，我们把这种情况称为<strong>插件（plugin）</strong>：MovieFinder的实现类<strong>不是在编译期连入程序之中的</strong>，因为我并不知道我的朋友会使用哪个实现类。我们希望MovieLister类能够与MovieFinder的任何实现类配合工作，并且允许<strong>在运行期插入具体的实现类</strong>，插入动作完全脱离我（原作者）的控制。这里的问题就是：<strong>如何设计这个连接过程，使MovieLister类在不知道实现类细节的前提下与其实例协同工作。</strong></p><p>将这个例子推而广之，在一个真实的系统中，我们可能有数十个服务和组件。在任何时候，我们总可以对使用组件的情形加以抽象，<strong>通过接口与具体的组件交流</strong>（如果组件并没有设计一个接口，也可以通过适配器与之交流）。但是，如果我们希望以不同的方式部署这个系统，就需要用插件机制来处理服务之间的交互过程，这样我们才可能在不同的部署方案中使用不同的实现。所以，现在的核心问题就是：<strong>如何将这些插件组合成一个应用程序？这正是新生的轻量级容器所面临的主要问题，而它们解决这个问题的手段无一例外地是控制反转（Inversion of Control）模式</strong>。</p><h1 id="3-控制反转"><a href="#3-控制反转" class="headerlink" title="3. 控制反转"></a>3. 控制反转</h1><p>几位轻量级容器的作者曾骄傲地对我说：这些容器非常有用，因为它们实现了控制反转。这样的说辞让我深感迷惑：控制反转是框架所共有的特征，如果仅仅因为使用了控制反转就认为这些轻量级容器与众不同，就好象在说我的轿车是与众不同的，因为它有四个轮子。</p><p>问题的关键在于：它们反转了哪方面的控制？我第一次接触到的控制反转针对的是用户界面的主控权。早期的用户界面是完全由应用程序来控制的，你预先设计一系列命令，例如输入姓名、输入地址等，应用程序逐条输出提示信息，并取回用户的响应。而在图形用户界面环境下，UI框架将负责执行一个主循环，你的应用程序只需为屏幕的各个区域提供事件处理函数即可。在这里，程序的主控权发生了反转：从应用程序移到了框架。对于这些新生的容器，它们反转的是如何定位插件的具体实现。在前面那个简单的例子中，MovieLister类负责定位MovieFinder的具体实现——它直接实例化后者的一个子类。这样一来，MovieFinder也就不成其为一个插件了，因为它并不是在运行期插入应用程序中的。而这些轻量级容器则使用了更为灵活的办法，<strong>只要插件遵循一定的规则，一个独立的组装模块就能够将插件的具体实现注射到应用程序中。</strong>因此，我想我们需要给这个模式起一个更能说明其特点的名字——”控制反转”这个名字太泛了，常常让人有些迷惑。与多位IoC 爱好者讨论之后，我们决定将这个模式叫做”依赖注入”（Dependency Injection）。</p><p>下面，我将开始介绍Dependency Injection模式的几种不同形式。不过，在此之前，我要首先指出：要消除应用程序对插件实现的依赖，依赖注入并不是唯一的选择，你也可以用ServiceLocator模式获得同样的效果。介绍完Dependency Injection模式之后，我也会谈到ServiceLocator 模式。</p><h2 id="3-1-依赖注入的几种形式"><a href="#3-1-依赖注入的几种形式" class="headerlink" title="3.1 依赖注入的几种形式"></a>3.1 依赖注入的几种形式</h2><p>Dependency Injection模式的基本思想是：用一个单独的对象（装配器）来获得MovieFinder的一个合适的实现，并将其实例赋给MovieLister类的一个字段。这样一来，我们就得到了图2所示的依赖图：</p><p><img src="https://i.loli.net/2020/02/03/wySa8WINcA2Xp49.gif" alt="figure2.gif"></p><h3 id="3-1-1-构造函数注入"><a href="#3-1-1-构造函数注入" class="headerlink" title="3.1.1 构造函数注入"></a>3.1.1 构造函数注入</h3><p>这里使用PicoContainer，一个轻量级容器来完成依赖注入。</p><p>PicoContainer通过构造函数来判断如何将MovieFinder实例注入MovieLister 类。因此，MovieLister类必须声明一个构造函数，并在其中包含所有需要注入的元素：</p><pre><code>class MovieLister...    public MovieLister(MovieFinder finder)    {        this.finder = finder;    }</code></pre><p>MovieFinder实例本身也将由PicoContainer来管理，因此文本文件的名字也可以由容器注入：</p><pre><code>class ColonMovieFinder...    public ColonMovieFinder(String filename)    {        this.filename = filename;    }</code></pre><p>随后，需要告诉PicoContainer：各个接口分别与哪个实现类关联、将哪个字符串注入MovieFinder组件。</p><pre><code>private MutablePicoContainer configureContainer(){    MutablePicoContainer pico = new DefaultPicoContainer();    Parameter[] finderParams = {newConstantParameter(&quot;movies1.txt&quot;)};    pico.registerComponentImplementation(MovieFinder.class,ColonMovieFinder.class, finderParams);    pico.registerComponentImplementation(MovieLister.class);    return pico;}</code></pre><p>这段配置代码通常位于另一个类。对于我们这个例子，使用我的MovieLister 类的朋友需要在自己的设置类中编写合适的配置代码。当然，还可以将这些配置信息放在一个单独的配置文件中，这也是一种常见的做法。你可以编写一个类来读取配置文件，然后对容器进行合适的设置。尽管PicoContainer本身并不包含这项功能，但另一个与它关系紧密的项目NanoContainer提供了一些包装，允许开发者使用XML配置文件保存配置信息。NanoContainer能够解析XML文件，并对底下的PicoContainer进行配置。这个项目的哲学观念就是：将配置文件的格式与底下的配置机制分离开。</p><pre><code>public void testWithPico(){    MutablePicoContainer pico = configureContainer();    MovieLister lister = (MovieLister)pico.getComponentInstance(MovieLister.class);    Movie[] movies = lister.moviesDirectedBy(&quot;Sergio Leone&quot;);    assertEquals(&quot;Once Upon a Time in the West&quot;,movies[0].getTitle());}</code></pre><h3 id="3-1-2-设值方法注入"><a href="#3-1-2-设值方法注入" class="headerlink" title="3.1.2 设值方法注入"></a>3.1.2 设值方法注入</h3><p>Spring 框架是一个用途广泛的企业级Java 开发框架，其中包括了针对事务、持久化框架、web应用开发和JDBC等常用功能的抽象。和PicoContainer一样，它也同时支持构造函数注入和设值方法注入，但该项目的开发者更推荐使用设值方法注入——恰好适合这个例子。为了让MovieLister类接受注入，我需要为它定义一个设值方法，该方法接受类型为MovieFinder的参数：</p><pre><code>class MovieLister...private MovieFinder finder;public void setFinder(MovieFinder finder){    this.finder = finder;}</code></pre><p>类似地，在MovieFinder的实现类中，我也定义了一个设值方法，接受类型为String 的参数：</p><pre><code>class ColonMovieFinder...    public void setFilename(String filename)    {        this.filename = filename;    }</code></pre><p>第三步是设定配置文件。Spring 支持多种配置方式，你可以通过XML 文件进行配置，也可以直接在代码中配置。不过，XML 文件是比较理想的配置方式。</p><pre><code>&lt;beans&gt;    &lt;bean id=&quot;MovieLister&quot; class=&quot;spring.MovieLister&quot;&gt;        &lt;property name=&quot;finder&quot;&gt;            &lt;ref local=&quot;MovieFinder&quot;/&gt;        &lt;/property&gt;    &lt;/bean&gt;    &lt;bean id=&quot;MovieFinder&quot; class=&quot;spring.ColonMovieFinder&quot;&gt;        &lt;property name=&quot;filename&quot;&gt;            &lt;value&gt;movies1.txt&lt;/value&gt;        &lt;/property&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre><p>测试代码：</p><pre><code>public void testWithSpring() throws Exception{    ApplicationContext ctx = newFileSystemXmlApplicationContext(&quot;spring.xml&quot;);    MovieLister lister = (MovieLister) ctx.getBean(&quot;MovieLister&quot;);    Movie[] movies = lister.moviesDirectedBy(&quot;Sergio Leone&quot;);    assertEquals(&quot;Once Upon a Time in the West&quot;,movies[0].getTitle());}</code></pre><h3 id="3-1-3-接口注入"><a href="#3-1-3-接口注入" class="headerlink" title="3.1.3 接口注入"></a>3.1.3 接口注入</h3><p>除了前面两种注入技术，还可以在接口中定义需要注入的信息，并通过接口完成注入。Avalon框架就使用了类似的技术。在这里，我首先用简单的范例代码说明它的用法，后面还会有更深入的讨论。首先，我需要定义一个接口，<strong>组件的注入将通过这个接口进行</strong>。在本例中，这个接口的用途是将一个MovieFinder实例注入继承了该接口的对象。</p><pre><code>public interface InjectFinder{    void injectFinder(MovieFinder finder);}</code></pre><p>这个接口应该由提供MovieFinder接口的人一并提供。任何想要使用MovieFinder实例的类（例如MovieLister类）都必须实现这个接口。</p><pre><code>class MovieLister implements InjectFinder...    public void injectFinder(MovieFinder finder)    {        this.finder = finder;    }</code></pre><p>然后，我使用类似的方法将文件名注入MovieFinder的实现类：</p><pre><code>public interface InjectFilename{    void injectFilename (String filename);}class ColonMovieFinder implements MovieFinder, InjectFilename...    public void injectFilename(String filename)    {        this.filename = filename;    }</code></pre><p>现在，还需要用一些配置代码将所有的组件实现装配起来。简单起见，我直接在代码中完成配置，并将配置好的MovieLister 对象保存在名为lister的字段中：</p><pre><code>class IfaceTester...    private MovieLister lister;    private void configureLister()    {        ColonMovieFinder finder = new ColonMovieFinder();        finder.injectFilename(&quot;movies1.txt&quot;);        lister = new MovieLister();        lister.injectFinder(finder);    }</code></pre><p>测试代码：</p><pre><code>class IfaceTester...public void testIface(){    configureLister();    Movie[] movies = lister.moviesDirectedBy(&quot;Sergio Leone&quot;);    assertEquals(&quot;Once Upon a Time in the West&quot;,movies[0].getTitle());}</code></pre><h2 id="3-2-构造函数注入-vs-设值方法注入"><a href="#3-2-构造函数注入-vs-设值方法注入" class="headerlink" title="3.2 构造函数注入 vs. 设值方法注入"></a>3.2 构造函数注入 vs. 设值方法注入</h2><p>在组合服务时，你总得遵循一定的约定，才可能将所有东西拼装起来。<strong>依赖注入的优点主要在于：它只需要非常简单的约定——至少对于构造函数注入和设值方法注入来说是这样</strong>。相比于这两者，接口注入的侵略性要强得多，比起Service Locator模式的优势也不那么明显。所以，如果你想要提供一个组件给多个使用者，构造函数注入和设值方法注入看起来很有吸引力。你不必在组件中加入什么希奇古怪的东西，注入器可以相当轻松地把所有东西配置起来。</p><p>设值函数注入和构造函数注入之间的选择相当有趣，因为它折射出面向对象编程的一些更普遍的问题：应该在哪里填充对象的字段，构造函数还是设值方法？</p><p>一直以来，我首选的做法是尽量在构造阶段就创建完整、合法的对象——也就是说，在构造函数中填充对象字段。这样做的好处可以追溯到Kent Beck在Smalltalk Best Practice Patterns一书中介绍的两个模式：Constructor Method和Constructor Parameter Method。带有参数的构造函数可以明确地告诉你如何创建一个合法的对象。如果创建合法对象的方式不止一种，你还可以提供多个构造函数，以说明不同的组合方式。</p><p>构造函数初始化的另一个好处是：你可以隐藏任何不可变的字段——只要不为它提供设值方法就行了。我认为这很重要：如果某个字段是不应该被改变的，没有针对该字段的设值方法就很清楚地说明了这一点。如果你通过设值方法完成初始化，暴露出来的设值方法很可能成为你心头永远的痛。（实际上，在这种时候我更愿意回避通常的设值方法约定，而是使用诸如initFoo之类的方法名，以表明该方法只应该在对象创建之初调用。）</p><p>不过，世事总有例外。如果参数太多，构造函数会显得凌乱不堪，特别是对于不支持关键字参数的语言更是如此。的确，如果构造函数参数列表太长，通常标志着对象太过繁忙，理应将其拆分成几个对象，但有些时候也确实需要那么多的参数。如果有不止一种的方式可以构造一个合法的对象，也很难通过构造函数描述这一信息，因为构造函数之间只能通过参数的个数和类型加以区分。这就是Factory Method模式适用的场合了，工厂方法<strong>可以借助多个私有构造函数和设值方法的组合来完成自己的任务</strong>。经典Factory Method模式的问题在于：它们往往以静态方法的形式出现，你无法在接口中声明它们。你可以创建一个工厂类，但那又变成另一个服务实体了。工厂服务是一种不错的技巧，但你仍然需要以某种方式实例化这个工厂对象，问题仍然没有解决。</p><p>如果要传入的参数是像字符串这样的简单类型，构造函数注入也会带来一些麻烦。使用设值方法注入时，你可以在每个设值方法的名字中说明参数的用途；而使用构造函数注入时，你只能靠参数的位置来决定每个参数的作用，而记住参数的正确位置显然要困难得多。</p><p>如果对象有多个构造函数，对象之间又存在继承关系，事情就会变得特别讨厌。为了让所有东西都正确地初始化，你必须将对子类构造函数的调用转发给超类的构造函数，然后处理自己的参数。这可能造成构造函数规模的进一步膨胀。</p><p>尽管有这些缺陷，但我仍然建议你首先考虑构造函数注入。不过，一旦前面提到的问题真的成了问题，你就应该准备转为使用设值方法注入。</p><h2 id="3-3-代码配置-vs-配置文件"><a href="#3-3-代码配置-vs-配置文件" class="headerlink" title="3.3 代码配置 vs 配置文件"></a>3.3 代码配置 vs 配置文件</h2><p>另一个问题相对独立，但也经常与其他问题牵涉在一起：如何配置服务的组装，通过配置文件还是直接编码组装？对于大多数需要在多处部署的应用程序来说，一个单独的配置文件会更合适。配置文件几乎都是XML 文件，XML 也的确很适合这一用途。不过，有些时候直接在程序代码中实现装配会更简单。譬如一个简单的应用程序，也没有很多部署上的变化，这时用几句代码来配置就比XML 文件要清晰得多。</p><p>与之相对的，有时应用程序的组装非常复杂，涉及大量的条件步骤。一旦编程语言中的配置逻辑开始变得复杂，你就应该用一种合适的语言来描述配置信息，使程序逻辑变得更清晰。然后，<strong>你可以编写一个构造器（builder）类来完成装配工作</strong>。如果使用构造器的情景不止一种，你可以提供多个构造器类，然后通过一个简单的配置文件在它们之间选择。</p><p>我常常发现，人们太急于定义配置文件。编程语言通常会提供简捷而强大的配置管理机制，现代编程语言也可以将程序编译成小的模块，并将其插入大型系统中。如果编译过程会很费力，脚本语言也可以在这方面提供帮助。通常认为，配置文件不应该用编程语言来编写，因为它们需要能够被不懂编程的系统管理人员编辑。但是，这种情况出现的几率有多大呢？我们真的希望不懂编程的系统管理人员来改变一个复杂的服务器端应用程序的事务隔离等级吗？只有在非常简单的时候，非编程语言的配置文件才有最好的效果。如果配置信息开始变得复杂，就应该考虑选择一种合适的编程语言来编写配置文件。</p><p>在Java 世界里，我们听到了来自配置文件的不和谐音——每个组件都有它自己的配置文件，而且格式还各不相同。如果你要使用一打这样的组件，你就得维护一打的配置文件，那会很快让你烦死。</p><p>在这里，我的建议是：始终提供一种标准的配置方式，使程序员能够通过同一个编程接口轻松地完成配置工作。至于其他的配置文件，仅仅把它们当作一种可选的功能。借助这个编程接口，开发者可以轻松地管理配置文件。如果你编写了一个组件，则可以由组件的使用者来选择如何管理配置信息：使用你的编程接口、直接操作配置文件格式，或者定义他们自己的配置文件格式，并将其与你的编程接口相结合。</p><h2 id="3-4-分离配置和使用"><a href="#3-4-分离配置和使用" class="headerlink" title="3.4 分离配置和使用"></a>3.4 分离配置和使用</h2><p>所有这一切的关键在于：<strong><em>服务的配置应该与使用分开</em></strong>。实际上，这是一个基本的设计原则——分离接口与实现。在面向对象程序里，我们在一个地方用条件逻辑来决定具体实例化哪一个类，以后的条件分支都由多态来实现，而不是继续重复前面的条件逻辑，这就是分离接口与实现的原则。</p><p>如果对于一段代码而言，接口与实现的分离还只是有用的话，那么当你需要使用外部元素（例如组件和服务）时，它就是生死攸关的大事。这里的第一个问题是：你是否希望将选择具体实现类的决策推迟到部署阶段。如果是，那么你需要使用插入技术。使用了插入技术之后，插件的装配原则上是与应用程序的其余部分分开的，这样你就可以轻松地针对不同的部署替换不同的配置。这种配置机制可以通过服务定位器来实现（Service Locator模式），也可以借助依赖注入直接完成（Dependency Injection 模式）。</p><h1 id="4-结论与思考"><a href="#4-结论与思考" class="headerlink" title="4. 结论与思考"></a>4. 结论与思考</h1><p>在时下流行的轻量级容器都使用了一个共同的模式来组装应用程序所需的服务，我把这个模式称为Dependency Injection，它可以有效地替代Service Locator模式。在开发应用程序时，两者不相上下，但我认为Service Locator模式略有优势，因为它的行为方式更为直观。但是，如果你开发的组件要交给多个应用程序去使用，那么Dependency Injection模式会是更好的选择。</p><p>如果你决定使用Dependency Injection模式，这里还有几种不同的风格可供选择。我建议你首先考虑构造函数注入；如果遇到了某些特定的问题，再改用设值方法注入。如果你要选择一个容器，在其之上进行开发，我建议你选择同时支持这两种注入方式的容器。</p><p>Service Locator 模式和Dependency Injection 模式之间的选择并是最重要的，更重要的是：应该将服务的配置和应用程序内部对服务的使用分离开。</p><p><a href="https://martinfowler.com/articles/injection.html" target="_blank" rel="noopener">1.[Inversion of Control Containers and the Dependency Injection pattern]</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> BackEnd </tag>
            
            <tag> IOC </tag>
            
            <tag> Dependency Injection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>UML - Class Diagram</title>
      <link href="/UML-Class-Diagram/"/>
      <url>/UML-Class-Diagram/</url>
      
        <content type="html"><![CDATA[<p>Alright, some basic knowledge collecting from wiki, uml tutorial websites. Merely regrad this blog as a reference, when you creating/ reading some class disgram, you might wanna look at the blog for better understanding. </p><h1 id="1-Visibility"><a href="#1-Visibility" class="headerlink" title="1. Visibility"></a>1. Visibility</h1><ul><li>+ public </li><li>- private </li><li># protected </li><li>~ package </li></ul><h1 id="2-Relationships"><a href="#2-Relationships" class="headerlink" title="2. Relationships"></a>2. Relationships</h1><p>Types of logical connections found on class and object diagrams. </p><p><img src="https://i.loli.net/2020/02/03/EHNIMsw3hv142yd.png" alt="fig1.png"></p><h2 id="2-1-Dependency"><a href="#2-1-Dependency" class="headerlink" title="2.1 Dependency"></a>2.1 Dependency</h2><p>A sementic connection between dependent and independent model elements. </p><h2 id="2-2-Association"><a href="#2-2-Association" class="headerlink" title="2.2 Association"></a>2.2 Association</h2><p>A binary association </p><h2 id="2-3-Aggregation"><a href="#2-3-Aggregation" class="headerlink" title="2.3 Aggregation"></a>2.3 Aggregation</h2><p>Has a assocation relationship </p><h2 id="2-4-Compostion"><a href="#2-4-Compostion" class="headerlink" title="2.4 Compostion"></a>2.4 Compostion</h2><p>Has a, and without parent, child will not exist </p><h2 id="2-5-Inheritance"><a href="#2-5-Inheritance" class="headerlink" title="2.5 Inheritance"></a>2.5 Inheritance</h2><h2 id="2-6-Realization-Implementation"><a href="#2-6-Realization-Implementation" class="headerlink" title="2.6 Realization/ Implementation"></a>2.6 Realization/ Implementation</h2><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/Class_diagram" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Class_diagram</a></li><li><a href="https://design-patterns.readthedocs.io/zh_CN/latest/read_uml.html" target="_blank" rel="noopener">https://design-patterns.readthedocs.io/zh_CN/latest/read_uml.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> System Design </tag>
            
            <tag> UML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Event Storming</title>
      <link href="/Event-Storming/"/>
      <url>/Event-Storming/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是事件风暴？"><a href="#1-什么是事件风暴？" class="headerlink" title="1. 什么是事件风暴？"></a>1. 什么是事件风暴？</h1><p>通过便签而不是代码来理解你的整个系统，并不断革新你的商业逻辑和需求。</p><p>构建一个能够对事件及时作出反应的系统</p><p>事件风暴是一种组织架构的方法，他是在讨论事件在你的组织里的流动，并将其用一种易于理解的方式模型化。</p><p>实质上想做的事情是通过交流，能够更加迅速的了解到在这个简单事情的背后都发生了什么，了解到数据/信息究竟是如何在多个系统间进行流动的。</p><p>想达到的目标就是通过便签纸在白板上展现出在每个步骤当中想要做的事情，这样能更好的理解商业需求，不需要太过于关注技术细节。</p><h1 id="2-关键的几个概念"><a href="#2-关键的几个概念" class="headerlink" title="2. 关键的几个概念"></a>2. 关键的几个概念</h1><h2 id="2-1-Events-and-Reactions"><a href="#2-1-Events-and-Reactions" class="headerlink" title="2.1 Events and Reactions"></a>2.1 Events and Reactions</h2><p>可以简化为因果关系，或者说是起因及其影响。重要的事件会在系统当中引发一些影响，我们需要理解为什么这些反应会发生，以及其是怎么样发生的。</p><h2 id="2-2-事件流"><a href="#2-2-事件流" class="headerlink" title="2.2 事件流"></a>2.2 事件流</h2><p>单独的事件没有什么太大的影响，我们需要考虑的是事件流，即事件在一段时间内的变化。我们要做的实际上就是使用便签纸，从左到右，按照时间顺序，记录下事件的发生。当我们有了这样的一个线性的事件流以后，下一步是去思考事件是因何而发生的。</p><h2 id="2-3-Reactions"><a href="#2-3-Reactions" class="headerlink" title="2.3 Reactions"></a>2.3 Reactions</h2><p>反馈是在其他事件发生以后发生的事件。 – this happens whenever that happens. </p><h2 id="2-4-Policy"><a href="#2-4-Policy" class="headerlink" title="2.4 Policy"></a>2.4 Policy</h2><p>Policy是指事件和其反馈的整体流动。我们称其为policy 是因为这个流动捕捉到了核心的商业逻辑和规则。</p><h2 id="2-5-Commands"><a href="#2-5-Commands" class="headerlink" title="2.5 Commands"></a>2.5 Commands</h2><p>来代表用户的某些行为，这些行为可以触发某些事件的发生，或者说这些行为本身很有可能就是某些事件，而这些事件会触发某些reaction，然后再度触发事件，一以贯之。</p><h1 id="3-背后逻辑"><a href="#3-背后逻辑" class="headerlink" title="3. 背后逻辑"></a>3. 背后逻辑</h1><p>个人感觉这不仅仅是应用在技术架构和模型上，任何商业上的事务，想要明晰商业逻辑，都可以用这一套逻辑链条来进行分析。核心就是用户行为，事件，平台/app 对事件作出的反应，三者形成一个可以循环往复的圈，不停带来新的行为和新的反馈。这是行为环，还有利益环，即每个角色在这整个过程当中交换了什么，获得了什么。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://ziobrando.blogspot.com/2013/11/introducing-event-storming.html" target="_blank" rel="noopener">https://ziobrando.blogspot.com/2013/11/introducing-event-storming.html</a></li><li><a href="https://blog.redelastic.com/corporate-arts-crafts-modelling-reactive-systems-with-event-storming-73c6236f5dd7" target="_blank" rel="noopener">https://blog.redelastic.com/corporate-arts-crafts-modelling-reactive-systems-with-event-storming-73c6236f5dd7</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DDD-领域驱动设计</title>
      <link href="/DDD-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"/>
      <url>/DDD-%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><h2 id="1-1-什么是领域驱动设计"><a href="#1-1-什么是领域驱动设计" class="headerlink" title="1.1 什么是领域驱动设计"></a>1.1 什么是领域驱动设计</h2><p>、】=op90q`</p><blockquote><p>DDD是面向对象的一套方言，提供了一种基于业务领域的对象划分和分类方法，其最大的价值就在于对于软件开发过程全生命周期使用语言的统一。</p></blockquote><h2 id="1-2-常用名词"><a href="#1-2-常用名词" class="headerlink" title="1.2 常用名词"></a>1.2 常用名词</h2><ul><li>Controller </li><li>Service </li><li>Repository </li><li>Entity </li></ul><h2 id="1-3-为什么使用DDD"><a href="#1-3-为什么使用DDD" class="headerlink" title="1.3 为什么使用DDD?"></a>1.3 为什么使用DDD?</h2><p>我们在使用面向对象语言来解决实际问题的时候，知道所有东西都是对象，但我们并没有明确的关于对象应当如何组织和划分的规范。</p><p>作为技术人员，我们习惯于从技术角度来出发进行思考，出现了用<strong>技术语言</strong>定义对象的习惯，例如DAO(Data Access Objects), DTO(Data Transfer Object)这类对象及其体现出来的划分方式。</p><p>但是我们日常工作当中很多时间需要做大量的业务语言和技术语言的相互翻译。DDD - Domain Driven Design 就是想解决这样的相互翻译的问题，希望能通过一套面向对象的分类方法，从领域触发，实现软件开发过程当中各个角色和环境的统一语言(Ubiquitous Language).例如使用Repository（仓库）替代数据访问对象（DAO），就更能让业务和技术同时理解这个对象的作用了。</p><p>DDD分为战术和战略两部分，恰好可以用在微服务的划分当中。我们需要利用DDD的战略部分，划分问题域，来合理对微服务进行划分。</p><h1 id="2-事件风暴-EventStorming"><a href="#2-事件风暴-EventStorming" class="headerlink" title="2. 事件风暴 EventStorming"></a>2. 事件风暴 EventStorming</h1><blockquote><p>是一套独立的通过协作基于事件还原系统全貌，从而快速分析复杂业务领域，完成领域建模的方法。</p></blockquote><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://insights.thoughtworks.cn/ddd-eventstorming-zhongtai/#utm_source=rss&amp;utm_medium=rss" target="_blank" rel="noopener">https://insights.thoughtworks.cn/ddd-eventstorming-zhongtai/#utm_source=rss&amp;utm_medium=rss</a></li><li><a href="https://www.eventstorming.com/#services" target="_blank" rel="noopener">https://www.eventstorming.com/#services</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> SystemDesign </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(十一)-用双十一理顺起来的网络协议</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%8D%81%E4%B8%80-%E7%94%A8%E5%8F%8C%E5%8D%81%E4%B8%80%E7%90%86%E9%A1%BA%E8%B5%B7%E6%9D%A5%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%8D%81%E4%B8%80-%E7%94%A8%E5%8F%8C%E5%8D%81%E4%B8%80%E7%90%86%E9%A1%BA%E8%B5%B7%E6%9D%A5%E7%9A%84%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<p>本文会尽可能详细描述双十一的技术栈，希望对大家能有所裨益。</p><p>整个过程会分为十个阶段，接下来也会分别从这十个方面进行讲述： </p><ul><li>部署高可用高并发的电商平台</li><li>广播全网</li><li>域名解析</li></ul><h1 id="1-部署高可用高并发的电商平台"><a href="#1-部署高可用高并发的电商平台" class="headerlink" title="1. 部署高可用高并发的电商平台"></a>1. 部署高可用高并发的电商平台</h1><p><img src="https://i.loli.net/2020/02/02/6AuPT1RQZilKpcB.jpg" alt="fig1.jpg"></p><ul><li>主站点</li><li>多机房，多Available zone </li><li>数据中心，一个AZ<ul><li>汇聚交换机 <ul><li>机柜<ul><li>接入交换机 </li><li>服务器</li></ul></li></ul></li></ul></li></ul><p>这些服务器上部署的都是计算节点，每台上面都有Open vSwitch创建的虚拟交换机，将来在这台机器上创建的虚拟机，都会连到Open vSwitch上。</p><p><img src="https://i.loli.net/2020/02/02/JCiMoL1DwbGcqQB.jpg" alt="fig2.jpg"></p><ul><li>创建VPC</li><li>指定IP段<ul><li>这样以后部署的所有应用都会在这个虚拟网络当中，使用你分配的这个IP段</li><li>即使同一台物理机，不同的VPC也不会相通</li><li>多个可用区，为每个可用区分配Subnet<ul><li>在两个可用区里面网段不同的时候，就可以配置路由策略，访问另一个可用区</li></ul></li></ul></li><li>创建数据库持久化层<ul><li>云平台给每个Subnet的数据库实例分配一个域名，在创建的时候，需要指定可用区和Subnet，这样创建出来的数据库实例可以通过这个Subnet的私网IP进行访问。 </li><li>各个可用区都要有数据库，主从数据库，云平台会提供数据库同步工具，将应用写入的主数据同步给备数据库集群</li></ul></li><li>创建缓存集群<ul><li>每个可用区，Subnet有一套</li><li>缓存的数据写在内存中</li><li>因为较高的读写性能要求，一般不需要跨可用区读写</li></ul></li><li>写的程序们…<ul><li>相互关系<ul><li>之间通过RPC相互调用</li><li>需要到注册中心去进行注册</li><li>网络通信是虚拟机和虚拟机之间的</li><li>不同的可用区之间，通过核心交换机连在一起，核心交换机之外是边界路由器。</li></ul></li><li>基础服务层</li><li>组合服务层</li><li>Controller层</li><li>Nginx层<ul><li>负载均衡也是云平台提供的 PaaS 服务，也是属于某个 VPC 的，部署在虚拟机里面的，但是负载均衡有个外网的 IP，这个外网的 IP 地址就是在网关节点的外网网口上的。在网关节点上，会有 NAT 规则，将外网 IP 地址转换为 VPC 里面的私网 IP 地址，通过这些私网 IP 地址访问到虚拟机上的负载均衡节点，然后通过负载均衡节点转发到 API 网关的节点。 </li></ul></li><li>API网关<ul><li>网关节点的外网网口是带公网IP地址的，里面有一个虚拟网关转发模块，还会有一个OVS，将私网IP地址放到VXLAN隧道里面，转发到虚拟机上，从而实现外网和虚拟机网络之间的互通。</li></ul></li><li>智能DNS<ul><li>对于不同地区和不同运营商的用户，保证访问速度</li></ul></li><li>CDN与边缘节点<ul><li>存储静态资源到对象存储里</li><li>通过CDN下发到边缘节点</li></ul></li></ul></li></ul><h1 id="2-广播给全网"><a href="#2-广播给全网" class="headerlink" title="2. 广播给全网"></a>2. 广播给全网</h1><p><img src="https://i.loli.net/2020/02/02/padlBADogKVHhGI.jpg" alt="fig3.jpg"></p><p>外网IP是放在虚拟网关的外网网口上的，通过BGP路由协议让全世界知道。</p><p>BGP路由协议 Border Gateway Protocol， 去中心化自治路由协议，通过维护IP路由表来实现自治系统之间的可达性，属于矢量路由协议</p><p>每个可用区都有自己的汇聚交换机，每个Region也有自己的核心交换区域。</p><p>在核心交换外面是安全设备，然后是边界路由器。边界路由器会和多个运营商连接，从而每个运营商都能够访问到这个网站。边界路由器可以通过BGP协议，将自己的数据中心里面的外网IP向外广播。</p><h1 id="3-域名解析地址"><a href="#3-域名解析地址" class="headerlink" title="3. 域名解析地址"></a>3. 域名解析地址</h1><p><img src="https://i.loli.net/2020/02/02/HoziVPFMukRL9wa.jpg" alt="fig4.jpg"></p><p>客户的手机开机以后，在附近寻找基站 eNodeB，发送请求，申请上网。基站将请求发给 MME，MME 对手机进行认证和鉴权，还会请求 HSS 看有没有钱，看看是在哪里上网。</p><p>当 MME 通过了手机的认证之后，开始建立隧道，建设的数据通路分两段路，其实是两个隧道。一段是从 eNodeB 到 SGW，第二段是从 SGW 到 PGW，在 PGW 之外，就是互联网。</p><p>PGW 会为手机分配一个 IP 地址，手机上网都是带着这个 IP 地址的。当在手机上面打开一个 App 的时候，首先要做的事情就是解析这个网站的域名。</p><p>在手机运营商所在的互联网区域里，有一个本地的 DNS，手机会向这个 DNS 请求解析 DNS。当这个 DNS 本地有缓存，则直接返回；如果没有缓存，本地 DNS 才需要递归地从根 DNS 服务器，查到.com 的顶级域名服务器，最终查到权威 DNS 服务器。</p><p>如果配置了DNS和全局负载均衡，在权威DNS服务中，我们可以通过配置CNAME的方式，起一个别名，然后告诉本地 DNS 服务器，让它请求 GSLB 解析这个域名，GSLB 就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。</p><p>GSLB 通过查看请求它的本地 DNS 服务器所在的运营商和地址，就知道用户所在的运营商和地址，然后将距离用户位置比较近的 Region 里面，三个负载均衡 SLB 的公网 IP 地址，返回给本地 DNS 服务器。本地 DNS 解析器将结果缓存后，返回给客户端。</p><p>对于手机 App 来说，可以绕过刚才的传统 DNS 解析机制，直接只要 HTTPDNS 服务，通过直接调用 HTTPDNS 服务器，得到这三个 SLB 的公网 IP 地址。</p><h1 id="4-购物前浏览的过程-静态资源CDN"><a href="#4-购物前浏览的过程-静态资源CDN" class="headerlink" title="4. 购物前浏览的过程 - 静态资源CDN"></a>4. 购物前浏览的过程 - 静态资源CDN</h1><p><img src="https://i.loli.net/2020/02/02/HmRsg9l7X1yzF4q.jpg" alt="fig5.jpg"></p><p>DNS -&gt; CDN -&gt; Cloud </p><p>我们部署电商应用的时候，一般会将静态资源保存在两个地方： </p><ul><li>接入层nginx后面的varnish缓存里</li><li>对于比较大，不常更新的静态图片，会保存在对象存储里面</li></ul><p>这两个地方的静态资源都会配置CDN，将资源下发到边缘节点。</p><p>配置了CDN之后，权威DNS服务器上，会为<strong>静态资源设置一个CNAME别名</strong>，指向另外一个域名，cdn.com，返回给本地的DNS服务器。当本地 DNS 服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的时候就不是原来的权威 DNS 服务器了，而是cdn.com的权威DNS服务器，这是CDN自己的。</p><p>在这个服务器上，还是会设置一个 CNAME，指向另外一个域名，也即 CDN 网络的全局负载均衡器。</p><p>本地 DNS 服务器去请求 CDN 的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，将 IP 返回给客户端，客户端去访问这个边缘节点，下载资源。缓存服务器响应用户请求，将用户所需内容传送到用户终端。</p><p><strong><em>如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器，将内容拉到本地</em></strong></p><h1 id="5-下单过程，双方建立连接"><a href="#5-下单过程，双方建立连接" class="headerlink" title="5. 下单过程，双方建立连接"></a>5. 下单过程，双方建立连接</h1><p>对于下单，网站会提供RESTful的下单接口，这种操作有很强的私密性，因此需要通过HTTPS协议进行请求。</p><p><img src="https://i.loli.net/2020/02/02/ENjJD3su5RIHdAk.jpg" alt="fig6.jpg"></p><p>建立TCP连接的行为是在手机的APP和负载均衡器SLB之间发生的。</p><p>对于TCP连接来讲，需要通过三次握手建立连接，为了维护这个连接，双方都需要在TCP层维护一个连接的状态机。</p><p>一开始，客户端和服务端都处于 CLOSED 状态。服务端先是主动监听某个端口，处于 LISTEN 状态。然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。</p><p>客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态。这是因为，它一发一收成功了。服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它的一发一收也成功了。</p><p>TCP层连接建立完毕之后，接下来是在HTTPS层建立连接，在HTTPS的交换过程中，TCP层始终处于ESTABLISHED状态。</p><p>对于 HTTPS，客户端会发送 Client Hello 消息到服务器，用明文传输 TLS 版本信息、加密套件候选列表、压缩算法候选列表等信息。另外，还会有一个随机数，在协商对称密钥的时候使用。</p><p>然后，服务器会返回 Server Hello 消息，告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等。这也有一个随机数，用于后续的密钥协商。</p><p>然后，服务器会给你一个服务器端的证书，然后说：“Server Hello Done，我这里就这些信息了。”</p><p>客户端当然不相信这个证书，于是从自己信任的 CA 仓库中，拿 CA 的证书里面的公钥去解密电商网站的证书。如果能够成功，则说明电商网站是可信的。这个过程中，你可能会不断往上追溯 CA、CA 的 CA、CA 的 CA 的 CA，反正直到一个授信的 CA，就可以了。</p><p>证书验证完毕之后，觉得这个服务端是可信的，于是客户端计算产生随机数字 Pre-master，发送 Client Key Exchange，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。</p><p>接下来，无论是客户端还是服务器，都有了三个随机数，分别是：自己的、对端的，以及刚生成的 Pre-Master 随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。</p><p>有了对称密钥，客户端就可以说：“Change Cipher Spec，咱们以后都采用协商的通信密钥和加密算法进行加密通信了。”</p><p>然后客户端发送一个 Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。</p><p>同样，服务器也可以发送 Change Cipher Spec，说：“没问题，咱们以后都采用协商的通信密钥和加密算法进行加密通信了”，并且也发送 Encrypted Handshake Message 的消息试试。</p><p>当双方握手结束之后，就可以通过对称密钥进行加密传输了。</p><h1 id="6-发送下单请求的网络包"><a href="#6-发送下单请求的网络包" class="headerlink" title="6. 发送下单请求的网络包"></a>6. 发送下单请求的网络包</h1><p>客户端和服务端之间建立连接之后，接下来就是发送下单请求的网络包了。</p><p>在用户层发送的是 HTTP 的网络包，因为服务端提供的是 RESTful API，因而 HTTP 层发送的就是一个请求。</p><pre><code>POST /purchaseOrder HTTP/1.1Host: www.llchen60.comContent-Type: application/json; charset=utf-8Content-Length: nnn{ &quot;order&quot;: {  &quot;date&quot;: &quot;2018-07-01&quot;,  &quot;className&quot;: &quot; 趣谈网络协议 &quot;,  &quot;Author&quot;: &quot; leilei &quot; }}</code></pre><p>HTTP报文分为三个部分</p><ul><li>请求行<ul><li><a href="http://www.llchen60.com/purchaseOrder">www.llchen60.com/purchaseOrder</a></li></ul></li><li>请求首部<ul><li>key value的形式， 通过冒号分隔 </li></ul></li><li>请求的正文实体</li></ul><p>HTTP请求的报文格式搞好了以后，浏览器会将其交给传输层，交给的方式是用socket进行程序设计。</p><p>HTTP协议是基于TCP协议的，所以使用面向连接的方式发送请求，通过Stream二进制流的方式传给对方。到了TCP层，它会把二进制流变成一个报文段发送给服务器。</p><p>在 TCP 头里面，会有源端口号和目标端口号，<strong>目标端口号一般是服务端监听的端口号</strong>，源端口号在手机端，往往是随机分配一个端口号。这个端口号在客户端和服务端用于区分请求和返回，发给那个应用。</p><p>在 IP 头里面，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址）。当一个手机上线的时候，PGW 会给这个手机分配一个 IP 地址，这就是源地址，而目标地址则是云平台的负载均衡器的外网 IP 地址。</p><p>在 IP 层，客户端需要查看目标地址和自己是否是在同一个局域网，计算是否是同一个网段，往往需要通过 CIDR 子网掩码来计算。</p><p>对于这个下单场景，目标 IP 和源 IP 不会在同一个网段，因而需要发送到默认的网关。一般通过 DHCP 分配 IP 地址的时候，同时配置默认网关的 IP 地址。</p><p>但是客户端不会直接使用默认网关的 IP 地址，而是发送 ARP 协议，来获取网关的 MAC 地址，然后将网关 MAC 作为目标 MAC，自己的 MAC 作为源 MAC，放入 MAC 头，发送出去。</p><p>完整的网络包如下所示： </p><p><img src="https://i.loli.net/2020/02/02/MfVQxW1XCzjuLN7.jpg" alt="fig7.jpg"></p><h1 id="7-流控拥塞与重传"><a href="#7-流控拥塞与重传" class="headerlink" title="7. 流控拥塞与重传"></a>7. 流控拥塞与重传</h1><p>对于手机来讲，默认的网关在 PGW 上。在移动网络里面，从手机到 SGW，到 PGW 是有一条隧道的。在这条隧道里面，会将上面的这个包作为隧道的乘客协议放在里面，外面 SGW 和 PGW 在核心网机房的 IP 地址。网络包直到 PGW（PGW 是隧道的另一端）才将里面的包解出来，转发到外部网络。</p><p>从手机发送出来的网络包的结构如下：</p><ul><li>源MAC地址</li><li>目标MAC地址： 网关PGW上面的隧道端点的MAC</li><li>源IP： UE的IP地址</li><li>目标IP： SLB的公网IP地址</li></ul><p>进入隧道之后，要封装外层的网络地址，因而网络包的格式为：</p><ul><li>外层源MAC： E-NodeB的MAC</li><li>外层目标MAC： SGW的MAC</li><li>外层源IP： E-NodeB的IP</li><li>外层目标IP： SGW的IP</li><li>内层源 MAC：手机也即 UE 的 MAC</li><li>内层目标 MAC：网关 PGW 上面的隧道端点的 MAC</li><li>内层源 IP：UE 的 IP 地址</li><li>内层目标 IP：SLB 的公网 IP 地址</li></ul><p>当隧道在 SGW 的时候，切换了一个隧道，会从 SGW 到 PGW 的隧道，因而网络包的格式为：</p><ul><li>外层源 MAC：SGW 的 MAC</li><li>外层目标 MAC：PGW 的 MAC</li><li>外层源 IP：SGW 的 IP</li><li>外层目标 IP：PGW 的 IP</li><li>内层源 MAC：手机也即 UE 的 MAC</li><li>内层目标 MAC：网关 PGW 上面的隧道端点的 MAC</li><li>内层源 IP：UE 的 IP 地址</li><li>内层目标 IP：SLB 的公网 IP 地址</li></ul><p>在 PGW 的隧道端点将包解出来，转发出去的时候，一般在 PGW 出外部网络的路由器上，会部署 NAT 服务，将手机的 IP 地址转换为公网 IP 地址，当请求返回的时候，再 NAT 回来。因而在PGW之后，网络包格式为： </p><ul><li>源 MAC：PGW 出口的 MAC；</li><li>目标 MAC：NAT 网关的 MAC；</li><li>源 IP：UE 的 IP 地址；</li><li>目标 IP：SLB 的公网 IP 地址。</li></ul><p>在NAT网关，网络包的格式变成： </p><ul><li>源 MAC：NAT 网关的 MAC</li><li>目标 MAC：A2 路由器的 MAC</li><li>源 IP：UE 的公网 IP 地址</li><li>目标 IP：SLB 的公网 IP 地址</li></ul><p><img src="https://i.loli.net/2020/02/02/GMPYBduQXoiTgcW.jpg" alt="fig8.jpg"></p><p>出了 NAT 网关，就从核心网到达了互联网。在网络世界，每一个运营商的网络成为自治系统 AS。每个自治系统都有边界路由器，通过它和外面的世界建立联系。</p><p>如何从出口的运营商到达云平台的边界路由器？在路由器之间需要通过 BGP 协议实现，BGP 又分为两类，eBGP 和 iBGP。自治系统之间、边界路由器之间使用 eBGP 广播路由。内部网络也需要访问其他的自治系统。</p><p>边界路由器如何将 BGP 学习到的路由导入到内部网络呢？通过运行 iBGP，使内部的路由器能够找到到达外网目的地最好的边界路由器。</p><p>网站的 SLB 的公网 IP 地址早已经通过云平台的边界路由器，让全网都知道了。于是这个下单的网络包选择的下一跳是 A2，也即将 A2 的 MAC 地址放在目标 MAC 地址中。</p><p>到达 A2 之后，从路由表中找到下一跳是路由器 C1，于是将目标 MAC 换成 C1 的 MAC 地址。到达 C1 之后，找到下一跳是 C2，将目标 MAC 地址设置为 C2 的 MAC。到达 C2 后，找到下一跳是云平台的边界路由器，于是将目标 MAC 设置为边界路由器的 MAC 地址。</p><p>你会发现，这一路，都是只换 MAC，不换目标 IP 地址。这就是所谓下一跳的概念。在云平台的边界路由器，会将下单的包转发进来，经过核心交换，汇聚交换，到达外网网关节点上的 SLB 的公网 IP 地址。</p><p>我们可以看到，手机到 SLB 的公网 IP，是一个端到端的连接，连接的过程发送了很多包。所有这些包，无论是 TCP 三次握手，还是 HTTPS 的密钥交换，都是要走如此复杂的过程到达 SLB 的，当然每个包走的路径不一定一致。</p><p>网络包走在这个复杂的道路上，很可能一不小心就丢了，怎么办？这就需要借助 TCP 的机制重新发送。</p><p>既然 TCP 要对包进行重传，就需要维护 Sequence Number，看哪些包到了，哪些没到，哪些需要重传，传输的速度应该控制到多少，这就是TCP的滑动窗口协议。</p><p><img src="https://i.loli.net/2020/02/02/uKBpG8RZn5lHeEU.jpg" alt="fig9.jpg"></p><p>整个 TCP 的发送，一开始会协商一个 Sequence Number，从这个 Sequence Number 开始，每个包都有编号。滑动窗口将接收方的网络包分成四个部分：</p><ul><li>已经接收，已经 ACK，已经交给应用层的包</li><li>已经接收，已经 ACK，未发送给应用层</li><li>已经接收，尚未发送 ACK</li><li>未接收，尚有空闲的缓存区域</li></ul><p>对于 TCP 层来讲，每一个包都有 ACK。ACK 需要从 SLB 回复到手机端，将上面的那个过程反向来一遍，当然路径不一定一致，可见 ACK 也不是那么轻松的事情。</p><p>如果发送方超过一定的时间没有收到 ACK，就会重新发送。只有 TCP 层 ACK 过的包，才会发给应用层，并且只会发送一份，对于下单的场景，应用层是 HTTP 层。</p><p>你可能会问了，TCP 老是重复发送，会不会导致一个单下了两遍？是否要求服务端实现幂等？从 TCP 的机制来看，是不会的。只有收不到 ACK 的包才会重复发，发到接收端，在窗口里面只保存一份，所以在同一个 TCP 连接中，不用担心重传导致二次下单。</p><p>但是 TCP 连接会因为某种原因断了，例如手机信号不好，这个时候手机把所有的动作重新做一遍，建立一个新的 TCP 连接，在 HTTP 层调用两次 RESTful API。这个时候可能会导致两遍下单的情况，因而 RESTful API 需要实现幂等。</p><p>当 ACK 过的包发给应用层之后，TCP 层的缓存就空了出来，这会导致上面图中的大三角，也即接收方能够容纳的总缓存，整体顺时针滑动。小的三角形，也即接收方告知发送方的窗口总大小，也即还没有完全确认收到的缓存大小，如果把这些填满了，就不能再发了，因为没确认收到，所以一个都不能扔。</p><h1 id="8-从数据中心进网关，公网NAT成私网"><a href="#8-从数据中心进网关，公网NAT成私网" class="headerlink" title="8. 从数据中心进网关，公网NAT成私网"></a>8. 从数据中心进网关，公网NAT成私网</h1><p>包从手机端到了SLB公网IP所在的公网网口，由于匹配上了MAC地址和IP地址，因而将网络包收了起来。</p><p><img src="https://i.loli.net/2020/02/02/I4NUqCcgnXFZ5TQ.jpg" alt="fig10.jpg"></p><p>在虚拟网关节点的外网网口上，会有一个 NAT 规则，将公网 IP 地址转换为 VPC 里面的私网 IP 地址，这个私网 IP 地址就是 SLB 的 HAProxy 所在的虚拟机的私网 IP 地址。</p><p>当然为了承载比较大的吞吐量，虚拟网关节点会有多个，物理网络会将流量分发到不同的虚拟网关节点。同样 HAProxy 也会是一个大的集群，虚拟网关会选择某个负载均衡节点，将某个请求分发给它，负载均衡之后是 Controller 层，也是部署在虚拟机里面的。</p><p>当网络包里面的目标 IP 变成私有 IP 地址之后，虚拟路由会查找路由规则，将网络包从下方的私网网口发出来。这个时候包的格式为：</p><ul><li>源 MAC：网关 MAC；</li><li>目标 MAC：HAProxy 虚拟机的 MAC；</li><li>源 IP：UE 的公网 IP；</li><li>目标 IP：HAProxy 虚拟机的私网 IP。</li></ul><h1 id="9-进入隧道，RPC远程调用下单"><a href="#9-进入隧道，RPC远程调用下单" class="headerlink" title="9. 进入隧道，RPC远程调用下单"></a>9. 进入隧道，RPC远程调用下单</h1><p>在虚拟路由节点上，也会有 OVS，将网络包封装在 VXLAN 隧道里面，VXLAN ID 就是给你的租户创建 VPC 的时候分配的。包的格式为：</p><ul><li>外层源 MAC：网关物理机 MAC；</li><li>外层目标 MAC：物理机 A 的 MAC；</li><li>外层源 IP：网关物理机 IP；</li><li>外层目标 IP：物理机 A 的 IP；</li><li>内层源 MAC：网关 MAC；</li><li>内层目标 MAC：HAProxy 虚拟机的 MAC；</li><li>内层源 IP：UE 的公网 IP；</li><li>内层目标 IP：HAProxy 虚拟机的私网 IP。</li></ul><p>在物理机 A 上，OVS 会将包从 VXLAN 隧道里面解出来，发给 HAProxy 所在的虚拟机。HAProxy 所在的虚拟机发现 MAC 地址匹配，目标 IP 地址匹配，就根据 TCP 端口，将包发给 HAProxy 进程，因为 HAProxy 是在监听这个 TCP 端口的。因而 HAProxy 就是这个 TCP 连接的服务端，客户端是手机。对于 TCP 的连接状态、滑动窗口等，都是在 HAProxy 上维护的。</p><p>在这里 HAProxy 是一个四层负载均衡，也即它只解析到 TCP 层，里面的 HTTP 协议它不关心，就将请求转发给后端的多个 Controller 层的一个。</p><p>HAProxy 发出去的网络包就认为 HAProxy 是客户端了，看不到手机端了。网络包格式如下：</p><ul><li>源 MAC：HAProxy 所在虚拟机的 MAC；</li><li>目标 MAC：Controller 层所在虚拟机的 MAC；</li><li>源 IP：HAProxy 所在虚拟机的私网 IP；</li><li>目标 IP：Controller 层所在虚拟机的私网 IP。</li></ul><p>这个包发出去之后，会被物理机上的OVS放入VXLAN隧道里面，网络包格式为;</p><ul><li>外层源 MAC：物理机 A 的 MAC；</li><li>外层目标 MAC：物理机 B 的 MAC；</li><li>外层源 IP：物理机 A 的 IP；</li><li>外层目标 IP：物理机 B 的 IP；</li><li>内层源 MAC：HAProxy 所在虚拟机的 MAC；</li><li>内层目标 MAC：Controller 层所在虚拟机的 MAC；</li><li>内层源 IP：HAProxy 所在虚拟机的私网 IP；</li><li>内层目标 IP：Controller 层所在虚拟机的私网 IP。</li></ul><p>在物理机 B 上，OVS 会将包从 VXLAN 隧道里面解出来，发给 Controller 层所在的虚拟机。Controller 层所在的虚拟机发现 MAC 地址匹配，目标 IP 地址匹配，就根据 TCP 端口，将包发给 Controller 层的进程，因为它在监听这个 TCP 端口。</p><p>在 HAProxy 和 Controller 层之间，维护一个 TCP 的连接。</p><p>Controller 层收到包之后，它是关心 HTTP 里面是什么的，于是解开 HTTP 的包，发现是一个 POST 请求，内容是下单购买一个课程。</p><h1 id="10-下单扣减库存，数据入库返回成功"><a href="#10-下单扣减库存，数据入库返回成功" class="headerlink" title="10. 下单扣减库存，数据入库返回成功"></a>10. 下单扣减库存，数据入库返回成功</h1><p>一般在组合服务层会有专门管理下单的服务，Controller层会通过RPC调用这个组合服务层。</p><p>假设我们使用的是 Dubbo，则 Controller 层需要读取注册中心，将下单服务的进程列表拿出来，选出一个来调用。Dubbo 中默认的 RPC 协议是 Hessian2。Hessian2 将下单的远程调用序列化为二进制进行传输。</p><p>Netty 是一个非阻塞的基于事件的网络传输框架。Controller 层和下单服务之间，使用了 Netty 的网络传输框架。有了 Netty，就不用自己编写复杂的异步 Socket 程序了。Netty 使用的方式，就是IO多路复用。</p><p>Netty 还是工作在 Socket 这一层的，发送的网络包还是基于 TCP 的。在 TCP 的下层，还是需要封装上 IP 头和 MAC 头。如果跨物理机通信，还是需要封装的外层的 VXLAN 隧道里面。当然底层的这些封装，Netty 都不感知，它只要做好它的异步通信即可。</p><p>在 Netty 的服务端，也即下单服务中，收到请求后，先用 Hessian2 的格式进行解压缩。然后将请求分发到线程中进行处理，在线程中，会调用下单的业务逻辑。</p><p>下单的业务逻辑比较复杂，往往要调用基础服务层里面的库存服务、优惠券服务等，将多个服务调用完毕，才算下单成功。下单服务调用库存服务和优惠券服务，也是通过 Dubbo 的框架，通过注册中心拿到库存服务和优惠券服务的列表，然后选一个调用。</p><p>调用的时候，统一使用 Hessian2 进行序列化，使用 Netty 进行传输，底层如果跨物理机，仍然需要通过 VXLAN 的封装和解封装。</p><p>咱们以库存为例子的时候，讲述过幂等的接口实现的问题。因为如果扣减库存，仅仅是谁调用谁减一。这样存在的问题是，如果扣减库存因为一次调用失败，而多次调用，这里指的不是 TCP 多次重试，而是应用层调用的多次重试，就会存在库存扣减多次的情况。</p><p>这里常用的方法是，使用乐观锁（Compare and Set，简称 CAS）。CAS 要考虑三个方面，当前的库存数、预期原来的库存数和版本，以及新的库存数。在操作之前，查询出原来的库存数和版本，真正扣减库存的时候，判断如果当前库存的值与预期原值和版本相匹配，则将库存值更新为新值，否则不做任何操作。</p><p>这是一种基于状态而非基于动作的设计，符合 RESTful 的架构设计原则。这样的设计有利于高并发场景。当多个线程尝试使用 CAS 同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。</p><p>最终，当下单更新到分布式数据库当中之后，整个下单过程结束。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> Distributed System </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(十) - RPC, SOAP, RESTful</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%8D%81-RPC-SOAP-RESTful/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%8D%81-RPC-SOAP-RESTful/</url>
      
        <content type="html"><![CDATA[<h1 id="1-RPC协议综述"><a href="#1-RPC协议综述" class="headerlink" title="1. RPC协议综述"></a>1. RPC协议综述</h1><p><img src="https://i.loli.net/2020/02/02/jrVzNFexLaUElXY.jpg" alt="fig1.jpg"></p><p>我们需要研究的是在网络打通以后，服务之间是如何互相调用的呢？</p><p>实质上是调用方和被调用方之间建立一个TCP或者UDP连接，来进行通信的。</p><p><img src="https://i.loli.net/2020/02/02/sWc8My2XSKHukzv.jpg" alt="fig2.jpg"></p><p>但是实际过程会非常复杂，假设一个场景，即客户端调用一个加法函数，将两个整数相加返回他们的和。放在远程调用上，因为要牵扯到网络，就要牵扯到Socket编程.</p><h2 id="1-1-实现远程调用的问题"><a href="#1-1-实现远程调用的问题" class="headerlink" title="1.1 实现远程调用的问题"></a>1.1 实现远程调用的问题</h2><ol><li>如何规定远程调用的语法？ </li></ol><p>如何表示加减，如何表示整数间的和小数间的？ </p><ol start="2"><li>如何传递参数？ </li></ol><p>参数和操作符的传递顺序；TCP流如何区分各个参数</p><ol start="3"><li>如何表示数据？</li></ol><p>对于长度不一定的类，结构体，怎么给空间来传递？<br>Big Endian 和Little Endian，采用的方式不一样的问题。</p><ol start="4"><li>如何知道一个服务端都实现了哪些远程调用？从哪个端口可以访问到？</li></ol><p>假设服务端实现了多个远程调用，每个可能实现在不同的进程当中，监听的端口也不一样，而且由于服务端都是自己实现的，不可能使用一个大家都公认的端口，而且有可能多个进程部署在同一台机器上，大家就需要抢占端口，为了防止冲突，往往使用随机端口，那客户端如何找到这些监听的端口呢？</p><ol start="5"><li>发生了错误、重传、丢包、性能等问题怎么办？ </li></ol><p>本地调用没有这个问题，但是一旦到网络上，这些问题都需要处理，因为网络是不可靠的，虽然在同一个连接中，我们还可通过 TCP 协议保证丢包、重传的问题，但是如果服务器崩溃了又重启，当前连接断开了，TCP 就保证不了了，需要应用自己进行重新调用，重新传输会不会同样的操作做两遍，远程调用性能会不会受影响呢？</p><h2 id="1-2-协议约定问题"><a href="#1-2-协议约定问题" class="headerlink" title="1.2 协议约定问题"></a>1.2 协议约定问题</h2><p>上述的各种问题是需要服务端和客户端协商来解决的，Jay Nelson写了一篇论文，<a href="http://www.cs.cmu.edu/~dga/15-712/F07/papers/birrell842.pdf" target="_blank" rel="noopener">Implementing Remote Procedure Calls</a> 定义了RPC的标准。</p><p><img src="https://i.loli.net/2020/02/02/KJDQzCel3fSuvTy.jpg" alt="fig3.jpg"></p><h3 id="1-2-1-客户端发起远程调用"><a href="#1-2-1-客户端发起远程调用" class="headerlink" title="1.2.1 客户端发起远程调用"></a>1.2.1 客户端发起远程调用</h3><p>通过本地调用本地调用方的Stub，负责将调用的接口、方法和参数，通过约定的协议规范进行编码，并通过本地的RPCRuntime进行传输，将调用网络包发送到服务器上。</p><h3 id="1-2-2-服务器端处理请求"><a href="#1-2-2-服务器端处理请求" class="headerlink" title="1.2.2 服务器端处理请求"></a>1.2.2 服务器端处理请求</h3><p>服务器端的RPCRuntime收到请求以后，交给提供方Stub进行解码，然后调用服务端的方法，服务端执行方法，返回结果，提供方Stub将返回结果编码后，发送给客户端，客户端的RPCRuntime收到结果，发给调用方Stub解码得到结果，返回给客户端。</p><h3 id="1-2-3-分析"><a href="#1-2-3-分析" class="headerlink" title="1.2.3 分析"></a>1.2.3 分析</h3><p>这里面分了三个层次，对于客户端和服务端，都像是本地调用一样，专注于业务逻辑的处理就可以了。对于Stub层，主要处理双方约定好的语法、语义、封装、解封装。对于RPCRuntime，主要处理高性能的传输，以及网络的错误和异常。</p><h2 id="1-3-RPC调用细节"><a href="#1-3-RPC调用细节" class="headerlink" title="1.3 RPC调用细节"></a>1.3 RPC调用细节</h2><p>最早的RPC是在NFS协议中使用的。NFS(Network File System)就是网络文件系统。要使NFS成功运行，要启动两个服务端，一个是MountID，用来挂载文件路径；一个是nfsd，用来读写文件。NFS可以在本地mount一个远程的目录到本地的一个目录，从而本地的用户在这个目录里面读写的时候，实际上操作的是远程另一台机器上的文件。</p><p><img src="https://i.loli.net/2020/02/02/lQ6Cbu58OWX7vTE.jpg" alt="fig4.jpg"></p><p>XDR(External Data Representation，外部数据表示法)是一个标准的数据压缩格式，可以表示基本的数据类型，也可以表示结构体。</p><p><img src="https://i.loli.net/2020/02/02/XTKIjcPuGNeiYt7.jpg" alt="fig5.jpg"></p><p>在RPC的调用中，所有的数据类型都要封装成类似的格式。而且RPC的调用和结果的返回，也有严格的格式。</p><ul><li>XID 唯一标识一对请求和回复。请求为 0，回复为 1。</li><li>RPC 有版本号，两端要匹配 RPC 协议的版本号。如果不匹配，就会返回 Deny，原因就是 RPC_MISMATCH。</li><li>程序有编号。如果服务端找不到这个程序，就会返回 PROG_UNAVAIL。</li><li>程序有版本号。如果程序的版本号不匹配，就会返回 PROG_MISMATCH。</li><li>一个程序可以有多个方法，方法也有编号，如果找不到方法，就会返回 PROC_UNAVAIL。</li><li>调用需要认证鉴权，如果不通过，则 Deny。</li><li>对于参数列表，如果参数无法解析，则返回GARBAGE_ARGS</li></ul><p><img src="https://i.loli.net/2020/02/02/oqLCI6nlrb9HpFZ.jpg" alt="fig6.jpg"></p><p>因此为了可以成功调用RPC，在客户端和服务端实现RPC的时候，首先要定义一个双方都认可的程序、版本、方法、参数等。</p><p><img src="https://i.loli.net/2020/02/02/FplZqHnDdILKmkw.jpg" alt="fig7.jpg"></p><p>如果还是上面的加法，则双方约定为一个协议定义文件，同理如果是 NFS、mount 和读写，也会有类似的定义。</p><p>有了协议定义文件，ONC RPC 会提供一个工具，根据这个文件生成客户端和服务器端的 Stub 程序。</p><p><img src="https://i.loli.net/2020/02/02/tjTU6N2nwdbEpZz.jpg" alt="fig8.jpg"></p><p>最下层的是XDR文件，用于编码和解码参数。这个文件是客户端和服务端共享的，因为只有双方一致才能成功通信。</p><p>在客户端，会调用 clnt_create 创建一个连接，然后调用 add_1，这是一个 Stub 函数，感觉是在调用本地一样。其实是这个函数发起了一个 RPC 调用，通过调用 clnt_call 来调用 ONC RPC 的类库，来真正发送请求。</p><p>当然服务端也有一个 Stub 程序，监听客户端的请求，当调用到达的时候，判断如果是 add，则调用真正的服务端逻辑，也即将两个数加起来。</p><p>服务端将结果返回服务端的 Stub，这个 Stub 程序发送结果给客户端，客户端的 Stub 程序正在等待结果，当结果到达客户端 Stub，就将结果返回给客户端的应用程序，从而完成整个调用过程。</p><h2 id="1-4-传输问题"><a href="#1-4-传输问题" class="headerlink" title="1.4 传输问题"></a>1.4 传输问题</h2><p>传输问题主要解决错误，重传，丢包，性能的问题，这些不是Stub来解决的，而是由One RPC类库来实现。</p><p><img src="https://i.loli.net/2020/02/02/FKCS6taMrDpizqv.jpg" alt="fig9.jpg"></p><p>在这个类库中，为了解决传输问题，对于每一个客户端，都会创建一个传输管理层，而每一次RPC调用，都会是一个任务，在传输管理层会有队列机制、拥塞控制机制等等。</p><p>由于在网络传输的时候，经常需要等待，因而同步的方式往往效率比较低，因而也就有 Socket 的异步模型。为了能够异步处理，对于远程调用的处理，往往是通过状态机来实现的。只有当满足某个状态的时候，才进行下一步，如果不满足状态，不是在那里等，而是将资源留出来，用来处理其他的 RPC 调用。</p><p><img src="https://i.loli.net/2020/02/02/rJ7AGCRfNMSVtHc.jpg" alt="fig10.jpg"></p><p>首先，进入起始状态，查看 RPC 的传输层队列中有没有空闲的位置，可以处理新的 RPC 任务。如果没有，说明太忙了，或直接结束或重试。如果申请成功，就可以分配内存，获取服务的端口号，然后连接服务器。</p><p>连接的过程要有一段时间，因而要等待连接的结果，会有连接失败，或直接结束或重试。如果连接成功，则开始发送 RPC 请求，然后等待获取 RPC 结果，这个过程也需要一定的时间；如果发送出错，可以重新发送；如果连接断了，可以重新连接；如果超时，可以重新传输；如果获取到结果，就可以解码，正常结束。</p><h2 id="1-5-服务发现问题"><a href="#1-5-服务发现问题" class="headerlink" title="1.5 服务发现问题"></a>1.5 服务发现问题</h2><p>如何找到RPC服务端的随机端口，在Onc RPC中，服务发现是通过portmapper实现的</p><p><img src="https://i.loli.net/2020/02/02/5BRPnap1Z9GcfkK.jpg" alt="fig11.jpg"></p><p>portmapper 会启动在一个众所周知的端口上，RPC 程序由于是用户自己写的，会监听在一个随机端口上，但是 RPC 程序启动的时候，会向 portmapper 注册。客户端要访问 RPC 服务端这个程序的时候，首先查询 portmapper，获取 RPC 服务端程序的随机端口，然后向这个随机端口建立连接，开始 RPC 调用。从图中可以看出，mount 命令的 RPC 调用，就是这样实现的。</p><h1 id="2-基于XML的SOAP协议"><a href="#2-基于XML的SOAP协议" class="headerlink" title="2. 基于XML的SOAP协议"></a>2. 基于XML的SOAP协议</h1><p>上述的ONC RPC协议还存在一些问题： </p><ol><li>需要双方的压缩格式完全一致</li><li>协议修改不灵活</li><li>版本问题</li></ol><p>即还是很难在客户端和服务端之间进行开发。</p><h2 id="2-1-XML-amp-SOAP"><a href="#2-1-XML-amp-SOAP" class="headerlink" title="2.1 XML &amp; SOAP"></a>2.1 XML &amp; SOAP</h2><p>要让所有不同的人都能看懂我们的信息，那么我们就需要用<strong>文本类</strong>的方式进行传输，无论哪个客户端获得这个文本，都能够知道它的意义。</p><h2 id="2-2-传输协议问题"><a href="#2-2-传输协议问题" class="headerlink" title="2.2 传输协议问题"></a>2.2 传输协议问题</h2><p>基于XML的最著名的通信协议就是SOAP了(Simple Object Access Protocol)-简单对象访问协议。使用XML编写简单的请求和回复消息，并用HTTP协议进行传输。</p><p>SOAP将请求和回复放在一个信封里，就像传递邮件一样，有抬头与正文的区别。</p><pre><code>POST /purchaseOrder HTTP/1.1Host: www.baidu.comContent-Type: application/soap+xml; charset=utf-8Content-Length: nnn&lt;?xml version=&quot;1.0&quot;?&gt;&lt;soap:Envelope xmlns:soap=&quot;http://www.w3.org/2001/12/soap-envelope&quot;soap:encodingStyle=&quot;http://www.w3.org/2001/12/soap-encoding&quot;&gt;    &lt;soap:Header&gt;        &lt;m:Trans xmlns:m=&quot;http://www.w3schools.com/transaction/&quot;          soap:mustUnderstand=&quot;1&quot;&gt;1234        &lt;/m:Trans&gt;    &lt;/soap:Header&gt;    &lt;soap:Body xmlns:m=&quot;http://www.baidu.com/perchaseOrder&quot;&gt;        &lt;m:purchaseOrder&quot;&gt;            &lt;order&gt;                &lt;date&gt;2018-07-01&lt;/date&gt;                &lt;className&gt; RPC &amp; SOAP &lt;/className&gt;                &lt;Author&gt; LLCHEN &lt;/Author&gt;            &lt;/order&gt;        &lt;/m:purchaseOrder&gt;    &lt;/soap:Body&gt;&lt;/soap:Envelope&gt;</code></pre><p>这个请求使用POST方法，发送一个格式为<code>application/soap + xml</code>的XML正文给<a href="http://www.baidu.com，从而下一个单，这个订单封装在SOAP的信封里。" target="_blank" rel="noopener">www.baidu.com，从而下一个单，这个订单封装在SOAP的信封里。</a></p><h2 id="2-3-协议约定问题"><a href="#2-3-协议约定问题" class="headerlink" title="2.3 协议约定问题"></a>2.3 协议约定问题</h2><p>因为服务开发出来是给陌生人用的，就像上面下单的那个 XML 文件，对于客户端来说，它如何知道应该拼装成上面的格式呢？这就需要对于服务进行描述，因为调用的人不认识你，所以没办法找到你，问你的服务应该如何调用。</p><p>当然你可以写文档，然后放在官方网站上，但是你的文档不一定更新得那么及时，而且你也写的文档也不一定那么严谨，所以常常会有调试不成功的情况。因而，我们需要一种相对比较严谨的<strong>Web服务描述语言， WSDL(Web Service Description Languages)</strong></p><p>在这个文件里，要定义一个类型的order，与上面的XML对应起来。</p><pre><code> &lt;wsdl:types&gt;  &lt;xsd:schema targetNamespace=&quot;http://www.example.org/geektime&quot;&gt;   &lt;xsd:complexType name=&quot;order&quot;&gt;    &lt;xsd:element name=&quot;date&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:element&gt;&lt;xsd:element name=&quot;className&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:element&gt;&lt;xsd:element name=&quot;Author&quot; type=&quot;xsd:string&quot;&gt;&lt;/xsd:element&gt;    &lt;xsd:element name=&quot;price&quot; type=&quot;xsd:int&quot;&gt;&lt;/xsd:element&gt;   &lt;/xsd:complexType&gt;  &lt;/xsd:schema&gt; &lt;/wsdl:types&gt;</code></pre><p>定义一个message结构</p><pre><code> &lt;wsdl:message name=&quot;purchase&quot;&gt;  &lt;wsdl:part name=&quot;purchaseOrder&quot; element=&quot;tns:order&quot;&gt;&lt;/wsdl:part&gt; &lt;/wsdl:message&gt;</code></pre><p>暴露一个端口</p><pre><code> &lt;wsdl:portType name=&quot;PurchaseOrderService&quot;&gt;  &lt;wsdl:operation name=&quot;purchase&quot;&gt;   &lt;wsdl:input message=&quot;tns:purchase&quot;&gt;&lt;/wsdl:input&gt;   &lt;wsdl:output message=&quot;......&quot;&gt;&lt;/wsdl:output&gt;  &lt;/wsdl:operation&gt; &lt;/wsdl:portType&gt;</code></pre><p>编写一个binding，将上面定义的信息绑定到SOAP请求的body里面</p><pre><code> &lt;wsdl:binding name=&quot;purchaseOrderServiceSOAP&quot; type=&quot;tns:PurchaseOrderService&quot;&gt;  &lt;soap:binding style=&quot;rpc&quot;   transport=&quot;http://schemas.xmlsoap.org/soap/http&quot; /&gt;  &lt;wsdl:operation name=&quot;purchase&quot;&gt;   &lt;wsdl:input&gt;    &lt;soap:body use=&quot;literal&quot; /&gt;   &lt;/wsdl:input&gt;   &lt;wsdl:output&gt;    &lt;soap:body use=&quot;literal&quot; /&gt;   &lt;/wsdl:output&gt;  &lt;/wsdl:operation&gt; &lt;/wsdl:binding&gt;</code></pre><p>对应的Service：</p><pre><code> &lt;wsdl:service name=&quot;PurchaseOrderServiceImplService&quot;&gt;  &lt;wsdl:port binding=&quot;tns:purchaseOrderServiceSOAP&quot; name=&quot;PurchaseOrderServiceImplPort&quot;&gt;   &lt;soap:address location=&quot;http://www.geektime.com:8080/purchaseOrder&quot; /&gt;  &lt;/wsdl:port&gt; &lt;/wsdl:service&gt;</code></pre><h2 id="2-4-服务发现问题"><a href="#2-4-服务发现问题" class="headerlink" title="2.4 服务发现问题"></a>2.4 服务发现问题</h2><p>采用UDDI协议(Universal Description, Discovery, and Integration),即统一描述、发现和继承协议。它其实是一个注册中心，服务提供方可以将上面的 WSDL 描述文件，发布到这个注册中心，注册完毕后，服务使用方可以查找到服务的描述，封装为本地的客户端进行调用。</p><h1 id="3-基于JSON的RESTful接口协议"><a href="#3-基于JSON的RESTful接口协议" class="headerlink" title="3. 基于JSON的RESTful接口协议"></a>3. 基于JSON的RESTful接口协议</h1><h2 id="3-1-RESTful"><a href="#3-1-RESTful" class="headerlink" title="3.1 RESTful"></a>3.1 RESTful</h2><p>然而 RESTful 可不仅仅是指 API，而是一种架构风格，全称 Representational State Transfer，表述性状态转移</p><h2 id="3-2-协议约定问题"><a href="#3-2-协议约定问题" class="headerlink" title="3.2 协议约定问题"></a>3.2 协议约定问题</h2><p>和 SOAP 不一样，REST 不是一种严格规定的标准，它其实是一种设计风格。如果按这种风格进行设计，RESTful 接口和 SOAP 接口都能做到，只不过后面的架构是 REST 倡导的，而 SOAP 相对比较关注前面的接口。</p><p>然而本地调用和远程跨网络调用毕竟不一样，这里的不一样还不仅仅是因为有网络而导致的客户端和服务端的分离，从而带来的网络性能问题。更重要的问题是，客户端和服务端谁来维护状态。所谓的状态就是对某个数据当前处理到什么程度了。</p><p>当有了 RPC 之后，我们本来期望对上层透明，就像上一节说的“远在天边，尽在眼前”。于是使用 RPC 的时候，对于状态的问题也没有太多的考虑。上面的例子都是在 RPC 场景下，由服务端来维护状态，很多 SOAP 接口设计的时候，也常常按这种模式。这种模式原来没有问题，是因为客户端和服务端之间的比例没有失衡。因为一般不会同时有太多的客户端同时连上来，所以 NFS 还能把每个客户端的状态都记住。</p><p>但是互联网场景下，客户端和服务端就彻底失衡了。你可以想象“双十一”，多少人同时来购物，作为服务端，它能记得过来吗？当然不可能，只好多个服务端同时提供服务，大家分担一下。但是这就存在一个问题，服务端怎么把自己记住的客户端状态告诉另一个服务端呢？或者说，你让我给你分担工作，你也要把工作的前因后果给我说清楚啊！</p><p>因此应该是服务端只记录资源的状态，而客户端自己维护自己的状态，比如已经访问到哪个目录了，哪一页等等这类信息。</p><p>当客户端维护了自己的状态的时候，就不需要这样调用服务端了。通过这种让客户端记录自己的状态的方式，我们可以实现服务端的无状态化，就可以让服务端来横向扩展了。</p><p>所谓的无状态，其实是服务端维护资源的状态，客户端维护会话的状态。对于服务端来讲，只有资源的状态改变了，客户端才调用 POST、PUT、DELETE 方法来找我；如果资源的状态没变，只是客户端的状态变了，就不用告诉我了，对于我来说都是统一的 GET。</p><p>虽然这只改进了 GET，但是已经带来了很大的进步。因为对于互联网应用，大多数是读多写少的。<strong>而且只要服务端的资源状态不变，就给了我们缓存的可能。例如可以将状态缓存到接入层，甚至缓存到 CDN 的边缘节点，这都是资源状态不变的好处</strong>。</p><p>按照这种思路，对于API的设计，就慢慢变成了以资源为核心，而不是以过程为核心了。也就是说服务端只需要客户端告诉它你需要什么资源就好了，具体的过程和动作就不需要知道了。</p><p>还是文件目录的例子。客户端应该访问哪个绝对路径，而非一个动作，我就要进入某个路径。再如，库存的调用，应该查看当前的库存数目，然后减去购买的数量，得到结果的库存数。这个时候应该设置为目标库存数（但是当前库存数要匹配），而非告知减去多少库存。</p><p>这种 API 的设计需要实现幂等，因为网络不稳定，就会经常出错，因而需要重试，但是一旦重试，就会存在幂等的问题，也就是同一个调用，多次调用的结果应该一样，不能一次支付调用，因为调用三次变成了支付三次。不能进入 cd a，做了三次，就变成了 cd a/a/a。也不能扣减库存，调用了三次，就扣减三次库存。</p><p>当然按照这种设计模式，无论 RESTful API 还是 SOAP API 都可以将架构实现成无状态的，面向资源的、幂等的、横向扩展的、可缓存的。</p><p>但SOAP的XML正文可以放任何动作，而RESTful基本描述的就是资源的状态，没法描述动作，能发出的动作只有CRUD。</p><h2 id="3-3-服务发现问题"><a href="#3-3-服务发现问题" class="headerlink" title="3.3 服务发现问题"></a>3.3 服务发现问题</h2><p>有个著名的基于 RESTful API 的跨系统调用框架叫 Spring  Cloud。在 Spring  Cloud 中有一个组件叫 Eureka。传说，阿基米德在洗澡时发现浮力原理，高兴得来不及穿上裤子，跑到街上大喊：“Eureka（我找到了）！”所以 Eureka 是用来实现注册中心的，负责维护注册的服务列表。</p><p>服务分服务提供方，它向 Eureka 做服务注册、续约和下线等操作，注册的主要数据包括服务名、机器 IP、端口号、域名等等。</p><p>另外一方是服务消费方，向 Eureka 获取服务提供方的注册信息。为了实现负载均衡和容错，服务提供方可以注册多个。</p><p>当消费方要调用服务的时候，会从注册中心读出多个服务来，那怎么调用呢？当然是 RESTful 方式了。</p><p>Spring Cloud 提供一个 RestTemplate 工具，用于将请求对象转换为 JSON，并发起 Rest 调用，RestTemplate 的调用也是分 POST、PUT、GET、  DELETE 的，当结果返回的时候，根据返回的 JSON 解析成对象。</p><h1 id="4-二进制类RPC协议"><a href="#4-二进制类RPC协议" class="headerlink" title="4. 二进制类RPC协议"></a>4. 二进制类RPC协议</h1><p>接入层设计，在CDN, DNS当中，对于静态资源或者动态资源静态化的部分都可以做缓存。但是对于下单，支付等交易场景，还是需要调用API。</p><p>对于微服务的架构，API需要一个API网关统一进行管理。实现方式有：用Nginx或者OpenResty结合Lua脚本。在Spring Cloud当中，用组件Zuul也可以。</p><h2 id="4-1-数据中心内部是如何调用的？"><a href="#4-1-数据中心内部是如何调用的？" class="headerlink" title="4.1 数据中心内部是如何调用的？"></a>4.1 数据中心内部是如何调用的？</h2><p>API网关用来管理API，但是API的实现一般在Controller层进行实现，这一层对外提供API。因为是面向大规模互联网应用的，所以主流还是使用RESTful API。</p><p><img src="https://i.loli.net/2020/02/02/r5w7jdebPcLEDty.jpg" alt="fig12.jpg"></p><p>非常棒的分层图:</p><ol><li>客户端进入的请求首先会进入负载均衡系统-nginx</li><li>静态资源先到Varnish找</li><li>动态资源去Redis找</li><li>2，3是负责整个页面的渲染</li><li>对于API调用，会到Controller层去解决，这里主要是处理各种业务逻辑的</li><li>Controller层下方会有细化的基础服务层</li><li>缓存层</li><li>持久化层（分布式数据库+搜索引擎）</li></ol><p>在Controller之内，就是互联网应用的业务逻辑实现了。业务逻辑的实现最好是无状态的，从而可以横向扩展，但是资源的状态还是需要服务端来维护的。资源的状态不应该维护在业务逻辑层，而是在最底层的持久化层，一般会使用分布式数据库和Elastic Search.</p><p>这些服务端的状态，例如订单、库存、商品等，都是重中之重，都需要持久化到硬盘上，数据不能丢，但是由于硬盘读写性能差，因而持久化层往往吞吐量不能达到互联网应用要求的吞吐量，因而前面要有一层缓存层，使用 Redis 或者 memcached 将请求拦截一道，不能让所有的请求都进入数据库“中军大营”。</p><p>缓存和持久化层之上一般是<strong>基础服务层</strong>，这里面提供一些原子化的接口。例如，对于用户、商品、订单、库存的增删查改，将缓存和数据库对再上层的业务逻辑屏蔽一道。有了这一层，上层业务逻辑看到的都是接口，而不会调用数据库和缓存。因而对于缓存层的扩容，数据库的分库分表，所有的改变，都截止到这一层，这样有利于将来对于缓存和数据库的运维。</p><p>再上面就是<strong>组合层</strong>。因为基础服务层只是提供简单的接口，实现简单的业务逻辑，而复杂的业务逻辑，比如下单，要扣优惠券，扣减库存等，就要在组合服务层实现。</p><p>这样，Controller 层、组合服务层、基础服务层就会相互调用，这个调用是在数据中心内部的，量也会比较大，还是使用 RPC 的机制实现的。</p><p>由于服务比较多，需要一个单独的注册中心来做服务发现。服务提供方会将自己提供哪些服务注册到注册中心中去，同时服务消费方订阅这个服务，从而可以对这个服务进行调用。</p><p>调用的时候有一个问题，这里的 RPC 调用，应该用二进制还是文本类？其实文本的最大问题是，占用字节数目比较多。比如数字 123，其实本来二进制 8 位就够了，但是如果变成文本，就成了字符串 123。如果是 UTF-8 编码的话，就是三个字节；如果是 UTF-16，就是六个字节。同样的信息，要多费好多的空间，传输起来也更加占带宽，时延也高。因而对于数据中心内部的相互调用，很多公司选型的时候，还是希望采用更加省空间和带宽的二进制的方案。</p><h2 id="4-2-Dubbo服务化框架二进制的RPC方式"><a href="#4-2-Dubbo服务化框架二进制的RPC方式" class="headerlink" title="4.2 Dubbo服务化框架二进制的RPC方式"></a>4.2 Dubbo服务化框架二进制的RPC方式</h2><p><img src="https://i.loli.net/2020/02/02/fX8e25rG6xkBpq4.jpg" alt="fig13.jpg"></p><p>Dubbo 会在客户端的本地启动一个 Proxy，其实就是客户端的 Stub，对于远程的调用都通过这个 Stub 进行封装。</p><p>接下来，Dubbo 会从注册中心获取服务端的列表，根据路由规则和负载均衡规则，在多个服务端中选择一个最合适的服务端进行调用。</p><p>调用服务端的时候，首先要进行编码和序列化，形成 Dubbo 头和序列化的方法和参数。将编码好的数据，交给网络客户端进行发送，网络服务端收到消息后，进行解码。然后将任务分发给某个线程进行处理，在线程中会调用服务端的代码逻辑，然后返回结果。</p><h2 id="4-3-如何解决协议约定问题？"><a href="#4-3-如何解决协议约定问题？" class="headerlink" title="4.3 如何解决协议约定问题？"></a>4.3 如何解决协议约定问题？</h2><p>Dubbo 中默认的 RPC 协议是 Hessian2。为了保证传输的效率，Hessian2 将远程调用序列化为二进制进行传输，并且可以进行一定的压缩。这个时候你可能会疑惑，同为二进制的序列化协议，Hessian2 和前面的二进制的 RPC 有什么区别呢？Hessian2 是解决了一些问题的。例如，原来要定义一个协议文件，然后通过这个文件生成客户端和服务端的 Stub，才能进行相互调用，这样使得修改就会不方便。Hessian2 不需要定义这个协议文件，而是自描述的。什么是自描述呢？</p><p>所谓自描述就是，关于调用哪个函数，参数是什么，另一方不需要拿到某个协议文件、拿到二进制，靠它本身根据 Hessian2 的规则，就能解析出来。</p><h2 id="4-4-如何解决RPC传输问题？"><a href="#4-4-如何解决RPC传输问题？" class="headerlink" title="4.4 如何解决RPC传输问题？"></a>4.4 如何解决RPC传输问题？</h2><p>Dubbo使用了Netty的网络传输框架。</p><p>Netty是一个非阻塞的基于事件的网络传输框架，在服务端启动的时候，会监听一个端口，并注册以下事件：</p><ul><li>连接事件 - 当收到客户端的连接事件时，会调用void connected(Channel channel)方法</li><li>当<strong>可写事件</strong>触发时，会调用void sent(Channel channel, Object message)，服务端向客户端返回响应数据</li><li>当<strong>可读事件</strong>触发时，会调用 void received(Channel channel, Object message) ，服务端在收到客户端的请求数据。</li><li>当<strong>发生异常</strong>时，会调用 void caught(Channel channel, Throwable exception)。</li></ul><p>当事件触发之后，服务端在这些函数中的逻辑，可以选择<strong>直接在这个函数里面进行操作，还是将请求分发到线程池</strong>去处理。一般异步的数据读写都需要另外的线程池参与，在线程池中会<strong>调用真正的服务端业务代码逻辑</strong>，返回结果</p><p>到这里，我们说了数据中心里面的相互调用。为了高性能，大家都愿意用二进制，但是为什么后期 Spring Cloud 又兴起了呢？这是因为，并发量越来越大，已经到了微服务的阶段。同原来的 SOA 不同，微服务粒度更细，模块之间的关系更加复杂。</p><p>在上面的架构中，如果使用二进制的方式进行序列化，虽然不用协议文件来生成 Stub，但是对于接口的定义，以及传的对象 DTO，<strong>还是需要共享 JAR</strong>。因为只有客户端和服务端都有这个 JAR，才能成功地序列化和反序列化。</p><p>但当关系复杂的时候，JAR 的依赖也变得异常复杂，难以维护，而且如果在 DTO 里加一个字段，双方的 JAR 没有匹配好，也会导致序列化不成功，而且还有可能循环依赖。这个时候，一般有两种选择。</p><ol><li>建立严格的项目管理流程</li></ol><ul><li>不允许循环调用，不允许跨层调用，只准上层调用下层，不允许下层调用上层。</li><li>接口要保持兼容性，不兼容的接口新添加而非改原来的，当接口通过监控，发现不用的时候，再下掉。</li><li>升级的时候，先升级服务提供端，再升级服务消费端。</li></ul><ol start="2"><li>改用RESTful方式</li></ol><ul><li>使用 Spring Cloud，消费端和提供端不用共享 JAR，各声明各的，只要能变成 JSON 就行，而且 JSON 也是比较灵活的。</li><li>使用 RESTful 的方式，性能会降低，所以需要通过横向扩展来抵消单机的性能损耗。</li></ul><h1 id="5-跨语言类RPC协议"><a href="#5-跨语言类RPC协议" class="headerlink" title="5. 跨语言类RPC协议"></a>5. 跨语言类RPC协议</h1><p>通过学习，我们知道，二进制的传输性能好，文本类的传输性能差一些；二进制的难以跨语言，文本类的可以跨语言；要写协议文件的严谨一些，不写协议文件的灵活一些。虽然都有服务发现机制，有的可以进行服务治理，有的则没有。</p><p>RPC从最初的客户端服务器的模式，最终演化到微服务。对于RPC框架的要求也开始逐渐变多，要求如下： </p><ol><li>传输性能很重要，因为服务之间的调用太过频繁，还是二进制的越快越好</li><li>跨语言很重要，因为服务多了，什么语言写成的都有，而且不同的场景适宜用不同的语言，不能一个语言走到底。</li><li>最好既严谨又灵活，添加一个字段不需要重新编译和发布程序</li><li>最好既有服务发现，也有服务治理，就像Dubbo和Spring Cloud这样子。</li></ol><h2 id="5-1-gRPC协议"><a href="#5-1-gRPC协议" class="headerlink" title="5.1 gRPC协议"></a>5.1 gRPC协议</h2><p>二进制传输，并且可以跨语言传输。因为语言不同，还压缩过了，所以双方必须搞一个协议约定文件，规定好双方沟通的专业术语，这样来让整个沟通更加顺畅。</p><p>对于 GRPC 来讲，二进制序列化协议是 Protocol Buffers。首先，需要定义一个协议文件.proto。</p><pre><code>syntax = “proto3”;package com.llchen60.grpcoption java_package = “com.llchen60.grpc”;message Order {  required string date = 1;  required string classname = 2;  required string author = 3;  required int price = 4;}message OrderResponse {  required string message = 1;}service PurchaseOrder {  rpc Purchase (Order) returns (OrderResponse) {}}</code></pre><p>在这个协议文件中，我们首先指定使用 proto3 的语法，然后我们使用** Protocol Buffers 的语法<strong>，定义两个消息的类型，一个是发出去的参数，一个是返回的结果。里面的每一个字段，例如 date、classname、author、price 都有</strong>唯一的一个数字标识**，这样在压缩的时候，就不用传输字段名称了，只传输这个数字标识就行了，能节省很多空间。</p><p>最后定义一个Service，里面会有一个RPC调用的声明，无论使用什么语言，都有相应的工具生成客户端和服务端的Stub程序，这样客户端就可以像调用本地一样，调用远程的服务了。</p><h2 id="5-2-协议约定问题"><a href="#5-2-协议约定问题" class="headerlink" title="5.2 协议约定问题"></a>5.2 协议约定问题</h2><p>Protocol Buffers，是一个有着很高的压缩效率的序列化协议。对于 int 类型 32 位的，一般都需要 4 个 Byte 进行存储。在 Protocol Buffers 中，使用的是变长整数的形式。对于每一个 Byte 的 8 位，最高位都有特殊的含义。如果该位为 1，表示这个数字没完，后续的 Byte 也属于这个数字；如果该位为 0，则这个数字到此结束。其他的 7 个 Bit 才是用来表示数字的内容。因此，小于 128 的数字都可以用一个 Byte 表示；大于 128 的数字，比如 130，会用两个字节来表示。对于每一个字段，使用的是 TLV（Tag，Length，Value）的存储办法。其中 Tag = (field_num &lt;&lt; 3) | wire_type。field_num 就是在 proto 文件中，给每个字段指定唯一的数字标识，而 wire_type 用于标识后面的数据类型。</p><p><img src="https://i.loli.net/2020/02/02/Rvy2MsuzKemHNb6.jpg" alt="fig14.jpg"></p><p>在灵活性方面，这种基于协议文件的二进制压缩协议往往存在更新不方便的问题。例如，客户端和服务器因为需求的改变需要添加或者删除字段。这一点上，Protocol Buffers考虑了兼容性，在上面的协议文件当中，每一个字段都有修饰符，比如：</p><ul><li>required </li><li>optional </li><li>repeated </li></ul><p>如果我们想修改协议文件，对于赋给某个标签的数字，例如 string author=3，这个就不要改变了，改变了就不认了；也不要添加或者删除 required 字段，因为解析的时候，发现没有这个字段就会报错。对于 optional 和 repeated 字段，可以删除，也可以添加。这就给了客户端和服务端升级的可能性。</p><h2 id="5-3-网络传输问题"><a href="#5-3-网络传输问题" class="headerlink" title="5.3 网络传输问题"></a>5.3 网络传输问题</h2><p>假设是Java技术栈，那么gRPC的客户端和服务器之间通过Netty Channel作为数据通道，每个请求都被封装成HTTP2.0的Stream当中。</p><p>Netty是一个搞笑的基于异步IO的网络传输框架，</p><p>HTTP2.0还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。</p><p>通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。</p><p><img src="https://i.loli.net/2020/02/02/bqVPBtkcZwWL5A4.jpg" alt="fig15.jpg"></p><p>由于基于HTTP2.0，gRPC和其他的RPC不同，可以定义四种服务方法。</p><h3 id="5-3-1-单向RPC"><a href="#5-3-1-单向RPC" class="headerlink" title="5.3.1 单向RPC"></a>5.3.1 单向RPC</h3><p>客户端发送一个请求给服务端，从服务端获取一个应答，就像普通的一次函数调用一样。</p><pre><code>rpc SayHello(HelloRequest) returns (HelloResponse){}</code></pre><h3 id="5-3-2-服务端流式RPC"><a href="#5-3-2-服务端流式RPC" class="headerlink" title="5.3.2 服务端流式RPC"></a>5.3.2 服务端流式RPC</h3><p>服务端返回的不是一个结果，而是一批。客户端发送一个请求给服务端，可获取一个数据流用来读取一系列信息。客户端从返回的数据流里一直读取，直到没有更多的消息为止。</p><pre><code>rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse){}</code></pre><h3 id="5-3-3-客户端流式RPC"><a href="#5-3-3-客户端流式RPC" class="headerlink" title="5.3.3 客户端流式RPC"></a>5.3.3 客户端流式RPC</h3><p>客户端的请求不是一个，而是一批，客户端用提供的一个数据流写入并发送一系列消息给服务端。一旦客户端完成消息写入，就等待服务端读取这些消息并返回应答。</p><pre><code>rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) {}</code></pre><h3 id="5-3-4-双向流式RPC"><a href="#5-3-4-双向流式RPC" class="headerlink" title="5.3.4 双向流式RPC"></a>5.3.4 双向流式RPC</h3><p>即两边都可以分别通过一个读写数据流来发送一系列消息。这两个数据流操作是<strong>相互独立</strong>的，所以客户端和服务端<strong>能按其希望的任意顺序读写</strong>，服务端可以在写应答前等待所有的客户端消息，或者它可以先读一个消息再写一个消息，或者读写相结合的其他方式。每个数据流里消息的顺序会被保持。</p><pre><code>rpc BidiHello(stream HelloRequest) returns (stream HelloResponse){}</code></pre><p>如果基于 HTTP  2.0，客户端和服务器之间的交互方式要丰富得多，不仅可以单方向远程调用，还可以实现当服务端状态改变的时候，主动通知客户端。</p><h2 id="5-4-服务发现与治理问题"><a href="#5-4-服务发现与治理问题" class="headerlink" title="5.4 服务发现与治理问题"></a>5.4 服务发现与治理问题</h2><p>gRPC本身没有提供服务发现的机制，需要借助其他的组件，发现要访问的服务端，在多个服务端之间进行容错和负载均衡。</p><p>这个地方的重点问题在于如何发现服务端，并根据服务端的变化，动态修改负载均衡器的配置。</p><h3 id="5-4-1-Envoy配置"><a href="#5-4-1-Envoy配置" class="headerlink" title="5.4.1 Envoy配置"></a>5.4.1 Envoy配置</h3><p>在这里我们介绍一种对于 GRPC 支持比较好的负载均衡器 Envoy。其实 Envoy 不仅仅是负载均衡器，它还是一个高性能的 C++ 写的 Proxy 转发器，可以配置非常灵活的转发规则。</p><p>这些规则可以是静态的，放在配置文件中的，在启动的时候加载。要想重新加载，一般需要重新启动，但是 Envoy 支持热加载和热重启，这在一定程度上缓解了这个问题。</p><p>当然，最好的方式是将规则设置为动态的，放在统一的地方维护。这个统一的地方在 Envoy 眼中被称为服务发现（Discovery Service），过一段时间去这里拿一下配置，就修改了转发策略。</p><p>无论是静态的，还是动态的，在配置里面往往会配置四个东西： </p><ol><li>listener: Envoy既然是Proxy，专门做转发，就得监听一个端口，接入请求，然后才能根据策略转发，这个监听的端口就称为listener.</li><li>endpoint: 是目标的IP地址和端口。这个是proxy最终将请求转发到的地方。</li><li>cluster: 一个cluster是具有完全相同行为的多个endpoint，即如果有三个服务端在运行，就会有三个IP和端口，但是部署的是完全相同的三个服务，它们组成了一个cluster，从cluster到endpoint的过程称为负载均衡，可以轮询。</li><li>route: 有时候多个cluster具有类似的功能，但是是不同的版本，可以通过route规则，选择将请求路由到某一个版本号当中，就到了对应的cluster里面。</li></ol><p>如果是静态的，则将后端的服务端的 IP 地址拿到，然后放在配置文件里面就可以了。</p><p>如果是动态的，就需要配置一个服务发现中心，这个服务发现中心要实现 Envoy 的 API，Envoy 可以主动去服务发现中心拉取转发策略。</p><p><img src="https://i.loli.net/2020/02/02/TFIJXoGlNMCh1Ec.jpg" alt="fig16.jpg"></p><p>看来，Envoy 进程和服务发现中心之间要经常相互通信，互相推送数据，所以 Envoy 在控制面和服务发现中心沟通的时候，就可以使用 GRPC，也就天然具备在用户面支撑 GRPC 的能力。</p><h3 id="5-4-2-Envoy-功能"><a href="#5-4-2-Envoy-功能" class="headerlink" title="5.4.2 Envoy 功能"></a>5.4.2 Envoy 功能</h3><ul><li>配置路由策略</li></ul><p>例如后端的服务有两个版本，可以通过配置 Envoy 的 route，来设置两个版本之间，也即两个 cluster 之间的 route 规则，一个占 99% 的流量，一个占 1% 的流量。</p><ul><li>负载均衡策略</li></ul><p>对于一个 cluster 下的多个endpoint，可以配置负载均衡机制和健康检查机制，当服务端新增了一个，或者挂了一个，都能够及时配置 Envoy，进行负载均衡。</p><p><img src="https://i.loli.net/2020/02/02/E7Qrsp6q2tySUK5.jpg" alt="fig17.jpg"></p><p>所有这些节点的变化都会上传到注册中心，所有这些策略都可以通过注册中心进行下发，所以，更严格的意义上讲，注册中心可以称为注册治理中心。</p><p>Envoy 这么牛，是不是能够将服务之间的相互调用全部由它代理？如果这样，服务也不用像 Dubbo，或者 Spring Cloud 一样，自己感知到注册中心，自己注册，自己治理，对应用干预比较大。</p><p>如果我们的应用能够意识不到服务治理的存在，就是直接进行 GRPC 的调用就可以了。</p><p>这就是未来服务治理的趋势<strong><em>Service Mesh</em></strong>，即应用之间的相互调用全部由Envoy进行代理，服务之间的治理也被Envoy进行代理，完全将服务治理抽象出来，到平台层解决。</p><p><img src="https://i.loli.net/2020/02/02/8naO9kR1dh3K4Cj.jpg" alt="fig18.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RESTFul </tag>
            
            <tag> RPC </tag>
            
            <tag> SOAP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(九)-云</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B9%9D-%E4%BA%91/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B9%9D-%E4%BA%91/</url>
      
        <content type="html"><![CDATA[<h1 id="1-虚拟网卡"><a href="#1-虚拟网卡" class="headerlink" title="1. 虚拟网卡"></a>1. 虚拟网卡</h1><p>数据中心的维护非常复杂麻烦，主要体现在采购，运维，规格，复用等方面。为了解决这个问题，我们发明了虚拟机，并基于它产生了云计算技术。</p><h2 id="1-1-物理机到虚拟机"><a href="#1-1-物理机到虚拟机" class="headerlink" title="1.1 物理机到虚拟机"></a>1.1 物理机到虚拟机</h2><p>软件模拟硬件的方式，数据中心里面用的是qumu-kvm，能让你在一台巨大的物理机里面，掏出一台台小机器。这套软件就能解决上面的问题：一点就能创建，一点就能销毁。想多大就有多大，每次创建的系统都还是新的。</p><p>其实做的事情就和OS做的事情一样，让虚拟机觉得自己在使用独立的设备，占有所有的内存，CPU，网络，硬盘。</p><p>实质上是多个虚拟机轮流使用物理CPU，内存也是使用虚拟内存映射的方式，最终映射到物理内存上。硬盘在一块大的文件系统上创建一个N个G的文件，作为虚拟机的硬盘。</p><h2 id="1-2-虚拟网卡的原理-如何将虚拟机的网络和物理机的网络连接起来？"><a href="#1-2-虚拟网卡的原理-如何将虚拟机的网络和物理机的网络连接起来？" class="headerlink" title="1.2 虚拟网卡的原理 - 如何将虚拟机的网络和物理机的网络连接起来？"></a>1.2 虚拟网卡的原理 - 如何将虚拟机的网络和物理机的网络连接起来？</h2><p><img src="https://i.loli.net/2020/02/02/PkNpQgShKDFRtyx.jpg" alt="fig1.jpg"></p><p>虚拟机是物理机上跑着的一个软件，这个软件可以像其他应用打开文件一样，打开一个称谓TUN/TAP的Char Dev(字符设备文件)。打开了这个字符设备文件之后，在物理机上就能看到一张虚拟TAP网卡。</p><p>虚拟机会打开这个文件，然后在自己的虚拟的身上(hhhh)虚拟出一张网卡，让虚拟机里的应用觉得它们真的有一张网卡。然后，所有的网络包都往这里发。</p><p>当然，网络包会到虚拟化软件这里。它会将网络包转换成为<strong>文件</strong>流，写入字符设备，就像写一个文件一样。内核中 TUN/TAP 字符设备驱动会收到这个写入的文件流，交给 TUN/TAP 的虚拟网卡驱动。这个驱动将文件流再次转成网络包，交给 TCP/IP 协议栈，最终从虚拟 TAP 网卡发出来，成为标准的网络包。这样数据就能从虚拟机里面最终发送到虚拟机的外面。</p><h2 id="1-3-虚拟网卡的连接"><a href="#1-3-虚拟网卡的连接" class="headerlink" title="1.3 虚拟网卡的连接"></a>1.3 虚拟网卡的连接</h2><h3 id="1-3-1-云计算中的网络问题"><a href="#1-3-1-云计算中的网络问题" class="headerlink" title="1.3.1 云计算中的网络问题"></a>1.3.1 云计算中的网络问题</h3><ul><li>共享： 尽管每个虚拟机都会有一个或者多个虚拟网卡，但是物理机可能只有有限的网卡。这么多虚拟网卡如何共享同一个出口？ </li><li>隔离： 安全隔离-同一个机器上的两个虚拟机属于两个用户，怎么保证相互之间不会被窃听？  流量隔离-同一个机器上的两个虚拟机，一个占用大量带宽，另外一个还能上网么？ </li><li>互通： 同一个机器两个虚拟机，同一用户，如何通信？ 不同物理机上两个虚拟机，属于同一个用户的话，这两个如何相互通信？ </li><li>灵活： 虚拟机会经常有创建，删除的操作，或者所有配置的迁移搬运，需要能够进行灵活配置。</li></ul><h3 id="1-3-2-共享与互通的问题"><a href="#1-3-2-共享与互通的问题" class="headerlink" title="1.3.2 共享与互通的问题"></a>1.3.2 共享与互通的问题</h3><ul><li>一台物理机上有多个虚拟机，多个虚拟网卡，这些虚拟网卡如何连接在一起，进行相互访问，并且能够访问外网的呢？ </li></ul><h4 id="1-3-2-1-网桥"><a href="#1-3-2-1-网桥" class="headerlink" title="1.3.2.1 网桥"></a>1.3.2.1 网桥</h4><p>物理机上应该有一个虚拟的交换机，通过创建虚拟的网桥  <code>brctl addbr br0</code> 将几个虚拟机的虚拟网卡都连接到虚拟网桥brctl addif br0 tap0上，这样讲两个虚拟机配置相同的子网网段，两台虚拟机就能够相互通信了。</p><p><img src="https://i.loli.net/2020/02/02/f9AW6sK2tF4qNMO.jpg" alt="fig2.jpg"></p><p>要让几台虚拟机都能访问外网，可以采用桥接的方式，形成以下的结构：</p><p><img src="https://i.loli.net/2020/02/02/WA1KMhrXbvt4ke9.jpg" alt="fig3.jpg"></p><p>这个时候如果你去看你的IP地址，会发现你的虚拟机的地址和你的笔记本电脑和你旁边的人的网段是一致的。因为网桥将这几个都连接起来了。在数据中心里面，采取的也是类似的技术，只不过都是 Linux，在每台机器上都创建网桥 br0，虚拟机的网卡都连到 br0 上，物理网卡也连到br0上，所有的br0都通过物理网卡出来连接到物理交换机上。</p><p><img src="https://i.loli.net/2020/02/02/HyPYxt9M5Ob2gJd.jpg" alt="fig4.jpg"><br><img src="https://i.loli.net/2020/02/02/nkVRqf7bU1YtDPi.jpg" alt="fig9.jpg"></p><p>你还记得吗？在一个二层网络里面，最大的问题是广播。一个数据中心的物理机已经很多了，广播已经非常严重，需要通过 VLAN 进行划分。如果使用了虚拟机，假设一台物理机里面创建 10 台虚拟机，全部在一个二层网络里面，那广播就会很严重，所以除非是你的桌面虚拟机或者数据中心规模非常小，才可以使用这种相对简单的方式。</p><h4 id="1-3-2-2-NAT"><a href="#1-3-2-2-NAT" class="headerlink" title="1.3.2.2 NAT"></a>1.3.2.2 NAT</h4><p><img src="https://i.loli.net/2020/02/02/rnV3TutSEp9Z72B.jpg" alt="fig5.jpg"></p><p>在这种方式下，你登录到虚拟机里面查看 IP 地址，会发现虚拟机的网络是虚拟机的，物理机的网络是物理机的，两个不相同。虚拟机要想访问物理机的时候，需要将地址 NAT 成为物理机的地址。</p><p>除此之外，它还会在你的笔记本电脑里内置一个 DHCP 服务器，为笔记本电脑上的虚拟机动态分配 IP 地址。因为虚拟机的网络自成体系，需要进行 IP 管理。为什么桥接方式不需要呢？因为桥接将网络打平了，虚拟机的 IP 地址应该由物理网络的 DHCP 服务器分配。</p><p><img src="https://i.loli.net/2020/02/02/9PSTLm8MdbO6f3v.jpg" alt="fig6.jpg"></p><p>虚拟机是你的电脑，路由器和 DHCP Server 相当于家用路由器或者寝室长的电脑，物理网卡相当于你们宿舍的外网网口，用于访问互联网。所有电脑都通过内网网口连接到一个网桥 br0 上，虚拟机要想访问互联网，需要通过 br0 连到路由器上，然后通过路由器将请求 NAT 成为物理网络的地址，转发到物理网络。</p><p>如果是你自己登录到物理机上做个简单配置，你可以简化一下。例如将虚拟机所在网络的网关的地址直接配置到 br0 上，不用 DHCP Server，手动配置每台虚拟机的 IP 地址，通过命令 iptables -t nat -A POSTROUTING -o ethX -j MASQUERADE，直接在物理网卡 ethX 上进行 NAT，所有从这个网卡出去的包都 NAT 成这个网卡的地址。通过设置 net.ipv4.ip_forward = 1，开启物理机的转发功能，直接做路由器，而不用单独的路由器，这样虚拟机就能直接上网了。</p><p><img src="https://i.loli.net/2020/02/02/6nB4Z2ekyQMivqP.jpg" alt="fig7.jpg"></p><h2 id="1-3-3-隔离问题"><a href="#1-3-3-隔离问题" class="headerlink" title="1.3.3 隔离问题"></a>1.3.3 隔离问题</h2><p>如果一台机器上的两个虚拟机不属于同一个用户，怎么办呢？好在 brctl 创建的网桥也是支持 VLAN 功能的，可以设置两个虚拟机的 tag，这样在这个虚拟网桥上，两个虚拟机是不互通的。</p><p>但是如何跨物理机互通，并且实现 VLAN 的隔离呢？由于 brctl 创建的网桥上面的 tag 是没办法在网桥之外的范围内起作用的，于是我们需要寻找其他的方式。</p><p>有一个命令<code>vconfig</code>，可以基于物理网卡eth0创建带VLAN的虚拟网卡，所有从这个虚拟网卡出去的包，都带这个VLAN，如果这样跨物理机的互通和隔离就可以通过这个网卡来实现了。</p><p><img src="https://i.loli.net/2020/02/02/HtvwWh5iqmpDfze.jpg" alt="fig8.jpg"></p><p>首先为每个用户分配不同的 VLAN，例如有一个用户 VLAN 10，一个用户 VLAN 20。在一台物理机上，基于物理网卡，为每个用户用 vconfig 创建一个带 VLAN 的网卡。不同的用户使用不同的虚拟网桥，带 VLAN 的虚拟网卡也连接到虚拟网桥上。</p><p>这样是否能保证两个用户的隔离性呢？不同的用户由于网桥不通，不能相互通信，一旦出了网桥，由于 VLAN 不同，也不会将包转发到另一个网桥上。另外，出了物理机，也是带着 VLAN ID 的。只要物理交换机也是支持 VLAN 的，到达另一台物理机的时候，VLAN ID 依然在，它只会将包转发给相同 VLAN 的网卡和网桥，所以跨物理机，不同的 VLAN 也不会相互通信。</p><p>使用 brctl 创建出来的网桥功能是简单的，基于 VLAN 的虚拟网卡也能实现简单的隔离。但是这都不是大规模云平台能够满足的，一个是 VLAN 的隔离，数目太少。前面我们学过，VLAN ID 只有 4096 个，明显不够用。另外一点是这个配置不够灵活。谁和谁通，谁和谁不通，流量的隔离也没有实现，还有大量改进的空间。</p><h1 id="2-云中网络Qos"><a href="#2-云中网络Qos" class="headerlink" title="2. 云中网络Qos"></a>2. 云中网络Qos</h1><p>流量控制技术，来实现Quality of Service,从而保障大多数人的服务质量</p><p><img src="https://i.loli.net/2020/02/02/joSwOU5tpml7a6n.jpg" alt="fig10.jpg"></p><p>我们能控制的只有出方向，通过Shaping，将出的流量控制成自己想要的模样。而进入的方向无法控制，只能通过Policy将包丢弃。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(八)-数据中心, VPN, 移动网络</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AB-%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83-VPN-%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AB-%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%BF%83-VPN-%E7%A7%BB%E5%8A%A8%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="1-数据中心"><a href="#1-数据中心" class="headerlink" title="1. 数据中心"></a>1. 数据中心</h1><p>数据中心里都是服务器，放在机架上(Rack)。数据中心的出口和入口也是路由器，多个边界路由器使其可用性更高。</p><p>为了高可用性，数据中心的边界路由器会连接多个运营商网络。</p><p>对于各个机架上的服务器，需要用交换机进行连接，TOR(Top of Rack)。</p><p><img src="https://i.loli.net/2020/02/02/PudyE2nb3oJ8ARr.jpg" alt="fig1.jpg"></p><p>当一个机架放不下的时候，就需要多个机架，并使用交换机将多个机架连接起来。这些交换机称为汇聚层交换机。</p><p>数据中心的服务器需要有至少两个网卡，保证可用性。对网卡要进行网卡绑定的操作。</p><p>这就需要服务器和交换机都支持一种协议，LACP, Link Aggregation Control Protocol。互相通信，将多个网卡聚合成一个网卡，多个网线聚合成一个网线，在网线之间可以进行负载均衡，也可以为高可用作准备。</p><p><img src="https://i.loli.net/2020/02/02/81kG3HRJU4KfYWE.jpg" alt="fig2.jpg"></p><p>交换机有一种技术叫作堆叠，将多个交换机形成一个逻辑的交换机，服务器通过多根线分配连到多个接入层交换机上，而接入层交换机多根线分别连接到多个交换机上，并且通过堆叠的私有协议，形成双活的连接方式。</p><p><img src="https://i.loli.net/2020/02/02/8nGwLsV6ziAWIgP.jpg" alt="fig3.jpg"></p><p>汇聚层将大量的节点相互连接在一起，形成了一个集群。在这个集群里面，服务器之间通过二层互通，这个区域成为一个POD(Point of Delivery)， 又称为可用区(Available Zone). </p><p>当节点数目再多的时候，一个可用区放不下，需要将多个可用区连在一起，连接多个可用区的交换机称为核心交换机。</p><p><img src="https://i.loli.net/2020/02/02/GcgNHiBLT9OUey1.jpg" alt="fig4.jpg"></p><p><img src="https://i.loli.net/2020/02/02/G2qbpI8MNBdTCVr.jpg" alt="fig5.jpg"></p><h1 id="2-VPN"><a href="#2-VPN" class="headerlink" title="2. VPN"></a>2. VPN</h1><p><img src="https://i.loli.net/2020/02/02/qwKnYlM3y4saCHr.jpg" alt="fig6.jpg"></p><p>VPN(Virtual Private Network)， 虚拟专用网，就是利用开放的公众网络，建立专用数据传输通道，将远程的分支机构、移动办公人员连接起来。</p><h2 id="2-1-VPN是如何工作的"><a href="#2-1-VPN是如何工作的" class="headerlink" title="2.1 VPN是如何工作的"></a>2.1 VPN是如何工作的</h2><p>VPN通过隧道技术在公众网络上仿真一条点到点的专线，是通过一种协议来传输另外一种协议的技术：这里面涉及三种协议：乘客协议、隧道协议、承载协议。</p><p>以IPsec协议为例说明</p><p><img src="https://i.loli.net/2020/02/02/3rCDzlsnipXjH8A.jpg" alt="fig7.jpg"></p><p>IPsec VPN, 是基于IP协议的安全隧道协议，为了保证在公网上信息的安全，因而采取了一定的机制保证安全性。</p><h2 id="2-2-VPN-采取的保证安全的机制"><a href="#2-2-VPN-采取的保证安全的机制" class="headerlink" title="2.2 VPN 采取的保证安全的机制"></a>2.2 VPN 采取的保证安全的机制</h2><ol><li>私密性</li></ol><p>通过加密把数据从明文编程无法读懂的密文，从而确保数据的私密性。采用对称加密， 因为VPN一旦建立，是需要传输大量数据的。</p><p>存在加密密钥如何传输的问题，这里需要用到因特网密钥交换协议(IKE, Internet Key Exchange)。</p><ol start="2"><li>完整性</li></ol><p>数据没有被非法篡改，通过对数据进行hash运算，产生类似于指纹的数据摘要，以保证数据的完整性</p><ol start="3"><li>真实性</li></ol><p>数据确实是由特定的对端发出，通过身份认证可以保证数据的真实性。</p><ol start="4"><li>保证对方真实的方式</li></ol><ul><li>预共享秘钥</li><li>数字签名验证</li></ul><h2 id="2-3-IPsec-VPN协议"><a href="#2-3-IPsec-VPN协议" class="headerlink" title="2.3 IPsec VPN协议"></a>2.3 IPsec VPN协议</h2><p><img src="https://i.loli.net/2020/02/02/PXUnhNDlZmbHi6L.jpg" alt="fig8.jpg"></p><p>在这个协议族里面，有两种协议，区别在于封装网络 包的格式不一样。</p><ul><li>AH(Authentication Header)，只能进行数据摘要，不能实现数据加密</li><li>ESP(Encapsulating Security Payload), 能够进行数据加密和数据摘要</li></ul><p>在这个协议族里，有加密算法和摘要算法。包含了两大组件，一个用于VPN的双方要进行对称密钥交换的IKE组件，另一个是VPN的双方要对连接进行维护的SA(Security Association) 组件。</p><h2 id="2-4-IPsec-VPN-建立过程"><a href="#2-4-IPsec-VPN-建立过程" class="headerlink" title="2.4 IPsec VPN 建立过程"></a>2.4 IPsec VPN 建立过程</h2><h3 id="2-4-1-建立IKE自己的SA-Security-Association"><a href="#2-4-1-建立IKE自己的SA-Security-Association" class="headerlink" title="2.4.1 建立IKE自己的SA(Security Association)"></a>2.4.1 建立IKE自己的SA(Security Association)</h3><p>用来维护一个通过身份认证和安全保护的通道，为第二个阶段提供服务。通过DH(Diffie-Hellman)算法计算出一个对称密钥K。</p><p>DH算法很巧妙。客户端和服务端约定两个公开的质数p和q，然后客户端随机产生一个数a作为自己的私钥，服务端随机产生一个b作为自己的私钥，客户端可以根据p q a计算出公钥A，服务端根据p，q，b计算出公钥B，然后双方交换公钥A和B。</p><p>至此客户端和服务e端可以根据已有信息，各自独立算出相同的结果K，就是对称密钥。但是这个过程当中，对称密钥从来没有在通道上传输过，只传输了生成密钥的材料。截获的人根本无法算出到底是生成了什么数字。</p><p><img src="https://i.loli.net/2020/02/02/mowAje5ZFLitCfJ.jpg" alt="fig9.jpg"></p><h3 id="2-4-2-建立IPsec-SA"><a href="#2-4-2-建立IPsec-SA" class="headerlink" title="2.4.2 建立IPsec SA"></a>2.4.2 建立IPsec SA</h3><p>在这个SA里面，双方会生成一个随机的对称密钥M，由K加密传给对方，然后使用M进行双方接下来通信的数据。对称密钥M是有过期时间的，会过一段时间，重新生成一次，从而防止被破解。</p><p>IPsec SA 里面有以下内容：</p><ul><li>SPI(Security Parameter Index),用于标识不同的连接</li><li>双方商量好的加密算法，哈希算法和封装算法</li><li>生存周期，超过这个周期，就要重新生成一个IPsec SA，重新生成对称密钥</li></ul><p><img src="https://i.loli.net/2020/02/02/RfP8cp4zw9KT27G.jpg" alt="fig10.jpg"></p><p>当IPsec建立好，接下来就可以开始打包封装传输了。</p><p><img src="https://i.loli.net/2020/02/02/NlPSm6hzrvQxAcj.jpg" alt="fig11.jpg"></p><p>左面是原始的 IP 包，在 IP 头里面，会指定上一层的协议为 TCP。ESP 要对 IP 包进行封装，因而 IP 头里面的上一层协议为 ESP。在 ESP 的正文里面，ESP 的头部有双方商讨好的 SPI，以及这次传输的序列号。</p><p>接下来全部是加密的内容。可以通过对称密钥进行解密，解密后在正文的最后，指明了里面的协议是什么。如果是 IP，则需要先解析 IP 头，然后解析 TCP 头，这是从隧道出来后解封装的过程。</p><p>有了 IPsec VPN 之后，客户端发送的明文的 IP 包，都会被加上 ESP 头和 IP 头，在公网上传输，由于加密，可以保证不被窃取，到了对端后，去掉 ESP 的头，进行解密。</p><p><img src="https://i.loli.net/2020/02/02/muPYyMVGEKWLFz6.jpg" alt="fig12.jpg"></p><p>这种点对点的基于 IP 的 VPN，能满足互通的要求，但是速度往往比较慢，这是由底层 IP 协议的特性决定的。IP 不是面向连接的，是尽力而为的协议，每个 IP 包自由选择路径，到每一个路由器，都自己去找下一跳，丢了就丢了，是靠上一层 TCP 的重发来保证可靠性。</p><p><img src="https://i.loli.net/2020/02/02/TSRuA7tq8eLphHZ.jpg" alt="fig13.jpg"></p><p>因为 IP 网络从设计的时候，就认为是不可靠的，所以即使同一个连接，也可能选择不同的道路，这样的好处是，一条道路崩溃的时候，总有其他的路可以走。当然，带来的代价就是，不断的路由查找，效率比较差。</p><p>和 IP 对应的另一种技术称为 ATM。这种协议和 IP 协议的不同在于，它是面向连接的。你可以说 TCP 也是面向连接的啊。这两个不同，ATM 和 IP 是一个层次的，和 TCP 不是一个层次的。</p><p>另外，TCP 所谓的面向连接，是不停地重试来保证成功，其实下层的 IP 还是不面向连接的，丢了就丢了。ATM 是传输之前先建立一个连接，形成一个虚拟的通路，一旦连接建立了，所有的包都按照相同的路径走，不会分头行事。</p><p><img src="https://i.loli.net/2020/02/02/u36xtoN72KkBGQZ.jpg" alt="fig14.jpg"></p><p>ATM的好处是不需要每次都查路由表了，虚拟路径已经建立，打上了标签，后续的包跟着走就可以了；但是一旦虚拟路径上的某个路由器坏了，那么这个连接就断了.</p><h2 id="2-4-3-多协议标签交换-MPLS-Multi-Protocol-Label-Switching"><a href="#2-4-3-多协议标签交换-MPLS-Multi-Protocol-Label-Switching" class="headerlink" title="2.4.3 多协议标签交换(MPLS, Multi-Protocol Label Switching)"></a>2.4.3 多协议标签交换(MPLS, Multi-Protocol Label Switching)</h2><p>这种协议可以结合IP和ATM协议的优点，其结构是在原始的IP头之外，多了MPLS的头，里面可以打标签。</p><p><img src="https://i.loli.net/2020/02/02/WxC8o6wYshu1bSJ.jpg" alt="fig15.jpg"></p><p>在 MPLS 头里面，首先是标签值占 20 位，接着是 3 位实验位，再接下来是 1 位栈底标志位，表示当前标签是否位于栈底了。这样就允许多个标签被编码到同一个数据包中，形成标签栈。最后是 8 位 TTL 存活时间字段，如果标签数据包的出发 TTL 值为 0，那么该数据包在网络中的生命期被认为已经过期了。</p><p>有了标签，还需要设备认这个标签，并且能够根据这个标签转发，这种能够转发标签的路由器称为标签交换路由器(LSR, Label Switching Router).</p><p>这种路由器会有两个表格，一个是传统的FIB，路由表，另外一个就是LFIB，标签转发表。有着这两个表，就既可以进行普通的路由转发，也可以进行基于标签的转发。</p><p><img src="https://i.loli.net/2020/02/02/p2WM8XwjtuLRxNn.jpg" alt="fig16.jpg"></p><p>有了标签转发表，转发的过程如图所示，不需要每次都进行普通路由的查找了。</p><p>这里我们区分 MPLS 区域和非 MPLS 区域。在 MPLS 区域中间，使用标签进行转发，非 MPLS 区域，使用普通路由转发，在边缘节点上，需要有能力将对于普通路由的转发，变成对于标签的转发。</p><p>例如图中要访问 114.1.1.1，在边界上查找普通路由，发现马上要进入 MPLS 区域了，进去了对应标签 1，于是在 IP 头外面加一个标签 1，在区域里面，标签 1 要变成标签 3，标签 3 到达出口边缘，将标签去掉，按照路由发出。</p><p>这样一个通过标签转化而建立的路径称为LSP，标签交换路径。在一条LSP上，沿数据包传送的方向，相邻的LSR分别叫做上游LSR(upstream LSR), 和下游LSR(downstream LSR).</p><p>MPLS有个动态生成标签的协议, LDP(Label Distribution Protocol)。 其实 LDP 与 IP 帮派中的路由协议十分相像，通过 LSR 的交互，互相告知去哪里应该打哪个标签，称为标签分发，往往是从下游开始的。</p><p><img src="https://i.loli.net/2020/02/02/dVlJvoAQfKLSwsb.jpg" alt="fig17.jpg"></p><p>如果有一个边缘节点发现自己的路由表中出现了新的目的地址，它就要给别人说，我能到达一条新的路径了。</p><p>如果此边缘节点存在上游 LSR，并且尚有可供分配的标签，则该节点为新的路径分配标签，并向上游发出标签映射消息，其中包含分配的标签等信息。</p><p>收到标签映射消息的 LSR 记录相应的标签映射信息，在其标签转发表中增加相应的条目。此 LSR 为它的上游 LSR 分配标签，并继续向上游 LSR 发送标签映射消息。</p><p>当入口 LSR 收到标签映射消息时，在标签转发表中增加相应的条目。这时，就完成了 LSP 的建立。有了标签，转发轻松多了，但是这个和 VPN 什么关系呢？</p><p>可以想象，如果我们 VPN 通道里面包的转发，都是通过标签的方式进行，效率就会高很多。所以要想个办法把 MPLS 应用于 VPN。</p><p><img src="https://i.loli.net/2020/02/02/9F5D3xSad7PzhYw.jpg" alt="fig18.jpg"></p><p>在MPLS VPN中，网络中的路由器分成以下几类：</p><ul><li>PE (Provider Edge): 运营商网络与客户网络相连的边缘网络设备</li><li>CE (Customer Edge): 客户网络与PE相连接的边缘设备</li><li>P (Provider): 指运营商网络中除了PE以外的其他运营商网络设备</li></ul><p>为什么要这样分呢？因为我们发现，在运营商网络里面，也即 P Router 之间，使用标签是没有问题的，因为都在运营商的管控之下，对于网段，路由都可以自己控制。但是一旦客户要接入这个网络，就复杂得多。</p><p>首先是客户地址重复的问题。客户所使用的大多数都是私网的地址 (192.168.X.X;10.X.X.X;172.X.X.X)，而且很多情况下都会与其它的客户重复。</p><p>比如，机构 A 和机构 B 都使用了 192.168.101.0/24 网段的地址，这就发生了地址空间重叠（Overlapping Address Spaces）。</p><p>首先困惑的是 BGP 协议，既然 VPN 将两个数据中心连起来，应该看起来像一个数据中心一样，那么如何到达另一端需要通过 BGP 将路由广播过去，传统 BGP 无法正确处理地址空间重叠的 VPN 的路由。</p><p>假设机构 A 和机构 B 都使用了 192.168.101.0/24 网段的地址，并各自发布了一条去往此网段的路由，BGP 将只会选择其中一条路由，从而导致去往另一个 VPN 的路由丢失。</p><p>所以 PE 路由器之间使用特殊的 MP-BGP 来发布 VPN 路由，在相互沟通的消息中，在一般 32 位 IPv4 的地址之前加上一个客户标示的区分符用于客户地址的区分，这种称为 VPN-IPv4 地址族，这样 PE 路由器会收到如下的消息，机构 A 的 192.168.101.0/24 应该往这面走，机构 B 的 192.168.101.0/24 则应该去另外一个方向。</p><p>另外一个困惑是路由表，当两个客户的IP包到达PE的时候，PE就困惑了，因为网段是重复的。如何区分哪些路由是属于哪些客户 VPN 内的？如何保证 VPN 业务路由与普通路由不相互干扰？</p><p>在 PE 上，可以通过 VRF（VPN Routing&amp;Forwarding Instance）建立每个客户一个路由表，与其它 VPN 客户路由和普通路由相互区分。可以理解为专属于客户的小路由器。</p><p>远端 PE 通过 MP-BGP 协议把业务路由放到近端 PE，近端 PE 根据不同的客户选择出相关客户的业务路由放到相应的 VRF 路由表中。</p><p>VPN报文转发采用两层标签的方式：</p><ul><li>第一层（外层）标签在骨干网内部进行交换，指示从 PE 到对端 PE 的一条 LSP。VPN 报文利用这层标签，可以沿 LSP 到达对端 PE；</li><li>第二层（内层）标签在从对端 PE 到达 CE 时使用，在 PE 上，通过查找 VRF 表项，指示报文应被送到哪个 VPN 用户，或者更具体一些，到达哪一个 CE。这样，对端 PE 根据内层标签可以找到转发报文的接口。</li></ul><p><img src="https://i.loli.net/2020/02/02/fTPFVvbBgOxsqE5.jpg" alt="fig19.jpg"></p><p>举例说明MPLS VPN的包发送过程</p><ol><li>机构 A 和机构 B 都发出一个目的地址为 192.168.101.0/24 的 IP 报文，分别由各自的 CE 将报文发送至 PE。</li><li>PE 会根据报文到达的接口及目的地址查找 VPN 实例表项 VRF，匹配后将报文转发出去，同时打上内层和外层两个标签。假设通过 MP-BGP 配置的路由，两个报文在骨干网走相同的路径。</li><li>MPLS 网络利用报文的外层标签，将报文传送到出口 PE，报文在到达出口 PE 2 前一跳时已经被剥离外层标签，仅含内层标签。</li><li>出口 PE 根据内层标签和目的地址查找 VPN 实例表项 VRF，确定报文的出接口，将报文转发至各自的 CE。</li><li>CE 根据正常的 IP 转发过程将报文传送到目的地。</li></ol><h1 id="3-移动网络"><a href="#3-移动网络" class="headerlink" title="3. 移动网络"></a>3. 移动网络</h1><p>研究下手机上网的场景：</p><h2 id="3-1-2G网络"><a href="#3-1-2G网络" class="headerlink" title="3.1 2G网络"></a>3.1 2G网络</h2><p>2G时代上网不是使用的IP网络，而是电话网络，走模拟信号，叫做公共交换电话网(PSTN, Public Switched Telephone Network)</p><p>手机通过收发无线信号来通信，成为Mobile Station， 简称MS，需要嵌入SIM。手机是客户端，而无线信号的服务端，就是基站子系统(BBS, Base Station SubsystemBSS).</p><blockquote><p>无论无线通信如何无线，最终还要连接到有线网络里。</p></blockquote><p>因而，基站子系统分两部分，一部分对外提供无线通信，叫作基站收发信台（BTS，Base Transceiver Station），另一部分对内连接有线网络，叫作基站控制器（BSC，Base Station Controller）。基站收发信台通过无线收到数据后，转发给基站控制器。</p><p>这部分属于无线的部分，统称为无线接入网（RAN，Radio Access Network）。</p><p>基站控制器通过有线网络，连接到提供手机业务的运营商的数据中心，这部分称为核心网（CN，Core Network）。核心网还没有真的进入互联网，这部分还是主要提供手机业务，是手机业务的有线部分。</p><p>首先接待基站来的数据的是移动业务交换中心（MSC，Mobile Service Switching Center），它是进入核心网的入口，但是它不会让你直接连接到互联网上。</p><p>因为在让你的手机真正进入互联网之前，提供手机业务的运营商，需要认证是不是合法的手机接入。别你自己造了一张手机卡，就连接上来。鉴权中心（AUC，Authentication Center）和设备识别寄存器（EIR，Equipment Identity Register）主要是负责安全性的。</p><p>另外，需要看你是本地的号，还是外地的号，这个牵扯到计费的问题，异地收费还是很贵的。访问位置寄存器（VLR，Visit Location Register）是看你目前在的地方，归属位置寄存器（HLR，Home Location Register）是看你的号码归属地。</p><p>当你的手机卡既合法又有钱的时候，才允许你上网，这个时候需要一个网关，连接核心网和真正的互联网。网关移动交换中心（GMSC ，Gateway Mobile Switching Center）就是干这个的，然后是真正的互连网。在 2G 时代，还是电话网络 PSTN。</p><p>数据中心里的这些模块统称为网络子系统(NSS, Network and Switching Subsystem)</p><p><img src="https://i.loli.net/2020/02/02/SOJQsF8LxMjBkia.jpg" alt="fig20.jpg"></p><p>2G时代的上网，有几个核心点：</p><ul><li>手机通过无线信号连接基站；</li><li>基站一面朝前接无线，一面朝后接核心网；</li><li>核心网一面朝前接到基站请求，一是判断你是否合法，二是判断你是不是本地号，还有没有钱，一面通过网关连接电话网络。</li></ul><h2 id="3-2-2-5G网络"><a href="#3-2-2-5G网络" class="headerlink" title="3.2 2.5G网络"></a>3.2 2.5G网络</h2><p>后来从 2G 到了 2.5G，也即在原来电路交换的基础上，加入了分组交换业务，支持 Packet 的转发，从而支持 IP 网络。</p><p>在上述网络的基础上，基站一面朝前接无线，一面朝后接核心网。在朝后的组件中，多了一个分组控制单元（PCU，Packet Control Unit），用以提供分组交换通道。</p><p>在核心网里面，有个朝前的接待员（SGSN，Service GPRS Supported Node）和朝后连接 IP 网络的网关型 GPRS 支持节点（GGSN，Gateway GPRS Supported Node）。</p><p><img src="https://i.loli.net/2020/02/02/6G2FysU1h7YvZNr.jpg" alt="fig21.jpg"></p><h2 id="3-3-3G网络"><a href="#3-3-3G网络" class="headerlink" title="3.3 3G网络"></a>3.3 3G网络</h2><p>到了 3G 时代，主要是无线通信技术有了改进，大大增加了无线的带宽。</p><p>以 W-CDMA 为例，理论最高 2M 的下行速度，因而基站改变了，一面朝外的是 Node  B，一面朝内连接核心网的是无线网络控制器（RNC，Radio Network Controller）。核心网以及连接的 IP 网络没有什么变化。</p><p><img src="https://i.loli.net/2020/02/02/3oOgzejCiLG86Sk.jpg" alt="fig22.jpg"></p><h2 id="3-4-4G网络"><a href="#3-4-4G网络" class="headerlink" title="3.4 4G网络"></a>3.4 4G网络</h2><p><img src="https://i.loli.net/2020/02/02/vAWC6fOwgQmSa37.jpg" alt="fig30.jpg"></p><p>4G网络的协议相对复杂了很多：</p><p><img src="https://i.loli.net/2020/02/02/pJBhu8y2LR6FSrV.jpg" alt="fig23.jpg"></p><h3 id="3-4-1-控制面协议"><a href="#3-4-1-控制面协议" class="headerlink" title="3.4.1 控制面协议"></a>3.4.1 控制面协议</h3><p>其中虚线部分是控制面的协议。当一个手机想上网的时候，先要连接 eNodeB，并通过 S1-MME 接口，请求 MME 对这个手机进行认证和鉴权。S1-MME 协议栈如下图所示。</p><p><img src="https://i.loli.net/2020/02/02/LCZHKxFuf1tJbBd.jpg" alt="fig24.jpg"></p><p>UE是手机，eNodeB朝前对接无线网络，朝后对接核心网络，在控制面对接的是MME。</p><p>eNode与MME之间的连接是靠IP网络，而在IP层上，是用的SCTP。这是面向连接的传输层的协议，更适合移动网络。继承了TCP较为完善的拥塞控制，并改进了TCP的不足之处。</p><p>SCTP特点是多宿主，引入了联合的概念，将多个接口、多条路径放到一个association当中，当检测到一条路径失效时，协议就会从另外一条路径来发送通信数据。应用程序甚至不必知道发生了故障和恢复，从而提供更高的可用性和可靠性。</p><p>SCTP还可以将一个联合分成多个流。一个联合中的所有流都是独立的，但均与这个联合相关。每个流都给定了一个流编号，被编码到SCTP报文当中，通过联合在网络上传送。在TCP的机制当中，由于强制顺序，导致前一个不到达，后一个就得等待，SCTP的多个流不会相互阻塞。</p><p>SCP还可以进行四次握手，防止 SYN 攻击。在 TCP 中是三次握手，当服务端收到客户的 SYN 之后，返回一个 SYN-ACK 之前，就建立数据结构，并记录下状态，等待客户端发送 ACK 的 ACK。当恶意客户端使用虚假的源地址来伪造大量 SYN 报文时，服务端需要分配大量的资源，最终耗尽资源，无法处理新的请求。</p><p>SCTP 可以通过四次握手引入 Cookie 的概念，来有效地防止这种攻击的产生。在 SCTP 中，客户机使用一个 INIT 报文发起一个连接。服务器使用一个 INIT-ACK 报文进行响应，其中就包括了 Cookie。然后客户端就使用一个 COOKIE-ECHO 报文进行响应，其中包含了服务器所发送的 Cookie。这个时候，服务器为这个连接分配资源，并通过向客户机发送一个 COOKIE-ACK 报文对其进行响应。</p><p>SCTP还可以对信息进行分帧。TCP是面向流的，即发送的数据没头没尾，没有明显的界限。这对于发送数据没有什么大问题，但是对于发送一个个消息类型的数据，就不太方便了。有可能客户端写入10个字节，再写入20个。服务端不是按照10-20来读的，而是先25个字节，再读入5个字节，需要业务层去组合成消息。</p><p>SCTP借鉴了UDP的机制，在数据传输中提供了消息分帧功能。当一端对一个套接字执行写操作时，可确保对等端读出的数据大小与此相同。 </p><p>SCTP在断开连接的时候是三次挥手。在TCP里面，断开连接是四次挥手，云溪另一端处于半关闭的状态。SCTP选择放弃这种状态，当一端关闭自己的套接字的时候，对等的两端全部需要关闭，将来任何一端都不允许再进行数据的移动了。</p><p>当 MME 通过认证鉴权，同意这个手机上网的时候，需要建立一个数据面的数据通路。建立通路的过程还是控制面的事情，因而使用的是控制面的协议 GTP-C。</p><p>建设的数据通路分两段路，其实是两个隧道。一段是从 eNodeB 到 SGW，这个数据通路由 MME 通过 S1-MME 协议告诉 eNodeB，它是隧道的一端，通过 S11 告诉 SGW，它是隧道的另一端。第二端是从 SGW 到 PGW，SGW 通过 S11 协议知道自己是其中一端，并主动通过 S5 协议，告诉 PGW 它是隧道的另一端。</p><p>GTP-C协议是基于UDP的，如果看GTP的头，可以看到里面有隧道的ID还有序列号。 </p><p><img src="https://i.loli.net/2020/02/02/wHfyhS7pLVe1RQl.jpg" alt="fig25.jpg"></p><h3 id="3-4-2-数据面协议"><a href="#3-4-2-数据面协议" class="headerlink" title="3.4.2 数据面协议"></a>3.4.2 数据面协议</h3><p>当两个隧道都打通，接在一起的时候，PGW 会给手机分配一个 IP 地址，这个 IP 地址是隧道内部的 IP 地址，可以类比为 IPsec 协议里面的 IP 地址。这个 IP 地址是归手机运营商管理的。然后，手机可以使用这个 IP 地址，连接 eNodeB，从 eNodeB 经过 S1-U 协议，通过第一段隧道到达 SGW，再从 SGW 经过 S8 协议，通过第二段隧道到达 PGW，然后通过 PGW 连接到互联网。</p><p>数据面的协议通过GTP-U, 如图所示：</p><p><img src="https://i.loli.net/2020/02/02/4eWXgcECuIbB3qk.jpg" alt="fig26.jpg"></p><p>手机每发出一个包，都由GTP-U隧道协议封装起来：</p><p><img src="https://i.loli.net/2020/02/02/WIgOKsLhw7tRpX8.jpg" alt="fig27.jpg"></p><p>和 IPsec 协议很类似，分为乘客协议、隧道协议、承载协议。其中乘客协议是手机发出来的包，IP 是手机的 IP，隧道协议里面有隧道 ID，不同的手机上线会建立不同的隧道，因而需要隧道 ID 来标识。承载协议的 IP 地址是 SGW 和 PGW 的 IP 地址。</p><h3 id="3-4-3-手机上网流程"><a href="#3-4-3-手机上网流程" class="headerlink" title="3.4.3 手机上网流程"></a>3.4.3 手机上网流程</h3><p>Attach:</p><p><img src="https://i.loli.net/2020/02/02/hwtE7aFNjqgSOCu.jpg" alt="fig28.jpg"></p><ol><li>手机开机以后，在附近寻找基站 eNodeB，找到后给 eNodeB 发送 Attach Request，说“我来啦，我要上网”。</li><li>eNodeB 将请求发给 MME，说“有个手机要上网”。</li><li>MME 去请求手机，一是认证，二是鉴权，还会请求 HSS 看看有没有钱，看看是在哪里上网。</li><li>当 MME 通过了手机的认证之后，开始分配隧道，先告诉 SGW，说要创建一个会话（Create Session）。在这里面，会给 SGW 分配一个隧道 ID  t1，并且请求 SGW 给自己也分配一个隧道 ID。</li><li>SGW 转头向 PGW 请求建立一个会话，为 PGW 的控制面分配一个隧道 ID  t2，也给 PGW 的数据面分配一个隧道 ID  t3，并且请求 PGW 给自己的控制面和数据面分配隧道 ID。</li><li>PGW 回复 SGW 说“创建会话成功”，使用自己的控制面隧道 ID t2，回复里面携带着给 SGW 控制面分配的隧道 ID  t4 和控制面的隧道 ID  t5，至此 SGW 和 PGW 直接的隧道建设完成。双方请求对方，都要带着对方给自己分配的隧道 ID，从而标志是这个手机的请求。</li><li>接下来 SGW 回复 MME 说“创建会话成功”，使用自己的隧道 ID  t1 访问 MME，回复里面有给 MME 分配隧道 ID  t6，也有 SGW 给 eNodeB 分配的隧道 ID  t7。</li><li>当 MME 发现后面的隧道都建设成功之后，就告诉 eNodeB，“后面的隧道已经建设完毕，SGW 给你分配的隧道 ID 是 t7，你可以开始连上来了，但是你也要给 SGW 分配一个隧道 ID”。</li><li>eNodeB 告诉 MME 自己给 SGW 分配一个隧道，ID 为 t8。</li><li>MME 将 eNodeB 给 SGW 分配的隧道 ID  t8 告知 SGW，从而前面的隧道也建设完毕。</li></ol><h3 id="3-4-4-异地上网问题"><a href="#3-4-4-异地上网问题" class="headerlink" title="3.4.4 异地上网问题"></a>3.4.4 异地上网问题</h3><p>为什么要分 SGW 和 PGW 呢，一个 GW 不可以吗？SGW 是你本地的运营商的设备，而 PGW 是你所属的运营商的设备。如果你在巴塞罗那，一下飞机，手机开机，周围搜寻到的肯定是巴塞罗那的 eNodeB。通过 MME 去查寻国内运营商的 HSS，看你是否合法，是否还有钱。如果允许上网，你的手机和巴塞罗那的 SGW 会建立一个隧道，然后巴塞罗那的 SGW 和国内运营商的 PGW 建立一个隧道，然后通过国内运营商的 PGW 上网。</p><p><img src="https://i.loli.net/2020/02/02/baY14UCmQ6ZkjOs.jpg" alt="fig29.jpg"></p><p>这样判断你是否能上网的在国内运营商的 HSS，控制你上网策略的是国内运营商的 PCRF，给手机分配的 IP 地址也是国内运营商的 PGW 负责的，给手机分配的 IP 地址也是国内运营商里统计的。运营商由于是在 PGW 里面统计的，这样你的上网流量全部通过国内运营商即可，只不过巴塞罗那运营商也要和国内运营商进行流量结算。</p><p>由于你的上网策略是由国内运营商在 PCRF 中控制的，因而你还是上不了脸书。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Data Center </tag>
            
            <tag> VPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(七)-流媒体协议(网络直播当中的视频压缩与传播问题)</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%83-%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE-%E7%BD%91%E7%BB%9C%E7%9B%B4%E6%92%AD%E5%BD%93%E4%B8%AD%E7%9A%84%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E4%B8%8E%E4%BC%A0%E6%92%AD%E9%97%AE%E9%A2%98/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%83-%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE-%E7%BD%91%E7%BB%9C%E7%9B%B4%E6%92%AD%E5%BD%93%E4%B8%AD%E7%9A%84%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E4%B8%8E%E4%BC%A0%E6%92%AD%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="1-视频压缩"><a href="#1-视频压缩" class="headerlink" title="1. 视频压缩"></a>1. 视频压缩</h1><p>网络直播,视频压缩是一个很关键的技术，因为假设每一张图片大小为1024 * 768，每个像素由RGB组成，其中每个占8位，共24位。那么每秒钟的视频大小为：</p><p>30帧 x 1024 x 768 x 24 = 70,778,880 Bytes<br>如果一分钟的视频，就已经是4个G了。</p><p>解决的方式是编码，通过对图片的压缩，使播放的时候画面看起来仍然足够精美。</p><h2 id="1-1-视频和图片压缩过程特征"><a href="#1-1-视频和图片压缩过程特征" class="headerlink" title="1.1 视频和图片压缩过程特征"></a>1.1 视频和图片压缩过程特征</h2><h3 id="1-1-1-空间冗余"><a href="#1-1-1-空间冗余" class="headerlink" title="1.1.1 空间冗余"></a>1.1.1 空间冗余</h3><p>图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，没必要每个像素都完整地保存，可以隔几个保存一个，中间的用算法计算出来。</p><h3 id="1-1-2-时间冗余"><a href="#1-1-2-时间冗余" class="headerlink" title="1.1.2 时间冗余"></a>1.1.2 时间冗余</h3><p>视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根据已有的图片进行预测和推断。</p><h3 id="1-1-3-视觉冗余"><a href="#1-1-3-视觉冗余" class="headerlink" title="1.1.3 视觉冗余"></a>1.1.3 视觉冗余</h3><p>人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数据。</p><h3 id="1-1-4-编码冗余"><a href="#1-1-4-编码冗余" class="headerlink" title="1.1.4 编码冗余"></a>1.1.4 编码冗余</h3><p>不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多</p><p>整个压缩过程如下图所示：</p><p><img src="https://i.loli.net/2020/02/02/s1dCD9uOXyP7t4E.jpg" alt="fig1.jpg"></p><h2 id="1-2-视频编码的两大种类-流派"><a href="#1-2-视频编码的两大种类-流派" class="headerlink" title="1.2 视频编码的两大种类/ 流派"></a>1.2 视频编码的两大种类/ 流派</h2><h3 id="1-2-1-ITU-International-Telecommunications-Union"><a href="#1-2-1-ITU-International-Telecommunications-Union" class="headerlink" title="1.2.1 ITU International Telecommunications Union"></a>1.2.1 ITU International Telecommunications Union</h3><p>VCEG(Video Conding Experts Group),视频编码，侧重于传输</p><h3 id="1-2-2-ISO-International-Standards-Organization"><a href="#1-2-2-ISO-International-Standards-Organization" class="headerlink" title="1.2.2 ISO International Standards Organization"></a>1.2.2 ISO International Standards Organization</h3><p>MPEG(Moving Picture Experts Group)，视频存储</p><h2 id="1-2-网络直播"><a href="#1-2-网络直播" class="headerlink" title="1.2 网络直播"></a>1.2 网络直播</h2><p>网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的服务端来接收这些网络包，从而得到里面的视频流。</p><p>服务端接到视频流以后，对视频流进行转码，保证用各种客户端都能看到直播。</p><p>如果有非常多的观众，同时看一个视频直播，都从一个服务器上拉流，压力太大了，因而需要一个视频的分发网络，将视频预先加载到就近的边缘节点，来降低服务器的压力。</p><p><img src="https://i.loli.net/2020/02/02/CqdINFefH17Pvph.jpg" alt="fig2.jpg"></p><h2 id="1-3-视频图片压缩过程详解"><a href="#1-3-视频图片压缩过程详解" class="headerlink" title="1.3 视频图片压缩过程详解"></a>1.3 视频图片压缩过程详解</h2><h3 id="1-3-1-编码"><a href="#1-3-1-编码" class="headerlink" title="1.3.1 编码"></a>1.3.1 编码</h3><p>会将视频序列分为三种帧，来分别进行压缩行为：</p><ul><li>I 帧</li></ul><p>也称关键帧。里面是完整的图片，只需要本帧数据，就可以完成解码。</p><ul><li>P 帧</li></ul><p>前向预测编码帧。P 帧表示的是这一帧跟之前的一个关键帧（或 P 帧）的差别，解码时需要用之前缓存的画面，叠加上和本帧定义的差别，生成最终画面。</p><ul><li>B 帧</li></ul><p>双向预测内插编码帧。B 帧记录的是本帧与前后帧的差别。要解码 B 帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的数据与本帧数据的叠加，取得最终的画面。</p><p>可以看出，I 帧最完整，B 帧压缩率最高，而压缩后帧的序列，应该是在 IBBP 的间隔出现的。这就是通过时序进行编码</p><p><img src="https://i.loli.net/2020/02/02/yS8dkhIKF5Xaf3w.jpg" alt="fig3.jpg"></p><p>在一帧中，分成多个片，每个片中分成多个宏块，每个宏块分成多个子块，这样将一张大的图分解成一个个小块，可以方便进行空间上的编码。</p><p>帧 -&gt; 片 -&gt; 宏块 -&gt; 子块</p><p>编码后的整个序列是要压缩为一个二进制流在网络上传播的，因此需要分割成一个个网络提取单元(NALU, network abstraction layer unit). </p><p><img src="https://i.loli.net/2020/02/02/dMZ329Vrgj6ynex.jpg" alt="fig4.jpg"></p><p>每一个 NALU 首先是一个起始标识符，用于标识 NALU 之间的间隔；然后是 NALU 的头，里面主要配置了 NALU 的类型；最终 Payload 里面是 NALU 承载的数据。</p><p>在 NALU 头里面，主要的内容是类型NAL Type.</p><ul><li>0x07 表示 SPS，是序列参数集， 包括一个图像序列的所有信息，如图像尺寸、视频格式等。</li><li>0x08 表示 PPS，是图像参数集，包括一个图像的所有分片的所有相关信息，包括图像类型、序列号等。</li><li>在传输视频流之前，必须要传输这两类参数，不然无法解码。为了保证容错性，每一个 I 帧前面，都会传一遍这两个参数集合。</li></ul><p>如果 NALU Header 里面的表示类型是 SPS 或者 PPS，则 Payload 中就是真正的参数集的内容。</p><p>如果类型是帧，则 Payload 中才是正的视频数据，当然也是一帧一帧存放的，前面说了，一帧的内容还是挺多的，因而每一个 NALU 里面保存的是一片。对于每一片，到底是 I 帧，还是 P 帧，还是 B 帧，在片结构里面也有个 Header，这里面有个类型，然后是片的内容。</p><p><strong>一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，在每一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列</strong></p><h3 id="1-3-2-推流"><a href="#1-3-2-推流" class="headerlink" title="1.3.2 推流"></a>1.3.2 推流</h3><p>需要将这个二进制流打包成网络包进行发送，一般使用RTMP协议。</p><p>RTMP协议是基于TCP的，因此肯定需要双方建立一个TCP的连接。在有TCP的连接的基础上，还需要建立一个RTMP的连接，即在程序当中，需要调用RTMP类库的Connect函数显示创建一个连接。</p><p>RTMP需要单独一个连接的原因在于：双方需要互相知道版本号，时间戳(看时间戳的差值)</p><p>未来沟通这些事情，需要发送六条消息：客户端发送 C0、C1、  C2，服务器发送 S0、  S1、  S2。首先，客户端发送 C0 表示自己的版本号，不必等对方的回复，然后发送 C1 表示自己的时间戳。服务器只有在收到 C0 的时候，才能返回 S0，表明自己的版本号，如果版本不匹配，可以断开连接。<br>服务器发送完 S0 后，也不用等什么，就直接发送自己的时间戳 S1。客户端收到 S1 的时候，发一个知道了对方时间戳的 ACK  C2。同理服务器收到 C1 的时候，发一个知道了对方时间戳的 ACK  S2。<br>握手完成。</p><p><img src="https://i.loli.net/2020/02/02/4DgIibdfYF9xmPl.jpg" alt="fig5.jpg"></p><p>握手之后，双方需要互相传递一些控制信息，比如Chunk块的大小，窗口大小等。真正传输数据的时候，还是需要创建一个流Stream，然后通过这个Stream来推流publish。 </p><p>推流的过程，就是将NALU放在message里面发送，称为RTMP Packet包。格式如下图所示：</p><p><img src="https://i.loli.net/2020/02/02/id8BeJZkDrVbpQX.jpg" alt="fig6.jpg"></p><p>发送的时候，去掉 NALU 的起始标识符。因为这部分对于 RTMP 协议来讲没有用。接下来，将 SPS 和 PPS 参数集封装成一个 RTMP 包发送，然后发送一个个片的 NALU。</p><p>RTMP 在收发数据的时候并不是以 Message 为单位的，而是把 Message 拆分成 Chunk 发送，而且必须在一个 Chunk 发送完成之后，才能开始发送下一个 Chunk。每个 Chunk 中都带有 Message  ID，表示属于哪个 Message，接收端也会按照这个 ID 将 Chunk 组装成 Message。</p><p>前面连接的时候，设置的 Chunk 块大小就是指这个 Chunk。将大的消息变为小的块再发送，可以在低带宽的情况下，减少网络拥塞。</p><p>举一个分块的例子：</p><p>假设一个视频的消息长度为 307，但是 Chunk 大小约定为 128，于是会拆分为三个 Chunk。</p><p>第一个 Chunk 的 Type＝0，表示 Chunk 头是完整的；头里面 Timestamp 为 1000，总长度 Length 为 307，类型为 9，是个视频，Stream  ID 为 12346，正文部分承担 128 个字节的 Data。</p><p>第二个 Chunk 也要发送 128 个字节，Chunk 头由于和第一个 Chunk 一样，因此采用 Chunk Type＝3，表示头一样就不再发送了。</p><p>第三个 Chunk 要发送的 Data 的长度为 307-128-128=51 个字节，还是采用 Type＝3。</p><p><img src="https://i.loli.net/2020/02/02/TvqDHjO9eQ8bcBo.jpg" alt="fig7.jpg"></p><p>这样数据就能源源不断到达流媒体服务器</p><p><img src="https://i.loli.net/2020/02/02/7gvWiSIFkPX64Oe.jpg" alt="fig8.jpg"></p><p>这个时候，大量观看直播的观众就可以通过 RTMP 协议从流媒体服务器上拉取，但是这么多的用户量，都去同一个地方拉取，服务器压力会很大，而且用户分布在全国甚至全球，如果都去统一的一个地方下载，也会时延比较长，需要有分发网络。</p><p>分发网络分为中心和边缘两层。边缘层服务器部署在全国各地及横跨各大运营商里，和用户距离很近。中心层是流媒体服务集群，负责内容的转发。智能负载均衡系统，根据用户的地理位置信息，就近选择边缘服务器，为用户提供推 / 拉流服务。中心层也负责转码服务，例如，把 RTMP 协议的码流转换为 HLS 码流。</p><p><img src="https://i.loli.net/2020/02/02/tcimUEH6WRv8wsA.jpg" alt="fig9.jpg"></p><h3 id="1-3-3-拉流"><a href="#1-3-3-拉流" class="headerlink" title="1.3.3 拉流"></a>1.3.3 拉流</h3><p>观众的客户端通过RTMP拉流的过程：</p><p><img src="https://i.loli.net/2020/02/02/9Br2WsplhnkzvjK.jpg" alt="fig10.jpg"></p><h1 id="2-P2P"><a href="#2-P2P" class="headerlink" title="2. P2P"></a>2. P2P</h1><h2 id="2-1-传输大文件的现有方式"><a href="#2-1-传输大文件的现有方式" class="headerlink" title="2.1 传输大文件的现有方式"></a>2.1 传输大文件的现有方式</h2><h3 id="2-1-1-HTTP方式"><a href="#2-1-1-HTTP方式" class="headerlink" title="2.1.1 HTTP方式"></a>2.1.1 HTTP方式</h3><p>最简单的是通过HTTP进行下载，但是通过浏览器下载速度非常慢。</p><h3 id="2-1-2-FTP方式"><a href="#2-1-2-FTP方式" class="headerlink" title="2.1.2 FTP方式"></a>2.1.2 FTP方式</h3><p>还可以通过FTP，即文件传输协议，FTP通过两个TCP连接来传输一个文件。</p><ul><li>控制连接</li></ul><p>服务器以被动的方式，打开用于FTP的端口21，客户端则主动发起连接。该连接将命令从客户端传给服务器，并传回服务器的应答。</p><ul><li>数据连接</li></ul><p>每当一个文件在客户端与服务器之间传输时，就创建一个数据连接</p><p>FTP有两种工作模式</p><ul><li>主动模式 PORT</li></ul><p>客户端随机打开一个大于1024的端口N，向服务器的命令端口21发起连接，同时开放N+1端口监听，并向服务器发出 prot N+1的命令，由服务器从自己的数据端口20主动连接到客户端指定的数据端口N+1 </p><ul><li>被动模式 PASV</li></ul><p>当开启一个FTP连接时，客户端打开两个任意的本地端口N（仍然需要大于1024）和N+1.第一个端口连接服务器的21端口，提交PASV命令。然后，服务器会开启一个任意的端口P（大于1024），返回”227 entering passive mode”信息，其中有FTP服务器开放的用来进行数据传输的端口。客户端收到信息获取端口号以后，会通过N+1号端口连接服务器的端口P，然后在两个端口之间进行数据传输。</p><h2 id="2-2-P2P概念"><a href="#2-2-P2P概念" class="headerlink" title="2.2 P2P概念"></a>2.2 P2P概念</h2><p>首先无论是HTTP的方式还是FTP的方式，都难以解决单一服务器的带宽压力的问题，因为它们使用的都是传统的客户端服务器方式。P2P是指peer-to-peer。资源开始并不集中地存储在某些设备上，而是分散地存储在多台设备上。</p><p>想要下载一个文件的时候，需要得到那些已经存在了文件的peer，并和这些peer之间建立点对点的连接，而不需要到中心服务器上，就可以就近下载文件。同时在做下载和上传。</p><h2 id="2-3-种子-torrent-文件"><a href="#2-3-种子-torrent-文件" class="headerlink" title="2.3 种子(.torrent) 文件"></a>2.3 种子(.torrent) 文件</h2><p>需要知道哪些peer有这些文件，因此需要用到种子，就是我们熟悉的.torrent文件。由两部分组成：分别是announce(tracker URL) 和文件信息</p><h3 id="2-3-1-文件信息"><a href="#2-3-1-文件信息" class="headerlink" title="2.3.1 文件信息"></a>2.3.1 文件信息</h3><ul><li>info区</li></ul><p>指定该中西有几个文件、文件有多长、目录结构，以及目录和文件的名字。</p><ul><li>name字段</li></ul><p>指定顶层目录的名字</p><ul><li>每个段的大小</li></ul><p>BitTorrent协议把一个文件分成很多小段，然后分段下载。</p><ul><li>段哈希值</li></ul><p>将整个种子种，每个段的SHA-1哈希值拼在一起。</p><h3 id="2-3-2-下载过程"><a href="#2-3-2-下载过程" class="headerlink" title="2.3.2 下载过程"></a>2.3.2 下载过程</h3><p>下载时，BT 客户端首先解析.torrent 文件，得到 tracker 地址，然后连接 tracker 服务器。tracker 服务器回应下载者的请求，将其他下载者（包括发布者）的 IP 提供给下载者。下载者再连接其他下载者，根据.torrent 文件，两者分别对方告知自己已经有的块，然后交换对方没有的数据。此时不需要其他服务器参与，并分散了单个线路上的数据流量，因此减轻了服务器的负担。</p><p>下载者每得到一个块，需要算出下载块的 Hash 验证码，并与.torrent 文件中的对比。如果一样，则说明块正确，不一样则需要重新下载这个块。这种规定是为了解决下载内容的准确性问题。</p><p>从这个过程也可以看出，这种方式特别依赖 tracker。tracker 需要收集下载者信息的服务器，并将此信息提供给其他下载者，使下载者们相互连接起来，传输数据。虽然下载的过程是非中心化的，但是加入这个 P2P 网络的时候，都需要借助 tracker 中心服务器，这个服务器是用来登记有哪些用户在请求哪些资源。</p><p>所以，这种工作方式有一个弊端，一旦 tracker 服务器出现故障或者线路遭到屏蔽，BT 工具就无法正常工作了。</p><h2 id="2-4-去中心化网络-Distributed-Hash-Table"><a href="#2-4-去中心化网络-Distributed-Hash-Table" class="headerlink" title="2.4 去中心化网络(Distributed Hash Table)"></a>2.4 去中心化网络(Distributed Hash Table)</h2><p>每个加入这个DHT网络的人都要负责存储这个网络里的资源信息和其它成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。</p><h3 id="2-4-1-Kademlia-协议"><a href="#2-4-1-Kademlia-协议" class="headerlink" title="2.4.1 Kademlia 协议"></a>2.4.1 Kademlia 协议</h3><p>任何一个BitTorrent启动之后，都有两个角色：一个是peer，监听一个TCP端口，用来上传和下载文件；另一个角色DHT node，监听一个UDP端口，通过这个角色，这个节点就可以加入到一个DHT网络当中。</p><p><img src="https://i.loli.net/2020/02/02/573ksTWaqClEcJo.jpg" alt="fig11.jpg"></p><p>在 DHT 网络里面，每一个 DHT node 都有一个 ID。这个 ID 是一个很长的串。每个 DHT node 都有责任掌握一些知识，也就是文件索引，即它应该知道某些文件时保存在哪些节点上的，这些信息就足够了，而它自己本身不一定就是保存这个文件的节点。</p><h3 id="2-4-2-哈希值"><a href="#2-4-2-哈希值" class="headerlink" title="2.4.2 哈希值"></a>2.4.2 哈希值</h3><p>每个文件可以计算出一个哈希值，而DHT node的ID是和哈希值相同长度的串。</p><p>DHT 算法是这样规定的：如果一个文件计算出一个哈希值，则和这个哈希值一样的那个 DHT node，就有责任知道从哪里下载这个文件，即便它自己没保存这个文件。</p><p>当然不一定这么巧，总能找到和哈希值一模一样的，有可能一模一样的 DHT node 也下线了，所以 DHT 算法还规定：除了一模一样的那个 DHT node 应该知道，ID 和这个哈希值非常接近的 N 个 DHT node 也应该知道。</p><p>什么叫和哈希值接近呢？例如只修改了最后一位，就很接近；修改了倒数 2 位，也不远；修改了倒数 3 位，也可以接受。总之，凑齐了规定的 N 这个数就行。</p><p>在这种模式下，种子.torrent 文件里面就不再是 tracker 的地址了，而是一个 list 的 node 的地址，而所有这些 node 都是已经在 DHT 网络里面的。当然随着时间的推移，很可能有退出的，有下线的，但是我们假设，不会所有的都联系不上，总有一个能联系上。</p><p>node new 只要在种子里面找到一个 DHT node，就加入了网络。</p><p>node new 会计算文件 1 的哈希值，并根据这个哈希值了解到，和这个哈希值匹配，或者很接近的 node 上知道如何下载这个文件，例如计算出来的哈希值就是 node C。</p><p>但是 node new 不知道怎么联系上 node C，因为种子里面的 node 列表里面很可能没有 node C，但是它可以问，DHT 网络特别像一个社交网络，node new 只有去它能联系上的 node 问，你们知道不知道 node C 的联系方式呀？</p><p>在 DHT 网络中，每个 node 都保存了一定的联系方式，但是肯定没有 node 的所有联系方式。DHT 网络中，节点之间通过互相通信，也会交流联系方式，也会删除联系方式。</p><p>在 node C 上，告诉 node new，下载文件 1，要去 B、D、 F，于是 node new 选择和 node B 进行 peer 连接，开始下载，它一旦开始下载，自己本地也有文件 1 了，于是 node new 告诉 node C 以及和 node C 的 ID 很像的那些节点，我也有文件 1 了，可以加入那个文件拥有者列表了。</p><p>但是你会发现 node new 上没有文件索引，但是根据哈希算法，一定会有某些文件的哈希值是和 node new 的 ID 匹配上的。在 DHT 网络中，会有节点告诉它，你既然加入了咱们这个网络，你也有责任知道某些文件的下载地址。</p><h1 id="3-DNS"><a href="#3-DNS" class="headerlink" title="3. DNS"></a>3. DNS</h1><h2 id="3-1-DNS服务器"><a href="#3-1-DNS服务器" class="headerlink" title="3.1 DNS服务器"></a>3.1 DNS服务器</h2><p>DNS服务器很重要，根据名称来查找对应的IP地址的协议。DNS服务器，一定要设置成高可用、高并发和分布式的。</p><p><img src="https://i.loli.net/2020/02/02/7nKk5iPVNmQRdot.jpg" alt="fig12.jpg"></p><ul><li>根DNS服务器：返回顶级域DNS服务器的IP地址</li><li>顶级域DNS服务器：返回权威DNS服务器的IP地址</li><li>权威DNS服务器：返回相应主机的IP地址</li></ul><h2 id="3-2-DNS解析流程"><a href="#3-2-DNS解析流程" class="headerlink" title="3.2 DNS解析流程"></a>3.2 DNS解析流程</h2><p><img src="https://i.loli.net/2020/02/02/oRQapO7AxS3jKqt.jpg" alt="fig13.jpg"></p><ol><li>电脑客户端会发出一个 DNS 请求，问 <a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 的 IP 是啥啊，并发给本地域名服务器 (本地 DNS)。那本地域名服务器 (本地 DNS) 是什么呢？如果是通过 DHCP 配置，本地 DNS 由你的网络服务商（ISP），如电信、移动等自动分配，它通常就在你网络服务商的某个机房。</li><li>本地 DNS 收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应 IP 地址的大表格。如果能找到 <a href="http://www.163.com，它直接就返回" target="_blank" rel="noopener">www.163.com，它直接就返回</a> IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大，能告诉我 <a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 的 IP 地址吗？”根域名服务器是最高层次的，全球共有 13 套。它不直接用于域名解析，但能指明一条道路。</li><li>根 DNS 收到来自本地 DNS 的请求，发现后缀是 .com，说：“哦，<a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 啊，这个域名是由.com 区域管理，我给你它的顶级域名服务器的地址，你去问问它吧。”</li><li>本地 DNS 转向问顶级域名服务器：“老二，你能告诉我 <a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 的 IP 地址吗？”顶级域名服务器就是大名鼎鼎的比如 .com、.net、 .org 这些一级域名，它负责管理二级域名，比如 163.com，所以它能提供一条更清晰的方向。</li><li>顶级域名服务器说：“我给你负责 <a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到。”</li><li>本地 DNS 转向问权威 DNS 服务器：“您好，<a href="http://www.163.com" target="_blank" rel="noopener">www.163.com</a> 对应的 IP 是啥呀？”163.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</li><li>权限 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</li><li>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。</li></ol><h2 id="3-3-DNS-负载均衡"><a href="#3-3-DNS-负载均衡" class="headerlink" title="3.3 DNS 负载均衡"></a>3.3 DNS 负载均衡</h2><p>DNS通过名称映射为IP地址的时候，并不会都映射到同一个IP地址，会根据距离选择最近的。</p><h3 id="3-3-1-DNS内部负载均衡"><a href="#3-3-1-DNS内部负载均衡" class="headerlink" title="3.3.1 DNS内部负载均衡"></a>3.3.1 DNS内部负载均衡</h3><p>例如，一个应用要访问数据库，在这个应用里面应该配置这个数据库的 IP 地址，还是应该配置这个数据库的域名呢？显然应该配置域名，因为一旦这个数据库，因为某种原因，换到了另外一台机器上，而如果有多个应用都配置了这台数据库的话，一换 IP 地址，就需要将这些应用全部修改一遍。但是如果配置了域名，则只要在 DNS 服务器里，将域名映射为新的 IP 地址，这个工作就完成了，大大简化了运维。</p><p>都尽量用域名进行配置，然后就可以在DNS层面上对其进行限制，比如轮询不同的IP地址，达到负载均衡的目的。</p><h3 id="3-3-2-全局负载均衡"><a href="#3-3-2-全局负载均衡" class="headerlink" title="3.3.2 全局负载均衡"></a>3.3.2 全局负载均衡</h3><p>为了保证我们的应用高可用，往往会部署在多个机房，每个地方都会有自己的 IP 地址。当用户访问某个域名的时候，这个 IP 地址可以轮询访问多个数据中心。如果一个数据中心因为某种原因挂了，只要在 DNS 服务器里面，将这个数据中心对应的 IP 地址删除，就可以实现一定的高可用。</p><h3 id="3-3-3-DNS访问数据中心中对象存储上的静态资源"><a href="#3-3-3-DNS访问数据中心中对象存储上的静态资源" class="headerlink" title="3.3.3 DNS访问数据中心中对象存储上的静态资源"></a>3.3.3 DNS访问数据中心中对象存储上的静态资源</h3><p>我们通过 DNS 访问数据中心中对象存储上的静态资源为例，看一看整个过程。</p><p>假设全国有多个数据中心，托管在多个运营商，每个数据中心三个可用区（Available Zone）。对象存储通过跨可用区部署，实现高可用性。在每个数据中心中，都至少部署两个内部负载均衡器，内部负载均衡器后面对接多个对象存储的前置服务器（Proxy-server）。</p><p><img src="https://i.loli.net/2020/02/02/ZJqxP9mMeatDEjo.jpg" alt="fig14.jpg"></p><ol><li>当一个客户端要访问 object.yourcompany.com 的时候，需要将域名转换为 IP 地址进行访问，所以它要请求本地 DNS 解析器。</li><li>本地 DNS 解析器先查看看本地的缓存是否有这个记录。如果有则直接使用，因为上面的过程太复杂了，如果每次都要递归解析，就太麻烦了。</li><li>如果本地无缓存，则需要请求本地的 DNS 服务器。</li><li>本地的 DNS 服务器一般部署在你的数据中心或者你所在的运营商的网络中，本地 DNS 服务器也需要看本地是否有缓存，如果有则返回，因为它也不想把上面的递归过程再走一遍。</li><li>至 7. 如果本地没有，本地 DNS 才需要递归地从根 DNS 服务器，查到.com 的顶级域名服务器，最终查到 yourcompany.com 的权威 DNS 服务器，给本地 DNS 服务器，权威 DNS 服务器按说会返回真实要访问的 IP 地址。</li></ol><p>对于不需要进行全局负载均衡的简单应用来讲，权威DNS服务器就可以直接将域名解析为一个或者多个IP地址，然后客户端可以通过多个IP地址进行简单的轮询，实现简单的负载均衡。</p><p>但是对于复杂的应用，尤其是跨地域运营商的大型应用，需要专门的设备或者服务器来做这件事情，这就是全局负载均衡器。(GSLB, Global Server Load Balance)</p><p>在 yourcompany.com 的 DNS 服务器中，一般是通过配置 CNAME 的方式，给 object.yourcompany.com 起一个别名，例如 object.vip.yourcomany.com，然后告诉本地 DNS 服务器，让它请求 GSLB 解析这个域名，GSLB 就可以在解析这个域名的过程中，通过自己的策略实现负载均衡。</p><ol><li>第一层 GSLB，通过查看请求它的本地 DNS 服务器所在的运营商，就知道用户所在的运营商。假设是移动，通过 CNAME 的方式，通过另一个别名 object.yd.yourcompany.com，告诉本地 DNS 服务器去请求第二层的 GSLB。</li><li>第二层 GSLB，通过查看请求它的本地 DNS 服务器所在的地址，就知道用户所在的地理位置，然后将距离用户位置比较近的 Region 里面，六个内部负载均衡的地址返回给本地DNS服务器</li><li>本地DNS服务器将结果返回给本地DNS解析器</li><li>本地DNS解析器将结果缓存后，返回给客户端</li><li>客户端开始访问属于相同运营商的距离较近的 Region 1 中的对象存储，当然客户端得到了六个 IP 地址，它可以通过负载均衡的方式，随机或者轮询选择一个可用区进行访问。对象存储一般会有三个备份，从而可以实现对存储读写的负载均衡。</li></ol><h2 id="3-4-DNS功能"><a href="#3-4-DNS功能" class="headerlink" title="3.4 DNS功能"></a>3.4 DNS功能</h2><ol><li>根据名称找具体地址</li><li>针对多个地址做负载均衡</li></ol><p>在多个地址中选择一个距离你近的地方访问。</p><h2 id="3-5-传统DNS的问题"><a href="#3-5-传统DNS的问题" class="headerlink" title="3.5 传统DNS的问题"></a>3.5 传统DNS的问题</h2><h3 id="3-5-1-域名缓存问题"><a href="#3-5-1-域名缓存问题" class="headerlink" title="3.5.1 域名缓存问题"></a>3.5.1 域名缓存问题</h3><p>DNS会对域名做缓存，在访问过一次以后会把结果缓存到本地，当其他人来问的时候，直接就返回这个缓存数据。某些运营商会将静态页面缓存到本运营商的服务器内，这样用户请求的时候，就不用跨运营商进行访问了。既加快了速度，也减少了运营商之间流量计算的成本。 在做域名解析的时候，<strong>不会将用户导向真正的网址，而是指向这个缓存的服务器。</strong></p><p>还有就是本地的缓存往往会使全局负载失败，因为上次进行缓存的时候，缓存中的地址不一定是这次访问离客户最近的地方。</p><h3 id="3-5-2-域名转发问题"><a href="#3-5-2-域名转发问题" class="headerlink" title="3.5.2 域名转发问题"></a>3.5.2 域名转发问题</h3><p>运营商可能不是直接和DNS服务器交流的，可能用转发给了其他的做解析，自己只是外包了出去。</p><h3 id="3-5-3-出口NAT问题"><a href="#3-5-3-出口NAT问题" class="headerlink" title="3.5.3 出口NAT问题"></a>3.5.3 出口NAT问题</h3><p>网络地址转换，使得从网关出去的包都换成了新的IP地址，当请求返回的时候，在这个网关，再将IP地址转换回去。但一旦做了网络地址转换，权威DNS服务器就没法通过这个地址来判断客户到底来自哪个运营商，极有可能误判运营商，导致跨运营商的访问</p><h3 id="3-5-4-域名更新问题"><a href="#3-5-4-域名更新问题" class="headerlink" title="3.5.4 域名更新问题"></a>3.5.4 域名更新问题</h3><p>本地 DNS 服务器是由不同地区、不同运营商独立部署的。对域名解析缓存的处理上，实现策略也有区别，有的会偷懒，忽略域名解析结果的 TTL 时间限制，在权威 DNS 服务器解析变更的时候，解析结果在全网生效的周期非常漫长。但是有的时候，在 DNS 的切换中，场景对生效时间要求比较高。</p><p>例如双机房部署的时候，跨机房的负载均衡和容灾多使用 DNS 来做。当一个机房出问题之后，需要修改权威 DNS，将域名指向新的 IP 地址，但是如果更新太慢，那很多用户都会出现访问异常。</p><h2 id="3-6-HTTPDNS"><a href="#3-6-HTTPDNS" class="headerlink" title="3.6 HTTPDNS"></a>3.6 HTTPDNS</h2><p>HTTPDNS就是不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商。当客户端需要DNS解析的时候，直接通过HTTP协议进行请求这个服务器集群，得到就近的地址。大部分应用在手机中，在手机端嵌入支持HTTPDNS的客户端SDK来进行使用。 </p><h1 id="4-CDN"><a href="#4-CDN" class="headerlink" title="4. CDN"></a>4. CDN</h1><p>当一个用户想访问一个网址的时候，指定这个网站的域名，DNS就会将这个域名解析为地址，然后用户请求这个地址，返回一个网页。</p><p>但是还有很多可以优化的地方： </p><p>借鉴快递的就近配送的原则/思路，在数据中心里部署几台机器，形成一个缓存的集群来缓存部分数据。 </p><p>这些分布在各个地方的各个数据中心的节点，称为边缘节点。</p><p>由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中，这样就会在边缘节点之上。有区域节点，规模就要更大，缓存的数据会更多，命中的概率也就更大。在区域节点之上是中心节点，规模更大，缓存数据更多。如果还不命中，就只好回源网站访问了。</p><p><img src="https://i.loli.net/2020/02/02/71hNwRIfryiuJHb.jpg" alt="fig15.jpg"></p><p>在没有CDN的情况下，用户向浏览器输入 <a href="http://www.web.com" target="_blank" rel="noopener">www.web.com</a> 这个域名，客户端访问本地 DNS 服务器的时候，如果本地 DNS 服务器有缓存，则返回网站的地址；如果没有，递归查询到网站的权威 DNS 服务器，这个权威 DNS 服务器是负责 web.com 的，它会返回网站的 IP 地址。本地 DNS 服务器缓存下 IP 地址，将 IP 地址返回，然后客户端直接访问这个 IP 地址，就访问到了这个网站。</p><p>当CDN存在的时候，在web.com这个权威DNS服务器上，会设置一个CNAME别名，指向另一个域名 <a href="http://www.web.cdn.com,并返回给本地DNS服务器。" target="_blank" rel="noopener">www.web.cdn.com,并返回给本地DNS服务器。</a></p><p><img src="https://i.loli.net/2020/02/02/KPOFwGSbZcgsqr9.jpg" alt="fig16.jpg"></p><p>当本地 DNS 服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是 web.com 的权威 DNS 服务器了，而是 web.cdn.com 的权威 DNS 服务器，这是 CDN 自己的权威 DNS 服务器。在这个服务器上，还是会设置一个 CNAME，指向另外一个域名，也即 CDN 网络的全局负载均衡器。接下来，本地 DNS 服务器去请求 CDN 的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：</p><ol><li>根据用户 IP 地址，判断哪一台服务器距用户最近；</li><li>用户所处的运营商；</li><li>根据用户所请求的 URL 中携带的内容名称，判断哪一台服务器上有用户所需的内容；</li><li>查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。</li></ol><p>基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的 IP 地址。</p><p>本地 DNS 服务器缓存这个 IP 地址，然后将 IP 返回给客户端，客户端去访问这个边缘节点，下载资源。缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。</p><h2 id="4-1-CDN缓存的内容"><a href="#4-1-CDN缓存的内容" class="headerlink" title="4.1 CDN缓存的内容"></a>4.1 CDN缓存的内容</h2><p><img src="https://i.loli.net/2020/02/02/1dZ6rmyNulOwSbY.jpg" alt="fig17.jpg"></p><p>会保存静态页面，图片等，因为这些东西变化的可能性不高。</p><p>在进入数据中心的时候，我们希望通过最外层接入层的缓存，将大部分静态资源的访问拦在边缘。而CDN则更进一步，将这些静态资源缓存到离用户更近的数据中心外。越接近客户，访问性能越好，时延越低。</p><p>静态资源中，流媒体也大量使用了CDN技术。CDN支持流媒体协议，例如前面讲过的 RTMP 协议。在很多情况下，这相当于一个代理，从上一级缓存读取内容，转发给用户。由于流媒体往往是连续的，因而可以进行预先缓存的策略，也可以预先推送到用户的客户端。</p><p>对于静态页面来讲，内容的分发往往采取拉取的方式，即未命中的时候，向上一级进行拉取，但流媒体数据量很大，如果出现回源，压力会比较大，因此往往采取主动推送的模式，将热点数据主动推送到边缘节点。</p><p>对于流媒体来讲，很多CDN还提供预处理服务，即在文件分发之前，经过一定的处理。例如将视频转换为不同的码流，以适应不同的网络带宽的用户需求；再比如对视频进行分片，降低存储压力，也使得客户端可以选择使用不同的码率加载不同的分片。</p><h2 id="4-2-防盗链问题"><a href="#4-2-防盗链问题" class="headerlink" title="4.2 防盗链问题"></a>4.2 防盗链问题</h2><p>对于流媒体来说，防盗链很重要，即视频都有版权的，只能在自己的网站里播才可以的。</p><h3 id="4-2-1-refer机制"><a href="#4-2-1-refer机制" class="headerlink" title="4.2.1 refer机制"></a>4.2.1 refer机制</h3><p>HTTP头的refer字段，告诉服务器这个请求从哪里来的，服务器基于此可以获得一些信息用于处理。如果referer的信息不是来自本站，就阻止访问或者调到其它链接当中。</p><h3 id="4-2-2-时间戳防盗链"><a href="#4-2-2-时间戳防盗链" class="headerlink" title="4.2.2 时间戳防盗链"></a>4.2.2 时间戳防盗链</h3><p>使用 CDN 的管理员可以在配置界面上，和 CDN 厂商约定一个加密字符串。客户端取出当前的时间戳，要访问的资源及其路径，连同加密字符串进行签名算法得到一个字符串，然后生成一个下载链接，带上这个签名字符串和截止时间戳去访问 CDN。在 CDN 服务端，根据取出过期时间，和当前 CDN 节点时间进行比较，确认请求是否过期。然后 CDN 服务端有了资源及路径，时间戳，以及约定的加密字符串，根据相同的签名算法计算签名，如果匹配则一致，访问合法，才会将资源返回给客户。</p><h2 id="4-3-动态CDN"><a href="#4-3-动态CDN" class="headerlink" title="4.3 动态CDN"></a>4.3 动态CDN</h2><h3 id="4-3-1-边缘计算模式"><a href="#4-3-1-边缘计算模式" class="headerlink" title="4.3.1 边缘计算模式"></a>4.3.1 边缘计算模式</h3><p>既然数据时动态生成的，那数据的逻辑计算和存储也应当相应的放在边缘节点。其中定时从源数据哪里同步存储的数据，然后再边缘进行计算得到结果。 </p><h3 id="4-3-2-路径优化模式"><a href="#4-3-2-路径优化模式" class="headerlink" title="4.3.2 路径优化模式"></a>4.3.2 路径优化模式</h3><p>数据不是在边缘计算生成的，而是在源站生成的，数据的下发则可以通过CDN网络，对路径进行优化。因为CDN节点较多，能够找到离源站很近的边缘节点，也能找到离用户很近的边缘节点。中间的链路完全由CDN规划，选择一个更加可靠的路径，使用类似专线的方式进行访问。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> CDN </tag>
            
            <tag> 流媒体协议 </tag>
            
            <tag> P2P </tag>
            
            <tag> DNS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(六)-应用层</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AD-%E5%BA%94%E7%94%A8%E5%B1%82/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AD-%E5%BA%94%E7%94%A8%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-HTTP协议"><a href="#1-HTTP协议" class="headerlink" title="1. HTTP协议"></a>1. HTTP协议</h1><p>以输入一个网址<a href="http://www.google.com为例。这是一个URL，称为统一资源定位符。HTTP是一个协议，www.google.com是一个域名，表示互联网上的一个位置。因为有规范，浏览器才知道如何统一进行处理。" target="_blank" rel="noopener">http://www.google.com为例。这是一个URL，称为统一资源定位符。HTTP是一个协议，www.google.com是一个域名，表示互联网上的一个位置。因为有规范，浏览器才知道如何统一进行处理。</a></p><h2 id="1-1-HTTP请求的准备"><a href="#1-1-HTTP请求的准备" class="headerlink" title="1.1 HTTP请求的准备"></a>1.1 HTTP请求的准备</h2><p>浏览器会将域名发送给DNS服务器，将其解析为IP地址。而后因为HTTP是基于TCP协议的，所以需要先通过三次握手来建立TCP连接。目前使用的HTTP协议大多数是1.1版本的，在1.1的协议当中，默认开启了Keep-alive，这意味着建立的TCP连接可以在多次请求中复用。</p><h2 id="1-2-HTTP请求的构建"><a href="#1-2-HTTP请求的构建" class="headerlink" title="1.2 HTTP请求的构建"></a>1.2 HTTP请求的构建</h2><p>连接建立以后，浏览器就要发送HTTP请求。</p><p>请求的格式如下图所示：</p><p><img src="https://i.loli.net/2020/02/02/9UN4fDEwdcCV8qZ.jpg" alt="fig1.jpg"></p><p>HTTP的请求分为三部分，分别为请求行，请求的首部，请求的正文实体。</p><h3 id="1-2-1-请求行"><a href="#1-2-1-请求行" class="headerlink" title="1.2.1 请求行"></a>1.2.1 请求行</h3><p>方法 + sp + URL + sp + 版本 + cr + If</p><p>在请求行中，URL就是<code>http://www.google.com</code>, 版本是HTTP1.1。</p><p>方法有几个类型：</p><ol><li>GET</li></ol><p>GET就是去服务器获取一些资源。对于访问网页来讲，要获取的往往是一个页面，也会有很多其他的格式，比如返回一个JSON字符串等等。返回的状态是由服务器的实现来决定的。</p><ol start="2"><li>POST</li></ol><p>主动告诉服务端一些信息，而非获取。一般是将这些信息放在正文当中。</p><ol start="3"><li>PUT</li></ol><p>向指定资源位置上传最新的内容，但是HTTP的服务器往往不允许上传文件，所以PUT和POST就都变成了要传给服务器东西的方法。POST往往是用来创建一个资源的，而PUT往往是用来修改一个资源的。</p><ol start="4"><li>DELETE</li></ol><p>用来删除资源的。</p><h3 id="1-2-2-首部字段"><a href="#1-2-2-首部字段" class="headerlink" title="1.2.2 首部字段"></a>1.2.2 首部字段</h3><p>首部字段首先是key value，通过冒号分隔。这里往往保存了一些非常重要的字段，比如：</p><ul><li>Accept-Charset： 这里表示客户端可以接受的字符集，防止传过来的是另外的字符集，从而导致出现乱码。</li><li>Content-Type: 正文的格式。例如如果正文是JSON，那这里我们就应该将其设为JSON。</li><li>缓存</li></ul><p>为什么要使用缓存呢？因为一个大的页面会有很多的东西。图片和大段的介绍内容往往是不会太经常发生变化的，因此我们每次更新页面的时候，不应该刷新整个页面，完全的从服务器重新获取一遍数据，应该做局部的刷新的。</p><p>对于这种高并发场景下的系统，在真正的业务逻辑之前，都会有一个<strong>接入层</strong>，将这些静态资源的请求拦在最外面。架构图如下所示：</p><p><img src="https://i.loli.net/2020/02/02/7BHNARp3Lg8Yuav.jpg" alt="fig2.jpg"></p><p>基本上是客户端和DNS还有CDN相连，再联系负载均衡模块 - nginx。将资源划分为动态资源和静态资源，对于静态资源，使用Varnish缓存层；对于动态资源，使用Redis，Varnish和Redis都和Tomcat应用集群相连，这意味着如果无法从缓存中拿到数据，那就访问服务器，调取数据。</p><p>在HTTP头里面，Cache-control是用来控制缓存的，当客户端发送的请求中包含max-age指令时，如果判定缓存层中资源的缓存时间数值比指定时间的数值小，那么客户端可以接受缓存的资源；当指定max-age值为0，那么缓存层通常需要将请求转发给应用集群。</p><ul><li>If-Modified-Since</li></ul><p>如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回”304 Not Modified”的响应，那客户端就不用下载了，也会节省带宽。</p><p>到目前为止，我们有了HTTP请求的报文格式，接下来，浏览器会通过Socket将其交给传输层。</p><h3 id="1-2-3-HTTP请求的发送"><a href="#1-2-3-HTTP请求的发送" class="headerlink" title="1.2.3 HTTP请求的发送"></a>1.2.3 HTTP请求的发送</h3><p>HTTP协议是基于TCP协议的。使用面向连接的方式发送请求，通过stream二进制流的方式传给对方。到了TCP层，它会把二进制流变成一个报文段发送给服务器。</p><p>在发送每一个报文段的时候，都需要对方回应一个ACK，来保证报文可靠地到达对方。如果没有回应，那么TCP这一层会重新传输，直到可以到达。</p><p>TCP 层发送每一个报文的时候，都需要加上自己的地址（即源地址）和它想要去的地方（即目标地址），将这两个信息放到 IP 头里面，交给 IP 层进行传输。</p><p>IP 层需要查看目标地址和自己是否是在同一个局域网。如果是，就发送 ARP 协议来请求这个目标地址对应的 MAC 地址，然后将源 MAC 和目标 MAC 放入 MAC 头，发送出去即可；如果不在同一个局域网，就需要发送到网关，还要需要发送 ARP 协议，来获取网关的 MAC 地址，然后将源 MAC 和网关 MAC 放入 MAC 头，发送出去。</p><p>网关收到包发现 MAC 符合，取出目标 IP 地址，根据路由协议找到下一跳的路由器，获取下一跳路由器的 MAC 地址，将包发给下一跳路由器。这样路由器一跳一跳终于到达目标的局域网。这个时候，最后一跳的路由器能够发现，目标地址就在自己的某一个出口的局域网上。于是，在这个局域网上发送 ARP，获得这个目标地址的 MAC 地址，将包发出去。</p><p>目标的机器发现 MAC 地址符合，就将包收起来；发现 IP 地址符合，根据 IP 头中协议项，知道自己上一层是 TCP 协议，于是解析 TCP 的头，里面有序列号，需要看一看这个序列包是不是我要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。</p><p>TCP 头里面还有端口号，HTTP 的服务器正在监听这个端口号。于是，目标机器自然知道是 HTTP 服务器这个进程想要这个包，于是将包发给 HTTP 服务器。HTTP 服务器的进程看到，原来这个请求是要访问一个网页，于是就把这个网页发给客户端。</p><h3 id="1-2-4-HTTP返回的构建"><a href="#1-2-4-HTTP返回的构建" class="headerlink" title="1.2.4 HTTP返回的构建"></a>1.2.4 HTTP返回的构建</h3><p>基于HTTP/1.1的返回报文：</p><p><img src="https://i.loli.net/2020/02/02/2nmbaI9hzYTKUr1.jpg" alt="fig3.jpg"></p><p>状态码会返回HTTP请求的结果。</p><p>而后是返回首部的key value。 </p><ul><li>Retry-After表示告诉客户端应该在多长时间以后再次尝试一下。</li><li>Content-Type: 表示返回的是HTML，还是JSON。</li></ul><p>构造好了返回的HTTP报文，接下来就是把这个报文发送出去。交给Socket去发送，交给TCP层，让TCP层将返回的HTML分成一个个小段，并且保证每个段都可靠到达。这些段加上TCP头后会交给IP层，然后将刚才的发送过程反方向来一遍。两次的逻辑基本相同，一直到达客户端。</p><p>客户端发现 MAC 地址符合、IP 地址符合，于是就会交给 TCP 层。根据序列号看是不是自己要的报文段，如果是，则会根据 TCP 头中的端口号，发给相应的进程。这个进程就是浏览器，浏览器作为客户端也在监听某个端口。</p><p>当浏览器拿到了 HTTP 的报文。发现返回“200”，一切正常，于是就从正文中将 HTML 拿出来。HTML 是一个标准的网页格式。浏览器只要根据这个格式，展示出一个绚丽多彩的网页。</p><p>这是一个正常的HTTP请求和返回的完整过程。</p><h2 id="1-3-HTTP-2-0"><a href="#1-3-HTTP-2-0" class="headerlink" title="1.3 HTTP 2.0"></a>1.3 HTTP 2.0</h2><p>HTTP 1.1 在应用层以纯文本的形式进行通信。每次通信都要带完整的 HTTP 的头，而且不考虑 pipeline 模式的话，每次的过程总是像上面描述的那样一去一回。这样在实时性、并发性上都存在问题。</p><p>为了解决这些问题，HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key  value 在两端建立一个索引表，对相同的头只发送索引表中的索引。</p><p>另外，HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。</p><p>HTTP 2.0 还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有Header帧，用于传输Header内容，并且会开启一个新的流。再就是Data帧，用来传输正文实体。多个帧属于同一个流。</p><p>通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。</p><p>我们来举一个例子。假设我们的一个页面要发送三个独立的请求，一个获取 css，一个获取 js，一个获取图片 jpg。如果使用 HTTP 1.1 就是串行的，但是如果使用 HTTP 2.0，就可以在一个连接里，客户端和服务端都可以同时发送多个请求或回应，而且不用按照顺序一对一对应。</p><p><img src="https://i.loli.net/2020/02/02/eyvpNZfrz3ClsnT.jpg" alt="fig4.jpg"></p><p>HTTP2.0实际上是将三个请求变成三个流，将数据分成帧，乱序发送到一个TCP连接当中。</p><p><img src="https://i.loli.net/2020/02/02/ymohztOPXklU84f.jpg" alt="fig5.jpg"></p><p>HTTP 2.0 成功解决了 HTTP 1.1 的队首阻塞问题，同时，也不需要通过 HTTP 1.x 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应；减少了 TCP 连接数对服务器性能的影响，同时将页面的多个数据 css、js、 jpg 等通过一个数据链接进行传输，能够加快页面组件的传输速度。</p><p>HTTP2.0虽然大大增加了并发性，但是还存在问题，因为HTTP2.0还是基于TCP协议的，TCP协议在处理包时是有严格顺序的。当其中一个数据包遇到问题，TCP连接需要等待这个包完成重传之后才能继续进行。因此Google引入QUIC协议来加速整个过程。</p><h2 id="1-4-QUIC协议"><a href="#1-4-QUIC协议" class="headerlink" title="1.4 QUIC协议"></a>1.4 QUIC协议</h2><p>从TCP切换到了UDP！</p><h3 id="1-4-1-自定义连接机制"><a href="#1-4-1-自定义连接机制" class="headerlink" title="1.4.1 自定义连接机制"></a>1.4.1 自定义连接机制</h3><p>我们都知道，一条 TCP 连接是由四元组标识的，分别是源 IP、源端口、目的 IP、目的端口。一旦一个元素发生变化时，就需要断开重连，重新连接。在移动互联情况下，当手机信号不稳定或者在 WIFI 和 移动网络切换时，都会导致重连，从而进行再次的三次握手，导致一定的时延。</p><p>这在 TCP 是没有办法的，但是基于 UDP，就可以在 QUIC 自己的逻辑里面维护连接的机制，不再以四元组标识，而是以一个 64 位的随机数作为 ID 来标识，而且 UDP 是无连接的，所以当 IP 或者端口变化的时候，只要 ID 不变，就不需要重新建立连接。</p><h3 id="1-4-2-自定义重传机制"><a href="#1-4-2-自定义重传机制" class="headerlink" title="1.4.2 自定义重传机制"></a>1.4.2 自定义重传机制</h3><p>TCP使用序号和应答机制来解决顺序问题和丢包问题。任何一个序号的包发过去，都要在一定的时间内得到应答，否则一旦超时，就会重发这个序号的包。那怎么样才算超时呢？通过使用自适应重传算法，通过采样往返时间RTT不断调整。</p><p>其实，在 TCP 里面超时的采样存在不准确的问题。例如，发送一个包，序号为 100，发现没有返回，于是再发送一个 100，过一阵返回一个 ACK101。这个时候客户端知道这个包肯定收到了，但是往返时间是多少呢？是 ACK 到达的时间减去后一个 100 发送的时间，还是减去前一个 100 发送的时间呢？事实是，第一种算法把时间算短了，第二种算法把时间算长了。</p><p>QUIC 也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。例如，发送一个包，序号是 100，发现没有返回；再次发送的时候，序号就是 101 了；如果返回的 ACK  100，就是对第一个包的响应。如果返回 ACK  101 就是对第二个包的响应，RTT 计算相对准确。</p><p>但是这里有一个问题，就是怎么知道包 100 和包 101 发送的是同样的内容呢？QUIC 定义了一个 offset 概念。QUIC 既然是面向连接的，也就像 TCP 一样，是一个数据流，发送的数据在这个数据流里面有个偏移量 offset，可以通过 offset 查看数据发送到了哪里，这样只要这个 offset 的包没有来，就要重发；如果来了，按照 offset 拼接，还是能够拼成一个流。</p><p><img src="https://i.loli.net/2020/02/02/p2nxwzvTsV1toX9.jpg" alt="fig6.jpg"></p><h3 id="1-4-3-无阻塞的多路复用"><a href="#1-4-3-无阻塞的多路复用" class="headerlink" title="1.4.3 无阻塞的多路复用"></a>1.4.3 无阻塞的多路复用</h3><p>有了自定义的连接和重传机制，我们就可以解决HTTP2.0的多路复用问题。同 HTTP 2.0 一样，同一条 QUIC 连接上可以创建多个 stream，来发送多个 HTTP 请求。但是，QUIC 是基于 UDP 的，一个连接上的多个 stream 之间没有依赖。这样，假如 stream2 丢了一个 UDP 包，后面跟着 stream3 的一个 UDP 包，虽然 stream2 的那个包需要重传，但是 stream3 的包无需等待，就可以发给用户。</p><h3 id="1-4-4-自定义流量控制"><a href="#1-4-4-自定义流量控制" class="headerlink" title="1.4.4 自定义流量控制"></a>1.4.4 自定义流量控制</h3><p>TCP的流量控制是通过滑动窗口协议。QUIC的流量控制是通过window_update，来告诉对方它可以接收的字节数。但是QUIC的窗口是适应自己的多路复用机制的，可以在一个连接中的每一个stream控制窗口大小。</p><p>在 TCP 协议中，接收端的窗口的起始点是下一个要接收并且 ACK 的包，即便后来的包都到了，放在缓存里面，窗口也不能右移，因为 TCP 的 ACK 机制是基于序列号的累计应答，一旦 ACK 了一个系列号，就说明前面的都到了，所以只要前面的没到，后面的到了也不能 ACK，就会导致后面的到了，也有可能超时重传，浪费带宽。</p><p>QUIC 的 ACK 是基于 offset 的，每个 offset 的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空挡会等待到来或者重发即可，而窗口的起始位置为当前收到的最大 offset，从这个 offset 到当前的 stream 所能容纳的最大缓存，是真正的窗口大小。显然，这样更加准确。</p><p><img src="https://i.loli.net/2020/02/02/k4weK82tcO7yfuq.jpg" alt="fig7.jpg"></p><h1 id="2-HTTPS-协议"><a href="#2-HTTPS-协议" class="headerlink" title="2.HTTPS 协议"></a>2.HTTPS 协议</h1><p>HTTPS协议的适用场景：我们可以用HTTP协议来看新闻，但是放到下单支付的应用场景中会存在很多的风险。如果适用HTTP，假设点外卖支付，网络包被截获了，于是在服务器回复你之前，黑客假装是外卖网站，然后给你回复一个假消息让你发送银行卡号和密码。</p><p>为了解决在这种应用场景下的安全问题，需要进行加密，分为对称加密和非对称加密两种：</p><h2 id="2-1-加密方式"><a href="#2-1-加密方式" class="headerlink" title="2.1 加密方式"></a>2.1 加密方式</h2><h3 id="2-1-1-对称加密"><a href="#2-1-1-对称加密" class="headerlink" title="2.1.1 对称加密"></a>2.1.1 对称加密</h3><p>在对称加密算法中，加密和解密使用的密钥是相同的。也就是说，加密和解密使用的是同一个密钥。因此，对称加密算法要保证安全性的话，密钥要做好保密。只能让使用的人知道，不能对外公开。</p><p>在上述场景当中的问题变成了：如何让用户和银行之间进行交流，来传递公钥，对称加密下这种交流非常的困难。</p><h3 id="2-1-2-非对称加密"><a href="#2-1-2-非对称加密" class="headerlink" title="2.1.2 非对称加密"></a>2.1.2 非对称加密</h3><p>在非对称加密算法中，加密使用的密钥和解密使用的密钥是不相同的。一把是作为公开的公钥，另一把是作为谁都不能给的私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。</p><p>依旧以上述为例，非对称加密的私钥放在银行网站上，不在互联网上传播，这样就可以保证私钥的私密性；银行网站传播对应私钥的公钥。</p><p>这样，客户端给外卖网站发送的时候，用外卖网站的公钥加密。而外卖网站给客户端发送消息的时候，使用客户端的公钥。这样就算有黑客企图模拟客户端获取一些信息，或者半路截获回复信息，但是由于它没有私钥，这些信息它还是打不开。</p><p>非对称加密的另一个问题是如何将公钥给对方： </p><ol><li>放在一个公网的地址上，供下载使用</li><li>在建立连接的时候，传给对方</li></ol><p>需要权威部门的认证来证明我的公钥是官方的，需要证书。证书里面包含公钥还有证书的所有者。注意权威部门是分层级的，通过层层授信背书的方式，来保证非对称加密模式的正常运转。</p><h2 id="2-2-HTTPS的工作模式"><a href="#2-2-HTTPS的工作模式" class="headerlink" title="2.2 HTTPS的工作模式"></a>2.2 HTTPS的工作模式</h2><p>利用非对称加密来传输对称加密的密钥，而真正的双方大数据量的通信都是通过对称加密来进行的。 </p><p><img src="https://i.loli.net/2020/02/02/9o2gqFN1pmkKSte.jpg" alt="fig8.jpg"></p><p>当你登录一个外卖网站的时候，由于是 HTTPS，客户端会发送 Client Hello 消息到服务器，以明文传输 TLS 版本信息、加密套件候选列表、压缩算法候选列表等信息。另外，还会有一个随机数，在协商对称密钥的时候使用。</p><p>然后，外卖网站返回 Server Hello 消息, 告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等，还有一个随机数，用于后续的密钥协商。</p><p>然后，外卖网站会给你一个服务器端的证书，然后说：“Server Hello Done，我这里就这些信息了。”</p><p>你当然不相信这个证书，于是你从自己信任的 CA 仓库中，拿 CA 的证书里面的公钥去解密外卖网站的证书。如果能够成功，则说明外卖网站是可信的。这个过程中，你可能会不断往上追溯 CA、CA 的 CA、CA 的 CA 的 CA，反正直到一个授信的 CA，就可以了。</p><p>证书验证完毕之后，觉得这个外卖网站可信，于是客户端计算产生随机数字 Pre-master，发送 Client Key Exchange，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。</p><p>此时无论是客户端还是服务器都有三个随机数：自己的，对端的，以及刚生成的Pre-Master随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。</p><p>客户端Change Cipher Spec, 开始采用协商的通信密钥和加密算法进行加密通信了。然后发送一个 Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。</p><h1 id="3-RTMP协议"><a href="#3-RTMP协议" class="headerlink" title="3. RTMP协议"></a>3. RTMP协议</h1><p>Real Time Messaging </p><p>RTMP协议是应用层协议，是要靠底层可靠的传输层协议（通常是TCP）来保证信息传输的可靠性的。在基于传输层协议的链接建立完成后，RTMP协议也要客户端和服务器通过“握手”来建立基于传输层链接之上的RTMP Connection链接，在Connection链接上会传输一些控制信息，如SetChunkSize,SetACKWindowSize。其中CreateStream命令会创建一个Stream链接，用于传输具体的音视频数据和控制这些信息传输的命令信息。RTMP协议传输时会对数据做自己的格式化，这种格式的消息我们称之为RTMP Message，而实际传输的时候为了更好地实现多路复用、分包和信息的公平性，发送端会把Message划分为带有Message ID的Chunk，每个Chunk可能是一个单独的Message，也可能是Message的一部分，在接受端会根据chunk中包含的data的长度，message id和message的长度把chunk还原成完整的Message，从而实现信息的收发。</p><p>详细应用见<a href="https://www.llchen60.com/2019/01/06/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%83-%E6%B5%81%E5%AA%92%E4%BD%93%E5%8D%8F%E8%AE%AE-%E7%BD%91%E7%BB%9C%E7%9B%B4%E6%92%AD%E5%BD%93%E4%B8%AD%E7%9A%84%E8%A7%86%E9%A2%91%E5%8E%8B%E7%BC%A9%E4%B8%8E%E4%BC%A0%E6%92%AD%E9%97%AE%E9%A2%98/">网络协议-七-流媒体协议-网络直播当中的视频压缩与传播问题</a></p><h1 id="4-HTTP的历史"><a href="#4-HTTP的历史" class="headerlink" title="4. HTTP的历史"></a>4. HTTP的历史</h1><h2 id="4-1-HTTP-0-9-1-0"><a href="#4-1-HTTP-0-9-1-0" class="headerlink" title="4.1 HTTP 0.9/ 1.0"></a>4.1 HTTP 0.9/ 1.0</h2><ul><li>0.9协议十分简单<ul><li>不支持请求头</li><li>只支持GET方法</li></ul></li><li>1.0 扩展了0.9<ul><li>请求中加入了HTTP版本号</li><li>有Header，不管是request还是response都有header<ul><li>将元数据和业务数据解耦，也可以成为业务逻辑和控制逻辑的分离 </li></ul></li><li>增加了HTTP status code标识相关的状态码</li><li>content-type可以传输其它文件了</li><li>缺点是<ul><li>每请求一个资源就要新建一个TCP连接，而且是串行请求的</li></ul></li></ul></li></ul><h2 id="4-2-HTTP-1-1"><a href="#4-2-HTTP-1-1" class="headerlink" title="4.2 HTTP/1.1"></a>4.2 HTTP/1.1</h2><p>主要目的在于解决HTTP1.0的网络性能问题，以及：</p><ul><li>增加<code>keepalive</code>来让HTTP重用TCP连接，重用TCP连接可以省去每次建立连接时需要的TCP三次握手的开销 – 又名 HTTP长连接 - HTTP Persistent Connection </li><li>支持pipeline网络传输<ul><li>只要第一个请求发出，不用等到拿到响应就可以发出第二个请求了</li></ul></li><li>支持 Chunked Responses 在response的时候不必说明Context-length。这样客户端就直到收到服务端的EOF标识才可以断连接了。</li><li>增加了cache control机制</li><li>协议头增加了language, encoding, type等等，让客户端可以跟服务器端进行更多的协商</li><li>加了<code>Host</code> 头，这样子服务器就可以直到你要请求的网站了</li></ul><h2 id="4-3-HTTP-2"><a href="#4-3-HTTP-2" class="headerlink" title="4.3 HTTP/2"></a>4.3 HTTP/2</h2><p>HTTP/1.1虽然说可以重用TCP连接，但是请求依旧串行的，需要保证其顺序。然而，大量的网页请求中都是些资源类的东西，如果我们能并行这类请求，那就会大大增加网络吞吐量和性能。</p><p>另外1.1是以文本的方式来传输数据，然后做zip压缩减少网络带宽，但是这样做就会消耗前端和后端的CPU了。HTTP/2就是为了解决上述的性能问题的。</p><ul><li>二进制协议，增加数据传输的效率</li><li>可以在一个TCP连接中并发请求多个HTTP请求</li><li>压缩头，如果同时发送多个请求，他们的头是一样的或者是类似的，那么协议就会帮助你消除重复的部分</li><li>允许服务端在客户端放cache，又叫做服务端push。也就是说，你没有请求的东西，我服务端可以先送给你放在本地的缓存当中。</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://coolshell.cn/articles/19840.html" target="_blank" rel="noopener">https://coolshell.cn/articles/19840.html</a> </p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> HTTP 2.0 </tag>
            
            <tag> QUIC </tag>
            
            <tag> HTTPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(五)-传输层</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%BA%94-%E4%BC%A0%E8%BE%93%E5%B1%82/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%BA%94-%E4%BC%A0%E8%BE%93%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-UDP协议"><a href="#1-UDP协议" class="headerlink" title="1. UDP协议"></a>1. UDP协议</h1><h2 id="1-1-UDP和TCP协议的区别"><a href="#1-1-UDP和TCP协议的区别" class="headerlink" title="1.1 UDP和TCP协议的区别"></a>1.1 UDP和TCP协议的区别</h2><table><thead><tr><th>类型</th><th>是否面向连接</th><th>传输可靠性</th><th>传输形式</th><th>传输效率</th><th>所需资源</th><th>应用场景</th><th>首部字节</th></tr></thead><tbody><tr><td>TCP</td><td>面向连接</td><td>可靠</td><td>字节流</td><td>慢</td><td>多</td><td>要求通信数据可靠（文件传输）</td><td>20-60</td></tr><tr><td>UDP</td><td>无连接</td><td>不可靠</td><td>数据报文段</td><td>快</td><td>少</td><td>要求通信速度高（视频直播）</td><td>8字节</td></tr></tbody></table><p>TCP是面向连接的，UDP无连接。</p><p>面向连接指，在互通之前，先建立连接，比如TCP三次握手，而UDP不会。建立连接是为了在客户端和服务端维护连接，而建立一定的数据结构来保证所谓的面向连接的特性。</p><p>TCP提供可靠支付，UDP不保证不丢失，不保证按顺序到达</p><p>TCP面向字节流，发送的时候发一个流。这是靠TCP自身的状态维护做的事情。</p><p>UDP继承了IP包的特性，不保证不丢失，不保证按顺序到达。</p><p>TCP具有拥塞控制，意识到丢包或者网络环境不好，会调整整个发送的速度的。UDP不做调整。</p><p>TCP有状态服务，精确记录了发送了没有，接收了没有，以及该接收哪一个了这样的信息。</p><p>如果MAC层定义了本地局域网的传输行为，IP层定义了整个网络端到端的传输行为，这两层基本定义了：网络传输是以包为单位的；二层叫帧，网络层叫包，传输层叫段。包单独传输，自行选段，在不同的设备封装解封装，不保证到达。 </p><h2 id="1-2-UDP-包头"><a href="#1-2-UDP-包头" class="headerlink" title="1.2 UDP 包头"></a>1.2 UDP 包头</h2><p>接收的机器通过看IP头里面的8位协议位来确定数据到底是通过TCP还是UDP来传的。</p><p>无论应用程序写的是用TCP传数据还是UDP传数据，都要监听一个端口。正是这个端口用来区分应用程序，无论是TCP还是UDP都有端口号，根据端口号来将数据交给相应的应用程序。</p><p><img src="https://i.loli.net/2020/02/02/KRSsZMkCaTFN8Vt.jpg" alt="fig1.jpg"></p><h2 id="1-3-UDP-使用场景"><a href="#1-3-UDP-使用场景" class="headerlink" title="1.3 UDP 使用场景"></a>1.3 UDP 使用场景</h2><ol><li><p>需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用</p><p>DHCP 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 又没事，过一会儿还有机会。我们讲过 PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下载使用的 TFTP，这个也是基于 UDP 协议的。在还没有操作系统的时候，客户端拥有的资源很少，不适合维护一个复杂的状态机，而是因为是内网，一般也没啥问题。</p><ol start="2"><li>不需要一对一沟通，建立连接，而是可以广播的应用</li></ol></li></ol><p>UDP 的不面向连接的功能，可以使得可以承载广播或者多播的协议。DHCP 就是一种广播的形式，就是基于 UDP 协议的，而广播包的格式前面说过了。</p><p>对于多播，我们在讲 IP 地址的时候，讲过一个 D 类地址，也即组播地址，使用这个地址，可以将包组播给一批机器。当一台机器上的某个进程想监听某个组播地址的时候，需要发送 IGMP 包，所在网络的路由器就能收到这个包，知道有个机器上有个进程在监听这个组播地址。当路由器收到这个组播地址的时候，会将包转发给这台机器，这样就实现了跨路由器的组播。</p><ol start="3"><li>需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候</li></ol><p>同理，UDP 简单、处理速度快，不像 TCP 那样，操这么多的心，各种重传啊，保证顺序啊，前面的不收到，后面的没法处理啊。不然等这些事情做完了，时延早就上去了。而 TCP 在网络不好出现丢包的时候，拥塞控制策略会主动的退缩，降低发送速度，这就相当于本来环境就差，还自断臂膀，用户本来就卡，这下更卡了。</p><p>当前很多应用都是要求低时延的，它们可不想用 TCP 如此复杂的机制，而是想根据自己的场景，实现自己的可靠和连接保证。例如，如果应用自己觉得，有的包丢了就丢了，没必要重传了，就可以算了，有的比较重要，则应用自己重传，而不依赖于 TCP。有的前面的包没到，后面的包到了，那就先给客户展示后面的嘛，干嘛非得等到齐了呢？如果网络不好，丢了包，那不能退缩啊，要尽快传啊，速度不能降下来啊，要挤占带宽，抢在客户失去耐心之前到达。</p><h2 id="1-4-UDP的应用实例"><a href="#1-4-UDP的应用实例" class="headerlink" title="1.4 UDP的应用实例"></a>1.4 UDP的应用实例</h2><h3 id="1-4-1-网页或者APP的访问"><a href="#1-4-1-网页或者APP的访问" class="headerlink" title="1.4.1 网页或者APP的访问"></a>1.4.1 网页或者APP的访问</h3><p>原来访问网页和手机 APP 都是基于 HTTP 协议的。HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的目前主流的移动互联网来讲，建立一次连接需要的时间会比较长，然而既然是移动中，TCP 可能还会断了重连，也是很耗时的。而且目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，<strong>但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。</strong></p><p>而QUIC (Quick UDP Internet Connections)是谷歌提出的一种基于UDP改进的通信协议，QUIC 在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制，是应用层“城会玩”的代表。这一节主要是讲 UDP，QUIC 我们放到应用层去讲。</p><h3 id="1-4-2-流媒体的协议"><a href="#1-4-2-流媒体的协议" class="headerlink" title="1.4.2 流媒体的协议"></a>1.4.2 流媒体的协议</h3><p>现在直播比较火，直播协议多使用 RTMP，这个协议我们后面的章节也会讲，而这个 RTMP 协议也是基于 TCP 的。TCP 的严格顺序传输要保证前一个收到了，下一个才能确认，如果前一个收不到，下一个就算包已经收到了，在缓存里面，也需要等着。对于直播来讲，这显然是不合适的，因为老的视频帧丢了其实也就丢了，就算再传过来用户也不在意了，他们要看新的了，如果老是没来就等着，卡顿了，新的也看不了，那就会丢失客户，所以直播，实时性比较比较重要，宁可丢包，也不要卡顿的。</p><p>另外，对于丢包，其实对于视频播放来讲，有的包可以丢，有的包不能丢，因为视频的连续帧里面，有的帧重要，有的不重要，如果必须要丢包，隔几个帧丢一个，其实看视频的人不会感知，但是如果连续丢帧，就会感知了，因而在网络不好的情况下，应用希望选择性的丢帧。</p><p>还有就是当网络不好的时候，TCP 协议会主动降低发送速度，这对本来当时就卡的看视频来讲是要命的，应该应用层马上重传，而不是主动让步。因而，很多直播应用，都基于 UDP 实现了自己的视频传输协议。</p><h3 id="1-4-3-实时游戏"><a href="#1-4-3-实时游戏" class="headerlink" title="1.4.3 实时游戏"></a>1.4.3 实时游戏</h3><p>游戏有一个特点，就是实时性比较高。快一秒你干掉别人，慢一秒你被别人爆头，所以很多职业玩家会买非常专业的鼠标和键盘，争分夺秒。</p><p>因而，实时游戏中客户端和服务端要建立长连接，来保证实时传输。但是游戏玩家很多，服务器却不多。由于维护 TCP 连接需要在内核维护一些数据结构，因而一台机器能够支撑的 TCP 连接数目是有限的，然后 UDP 由于是没有连接的，在异步 IO 机制引入之前，常常是应对海量客户端连接的策略。</p><p>另外还是 TCP 的强顺序问题，对战的游戏，对网络的要求很简单，玩家通过客户端发送给服务器鼠标和键盘行走的位置，服务器会处理每个用户发送过来的所有场景，处理完再返回给客户端，客户端解析响应，渲染最新的场景展示给玩家。</p><p>如果出现一个数据包丢失，所有事情都需要停下来等待这个数据包重发。客户端会出现等待接收数据，然而玩家并不关心过期的数据，激战中卡 1 秒，等能动了都已经死了。游戏对实时要求较为严格的情况下，采用自定义的可靠 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。</p><h3 id="1-4-4-物联网"><a href="#1-4-4-物联网" class="headerlink" title="1.4.4 物联网"></a>1.4.4 物联网</h3><p>一方面，物联网领域终端资源少，很可能只是个内存非常小的嵌入式系统，而维护 TCP 协议代价太大；另一方面，物联网对实时性要求也很高，而 TCP 还是因为上面的那些原因导致时延大。Google 旗下的 Nest 建立 Thread Group，推出了物联网通信协议 Thread，就是基于 UDP 协议的。</p><h3 id="1-4-5-移动通信领域"><a href="#1-4-5-移动通信领域" class="headerlink" title="1.4.5 移动通信领域"></a>1.4.5 移动通信领域</h3><p>4G网络中移动流量上网的数据面对的协议GTP-U就是基于UDP的。</p><h1 id="2-TCP协议"><a href="#2-TCP协议" class="headerlink" title="2. TCP协议"></a>2. TCP协议</h1><p>更倾向于网络环境是恶劣的，丢包，乱序，重传，拥塞都是常有的事情，很有可能送达不了，所以要从算法层面来保证可靠性。</p><h1 id="2-1-TCP包头格式"><a href="#2-1-TCP包头格式" class="headerlink" title="2.1 TCP包头格式"></a>2.1 TCP包头格式</h1><p><img src="https://i.loli.net/2020/02/02/C5bnKw2gUVLj9Ap.jpg" alt="fig2.jpg"></p><ul><li>源端口号-16</li><li>目的端口号-16</li></ul><p>源端口号和目标端口号，来确定从哪发送，要发送到哪里去。</p><ul><li>序号-32</li></ul><p>给包编序号，解决包的乱序问题</p><ul><li>确认序号-32</li></ul><p>发出去的包要有确认，来确认对方收到了。如果没有收到就需要重发，直到送达为止</p><ul><li>首部长度-4</li><li>保留位-6</li></ul><p>下述的状态位的存在是因为TCP是面向连接的，双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</p><ul><li>URG</li><li>ACK</li></ul><p>回复</p><ul><li>PSH</li><li>RST</li></ul><p>重新连接</p><ul><li>SYN</li></ul><p>发起一个连接</p><ul><li>FIN</li></ul><p>结束连接</p><ul><li>窗口大小-16</li></ul><p>TCP要做流量控制，通信双方各声明一个窗口，标识自己当前的处理能力，保持接收和处理的速度适宜。</p><ul><li>校验和-16</li><li>紧急指针-16</li><li>选项</li><li>数据</li></ul><h2 id="2-2-TCP三次握手"><a href="#2-2-TCP三次握手" class="headerlink" title="2.2 TCP三次握手"></a>2.2 TCP三次握手</h2><p>客户端–发送带有 SYN 标志的数据包–一次握手–服务端<br>服务端–发送带有 SYN/ACK 标志的数据包–二次握手–客户端<br>传回SYN的原因，确保就是传过来的那个信息</p><p>客户端–发送带有带有 ACK 标志的数据包–三次握手–服务端</p><p>第一次握手：Client 什么都不能确认；Server 确认了对方发送正常<br>第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常<br>第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常</p><p>三次握手除了建立双方的连接以外，还要解决TCP包的序号问题。每个连接都要有不同的序号，这个序号队列的起始序号是随着时间变化的，这样子可以避免有一个包到的有一点晚的问题。</p><p>我们在做设计的时候，会开启keepalive机制，即使没有真实的数据包，也会有探活包来保证连接的保持。</p><p><img src="https://i.loli.net/2020/02/02/n3gk8OYMdvoNHVI.jpg" alt="fig3.jpg"></p><p>一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。</p><h2 id="2-3-TCP四次挥手"><a href="#2-3-TCP四次挥手" class="headerlink" title="2.3 TCP四次挥手"></a>2.3 TCP四次挥手</h2><p>以下是四次挥手的状态时序图</p><p><img src="https://i.loli.net/2020/02/02/hLMrV2E5fA67nsw.jpg" alt="fig4.jpg"></p><p>断开的时候，我们可以看到，当 A 说“不玩了”，就进入 FIN_WAIT_1 的状态，B 收到“A 不玩”的消息后，发送知道了，就进入 CLOSE_WAIT 的状态。</p><p>A 收到“B 说知道了”，就进入 FIN_WAIT_2 的状态，如果这个时候 B 直接跑路，则 A 将永远在这个状态。TCP 协议里面并没有对这个状态的处理，但是 Linux 有，可以调整 tcp_fin_timeout 这个参数，设置一个超时时间。</p><p>如果 B 没有跑路，发送了“B 也不玩了”的请求到达 A 时，A 发送“知道 B 也不玩了”的 ACK 后，从 FIN_WAIT_2 状态结束，按说 A 可以跑路了，但是最后的这个 ACK 万一 B 收不到呢？则 B 会重新发一个“B 不玩了”，这个时候 A 已经跑路了的话，B 就再也收不到 ACK 了，因而 TCP 协议要求 A 最后等待一段时间 TIME_WAIT，这个时间要足够长，长到如果 B 没收到 ACK 的话，“B 说不玩了”会重发的，A 会重新发一个 ACK 并且足够时间到达 B。</p><p>A 直接跑路还有一个问题是，A 的端口就直接空出来了，但是 B 不知道，B 原来发过的很多包很可能还在路上，如果 A 的端口被一个新的应用占用了，这个新的应用会收到上个连接中 B 发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来 B 发送的所有的包都死翘翘，再空出端口来。</p><p>等待的时间设为 2MSL，MSL是Maximum Segment Lifetime, 报文最大生存时间。，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟和 2 分钟等。</p><h2 id="2-4-TCP状态机"><a href="#2-4-TCP状态机" class="headerlink" title="2.4 TCP状态机"></a>2.4 TCP状态机</h2><p><img src="https://i.loli.net/2020/02/02/uEPq9i54UK2Ya8m.jpg" alt="fig5.jpg"></p><h2 id="2-5-重传策略"><a href="#2-5-重传策略" class="headerlink" title="2.5 重传策略"></a>2.5 重传策略</h2><p>TCP传输的时候，每一个包都有一个ID。在建立连接的时候，会商定起始的ID是什么，然后按照ID一个个发送。为了保证不丢包，对于发送的包都要进行应答，但这个应答并不是一个一个来的，而是会应答某个之前的ID，表示都收到了，这种模式称为<strong><em>累计确认</em></strong> 或者<strong><em>累计应答</em></strong>。</p><h3 id="2-5-1-发送端缓存结构"><a href="#2-5-1-发送端缓存结构" class="headerlink" title="2.5.1 发送端缓存结构"></a>2.5.1 发送端缓存结构</h3><p>为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分。</p><p>第一部分：发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。</p><p>第二部分：发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。</p><p>第三部分：没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。</p><p>第四部分：没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。</p><p>区分第三第四部分的原因是为了进行流量控制 - 窗口大小。在TCP里，接收端会给发送端报一个窗口的大小，叫做Advertised Window. 这个窗口的大小应该等于上面的第二部分加上第三部分，超过了这个大小的接收端没法接收。</p><p>因此发送端需要保持以下的数据结构：</p><p><img src="https://i.loli.net/2020/02/02/TbYHfF2AS8XNKoR.jpg" alt="fig6.jpg"></p><ul><li>LastByteAcked：第一部分和第二部分的分界线</li><li>LastByteSent：第二部分和第三部分的分界线</li><li>LastByteAcked + AdvertisedWindow：第三部分和第四部分的分界线</li></ul><h3 id="2-5-2-接收端缓存结构"><a href="#2-5-2-接收端缓存结构" class="headerlink" title="2.5.2 接收端缓存结构"></a>2.5.2 接收端缓存结构</h3><p>第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的。</p><p>第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。</p><p>第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。</p><p><img src="https://i.loli.net/2020/02/02/gnSOQJytzlDp2EF.jpg" alt="fig7.jpg"></p><ul><li>MaxRcvBuffer：最大缓存的量；</li><li>LastByteRead 之后是已经接收了，但是还没被应用层读取的；</li><li>NextByteExpected 是第一部分和第二部分的分界线。</li></ul><p>第二部分的窗口有多大呢？</p><p>NextByteExpected 和 LastByteRead 的差其实是还没被应用层读取的部分占用掉的 MaxRcvBuffer 的量，我们定义为 A。AdvertisedWindow 其实是 MaxRcvBuffer 减去 A。也就是：AdvertisedWindow=MaxRcvBuffer-((NextByteExpected-1)-LastByteRead)。那第二部分和第三部分的分界线在哪里呢？NextByteExpected 加 AdvertisedWindow 就是第二部分和第三部分的分界线，其实也就是 LastByteRead 加上 MaxRcvBuffer。其中第二部分里面，由于受到的包可能不是顺序的，会出现空挡，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。</p><h3 id="2-5-3-顺序问题和丢包问题"><a href="#2-5-3-顺序问题和丢包问题" class="headerlink" title="2.5.3 顺序问题和丢包问题"></a>2.5.3 顺序问题和丢包问题</h3><p><strong>超时重试</strong>： 对于每一个发送了但是没有ACK的包，都设定一个定时器，超过了一定时间就重新尝试。这是时间不宜太短，时间必须大于往返时间RTT(Round trip time)，否则会引起不必要的重传。</p><p>估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为<strong><em>自适应重传算法</em></strong></p><p><strong>超时间隔加倍</strong>：每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</p><p><strong>快速重传机制</strong>：有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的 ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。</p><p>另外一种方式成为<strong>Selective Acknowledgment(SACK)</strong>, ）。这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方。例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了。</p><h3 id="2-5-4-流量控制问题"><a href="#2-5-4-流量控制问题" class="headerlink" title="2.5.4 流量控制问题"></a>2.5.4 流量控制问题</h3><p>在对于包的确认中，会携带一个窗口的大小。</p><p>我们先假设窗口不变的情况，窗口始终为 9。4 的确认来的时候，会右移一个，这个时候第 13 个包也可以发送了。</p><p><img src="https://i.loli.net/2020/02/02/hNHO7CLUzQqfwmt.jpg" alt="fig8.jpg"></p><p>这个时候，假设发送端发送过猛，会将第三部分的 10、11、12、13 全部发送完毕，之后就停止发送了，未发送可发送部分为 0。</p><p><img src="https://i.loli.net/2020/02/02/XaQ4KcUZe7vCNPn.jpg" alt="fig9.jpg"></p><p>当对于包 5 的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第 14 个包才可以发送。</p><p><img src="https://i.loli.net/2020/02/02/v3BKa6imlSHhXRd.jpg" alt="fig10.jpg"></p><p>如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送。</p><p>我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包 6 确认后，窗口大小就不能再是 9 了，就要缩小一个变为 8。</p><p><img src="https://i.loli.net/2020/02/02/Sdia3Akts1cKGnD.jpg" alt="fig11.jpg"></p><p>这个新的窗口 8 通过 6 的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从 9 改成了 8。</p><p><img src="https://i.loli.net/2020/02/02/MpGW7ZkgRBuwQxq.jpg" alt="fig12.jpg"></p><p>如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。</p><p><img src="https://i.loli.net/2020/02/02/oI1u3nGxDOyfe4q.jpg" alt="fig13.jpg"></p><p>当这个窗口通过包 14 的确认到达发送端的时候，发送端的窗口也调整为 0，停止发送。</p><p><img src="https://i.loli.net/2020/02/02/lqjmcvphQ6wZoNU.jpg" alt="fig14.jpg"></p><p>如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。</p><h3 id="2-5-5-拥塞控制"><a href="#2-5-5-拥塞控制" class="headerlink" title="2.5.5 拥塞控制"></a>2.5.5 拥塞控制</h3><p>通过控制窗口的大小来控制，拥塞窗口是防止将网络塞满。类比水管： 水管里面的水量 = 水管粗细 x 水管长度。 同理，网络通道的容量 = 带宽 x 往返延迟。如果我们设置发送窗口，使得发送但未确认的包为通道的容量，就能够撑满整个管道。</p><p><img src="https://i.loli.net/2020/02/02/WLgk5KJ8i4vMOlP.jpg" alt="fig15.jpg"></p><p>如图所示，假设往返时间为 8s，去 4s，回 4s，每秒发送一个包，每个包 1024byte。已经过去了 8s，则 8 个包都发出去了，其中前 4 个包已经到达接收端，但是 ACK 还没有返回，不能算发送成功。5-8 后四个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为 8 个包，正好等于带宽，也即每秒发送 1 个包，乘以来回时间 8s。</p><p>如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？</p><p>我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费 1s，所以到达另一端需要耗费 4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。</p><p>这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s 肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。</p><p>于是 TCP 的拥塞控制主要来避免两种现象，包丢失以及超时重传。一旦发生了这种现象，就说明发送速度太快了，TCP采用慢启动来避免发送速度太快的现象。</p><p>一条 TCP 连接开始，cwnd 设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd 加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认 cwnd 加一，两个确认 cwnd 加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认 cwnd 加一，四个确认 cwnd 加四，于是一次能够发送八个。可以看出这是呈指数性增长的。</p><p>在增长到ssthresh值-65535字节的时候，会减速变成线性增长。</p><p>每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加 1/8，八个确认一共 cwnd 增加 1，于是一次能够发送九个，变成了线性增长。</p><p>采用快速重传算法解决丢包问题，当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。</p><p>但是TCP的拥塞控制存在问题：</p><ol><li>丢包并不代表着通道满了，也可能是管子本来就漏水。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。</li><li>TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实 TCP 只要填满管道就可以了，不应该接着填，直到连缓存也填满。</li></ol><p>为了解决这个问题，就有了TCP BBR拥塞算法，企图找到一个平衡点，通过不断加快发送速度，将管道填满，但是不填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以达到高带宽和低时延的平衡。</p><p><img src="https://i.loli.net/2020/02/02/ApmJWIycxjXfNaq.jpg" alt="fig16.jpg"></p><h1 id="3-套接字Socket"><a href="#3-套接字Socket" class="headerlink" title="3. 套接字Socket"></a>3. 套接字Socket</h1><p>Socket编程是基于TCP和UDP协议的。Socket编程进行的是端到端的通信，往往意识不到中间经过了多少局域网、路由器，因而能够设置的参数是在端到端协议智商的网络层和传输层上。</p><p>网络层： 指定是IPV4(AF_INET)还是IPV6(AF_INET6). </p><p>传输层： 指定是TCP(SOCK_STREAM)还是UDP(SOCK_DGRAM)。</p><h2 id="3-1-基于TCP协议的Socket程序函数调用过程"><a href="#3-1-基于TCP协议的Socket程序函数调用过程" class="headerlink" title="3.1 基于TCP协议的Socket程序函数调用过程"></a>3.1 基于TCP协议的Socket程序函数调用过程</h2><p>首先是两端要创建Socket，这之后<br>TCP 的服务端要先监听一个端口，一般是先调用 bind 函数，给这个 Socket 赋予一个 IP 地址和端口。为什么需要端口呢？要知道，你写的是一个应用程序，当一个网络包来的时候，内核要通过 TCP 头里面的这个端口，来找到你这个应用程序，把包给你。为什么要 IP 地址呢？有时候，一台机器会有多个网卡，也就会有多个 IP 地址，你可以选择监听所有的网卡，也可以选择监听一个网卡，这样，只有发给这个网卡的包，才会给你。</p><p>当服务端有了 IP 和端口号，就可以调用 listen 函数进行监听。在 TCP 的状态图里面，有一个 listen 状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。</p><p>在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于 established 状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于 syn_rcvd 的状态。</p><p>接下来，服务端调用Accept函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。 </p><p>在服务端等待的时候，客户端可以通过 connect 函数发起连接。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的 accept 就会返回另一个 Socket。注意**监听的socket和真正用来传数据的Socket是两个，一个叫做监听Socket，一个叫做已连接Socket。 </p><p>连接建立成功之后，双方开始通过read和write函数来读写数据，就像往一个文件流里面写东西一样。</p><p>下图是基于TCP协议的Socket程序函数调用过程。</p><p><img src="https://i.loli.net/2020/02/02/tLb6hp47lYN3yZu.jpg" alt="fig17.jpg"></p><p>说 TCP 的 Socket 就是一个文件流，是非常准确的。因为，Socket 在 Linux 中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。</p><p>在内核中，Socket 是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构 task_struct，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。</p><p>这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个 inode，只不过 Socket 对应的 inode 不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。</p><p>在这个结构里面，主要是两个队列，一个是发送队列，一个是接收队列。在这两个队列里面保存的是一个缓存sk_buff.这个缓存里面能够看到完整的包的结构。</p><p><img src="https://i.loli.net/2020/02/02/Ag5IO6YfPbZ3SUQ.jpg" alt="fig18.jpg"></p><h2 id="3-2-基于UDP协议的Socket程序函数调用过程"><a href="#3-2-基于UDP协议的Socket程序函数调用过程" class="headerlink" title="3.2 基于UDP协议的Socket程序函数调用过程"></a>3.2 基于UDP协议的Socket程序函数调用过程</h2><p>和TCP协议的Socket编程相比，不同在于UDP是无连接的，不需要三次握手，也不需要调用listen和connect，但是UDP的交互仍然需要IP和端口号，因此也需要bind。UDP是没有维护连接状态的，因为不需要每对连接建立一组socket，而是只要有一个socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都需要调用sendto和recvfrom，都可以传入IP地址和端口。</p><p><img src="https://i.loli.net/2020/02/02/5XzPcB4R9Mrpf1b.jpg" alt="fig19.jpg"></p><h2 id="3-3-服务器最大连接数"><a href="#3-3-服务器最大连接数" class="headerlink" title="3.3 服务器最大连接数"></a>3.3 服务器最大连接数</h2><pre><code>{本机 IP, 本机端口, 对端 IP, 对端端口}</code></pre><p>服务器通常固定在某个本地端口上监听，等待客户端的连接请求。因此，服务端端 TCP 连接四元组中只有对端 IP, 也就是客户端的 IP 和对端的端口，也即客户端的端口是可变的，因此，最大 TCP 连接数 = 客户端 IP 数×客户端端口数。对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。</p><p>当然，服务端最大并发 TCP 连接数远不能达到理论上限。首先主要是文件描述符的限制，，按照上面的原理，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目；另一个限制是内存，按照上面的数据结构，每个TCP连接都要占用一定的内存，操作系统是有限的。</p><p>因此需要寻找方法去降低每个项目消耗的资源数目</p><h3 id="3-3-1-多进程方式"><a href="#3-3-1-多进程方式" class="headerlink" title="3.3.1 多进程方式"></a>3.3.1 多进程方式</h3><p>这就相当于你是一个代理，在那里监听来的请求。一旦建立了一个连接，就会有一个已连接 Socket，这时候你可以创建一个子进程，然后将基于已连接 Socket 的交互交给这个新的子进程来做。就像来了一个新的项目，但是项目不一定是你自己做，可以再注册一家子公司，招点人，然后把项目转包给这家子公司做，以后对接就交给这家子公司了，你又可以去接新的项目了。</p><p>在linux中使用fork来做的。</p><p><img src="https://i.loli.net/2020/02/02/9MOWKfI7kzEdD6V.jpg" alt="fig20.jpg"></p><p>因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得。</p><p>接下来，子进程就可以通过这个已连接 Socket 和客户端进行互通了，当通信完毕之后，就可以退出进程，那父进程如何知道子进程干完了项目，要退出呢？还记得 fork 返回的时候，如果是整数就是父进程吗？这个整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出。</p><h3 id="3-3-2-多线程方式"><a href="#3-3-2-多线程方式" class="headerlink" title="3.3.2 多线程方式"></a>3.3.2 多线程方式</h3><p>相当于不成立子公司了，而是在公司里成立新的项目组。在 Linux 下，通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一个引用而已。</p><p><img src="https://i.loli.net/2020/02/02/a8SoUfLwyzp5Ze3.jpg" alt="fig21.jpg"></p><p>上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程。一台机器无法创建很多进程或者线程。有个C10k. ，它的意思是一台机器要维护 1 万个连接，就要创建 1 万个进程或者线程，那么操作系统是无法承受的。如果维持 1 亿用户在线需要 10 万台服务器，成本也太高了。</p><h3 id="3-3-3-IO多路复用，一个线程维护多个Socket"><a href="#3-3-3-IO多路复用，一个线程维护多个Socket" class="headerlink" title="3.3.3 IO多路复用，一个线程维护多个Socket"></a>3.3.3 IO多路复用，一个线程维护多个Socket</h3><p>即一个线程维护多个Socket。 由于 Socket 是文件描述符，因而某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中，这就是项目进度墙。，然后调用 select 函数来监听文件描述符集合是否有变化。一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化。。</p><h3 id="3-3-4-IO多路复用，subscribe-publish模式"><a href="#3-3-4-IO多路复用，subscribe-publish模式" class="headerlink" title="3.3.4 IO多路复用，subscribe/publish模式"></a>3.3.4 IO多路复用，subscribe/publish模式</h3><p>上面 select 函数还是有问题的，因为每次 Socket 所在的文件描述符集合中有 Socket 发生变化的时候，都需要通过轮询的方式，也就是需要将全部项目都过一遍的方式来查看进度，这大大影响了一个项目组能够支撑的最大的项目数量。因而使用 select，能够同时盯的项目数量由 FD_SETSIZE 限制。</p><p>如果改成事件通知的方式，情况就会好很多，项目组不需要通过轮询挨个盯着这些项目，而是当项目进度发生变化的时候，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。</p><p>能完成这件事情的函数叫 epoll，它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数的方式，当某个文件描述符发送变化的时候，就会主动通知。</p><p><img src="https://i.loli.net/2020/02/02/MqYfXpClu6AGvQs.jpg" alt="fig22.jpg"></p><p>如图所示，假设进程打开了 Socket m, n, x 等多个文件描述符，现在需要通过 epoll 来监听是否这些 Socket 都有事件发生。其中 epoll_create 创建一个 epoll 对象，也是一个文件，也对应一个文件描述符，同样也对应着打开文件列表中的一项。在这项里面有一个红黑树，在红黑树里，要保存这个 epoll 要监听的所有 Socket。</p><p>当 epoll_ctl 添加一个 Socket 的时候，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的 Socket 的事件列表中。当一个 Socket 来了一个事件的时候，可以从这个列表中得到 epoll 对象，并调用 call  back 通知它。</p><p>这种通知方式使得监听的 Socket 数据增加的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> UDP </tag>
            
            <tag> TCP </tag>
            
            <tag> Socket </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(四)-网络层</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%9B%9B-%E7%BD%91%E7%BB%9C%E5%B1%82/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%9B%9B-%E7%BD%91%E7%BB%9C%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-IP协议"><a href="#1-IP协议" class="headerlink" title="1. IP协议"></a>1. IP协议</h1><pre><code>root@test:~# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff    inet 10.100.122.2/24 brd 10.100.122.255 scope global eth0       valid_lft forever preferred_lft forever    inet6 fe80::f816:3eff:fec7:7975/64 scope link        valid_lft forever preferred_lft forever</code></pre><p>10.100.122.2是一个IP地址，inet6 fe80::f816:3eff:fec7:7975/64是IPv6地址。IP地址分为五类： </p><p><img src="https://i.loli.net/2020/02/02/D9CGtkc5s1TKfN4.jpg" alt="fig1.jpg"></p><p>D类是组播地址，使用这一类地址，属于某个组的机器都能收到。</p><p>下面这个表展示了ABC三类地址所能包含的主机的数量：</p><p><img src="https://i.loli.net/2020/02/02/ztmCUuYxdwejnfS.jpg" alt="fig2.jpg"></p><p>C类地址只能包含254的主机，而B类地址又太大了，能包含65534个主机，因此采用了CIDR方式进行优化</p><h2 id="1-1-CIDR-无类型域间选路"><a href="#1-1-CIDR-无类型域间选路" class="headerlink" title="1.1 CIDR 无类型域间选路"></a>1.1 CIDR 无类型域间选路</h2><h3 id="1-1-1-CIDR的斜杆-数字的表示方式"><a href="#1-1-1-CIDR的斜杆-数字的表示方式" class="headerlink" title="1.1.1 CIDR的斜杆+数字的表示方式"></a>1.1.1 CIDR的斜杆+数字的表示方式</h3><p>这种方式打破了上述的分成几类地址的方式，将32位地址一分为二，前面是网络号，后面是主机号，例如：</p><pre><code>10.100.122.2/24</code></pre><p>斜杠和24表示对于这个32位地址而言，前24位是其网络号，后8位是其主机号。</p><h3 id="1-1-2-广播地址"><a href="#1-1-2-广播地址" class="headerlink" title="1.1.2 广播地址"></a>1.1.2 广播地址</h3><p>继续以上述的地址为例，其广播地址为</p><pre><code>10.100.122.255</code></pre><p>如果发送这个地址，所有10.100.122网络里的机器都可以收到</p><h3 id="1-1-3-子网掩码"><a href="#1-1-3-子网掩码" class="headerlink" title="1.1.3 子网掩码"></a>1.1.3 子网掩码</h3><p>继续以上述的地址为例，其子网掩码为</p><pre><code>255.255.255.0</code></pre><p>与IP地址按位与，就可以得到网络号</p><h2 id="1-2-公有IP地址和私有IP地址"><a href="#1-2-公有IP地址和私有IP地址" class="headerlink" title="1.2 公有IP地址和私有IP地址"></a>1.2 公有IP地址和私有IP地址</h2><p>这是按类对IP地址进行划分的时候的概念，私有地址，即允许组织内部的IT人员自己进行管理分配的地址。公有IP的资源有组织统一分配的，需要去买。</p><p><img src="https://i.loli.net/2020/02/02/KF8xGTD7mnwOBob.jpg" alt="fig3.jpg"></p><p>表格中就有我们很常见的<code>192.168.0.0</code>,一般来说，整个网络的第一个地址<code>192.168.0.1</code>就是你这个私有网络的出口地址，比如你家的路由器地址就是这个；而<code>192.1678.0.255</code>就是广播地址。</p><h2 id="1-3-动态主机配置协议-DHCP"><a href="#1-3-动态主机配置协议-DHCP" class="headerlink" title="1.3 动态主机配置协议(DHCP)"></a>1.3 动态主机配置协议(DHCP)</h2><p>网络管理员需要做的是，配置一段共享的IP地址，每一台新接入的机器都会通过DHCP协议，来这个共享的IP地址里申请，然后自动配置好。</p><h3 id="1-3-1-DHCP的工作方式"><a href="#1-3-1-DHCP的工作方式" class="headerlink" title="1.3.1 DHCP的工作方式"></a>1.3.1 DHCP的工作方式</h3><ol><li>新机器加入进网络 – DHCP discover</li></ol><p>新机器使用IP地址<code>0.0.0.0</code>发送一个广播包，目的IP地址是<code>255.255.255.255</code>. 广播包封装了UDP， UDP封装了BOOTP，DHCP是BOOTP的增强版。</p><p>在这个广播包里，新机器会说我是新来的(Boot Request), 我的MAC地址是blabla，我还没有IP地址，需要租一个！</p><p><img src="https://i.loli.net/2020/02/02/8U3bkmHJVsXzfgu.jpg" alt="fig4.jpg"></p><ol start="2"><li>DHCP offer</li></ol><p>DHCP server 为客户保留一个IP地址，不会再给别的客户用这个IP地址了。DHCP的offer的格式如下，里面有给新人分配的地址：</p><p><img src="https://i.loli.net/2020/02/02/JgBRu5WK9QvYFdG.jpg" alt="fig5.jpg"></p><p>这个时候仍然使用广播IP作为目的地址，因为此时新机器还没有IP地址呢。值得注意的是，有可能在配置的时候会有多个DHCP server，这个新机器可能收到多个DHCP Offer，新机器会选择一般是最近的一个，然后向网络发送一个告知信息的信息包，成为DHCP request</p><ol start="3"><li>DHCP request</li></ol><p>这个广播数据包里面包含客户端的MAC地址，接受的租约中的IP地址，提供此租约的DHCP服务器地址等信息。</p><p><img src="https://i.loli.net/2020/02/02/nzURpgrOsjeIJmd.jpg" alt="fig6.jpg"></p><p>注意这个时候新机器的IP还没有得到确认，所以客户端仍然使用0.0.0.0作为源地址</p><ol start="4"><li>DHCP ACK</li></ol><p>当DHCP server接收到客户机的DHCP request之后，会广播返回给客户机一个DHCP ACK消息，表示已经接受客户机的选择</p><p><img src="https://i.loli.net/2020/02/02/fYRICBnTgHGqF6c.jpg" alt="fig7.jpg"></p><h3 id="1-3-2-IP地址的收回和续租"><a href="#1-3-2-IP地址的收回和续租" class="headerlink" title="1.3.2 IP地址的收回和续租"></a>1.3.2 IP地址的收回和续租</h3><p>客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的 DHCP Server 发送 DHCP request 消息包。客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了。</p><h3 id="1-3-3-DHCP协议-自动安装操作系统-PXE-预启动执行环境"><a href="#1-3-3-DHCP协议-自动安装操作系统-PXE-预启动执行环境" class="headerlink" title="1.3.3 DHCP协议- 自动安装操作系统 - PXE(预启动执行环境)"></a>1.3.3 DHCP协议- 自动安装操作系统 - PXE(预启动执行环境)</h3><p>其实，这个过程和操作系统启动的过程有点儿像。首先，启动 BIOS。这是一个特别小的小系统，只能干特别小的一件事情。其实就是读取硬盘的 MBR 启动扇区，将 GRUB 启动起来；然后将权力交给 GRUB，GRUB 加载内核、加载作为根文件系统的 initramfs 文件；然后将权力交给内核；最后内核启动，初始化整个操作系统。那我们安装操作系统的过程，只能插在 BIOS 启动之后了。因为没安装系统之前，连启动扇区都没有。因而这个过程叫做<strong>预启动执行环境（Pre-boot Execution Environment）</strong></p><p>PXE协议会先把客户端放到BIOS里面，当计算机启动的时候，BIOS把PXE客户端调入内存里面，就可以连接到服务端做一些操作了。</p><p>首先，PXE 客户端自己也需要有个 IP 地址。因为 PXE 的客户端启动起来，就可以发送一个 DHCP 的请求，让 DHCP Server 给它分配一个地址。PXE 客户端有了自己的地址，那它怎么知道 PXE 服务器在哪里呢？对于其他的协议，都好办，要么人告诉他。例如，告诉浏览器要访问的 IP 地址，或者在配置中告诉它；例如，微服务之间的相互调用。</p><p>但是 PXE 客户端启动的时候，啥都没有。好在 DHCP Server 除了分配 IP 地址以外，还可以做一些其他的事情。这里有一个 DHCP Server 的一个样例配置：</p><pre><code>ddns-update-style interim;ignore client-updates;allow booting;allow bootp;subnet 192.168.1.0 netmask 255.255.255.0{option routers 192.168.1.1;option subnet-mask 255.255.255.0;option time-offset -18000;default-lease-time 21600;max-lease-time 43200;range dynamic-bootp 192.168.1.240 192.168.1.250;filename &quot;pxelinux.0&quot;;next-server 192.168.1.180;}</code></pre><p>按照上面的原理，默认的 DHCP Server 是需要配置的，无非是我们配置 IP 的时候所需要的 IP 地址段、子网掩码、网关地址、租期等。如果想使用 PXE，则需要配置 next-server，指向 PXE 服务器的地址，另外要配置初始启动文件 filename。</p><p><img src="https://i.loli.net/2020/02/02/jzfUBDdHvXFOorq.jpg" alt="fig8.jpg"></p><h1 id="2-ICMP协议"><a href="#2-ICMP协议" class="headerlink" title="2. ICMP协议"></a>2. ICMP协议</h1><p>ping的工作原理，ping是基于ICMP协议来工作的，ICMP全称为: Internet Control Message Protocol，就是互联网控制报文协议。</p><p>ICMP报文是封装在IP包里面的。如图所示</p><p><img src="https://i.loli.net/2020/02/02/msIXOvPpSal59h3.jpg" alt="fig9.jpg"></p><h2 id="2-1-查询报文类型"><a href="#2-1-查询报文类型" class="headerlink" title="2.1 查询报文类型"></a>2.1 查询报文类型</h2><p>ICMP主动发起的，对于ping的主动请求，进行网络抓包，称为ICMP ECHO REQUEST. 同理主动请求的回复称为ICMP ECHO REPLY. 比起原生的ICMP多了标识符和序号两个字段。</p><h2 id="2-2-差错报文类型"><a href="#2-2-差错报文类型" class="headerlink" title="2.2 差错报文类型"></a>2.2 差错报文类型</h2><ol><li>终点不可达 3</li></ol><ul><li>网络不可达 0</li><li>主机不可达 1</li><li>协议不可达 2</li><li>端口不可达 3</li><li>需要进行分片但设置了不分片</li></ul><ol start="2"><li>源抑制 4</li></ol><p>源站放慢了速度</p><ol start="3"><li>超时 11</li></ol><p>超过了网络包的生存时间，但是还没到</p><ol start="4"><li>重定向 5</li></ol><p>换下次发送使用的路由器</p><h2 id="2-3-Ping的使用-查询报文类型的使用"><a href="#2-3-Ping的使用-查询报文类型的使用" class="headerlink" title="2.3 Ping的使用 查询报文类型的使用"></a>2.3 Ping的使用 查询报文类型的使用</h2><p>下图描述了ping的整个发送和接收过程。<br><img src="https://i.loli.net/2020/02/02/myJlI8dY1rju3sw.jpg" alt="fig10.jpg"></p><p>假定主机 A 的 IP 地址是 192.168.1.1，主机 B 的 IP 地址是 192.168.1.2，它们都在同一个子网。那当你在主机 A 上运行“ping 192.168.1.2”后，会发生什么呢?</p><p>ping 命令执行的时候，源主机首先会构建一个 ICMP 请求数据包，ICMP 数据包内包含多个字段。最重要的是两个，第一个是类型字段，对于请求数据包而言该字段为 8；另外一个是顺序号，主要用于区分连续 ping 的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加 1。为了能够计算往返时间 RTT，它会在报文的数据部分插入发送时间。</p><p>然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，加上一些其他控制信息，构建一个 IP 数据包。</p><p>接下来，需要加入 MAC 头。如果在本节 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。</p><p>主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。</p><p>主机 B 会构建一个 ICMP 应答包，应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给主机 A。</p><p>在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 应答包，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。</p><h2 id="2-4-traceroute-差错报文类型的使用"><a href="#2-4-traceroute-差错报文类型的使用" class="headerlink" title="2.4 traceroute 差错报文类型的使用"></a>2.4 traceroute 差错报文类型的使用</h2><p>traceroute会故意设置特殊的TTL，来追踪去往目的地沿途经过的路由器。Traceroute 的参数指向某个目的 IP 地址，它会发送一个 UDP 的数据包。将 TTL 设置成 1，也就是说一旦遇到一个路由器或者一个关卡，就表示它“牺牲”了。</p><p>如果中间的路由器不止一个，当然碰到第一个就“牺牲”。于是，返回一个 ICMP 包，也就是网络差错包，类型是时间超时。那大军前行就带一顿饭，试一试走多远会被饿死，然后找个哨探回来报告，那我就知道大军只带一顿饭能走多远了。接下来，将 TTL 设置为 2。第一关过了，第二关就“牺牲”了，那我就知道第二关有多远。如此反复，直到到达目的主机。这样，Traceroute 就拿到了所有的路由器 IP。当然，有的路由器压根不会回这个 ICMP。这也是 Traceroute 一个公网的地址，看不到中间路由的原因。</p><p>怎么知道 UDP 有没有到达目的主机呢？Traceroute 程序会发送一份 UDP 数据报给目的主机，但它会选择一个不可能的值作为 UDP 端口号（大于 30000）。当该数据报到达时，将使目的主机的 UDP 模块产生一份“端口不可达”错误 ICMP 报文。如果数据报没有到达，则可能是超时。</p><p>Traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU。</p><p>要做的工作首先是发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口 MTU 相等。如果中间遇到窄的关口会被卡住，会发送 ICMP 网络差错包，类型为“需要进行分片但设置了不分片位”。其实，这是人家故意的好吧，每次收到 ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。</p><h1 id="3-跨网关访问"><a href="#3-跨网关访问" class="headerlink" title="3. 跨网关访问"></a>3. 跨网关访问</h1><p><img src="https://i.loli.net/2020/02/02/RY9W3aixfpqEtOc.jpg" alt="fig16.jpg"><br>一旦配置了IP地址和网关，往往就能够指定目标地址进行访问了。在跨网关访问的时候，会牵扯到MAC地址和IP地址的变化。</p><p>在 MAC 头里面，先是目标 MAC 地址，然后是源 MAC 地址，然后有一个协议类型，用来说明里面是 IP 协议。IP 头里面的版本号，目前主流的还是 IPv4，服务类型 TOS 在第三节讲 ip addr 命令的时候讲过，TTL 在第 7 节讲 ICMP 协议的时候讲过。另外，还有 8 位标识协议。这里到了下一层的协议，也就是，是 TCP 还是 UDP。最重要的就是源 IP 和目标 IP。先是源 IP 地址，然后是目标 IP 地址。</p><p>在任何一台机器上，当要访问另外一个IP地址的时候，都会先判断这个目标地址和当前机器的IP地址是否在同一个网段当中。使用CIDR和子网掩码来进行判断。</p><p>如果不是同一个网段的，就需要将请求发往默认网关gateway. Gateway的地址一定和源IP地址是一个网段的。例如192.168.1.0/24这个网段，Gateway往往是192.168.1.1/24或者192.168.1.2/24 </p><p>如何发往默认网关呢？网关不是和源 IP 地址是一个网段的么？这个过程就和发往同一个网段的其他机器是一样的：将源地址和目标 IP 地址放入 IP 头中，通过 ARP 获得网关的 MAC 地址，将源 MAC 和网关的 MAC 放入 MAC 头中，发送出去。网关所在的端口，例如 192.168.1.1/24 将网络包收进来，然后接下来怎么做，就完全看网关的了。</p><p>网关往往是一个<strong><em>路由器</em></strong>，是个三层转发设备（<strong><em>就是把MAC头和IP头都取下来，然后根据里面的内容，看看接下来把包往哪里转发的设备</em></strong>）</p><h2 id="3-1-静态路由"><a href="#3-1-静态路由" class="headerlink" title="3.1 静态路由"></a>3.1 静态路由</h2><p>在路由器上配置一条条规则，通过网关进行转发</p><h3 id="3-1-1-转发网关"><a href="#3-1-1-转发网关" class="headerlink" title="3.1.1 转发网关"></a>3.1.1 转发网关</h3><p>只改变MAC地址，不改变IP的网关</p><p><img src="https://i.loli.net/2020/02/02/QJE7CzFcOVjDuTp.jpg" alt="fig11.jpg"></p><p>服务器 A 要访问服务器 B。首先，服务器 A 会思考，192.168.4.101 和我不是一个网段的，因而需要先发给网关。那网关是谁呢？已经静态配置好了，网关是 192.168.1.1。网关的 MAC 地址是多少呢？发送 ARP 获取网关的 MAC 地址，然后发送包。包的内容是这样的：</p><ul><li>源MAC: server A MAC addr</li><li>目标MAC: 192.168.1.1 这个网口的MAC</li><li>源IP： 192.168.1.101</li><li>目标IP: 192.168.4.101 </li></ul><p>包到达 192.168.1.1 这个网口，发现 MAC 一致，将包收进来，开始思考往哪里转发。在路由器 A 中配置了静态路由之后，要想访问 192.168.4.0/24，要从 192.168.56.1 这个口出去，下一跳为 192.168.56.2。</p><p>于是，路由器 A 思考的时候，匹配上了这条路由，要从 192.168.56.1 这个口发出去，发给 192.168.56.2，那 192.168.56.2 的 MAC 地址是多少呢？路由器 A 发送 ARP 获取 192.168.56.2 的 MAC 地址，然后发送包。包的内容是这样的：</p><ul><li>源MAC: 192.168.56.1 MAC addr</li><li>目标MAC: 192.168.56.2 这个网口的MAC</li><li>源IP： 192.168.1.101</li><li>目标IP: 192.168.4.101 </li></ul><p>包到达 192.168.56.2 这个网口，发现 MAC 一致，将包收进来，开始思考往哪里转发。在路由器 B 中配置了静态路由，要想访问 192.168.4.0/24，要从 192.168.4.1 这个口出去，没有下一跳了。</p><p>于是，路由器 B 思考的时候，匹配上了这条路由，要从 192.168.4.1 这个口发出去，发给 192.168.4.101。那 192.168.4.101 的 MAC 地址是多少呢？路由器 B 发送 ARP 获取 192.168.4.101 的 MAC 地址，然后发送包。包的内容是这样的：</p><ul><li>源MAC: 192.168.4.1 MAC addr</li><li>目标MAC: 192.168.4.101 这个网口的MAC</li><li>源IP： 192.168.1.101</li><li>目标IP: 192.168.4.101 </li></ul><p>包到达服务器B，由上述过程可以看出，MAC地址一直都是变的，而IP地址一直都不会变。</p><h3 id="3-1-2-NAT网关-Network-Address-Translation"><a href="#3-1-2-NAT网关-Network-Address-Translation" class="headerlink" title="3.1.2 NAT网关 (Network Address Translation)"></a>3.1.2 NAT网关 (Network Address Translation)</h3><p>NAT网关出现的原因是IP冲突，如下图所示，各个局域网在设值的时候IP是一样的情况。</p><p><img src="https://i.loli.net/2020/02/02/tymIY6pk3iwNz1a.jpg" alt="fig12.jpg"></p><p>这里遇见的第一个问题是，局域网之间没有商量过，各定各的网段，因而 IP 段冲突了。最左面源地址是 192.168.1.101，最右面目标地址也是 192.168.1.101，如果单从 IP 地址上看，简直是自己访问自己，其实是源的 192.168.1.101 要访问目标的 192.168.1.101。</p><p>解决这个问题，就是在中间的局域网中使用另外的地址，来进行区分。有点像身份证和护照的关系。</p><p>首先，目标服务器 B 在国际上要有一个国际的身份，我们给它一个 192.168.56.2。在网关 B 上，我们记下来，国际身份 192.168.56.2 对应国内身份 192.168.1.101。凡是要访问 192.168.56.2，都转成 192.168.1.101。</p><p>于是，源服务器 A 要访问目标服务器 B，要指定的目标地址为 192.168.56.2。这是它的国际身份。服务器 A 想，192.168.56.2 和我不是一个网段的，因而需要发给网关，网关是谁？已经静态配置好了，网关是 192.168.1.1，网关的 MAC 地址是多少？发送 ARP 获取网关的 MAC 地址，然后发送包。包的内容是这样的：</p><ul><li>源MAC: 服务器A 的 MAC addr</li><li>目标MAC: 192.168.1.1 这个网口的MAC</li><li>源IP： 192.168.1.101</li><li>目标IP: 192.168.56.2</li></ul><p>包到达 192.168.1.1 这个网口，发现 MAC 一致，将包收进来，开始思考往哪里转发。</p><p>在路由器 A 中配置了静态路由：要想访问 192.168.56.2/24，要从 192.168.56.1 这个口出去，没有下一跳了。</p><p>于是，路由器 A 思考的时候，匹配上了这条路由，要从 192.168.56.1 这个口发出去，发给 192.168.56.2。那 192.168.56.2 的 MAC 地址是多少呢？路由器 A 发送 ARP 获取 192.168.56.2 的 MAC 地址。</p><p>当网络包发送到中间的局域网的时候，服务器 A 也需要有个国际身份，因而在国际上，源 IP 地址也不能用 192.168.1.101，需要改成 192.168.56.1。发送包的内容是这样的：</p><ul><li>源MAC: 192.168.1.1 MAC addr</li><li>目标MAC: 192.168.1.101 这个网口的MAC</li><li>源IP： 192.168.56.1</li><li>目标IP: 192.168.1.101</li></ul><p>从服务器B接收的包可以看出，源IP是服务器A的国际身份，发送包回去的时候，也是发给这个国际身份，由路由器A做NAT，转换为国内身份。</p><h2 id="3-2-动态路由"><a href="#3-2-动态路由" class="headerlink" title="3.2 动态路由"></a>3.2 动态路由</h2><h3 id="3-2-1-路由表"><a href="#3-2-1-路由表" class="headerlink" title="3.2.1 路由表"></a>3.2.1 路由表</h3><p>路由器是一台网络设备，有多张网卡，当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。这个转发信息库通常被称为路由表。</p><p>一张路由表会有多个路由规则，每一天规则至少包含这三项信息： </p><ul><li>目的网络</li><li>出口设备</li><li>下一跳网关</li></ul><h3 id="3-2-2-策略路由"><a href="#3-2-2-策略路由" class="headerlink" title="3.2.2 策略路由"></a>3.2.2 策略路由</h3><p>根据多个参数来配置路由，这样来使得不同来源的包走不同的路由。</p><p>家里的网络呢，就是普通的家用网段 192.168.1.x/24。家里有两个租户，分别把线连到路由器上。IP 地址为 192.168.1.101/24 和 192.168.1.102/24，网关都是 192.168.1.1/24，网关在路由器上。两个运营商都要为这个网关配置一个公网的 IP 地址。如果你去查看你们家路由器里的网段，基本就是我图中画的样子。</p><p><img src="https://i.loli.net/2020/02/02/ZCbyHwg8prBSIz2.jpg" alt="fig13.jpg"></p><p>运行商里面也有一个 IP 地址，在运营商网络里面的网关。不同的运营商方法不一样，有的是 /32 的，也即一个一对一连接。例如，运营商 1 给路由器分配的地址是 183.134.189.34/32，而运营商网络里面的网关是 183.134.188.1/32。有的是 /30 的，也就是分了一个特别小的网段。运营商 2 给路由器分配的地址是 60.190.27.190/30，运营商网络里面的网关是 60.190.27.189/30。</p><pre><code>$ ip route list table main 60.190.27.189/30 dev eth3  proto kernel  scope link  src 60.190.27.190183.134.188.1 dev eth2  proto kernel  scope link  src 183.134.189.34192.168.1.0/24 dev eth1  proto kernel  scope link  src 192.168.1.1127.0.0.0/8 dev lo  scope linkdefault via 183.134.188.1 dev eth2</code></pre><ul><li>如果去运营商二，就走 eth3；</li><li>如果去运营商一呢，就走 eth2；</li><li>如果访问内网，就走 eth1；</li><li>如果所有的规则都匹配不上，默认走运营商一，也即走快的网络。</li></ul><p>如何让IP默认走运营商2？</p><p>添加一个新的table， chao</p><pre><code># echo 200 chao &gt;&gt; /etc/iproute2/rt_tables</code></pre><p>添加一条规则：</p><pre><code># ip rule add from 192.168.1.101 table chao# ip rule ls0:    from all lookup local 32765:    from 10.0.0.10 lookup chao32766:    from all lookup main 32767:    from all lookup default</code></pre><p>设定规则为：从 192.168.1.101 来的包都查看个 chao 这个新的路由表。<br>在chao路由表中添加规则： </p><pre><code># ip route add default via 60.190.27.189 dev eth3 table chao# ip route flush cache</code></pre><h3 id="3-2-3-动态路由算法"><a href="#3-2-3-动态路由算法" class="headerlink" title="3.2.3 动态路由算法"></a>3.2.3 动态路由算法</h3><p>寻找最短路径，主要使用Bellman-Ford算法和Dijkstra算法。</p><ol><li>距离矢量路由算法</li></ol><p>这种算法的基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。</p><p>由此可以看出，每个路由器都是知道全局信息的。那这个信息如何更新呢？每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。</p><p>每个路由器根据新收集的信息，计算和其他路由器的距离，比如自己的一个邻居距离目标路由器的距离是 M，而自己距离邻居是 x，则自己距离目标路由器是 x+M。</p><p>存在的问题1： <strong><em>好消息传得快，坏消息传得慢</em></strong> 如果有个路由器加入了这个网络，它的邻居就能很快发现它，然后将消息广播出去。要不了多久，整个网络就都知道了。但是一旦一个路由器挂了，挂的消息是没有广播的。当每个路由器发现原来的道路到不了这个路由器的时候，感觉不到它已经挂了，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器是真的挂了。</p><p>原来的网络包括两个节点，B 和 C。A 加入了网络，它的邻居 B 很快就发现 A 启动起来了。于是它将自己和 A 的距离设为 1，同样 C 也发现 A 起来了，将自己和 A 的距离设置为 2。但是如果 A 挂掉，情况就不妙了。B 本来和 A 是邻居，发现连不上 A 了，但是 C 还是能够连上，只不过距离远了点，是 2，于是将自己的距离设置为 3。殊不知 C 的距离 2 其实是基于原来自己的距离为 1 计算出来的。C 发现自己也连不上 A，并且发现 B 设置为 3，于是自己改成距离 4。依次类推，数越来越大，直到超过一个阈值，我们才能判定 A 真的挂了。</p><p>存在的问题2： <strong><em>每次发送的时候，要发送整个全局路由表</em></strong> </p><p>当网络规模比较小的时候，全局路由表比较小（15跳以内）；如果网络规模比较大，就不适用了。</p><p>(不相关的分割线： 感觉很像区块链在做的事情，行为上的类似，目的上的不同)</p><ol start="2"><li>链路状态路由算法</li></ol><p>Link state routing </p><p>这种算法的基本思路是：当一个路由器启动的时候，首先是发现邻居，向邻居 say hello，邻居都回复。然后计算和邻居的距离，发送一个 echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到两点之间的最短路径。</p><p>不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和 CPU 利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。</p><h3 id="3-2-4-动态路由协议"><a href="#3-2-4-动态路由协议" class="headerlink" title="3.2.4 动态路由协议"></a>3.2.4 动态路由协议</h3><ol><li>基于链路状态路由算法的OSPF</li></ol><p>OSPF - Open Shortest Path First 开放式最短路径优先）就是基于链路状态路由协议，广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议Interior Gateway Protocol </p><p>内部网关协议的重点就是找到最短的路径。在一个组织内部，路径最短往往最优。当然有时候 OSPF 可以发现多个最短的路径，可以在这多个路径中进行负载均衡，这常常被称为等价路由。</p><p><img src="https://i.loli.net/2020/02/02/tbrWjqNz2swxkVY.jpg" alt="fig14.jpg"></p><ol start="2"><li>基于距离矢量路由算法的BGP(Border Gateway Protocol)</li></ol><p>外部政策的问题，每个数据中心都会设值自己的Policy：</p><ul><li>哪些外部IP可以让内部知道</li><li>哪些内部IP可以让外部知道</li></ul><p>每个都为一个自治系统AS, Autonomous System,自治系统分为几种类型：</p><ul><li>Stub AS：对外只有一个连接。这类 AS 不会传输其他 AS 的包。例如，个人或者小公司的网络。</li><li>Multihomed AS：可能有多个连接连到其他的 AS，但是大多拒绝帮其他的 AS 传输包。例如一些大公司的网络。</li><li>Transit AS：有多个连接连到其他的 AS，并且可以帮助其他的 AS 传输包。例如主干网。</li></ul><p>每个自治系统都有<strong>* 边界路由器*</strong>，来和外界进行联系。</p><p><img src="https://i.loli.net/2020/02/02/2CgFAUMGohak7OJ.jpg" alt="fig15.jpg"></p><p>BGP协议使用的是路径矢量路由协议，（path-vector protocol）。它是距离矢量路由协议的升级版。</p><p>前面说了距离矢量路由协议的缺点。其中一个是收敛慢。在 BGP 里面，除了下一跳 hop 之外，还包括了自治系统 AS 的路径，从而可以避免坏消息传的慢的问题，也即上面所描述的，B 知道 C 原来能够到达 A，是因为通过自己，一旦自己都到达不了 A 了，就不用假设 C 还能到达 A 了。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> IP Protocol </tag>
            
            <tag> CIDR </tag>
            
            <tag> DHCP </tag>
            
            <tag> ICMP </tag>
            
            <tag> Router </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(三)-链路层</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%89-%E9%93%BE%E8%B7%AF%E5%B1%82/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%89-%E9%93%BE%E8%B7%AF%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<p>MAC层是用来解决多路访问的堵车问题的，ARP通过在局域网大吼一声的方式来寻找目标MAC地址。交换机有MAC地址学习能力。 </p><h1 id="1-MAC层"><a href="#1-MAC层" class="headerlink" title="1. MAC层"></a>1. MAC层</h1><p>在物理层中，我们引入了Hub，集线器，这种设备可以将多个终端连起来，但是它会把所有自己收到的信息都复制到其他端口当中。</p><p>需要在数据链路层解决的问题有：</p><ol><li>包的发送方和接收方</li><li>多个包发送的时候的先后顺序的问题</li><li>发生错误了怎么办</li></ol><p>这些问题都是在数据链路层，也即MAC层(Medium Access Control)，要解决的问题.</p><p>做媒体访问控制，控制在往媒体上发数据的时候，谁先发谁后发的问题，防止发生混乱。—— 多路访问规则</p><p>下面针对三个问题的解决进行详细分析</p><h2 id="1-1-包的发送方接收方的确认"><a href="#1-1-包的发送方接收方的确认" class="headerlink" title="1.1 包的发送方接收方的确认"></a>1.1 包的发送方接收方的确认</h2><h3 id="1-1-1-知道目标和源MAC地址时"><a href="#1-1-1-知道目标和源MAC地址时" class="headerlink" title="1.1.1 知道目标和源MAC地址时"></a>1.1.1 知道目标和源MAC地址时</h3><p>用物理地址，——链路层地址，常被称为MAC地址</p><p><img src="https://i.loli.net/2020/02/02/apAPTkyrFx6vczW.jpg" alt="fig1.jpg"></p><h3 id="1-1-2-只知道目标IP地址时-——-ARP协议"><a href="#1-1-2-只知道目标IP地址时-——-ARP协议" class="headerlink" title="1.1.2 只知道目标IP地址时 —— ARP协议"></a>1.1.2 只知道目标IP地址时 —— ARP协议</h3><p>ARP协议，是已知IP地址，求MAC地址的协议。</p><p>在一个局域网内，知道IP，想获得对应的MAC，就是在局域网中大吼一声， 看回应，hhhh</p><p><img src="https://i.loli.net/2020/02/02/pS2vUbZIw638hGg.jpg" alt="fig2.jpg"></p><p>具体询问和回答的报文如下所示：</p><p><img src="https://i.loli.net/2020/02/02/TvSIZwFQf1tRWsy.jpg" alt="fig3.jpg"></p><h2 id="1-2-多路访问原则"><a href="#1-2-多路访问原则" class="headerlink" title="1.2 多路访问原则"></a>1.2 多路访问原则</h2><ol><li>信道划分：分成多个车道，各走各的</li><li>轮流协议：单双号限行</li><li>随机接入协议：错峰</li></ol><h2 id="1-3-错误处理-——-循环冗余检测"><a href="#1-3-错误处理-——-循环冗余检测" class="headerlink" title="1.3 错误处理 —— 循环冗余检测"></a>1.3 错误处理 —— 循环冗余检测</h2><p>看图1，整个数据包的最后四字节叫做CRC，这里是通过XOR算法计算整个包是否在发送的过程中出现了错误</p><h1 id="2-交换机"><a href="#2-交换机" class="headerlink" title="2.交换机"></a>2.交换机</h1><p>交换机比起集线器，有了记忆功能。通过学习得到对应的MAC地址。</p><p>一台 MAC1 电脑将一个包发送给另一台 MAC2 电脑，当这个包到达交换机的时候，一开始交换机也不知道 MAC2 的电脑在哪个口，所以没办法，它只能将包转发给除了来的那个口之外的其他所有的口。但是，这个时候，交换机会干一件非常聪明的事情，就是交换机会记住，MAC1 是来自一个明确的口。以后有包的目的地址是 MAC1 的，直接发送到这个口就可以了。</p><p>当交换机作为一个关卡一样，过了一段时间之后，就有了整个网络的一个结构了，这个时候，基本上不用广播了，全部可以准确转发。当然，每个机器的 IP 地址会变，所在的口也会变，因而交换机上的学习的结果，我们称为转发表。转发表是有过期时间的。</p><h2 id="2-1-办公室场景下的交换机使用"><a href="#2-1-办公室场景下的交换机使用" class="headerlink" title="2.1 办公室场景下的交换机使用"></a>2.1 办公室场景下的交换机使用</h2><p>可能有上百个网口需要联网，因此需要多个交换机，形成了一个稍微复杂一些的拓扑结构。</p><p><img src="https://i.loli.net/2020/02/02/A7OaPtoZLYSs8wi.jpg" alt="fig4.jpg"></p><p>先看看两台交换机的情形。两台交换机连接着三个局域网，每个局域网上都有多台机器。如果机器 1 只知道机器 4 的 IP 地址，当它想要访问机器 4，把包发出去的时候，它必须要知道机器 4 的 MAC 地址。</p><p>于是机器 1 发起广播，机器 2 收到这个广播，但是这不是找它的，所以没它什么事。交换机 A 一开始是不知道任何拓扑信息的，在它收到这个广播后，采取的策略是，<strong>除了广播包来的方向外，它还要转发给其他所有的网口</strong>。于是机器 3 也收到广播信息了，但是这和它也没什么关系。</p><p>当然，交换机 B 也是能够收到广播信息的，但是这时候它也是不知道任何拓扑信息的，因而也是进行广播的策略，将包转发到局域网三。这个时候，机器 4 和机器 5 都收到了广播信息。机器 4 主动响应说，这是找我的，这是我的 MAC 地址。于是一个 ARP 请求就成功完成了。</p><p>在上面的过程中，交换机 A 和交换机 B 都是能够学习到这样的信息：机器 1 是在左边这个网口的。当了解到这些拓扑信息之后，情况就好转起来。当机器 2 要访问机器 1 的时候，机器 2 并不知道机器 1 的 MAC 地址，所以机器 2 会发起一个 ARP 请求。这个广播消息会到达机器 1，也同时会到达交换机 A。这个时候交换机 A 已经知道机器 1 是不可能在右边的网口的，所以这个广播信息就不会广播到局域网二和局域网三。</p><p>当机器 3 要访问机器 1 的时候，也需要发起一个广播的 ARP 请求。这个时候交换机 A 和交换机 B 都能够收到这个广播请求。交换机 A 当然知道主机 A 是在左边这个网口的，所以会把广播消息转发到局域网一。同时，交换机 B 收到这个广播消息之后，由于它知道机器 1 是不在右边这个网口的，所以不会将消息广播到局域网三。</p><h3 id="2-1-1-环路问题"><a href="#2-1-1-环路问题" class="headerlink" title="2.1.1 环路问题"></a>2.1.1 环路问题</h3><p>当整个拓扑结构变复杂了以后，可能容易出现环路问题：</p><p><img src="https://i.loli.net/2020/02/02/OeXKUsIzw7J41Qa.jpg" alt="fig5.jpg"></p><p>我们来想象一下机器 1 访问机器 2 的过程。一开始，机器 1 并不知道机器 2 的 MAC 地址，所以它需要发起一个 ARP 的广播。广播到达机器 2，机器 2 会把 MAC 地址返回来，看起来没有这两个交换机什么事情。</p><p>但是问题来了，这两个交换机还是都能够收到广播包的。交换机 A 一开始是不知道机器 2 在哪个局域网的，所以它会把广播消息放到局域网二，在局域网二广播的时候，交换机 B 右边这个网口也是能够收到广播消息的。交换机 B 会将这个广播息信息发送到局域网一。局域网一的这个广播消息，又会到达交换机 A 左边的这个接口。交换机 A 这个时候还是不知道机器 2 在哪个局域网，于是将广播包又转发到局域网二。左转左转左转，好像是个圈哦。 </p><p>可能有人会说，当两台交换机都能够逐渐学习到拓扑结构之后，是不是就可以了？</p><p>然而当广播包从左边的局域网一广播的时候，两个交换机再次刷新三观，原来机器 1 是在左边的，过一会儿，又发现不对，是在右边的，过一会，又发现不对，是在左边的。</p><p>在计算机网络中，用最小生成树算法来解决交换机生成环的问题。简而言之，通过比较交换机之间的能力，给他们分不同等级，划分出一棵树。</p><h3 id="2-1-2-如何解决广播问题和安全问题？"><a href="#2-1-2-如何解决广播问题和安全问题？" class="headerlink" title="2.1.2 如何解决广播问题和安全问题？"></a>2.1.2 如何解决广播问题和安全问题？</h3><ol><li>物理隔离</li></ol><p>每个部门有自己的交换机，配置单独的子网</p><ol start="2"><li>虚拟隔离</li></ol><p>VLAN，虚拟局域网，一个交换机上会连属于多个局域网的机器。解决方案是在原来的二层的头上加一个TAG，里面有一个VLAN ID，一共12位，可以划分出4096个VLAN</p><p><img src="https://i.loli.net/2020/02/02/WtnOa3ToZG9FkpL.jpg" alt="fig6.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(二)-物理层</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%BA%8C-%E7%89%A9%E7%90%86%E5%B1%82/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%BA%8C-%E7%89%A9%E7%90%86%E5%B1%82/</url>
      
        <content type="html"><![CDATA[<h1 id="1-物理层实现多个终端的交流"><a href="#1-物理层实现多个终端的交流" class="headerlink" title="1. 物理层实现多个终端的交流"></a>1. 物理层实现多个终端的交流</h1><p>网线的1-3, 2-6交叉接法，12，36脚分别起到收发信号的作用。IP层封装了MAC层，然后组成了几个局域网，LAN</p><p>HUB在物理层工作，会将自己收到的每一个字节，都复制到其他端口上去。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络协议(一) -- 框架</title>
      <link href="/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%80-%E6%A1%86%E6%9E%B6/"/>
      <url>/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%80-%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="1-协议"><a href="#1-协议" class="headerlink" title="1. 协议"></a>1. 协议</h1><p>协议是由语法，语义，顺序三部分构成。内容要符合一定的规则和格式。内容要代表某种意义，要有先做再做的先后顺序。</p><h1 id="2-框架"><a href="#2-框架" class="headerlink" title="2.框架"></a>2.框架</h1><h2 id="2-1-应用层"><a href="#2-1-应用层" class="headerlink" title="2.1 应用层"></a>2.1 应用层</h2><p>DHCP HTTP HTTPS RTMP P2P DNS GTP RPC </p><h2 id="2-2-传输层"><a href="#2-2-传输层" class="headerlink" title="2.2 传输层"></a>2.2 传输层</h2><p>UDP TCP</p><h2 id="2-3-网络层"><a href="#2-3-网络层" class="headerlink" title="2.3 网络层"></a>2.3 网络层</h2><p>ICMP IP OSPF BGP IPSec GRE</p><h2 id="2-4-链路层"><a href="#2-4-链路层" class="headerlink" title="2.4 链路层"></a>2.4 链路层</h2><p>ARP VLAN STP</p><h2 id="2-5-物理层"><a href="#2-5-物理层" class="headerlink" title="2.5 物理层"></a>2.5 物理层</h2><p>网络跳线</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat - 连接器</title>
      <link href="/Tomcat-%E8%BF%9E%E6%8E%A5%E5%99%A8/"/>
      <url>/Tomcat-%E8%BF%9E%E6%8E%A5%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>Unix系统下的I/O模型共有5种: </p><ul><li>同步阻塞I/O </li><li>同步非阻塞I/O</li><li>I/O多路复用</li><li>信号驱动I/O</li><li>异步I/O</li></ul><p>关于连接器，我们将主要从Tomcat如何实现几种I/O手段来入手进行详解。</p><h1 id="1-Java-I-O-模型"><a href="#1-Java-I-O-模型" class="headerlink" title="1. Java I/O 模型"></a>1. Java I/O 模型</h1><p>I/O是指计算机内存与外部设备之间拷贝数据的过程。CPU是先把外部设备的数据读到内存里，然后再进行处理的。</p><p>Java I/O模型之间的不同之处在于在数据从外部设备拷贝到内存的过程当中，CPU闲置，是继续给当前进程使用，还是把CPU给其他进程使用呢。</p><p>在Java I/O模型当中，网络通信过程会涉及到两个对象：</p><ul><li>调用该I/O操作的用户线程<ul><li>用户线程等待内核将数据从网卡拷贝到内核空间</li><li>内核将数据从内核空间拷贝到用户空间</li></ul></li><li>操作系统内核</li></ul><p>各个I/O模型实现这两个步骤的方式是不一样的。</p><h2 id="1-1-同步阻塞I-O"><a href="#1-1-同步阻塞I-O" class="headerlink" title="1.1 同步阻塞I/O"></a>1.1 同步阻塞I/O</h2><p>用户线程发起read调用吼就阻塞了，让出CPU。内核等待网卡数据到来，把数据从网卡拷贝到内核空间，接着把数据拷贝到用户空间，再把用户线程叫醒。</p><p><img src="https://i.loli.net/2020/02/02/nPOsYLSymTGZKBf.jpg" alt="fig1.jpg"></p><h2 id="1-2-同步非阻塞I-O"><a href="#1-2-同步非阻塞I-O" class="headerlink" title="1.2 同步非阻塞I/O"></a>1.2 同步非阻塞I/O</h2><p>用户线程不断发起read调用，数据没到内核空间时，每次都返回失败，直到数据到了内核空间，这一次read调用后，在等待数据从内核空间拷贝到用户空间这段时间，线程还是阻塞的，等数据到了用户空间再把线程叫醒。 </p><p><img src="https://i.loli.net/2020/02/02/8eqioQx14zkZWjK.jpg" alt="fig2.jpg"></p><h2 id="1-3-I-O多路复用"><a href="#1-3-I-O多路复用" class="headerlink" title="1.3 I/O多路复用"></a>1.3 I/O多路复用</h2><p>用户线程的读取操作分为两步，线程首先发起select调用，目的是问内核数据准备好了没有，等内核把数据准备好，用户线程再发起read调用。在等待数据从内核空间拷贝到用户空间的这段时间里，线程还是阻塞的。</p><p>多路复用的意思是一次select调用会向内核查多个数据通道的状态，因此叫做多路复用。</p><p><img src="https://i.loli.net/2020/02/02/I3GH1PBRrwnfE9Q.jpg" alt="fig3.jpg"></p><h2 id="1-4-异步I-O"><a href="#1-4-异步I-O" class="headerlink" title="1.4 异步I/O"></a>1.4 异步I/O</h2><p>用户线程发起read调用的同时注册一个回调函数，read立即返回，等内核将数据准备好以后，再调用指定的回调函数完成处理。这个过程中，用户线程一直没有阻塞。</p><h1 id="2-NioEndpoint组件"><a href="#2-NioEndpoint组件" class="headerlink" title="2. NioEndpoint组件"></a>2. NioEndpoint组件</h1><p>Tomcat的NioEndpoint组件实现了I/O多路复用模型。</p><h2 id="2-1-总体工作流程"><a href="#2-1-总体工作流程" class="headerlink" title="2.1 总体工作流程"></a>2.1 总体工作流程</h2><ul><li>创建一个selector，注册各种事件，然后调用select方法，等待感兴趣的事情发生</li><li>感兴趣的事情发生了，就创建一个新的线程从Channel中读取数据。</li></ul><p><img src="https://i.loli.net/2020/02/02/8caQkFDGKJinjgy.jpg" alt="fig4.jpg"></p><p>NioEndpoint共有5个组件，分别是：</p><ul><li><p>LimitLatch</p><ul><li>连接控制器<ul><li>负责控制最大连接数</li><li>一般设定为10000</li></ul></li></ul></li><li><p>Acceptor</p><ul><li>跑在一个独立的线程当中</li><li>在一个死循环里调用accept方法来接收新连接，一旦有新的连接请求到来，accept方法返回一个Channel对象，接着把Channel对象交给Poller去处理</li></ul></li><li><p>Poller</p><ul><li>Poller本质上是一个selector, 也跑在单独线程里。Poller在内部维护一个Channel数组，在一个死循环里不断检测Channel的数据就绪状态，一旦有Channel可读，就生成一个SocketProcessor任务对象扔给Executor去处理 </li></ul></li><li><p>SocketProcessor</p><ul><li>run方法会调用Http11Processor来读取和解析请求数据 </li></ul></li><li><p>Executor </p><ul><li>线程池</li><li>负责运行SocketProcessor任务类</li></ul></li></ul><h2 id="2-2-LimitLatch"><a href="#2-2-LimitLatch" class="headerlink" title="2.2 LimitLatch"></a>2.2 LimitLatch</h2><p>用来控制连接个数，当连接数到达最大时阻塞线程，直到后续组件处理完一个连接后才将连接数减1.到达最大连接数以后操作系统底层还是会接收客户端连接，但用户层已经不再接收了。</p><pre><code>public class LimitLatch {// AbstractQueuedSynchronizer在内部维护一个状态和一个线程队列// 用来控制线程什么时候挂起，什么时候唤醒    private class Sync extends AbstractQueuedSynchronizer {        @Override        protected int tryAcquireShared() {            long newCount = count.incrementAndGet();            if (newCount &gt; limit) {                count.decrementAndGet();                return -1;            } else {                return 1;            }        }        // 定义合适唤醒被阻塞的用户线程        @Override        protected boolean tryReleaseShared(int arg) {            count.decrementAndGet();            return true;        }    }    private final Sync sync;    private final AtomicLong count;    private volatile long limit;    // 线程调用这个方法来获得接收新连接的许可，线程可能被阻塞     // AQS知道是否需要阻塞的逻辑在tryAcquireShared方法当中定义了    public void countUpOrAwait() throws InterruptedException {      sync.acquireSharedInterruptibly(1);    }    // 调用这个方法来释放一个连接许可，那么前面阻塞的线程可能被唤醒    //     public long countDown() {      sync.releaseShared(0);      long result = getCount();      return result;   }}</code></pre><h2 id="2-3-Acceptor"><a href="#2-3-Acceptor" class="headerlink" title="2.3 Acceptor"></a>2.3 Acceptor</h2><p>Acceptor实现了Runnable接口，一个端口号只能对应一个ServerSocketChannel，故而这个Channel是在多个Acceptor线程之间共享的。</p><pre><code>serverSock = ServerSocketChannel.open();serverSock.socket().bind(addr,getAcceptCount());serverSock.configureBlocking(true);</code></pre><ul><li>bind 方法的第二个参数表示操作系统的等待队列长度，我在上面提到，当应用层面的连接数到达最大值时，操作系统可以继续接收连接，那么操作系统能继续接收的最大连接数就是这个队列长度，可以通过 acceptCount 参数配置，默认是 100。</li><li>ServerSocketChannel 被设置成阻塞模式，也就是说它是以阻塞的方式接收连接的。</li></ul><p>ServerSocketChannel通过accept()接受新的连接，accept()方法返回获得SocketChannel对象，然后将SocketChannel对象封装在一个PollerEvent对象当中，并将PollerEvent对象压入Poller的Queue当中。</p><h2 id="2-4-Poller"><a href="#2-4-Poller" class="headerlink" title="2.4 Poller"></a>2.4 Poller</h2><p>本质是一个Selector，内部维护一个Queue </p><pre><code>private final SynchronizedQueue&lt;PollerEvent&gt; events = new SynchronizedQueue&lt;&gt;();</code></pre><p>使用synchronized关键字来保证在同一时刻只有一个Acceptor线程对Queue进行读写。</p><p>Poller不断通过内部的selector对象向内核查询Channel的状态，一旦可读就生成任务类SocketProcessor交给Executor去处理。Poller的另一个重要任务是循环遍历检查自己所管理的SocketChannel是否已经超时，若超时就关闭这个Channel。</p><h2 id="2-5-SocketProcessor"><a href="#2-5-SocketProcessor" class="headerlink" title="2.5 SocketProcessor"></a>2.5 SocketProcessor</h2><p>SocketProcessor任务类会被交给线程池去处理，processor内主要是调用Http11Processor组件来处理请求，http11Processor读取Channel的数据来生成ServletRequest对象</p><h2 id="2-6-NioEndpoint的高并发思路"><a href="#2-6-NioEndpoint的高并发思路" class="headerlink" title="2.6 NioEndpoint的高并发思路"></a>2.6 NioEndpoint的高并发思路</h2><p>对于三大方面的事情各自有一个线程组，可以配置线程数量。</p><ul><li>接受连接      Acceptor </li><li>检测I/O事件   Poller</li><li>处理请求      Executor </li></ul>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat - Servlet规范和Servlet容器</title>
      <link href="/Tomcat-Servlet%E8%A7%84%E8%8C%83%E5%92%8CServlet%E5%AE%B9%E5%99%A8/"/>
      <url>/Tomcat-Servlet%E8%A7%84%E8%8C%83%E5%92%8CServlet%E5%AE%B9%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Servlet规范"><a href="#1-Servlet规范" class="headerlink" title="1. Servlet规范"></a>1. Servlet规范</h1><p>浏览器给服务端一个HTTP格式的请求，HTTP服务器收到这个请求之后，需要调用服务端程序来做处理。</p><p>为了解决耦合问题 -&gt; 采用面向接口编程，就定义了一个接口，各种业务类都必须实现这个接口，这个接口就叫Servlet接口。</p><p>为了实例化Servlet，出现了Servlet容器，Servlet容器用来加载和管理业务类。</p><p>HTTP服务器并不直接跟业务类打交道，而是将请求交给Servlet容器去处理，Servlet容器会将请求转发到具体的Servlet，如果这个Servlet还没有创建，就去加载并且实例化这个Servlet，然后调用这个Servlet的接口方法。</p><p>Servlet接口其实是Servlet容器跟具体业务类之间的接口。</p><p><img src="https://i.loli.net/2020/02/02/Gfnmrp9AFldWq1s.jpg" alt="fig1.jpg"></p><p>Servlet接口和Servlet容器这一整套规范就叫做Servlet规范。 Tomcat和Jetty都按照Servlet规范的要求实现了Servlet容器，同时它们也具有HTTP服务器的功能。</p><p>作为开发者，我们只需要实现一个Servlet，并将其注册到容器当中，剩下的事情就交由Tomcat来帮助我们解决了。</p><h1 id="2-Servlet接口"><a href="#2-Servlet接口" class="headerlink" title="2. Servlet接口"></a>2. Servlet接口</h1><p>Servlet接口定义了以下的方法：</p><pre><code>public interface Servlet {    void init(ServletConfig config) throws ServletException;    ServletConfig getServletConfig();    void service(ServletRequest req, ServletResponse res）throws ServletException, IOException;    String getServletInfo();    void destroy();}</code></pre><p>最重要的是Service方法，具体业务类在这个方法里实现处理逻辑。</p><ul><li>参数 - 本质上这两个参数是对通信协议的封装<ul><li>ServletRequest <ul><li>封装请求信息 </li><li>其中包含所有请求的相关信息<ul><li>请求路径</li><li>Cookie</li><li>HTTP头</li><li>请求参数</li><li>Session</li></ul></li></ul></li><li>ServletResponse<ul><li>封装响应信息 </li></ul></li></ul></li><li>Servlet容器在加载Servlet类的时候会调用init方法，卸载的时候会调用destroy方法。</li><li>ServletConfig的作用是封装Servlet的初始化参数，可以在web.xml中给Servlet配置参数，并在程序里通过getServletConfig方法拿到这些参数</li></ul><h1 id="3-Servlet容器"><a href="#3-Servlet容器" class="headerlink" title="3. Servlet容器"></a>3. Servlet容器</h1><h2 id="3-1-Servlet容器工作流程"><a href="#3-1-Servlet容器工作流程" class="headerlink" title="3.1 Servlet容器工作流程"></a>3.1 Servlet容器工作流程</h2><ul><li>客户请求某个资源的时候，</li><li>HTTP服务器会用一个ServletRequest对象将客户的请求信息封装起来</li><li>调用Servlet容器的Service方法</li><li>Servlet容器接到请求</li><li>根据请求的URL和Servlet的映射关系，找到响应的Servlet</li><li>如果Servlet还没有被加载，就用反射机制创建这个Servlet，并调用Servlet的init方法来完成初始化，接着调用Servlet的service方法处理请求</li><li>将ServletResponse对象返回给HTTP服务器</li><li>HTTP服务器将响应发送给客户端</li></ul><p><img src="https://i.loli.net/2020/02/02/jvc2pThotnA8J59.jpg" alt="fig2.jpg"></p><h2 id="3-2-Web应用的目录格式"><a href="#3-2-Web应用的目录格式" class="headerlink" title="3.2 Web应用的目录格式"></a>3.2 Web应用的目录格式</h2><p>Servlet是以Web应用程式的方式来进行部署的，而根据Servlet规范，WEB应用程序需要有一定的目录结构，在这个目录下放置了：</p><ul><li><p>Servlet的类文件</p></li><li><p>配置文件</p></li><li><p>静态资源</p><p>  | -  MyWebApp</p><pre><code>    | -  WEB-INF/web.xml        -- 配置文件，用来配置 Servlet 等    | -  WEB-INF/lib/           -- 存放 Web 应用所需各种 JAR 包    | -  WEB-INF/classes/       -- 存放你的应用类，比如 Servlet 类    | -  META-INF/              -- 目录存放工程的一些信息</code></pre></li></ul><p>Servlet容器通过读取配置文件，就能找到并加载Servlet。</p><p>ServletContext这个接口用来对应一个Web应用，web应用部署好之后，Servlet容器在启动时会加载web应用，并为每个Web应用创建唯一的ServletContext对象。</p><p>ServletContext是个全局对象，一个Web应用可能有多个Servlet，这些Servlet可以通过全局的ServletContext来共享数据，包括Web应用的初始化参数，应用目录下的文件资源等</p><h2 id="3-3-如何扩展和定制化Servlet容器的功能"><a href="#3-3-如何扩展和定制化Servlet容器的功能" class="headerlink" title="3.3 如何扩展和定制化Servlet容器的功能"></a>3.3 如何扩展和定制化Servlet容器的功能</h2><p>Servlet规范提供了两中扩展机制，Filter and Listener</p><h3 id="3-3-1-Filter"><a href="#3-3-1-Filter" class="headerlink" title="3.3.1 Filter"></a>3.3.1 Filter</h3><p>Filter干预过程，是过程的一部分，是基于过程来被触发的</p><p>过滤器。允许你对请求和响应做一些统一的定制化处理，比如你可以根据请求的频率限制访问，或者根据不同国家修改响应内容。</p><ul><li>WEB应用完成部署</li><li>Servlet容器实例化Filter</li><li>Filter会被链接成一个FilterChain</li><li>当请求进来，获取第一个Filter并调用doFilter方法</li><li>doFilter方法负责调用这个FilterChain中的下一个Filter</li></ul><h3 id="3-3-2-Listener"><a href="#3-3-2-Listener" class="headerlink" title="3.3.2 Listener"></a>3.3.2 Listener</h3><p>Listener是基于状态的，任何行为改变同一个状态，触发的事件是一致的。</p><ul><li>Servlet容器提供一些默认的监听器来监听事件<ul><li>web应用的启动停止</li><li>用户请求到达等</li></ul></li><li>事件发生，Servlet调动监听器的方法</li><li>可以定义自己的监听器去监听你感兴趣的事件</li><li>将监听器配置在web.xml中</li></ul>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat - 什么是Web容器, cookie &amp; session</title>
      <link href="/Tomcat-%E4%BB%80%E4%B9%88%E6%98%AFWeb%E5%AE%B9%E5%99%A8-cookie-session/"/>
      <url>/Tomcat-%E4%BB%80%E4%B9%88%E6%98%AFWeb%E5%AE%B9%E5%99%A8-cookie-session/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是Web容器"><a href="#1-什么是Web容器" class="headerlink" title="1. 什么是Web容器"></a>1. 什么是Web容器</h1><p>早期的Web应用主要用于浏览新闻等静态页面，HTTP服务器(比如Apache、Nginx)向浏览器返回静态HTML，浏览器负责解析HTML，将结果呈现给用户。 </p><p>而后我们希望能够在页面上有一些交互操作，获取动态的结果，因此就需要一些扩展机制来使得HTTP服务器能够调用服务端的程序。于是Sun公司推出了Servlet技术，其没有main方法，需要被部署到Servlet容器当中，由容器来实例化并调用Servlet。</p><p>Tomcat和Jetty就是HTTP服务器 + Servlet容器，又称为Web容器。</p><h1 id="2-Cookie-amp-Session"><a href="#2-Cookie-amp-Session" class="headerlink" title="2. Cookie &amp; Session"></a>2. Cookie &amp; Session</h1><p>浏览器将请求打包成HTTP协议格式，当这个请求到达服务端的时候，会被Tomcat将HTTP请求数据字节流解析成一个Request对象，这个Request对象封装了HTTP所有的请求信息，接着Tomcat将这个请求交给Web应用去处理，处理完以后得到一个Response对象，Tomcat就会把这个Response对象转成HTTP格式的相应数据并发送给浏览器。</p><p>HTTP协议是无状态的，请求之间没有关系，为了让请求之间建立联系，设计出了Cookie还有Session技术。</p><h2 id="2-1-Cookie技术"><a href="#2-1-Cookie技术" class="headerlink" title="2.1 Cookie技术"></a>2.1 Cookie技术</h2><p>Cookie是HTTP报文的请求头，Web应用可以将用户的标识信息或者其他一些信息存储在Cookie中。用户通过验证之后，每次HTTP请求报文中都包含Cookie，这个服务器读取这个Cookie请求头就知道用户是谁了。</p><p>其本质上就是一份存储在用户本地的文件，里面包含了每次请求中都需要传递的信息。</p><h2 id="2-2-Session技术"><a href="#2-2-Session技术" class="headerlink" title="2.2 Session技术"></a>2.2 Session技术</h2><p>Cookie以明文的方式存储在本地，而Cookie中往往带有用户信息，Session就用来解决这个问题。是在服务端开辟的存储空间，里面保存了用户的状态。</p><p>用户信息以Session的形式存储在服务端，当用户请求到来时，服务端可以把用户的请求和用户的Session对应起来。</p><ul><li>服务器创建Session的时候，生成Session ID</li><li>当浏览器再次发送请求时，在Cookie里会带上Session ID</li><li>服务器根据SessionID找到对应的Session，并在Session当中获取或者添加内容</li></ul>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat - 优化Tomcat启动速度</title>
      <link href="/Tomcat-%E4%BC%98%E5%8C%96Tomcat%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6/"/>
      <url>/Tomcat-%E4%BC%98%E5%8C%96Tomcat%E5%90%AF%E5%8A%A8%E9%80%9F%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<p>优化tomcat的启动速度，可以使得当你的service down掉，你做出修改的时候，能够更快的上线，这是个很可取，也很需要优化的方面了。</p><h1 id="1-清理Tomcat"><a href="#1-清理Tomcat" class="headerlink" title="1. 清理Tomcat"></a>1. 清理Tomcat</h1><h2 id="1-1-清理不必要的web应用"><a href="#1-1-清理不必要的web应用" class="headerlink" title="1.1 清理不必要的web应用"></a>1.1 清理不必要的web应用</h2><p>删除掉webapps文件夹下不需要的工程：</p><ul><li>host-manager </li><li>example</li><li>doc</li></ul><h2 id="1-2-清理XML配置文件"><a href="#1-2-清理XML配置文件" class="headerlink" title="1.2 清理XML配置文件"></a>1.2 清理XML配置文件</h2><p>Tomcat在启动的时候会解析所有的XML配置文件，但XML的解析的代价并不小，尽量保持XML配置文件的简洁。</p><h2 id="1-3-清理JAR文件"><a href="#1-3-清理JAR文件" class="headerlink" title="1.3 清理JAR文件"></a>1.3 清理JAR文件</h2><p>可以删除所有不需要的JAR文件。JVM的类加载器在加载类时，需要查找每一个JAR文件来找到所需要的类，删除不需要的JAR文件，就可以使得查找的速度变快一些。</p><p>Web应用当中的lib目录下不应该出现Servlet API或者Tomcat自身的JAR，这些是由Tomcat负责提供的。</p><h2 id="1-4-清理其他文件"><a href="#1-4-清理其他文件" class="headerlink" title="1.4 清理其他文件"></a>1.4 清理其他文件</h2><p>及时清理日志，删除掉logs文件夹下不需要的日志文件。Catalina文件夹是Tomcat将JSP转换成Class文件的工作目录。每次启动会重新生成的。</p><h1 id="2-禁止Tomcat-TLD扫描"><a href="#2-禁止Tomcat-TLD扫描" class="headerlink" title="2. 禁止Tomcat TLD扫描"></a>2. 禁止Tomcat TLD扫描</h1><p>TLD是对于标签库的定义，用来支持JSP的，如果你没有定义的话，那么就可以设置不去扫描这个JAR包 </p><ul><li>如果完全没有使用JSP作为页面模板，可以将TLD扫描禁掉</li></ul><pre><code>&lt;Context&gt;    &lt;JarScanner&gt;        &lt;JarScanFilter defaultTldScan = &quot;false&quot;/&gt;    &lt;/JarScanner&gt;&lt;/Context&gt;</code></pre><ul><li>如果使用JSP作为模板，那么我们可以通过配置告诉Tomcat只扫描那些包括TLD文件的JAR包。找到<code>conf/</code>下的   <code>catalina.properties</code>文件，在这个文件里的jarsToSkip配置项当中，加入JAR包</li></ul><pre><code>tomcat.util.scan.StandardJarScanFilter.jarsToSkip=xxx.jar</code></pre><h1 id="3-关闭WebSocket的支持"><a href="#3-关闭WebSocket的支持" class="headerlink" title="3. 关闭WebSocket的支持"></a>3. 关闭WebSocket的支持</h1><p>Tomcat 会扫描 WebSocket 注解的 API 实现，比如@ServerEndpoint注解的类。我们知道，注解扫描一般是比较慢的，如果不需要使用 WebSockets 就可以关闭它。具体方法是，找到 Tomcat 的conf/目录下的context.xml文件，给 Context 标签加一个containerSciFilter的属性。</p><pre><code>&lt;Context containerSciFilter=&quot;org.apache.jasper.servlet.JasperInitializer&quot;&gt;&lt;/Context&gt; </code></pre><h1 id="4-禁止Servlet注解的扫描"><a href="#4-禁止Servlet注解的扫描" class="headerlink" title="4. 禁止Servlet注解的扫描"></a>4. 禁止Servlet注解的扫描</h1><p>Tomcat会在web应用启动时扫描你的类文件，如果你没有使用servlet 注解，可以告诉Tomcat不要去扫描。具体配置方法：在你的 Web 应用的<code>web.xml</code>文件中，设置元素的属性<code>metadata-complete=&quot;true&quot;</code></p><h1 id="5-随机数熵源优化"><a href="#5-随机数熵源优化" class="headerlink" title="5. 随机数熵源优化"></a>5. 随机数熵源优化</h1><p>Tomcat7以上版本依赖Java的SecureRandom类来生成随机数，比如SessionID, JVM默认使用阻塞式熵源(<code>/dev/random</code>), 某些情况下会导致tomcat启动变慢。</p><p>可以通过设置，让JVM使用非阻塞式的熵源。</p><pre><code> -Djava.security.egd=file:/dev/./urandom</code></pre><h1 id="6-并行启动多个Web应用"><a href="#6-并行启动多个Web应用" class="headerlink" title="6. 并行启动多个Web应用"></a>6. 并行启动多个Web应用</h1><p>Tomcat启动的时候，默认情况下Web应用时一个一个启动的，等所有Web 应用启动完成Tomcat才算启动完成。如果在一个Tomcat下我们有多个web应用，可以配置多个应用并行启动，通过修改server.xml文件当中的host元素的startStopThreads属性来完成。startStopThreads 的值表示你想用多少个线程来启动你的 Web 应用，如果设成 0 表示你要并行启动 Web 应用。</p><pre><code>&lt;Engine startStopThreads=&quot;0&quot;&gt;    &lt;Host startStopThreads=&quot;0&quot;&gt;    ...    &lt;/Host&gt;&lt;/Engine&gt;</code></pre>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat - 运行第一个 Servlet</title>
      <link href="/Tomcat-%E8%BF%90%E8%A1%8C%E7%AC%AC%E4%B8%80%E4%B8%AA-Servlet/"/>
      <url>/Tomcat-%E8%BF%90%E8%A1%8C%E7%AC%AC%E4%B8%80%E4%B8%AA-Servlet/</url>
      
        <content type="html"><![CDATA[<p>这篇文章会带着大家从下载安装Tomcat开始，编写自己的servlet，并且将其在Tomcat （Servlet 容器）当中进行运行，展现这整个过程。</p><h1 id="1-安装Tomcat"><a href="#1-安装Tomcat" class="headerlink" title="1. 安装Tomcat"></a>1. 安装Tomcat</h1><p> <a href="https://tomcat.apache.org/download-90.cgi" target="_blank" rel="noopener">官网链接</a></p><p> 解压以后的目录结构如下：</p><ul><li>bin<ul><li>存放在各个平台上启动和关闭Tomcat的脚本文件 </li></ul></li><li>conf<ul><li>存放Tomcat的全局配置文件，其中最重要的是server.xml  </li></ul></li><li>lib<ul><li>存放Tomcat以及所有Web应用都可以访问的JAR文件 </li></ul></li><li>logs<ul><li>存放Tomcat执行时产生的日志文件 </li></ul></li><li>work<ul><li>存放JSP编译后产生的Class文件 </li></ul></li><li>webapps<ul><li>Tomcat的web应用目录，默认情况下把Web应用放在这个目录下 </li></ul></li></ul><h1 id="2-Servlet类编写"><a href="#2-Servlet类编写" class="headerlink" title="2. Servlet类编写"></a>2. Servlet类编写</h1><pre><code>import java.io.IOException;import java.io.PrintWriter;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class MyServlet extends HttpServlet {    @Override    protected void doGet(HttpServletRequest request, HttpServletResponse response)            throws ServletException, IOException {        System.out.println(&quot;MyServlet 在处理 get（）请求...&quot;);        PrintWriter out = response.getWriter();        response.setContentType(&quot;text/html;charset=utf-8&quot;);        out.println(&quot;&lt;strong&gt;My Servlet!&lt;/strong&gt;&lt;br&gt;&quot;);    }    @Override    protected void doPost(HttpServletRequest request, HttpServletResponse response)            throws ServletException, IOException {        System.out.println(&quot;MyServlet 在处理 post（）请求...&quot;);        PrintWriter out = response.getWriter();        response.setContentType(&quot;text/html;charset=utf-8&quot;);        out.println(&quot;&lt;strong&gt;My Servlet!&lt;/strong&gt;&lt;br&gt;&quot;);    }}</code></pre><p>将编写好的类编译成.class文件</p><pre><code>javac -cp ./servlet-api.jar MyServlet.java</code></pre><h1 id="3-建立Web应用目录结构"><a href="#3-建立Web应用目录结构" class="headerlink" title="3. 建立Web应用目录结构"></a>3. 建立Web应用目录结构</h1><pre><code>WebApp/WEB-INF/web.xmlWebApp/WEB-INF/classes/MyServlet.class</code></pre><p>然后在web.xml里面配置Servlet</p><pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;  xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;  xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee  http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot;  version=&quot;4.0&quot;  metadata-complete=&quot;true&quot;&gt;    &lt;description&gt; Servlet Example. &lt;/description&gt;    &lt;display-name&gt; MyServlet Example &lt;/display-name&gt;    &lt;request-character-encoding&gt;UTF-8&lt;/request-character-encoding&gt;    &lt;servlet&gt;      &lt;servlet-name&gt;myServlet&lt;/servlet-name&gt;      &lt;servlet-class&gt;MyServlet&lt;/servlet-class&gt;    &lt;/servlet&gt;    &lt;servlet-mapping&gt;      &lt;servlet-name&gt;myServlet&lt;/servlet-name&gt;      &lt;url-pattern&gt;/myservlet&lt;/url-pattern&gt;    &lt;/servlet-mapping&gt;&lt;/web-app&gt;</code></pre><h1 id="4-运行"><a href="#4-运行" class="headerlink" title="4. 运行"></a>4. 运行</h1><p>将WebApp放到Tomcat的安装目录下的webapps目录里</p><p>在bin目录下，启动脚本 </p><ul><li>mac/ linux<ul><li>startup.sh</li></ul></li><li>windows<ul><li>startup.bat</li></ul></li></ul><p>而后我们可以在浏览器看到结果</p><pre><code>http://localhost:8080/WebApp/myServlet</code></pre><h1 id="5-查看日志"><a href="#5-查看日志" class="headerlink" title="5. 查看日志"></a>5. 查看日志</h1><ul><li>catalina.***.log<ul><li>主要记录Tomcat的启动过程</li><li>可以看到启动的JVM参数以及操作系统等日志信息</li></ul></li><li>catalina.out<ul><li>是Tomcat的标准输出和标准错误</li></ul></li><li>localhost.***.log<ul><li>主要记录Web应用在初始化过程中遇到的未处理的异常，会被Tomcat捕获而输出到这个日志文件当中</li></ul></li><li>localhost_access_log.***.txt<ul><li>存放访问Tomcat 请求的日志</li><li>包括<ul><li>IP地址</li><li>请求路径</li><li>请求时间</li><li>请求协议</li><li>状态码</li></ul></li></ul></li><li>manager.<strong><em>.log/host-manager.</em></strong>.log<ul><li>存放Tomcat自带的Manager项目的日志信息 </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tomcat - 整体架构</title>
      <link href="/Tomcat-%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/"/>
      <url>/Tomcat-%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="1-整体架构"><a href="#1-整体架构" class="headerlink" title="1. 整体架构"></a>1. 整体架构</h1><ul><li>Tomcat的核心功能<ul><li>处理Socket连接，负责网络字节流与Request，Response对象的转化</li><li>加载和管理Servlet，以及具体的处理Request请求</li></ul></li><li>socket <ul><li>连接器 Connector </li><li>支持大量不同的I/O模型<ul><li>NIO<ul><li>非阻塞I/O</li></ul></li><li>NIO.2<ul><li>异步I/O </li></ul></li><li>APR<ul><li>采用Apache可移植运行库数显 </li></ul></li></ul></li><li>支持不同的应用层协议<ul><li>HTTP/1.1</li><li>AJP<ul><li>用于和Web服务器集成 </li></ul></li><li>HTTP/2</li></ul></li></ul></li><li>servlet管理<ul><li>容器 Container  <ul><li>一个容器可能对接多个连接器  – 为了实现对于多种I/O和应用层协议的支持</li><li>连接器和容器的组合叫做Service组件</li><li>Tomcat内可能有多个Service，通过这种配置，可以实现通过不同的端口号来访问同一个机器上部署的不同应用。</li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2020/02/02/DQSx67LbjXzVANW.jpg" alt="fig1.jpg"></p><h1 id="2-连接器"><a href="#2-连接器" class="headerlink" title="2. 连接器"></a>2. 连接器</h1><p>连接器对Servlet容器屏蔽了协议以及I/O模型，无论是何种协议，在容器中获取的都是一个标准的ServletRequest对象。</p><p>细化连接器的功能：</p><ul><li>监听网络端口</li><li>接收网络连接请求</li><li>读取网络请求字节流</li><li>根据应用层协议，解析字节流，生成统一的Tomcat Request对象</li><li>将Tomcat Request对象转成标准的ServletRequest</li><li>调用Servlet容器，得到ServletResponse</li><li>将ServletResponse转成Tomcat Response对象</li><li>将Tomcat Response转成网络字节流</li><li>将相应字节流写回浏览器</li></ul><p>为了实现一个高内聚低耦合的系统，连接器需要在几个方面做针对性的设置</p><ul><li>网络通信</li><li>应用层协议解析</li><li>Tomcat Request/ Response 与 ServletRequest/ Response的转化</li></ul><p><img src="https://i.loli.net/2020/02/02/9aqpn2lF5UZs184.jpg" alt="fig2.jpg"></p><h2 id="2-1-Endpoint-part-of-protocal-handler"><a href="#2-1-Endpoint-part-of-protocal-handler" class="headerlink" title="2.1 Endpoint (part of protocal handler)"></a>2.1 Endpoint (part of protocal handler)</h2><p>ProtocalHandler是用来处理网络连接和应用层协议的</p><p>提供字节流给Processor</p><p>Endpoint是通信端点，即通信监听的接口，是具体的Socket接收和发送的处理器，是对传输层的抽象，因此Endpoint是用来实现TCP/IP协议的。</p><p>Endpoint是一个接口，对应的抽象实现类是AbstractEndpoint</p><ul><li>AbstractEndpoint <ul><li>Acceptor <ul><li>用于监听Socket连接请求 </li></ul></li><li>SocketProcessor<ul><li>用于处理接收到的Socket请求，实现Runnable接口，在run方法里调用协议处理组件Processor进行处理 </li></ul></li></ul></li></ul><h2 id="2-2-Processor-part-of-protocal-handler"><a href="#2-2-Processor-part-of-protocal-handler" class="headerlink" title="2.2 Processor (part of protocal handler)"></a>2.2 Processor (part of protocal handler)</h2><p>提供Tomcat Request对象给Adapter，在这里Processor接收来自Endpoint的Socket，读取字节流解析成Tomcat Request和Response对象，并通过Adapter将其提交到容器处理，Processor是对应用层协议的抽象。</p><p>一个定义了请求的处理方法的接口，其抽象实现类AbstractProcessor对协议共有的属性进行封装，没有对方法进行实现。这些具体的实现有AjpProcessor  Http11Processor等，具体的实现类实现了特定协议的解析方法和请求处理方式。</p><p><img src="https://i.loli.net/2020/02/02/QuqNCEvhrJInGSL.jpg" alt="fig3.jpg"></p><p>Endpoint接收Socket连接，生成一个SocketProcessor任务，提交到线程池去处理，SocketProcessor的run方法会调用Processor组件去解析应用层协议，Processor通过解析生成request对象之后，会调用Adapter的Service方法。</p><h2 id="2-3-Adapter"><a href="#2-3-Adapter" class="headerlink" title="2.3 Adapter"></a>2.3 Adapter</h2><p>由于协议不同，客户端发过来的请求信息也不尽相同，Tomcat定义了自己的Request类来存放这些请求信息。ProtocolHandler接口负责解析请求并生成TomcatRequest类。将传入的Tomcat Request对象转成ServletRequest，再调用容器的service方法。</p><p>Adapter负责提供ServletRequest对象给容器</p><h1 id="3-容器"><a href="#3-容器" class="headerlink" title="3. 容器"></a>3. 容器</h1><p>Tomcat当中，容器是用来装载Servlet的。</p><h2 id="3-1-容器的层次结构"><a href="#3-1-容器的层次结构" class="headerlink" title="3.1 容器的层次结构"></a>3.1 容器的层次结构</h2><p>Tomcat设计了4种容器，分别是Engine, Host, Context, Wrapper。通过这种分层的架构来增加Servlet容器的灵活性。</p><p><img src="https://i.loli.net/2020/02/02/nopbJmwXEx2KM5a.jpg" alt="fig4.jpg"></p><ul><li>Engine<ul><li>表示引擎</li><li>用来管理多个虚拟站点</li><li>一个Service最多只能有一个Engine</li></ul></li><li>Host<ul><li>虚拟主机 - 站点</li><li>给Tomcat配置多个虚拟主机地址</li><li>一个虚拟主机啊下又可以部署多个Web应用程序</li></ul></li><li>Context <ul><li>表示一个Web应用程序 </li><li>一个Context(Web应用程序)里可以有多个Servlet</li></ul></li><li>Wrapper <ul><li>表示一个Servlet </li></ul></li></ul><p>Tomcat的server.xml配置文件<br><img src="https://i.loli.net/2020/02/02/ED2SiGWfKzevJ7c.jpg" alt="fig5.jpg"></p><p>Tomcat通过组合模式来管理这些容器，所有容器组件都会实现Container接口，因此组合模式可以使得用户对但容器对象和组合容器对象的使用具有高度一致性。</p><pre><code>public interface Container extends Lifecycle {    public void setName(String name);    public Container getParent();    public void setParent(Container container);    public void addChild(Container child);    public void removeChild(Container child);    public Container findChild(String name);}</code></pre><h2 id="3-2-请求是如何定位Servlet的-Mapper"><a href="#3-2-请求是如何定位Servlet的-Mapper" class="headerlink" title="3.2 请求是如何定位Servlet的 - Mapper"></a>3.2 请求是如何定位Servlet的 - Mapper</h2><p>Tomcat使用Mapper组件来完成这个任务。</p><ul><li>Mapper功能<ul><li>将用户请求的URL定位到一个Servlet</li></ul></li><li>Mapper工作原理<ul><li>Mapper组件保存web应用的配置信息 - 容器组件与访问路径的映射关系<ul><li>host容器里配置的域名</li><li>Context容器里的Web应用路径</li><li>Wrapper容器里Servlet映射的路径</li></ul></li></ul></li><li>Mapper工作过程<ul><li>请求到来</li><li>Mapper组件解析请求URL里的域名和路径</li><li>到自己保存的Map里面去查找</li><li>定位到一个Servlet</li><li>一个URL最终只会定位到一个Wrapper容器，即一个Servlet</li></ul></li></ul><ul><li>E.g<ul><li>背景<ul><li>网购系统<ul><li>后台管理系统</li><li>在线购物系统</li></ul></li><li>两个系统在同一个Tomcat上，为了隔离其访问域名，配置虚拟域名</li></ul></li><li>Tomcat的功能<ul><li>创建一个Service组件和一个Engine容器组件</li><li>在Engine容器下创建两个Host子容器</li><li>每个Host下创建多个Context子容器</li></ul></li></ul></li></ul><p><img src="https://i.loli.net/2020/02/02/yo2IVCkzvsY5gjw.jpg" alt="fig6.jpg"></p><p>接着上面的例子，当用户访问一个URL，比如 <code>user.shopping.com:8080/order/buy</code>，Tomcat将这个URL定位到一个Servlet的过程如下：</p><ul><li>根据协议和端口号选定Service和Engine<ul><li>HTTP或者AJP连接器都是由自己的默认端口号的</li></ul></li><li>根据域名选定Host<ul><li>Mapper组件通过URL中的域名去查找响应的Host容器</li></ul></li><li>根据URL路径找到Context组件<ul><li>根据URL的路径来匹配相应的Web应用的路径</li></ul></li><li>根据URL路径找到Wrapper - Servlet<ul><li>Context确定后，Mapper再根据web.xml中配置的Servlet映射路径来找到具体的Wrapper和Servlet</li></ul></li></ul><h2 id="3-3-Pipeline-valve"><a href="#3-3-Pipeline-valve" class="headerlink" title="3.3 Pipeline - valve"></a>3.3 Pipeline - valve</h2><p>这整个层层递进的调用过程使用的是Pipeline-Value管道。</p><ul><li>Pipeline-valve<ul><li>责任链模式</li><li>在请求处理过程中有很多处理者依次对请求进行处理，每个处理着负责做自己的相应的处理，然后一个个传递给下一个处理者</li></ul></li></ul><p><img src="https://i.loli.net/2020/02/02/IMyaJTVZlbgmWEc.jpg" alt="fig7.jpg"></p><pre><code>public interface Valve {  public Valve getNext();  public void setNext(Valve valve);  public void invoke(Request request, Response response)}public interface Pipeline extends Container {  public void addValve(Valve valve);  public Valve getBasic();  public void setBasic(Valve valve);  public Valve getFirst();}</code></pre><p>Pipelin中维护了Valve的链表，整个调用链的执行是被valve来完成的，valve完成自己的处理以后，就会调用getNext.invoke来触发下一个Valve调用</p><p>不同的容器的pipeline之间的触发，上一层的最后一个valve负责调用下一层的第一个valve，整个流程如下：</p><p>Wrapper容器的最后一个Valve会创建一个Filter链，并调用doFilter方法，最终会调用Servlet的service方法。</p><ul><li>Valve和Filter<ul><li>valve是tomcat的私有机制</li><li>Filter是在servlet级别的，是公有标准</li><li>valve工作在web容器级别，拦截所有应用的请求</li><li>Servlet Filter工作在应用级别，只能拦截某个Web应用的所有请求。</li></ul></li></ul><h1 id="4-Tomcat一键启停"><a href="#4-Tomcat一键启停" class="headerlink" title="4. Tomcat一键启停"></a>4. Tomcat一键启停</h1><p>首先复习下Tomcat各个组件之间的关系。</p><p><img src="https://i.loli.net/2020/02/02/qaU4DIjHgezVodv.png" alt="fig8.png"></p><ul><li>为了使得一个系统能够对外提供服务，我们需要创建、组装并启动这些组件</li><li>在服务停止的时候，还需要释放资源，销毁这些组件</li><li>Tomcat需要动态地管理这些组件的生命周期</li></ul><ul><li>大组件管理小组件<ul><li>需要先启动子组件，再启动父组件，子组件需要被注入到父组件当中去</li></ul></li><li>请求的处理过程是由外层组件来驱动的<ul><li>先创建内层组件，再创建外层组件，内层组件需要被注入到外层组件当中</li></ul></li></ul><h2 id="4-1-LifeCycle接口"><a href="#4-1-LifeCycle接口" class="headerlink" title="4.1 LifeCycle接口"></a>4.1 LifeCycle接口</h2><ul><li>不变的点<ul><li>每个组件都要经历创建、初始化、启动这几个过程</li><li>创建Lifecycle接口<ul><li>init</li><li>start </li><li>stop</li><li>destroy</li></ul></li></ul></li><li>变化的点<ul><li>每个具体组件的初始化方法 </li><li>addLifecycleListener</li><li>removeLifecycleListner</li></ul></li></ul><p><img src="https://i.loli.net/2020/02/02/hBfJx9GELY1NWgq.png" alt="fig9.png"></p><ul><li>将公有逻辑抽象出来，放到抽象类当中，所以UML图就变成了图10的样子</li></ul><p><img src="https://i.loli.net/2020/02/02/vMpFBLw6mrQASa5.png" alt="fig10.png"></p><p>基类的具体实现如下: </p><pre><code>@Overridepublic final synchronized void init() throws LifecycleException {    //1. 状态检查    if (!state.equals(LifecycleState.NEW)) {        invalidTransition(Lifecycle.BEFORE_INIT_EVENT);    }    try {        //2. 触发 INITIALIZING 事件的监听器        setStateInternal(LifecycleState.INITIALIZING, null, false);        //3. 调用具体子类的初始化方法        initInternal();        //4. 触发 INITIALIZED 事件的监听器        setStateInternal(LifecycleState.INITIALIZED, null, false);    } catch (Throwable t) {      ...    }}</code></pre><h2 id="4-2-生命周期管理总体类图"><a href="#4-2-生命周期管理总体类图" class="headerlink" title="4.2 生命周期管理总体类图"></a>4.2 生命周期管理总体类图</h2><p><img src="https://i.loli.net/2020/02/02/4r7yVeiPqAzhYFI.png" alt="fig11.png"></p><h1 id="5-Tomcat运行过程"><a href="#5-Tomcat运行过程" class="headerlink" title="5. Tomcat运行过程"></a>5. Tomcat运行过程</h1><p>我们可以通过Tomcat的/bin目录下的脚本startup.sh来启动Tomcat，整个流程如下: </p><p><img src="https://i.loli.net/2020/02/02/Par89z2MyQj7KYH.png" alt="fig12.png"></p><ul><li>启动JVM，运行Tomcat启动类Bootstrap</li><li>Bootstrap类会初始化Tomcat的类加载器，并且创建Catalina</li><li>Catalina是一个启动类，通过解析server.xml，会创建相应的组件，并调用Server的start方法</li><li>server组件被用来管理Service组件，会负责调用Service的start方法</li><li>Service组件被用来管理连接器和顶层容器Engine，因此其会调用连接器和Engine的start方法</li></ul><h2 id="5-1-Catalina"><a href="#5-1-Catalina" class="headerlink" title="5.1 Catalina"></a>5.1 Catalina</h2><p>主要任务是创建Server，通过解析server.xml文件，将server.xml里配置的各种组件一一创建出来，接着调用Server组件的init方法和start方法，以此启动整个Tomcat。</p><p>Tomcat还需要处理各种异常情况，比如强制关闭的处理，Catalina在JVM当中注册了一个关闭钩子。</p><pre><code>public void start() {    //1. 如果持有的 Server 实例为空，就解析 server.xml 创建出来    if (getServer() == null) {        load();    }    //2. 如果创建失败，报错退出    if (getServer() == null) {        log.fatal(sm.getString(&quot;catalina.noServer&quot;));        return;    }    //3. 启动 Server    try {        getServer().start();    } catch (LifecycleException e) {        return;    }    // 创建并注册关闭钩子    if (useShutdownHook) {        if (shutdownHook == null) {            shutdownHook = new CatalinaShutdownHook();        }        Runtime.getRuntime().addShutdownHook(shutdownHook);    }    // 用 await 方法监听停止请求    if (await) {        await();        stop();    }}// catalina的关闭钩子执行了Server的stop方法，会释放和清理所有的资源。protected class CatalinaShutdownHook extends Thread {    @Override    public void run() {        try {            if (getServer() != null) {                Catalina.this.stop();            }        } catch (Throwable ex) {           ...        }    }}</code></pre><h2 id="5-2-Server组件"><a href="#5-2-Server组件" class="headerlink" title="5.2 Server组件"></a>5.2 Server组件</h2><p>其具体实现类是StandardServer，继承了LifecycleBase，生命周期被统一管理，子组件是Service，因此还需要管理Service的生命周期，在启动时调用Service组件的启动方法，在停止时调用其停止方法</p><p>Server维护多个Service组件，以数组来保存</p><pre><code>@Overridepublic void addService(Service service) {    service.setServer(this);    synchronized (servicesLock) {        // 创建一个长度 +1 的新数组        Service results[] = new Service[services.length + 1];        // 将老的数据复制过去        System.arraycopy(services, 0, results, 0, services.length);        results[services.length] = service;        services = results;        // 启动 Service 组件        if (getState().isAvailable()) {            try {                service.start();            } catch (LifecycleException e) {                // Ignore            }        }        // 触发监听事件        support.firePropertyChange(&quot;service&quot;, null, service);    }}</code></pre><p>节省内存空间的一种方式</p><p>Server组件会启动一个Socket来监听停止端口，在Catalina启动的时候，会调用Server的await方法，这个地方实际上是创建了一个Socket来监听一个端口，并在这个死循环里接收Socket的连接请求，如果有新的连接到来就建立连接，然后从Socket中读取数据；如果读到的数据是停止命令SHUTDOWN，就退出循环，进入stop流程</p><h2 id="5-3-Service组件"><a href="#5-3-Service组件" class="headerlink" title="5.3 Service组件"></a>5.3 Service组件</h2><p>具体实现类是StandardService</p><pre><code>public class StandardService extends LifecycleBase implements Service {    // 名字    private String name = null;    //Server 实例    private Server server = null;    // 连接器数组    protected Connector connectors[] = new Connector[0];    private final Object connectorsLock = new Object();    // 对应的 Engine 容器    private Engine engine = null;    // 映射器及其监听器    protected final Mapper mapper = new Mapper();    protected final MapperListener mapperListener = new MapperListener(this);</code></pre><p>MapperListener 是为了支持热部署，当Web应用的部署发生变化时，Mapper中的映射信息也要跟着变化，MapperListener是一个监听器，它监听容器的变化，并将信息更新到Mapper当中。</p><pre><code>protected void startInternal() throws LifecycleException {    //1. 触发启动监听器    setState(LifecycleState.STARTING);    //2. 先启动 Engine，Engine 会启动它子容器    if (engine != null) {        synchronized (engine) {            engine.start();        }    }    //3. 再启动 Mapper 监听器    mapperListener.start();    //4. 最后启动连接器，连接器会启动它子组件，比如 Endpoint    synchronized (connectorsLock) {        for (Connector connector: connectors) {            if (connector.getState() != LifecycleState.FAILED) {                connector.start();            }        }    }}</code></pre><h2 id="5-4-Engine"><a href="#5-4-Engine" class="headerlink" title="5.4 Engine"></a>5.4 Engine</h2><pre><code>public class StandardEngine extends ContainerBase implements Engine {}</code></pre><p>Engine子容器是Host，其持有一个Host容器数组</p><pre><code>protected final HashMap&lt;String, Container&gt; children = new HashMap&lt;&gt;();</code></pre><p>ContainerBase用HashMap保存了它的子容器，并且ContainerBase还实现了子容器的增删改查</p><pre><code>for (int i = 0; i &lt; children.length; i++) {   results.add(startStopExecutor.submit(new StartChild(children[i])));}</code></pre><p>Engine通过将请求转发给某一个Host子容器来对请求进行处理，Engine的基础阀定义如下：</p><pre><code>final class StandardEngineValve extends ValveBase {    public final void invoke(Request request, Response response)      throws IOException, ServletException {      // 拿到请求中的 Host 容器      Host host = request.getHost();      if (host == null) {          return;      }      // 调用 Host 容器中的 Pipeline 中的第一个 Valve      host.getPipeline().getFirst().invoke(request, response);  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Web 浏览器是如何构成的(四)</title>
      <link href="/Web-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%84%E6%88%90%E7%9A%84-%E5%9B%9B/"/>
      <url>/Web-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%84%E6%88%90%E7%9A%84-%E5%9B%9B/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章我们一起研究了渲染过程，并且初步接触了排版器。本篇文章当中，我们会一起研究下排版器(Compositor)是如何实现当用户输入内容时顺滑的进行交互的。</p><h1 id="1-从浏览器的角度看输入事件"><a href="#1-从浏览器的角度看输入事件" class="headerlink" title="1. 从浏览器的角度看输入事件"></a>1. 从浏览器的角度看输入事件</h1><p>当你听到输入事件的时候，你可能只想到在textbox里面输入或者鼠标的点击，但是从浏览器的角度来说，输入代表的是用户任何行为。滚动鼠标滑轮是个输入事件，碰触或者将鼠标悬在某个事件上面也是一个输入事件。</p><p>当用户的某种行为发生的时候，浏览器进程是第一个收到这行为的。但是浏览器进程只是获取这个动作，而真正的处理还是交由渲染进程来做的。因此浏览器进程会将事件类型以及其坐标发送给渲染进程。渲染进程会通过找到事件目标，运行其相应的监听者来对事件进行处理。</p><h1 id="2-理解non-fast-scrollable-区域"><a href="#2-理解non-fast-scrollable-区域" class="headerlink" title="2. 理解non-fast scrollable 区域"></a>2. 理解non-fast scrollable 区域</h1><p>运行JavaScript是主线程的任务，当对一个页面进行拼装的时候，拼装线程标注页面的有事件监听器的部分，标注为Non-fast scrollable region. 通过这种标注来确保党事件在该区域发生的时候，拼装线程可以将这个时间发送给主线程。如果输入事件来自不同的地方，那么拼装线程就会创建一个新的frame来装配这块区域，而不会等待主线程了。</p><h1 id="3-Tips-关于写event-handlers"><a href="#3-Tips-关于写event-handlers" class="headerlink" title="3. Tips 关于写event handlers"></a>3. Tips 关于写event handlers</h1><p>一般写event handling的pattern是事件代理。当事件发生的时候，你可以在最顶层的组件上加一个event handler 然后根据具体的事件目标来分配任务。代码可能会像下面这样子: </p><pre><code>document.body.addEventListener(&#39;touchstart&#39;, event =&gt; {    if (event.target === area) {        event.preventDefault();    }});</code></pre><p>从开发者的角度当时是个好事情，你只需要写一个event handler就可以了。但是从浏览器的角度意味着整个页面都被标注成non-fast scrollable region了，这意味着即使整个页面不在意页面某个部分的输入，拼装线程仍然需要和主线程沟通，并且每次有输入的时候就要等在那里。因此，拼装线程的轮转能力就失效了。</p><p>为了解决这个问题，你可以加上<code>passive:true</code>选项在你的事件监听器当中。这提示了浏览器你仍然想听主线程的事件，但是compositor, 即拼装线程可以自己做自己的事情，然后生成新的frame. 一篇很棒的讲<code>passive</code>的<a href="https://medium.com/@devlucky/about-passive-event-listeners-224ff620e68c" target="_blank" rel="noopener">文章</a>. </p><h1 id="4-检查一个事件是否是cancelable"><a href="#4-检查一个事件是否是cancelable" class="headerlink" title="4. 检查一个事件是否是cancelable"></a>4. 检查一个事件是否是cancelable</h1><p>假定你现在在页面中有个box，你想限制其滚动方向，只能横向的滚动。</p><p>这个时候使用<code>passive:true</code>只是保证页面的滚动可以足够顺滑，但是你还需要使用<code>preventDefault</code>来限制滚动的方向。</p><pre><code>document.body.addEventListener(&#39;pointermove&#39;, event =&gt; {    if (event.cancelable) {        event.preventDefault(); // block the native scroll        /*        *  do what you want the application to do here        */    }}, {passive: true});</code></pre><h1 id="5-减少派送到主线程的事件"><a href="#5-减少派送到主线程的事件" class="headerlink" title="5. 减少派送到主线程的事件"></a>5. 减少派送到主线程的事件</h1><p>对于输入来说，一个触屏设备可以每秒钟发布60-120次碰触事件，而鼠标的移动可以每秒触发100次。如果像触碰的移动这种事件每秒发给主线程120次，那么他会再触发大量的点击测试和js的执行，这样子会导致整个页面的更新非常慢。</p><p>Chrome合并了连续时间，比如滚动，鼠标的滑动，光标移动等，然后延迟分发知道下一次请求渲染的时候。</p><p>如果想知道轨迹的这种信息，可以使用<code>getCoalescedEvents</code>来获取</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part1" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part1</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part2" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part2</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part3" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part3</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part4" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part4</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web </tag>
            
            <tag> Browser </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Web 浏览器是如何构成的(三)</title>
      <link href="/Web-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%84%E6%88%90%E7%9A%84-%E4%B8%89/"/>
      <url>/Web-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%84%E6%88%90%E7%9A%84-%E4%B8%89/</url>
      
        <content type="html"><![CDATA[<p>在前面的两篇文章当中，我们覆盖了木偶进程的架构以及点击输入框以后发生的事情。在本文中，我们会深入去看看渲染进程当中发生了一些什么。</p><p>渲染进程影响网络表现的很多方面。本文还是起到给一个大致脉络的作用，如果想更深入了解，可以看 <a href="https://developers.google.com/web/fundamentals/performance/why-performance-matters/" target="_blank" rel="noopener">Performance Section</a>.</p><h1 id="1-渲染进程处理web内容"><a href="#1-渲染进程处理web内容" class="headerlink" title="1. 渲染进程处理web内容"></a>1. 渲染进程处理web内容</h1><p>渲染进程负责发生在tab当中的所有事情，主线程会处理你发送给用户的大部分代码。一些时候一部分你的js代码会被worker线程来处理(如果你使用web worker或者service worker的话)。Compositor 和 raster线程也是在渲染进程当中运行，使得整个渲染过程更加高效顺滑。</p><p>渲染进程的核心工作就是将HTML，CSS以及JavaScript转换成用户可以进行交互的页面。</p><h1 id="2-Parsing"><a href="#2-Parsing" class="headerlink" title="2. Parsing"></a>2. Parsing</h1><h2 id="2-1-DOM的构建"><a href="#2-1-DOM的构建" class="headerlink" title="2.1 DOM的构建"></a>2.1 DOM的构建</h2><p>当渲染进程收到一个commit信息，开始接受HTML的数据的时候，主线程就开始parseHTML，并且将其转化成Document Object Model了(DOM). </p><p>DOM是浏览器内部的对一个页面，数据结构以及JS构成的API的表示。parse的规则则是由<a href="https://html.spec.whatwg.org/" target="_blank" rel="noopener">HTML Standard</a>来进行定义的。Parser有很强的鲁棒性，因为他基本上可以处理绝大部分html本身写得时候的问题，比如忘记<code>&lt;/b&gt;</code>。都可以很优雅的进行解决。<a href="https://html.spec.whatwg.org/multipage/parsing.html#an-introduction-to-error-handling-and-strange-cases-in-the-parser" target="_blank" rel="noopener">Introduction to error handling</a></p><h2 id="2-2-子资源的加载"><a href="#2-2-子资源的加载" class="headerlink" title="2.2 子资源的加载"></a>2.2 子资源的加载</h2><p>一个网站经常会使用外部资源比如图像，CSS还有JavaScript. 这些文件需要从网络或者Cache里面加载出来。主线程可以在构建DOM树的时候依次去请求他们，但是为了加快整个过程，preload scanner 会同步运行这种加载任务。</p><p>如果遇到像<code>&lt;img&gt; &lt;link&gt;</code>这种tag，preload scanner就会看一下HTML parser转化来的tiken，然后向浏览器进程里的网络线程提交请求。  </p><p>当HTML parser发现一个<code>&lt;script&gt;</code>tag的时候，它会停止对于HTML文件的转译，然后必须要先去加载转译执行javascript代码。这样做的原因是JavaScript是可以去改变整个DOM树的结构的。需要先等其执行完以后再继续向下进行。</p><h2 id="3-自定义加载资源的方式"><a href="#3-自定义加载资源的方式" class="headerlink" title="3. 自定义加载资源的方式"></a>3. 自定义加载资源的方式</h2><ul><li>如果你的JS文件不包含document.write()这类指令，那么你就可以在script tag当中加上<code>async</code> or <code>defer</code> 属性。通过这种提示，浏览器在进行转译的时候就会异步执行js代码，不会阻止parsing的继续进行了。</li><li><code>&lt;link rel=&quot;preload&quot;&gt;</code>会告知浏览器这个资源对于当前的页面导览是必需的，浏览器需要尽快将其下载下来。</li></ul><h2 id="4-样式的处理"><a href="#4-样式的处理" class="headerlink" title="4. 样式的处理"></a>4. 样式的处理</h2><p>只有DOM是远远不够描述页面会是什么样子的。因为我们可以使用CSS来处理页面的各部分的样式。主线程会转译CSS文件，并且决定计算过得各个DOM节点的样式。这种判断取决于CSS选择器给出的各部分需要的样式。</p><p>而且即便你没有提供任何的CSS，每个DOM节点都会有一个计算过的本身的样式。<a href="https://cs.chromium.org/chromium/src/third_party/blink/renderer/core/html/resources/html.css" target="_blank" rel="noopener">Chrome默认样式文件</a></p><h1 id="5-布局"><a href="#5-布局" class="headerlink" title="5. 布局"></a>5. 布局</h1><p>当前的渲染进程已经知道了整个文件的结构，以及每个节点的样式了。但是很可能这还不足以去渲染一个页面。因为除了各部分的分别的大小以外，我们还需要知道他们的相对位置，是如何布局，最终构成整个页面的。</p><p>主线程会遍览DOM树和计算过的样式，然后创建布局样式树，包含了x,y坐标信息和包围的box的大小。注意布局树和DOM树非常相似，但是对于<code>display:none</code>具有这种属性的节点，就完全不会在布局树里出现了。然而，<code>visibility:hidden</code>依然会出现在布局树当中。</p><h1 id="6-上色"><a href="#6-上色" class="headerlink" title="6. 上色"></a>6. 上色</h1><p>主线程会遍历样式树，去创建上色记录。这个记录里面包含了整个上色所需的过程，比如先背景，再文字，blabla </p><h1 id="7-更新渲染的管道消耗很大"><a href="#7-更新渲染的管道消耗很大" class="headerlink" title="7. 更新渲染的管道消耗很大"></a>7. 更新渲染的管道消耗很大</h1><p>在前面所叙述的过程当中，你会发现上一步的结果会成为下一步的输入。换句话说，假设你现在在html里面加了一个节点，那么整个过程基本上就要完全重来一遍了。强烈建议访问<a href="https://developers.google.com/web/updates/2018/09/inside-browser-part3#updating_rendering_pipeline_is_costly" target="_blank" rel="noopener">link</a>，里面有整个过程的动图，很有助于理解。</p><h1 id="8-拼合-Compositing"><a href="#8-拼合-Compositing" class="headerlink" title="8. 拼合 (Compositing)"></a>8. 拼合 (Compositing)</h1><p>现在浏览器获得了整个文件的结构，每个成分的样式，整个页面的布局，上色的顺序。接下来就是拼接额过程了，这个将信息转化成像素的过程叫做rasterizing </p><p>最最开始的时候采取的拼接方案就是随着下滑一点点来渲染的，但是现在方案变得越来越复杂了。</p><p>首先会对整个页面做分层处理，然后分别对其进行渲染，像素化。<a href="https://blog.logrocket.com/eliminate-content-repaints-with-the-new-layers-panel-in-chrome-e2c306d4d752/?gi=cd6271834cea" target="_blank" rel="noopener">Layer 详解</a></p><p>为了知道每个成分都在哪一层，主线程会遍历布局树，去创建一个层级树。</p><p>一旦层级树被创建出来，主线程会将这些信息交给拼接线程。拼接线程接下来就会对每一层做像素化的处理。每一层可能都和整个页面一样大，相互之间是有重叠的，接下来拼接线程就会将他们分开，然后交给不同的像素化线程。像素化线程是在GPU下执行的，拼接线程会对像素胡线程进行优化，让相近的部分先一起像素化完。</p><p>一旦像素化完，拼接线程就会聚集这一部分信息，去创建拼接片。拼接片中包含了内存地址，还有在整个页面当中应处的位置。</p><p>拼接片然后会通过IPC被提交到浏览器进程当中。用拼合线程的好处是主线程不用参与，这样的话在主线程继续计算样式，执行javascript的时候拼接线程已经可以开始工作了。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part1" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part1</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part2" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part2</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part3" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part3</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part4" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part4</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web </tag>
            
            <tag> Browser </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Web 浏览器是如何构成的(二)</title>
      <link href="/Web-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%84%E6%88%90%E7%9A%84-%E4%BA%8C/"/>
      <url>/Web-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%84%E6%88%90%E7%9A%84-%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<p>上一篇文章我们一个看了进程以及线程是如何来处理一个浏览器的不同部分的，在本篇文章中，我们会一起研究下进程与线程之间是怎么进行交流，来最终展示出页面的。</p><p>本篇文章我们将聚焦于一个简单的应用场景:即用户在浏览器的输入框输入网址，回车。让我们看看浏览器是如何从互联网中拿出数据，渲染页面，最终展示出整个网页的。</p><p>正如第一讲中所说的那样，所有在tab之外的内容都是被浏览器进程来进行处理的。浏览器进程有多个线程来处理不同的事务:</p><ul><li>UI线程<ul><li>绘制所有的按钮</li><li>输入框</li></ul></li><li>网络线程<ul><li>解决网络通信问题</li></ul></li><li>存储线程<ul><li>控制对文件的访问</li></ul></li></ul><p>因此，当你在输入框输入网址的时候，请求会被浏览器进程进行处理。</p><h1 id="1-处理请求"><a href="#1-处理请求" class="headerlink" title="1. 处理请求"></a>1. 处理请求</h1><p>首先浏览器要判断你输入的是个query还是个网址。因为在Chrome当中，输入框既可以用来直接进行搜索，也可以去到各个网站。因此UI 线程就需要做parsing，然后判断输入的属性 query/ url，然后将你送到搜索引擎还是到网址。</p><h1 id="2-开启导览-navigation"><a href="#2-开启导览-navigation" class="headerlink" title="2. 开启导览 navigation"></a>2. 开启导览 navigation</h1><p>当你敲击Enter以后，UI 线程就会开始一个网络请求，去拿网站的内容，网络线程就会经由各种协议，DNS搜寻，创建TLS连接等。一些时候，网络线程会受到服务器的重定向header，比如HTTP301。这个时候网络线程就会通知UI线程请求重定向，然后另外一个URL请求会被创建出来。关于输入url以后都发生了什么，写过一篇博，比较详细 - <a href="https://llchen60.com/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E4%BB%A5%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/" target="_blank" rel="noopener">浏览器输入url以后都发生了什么</a></p><h1 id="3-读取Response"><a href="#3-读取Response" class="headerlink" title="3. 读取Response"></a>3. 读取Response</h1><p>一旦得到返回结果的主体(body)，网络线程就会看字节流的前几个字节。Content-Type header会包含返回的数据类型的信息。而后需要看返回的是什么类型的文件，如果是html，那么就交给render进程去进行渲染，如果是zip等文件，那么就意味着这是个下载请求，因此需要将这个请求转到下载管理器处。</p><h1 id="4-寻找一个渲染的进程"><a href="#4-寻找一个渲染的进程" class="headerlink" title="4. 寻找一个渲染的进程"></a>4. 寻找一个渲染的进程</h1><p>在做过各种安全检查以后，网络线程会通知UI线程数据传输完毕，UI线程会去找一个渲染进程来对页面做渲染。</p><p>这里做的一个小优化是在发起请求获取要渲染的页面的同时，UI线程会尝试着提前去找一个渲染进程待命。</p><h1 id="5-渲染页面"><a href="#5-渲染页面" class="headerlink" title="5. 渲染页面"></a>5. 渲染页面</h1><p>现在数据和渲染进程都已经准备好了，一个进程间的通信信息(IPC)就会从浏览器进程发送到渲染进程，告知其可以开始渲染了。同时它也会通过数据流来传递数据，这样渲染进程就可以持续得到数据了。这个时候就开始逐渐加载页面。</p><p>与此同时的，地址栏会得到更新，安全提示，和网站设置UI等都会得到更新。Session的信息，也会更新。</p><h1 id="6-渲染结束"><a href="#6-渲染结束" class="headerlink" title="6. 渲染结束"></a>6. 渲染结束</h1><p>渲染结束以后，渲染进程会送一个IPC回到浏览器进程。这个时候UI<br>线程就会停止显示tab上那个表示加载的旋转小圈圈。</p><h1 id="7-跳转到不同网站"><a href="#7-跳转到不同网站" class="headerlink" title="7. 跳转到不同网站"></a>7. 跳转到不同网站</h1><p>很类似于前面所叙述的过程，唯一不同的是在离开当前页面之前，如果开发者渲染了beforeunload事件，那么会先执行他，一般来说是像那种“你确定要离开当前页面”之类的信息。使用这个事件还是需要谨慎些的，首先技术角度上会让整个运行变慢，因为这个事件的运行和加载新页面需要线性执行；从产品角度上来说，这样的做法对于留存率的提升表现的作用也是有限的… </p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part1" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part1</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part2" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part2</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part3" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part3</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part4" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part4</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web </tag>
            
            <tag> Browser </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Web 浏览器是如何构成的(一)</title>
      <link href="/Web-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%84%E6%88%90%E7%9A%84-%E4%B8%80/"/>
      <url>/Web-%E6%B5%8F%E8%A7%88%E5%99%A8%E6%98%AF%E5%A6%82%E4%BD%95%E6%9E%84%E6%88%90%E7%9A%84-%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<p>这一个小系列是看到了developers.google.com上的一系列讲inside look of modern web browser的文章，觉得写得很有意思，里面叙述了浏览器是如何一步一步将你的代码进行渲染的整个过程，并且提及了各种语言在浏览器当中表现不同的原因。就在这里翻译下，和大家一起分享。</p><h1 id="1-CPU-GPU"><a href="#1-CPU-GPU" class="headerlink" title="1. CPU, GPU"></a>1. CPU, GPU</h1><p>首先是CPU与GPU的说明：</p><ul><li>CPU<ul><li>中央处理单元</li><li>计算机大脑</li><li>可以处理多种不同的任务</li></ul></li><li>GPU<ul><li>图像处理单元</li><li>擅长解决简单的任务，但是需要跨多核心来进行处理</li></ul></li></ul><p>当你在电脑或者浏览器当中运行一个应用的时候，CPU或者GPU就是实际运行程序的东西，而如何运行 - 这种机制是由操作系统来定义的。</p><h1 id="2-进程与线程，-多进程架构"><a href="#2-进程与线程，-多进程架构" class="headerlink" title="2. 进程与线程， 多进程架构"></a>2. 进程与线程， 多进程架构</h1><p>进程可以成为一个应用的执行程序，一个线程是进程的一部分，执行进程程序的任意一部分。</p><p><img src="https://i.loli.net/2020/02/02/nBacm7IHfkLe6MQ.png" alt="fig1.png"></p><p>当你打开一个应用，一个进程就被创建了出来。程序有可能会建立多个线程来帮助进程进行工作（可选择的）。操作系统给进程一部分的内存空间使用，所用的应用内的状态都会存储在这一部分私人的内存空间当中。当你关闭应用，进程就会结束，操作系统也会将内存空间释放掉。</p><p>一个进程可以要求操作系统去开另外一个进程来跑其他的一些任务。当这发生时，另外的一部分内存就会被分配给新的进程使用。两个进程之间可以进行进程间通信。使用进程间通信的好处是如果一个进程不工作了，那么操作系统只需要重启这个进程就好，不会影响到其他的进程。</p><h1 id="3-浏览器架构"><a href="#3-浏览器架构" class="headerlink" title="3. 浏览器架构"></a>3. 浏览器架构</h1><p>浏览器是如何使用进程和线程的呢？ 两种方式，但并无好坏之分，完全是不同的浏览器内核选择了不同的实现方式。</p><ul><li>一个进程，内含多个线程</li><li>多个进程，少量线程负责进程间的通信</li></ul><p><img src="https://i.loli.net/2020/02/02/1TRsOX2fBFN3DEg.png" alt="fig2.png"></p><h2 id="3-1-Chrome的架构"><a href="#3-1-Chrome的架构" class="headerlink" title="3.1 Chrome的架构"></a>3.1 Chrome的架构</h2><p><img src="https://i.loli.net/2020/02/02/Z6f4QiHO1FJCjeL.png" alt="fig3.png"></p><p>如图所示，最上层是浏览器进程和其他进程合作来管理应用的不同部分。对于渲染进程，多个进程会被创建，并分配给每个tab。</p><h2 id="3-2-进程控制体系"><a href="#3-2-进程控制体系" class="headerlink" title="3.2 进程控制体系"></a>3.2 进程控制体系</h2><ul><li>浏览器进程<ul><li>控制浏览器本身的一些功能<ul><li>书签，收藏</li><li>前进，后退</li></ul></li><li>处理看不到的权限处理，网络请求的部分</li></ul></li><li>Renderer<ul><li>处理tab以内的网址展示的部分</li></ul></li><li>Plugin<ul><li>控制plugins</li></ul></li><li>GPU<ul><li>专门用来解决GPU相关的任务，和其他的进程分开。这样做是因为GPU是将从不同app来的请求放到一块进行处理的，然后放在一个界面上。 </li></ul></li></ul><p><img src="https://i.loli.net/2020/02/02/1BkHY7NX85uPhyI.png" alt="fig4.png"></p><h2 id="3-3-多进程架构的优势劣势"><a href="#3-3-多进程架构的优势劣势" class="headerlink" title="3.3 多进程架构的优势劣势"></a>3.3 多进程架构的优势劣势</h2><ul><li>互不影响，可以只崩一个tab，但是如果是同一个进程，所有tab就都崩掉了</li><li>安全，沙盒  可以实现tab/ process级别的控制</li><li>因为每个进程都有自己的内存空间，所以chrome会使用更多的内存(相比于友商们). 但是当chrome到达限制以后，其会让多个tab使用同一个进程来缓解这个问题的。</li><li>Chrome当前正在做的是，通过检测硬件的状态来决定是否将每个微服务放到一个单独的进程上来运行，或者全放到一块。</li></ul><h2 id="3-4-组件隔离-site-isolation"><a href="#3-4-组件隔离-site-isolation" class="headerlink" title="3.4 组件隔离 (site isolation)"></a>3.4 组件隔离 (site isolation)</h2><p>Chrome会运行一个单独的渲染进程对于来自不同的网站的请求（对于组件的渲染）。一个tab一个进程的方式可能会使得同一个页面内来自不同的网址的组件在同一个进程内分享同一个内存空间中的东西，这是很不安全的。我们需要确保一个网站不可以不经过同意就去访问另外一个网站携带/获取的数据。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part1" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part1</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part2" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part2</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part3" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part3</a></li><li><a href="https://developers.google.com/web/updates/2018/09/inside-browser-part4" target="_blank" rel="noopener">https://developers.google.com/web/updates/2018/09/inside-browser-part4</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web </tag>
            
            <tag> Browser </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于5G</title>
      <link href="/%E5%85%B3%E4%BA%8E5G/"/>
      <url>/%E5%85%B3%E4%BA%8E5G/</url>
      
        <content type="html"><![CDATA[<p>关于5G本身，无须赘述，有太多太多文章or博客详细说了它的特征与改变，20GB/s的下载速度，10GB/s的上传速度， 低至4ms的延时, etc. 即高速，极低延时。</p><p>乍一听这个概念，很难想象有什么应用场景是非他不可的（向后看），又有什么新的应用场景是因为5G的兴盛将逐渐铺展开来的（向前看）。</p><p>BrainStorm  -&gt; 什么地方很需要高速？ 低延时？ 高带宽？ -&gt; 讲求实时性的应用场景 -&gt; 自动驾驶，物联网，VR虚拟现实。</p><p>疯狂畅想一下，当5G真的普及以后，整个社会会变成的样子。</p><h1 id="1-终端的配置还重要么？"><a href="#1-终端的配置还重要么？" class="headerlink" title="1. 终端的配置还重要么？"></a>1. 终端的配置还重要么？</h1><p>在3G， 4G时代我们对于终端的要求非常高，为了能够在终端中存储我们需要使用的app，获取我们想要获取的所有信息。但是如果有一天，我们直接从云端运行游戏和本机上有几乎一样的体验的时候，你还需要很高的配置么？ </p><p>我们现在所使用的手机，可以想象成一个巨大的缓存层，需要他是因为和服务器的交互有比较高的延时，我们在用各种方式去限制和服务器交流的次数，还有每次交流的大小；为了加快速度，还把很多东西都存到了本地。</p><p>那么，当5G成熟的时候，当我们和服务器的交互的延时几乎可以忽略不计的时候，为什么我们的终端还需要那么大的存储，那么强的性能呢？ 为什么我们还需要将app提前安装在自己的终端呢？ 这个时候可能变成，我们只需要一个屏幕，一个网卡，对于配置的要求几乎为零，就可以完成我们现在正在做需要做的所有事情了。</p><p>继续延伸，如果终端某种程度上演化为只需要一块屏幕，那么其成本要比现在低非常多，而5G网络本身的成本(基站，运维)，其边际成本几乎为零。那么会不会有一天真的能实现电影里描述的那种，身边全是屏幕，所有东西都可以进行点击，可以非常迅捷的完成各种操作呢？ </p><h1 id="2-物联网？智能家居？"><a href="#2-物联网？智能家居？" class="headerlink" title="2. 物联网？智能家居？"></a>2. 物联网？智能家居？</h1><p>如果有去过什么演唱会，现场球赛之类的，那你一定会察觉到现场网速非常慢… 可以这样简化下，这是因为每个部署的基站有着最大可以提供服务的连接数的限制，因此当人多了以后，连接数太大，互相之间就会开始抢占有限的资源，导致速度越来越慢。</p><p>这也是在3G, 4G时代，虽然我们喊了那么多年的物联网，万物互联，但实际上并没有太发展起来的原因。而5G，能够支持同时接入更多的设备。这也扫除了物联网发展的一大障碍。</p><h1 id="3-无人驾驶？-无人机？"><a href="#3-无人驾驶？-无人机？" class="headerlink" title="3. 无人驾驶？ 无人机？"></a>3. 无人驾驶？ 无人机？</h1><p>现在的无人驾驶方案都是在汽车上部署大量传感器和高性能计算机，传感器传输信息，高性能计算机实时进行分析和反馈。这带来了一些问题，首先是运算能力的不足，即在有限的空间和不稳定的环境(温度，震动等)需要有稳定的计算速度；相对较高的成本，每辆车都需要装高性能计算机，给后期的运维也造成了不小的困难。而当延时降低到可以忽略不计的程度的时候，我们可以将数据实时发送回云端，数据处理完以后再实时传送回来。云端服务器往往有更好的性能，后期维护成本也会低非常多。同理对无人机也适用。 </p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
            <tag> 5G </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>API-重新认识RESTFUL</title>
      <link href="/API-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86RESTFUL/"/>
      <url>/API-%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86RESTFUL/</url>
      
        <content type="html"><![CDATA[<p>本文主要讲如何对接口进行设计，让URL更为合理，指定合理的数据格式，处理错误码的方式</p><h1 id="1-API-概念"><a href="#1-API-概念" class="headerlink" title="1. API 概念"></a>1. API 概念</h1><p>广义的API（Application Programming Interface）是指应用程序编程接口，包括在操作系统中的动态链接库文件例如dll\so，或者基于TCP层的socket连接，用来提供预定义的方法和函数，调用者无需访问源码和理解内部原理便可实现相应功能。而当前通常指通过<strong>HTTP协议传输的web service技术</strong>。</p><p>API和语言无关，理论上具有网络操作能力的编程语言都可以通过相应HTTP请求并构造HTTP包来完成API的架构。API和Json，xml等媒体类型没有太大的关系，它们知识一种传输或媒体的格式，便于计算机解析和读取数据。</p><blockquote><p>基于以上，API设计的目的是为了让程序可读，应当遵从简单、易用、无状态等特性，这也是为什么Restful风格流行的原因。</p></blockquote><h1 id="2-Restful-API"><a href="#2-Restful-API" class="headerlink" title="2. Restful API"></a>2. Restful API</h1><blockquote><p>Restful = 有意义的URL + 合适的HTTP动词</p></blockquote><p><img src="https://i.loli.net/2020/02/01/1q85H4orvdW9KBG.png" alt="fig1.png"></p><p>REST（英文：Representational State Transfer，简称REST），RESTful是一种对基于HTTP的应用设计风格，只是提供了一组设计原则和约束条件，而不是一种标准。网络上有大量对RESTful风格的解读，简单来说Restful定义URI和HTTP状态码，让你的API设计变得更简洁、清晰和富有层次，对缓存等实现更有帮助。</p><p>HTTP包处于网络应用层，因此HTTP包为平台无关的字符串表示，如果尽可能的使用HTTP的包特征而不是大量在body定义自己的规则，可以用更简洁、清晰、高效的方式实现同样的需求。</p><p><img src="https://i.loli.net/2020/02/01/lCmurw9Z3hVDH8G.png" alt="fig2.png"></p><p>例子中使用路径参数构建URL和HTTP动词来区分我们需要对服务所做出的操作，而不是使用URL上的接口名称，例如 getProducts等；使用HTTP状态码，而不是在body中自定义一个状态码字段；URL需要有层次的设计，例如/catetory/{category_id}/products 便于获取path参数，在以后例如<strong>负载均衡和缓存的路由</strong>非常有好处。</p><p>RESTful的本质是基于HTTP协议对资源的增删改查操作做出定义。理解HTTP协议非常简单，HTTP是通过网络socket发送一段字符串，这个字符串由键值对组成的header部分和纯文本的body部分组成。Url、Cookie、Method都在header中。</p><h1 id="3-JSON-API"><a href="#3-JSON-API" class="headerlink" title="3. JSON API"></a>3. JSON API</h1><p>因为RESTFUL风格仅仅规定了URL和HTTP Method的使用，并没有定义body中数据的格式。那么问题来了：</p><blockquote><p>如何定义请求或者返回对象的结构，该如何针对不同的情况返回不同的HTTP状态码呢？ </p></blockquote><p>JSON已经是最主流的网络传输格式，因此本文默认JSON作为传输格式来讨论后面的话题。JSONAPI尝试去提供一个非常通用的描述数据资源的格式，关于记录的创建、更新和删除，因此要求在前后端均容易实现，并包含了基本的关系类型。</p><h2 id="3-1-MIME类型"><a href="#3-1-MIME类型" class="headerlink" title="3.1 MIME类型"></a>3.1 MIME类型</h2><p>JSON API数据格式已经被IANA机构接受了注册，因此必须使用<strong>application/vnd.api+json</strong>类型。客户端请求头中Content-Type应该为<strong>application/vnd.api+json</strong>，并且在Accept中也必须包含<strong>application/vnd.api+json</strong>。如果指定错误服务器应该返回415或406状态码。</p><h2 id="3-2-JSON文档结构"><a href="#3-2-JSON文档结构" class="headerlink" title="3.2 JSON文档结构"></a>3.2 JSON文档结构</h2><p>在顶级节点使用data、errors、meta，来描述数据、错误信息、元信息，<strong>注意data和errors应该互斥</strong>，不能再一个文档中同时存在，meta在项目实际上用的很少，只有特别情况才需要用到，比如返回服务器的一些信息。</p><p><img src="https://i.loli.net/2020/02/01/qAyxgkXnQfeELjS.png" alt="fig3.png"></p><h3 id="3-2-1-data-属性"><a href="#3-2-1-data-属性" class="headerlink" title="3.2.1 data 属性"></a>3.2.1 data 属性</h3><p>一个典型的data对象格式，我们的有效信息一般都放在attributes当中。</p><p><img src="https://i.loli.net/2020/02/01/DbLVQE2Gy184MqK.png" alt="fig4.png"></p><h3 id="3-2-2-errors属性"><a href="#3-2-2-errors属性" class="headerlink" title="3.2.2 errors属性"></a>3.2.2 errors属性</h3><p>这里的errors和data有一点不同，一般来说返回值中errors作为列表存在，因为针对每个资源可能出现多个错误信息。最典型的例子为，我们请求的对象中某些字段不符合验证要求，这里需要返回验证信息，但是HTTP状态码会使用一个通用的401，然后把具体的验证信息在errors给出来。</p><p><img src="https://i.loli.net/2020/02/01/wiKpC8Q9ngItRJr.png" alt="fig5.png"></p><h1 id="4-常用返回码"><a href="#4-常用返回码" class="headerlink" title="4. 常用返回码"></a>4. 常用返回码</h1><ul><li>200 OK</li><li>201 created </li></ul><p>如果客户端发起一个POST请求，在RESTful部分我们提到，POST为创建资源，如果服务器处理成功应该返回一个创建成功的标志，在HTTP协议中，201为新建成功的状态。文档规定，服务器必须在data中返回id和type。</p><ul><li>401 Unauthorized</li></ul><p>如果服务器在检查用户输入的时候，需要传入的参数不能满足条件，服务器可以给出401错误，标记客户端错误，需要客户端自查。</p><ul><li>415 Unsupported Media Type</li></ul><p>当服务器媒体类型Content-Type和Accept指定错误的时候，应该返回415。</p><ul><li>403 Forbidden </li></ul><p>当客户端访问未授权的资源时，服务器返回403要求用户授权信息。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RESTFul </tag>
            
            <tag> Web </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Thoughts on web accessibility(信息无障碍)</title>
      <link href="/Thoughts-on-web-accessibility-%E4%BF%A1%E6%81%AF%E6%97%A0%E9%9A%9C%E7%A2%8D/"/>
      <url>/Thoughts-on-web-accessibility-%E4%BF%A1%E6%81%AF%E6%97%A0%E9%9A%9C%E7%A2%8D/</url>
      
        <content type="html"><![CDATA[<p>我们在做前端的时候，实质上信息无障碍是很多工程师很容易忽视但又着实很重要的一部分，要知道在这个世界上是有很多人因为一些原因无法像正常人一样去浏览网页的，诸如色盲，盲人，老花等等，我们需要适配设计的网页，使其尽量对于各种人都是信息无障碍的。总觉得这是件大部分人都没有想到的事情，但是一旦想到了，那么就应该做点什么，来使这部分相对边缘的人也可以正常的去看我们设计的网页。</p><p>以下是Wiki给出的定义: </p><blockquote><p>“ Web accessibility refers to the inclusive practice of removing barriers that prevent interaction with, or access to websites, by people with disabilities. When sites are correctly designed, developed and edited, all users have equal access to information and functionality.”</p></blockquote><h1 id="1-Accessibility-标准"><a href="#1-Accessibility-标准" class="headerlink" title="1. Accessibility 标准"></a>1. Accessibility 标准</h1><ul><li>可感知<ul><li>如果只提供凭借一种感官才能让用户感知到内容，无形中会失去很多用户</li></ul></li><li>可操作<ul><li>能否正常使用每一个组件的功能<ul><li>E.G 下拉菜单，很多网站设计的时候hover over的时候就有下拉效果，但是无法点击。 如果我们的用户无法看到这些东西，那很可能就无法继续交互下去了。</li></ul></li></ul></li><li>可理解<ul><li>用户能否很好地理解呢？<ul><li>需要考虑读屏软件的适用性</li></ul></li></ul></li><li>强健性<ul><li>能否被多种User Agent使用<ul><li>屏幕阅读器</li><li>IE</li></ul></li></ul></li></ul><p>WebAIM (web accessibility in mind) <a href="https://webaim.org/standards/wcag/checklist" target="_blank" rel="noopener">Checklist</a> </p><h1 id="2-Tips-一些我们可以follow的东西"><a href="#2-Tips-一些我们可以follow的东西" class="headerlink" title="2. Tips 一些我们可以follow的东西"></a>2. Tips 一些我们可以follow的东西</h1><ul><li>标题 段落 列表 保持良好的结构<ul><li>屏幕阅读器在读到结构相对良好的标签的时候，会帮助用户更容易理解我们网站的内容</li></ul></li><li>尽可能使用语义化标签<ul><li>浏览器的调试工具当中有<strong>Accessibility tree</strong>,浏览器会获取DOM树，浏览器会获取DOM树，然后将其修改成适用于辅助技术的形式(无障碍树)，所以良好的使用语义化标签，能让辅助设备更合理地将我们网站的内容转化成Accessibility tree，从而解读给用户，确保页面中的重要的元素有正确的无障碍角色、状态和属性。</li></ul></li><li>为所有非文本内容提供文本替代项<ul><li>所有的图片都应当有alt属性，重要的图片应使用描述性替代文本简洁说明图像内容。</li></ul></li><li>DOM顺序与Tab键顺序保持一致</li><li>不要做<code>a {outline: none}</code>这种操作，因为这样的话这个小组件就是Unfocusable的了，对于不懂的人完全没法继续搞了</li><li>对比度 最低要求 4.5:1 </li><li>我们可以使用chrome浏览器的Audits找到自己的网站存在的所有无障碍问题，然后针对性的进行修改</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://insights.thoughtworks.cn/about-web-accessibility/" target="_blank" rel="noopener">https://insights.thoughtworks.cn/about-web-accessibility/</a></li><li><a href="https://webaim.org/standards/wcag/checklist" target="_blank" rel="noopener">https://webaim.org/standards/wcag/checklist</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> Web Accessibility </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RPC协议</title>
      <link href="/RPC%E5%8D%8F%E8%AE%AE/"/>
      <url>/RPC%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是远程过程调用"><a href="#1-什么是远程过程调用" class="headerlink" title="1. 什么是远程过程调用"></a>1. 什么是远程过程调用</h1><p>RPC是指计算机A上的进程，调用另外一台计算机B上的进程，其中A上的调用进程被挂起，而B上的被调用进程开始执行，当值返回给A时，A进程继续执行。</p><p>注意这中间，AB都经历了内核态和用户态之间的转变。</p><p>整个流程如图所示：</p><p><img src="https://i.loli.net/2020/02/01/tqlp2wST4KBcgyn.jpg" alt="fig1.jpg"></p><h1 id="2-痛点"><a href="#2-痛点" class="headerlink" title="2. 痛点"></a>2. 痛点</h1><p>那远程过程调用到底解决了什么问题呢？</p><p>由于各服务部署在不同机器上，要想再服务间进行远程调用免不了网络通信过程，服务消费方每调用一个服务都要写大量和网络通信相关的代码，RPC框架实际上完成了对网络通信的细节的封装，让消费方能够像调用本地服务一样调用远程服务。</p><h1 id="3-RPC框架入门"><a href="#3-RPC框架入门" class="headerlink" title="3. RPC框架入门"></a>3. RPC框架入门</h1><p>RPC框架中主要有三个角色，</p><ul><li>Provider 服务提供方</li><li>Consumer 服务消费方</li><li>Registry 服务注册中心</li></ul><p>使用服务注册中心的原因是，在SOA框架中，往往Provider和Consumer的数量不唯一，通过注册中心注册服务，可以做负载均衡。</p><p><img src="https://i.loli.net/2020/02/01/mYIbBUGoSEPTvu5.jpg" alt="fig2.jpg"></p><p><img src="https://i.loli.net/2020/02/01/HqPaDVrWStugIf6.jpg" alt="fig3.jpg"></p><p>服务提供者启动后主动向注册中心注册机器ip, port以及提供的服务列表；服务消费者启动时向注册中心获取服务提供方地址列表，可实现软负载均衡和Failover.<br>RPC框架当中需要使用很多技术，以下列出来主要的一部分： (do match internal amazon c***** framework!)</p><h2 id="3-1-动态代理"><a href="#3-1-动态代理" class="headerlink" title="3.1 动态代理"></a>3.1 动态代理</h2><h2 id="3-2-序列化"><a href="#3-2-序列化" class="headerlink" title="3.2 序列化"></a>3.2 序列化</h2><p>为了能在网络上传输和接收Java对象，需要进行序列化和反序列化的操作</p><h2 id="3-3-NIO"><a href="#3-3-NIO" class="headerlink" title="3.3 NIO"></a>3.3 NIO</h2><p>基于Netty这一IO通信框架</p><p><a href="https://blog.csdn.net/suifeng3051/article/details/23348587" target="_blank" rel="noopener">Netty4详解</a></p><h2 id="3-4-服务注册中心"><a href="#3-4-服务注册中心" class="headerlink" title="3.4 服务注册中心"></a>3.4 服务注册中心</h2><p>Redis/ ZooKeeper/ Consul/ Etcd</p><h1 id="4-RPC-vs-REST"><a href="#4-RPC-vs-REST" class="headerlink" title="4. RPC vs REST"></a>4. RPC vs REST</h1><p>是理念的不同，REST是一种设计风格，REST的URL主体是资源，是名词，而且也仅支持HTTP协议，规定了使用HTTP Method来表达本次要做的动作，类型个位数… 这些动作表达了对资源仅有的几种转换方式。</p><p>而RPC的思想，是把本地函数映射到API，也就是说一个API对应的是一个函数，本地有什么函数，远程也可以调用这个函数；是建立在采用的协议之上的。</p><p>可以参考<a href="https://www.zhihu.com/question/28570307" target="_blank" rel="noopener">WEB开发中，使用JSON-RPC好，还是RESTful API好？</a>获取更多细节。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web </tag>
            
            <tag> RPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RESTful vs RPC</title>
      <link href="/RESTful-vs-RPC/"/>
      <url>/RESTful-vs-RPC/</url>
      
        <content type="html"><![CDATA[<p>本文主要想分析二者的不同，以及为什么要采用RPC远程调用的方式，关于RPC协议本身，可以看这篇文章<a href="https://www.llchen60.com/2018/12/15/RPC%E5%8D%8F%E8%AE%AE/">RPC协议</a></p><h1 id="1-REST详解"><a href="#1-REST详解" class="headerlink" title="1. REST详解"></a>1. REST详解</h1><p>REST 代表 representational state transfer, 即表现层状态转移，划重点，状态的转移。 REST本身是不包含动作的，用一个个名词来划定资源，再通过定义的Get/Post/Put/delete等操作来做资源的交换。用Roy Fielding在其论文里的话来说： <strong>REST is all about a client-server relationship, where server-side data are made available through representations of data in simple formats, often JSON and XML.</strong><br>REST是来论述client和server之间的关系的，其中server端的数据是通过简单类型的数据(representation of data)来进行表示的，通常是JSON和XML.</p><p>这种数据的表现是可以进行修改的，我们可以通过方法以及多媒体(链接)来赋予动作和关系，然后进行各个状态的转移。相当于说，链接以及方法给予了状态转移的渠道和方式。</p><p>REST自身有一些限制：</p><ul><li>REST是无状态的，请求之间没有持久的会话信息</li><li>响应需要声明成可缓存的</li><li>REST关注一致性，如果使用HTTP，需要尽可能使用HTTP的特性，而不是去发明新的公约</li></ul><p>REST之美体现在从任何状态向任何状态转移的合法的行为总是被server所控制的，与client的关系比较小；client是运行时候发出的请求。而对于RPC而言，它的行为会更加固定一些。对比二者之间的区别，你可以想象你通过不停点击链接从淘宝首页最终转到产品详情页的整个过程，和输入一个名词，通过一个API call直接到详情页的过程。</p><p>在上述第一个例子里，只要对server端的url链接做各种变化就可以了，让他能接受各种参数；但是对于第二种情况而言，我们需要在client端实现这个API call，然后从client向server发出一个请求，是需要在client和server端都进行修改的。</p><p>其实这里可以稍微加一点和RPC相比的“优势”，相对而言，RPC给工程师更多的操作空间，即你可以写出有着超强限定的API，但这样往往适用性会很低，然后随着时间，会出现N多API call，这对于后期的维护，开发都会造成不太好的影响。</p><h1 id="2-What’s-RPC"><a href="#2-What’s-RPC" class="headerlink" title="2. What’s RPC"></a>2. What’s RPC</h1><p>RPC，远程过程调用，前面写过一篇博文来讲它，大家可以<a href="https://www.llchen60.com/2018/12/15/RPC%E5%8D%8F%E8%AE%AE/">点击</a>去看详情。这里说说它的发展的过程，起先的时候大家都用XML-RPC，奈何不怎么好用啊…因为XML对于各种类型的支持不是很好，大部分都只能当成String处理，这就尴尬了，你只能再附上metadata告诉别人这个到底是什么类型的。后面有了Json就好一些了。 </p><p>采用RPC比较难搞的还是你的API的精细度，解释一下，用REST的时候你可以通过query来询问不同的东西，这个时候实际上都是面对一个API的嘛，但是对于<br>RPC而言，我们是需要构建一个API专门来解决一个问题的。需要对其精细度（细化程度）做考量的。</p><h1 id="3-对比"><a href="#3-对比" class="headerlink" title="3. 对比"></a>3. 对比</h1><p>其实二者没有孰优孰劣，甚至某种程度上这种比较是有点神奇的。因为实质上他们是可以相套的，比如从client看是个REST的API，但是从Server来看，在这个URL之下，实际上是用了RPC协议，从远程调用了另外一个服务的某个API，来使用。</p><p>REST更多的是面向状态，如果全都用REST来写API的话，你会发现他给出的几种预制的行为有些时候是无法很切实的描述出这个动作的；而RPC则可以很好的解决这一点，其主体就是个动作。</p><p>[1]. <a href="https://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/" target="_blank" rel="noopener">https://etherealbits.com/2012/12/debunking-the-myths-of-rpc-rest/</a></p><p>[2] Roy Fielding’s dissertation <a href="https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm" target="_blank" rel="noopener">https://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm</a> </p><p>[3]. <a href="https://www.smashingmagazine.com/2016/09/understanding-rest-and-rpc-for-http-apis/" target="_blank" rel="noopener">https://www.smashingmagazine.com/2016/09/understanding-rest-and-rpc-for-http-apis/</a></p><p>[4]. <a href="https://zhuanlan.zhihu.com/p/34440779" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34440779</a></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RESTFul </tag>
            
            <tag> RPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LDAP Intro</title>
      <link href="/LDAP-Intro/"/>
      <url>/LDAP-Intro/</url>
      
        <content type="html"><![CDATA[<h1 id="1-What’s-LDAP"><a href="#1-What’s-LDAP" class="headerlink" title="1. What’s LDAP?"></a>1. What’s LDAP?</h1><p>LDAP stands for <strong><em>Lightweight Directory Access Protocol</em></strong>. It is a lightweight client-server protocol for accessing directory services. It runs over <strong>TCP/IP or other connection oriented transfer services</strong>. </p><h1 id="2-What’s-directory"><a href="#2-What’s-directory" class="headerlink" title="2. What’s directory?"></a>2. What’s directory?</h1><p>Similar to database, but contain more <strong>descriptive, attribute-based information</strong>. It has some features:</p><ol><li>Read much more often than it is written. </li><li>Directories are tuned to give quick response to high volume look up or search operations.</li><li>Have the ability to replicate information widely in order to increase availability and reliability</li></ol><h1 id="3-How-does-LDAP-work"><a href="#3-How-does-LDAP-work" class="headerlink" title="3. How does LDAP work?"></a>3. How does LDAP work?</h1><p>LDAP directory serve base on a client-server model. One or more LDAP servers contain the data making up the LDAP directory tree or LDAP backend database. An LDAP client connects to an LDAP server and asks it a question. The server responds with the answer, or with a pointer to where the client can get more information (typically, another LDAP server). No matter what LDAP server a client connects to, it sees the same view of the directory; a name presented to one LDAP server references the same entry it would at another LDAP server. This is an important feature of a global directory service, like LDAP.</p><h1 id="4-Directory-Structure"><a href="#4-Directory-Structure" class="headerlink" title="4. Directory Structure"></a>4. Directory Structure</h1><p>The protocol provides an interface with directories that follow the x.500 model:</p><ul><li><p>An entry consists of a set of attributes</p></li><li><p>An attribute has a name(an attribute type or attribute description) and one or more values. Attrs are defined in a schema. </p></li><li><p>Each entry has a unique identifier - distinguished Name(DN).This consists of its Relative Distinguished Name (RDN), constructed from some attribute(s) in the entry, followed by the parent entry’s DN.</p><p>   dn: cn=John Doe,dc=example,dc=com<br>   cn: John Doe<br>   givenName: John<br>   sn: Doe<br>   telephoneNumber: +1 888 555 6789<br>   telephoneNumber: +1 888 555 1232<br>   mail: <a href="mailto:john@example.com">john@example.com</a><br>   manager: cn=Barbara Doe,dc=example,dc=com<br>   objectClass: inetOrgPerson<br>   objectClass: organizationalPerson<br>   objectClass: person<br>   objectClass: top</p></li></ul><p><code>&quot;dn&quot;</code> is the distinguished name of the entry; it is neither an attribute nor a part of the entry. <code>&quot;cn=John Doe&quot;</code> is the entry’s RDN (Relative Distinguished Name), and <code>&quot;dc=example,dc=com&quot;</code> is the DN of the parent entry, where <code>&quot;dc&quot;</code> denotes <code>&#39;Domain Component&#39;</code>. The other lines show the attributes in the entry. Attribute names are typically mnemonic strings, like <code>&quot;cn&quot;</code> for common name, <code>&quot;dc&quot;</code> for domain component, <code>&quot;mail&quot;</code> for e-mail address, and <code>&quot;sn&quot;</code> for surname.</p><p>A server holds a subtree starting from a specific entry, e.g. <code>&quot;dc=example,dc=com&quot;</code> and its children. Servers may also hold references to other servers, so an attempt to access <code>&quot;ou=department,dc=example,dc=com&quot;</code> could return a referral or continuation reference to a server that holds that part of the directory tree. The client can then contact the other server. Some servers also support chaining, which means the server contacts the other server and returns the results to the client.</p><p>LDAP rarely defines any ordering: The server may return the values of an attribute, the attributes in an entry, and the entries found by a search operation in any order. This follows from the formal definitions - an entry is defined as a set of attributes, and an attribute is a set of values, and sets need not be ordered. </p><h1 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h1><p>1.<a href="https://segmentfault.com/a/1190000002607140" target="_blank" rel="noopener">LDAP服务器的概念和原理简单介绍</a><br>2.<a href="https://www.tldp.org/HOWTO/LDAP-HOWTO/whatisldap.html" target="_blank" rel="noopener">What’s LDAP</a><br>3.<a href="https://en.wikipedia.org/wiki/Lightweight_Directory_Access_Protocol" target="_blank" rel="noopener">Wiki: Lightweight_Directory_Access_Protocol</a></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web </tag>
            
            <tag> LDAP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP API认证与授权(七) - OAuth 2.0</title>
      <link href="/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%B8%83-OAuth-2-0/"/>
      <url>/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%B8%83-OAuth-2-0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><p>在前面，我们可以看到，从Digest Access， 到AppID+HMAC，再到JWT，再到OAuth 1.0，这些个API认证都是要向Client发一个密钥（或是用密码）然后用HASH或是RSA来签HTTP的请求，这其中有个主要的原因是，以前的HTTP是明文传输，所以，在传输过程中很容易被篡改，于是才搞出来一套的安全签名机制，所以，这些认证方法都是可以在HTTP明文协议下使用的。</p><p>这种使用签名方式大家可以看到是比较复杂的，所以，对于开发者来说，也是很不友好的，在组织签名的那些HTTP报文的时候，各种，URLEncode和Base64，还要对Query的参数进行排序，然后有的方法还要层层签名，非常容易出错，另外，这种认证的安全粒度比较粗，授权也比较单一，对于有终端用户参与的移动端来说也有点不够。所以，在2012年的时候，OAuth 2.0 的 RFC 6749 正式放出。</p><p>OAuth 2.0依赖于TLS/SSL的链路加密技术（HTTPS），完全放弃了签名的方式，认证服务器再也不返回什么 token secret 的密钥了，所以，OAuth 2.0是完全不同于1.0 的，也是不兼容的。</p><p>两个主要Flow</p><ul><li>Authorization Code Flow </li><li>Client Credential Flow </li></ul><h1 id="2-流程"><a href="#2-流程" class="headerlink" title="2. 流程"></a>2. 流程</h1><h2 id="2-1-名词定义"><a href="#2-1-名词定义" class="headerlink" title="2.1 名词定义"></a>2.1 名词定义</h2><ul><li>Third party application: 第三方应用程序</li><li>HTTP Service: HTTP服务提供商</li><li>Resource Owner: 资源所有者</li><li>User Agent: 用户代理</li><li>Authorization server: 认证服务器</li><li>Resource server: 资源服务器 </li></ul><h2 id="2-2-general-idea"><a href="#2-2-general-idea" class="headerlink" title="2.2 general idea"></a>2.2 general idea</h2><p>在客户端和服务提供商之间设置一个授权层，客户端只能通过授权层来到服务提供商那里获取信息。整个流程变成用户用用户名密码登录客户端，用户给客户端带有特定权限的token。客户端登录授权层以后，服务提供商根据token的权限范围和有效期，向客户端开放用户存储的资料。</p><h2 id="2-3-运行流程"><a href="#2-3-运行流程" class="headerlink" title="2.3 运行流程"></a>2.3 运行流程</h2><p><img src="https://i.loli.net/2020/02/01/Wdat63GcDsKT9mf.png" alt="fig1.png"></p><ul><li>A: 用户打开客户端以后，客户端要求用户给予授权</li><li>B: 用户同意给客户端授权</li><li>C: 客户端使用得到的授权，向认证服务器申请令牌</li><li>D: 认证服务器对客户端进行认证以后，确认无误，同意发放令牌</li><li>E: 客户端使用令牌，向资源服务器申请获取资源</li><li>F: 资源服务器确认令牌无误，同意向客户端开放资源</li></ul><h1 id="3-客户端授权模式"><a href="#3-客户端授权模式" class="headerlink" title="3 客户端授权模式"></a>3 客户端授权模式</h1><p>客户端必须要获得用户的授权才能获得令牌，授权方式有以下几种：</p><ul><li>授权码模式 (authorization code)</li><li>简化模式 (implicit)</li><li>密码模式 (resource owner password credentials)</li><li>客户端模式 (client credentials)</li></ul><h2 id="3-1-授权码模式"><a href="#3-1-授权码模式" class="headerlink" title="3.1 授权码模式"></a>3.1 授权码模式</h2><p>通过客户端的后台服务器，与服务提供商的认证服务器进行交流。</p><p><img src="https://i.loli.net/2020/02/01/BTpKrmRWw9Ju2aE.png" alt="fig2.png"></p><ul><li>A: 用户访问客户端，后者将前者导向认证服务器</li><li>B: 用户选择是否给予客户端授权</li><li>C: 假设用户给予授权，认证服务器将用户导向客户端事先指定的”重定向URI”（redirection URI），同时附上一个授权码。</li><li>D: 客户端收到授权码，附上早先的”重定向URI”，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。</li><li>E: 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌（access token）和更新令牌（refresh token）</li></ul><p>A步骤，客户端申请认证的URI，包含以下参数：</p><ul><li>response_type: 表示授权类型 值固定为code</li><li>client_id</li><li>redirect_uri</li><li>scope</li><li>state</li></ul><pre><code>GET /authorize?response_type=code&amp;client_id=s6BhdRkqt3&amp;state=xyz        &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1Host: server.example.com</code></pre><p>C步骤，服务器回应客户端的URI，包含以下参数</p><ul><li>code: 授权码 一般设为10分钟的有效时间 且只能使用一次</li><li>state: 如果客户端的请求中包含这个参数，认证服务器的回应也需要包含同样的</li></ul><pre><code>HTTP/1.1 302 FoundLocation: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA          &amp;state=xyz</code></pre><p>D步骤，客户端向认证服务器申请令牌的HTTP请求当中，包含如下参数：</p><ul><li>grant_type: 使用的授权模式 authrization_code</li><li>code: 上一步获得的授权码</li><li>redirect_uri: 重定向URI，与A中参数需一致</li><li>client_id: 表示客户端ID</li></ul><pre><code>POST /token HTTP/1.1Host: server.example.comAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA&amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb</code></pre><p>E步骤: 认证服务器发送的HTTP回复，包含以下参数</p><ul><li>access_token: 表示访问令牌</li><li>token_type: 令牌类型</li><li>expires_in: 表示过期时间</li><li>refresh_token: 表示更新令牌，用来获取下一次的访问令牌</li><li>scope: 权限范围</li></ul><pre><code> HTTP/1.1 200 OK Content-Type: application/json;charset=UTF-8 Cache-Control: no-store Pragma: no-cache {   &quot;access_token&quot;:&quot;2YotnFZFEjr1zCsicMWpAA&quot;,   &quot;token_type&quot;:&quot;example&quot;,   &quot;expires_in&quot;:3600,   &quot;refresh_token&quot;:&quot;tGzv3JOkF0XG5Qx2TlKWIA&quot;,   &quot;example_parameter&quot;:&quot;example_value&quot; }</code></pre><h2 id="3-2-简化模式"><a href="#3-2-简化模式" class="headerlink" title="3.2 简化模式"></a>3.2 简化模式</h2><p>不通过第三方的应用程序的服务器，直接在浏览器当中向认证服务器申请令牌，跳过授权码这个步骤。所有步骤在浏览器当中完成，令牌对访问者可见，且客户端不需要认证。</p><p><img src="https://i.loli.net/2020/02/01/6zt3Sjg4iMYoQn8.png" alt="fig3.png"></p><p>（A）客户端将用户导向认证服务器。</p><p>（B）用户决定是否给于客户端授权。</p><p>（C）假设用户给予授权，认证服务器将用户导向客户端指定的”重定向URI”，并在URI的Hash部分包含了访问令牌。</p><p>（D）浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。</p><p>（E）资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。</p><p>（F）浏览器执行上一步获得的脚本，提取出令牌。</p><p>（G）浏览器将令牌发给客户端。</p><p>A步骤，客户端发出HTTP请求，包含以下参数: </p><ul><li>response_type：表示授权类型，此处的值固定为”token”，必选项。</li><li>client_id：表示客户端的ID，必选项。</li><li>redirect_uri：表示重定向的URI，可选项。</li><li>scope：表示权限范围，可选项。</li><li>state：表示客户端的当前状态，可以指定任意值，认证服务器会原封不动地返回这个值</li></ul><pre><code>GET /authorize?response_type=token&amp;client_id=s6BhdRkqt3&amp;state=xyz    &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1Host: server.example.com</code></pre><p>C步骤，认证服务器回应客户端的URL，包含：</p><ul><li>access_token </li><li>token_type</li><li>expires_in</li><li>scope</li><li>state</li></ul><pre><code>HTTP/1.1 302 Found Location: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA           &amp;state=xyz&amp;token_type=example&amp;expires_in=3600</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html" target="_blank" rel="noopener">https://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> 认证授权 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP API认证与授权(六) - OAuth 1.0</title>
      <link href="/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E5%85%AD-OAuth-1-0/"/>
      <url>/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E5%85%AD-OAuth-1-0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><p>API认证协议，主要是为了做委托授权的。应用场景，比如用户想用第三方服务商来打印照片，访问其云存储，但是不想把用户名密码给这家第三方公司。</p><p>在这个模型当中，client可以代表资源的拥有者去做一些事情，也就是说，OAuth需要不仅能够确认证实资源拥有者得到授权认证，并且需要能够识别出提出请求的客户端的身份。</p><p>为了让客户端去访问资源：</p><ol><li>得到资源拥有者的许可 - 终端用户授权给客户端去访问服务器资源的流程 </li><li>去服务器访问资源 - 利用两个证书（用于识别客户端生成的请求和用于识别请求所代表的资源拥有者）来生成已认证的Http请求。</li></ol><p>三个角色</p><ul><li>User  照片所有者 - 用户</li><li>Consumer 第三方照片打印服务</li><li>Service Provider 照片存储服务</li></ul><p>协议的三个阶段</p><ul><li>Consumer 获取Request Token</li><li>Service Provider认证用户并且授权Consumer</li><li>Consumer获取Access Token调用API访问用户的照片</li></ul><p>整个授权流程： </p><ul><li>Consumer（第三方照片打印服务）需要先上Service Provider获得开发的 Consumer Key 和 Consumer Secret</li><li>当 User 访问 Consumer 时，Consumer 向 Service Provider 发起请求请求Request Token （需要对HTTP请求签名）</li><li>Service Provider 验明 Consumer 是注册过的第三方服务商后，返回 Request Token（oauth_token）和 Request Token Secret （oauth_token_secret）</li><li>Consumer 收到 Request Token 后，使用HTTP GET 请求把 User 切到 Service Provider 的认证页上（其中带上Request Token），让用户输入他的用户和口令。</li><li>Service Provider 认证 User 成功后，跳回 Consumer，并返回 Request Token （oauth_token）和 Verification Code（oauth_verifier）</li><li>接下来就是签名请求，用Request Token 和 Verification Code 换取 Access Token （oauth_token）和 Access Token Secret (oauth_token_secret)</li><li>最后使用Access Token访问用户授权访问的资源</li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://blog.csdn.net/turkeyzhou/article/details/7628399" target="_blank" rel="noopener">https://blog.csdn.net/turkeyzhou/article/details/7628399</a></li><li><a href="https://oauth.net/1/" target="_blank" rel="noopener">https://oauth.net/1/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> 认证授权 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP API认证与授权(五) - JWT</title>
      <link href="/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%BA%94-JWT/"/>
      <url>/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%BA%94-JWT/</url>
      
        <content type="html"><![CDATA[<h1 id="1-为什么选择JWT？"><a href="#1-为什么选择JWT？" class="headerlink" title="1. 为什么选择JWT？"></a>1. 为什么选择JWT？</h1><p>JWT也是一种Message Authentication Code的方法，选择使用JWT的好处是它可以将认证的逻辑交给第三方的服务器。而认证服务器和应用服务器之间也不需要有任何的直接连接。这样子做的好处就是应用服务器可以变成完全无状态的服务器了，不需要去存储token。</p><h1 id="2-步骤"><a href="#2-步骤" class="headerlink" title="2. 步骤"></a>2. 步骤</h1><ol><li>用户使用用户名和口令到认证服务器请求认证</li><li>认证服务器验证以后，以服务器端生成JWT Token</li></ol><ul><li>认证服务器生成一个Secret Key</li><li>对JWT Header和JWT Payload分别求Base64</li><li>用秘钥对JWT签名</li></ul><ol start="3"><li>将base64(header).base64(payload).signature作为JWT token返回客户端</li><li>客户端使用JWT Token向应用服务器发送相关的请求。这个JWT Token就像一个临时用户权证一样。</li></ol><p>当应用服务器收到请求之后：</p><ol><li>检查JWT Token, 确认签名正确</li><li>因为只有认证服务器有这个用户的Secret Key，所以应用服务器要将其传给认证服务器</li><li>认证服务器通过JWT Payload解出用户的抽象ID，然后通过抽象ID查到登录时生成的Secret Key，然后再检查签名</li><li>认证服务器检查通过后，应用服务就可以认为这是合法请求了</li></ol><p>我们可以看以，上面的这个过程，是在认证服务器上为用户动态生成 Secret Key的，应用服务在验签的时候，需要到认证服务器上去签，这个过程增加了一些网络调用，所以，JWT除了支持HMAC-SHA256的算法外，还支持RSA的非对称加密的算法。</p><p>使用RSA非对称算法，在认证服务器这边放一个私钥，在应用服务器那边放一个公钥，认证服务器使用私钥加密，应用服务器使用公钥解密，这样一来，就不需要应用服务器向认证服务器请求了，但是，RSA是一个很慢的算法，所以，虽然你省了网络调用，但是却费了CPU，尤其是Header和Payload比较长的时候。所以，一种比较好的玩法是，如果我们把header 和 payload简单地做SHA256，这会很快，然后，我们用RSA加密这个SHA256出来的字符串，这样一来，RSA算法就比较快了，而我们也做到了使用RSA签名的目的。</p><h1 id="3-技术细节"><a href="#3-技术细节" class="headerlink" title="3. 技术细节"></a>3. 技术细节</h1><h2 id="3-1-构成"><a href="#3-1-构成" class="headerlink" title="3.1 构成"></a>3.1 构成</h2><p>JWT有三部分组成：</p><ul><li>header</li><li>payload</li><li>signature</li></ul><h3 id="3-1-1-payload"><a href="#3-1-1-payload" class="headerlink" title="3.1.1 payload"></a>3.1.1 payload</h3><p>payload里可以包含任何信息的，没有给任何限制。值得注意的是token并没有进行编码，所以当token被拦截的时候，里面的信息是可以被看到的</p><h3 id="3-1-2-header"><a href="#3-1-2-header" class="headerlink" title="3.1.2 header"></a>3.1.2 header</h3><p>payload的内容在接收方是通过检查签名来进行验证的，而签名会有很多种。header里面就携带有不同签名的元数据(metadata).</p><h3 id="3-1-3-签名"><a href="#3-1-3-签名" class="headerlink" title="3.1.3 签名"></a>3.1.3 签名</h3><p>这一部分是一个Message Authentication Code, JWT的签名只有在获取了payload, header,还有被给予秘钥以后才可以生成。是三者的组合。</p><p>签名有很多种类，比如HS256，以及RS256. </p><h4 id="3-1-3-1-HS256"><a href="#3-1-3-1-HS256" class="headerlink" title="3.1.3.1 HS256"></a>3.1.3.1 HS256</h4><p>使用HS256， 我们会用到Header， payload以及密码， 然后我们将其组合起来做哈希。想要生成同样的哈希值，你必须保证三个信息你都有才可以的(header, payload, password)，否则不可能得到，而且也无法通过碰撞逐渐趋近结果，因为hs256可以保证哪怕仅仅改变了一个数字，最终出来的结果也会有将近一半是不一样的。</p><h4 id="3-1-3-1-RS256"><a href="#3-1-3-1-RS256" class="headerlink" title="3.1.3.1 RS256"></a>3.1.3.1 RS256</h4><p>使用RS256比使用HS256效率高很多，这是因为：</p><ol><li>HS256可以被暴力破解的，如果输入的秘钥很简单</li><li>其需要server和client端有提前沟通好的一样的密码。这就意味着如果我们要换密码，我们就要提前传输到每个网络节点当中供其使用。</li></ol><p>而使用RS256，我们仍要生成一个MAC码，目标仍然是创建一个数字签名来证明JWT是有效的。在这种签名当中，我们将会将创建token和验证token的能力分开。</p><p>实现这种目的的方式就是创建两个key而不是一个。</p><ul><li>一个私钥，只被认证服务器拥有，只被用来生成JWT</li><li>私钥只能用来生成，不能用来证明</li><li>公钥，用在应用服务器端，来认证JWT的</li><li>公钥不需要当成隐私。可以随意让人使用的</li></ul><p>使用RSA算法，RSA使用RSA keys。RSA算法可以用一个key来加密，另一个key来解密。但是RSA算法有个问题就是运行的比较慢。</p><p>这里采用的方法就是先把header和payload拿过来一起做一个hash，然后我们用私钥来对其进行加密，通过这种方式我们就能够得到RS256 的signature。</p><p>到了接收端，做的事情就是：</p><ol><li>拿到header和payload，然后用SHA-256做哈希，拿到真实数据</li><li>用公钥进行解码，并且拿到签名的signature</li><li>然后接收端比较两个哈希值，看是否相同</li></ol><h2 id="3-2-为什么使用JWT？-为了解决什么问题而创建？"><a href="#3-2-为什么使用JWT？-为了解决什么问题而创建？" class="headerlink" title="3.2 为什么使用JWT？ 为了解决什么问题而创建？"></a>3.2 为什么使用JWT？ 为了解决什么问题而创建？</h2><p>JWT使得认证服务器和应用服务器可以成为两个不同的服务器。这样的好处是使得应用服务器可以运行的更快，认证的功能都可以集中到认证服务器当中，然后再整个应用里面去复用。</p><h2 id="3-3-JWT-实例"><a href="#3-3-JWT-实例" class="headerlink" title="3.3 JWT 实例"></a>3.3 JWT 实例</h2><pre><code>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ</code></pre><p>分成了三个部分，第一部分是JWT Header:</p><pre><code>JWT Header: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9</code></pre><p>第二部分是JWT Payload:</p><pre><code>JWT Payload: eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9</code></pre><p>第三部分是JWT Signature:</p><pre><code>JWT Signature: TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ</code></pre><p>这里我们做了Base64编码，原因是各个电脑对于String有不同的处理方式，比如UTF-8, ISO 8859-1等等。使用Base64编码就可以解决这个问题了。</p><p>Base64和Base64url基本上是一样的，Base64url比起Base64，对在url中的展示做了一些优化。</p><h2 id="3-4-JWT的用户Session管理"><a href="#3-4-JWT的用户Session管理" class="headerlink" title="3.4 JWT的用户Session管理"></a>3.4 JWT的用户Session管理</h2><p>一般常用的payload有</p><ul><li><p>user identification </p></li><li><p>session expiration</p><p>  {</p><pre><code>  // 给出JWT的实体- 这里是我们的认证服务器  &quot;iss&quot;: &quot;Identifier of our Authentication Server&quot;,  // JWT的创建时间的时间戳  &quot;iat&quot;: 1504699136,   // 用户的id  &quot;sub&quot;: &quot;github|353454354354353453&quot;,  // token expiration  &quot;exp&quot;: 1504699256</code></pre><p>  }</p></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://blog.angular-university.io/angular-jwt/" target="_blank" rel="noopener">https://blog.angular-university.io/angular-jwt/</a></li><li><a href="https://coolshell.cn/articles/19395.html" target="_blank" rel="noopener">https://coolshell.cn/articles/19395.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> 认证授权 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP API认证与授权(四) - App Secret Key, HMAC</title>
      <link href="/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E5%9B%9B-App-Secret-Key-HMAC/"/>
      <url>/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E5%9B%9B-App-Secret-Key-HMAC/</url>
      
        <content type="html"><![CDATA[<h1 id="1-HMAC"><a href="#1-HMAC" class="headerlink" title="1. HMAC"></a>1. HMAC</h1><p>HMAC,指Hash based message authentication code。用哈希给消息来进行签名，因为我们怕消息在传递的过程中被修改，所以我们对消息进行一个MAC算法，得到一个摘要字串；接收方在收到了信息以后，会进行同样的运算，然后来比较这个MAC字符串。如果一致，则表示没有被修改过。</p><p><img src="https://i.loli.net/2020/02/01/8ewgJ24qbQYjT7I.png" alt="fig1.png"></p><h1 id="2-App-Id-amp-App-Secret-Key"><a href="#2-App-Id-amp-App-Secret-Key" class="headerlink" title="2. App Id &amp; App Secret Key"></a>2. App Id &amp; App Secret Key</h1><p>App ID和验证无关，只是用来区分，是谁来调用API的，就像我们每个人的身份证一样，只是用来标注不同的人，不是用来做身份认证的。与前面的不同之处是，这里，我们需要用App ID 来映射一个用于加密的密钥，这样一来，我们就可以在服务器端进行相关的管理，我们可以生成若干个密钥对（AppID, AppSecret），并可以有更细粒度的操作权限管理。</p><h2 id="2-1-S3-API-请求范例"><a href="#2-1-S3-API-请求范例" class="headerlink" title="2.1 S3 API 请求范例"></a>2.1 S3 API 请求范例</h2><ol><li>把HTTP的请求（方法、URI、查询字串、头、签名头，body）打个包叫 CanonicalRequest，作个SHA-256的签名，然后再做一个base16的编码</li><li>把上面的这个签名和签名算法 AWS4-HMAC-SHA256、时间戳、Scop，再打一个包，叫 StringToSign。</li><li>准备签名，用 AWSSecretAccessKey来对日期签一个 DataKey，再用 DataKey 对要操作的Region签一个 DataRegionKey ，再对相关的服务签一个DataRegionServiceKey ，最后得到 SigningKey.</li><li>用第三步的 SigningKey来对第二步的 StringToSign 签名。</li></ol><p><img src="https://i.loli.net/2020/02/01/5I6qCO1NBF9aQm3.png" alt="fig2.png"></p><p>这种认证的方式好处在于，AppID和AppSecretKey，是由服务器的系统开出的，所以，是可以被管理的，AWS的IAM就是相关的管理，其管理了用户、权限和其对应的AppID和AppSecretKey。但是不好的地方在于，这个东西没有标准 ，所以，各家的实现很不一致。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/HMAC" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/HMAC</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> 认证授权 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP API认证与授权(三) - Digest Access</title>
      <link href="/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%B8%89-Digest-Access/"/>
      <url>/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%B8%89-Digest-Access/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><p>HTTP 摘要认证.这种方式可以在发送各种敏感信息之前先确认用户的身份。其会先给用户名密码加一个哈希函数；而HTTP basic方式与之相对的是直接使用了简单可逆的Base64编码技术而不是任何加密技术，使得整个过程非常不安全，除非是在HTTPS的条件下。 (Transport Layer Security)</p><p>划重点: </p><ul><li>MD5 加密哈希</li><li>使用nonce(随机数) 避免重复攻击</li></ul><h1 id="2-流程"><a href="#2-流程" class="headerlink" title="2. 流程"></a>2. 流程</h1><ul><li>请求方将用户名口令和域做一个MD5哈希<code>MD5(username:realm:password)</code> 然后发给服务器</li><li>问题是用户名口令不怎么变的话那这个字符串也会不改变</li><li>因此在认证过程当中加入了nonce和qop</li></ul><h2 id="2-1-Client发起请求-无认证"><a href="#2-1-Client发起请求-无认证" class="headerlink" title="2.1 Client发起请求(无认证)"></a>2.1 Client发起请求(无认证)</h2><p>发生在Client直接进入一个需要认证的网页，此时并没有携带用户名和密码的信息</p><pre><code>GET /dir/index.html HTTP/1.0Host: localhost</code></pre><h2 id="2-2-Server返回错误信息401"><a href="#2-2-Server返回错误信息401" class="headerlink" title="2.2 Server返回错误信息401"></a>2.2 Server返回错误信息401</h2><p>401代表的是未认证，服务器会返回401信息，并且在Response Header里携带<code>WWW-Authenticate</code>域,含有认证的realm的信息，以及一个随机生成的nonce</p><pre><code>HTTP/1.0 401 UnauthorizedServer: HTTPd/0.9Date: Sun, 10 Apr 2014 20:26:47 GMTWWW-Authenticate: Digest realm=&quot;testrealm@host.com&quot;,                        qop=&quot;auth,auth-int&quot;,                        nonce=&quot;dcd98b7102dd2f0e8b11d0f600bfb0c093&quot;,                        opaque=&quot;5ccc069c403ebaf9f0171e9517f40e41&quot;Content-Type: text/htmlContent-Length: 153&lt;!DOCTYPE html&gt;&lt;html&gt;  &lt;head&gt;    &lt;meta charset=&quot;UTF-8&quot; /&gt;    &lt;title&gt;Error&lt;/title&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;h1&gt;401 Unauthorized.&lt;/h1&gt;  &lt;/body&gt;&lt;/html&gt;</code></pre><h2 id="2-3-Client输入信息，发送新请求"><a href="#2-3-Client输入信息，发送新请求" class="headerlink" title="2.3 Client输入信息，发送新请求"></a>2.3 Client输入信息，发送新请求</h2><pre><code>GET /dir/index.html HTTP/1.0Host: localhostAuthorization: Digest username=&quot;Mufasa&quot;,                     realm=&quot;testrealm@host.com&quot;,                     nonce=&quot;dcd98b7102dd2f0e8b11d0f600bfb0c093&quot;,                     uri=&quot;/dir/index.html&quot;,                     qop=auth,                     nc=00000001,                     cnonce=&quot;0a4f113b&quot;,                     response=&quot;6629fae49393a05397450978507c4ef1&quot;,                     opaque=&quot;5ccc069c403ebaf9f0171e9517f40e41&quot;</code></pre><p>这里的计算方式如下:</p><pre><code>HA1 = MD5(username:realm:password)HA2 = MD5(method:digestURI)// 这一步可以有更多的值一起做hash，比如 server nonce, request counter, client nonce, qop (quality of protection code)response = MD5(HA1:nonce:HA2)</code></pre><p>值得注意的是nonce需要隔一段时间就失效，request counter要累加，以此尽量使其更加安全</p><h2 id="2-4-Server返回认证成功的信息"><a href="#2-4-Server返回认证成功的信息" class="headerlink" title="2.4 Server返回认证成功的信息"></a>2.4 Server返回认证成功的信息</h2><pre><code>HTTP/1.0 200 OKServer: HTTPd/0.9Date: Sun, 10 Apr 2005 20:27:03 GMTContent-Type: text/htmlContent-Length: 7984</code></pre><h1 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h1><p>摘要认证这个方式会比之前的方式要好一些，因为没有在网上传递用户的密码，而只是把密码的MD5传送过去，相对会比较安全，而且，其并不需要是否TLS/SSL的安全链接。但是，别看这个算法这么复杂，最后你可以发现，整个过程其实关键是用户的password，这个password如果不够得杂，其实是可以被暴力破解的，而且，整个过程是非常容易受到中间人攻击——比如一个中间人告诉客户端需要一个。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/Digest_access_authentication" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Digest_access_authentication</a></li><li><a href="https://tools.ietf.org/html/rfc2617" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc2617</a></li><li><a href="https://tools.ietf.org/html/rfc2069" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc2069</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> 认证授权 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP API认证与授权(二) - HTTP Basic</title>
      <link href="/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%BA%8C-HTTP-Basic/"/>
      <url>/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%BA%8C-HTTP-Basic/</url>
      
        <content type="html"><![CDATA[<h1 id="1-HTTP-Basic-Intro"><a href="#1-HTTP-Basic-Intro" class="headerlink" title="1. HTTP Basic Intro"></a>1. HTTP Basic Intro</h1><p>传统的API认证技术，使用username和password来进行登录。</p><p>整个流程是：</p><ul><li>用户发送一个不带认证信息的请求</li><li>服务器返回401(unauthorized)状态，然后会在header里面包含一个<code>WWW-authenticate</code>域</li><li>用户如果想认证自己，就需要发一个携带有认证请求header的请求，其中包含了credentials的信息。</li><li>通常会让用户输入密码，然后将这些信息放到Authorization的header当中去</li></ul><p><img src="https://i.loli.net/2020/02/01/NE6ihK9GQpjrw7P.png" alt="fig1.png"></p><p>在上述的整个流程当中，因为相当于明文传输了，所以这整个过程必须发生在HTTPS(TLS)连接当中。</p><h1 id="2-技术原理"><a href="#2-技术原理" class="headerlink" title="2.技术原理"></a>2.技术原理</h1><ul><li>进行Base64编码<ul><li>Base64编码是为了处理特殊字符，方便在不同平台用不同方式进行传递的，其编码方式是可逆的，即可以很顺畅地被破解掉。 </li></ul></li><li>将编码后的字段放到HTTP头的Authorization字段中，发到服务端</li><li>服务端进行认证，成功则返回200；失败则返回401报错</li></ul><p>使用Base64是为了消除特殊字符带来的影响，这种传递方式最大的问题是将用户名和口令放到了网络上进行传递，因此一般需要配合TLS/ SSL的安全加密来使用。这种同时将用户名和密码进行明文传输的协议并不是很好，尽管有HTTPS作为安全保护，但还是很有风险的。 </p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://en.wikipedia.org/wiki/Basic_access_authentication" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Basic_access_authentication</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Authentication" target="_blank" rel="noopener">https://developer.mozilla.org/en-US/docs/Web/HTTP/Authentication</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> 认证授权 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP API认证与授权(一) - general</title>
      <link href="/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%B8%80-general/"/>
      <url>/HTTP-API%E8%AE%A4%E8%AF%81%E4%B8%8E%E6%8E%88%E6%9D%83-%E4%B8%80-general/</url>
      
        <content type="html"><![CDATA[<p>HTTP本身是无状态的，但我们常常需要检查用户的登录状态。一般来说，用户登录成功之后，服务器会发一个登录凭证(Token)。在计算机的世界当中，这个Token的相关数据会放到两个地方，一个在用户端，以Cookie的方式，另一个是放在服务器端，以Session的方式。</p><p>现实世界中验证登录会更为复杂一些，因为除了用户访问，还有用户委托的第三方的应用，还有企业之间的调用。</p><p>很多很有意思的问题： </p><ul><li>认证与授权各自指的是什么？ </li><li>在我们没有TLS/ SSL的时候我们是如何实现登录验证，并且对在网络中传递的信息进行加密的呢？ </li><li>HTTPS给整个认证与授权的过程带来了怎样的改变？ </li><li>我们常看到的通过微信/ google/ facebook/ amazon登录是如何实现的？<br>这一系列的博客会依次逐个解决上面描述的问题，inspired by <a href="https://coolshell.cn/articles/19395.html" target="_blank" rel="noopener">CoolShell-HTTP API 认证授权术</a>. 是对这篇博客的针对自己现有认知水平（啥都不懂）的有效扩充，希望通过这一系列的整理彻底搞懂整个API认证与授权的机制，敏感信息在client和server之间的传递。</li></ul><p>本系列的博客会大致上分为6部分，分别为：</p><ul><li>HTTP Basic </li><li>Digest Access</li><li>App Secret Key + HMAC</li><li>JWT</li><li>OAuth 1.0</li><li>OAuth 2.0 </li></ul><p>希望能对大家有所裨益。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://coolshell.cn/articles/19395.html" target="_blank" rel="noopener">https://coolshell.cn/articles/19395.html</a></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> 认证授权 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>网络知识必知必会</title>
      <link href="/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"/>
      <url>/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/</url>
      
        <content type="html"><![CDATA[<p>这里希望将大部分网络知识做个总结，redirect到各篇博文当中去。</p><p>首先当我们谈及整个网络的时候，我们讨论的到底是什么呢？ 我想大家想要了解网络知识往往开始于遇到Server, Client端的交互问题，遇到Tomcat, Socket编程这类东西。关于如何了解网络学习网络知识，势必需要先有个宏观的view，而后再分到各个部分去了解更多的细节。整个体系应该就是这样慢慢建立起来的，这里做个索引，带一些我认为最最关键的知识点们。</p><h1 id="1-网络层级模型"><a href="#1-网络层级模型" class="headerlink" title="1. 网络层级模型"></a>1. 网络层级模型</h1><ul><li><a href="https://llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%BA%8C-%E7%89%A9%E7%90%86%E5%B1%82/" target="_blank" rel="noopener">物理层</a><ul><li>LAN, WAN </li></ul></li><li><a href="https://llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%B8%89-%E9%93%BE%E8%B7%AF%E5%B1%82/" target="_blank" rel="noopener">链路层</a><ul><li>MAC - Medium Access Control  </li><li>ARP协议 - 已知目标IP地址，寻求MAC地址 </li><li>交换机 - 带有记忆功能的集线器 - 记录MAC地址<ul><li>转发表 - 过期时间 </li></ul></li></ul></li><li><a href="https://llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%9B%9B-%E7%BD%91%E7%BB%9C%E5%B1%82/" target="_blank" rel="noopener">网络层</a><ul><li>IP协议<ul><li>CIDR无类型域间选路   <ul><li>网络号 + 主机号 </li></ul></li><li>DHCP动态主机配置协议</li></ul></li><li>ICMP协议 Inernet Control Message Protocol<ul><li>互联网控制报文协议</li></ul></li><li>跨网关访问 </li></ul></li><li><a href="https://llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E4%BA%94-%E4%BC%A0%E8%BE%93%E5%B1%82/" target="_blank" rel="noopener">传输层</a><ul><li>UDP协议</li><li>TCP协议</li><li>套接字Socket</li></ul></li><li><a href="https://llchen60.com/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE-%E5%85%AD-%E5%BA%94%E7%94%A8%E5%B1%82/" target="_blank" rel="noopener">应用层</a><ul><li>HTTP协议 </li><li>HTTPS</li><li>QUIC</li></ul></li></ul><h1 id="2-网络相关的应用"><a href="#2-网络相关的应用" class="headerlink" title="2. 网络相关的应用"></a>2. 网络相关的应用</h1><ul><li>流媒体协议</li><li>数据中心</li><li>VPN</li><li>移动网络</li><li>云</li><li>RPC SOAP RESTFul</li></ul>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>正则表达式</title>
      <link href="/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
      <url>/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><p>Composed of simple characters, or a combination of simple and special characters. </p><h1 id="2-Using-simple-patterns"><a href="#2-Using-simple-patterns" class="headerlink" title="2. Using simple patterns"></a>2. Using simple patterns</h1><p>constructed of characters for which you want to find a <strong><em>direct match</em></strong>. For example, the pattern /abc/ matches character combinations in strings only when exactly the characters ‘abc’ occur together and in that order. Such a match would succeed in the strings “Hi, do you know your abc’s?” and “The latest airplane designs evolved from slabcraft.” In both cases the match is with the substring ‘abc’. There is no match in the string ‘Grab crab’ because while it contains the substring ‘ab c’, it does not contain the exact substring ‘abc’.</p><h1 id="3-Using-special-characters"><a href="#3-Using-special-characters" class="headerlink" title="3. Using special characters"></a>3. Using special characters</h1><p>Whne your search need more than a direct match. Now detailing special characters in regular expressions: </p><h2 id="3-1-–-gt-Indicate-next-character-is-special"><a href="#3-1-–-gt-Indicate-next-character-is-special" class="headerlink" title="3.1 \  –&gt; Indicate next character is special"></a>3.1 \  –&gt; Indicate next character is special</h2><ol><li>A backslash that precedes a non-special character indicates that <strong>the next character is special</strong> and <strong>is not to be interpreted literally</strong>.</li></ol><h2 id="3-2-–-gt-Matches-beginning-of-input"><a href="#3-2-–-gt-Matches-beginning-of-input" class="headerlink" title="3.2 ^  –&gt; Matches beginning of input"></a>3.2 ^  –&gt; Matches beginning of input</h2><p>For example, <code>/^A/</code> does not match the ‘A’ in “an A”, but does match the ‘A’ in “An E”.</p><h2 id="3-3-–-gt-matches-end-of-input"><a href="#3-3-–-gt-matches-end-of-input" class="headerlink" title="3.3 $ –&gt; matches end of input"></a>3.3 $ –&gt; matches end of input</h2><p>For example, <code>/t$/</code> does not match the ‘t’ in “eater”, but does match it in “eat”.</p><h2 id="3-4-–-gt-matches-the-preceding-expression-0-or-more-times-Equal-to-0"><a href="#3-4-–-gt-matches-the-preceding-expression-0-or-more-times-Equal-to-0" class="headerlink" title="3.4 * –&gt; matches the preceding expression 0 or more times. Equal to {0,}"></a>3.4 * –&gt; matches the preceding expression 0 or more times. Equal to {0,}</h2><p>For example, /bo*/ matches ‘boooo’ in “A ghost booooed” and ‘b’ in “A bird warbled” but nothing in “A goat grunted”.</p><h2 id="3-5-–-gt-matches-the-preceding-expression-1-or-more-times-Equals-t0-1"><a href="#3-5-–-gt-matches-the-preceding-expression-1-or-more-times-Equals-t0-1" class="headerlink" title="3.5 + –&gt; matches the preceding expression 1 or more times. Equals t0 {1,}"></a>3.5 + –&gt; matches the preceding expression 1 or more times. Equals t0 {1,}</h2><p>For example, <code>/a+/</code> matches the ‘a’ in “candy” and all the a’s in “caaaaaaandy”, but nothing in “cndy”.</p><h2 id="3-6-–-gt-matches-the-preceding-expression-0-or-1-time-Equivalent-to-0-1"><a href="#3-6-–-gt-matches-the-preceding-expression-0-or-1-time-Equivalent-to-0-1" class="headerlink" title="3.6 ? –&gt; matches the preceding expression 0 or 1 time. Equivalent to {0,1}"></a>3.6 ? –&gt; matches the preceding expression 0 or 1 time. Equivalent to {0,1}</h2><p>For example, /e?le?/ matches the ‘el’ in “angel” and the ‘le’ in “angle” and also the ‘l’ in “oslo”.</p><p>If used immediately after any of the quantifiers <em>, +, ?, or {}, makes the quantifier *</em>non-greedy** (matching the fewest possible characters), as opposed to the default, which is greedy (matching as many characters as possible). For example, applying /\d+/ to “123abc” matches “123”. But applying /\d+?/ to that same string matches only the “1”.</p><h2 id="3-7-–-gt-matches-any-single-character-except-the-newline-character"><a href="#3-7-–-gt-matches-any-single-character-except-the-newline-character" class="headerlink" title="3.7 . –&gt; matches any single character except the newline character"></a>3.7 . –&gt; matches any single character except the newline character</h2><p>For example, /.n/ matches ‘an’ and ‘on’ in “nay, an apple is on the tree”, but not ‘nay’.</p><h2 id="3-8-x-–-gt-Matches-‘x’-and-remembers-the-match-as-the-following-example-shows"><a href="#3-8-x-–-gt-Matches-‘x’-and-remembers-the-match-as-the-following-example-shows" class="headerlink" title="3.8 (x) –&gt; Matches ‘x’ and remembers the match, as the following example shows."></a>3.8 (x) –&gt; Matches ‘x’ and remembers the match, as the following example shows.</h2><p>The parentheses are called capturing parentheses. </p><p>The ‘(foo)’ and ‘(bar)’ in the pattern /(foo) (bar) \1 \2/ match and remember the first two words in the string “foo bar foo bar”. The \1 and \2  denote the first and second parenthesized substring matches - foo and bar, matching the string’s last two words. Note that \1, \2, …, \n are used in the matching part of the regex, for more information, see \n below. In the replacement part of a regex the syntax $1, $2, …, $n must be used, e.g.: ‘bar foo’.replace(/(…) (…)/, ‘$2 $1’).  $&amp; means the whole matched string.</p><h2 id="3-9-x-–-gt-Matches-‘x’-but-does-not-remember-the-match"><a href="#3-9-x-–-gt-Matches-‘x’-but-does-not-remember-the-match" class="headerlink" title="!!! 3.9 (?:x) –&gt; Matches ‘x’ but does not remember the match"></a>!!! 3.9 (?:x) –&gt; Matches ‘x’ but does not remember the match</h2><p>The parentheses are called non-capturing parentheses, and let you define subexpressions for regular expression operators to work with. </p><p>Matches ‘x’ but does not remember the match. The parentheses are called non-capturing parentheses, and let you define subexpressions for regular expression operators to work with. Consider the sample expression /(?:foo){1,2}/. If the expression was /foo{1,2}/, the {1,2} characters would apply only to the last ‘o’ in ‘foo’. With the non-capturing parentheses, the {1,2} applies to the entire word ‘foo’.</p><h2 id="3-10-x-y-–-gt-matches-‘x’-only-id-‘x’-is-followed-by-‘y’"><a href="#3-10-x-y-–-gt-matches-‘x’-only-id-‘x’-is-followed-by-‘y’" class="headerlink" title="3.10 x(?=y) –&gt; matches ‘x’ only id ‘x’ is followed by ‘y’"></a>3.10 x(?=y) –&gt; matches ‘x’ only id ‘x’ is followed by ‘y’</h2><p>For example, /Jack(?=Sprat)/ matches ‘Jack’ only if it is followed by ‘Sprat’. /Jack(?=Sprat|Frost)/ matches ‘Jack’ only if it is followed by ‘Sprat’ or ‘Frost’. However, neither ‘Sprat’ nor ‘Frost’ is part of the match results.</p><h2 id="3-11-x-y-–-gt-matches-‘x’-only-if-‘x’-is-not-followed-by-‘y’"><a href="#3-11-x-y-–-gt-matches-‘x’-only-if-‘x’-is-not-followed-by-‘y’" class="headerlink" title="3.11  x(?!y) –&gt; matches ‘x’ only if ‘x’ is not followed by ‘y’"></a>3.11  x(?!y) –&gt; matches ‘x’ only if ‘x’ is not followed by ‘y’</h2><p>For example, <code>/\d+(?!\.)/</code> matches a number only if it is not followed by a decimal point. The regular expression <code>/\d+(?!\.)/.exec(&quot;3.141&quot;)</code> matches ‘141’ but not ‘3.141’.</p><h2 id="3-12-x-y-–-gt-matches-x-or-y-if-there-is-no-match-for-‘x’"><a href="#3-12-x-y-–-gt-matches-x-or-y-if-there-is-no-match-for-‘x’" class="headerlink" title="3.12 x|y –&gt; matches x or y(if there is no match for ‘x’)"></a>3.12 x|y –&gt; matches x or y(if there is no match for ‘x’)</h2><p>For example, /green|red/ matches ‘green’ in “green apple” and ‘red’ in “red apple.” The order of ‘x’ and ‘y’ matters. For example a<em>|b matches the empty string in “b”, but b|a</em> matches “b” in the same string.</p><h2 id="3-13-n-–-gt-matches-exactly-n-occurences-of-the-preceding-expression"><a href="#3-13-n-–-gt-matches-exactly-n-occurences-of-the-preceding-expression" class="headerlink" title="3.13 {n} –&gt; matches exactly n occurences of the preceding expression."></a>3.13 {n} –&gt; matches exactly n occurences of the preceding expression.</h2><p>For example, /a{2}/ doesn’t match the ‘a’ in “candy,” but it does match all of the a’s in “caandy,” and the first two a’s in “caaandy.”</p><h2 id="3-14-n-–-gt-matches-at-least-n-occurrences-of-the-preceding-expression"><a href="#3-14-n-–-gt-matches-at-least-n-occurrences-of-the-preceding-expression" class="headerlink" title="3.14 {n,} –&gt; matches at least n occurrences of the preceding expression."></a>3.14 {n,} –&gt; matches at least n occurrences of the preceding expression.</h2><p>For example, /a{2,}/ will match “aa”, “aaaa” and “aaaaa” but not “a”</p><h2 id="3-15-n-m-–-gt-matches-at-least-n-and-at-more-m-occurrences-of-the-preceding-expression"><a href="#3-15-n-m-–-gt-matches-at-least-n-and-at-more-m-occurrences-of-the-preceding-expression" class="headerlink" title="3.15 {n,m} –&gt; matches at least n and at more m occurrences of the preceding expression."></a>3.15 {n,m} –&gt; matches at least n and at more m occurrences of the preceding expression.</h2><p>For example, /a{1,3}/ matches nothing in “cndy”, the ‘a’ in “candy,” the first two a’s in “caandy,” and the first three a’s in “caaaaaaandy”. Notice that when matching “caaaaaaandy”, the match is “aaa”, even though the original string had more a’s in it.</p><h2 id="3-16-xyz-–-gt-matches-any-one-of-the-characters-in-the-brackets"><a href="#3-16-xyz-–-gt-matches-any-one-of-the-characters-in-the-brackets" class="headerlink" title="3.16 [xyz] –&gt; matches any one of the characters in the brackets"></a>3.16 [xyz] –&gt; matches any one of the characters in the brackets</h2><p>The pattern [a-d], which performs the same match as [abcd], matches the ‘b’ in “brisket” and the ‘c’ in “city”. The patterns /[a-z.]+/ and /[\w.]+/ match the entire string “test.i.ng”.</p><h2 id="3-17-xyz-–-gt-matches-anything-that-is-not-enclosed-in-the-brackets"><a href="#3-17-xyz-–-gt-matches-anything-that-is-not-enclosed-in-the-brackets" class="headerlink" title="3.17 [^xyz] –&gt; matches anything that is not enclosed in the brackets"></a>3.17 [^xyz] –&gt; matches anything that is not enclosed in the brackets</h2><p>For example, [^abc] is the same as [^a-c]. They initially match ‘r’ in “brisket” and ‘h’ in “chop.”</p><h2 id="3-18-b-–-gt-matches-a-backspace"><a href="#3-18-b-–-gt-matches-a-backspace" class="headerlink" title="3.18 [\b] –&gt; matches a backspace"></a>3.18 [\b] –&gt; matches a backspace</h2><p>You need to use square brackets if you want to match a literal backspace character. (Not to be confused with \b.)</p><h2 id="3-19-b-–-gt-matches-a-word-boundary"><a href="#3-19-b-–-gt-matches-a-word-boundary" class="headerlink" title="3.19 \b –&gt; matches a word boundary"></a>3.19 \b –&gt; matches a word boundary</h2><p><strong><em>A word boundary matches the position between a word character followed by a non-word character</em></strong></p><p>Examples using the input string “moon”:<br>/\bm/ matches, because the <code>\b</code> is at the beginning of the string;<br>the ‘\b’ in /oo\b/ does not match, because the ‘\b’ is both preceded and followed by word characters;<br>the ‘\b’ in /oon\b/ matches, because it appears at the end of the string;<br>the ‘\b\ in /\w\b\w/ will never match anything, because it is both preceded and followed by a word character..</p><h2 id="3-20-B-–-gt-matches-a-non-word-boundary"><a href="#3-20-B-–-gt-matches-a-non-word-boundary" class="headerlink" title="3.20 \B –&gt; matches a non-word boundary"></a>3.20 \B –&gt; matches a non-word boundary</h2><p>matches the following case: </p><ul><li>Before the first character of the string.</li><li>After the last character of the string,.</li><li>Between two word characters</li><li>Between two non-word characters</li><li>The empty string</li></ul><h2 id="3-21-d-–-gt-matches-a-digit-chracter"><a href="#3-21-d-–-gt-matches-a-digit-chracter" class="headerlink" title="3.21 \d –&gt; matches a digit chracter"></a>3.21 \d –&gt; matches a digit chracter</h2><p>Equal to [0-9]</p><p>For example, /\d/ or /[0-9]/ matches ‘2’ in “B2 is the suite number.”</p><h2 id="3-22-D-–-gt-matches-a-non-digit-character"><a href="#3-22-D-–-gt-matches-a-non-digit-character" class="headerlink" title="3.22 \D –&gt; matches a non digit character"></a>3.22 \D –&gt; matches a non digit character</h2><p>Equivalent to [^0-9].</p><p>For example, /\D/ or /[^0-9]/ matches ‘B’ in “B2 is the suite number.”</p><h2 id="3-23-s-–-gt-matches-a-white-space-chracter"><a href="#3-23-s-–-gt-matches-a-white-space-chracter" class="headerlink" title="3.23 \s –&gt; matches a white space chracter"></a>3.23 \s –&gt; matches a white space chracter</h2><p>can be space, tab, form feed, line feed </p><h2 id="3-24-S-–-gt-matches-a-character-other-than-white-space"><a href="#3-24-S-–-gt-matches-a-character-other-than-white-space" class="headerlink" title="3.24 \S –&gt; matches a character other than white space"></a>3.24 \S –&gt; matches a character other than white space</h2><h2 id="3-25-w-–-gt-matches-any-apphanumeric-character-including-the-underscore"><a href="#3-25-w-–-gt-matches-any-apphanumeric-character-including-the-underscore" class="headerlink" title="3.25 \w –&gt; matches any apphanumeric character including the underscore"></a>3.25 \w –&gt; matches any apphanumeric character including the underscore</h2><p>Equivalent to <code>[A-Za-z0-9_]</code></p><p>For example, /\w/ matches ‘a’ in “apple,” ‘5’ in “$5.28,” and ‘3’ in “3D.”</p><h2 id="3-26-W-matches-any-non-word-character"><a href="#3-26-W-matches-any-non-word-character" class="headerlink" title="3.26 \W matches any non word character"></a>3.26 \W matches any non word character</h2><p>Equivalent to [^A-Za-z0-9_].</p><p>For example, /\W/ or /[^A-Za-z0-9_]/ matches ‘%’ in “50%.”</p><h2 id="3-27-n-–-gt-Where-n-is-a-positive-integer-a-back-reference-to-the-last-substring-matching-the-n-parenthetical-in-the-regular-expression-counting-left-parentheses"><a href="#3-27-n-–-gt-Where-n-is-a-positive-integer-a-back-reference-to-the-last-substring-matching-the-n-parenthetical-in-the-regular-expression-counting-left-parentheses" class="headerlink" title="3.27 \n –&gt; Where n is a positive integer, a back reference to the last substring matching the n parenthetical in the regular expression (counting left parentheses)."></a>3.27 \n –&gt; Where n is a positive integer, a back reference to the last substring matching the n parenthetical in the regular expression (counting left parentheses).</h2><p>For example, /apple(,)\sorange\1/ matches ‘apple, orange,’ in “apple, orange, cherry, peach.”</p><h1 id="4-Rethink-for-some-cool-things"><a href="#4-Rethink-for-some-cool-things" class="headerlink" title="4. Rethink for some cool things"></a>4. Rethink for some cool things</h1><h2 id="4-1-n"><a href="#4-1-n" class="headerlink" title="4.1 \n"></a>4.1 \n</h2><p>选择器<br>(a|b)\1  —&gt; aa or bb</p><p>(1|2)(3|4)\1\2 –&gt; 1313  or 1414 or 2323  or 2424 </p><h2 id="4-2-x"><a href="#4-2-x" class="headerlink" title="4.2 (x)"></a>4.2 (x)</h2><p>给分组用的，然后用$0, $1, $2 来进行分别的表示</p><h1 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h1><p>1.<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions" target="_blank" rel="noopener">Regular Expressions</a></p><p>2.<a href="https://juejin.im/post/5b5db5b8e51d4519155720d2" target="_blank" rel="noopener">掘金正则总结</a></p><p>3.<a href="https://stackoverflow.com/questions/8624345/whats-the-meaning-of-a-number-after-a-backslash-in-a-regular-expression" target="_blank" rel="noopener">Stackoverflow: what’s the meaning of a number after a backslash in a regular expression?</a></p>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> Regex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Scaling webapps</title>
      <link href="/Scaling-webapps/"/>
      <url>/Scaling-webapps/</url>
      
        <content type="html"><![CDATA[<h1 id="1-How-scaling-works"><a href="#1-How-scaling-works" class="headerlink" title="1. How scaling works"></a>1. How scaling works</h1><h2 id="1-1-Vertical-scaling"><a href="#1-1-Vertical-scaling" class="headerlink" title="1.1 Vertical scaling"></a>1.1 Vertical scaling</h2><p>Run same things on a more powerful computer</p><h2 id="1-2-Horizontal-scaling"><a href="#1-2-Horizontal-scaling" class="headerlink" title="1.2 Horizontal scaling"></a>1.2 Horizontal scaling</h2><p>Means run many processes in parallel. </p><p>Nowadays, mostly we use horizontal scaling, since every computer internally have multi processors, we could do parallel programming to make whole thing work faster by nature.</p><h1 id="2-Scaling-process"><a href="#2-Scaling-process" class="headerlink" title="2. Scaling process"></a>2. Scaling process</h1><h2 id="2-1-Initialization-single-server-and-database"><a href="#2-1-Initialization-single-server-and-database" class="headerlink" title="2.1 Initialization: single server and database"></a>2.1 Initialization: single server and database</h2><p><img src="https://i.loli.net/2020/01/31/klA2HgITCiwtRPc.png" alt="fig1.png"></p><h2 id="2-2-Reverse-proxy"><a href="#2-2-Reverse-proxy" class="headerlink" title="2.2 Reverse proxy"></a>2.2 Reverse proxy</h2><p><img src="https://i.loli.net/2020/01/31/CgBvyKAW938H1Un.png" alt="fig2.png"></p><ul><li>Check if guests are allowed to enter </li><li>A proxy is a process that receives and forwards requests </li><li>Reverse means reqeust comes from teh internet and needs to be routed to our server </li></ul><p>Reverse proxy does following tasks: </p><ul><li>health check<ul><li>make sure actual server is still up and running </li></ul></li><li>routing <ul><li>forward a request to the right endpoint </li></ul></li><li>authentication <ul><li>make sure that a user is actually permitted to access the server </li></ul></li><li>firewall<ul><li>ensure users only have access to the parts they are allowed to use </li></ul></li></ul><h2 id="2-3-Load-balancer"><a href="#2-3-Load-balancer" class="headerlink" title="2.3 Load balancer"></a>2.3 Load balancer</h2><p><img src="https://i.loli.net/2020/01/31/YR6kcGwTFC8JQf3.png" alt="fig3.png"></p><p>Most reverse proxy can also act as load balancers. Load balancer’s job is to split incoming requests among those servers</p><h2 id="2-4-Grow-database"><a href="#2-4-Grow-database" class="headerlink" title="2.4 Grow database"></a>2.4 Grow database</h2><p><img src="https://i.loli.net/2020/01/31/LVqBUhFscRAgt9w.png" alt="fig4.png"></p><ul><li>Scaling database needs to deal with consistency </li><li>Master - slace setup or write with read-replicas <ul><li>one part is exclusively responsible for receiving data and storing it </li><li>all other parts are responsible for retrieving the stored data </li></ul></li></ul><h2 id="2-5-Microservices"><a href="#2-5-Microservices" class="headerlink" title="2.5 Microservices"></a>2.5 Microservices</h2><p><img src="https://i.loli.net/2020/01/31/Qj5ibmHAzLSWeqJ.png" alt="fig5.png"></p><ul><li><p>why we need microservices? </p><ul><li>different part use server to different extends </li><li>development - might have more overlaps in singe service </li></ul></li><li><p>break server down into functional units and deploy them as individual, inter connected mini servers </p></li></ul><h2 id="2-6-Caching-amp-Content-Delivery-Networks"><a href="#2-6-Caching-amp-Content-Delivery-Networks" class="headerlink" title="2.6 Caching &amp; Content Delivery Networks"></a>2.6 Caching &amp; Content Delivery Networks</h2><p><img src="https://i.loli.net/2020/01/31/NRO6oguPe8JHMWb.png" alt="fig6.png"></p><ul><li>Large portion of our web app consists of static assets - almost never change <ul><li>use cache to speed it up </li></ul></li></ul><h2 id="2-7-Message-Queues"><a href="#2-7-Message-Queues" class="headerlink" title="2.7 Message Queues"></a>2.7 Message Queues</h2><p><img src="https://i.loli.net/2020/01/31/yXA4rKHbvw7cfuF.png" alt="fig7.png"></p><ul><li>deal with the waiting E.G fackbook deal with uploaded images <ul><li>store the raw, unprocessed image </li><li>confirm the upload to users </li><li>add to queue to process in the near future (async)</li></ul></li><li>benefits <ul><li>decouple tasks and processors </li><li>scale on demand </li></ul></li></ul><h2 id="2-8-sharding"><a href="#2-8-sharding" class="headerlink" title="2.8 sharding"></a>2.8 sharding</h2><p><img src="https://i.loli.net/2020/01/31/dXanh3b217s4Miq.png" alt="fig8.png"></p><ul><li>A technique of parallelizing an application’s stacks by separating them into multiple units, each responsible for a certain key or namespace </li><li>shard based on location, use frequency and so on</li></ul><h2 id="2-9-load-balancer"><a href="#2-9-load-balancer" class="headerlink" title="2.9 load balancer"></a>2.9 load balancer</h2><p><img src="https://i.loli.net/2020/01/31/4FblrsEOeP6982U.png" alt="fig9.png"></p><p>Load balancer has hard limit of how many requests they can handle</p><ul><li>DNS<ul><li>free load balancers </li><li>registry allows you to specify multiple IPs per domain name, each leading to a different load balancer </li></ul></li></ul><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><p><a href="https://arcentry.com/blog/scaling-webapps-for-newbs-and-non-techies/" target="_blank" rel="noopener">https://arcentry.com/blog/scaling-webapps-for-newbs-and-non-techies/</a></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Web </tag>
            
            <tag> Scalibility </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React - capture click outside component</title>
      <link href="/React-capture-click-outside-component/"/>
      <url>/React-capture-click-outside-component/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Use-case"><a href="#1-Use-case" class="headerlink" title="1. Use case"></a>1. Use case</h1><p>Suppose you create your own pop up modal, or you invent your own dropdown, you will need to deal/ capture with click outside of the component. This blog will illustrate how to do so. </p><h1 id="2-Handy-instructions"><a href="#2-Handy-instructions" class="headerlink" title="2. Handy instructions"></a>2. Handy instructions</h1><h2 id="2-1-Create-a-ref-to-div"><a href="#2-1-Create-a-ref-to-div" class="headerlink" title="2.1 Create a ref to div"></a>2.1 Create a ref to div</h2><pre><code>render() {    return (        &lt;div ref = {node =&gt; this.node = node}&gt; &lt;/div&gt;    );}</code></pre><h2 id="2-2-Add-event-listener"><a href="#2-2-Add-event-listener" class="headerlink" title="2.2 Add event listener"></a>2.2 Add event listener</h2><pre><code>componentWillMount() {    document.addEventListener(&#39;mousedown&#39;, this.handleClick, false);}componentWillUnmount() {    document.removeEventListener(&#39;mousedown&#39;, this.handleClick, false);}handleClick = (e) =&gt; {    if (this.node.contains(e.target)) {        // inside this component, do whatever you want        return;    }    // handle outside click    this.handleOutsideClick();}</code></pre>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Run your first Puppeteer with recorder</title>
      <link href="/Run-your-first-Puppeteer-with-recorder/"/>
      <url>/Run-your-first-Puppeteer-with-recorder/</url>
      
        <content type="html"><![CDATA[<p>This blog wanna give you some introduction on how to write and run your first puppeteer script. </p><p>I love puppeteer over selenium cause it could use js to interact with browser in almost all ways. It’s super easy to write some scripts to free you from repetive browser work (click, save, blabla…). I learnt this merely cause I don’t want to waste too much of my time on ops work. I believe you guys have the thought with me :) </p><h1 id="1-Install-puppeteer"><a href="#1-Install-puppeteer" class="headerlink" title="1. Install puppeteer"></a>1. Install puppeteer</h1><p>In your command line tool, run </p><pre><code>npm i puppeteer </code></pre><p>It will show you if you have succeeded install puppeteer there. </p><h1 id="2-Write-some-basic-script"><a href="#2-Write-some-basic-script" class="headerlink" title="2. Write some basic script"></a>2. Write some basic script</h1><p>Let’s write some basic code to interact with one page: </p><pre><code>&gt; vim firstPuppeteer.js// in the js file, input // Require the node module, our pre installed puppeteer const puppeteer = require(&#39;puppeteer&#39;);(async () =&gt; {  // launch a browser   const browser = await puppeteer.launch();  // launch a page   const page = await browser.newPage();  // Go to some link you wanna go  await page.goto(&#39;https://www.llchen60.com&#39;);  // Get the &quot;viewport&quot; of the page, as reported by the page.  const dimensions = await page.evaluate(() =&gt; {    return {      width: document.documentElement.clientWidth,      height: document.documentElement.clientHeight,      deviceScaleFactor: window.devicePixelRatio    };  });  console.log(&#39;Dimensions:&#39;, dimensions);  await browser.close();})();</code></pre><p>Well, this start script could get the dimension of the page you want. To execute it, run command <code>node firstPuppeteer.js</code></p><p>The output would be : <code>Dimensions: { width: 800, height: 600, deviceScaleFactor: 1 }</code></p><h1 id="3-Write-your-own-interaction-with-Puppeteer-Recorder"><a href="#3-Write-your-own-interaction-with-Puppeteer-Recorder" class="headerlink" title="3. Write your own interaction with Puppeteer Recorder"></a>3. Write your own interaction with Puppeteer Recorder</h1><p>Here, I wanna introduce you a chrome extension named: <strong>Puppeteer Recorder</strong>. Basically, you could start your interaction with browser and this extension can record all your behavior. </p><ul><li>It uses ES6 syntax to await for your selected component to be available</li><li>With recorder, it comes to be super easy to write puppeteer scripts, no more need to inspect all elements in browser and tracing down one by one! </li></ul><p>Still using my blog as an example, I start record when I’m at the home page, and look around, click on the puppeteer turorial link and then try to leave some comments there, the auto generated script are shown below: </p><pre><code>const puppeteer = require(&#39;puppeteer&#39;);(async () =&gt; {  const browser = await puppeteer.launch()  const page = await browser.newPage()  let frames = await page.frames()  const frame_35 = frames.find(f =&gt; f.url() === &#39;https://disqus.com/embed/comments/?base=default&amp;f=leilei-blog&amp;t_u=https%3A%2F%2Fwww.llchen60.com%2FPupperteer-Tutorial%2F&amp;t_d=Pupperteer%20Tutorial%20-%20Leilei%20%7C%20%E7%A3%8A%E7%A3%8A%E7%9A%84%E5%8D%9A%E5%AE%A2&amp;t_t=Pupperteer%20Tutorial%20-%20Leilei%20%7C%20%E7%A3%8A%E7%A3%8A%E7%9A%84%E5%8D%9A%E5%AE%A2&amp;s_o=default#version=50739766d3d12616cb0b6361b7b2fd85&#39;)  const navigationPromise = page.waitForNavigation()  await page.goto(&#39;https://llchen60.com/&#39;)  await page.setViewport({ width: 1080, height: 1809 })  await page.waitForSelector(&#39;.row &gt; .col-lg-8 &gt; .post-preview:nth-child(17) &gt; a &gt; .post-title&#39;)  await page.click(&#39;.row &gt; .col-lg-8 &gt; .post-preview:nth-child(17) &gt; a &gt; .post-title&#39;)  await navigationPromise  await frame_35.waitForSelector(&#39;.postbox &gt; .textarea-outer-wrapper &gt; .textarea-wrapper &gt; div &gt; .placeholder&#39;)  await frame_35.click(&#39;.postbox &gt; .textarea-outer-wrapper &gt; .textarea-wrapper &gt; div &gt; .placeholder&#39;)  await frame_35.waitForSelector(&#39;div #view27_display_name&#39;)  await frame_35.click(&#39;div #view27_display_name&#39;)  await browser.close()})();</code></pre><p>As you see, it auto generates the code we need, usually we could some modifications and put it on our existing scripts. </p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://llchen60.com/Pupperteer-Tutorial/" target="_blank" rel="noopener">https://llchen60.com/Pupperteer-Tutorial/</a></li><li><a href="https://chrome.google.com/webstore/search/puppeteer?hl=en-US" target="_blank" rel="noopener">https://chrome.google.com/webstore/search/puppeteer?hl=en-US</a></li><li><a href="https://github.com/GoogleChrome/puppeteer" target="_blank" rel="noopener">https://github.com/GoogleChrome/puppeteer</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> UI Test </tag>
            
            <tag> Puppeteer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React Advanced(4)</title>
      <link href="/React-Advanced-4/"/>
      <url>/React-Advanced-4/</url>
      
        <content type="html"><![CDATA[<h1 id="1-The-component-lifecycle"><a href="#1-The-component-lifecycle" class="headerlink" title="1. The component lifecycle"></a>1. The component lifecycle</h1><p>Each component has several lifecycle methods that you can override to run code at perticular times in the process. </p><h2 id="1-1-Mounting"><a href="#1-1-Mounting" class="headerlink" title="1.1 Mounting"></a>1.1 Mounting</h2><p>Methods are called <strong>in this order</strong> when an instance of a component is being created and inserted into the DOM. </p><ol><li>constructor()</li><li>static getDerivedStateFromProps(): exists for use cases where the state depends on changes in props over time </li><li>render()</li><li>componentDidMount()</li></ol><h2 id="1-2-Updating"><a href="#1-2-Updating" class="headerlink" title="1.2 Updating"></a>1.2 Updating</h2><ol><li>static getDerivedStateFromProps()</li><li>shouldComponentUpdate(): judge if a component’s output is not affected by the current change in state or props</li><li>render()</li><li>getSnapshotBeforeUpdate()</li><li>componentDidUpdate() </li></ol><h2 id="1-3-Unmounting"><a href="#1-3-Unmounting" class="headerlink" title="1.3 Unmounting"></a>1.3 Unmounting</h2><ol><li>ComponentWillUnmount()</li></ol><h2 id="1-4-Error-Handling"><a href="#1-4-Error-Handling" class="headerlink" title="1.4 Error Handling"></a>1.4 Error Handling</h2><ol><li>static getDerivedStateFromError()</li><li>componentDidCatch() </li></ol><h1 id="2-JSX-in-Depth"><a href="#2-JSX-in-Depth" class="headerlink" title="2. JSX in Depth"></a>2. JSX in Depth</h1><h2 id="2-1-Specifying-the-react-element-type"><a href="#2-1-Specifying-the-react-element-type" class="headerlink" title="2.1 Specifying the react element type"></a>2.1 Specifying the react element type</h2><p>Capitalized types indicate that the JSX tag is <strong>referring to a React component</strong>. These tages get compiled into a direct reference to the named variable, so if you use the JSX <code>&lt;Foo/&gt;</code> expression, Foo must be in scope. </p><p>E.G Here: </p><pre><code>import React from &#39;react&#39;;import CustomButton from &#39;./CustomButton&#39;;function WarningButton() {  // return React.createElement(CustomButton, {color: &#39;red&#39;}, null);  return &lt;CustomButton color=&quot;red&quot; /&gt;;}</code></pre><p>Need to import those things before truly use it in function scope. </p><h2 id="2-2-User-defined-components-must-be-capitalized"><a href="#2-2-User-defined-components-must-be-capitalized" class="headerlink" title="2.2 User defined components must be capitalized"></a>2.2 User defined components must be capitalized</h2><p>When an element type starts with a lowercase letter, it refers to a build-in component like <code>&lt;div&gt;</code> or <code>&lt;span&gt;</code> passed to React.createElement.  </p><p>***Types that start with a capital letter like <code>&lt;Foo/&gt;</code> compile to React.createElement(Foo) and correspond to a component defined or imported in your js file. </p><h2 id="2-3-Spread-Attributes"><a href="#2-3-Spread-Attributes" class="headerlink" title="2.3 Spread Attributes"></a>2.3 Spread Attributes</h2><p>If you already have props as an object, and you want to pass it in JSX, you can use <code>...</code> as a spread operator to pass the whole props object. </p><p>Equivalent expressions: </p><pre><code>function App1() {  return &lt;Greeting firstName=&quot;Ben&quot; lastName=&quot;Hector&quot; /&gt;;}function App2() {  const props = {firstName: &#39;Ben&#39;, lastName: &#39;Hector&#39;};  return &lt;Greeting {...props} /&gt;;}</code></pre><h2 id="2-4-Children-in-JSX"><a href="#2-4-Children-in-JSX" class="headerlink" title="2.4 Children in JSX"></a>2.4 Children in JSX</h2><p>In JSX expressions that contain both an opening tag and a closing tag, the content between those tags is passed as a special prop: <code>props.children</code>. Several different ways to pass children: </p><ol><li>String literals </li></ol><p><code>&lt;div&gt;Hello World!&lt;/div&gt;</code></p><ol start="2"><li><p>JSX children</p></li><li><p>JS Expressions as Children</p></li></ol><p>Wrap it within <code>{}</code></p>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React Advanced(3)</title>
      <link href="/React-Advanced-3/"/>
      <url>/React-Advanced-3/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Error-Boundaries"><a href="#1-Error-Boundaries" class="headerlink" title="1. Error Boundaries"></a>1. Error Boundaries</h1><h2 id="1-1-Why-need-error-boundaries"><a href="#1-1-Why-need-error-boundaries" class="headerlink" title="1.1 Why need error boundaries"></a>1.1 Why need error boundaries</h2><p>In the past, JavaScript errors inside components used to corrupt React’s internal state and cause it to emit cryptic errors on next renders. These errors were always caused by an earlier error in the application code,** but React did not provide a way to handle them gracefully in components, and could not recover from them**.</p><h2 id="1-2-Intro"><a href="#1-2-Intro" class="headerlink" title="1.2 Intro"></a>1.2 Intro</h2><p>A js error in a part of the UI shouldn’t break the whole app. </p><blockquote><p>Error boundaries are React components that catch JS errors anywhere in their child component tree,log these errors, and display a fallback UI instead of the component tree, log those errors, and display a fallback UI instead of the component tree that crashed. </p></blockquote><p>Notice: Error boundaries do not catch errors for: </p><ol><li>Event handler</li><li>Asynchrounous code </li><li>server side rendering </li><li>errors thrown in the error boundary itself </li></ol><p>A class component becomes an error boundary if it defines either (or both) of the lifecycle methods <code>static getDerivedStateFromError()</code> or <code>componentDidCatch()</code>. Use <code>static getDerivedStateFromError()</code> to render a fallback UI after an error has been thrown. Use <code>componentDidCatch()</code> to log error information.</p><pre><code>class ErrorBoundary extends React.Component {  constructor(props) {    super(props);    this.state = { hasError: false };  }  static getDerivedStateFromError(error) {    // Update state so the next render will show the fallback UI.    return { hasError: true };  }  componentDidCatch(error, info) {    // You can also log the error to an error reporting service    logErrorToMyService(error, info);  }  render() {    if (this.state.hasError) {      // You can render any custom fallback UI      return &lt;h1&gt;Something went wrong.&lt;/h1&gt;;    }    return this.props.children;   }}</code></pre><p>We can use it as a regular component: </p><pre><code>&lt;ErrorBoundary&gt;  &lt;MyWidget /&gt;&lt;/ErrorBoundary&gt;</code></pre><h2 id="1-3-Notifications"><a href="#1-3-Notifications" class="headerlink" title="1.3 Notifications"></a>1.3 Notifications</h2><ol><li>Error boundaries work like a JS <code>catch {}</code> block, but for components. </li><li>Only calss components can be error boundaries.</li><li>Error boundaries only catch errors in the components below them in the tree. </li><li>It cannot catch an error within itself.</li></ol><h1 id="2-Forwarding-Refs"><a href="#2-Forwarding-Refs" class="headerlink" title="2. Forwarding Refs"></a>2. Forwarding Refs</h1><p>Ref forwarding is a tech for <strong><em>automatically passing a ref through a component to one of its children</em></strong></p><h2 id="2-1-Forwarding-Refs-to-DOM-components"><a href="#2-1-Forwarding-Refs-to-DOM-components" class="headerlink" title="2.1 Forwarding Refs to DOM components"></a>2.1 Forwarding Refs to DOM components</h2><pre><code>function FancyButton(props) {  return (    &lt;button className=&quot;FancyButton&quot;&gt;      {props.children}    &lt;/button&gt;  );}</code></pre><p>In this example, FancyButton wrap a button, and we can reuse in our dev work. But the problem is FancyButton is expected to be used in a similar manner as a regular DOM button. We might need to access their DOM nodes for <strong><em>managing focus, selection, or animations</em></strong>.</p><blockquote><p>Ref forwarding is an opt-in feature that lets some components take a ref they receive, and pass it further down to a child. </p></blockquote><pre><code>const FancyButton = React.forwardRef((props, ref) =&gt; (  &lt;button ref={ref} className=&quot;FancyButton&quot;&gt;    {props.children}  &lt;/button&gt;));// You can now get a ref directly to the DOM button:const ref = React.createRef();&lt;FancyButton ref={ref}&gt;Click me!&lt;/FancyButton&gt;;</code></pre><p>Here, use <code>React.forwardRef()</code> to obtain the ref passed to it, and then forward it to the DOM button that it renders. </p><p>Here is a step-by-step explanation of what happens in the above example:</p><ol><li>We create a React ref by calling <code>React.createRef</code> and assign it to a ref variable.</li><li>We pass our ref down to <code>&lt;FancyButton ref={ref}&gt;</code> by specifying it as a JSX attribute.</li><li>React passes the ref to the <code>(props, ref) =&gt; ...</code> function inside forwardRef as a second argument.</li><li>We forward this ref argument down to <code>&lt;button ref={ref}&gt;</code> by specifying it as a JSX attribute.</li><li>When the ref is attached, <code>ref.current</code> will point to the <button> DOM node.</li></ol><h1 id="3-Higher-Order-Components-KEY-FACTOR"><a href="#3-Higher-Order-Components-KEY-FACTOR" class="headerlink" title="3. Higher-Order Components (KEY FACTOR)"></a>3. Higher-Order Components (KEY FACTOR)</h1><blockquote><p>A higher order component(HOC) is an advanced technique in React for reusing component logic. It’s a pattern that emerges from React’s compositional nature. </p></blockquote><blockquote><p>Concretely, <strong><em>a higher order component is a function that takes a component and returns a new component</em></strong></p></blockquote><p>Whereas a component transforms props into UI, a higher-order component transforms a component into another component.</p><h2 id="3-1-Use-HOCs-For-cross-cutting-concerns"><a href="#3-1-Use-HOCs-For-cross-cutting-concerns" class="headerlink" title="3.1 Use HOCs For cross cutting concerns"></a>3.1 Use HOCs For cross cutting concerns</h2><p>CommentList component that subscribes to an external data source to render a list of comments: </p><pre><code>class CommentList extends React.Component {  constructor(props) {    super(props);    this.handleChange = this.handleChange.bind(this);    this.state = {      // &quot;DataSource&quot; is some global data source      comments: DataSource.getComments()    };  }  componentDidMount() {    // Subscribe to changes    DataSource.addChangeListener(this.handleChange);  }  componentWillUnmount() {    // Clean up listener    DataSource.removeChangeListener(this.handleChange);  }  handleChange() {    // Update component state whenever the data source changes    this.setState({      comments: DataSource.getComments()    });  }  render() {    return (      &lt;div&gt;        {this.state.comments.map((comment) =&gt; (          &lt;Comment comment={comment} key={comment.id} /&gt;        ))}      &lt;/div&gt;    );  }}</code></pre><p>A component for subscribing to a single blog post:</p><pre><code>class BlogPost extends React.Component {  constructor(props) {    super(props);    this.handleChange = this.handleChange.bind(this);    this.state = {      blogPost: DataSource.getBlogPost(props.id)    };  }  componentDidMount() {    DataSource.addChangeListener(this.handleChange);  }  componentWillUnmount() {    DataSource.removeChangeListener(this.handleChange);  }  handleChange() {    this.setState({      blogPost: DataSource.getBlogPost(this.props.id)    });  }  render() {    return &lt;TextBlock text={this.state.blogPost} /&gt;;  }}</code></pre><p>Much of those two component are similar, need an abstraction that allows us to define the logic in a single place and share it across many components.</p><p>Write a function that creates components, like CommentList and BlogList, that subscribe to DataSourse. </p><pre><code>const CommentListWithSubscription = withSubscription(  CommentList,  (DataSource) =&gt; DataSource.getComments());const BlogPostWithSubscription = withSubscription(  BlogPost,  (DataSource, props) =&gt; DataSource.getBlogPost(props.id));</code></pre><p>When CommentListWithSubscription and BlogPostWithSubscription are rendered, <strong>CommentList and BlogPost will be passed a data prop with the most current data retrieved from DataSource</strong>:</p><pre><code>// This function takes a component...function withSubscription(WrappedComponent, selectData) {  // ...and returns another component...  return class extends React.Component {    constructor(props) {      super(props);      this.handleChange = this.handleChange.bind(this);      this.state = {        data: selectData(DataSource, props)      };    }    componentDidMount() {      // ... that takes care of the subscription...      DataSource.addChangeListener(this.handleChange);    }    componentWillUnmount() {      DataSource.removeChangeListener(this.handleChange);    }    handleChange() {      this.setState({        data: selectData(DataSource, this.props)      });    }    render() {      // ... and renders the wrapped component with the fresh data!      // Notice that we pass through any additional props      return &lt;WrappedComponent data={this.state.data} {...this.props} /&gt;;    }  };}</code></pre><p>Note that a HOC doesn’t modify the input component, nor does it use inheritance to copy its behavior. Rather, a HOC composes the original component by wrapping it in a container component. A HOC is a pure function with zero side-effects.</p><p>The wrapped component receives all the props of the container, along with a new prop, data, which it uses to render its output. The HOC isn’t concerned with how or why the data is used, and the wrapped component isn’t concerned with where the data came from. </p><h1 id="4-Fragments"><a href="#4-Fragments" class="headerlink" title="4. Fragments"></a>4. Fragments</h1><p>Fragments let you group a list of children without adding extra nodes to the DOM. </p><pre><code>render() {  return (    &lt;React.Fragment&gt;      &lt;ChildA /&gt;      &lt;ChildB /&gt;      &lt;ChildC /&gt;    &lt;/React.Fragment&gt;  );}</code></pre><h2 id="4-1-Why-introduce-Fragments"><a href="#4-1-Why-introduce-Fragments" class="headerlink" title="4.1 Why introduce Fragments"></a>4.1 Why introduce <code>Fragments</code></h2><pre><code>&lt;table&gt;  &lt;tr&gt;    &lt;div&gt;      &lt;td&gt;Hello&lt;/td&gt;      &lt;td&gt;World&lt;/td&gt;    &lt;/div&gt;  &lt;/tr&gt;&lt;/table&gt;</code></pre><p>In this example, if there are two components, and we want to seperate it, and make <code>&lt;div&gt;</code> doesn’t work(group elements inside, but keep table format works), we can modify it to: </p><pre><code>class Columns extends React.Component {  render() {    return (      &lt;React.Fragment&gt;        &lt;td&gt;Hello&lt;/td&gt;        &lt;td&gt;World&lt;/td&gt;      &lt;/React.Fragment&gt;    );  }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React Advanced(2)</title>
      <link href="/React-Advanced-2/"/>
      <url>/React-Advanced-2/</url>
      
        <content type="html"><![CDATA[<p>In this part, dive deeper into React. In the previous post, found a lot of new things. Though I can write some jsx code, but I have to admit it’s really ugly…wihout reuse, with some useless states for no reasons, duplicate, boring. That’s why try to write some articles following authoritive docs. There are some of my thoughts inside, hope it can help you. :) </p><h1 id="1-Accessibility"><a href="#1-Accessibility" class="headerlink" title="1. Accessibility"></a>1. Accessibility</h1><p>Also known as a11y, is the design and creation of websites that can be used by everyone. </p><h2 id="1-1-Semantic-HTML"><a href="#1-1-Semantic-HTML" class="headerlink" title="1.1 Semantic HTML"></a>1.1 Semantic HTML</h2><p>Sometimes, we break HTML sementics when we add <code>&lt;div&gt;</code> elements to our JSX to make our React code work, especially working with lists and table. In these case, we should use <strong><em>React Fragments</em></strong> to group together multiple elements. </p><pre><code>import React, { Fragment } from &#39;react&#39;;function ListItem({ item }) {  return (    &lt;Fragment&gt;      &lt;dt&gt;{item.term}&lt;/dt&gt;      &lt;dd&gt;{item.description}&lt;/dd&gt;    &lt;/Fragment&gt;  );}function Glossary(props) {  return (    &lt;dl&gt;      {props.items.map(item =&gt; (        &lt;ListItem item={item} key={item.id} /&gt;      ))}    &lt;/dl&gt;  );}</code></pre><p>Map a collection of items to an array of fragments as you would any other type of elements as well: </p><pre><code>function Glossary(props) {  return (    &lt;dl&gt;      {props.items.map(item =&gt; (        // Fragments should also have a `key` prop when mapping collections        &lt;Fragment key={item.id}&gt;          &lt;dt&gt;{item.term}&lt;/dt&gt;          &lt;dd&gt;{item.description}&lt;/dd&gt;        &lt;/Fragment&gt;      ))}    &lt;/dl&gt;  );}</code></pre><h1 id="2-Refs-and-the-DOM"><a href="#2-Refs-and-the-DOM" class="headerlink" title="2 Refs and the DOM"></a>2 Refs and the DOM</h1><blockquote><p>Refs provide a way to access DOM nodes or React elements created in the render method. </p></blockquote><p>Refs offer another way to change a child outside of the typical dataflow - use props from parent to child. <strong>The child to be modified could be an instance of a React Component, or it could be a DOM element.</strong> </p><h2 id="2-1-When-to-use-Refs"><a href="#2-1-When-to-use-Refs" class="headerlink" title="2.1 When to use Refs"></a>2.1 When to use Refs</h2><ol><li>Managing focus, text selection, media playback </li><li>triggering imperative animations</li><li>integrating with third party DOM libraries </li></ol><h2 id="2-2-How-to-use-Refs"><a href="#2-2-How-to-use-Refs" class="headerlink" title="2.2 How to use Refs"></a>2.2 How to use Refs</h2><p>Use by <code>React.createRef()</code>, to create a ref</p><pre><code>class MyComponent extends React.Component {  constructor(props) {    super(props);    this.myRef = React.createRef();  }  render() {    return &lt;div ref={this.myRef} /&gt;;  }}</code></pre><p>When a ref is passed to an element in render, a reference to the node becomes accessible at the <strong><em>current</em></strong> attribute of the ref</p><pre><code>const node = this.myRef.current;</code></pre><h2 id="2-3-Value-of-the-ref"><a href="#2-3-Value-of-the-ref" class="headerlink" title="2.3 Value of the ref"></a>2.3 Value of the ref</h2><ol><li><p>When the ref attribute is used on an HTML element, the ref created in the constructor with React.createRef() receives the underlying DOM element as its current property.</p></li><li><p>When the ref attribute is used on a custom class component, the ref object receives the mounted instance of the component as its current.</p><p> class CustomTextInput extends React.Component {<br>   constructor(props) {</p><pre><code> super(props); // create a ref to store the textInput DOM element this.textInput = React.createRef(); this.focusTextInput = this.focusTextInput.bind(this);</code></pre><p>   }</p><p>   focusTextInput() {</p><pre><code> // Explicitly focus the text input using the raw DOM API // Note: we&#39;re accessing &quot;current&quot; to get the DOM node this.textInput.current.focus();</code></pre><p>   }</p><p>   render() {</p><pre><code> // tell React that we want to associate the &lt;input&gt; ref // with the `textInput` that we created in the constructor return (   &lt;div&gt;     &lt;input       type=&quot;text&quot;       ref={this.textInput} /&gt;     &lt;input       type=&quot;button&quot;       value=&quot;Focus the text input&quot;       onClick={this.focusTextInput}     /&gt;   &lt;/div&gt; );</code></pre><p>   }<br> }</p></li></ol><p>Here, React will assign the current property with the DOM element when the component mounts, and assign it back to null when it unmounts. Ref updates happen before componentDidMount or componentDidUpdate lifecycle methods. </p><p><strong>*!!! We cannot use ref attribute on function componnets because they don’t have instances. *</strong></p><h1 id="3-Code-Splitting"><a href="#3-Code-Splitting" class="headerlink" title="3. Code Splitting"></a>3. Code Splitting</h1><h2 id="3-1-Bundling"><a href="#3-1-Bundling" class="headerlink" title="3.1 Bundling"></a>3.1 Bundling</h2><p>Most React Apps will have their files bundles using tools like webpack or browserify. Bundling is the process of following imported files and merging them into a single file. This file can then be included on a webpage to load an entire app at once. </p><h2 id="3-2-Code-splitting"><a href="#3-2-Code-splitting" class="headerlink" title="3.2 Code splitting"></a>3.2 Code splitting</h2><p>Bundling is great, but as your app grows, bundle will grow too. Especially if you are including large third party libraries. </p><p>To void winding up with a large bundle, it’s good to get ahead of the problkem and start splitting your bundle. </p><p>Code-splitting your app can help you “lazy-load” just the things that are currently needed by the user, which can dramatically improve the performance of your app. While you haven’t reduced the overall amount of code in your app, you’ve avoided loading code that the user may never need, and reduced the amount of code needed during the initial load.</p><h2 id="3-3-Dynamic-import"><a href="#3-3-Dynamic-import" class="headerlink" title="3.3 Dynamic import()"></a>3.3 Dynamic <code>import()</code></h2><p>The beast way to introduce code-splitting into app is through the dynamic import() syntax. </p><pre><code>import { add } from &#39;./math&#39;;console.log(add(16, 26));</code></pre><p>Before, now with dynamic import: </p><pre><code>import(&quot;./math&quot;).then(math =&gt; {  console.log(math.add(16, 26));});</code></pre><h2 id="3-4-React-lazy"><a href="#3-4-React-lazy" class="headerlink" title="3.4 React.lazy"></a>3.4 React.lazy</h2><p>lets you render a dynamic import as a regular component. </p><pre><code>import OtherComponent from &#39;./OtherComponent&#39;;function MyComponent() {  return (    &lt;div&gt;      &lt;OtherComponent /&gt;    &lt;/div&gt;  );}</code></pre><p>Switch to: </p><pre><code>const OtherComponent = React.lazy(() =&gt; import(&#39;./OtherComponent&#39;));function MyComponent() {  return (    &lt;div&gt;      &lt;OtherComponent /&gt;    &lt;/div&gt;  );}</code></pre><h2 id="3-5-Suspense"><a href="#3-5-Suspense" class="headerlink" title="3.5 Suspense"></a>3.5 Suspense</h2><p>If the modile containing other component is not yet loaded by the time current one renders, we must <strong>show some fallback content</strong> while we are waiting for it to load. </p><pre><code>const OtherComponent = React.lazy(() =&gt; import(&#39;./OtherComponent&#39;));function MyComponent() {  return (    &lt;div&gt;      &lt;Suspense fallback={&lt;div&gt;Loading...&lt;/div&gt;}&gt;        &lt;OtherComponent /&gt;      &lt;/Suspense&gt;    &lt;/div&gt;  );}</code></pre><p>The fallback prop accepts any React elements that you want to render while waiting for the component to load. </p><h1 id="4-Context"><a href="#4-Context" class="headerlink" title="4. Context"></a>4. Context</h1><p>Context provides a way to pass data through the component tree without having to pass props down manually at every level. </p><p>some props, like locale preference, UI theme, that are required by many components within an application. <strong>Context provides a way to share values like these between components without having to explicitly pass a prop throught every level of the tree.</strong></p><h2 id="4-1-When-to-use-Context"><a href="#4-1-When-to-use-Context" class="headerlink" title="4.1 When to use Context"></a>4.1 When to use Context</h2><pre><code>class App extends React.Component {  render() {    return &lt;Toolbar theme=&quot;dark&quot; /&gt;;  }}function Toolbar(props) {  // The Toolbar component must take an extra &quot;theme&quot; prop  // and pass it to the ThemedButton. This can become painful  // if every single button in the app needs to know the theme  // because it would have to be passed through all components.  return (    &lt;div&gt;      &lt;ThemedButton theme={props.theme} /&gt;    &lt;/div&gt;  );}class ThemedButton extends React.Component {  render() {    return &lt;Button theme={this.props.theme} /&gt;;  }}</code></pre><p>With context, we can avoid passing props through intermidiate elements: </p><pre><code>// Context lets us pass a value deep into the component tree// without explicitly threading it through every component.// Create a context for the current theme (with &quot;light&quot; as the default).const ThemeContext = React.createContext(&#39;light&#39;);class App extends React.Component {  render() {    // Use a Provider to pass the current theme to the tree below.    // Any component can read it, no matter how deep it is.    // In this example, we&#39;re passing &quot;dark&quot; as the current value.    return (      &lt;ThemeContext.Provider value=&quot;dark&quot;&gt;        &lt;Toolbar /&gt;      &lt;/ThemeContext.Provider&gt;    );  }}// A component in the middle doesn&#39;t have to// pass the theme down explicitly anymore.function Toolbar(props) {  return (    &lt;div&gt;      &lt;ThemedButton /&gt;    &lt;/div&gt;  );}class ThemedButton extends React.Component {  // Assign a contextType to read the current theme context.  // React will find the closest theme Provider above and use its value.  // In this example, the current theme is &quot;dark&quot;.  static contextType = ThemeContext;  render() {    return &lt;Button theme={this.context} /&gt;;  }}</code></pre><p>Notice: </p><ol><li><code>contextType</code></li><li><code>context.provider</code></li></ol><h2 id="4-2-Before-using-context"><a href="#4-2-Before-using-context" class="headerlink" title="4.2 Before using context"></a>4.2 Before using context</h2><p>Context is primarily used when some data needs to be accessible by many components at different nesting levels. </p><p>Multiple other choices can be used to resolve similar problems. </p><ol><li>Pass down the combined component itself </li></ol><pre><code>&lt;Page user={user} avatarSize={avatarSize} /&gt;// ... which renders ...&lt;PageLayout user={user} avatarSize={avatarSize} /&gt;// ... which renders ...&lt;NavigationBar user={user} avatarSize={avatarSize} /&gt;// ... which renders ...&lt;Link href={user.permalink}&gt;  &lt;Avatar user={user} size={avatarSize} /&gt;&lt;/Link&gt;function Page(props) {  const user = props.user;  const userLink = (    &lt;Link href={user.permalink}&gt;      &lt;Avatar user={user} size={props.avatarSize} /&gt;    &lt;/Link&gt;  );  return &lt;PageLayout userLink={userLink} /&gt;;}// Now, we have:&lt;Page user={user} /&gt;// ... which renders ...&lt;PageLayout userLink={...} /&gt;// ... which renders ...&lt;NavigationBar userLink={...} /&gt;// ... which renders ...{props.userLink}</code></pre><h2 id="4-3-API"><a href="#4-3-API" class="headerlink" title="4.3 API"></a>4.3 API</h2><ol><li><p><code>React.createContext</code></p><p> const MyContext = React.createContext(defaultValue);</p></li></ol><p>Create a context object. When React renders a component that subscribes to this Context object it will read the current context value from the closest matching Provider above it in the tree. <strong>Read context value from provider!</strong></p><p>The defaultValue argument is only used when a component does not have a matching Provider above it in the tree. This can be helpful for testing components in isolation without wrapping them.</p><ol start="2"><li><p><code>Context.Provider</code></p><p> &lt;MyContext.Provider value={/* some value */}&gt;</p></li></ol><p>Every Context object comes with a Provider React Component that allows consuming components to subscribe to context changes. One Provider can be connected to many consumers. Providers can be nested to override values deeper within the tree. All consumers that are descendants of a Provider will re-render whenever the Provider’s value prop changes. The propagation from Provider to its descendant consumers is not subject to the shouldComponentUpdate method, so the consumer is updated even when an ancestor component bails out of the update.</p><ol start="3"><li><code>Class.contextType</code></li></ol><p>contextType property on a class can be assigned a context object created by <code>React.createContext()</code>. This lets you consume the nearest current value of that Context type using this.context. You can reference this in any of the lifecycle methods including the render function.</p><ol start="4"><li><code>Context.consumer</code></li></ol><pre><code>&lt;MyContext.Consumer&gt;  {value =&gt; /* render something based on the context value */}&lt;/MyContext.Consumer&gt;</code></pre><p>A react component that subscribes to context changes. This lets you subscribe to a context within a function component.</p><h2 id="4-4-Example"><a href="#4-4-Example" class="headerlink" title="4.4 Example"></a>4.4 Example</h2><p>theme-context.js </p><pre><code>export const themes = {  light: {    foreground: &#39;#000000&#39;,    background: &#39;#eeeeee&#39;,  },  dark: {    foreground: &#39;#ffffff&#39;,    background: &#39;#222222&#39;,  },};export const ThemeContext = React.createContext(  themes.dark // default value);</code></pre><p>theme-button.js</p><pre><code>import {ThemeContext} from &#39;./theme-context&#39;;class ThemedButton extends React.Component {  render() {    let props = this.props;    let theme = this.context;    return (      &lt;button        {...props}        style={{backgroundColor: theme.background}}      /&gt;    );  }}ThemedButton.contextType = ThemeContext;export default ThemedButton;</code></pre><p>app.js</p><pre><code>import {ThemeContext, themes} from &#39;./theme-context&#39;;import ThemedButton from &#39;./themed-button&#39;;// An intermediate component that uses the ThemedButtonfunction Toolbar(props) {  return (    &lt;ThemedButton onClick={props.changeTheme}&gt;      Change Theme    &lt;/ThemedButton&gt;  );}class App extends React.Component {  constructor(props) {    super(props);    this.state = {      theme: themes.light,    };    this.toggleTheme = () =&gt; {      this.setState(state =&gt; ({        theme:          state.theme === themes.dark            ? themes.light            : themes.dark,      }));    };  }  render() {    // The ThemedButton button inside the ThemeProvider    // uses the theme from state while the one outside uses    // the default dark theme    return (      &lt;Page&gt;        &lt;ThemeContext.Provider value={this.state.theme}&gt;          &lt;Toolbar changeTheme={this.toggleTheme} /&gt;        &lt;/ThemeContext.Provider&gt;        &lt;Section&gt;          &lt;ThemedButton /&gt;        &lt;/Section&gt;      &lt;/Page&gt;    );  }}ReactDOM.render(&lt;App /&gt;, document.root);</code></pre><h1 id="5-Reference"><a href="#5-Reference" class="headerlink" title="5. Reference"></a>5. Reference</h1><ol><li><a href="https://reactjs.org/docs/context.html" target="_blank" rel="noopener">React Doc</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React Advanced(1)</title>
      <link href="/React-Advanced-1/"/>
      <url>/React-Advanced-1/</url>
      
        <content type="html"><![CDATA[<p>For this part, aim to know all the necessary react knowledge to better do the development work. Start from the very beginning, and try to grab all the basic and advanced knowledge follow the authoritive doc. </p><h1 id="1-Main-Concepts"><a href="#1-Main-Concepts" class="headerlink" title="1. Main Concepts"></a>1. Main Concepts</h1><h2 id="1-1-JSX"><a href="#1-1-JSX" class="headerlink" title="1.1 JSX"></a>1.1 JSX</h2><pre><code>const element = &lt;h1&gt;Hello World!&lt;/h1&gt;</code></pre><p>JSX, syntax extension to JS. JSX produces <strong>React Elements</strong>. And then we try to render them to the DOM. </p><p>JSX out logic and markup together, react separates concerns with loosely coupled units called components that contain both. </p><h3 id="1-1-1-Embedding-expressions-in-JSX"><a href="#1-1-1-Embedding-expressions-in-JSX" class="headerlink" title="1.1.1 Embedding expressions in JSX"></a>1.1.1 Embedding expressions in JSX</h3><pre><code>const name = &#39;Josh Perez&#39;;const element = &lt;h1&gt;Hello, {name}&lt;/h1&gt;;ReactDOM.render(  element,  document.getElementById(&#39;root&#39;));</code></pre><p>Here, by wrapping name in curly braces, we call a variable. </p><blockquote><p>Inside the curly brace, we can put any valid <strong><em>JS expression</em></strong>.  </p></blockquote><h3 id="1-1-2-JSX-is-an-Expression"><a href="#1-1-2-JSX-is-an-Expression" class="headerlink" title="1.1.2 JSX is an Expression"></a>1.1.2 JSX is an Expression</h3><p>After compilation, JSX expressions become regular <strong>JS function calls</strong> and evaluate to <strong>JS objects</strong>. React DOM uses camelCase property naming convention </p><p>JSX represents Object, Babel will help JSX to compile to React.createElement() call. </p><h2 id="1-2-Rendering-Elements"><a href="#1-2-Rendering-Elements" class="headerlink" title="1.2 Rendering Elements"></a>1.2 Rendering Elements</h2><h3 id="1-2-1-Element"><a href="#1-2-1-Element" class="headerlink" title="1.2.1 Element"></a>1.2.1 Element</h3><p>An element describes what you want to see on the screen. </p><pre><code>const element = &lt;h1&gt;Hello world!&lt;/h1&gt;</code></pre><p>Components are made of elements. </p><blockquote><p>Applications built with React usually have a <strong><em>single root DOM node</em></strong>. If you are integrating React into an existing app, you may have as many isolated root DOM nodes as you like. </p></blockquote><h3 id="1-2-2-Updating-the-rendered-element"><a href="#1-2-2-Updating-the-rendered-element" class="headerlink" title="1.2.2 Updating the rendered element"></a>1.2.2 Updating the rendered element</h3><blockquote><p><strong><em>React elements are immutable</em></strong></p></blockquote><p>Once you create an element, you cannot change its children or attributes</p><h3 id="1-2-3-Only-updates-what’s-necessary"><a href="#1-2-3-Only-updates-what’s-necessary" class="headerlink" title="1.2.3 Only updates what’s necessary"></a>1.2.3 Only updates what’s necessary</h3><p>React DOM compares the element and its children to the previous one, and only applies the DOM updates necessary to bring the DOM to the desired state. </p><blockquote><p>In this way, we can spend more time thinking how the UI should look like rather than how to change it over time eliminates a whole class of bugs. </p></blockquote><h2 id="1-3-Components-and-Props"><a href="#1-3-Components-and-Props" class="headerlink" title="1.3 Components and Props"></a>1.3 Components and Props</h2><h3 id="1-3-1-Components"><a href="#1-3-1-Components" class="headerlink" title="1.3.1 Components"></a>1.3.1 Components</h3><p>Components let you split the UI into independent, reusable pieces, and think about each piece in isolation. They accept arbitrary inputs(named props) and return React elements describing what should appear on the screen. </p><p>When React sees an element representing a user-defined component, it <strong>passes JSX attributes to this component</strong> as a single object. We call this object “props”.</p><pre><code>function Welcome(props) {  return &lt;h1&gt;Hello, {props.name}&lt;/h1&gt;;}const element = &lt;Welcome name=&quot;Sara&quot; /&gt;;ReactDOM.render(  element,  document.getElementById(&#39;root&#39;));</code></pre><h3 id="1-3-2-Extract-Components"><a href="#1-3-2-Extract-Components" class="headerlink" title="1.3.2 Extract Components"></a>1.3.2 Extract Components</h3><p>To make them better reusable. </p><h3 id="1-3-3-Props-are-Read-only"><a href="#1-3-3-Props-are-Read-only" class="headerlink" title="1.3.3 Props are Read only"></a>1.3.3 Props are <strong><em>Read only</em></strong></h3><p>All React Components must act like pure functions with respect to their props. </p><h2 id="1-4-State-and-Lifecycle"><a href="#1-4-State-and-Lifecycle" class="headerlink" title="1.4 State and Lifecycle"></a>1.4 State and Lifecycle</h2><h3 id="1-4-1-State"><a href="#1-4-1-State" class="headerlink" title="1.4.1 State"></a>1.4.1 State</h3><p>State is private, and fully controlled by the component. </p><h3 id="1-4-2-Adding-lifecycle-methods-to-a-Class"><a href="#1-4-2-Adding-lifecycle-methods-to-a-Class" class="headerlink" title="1.4.2 Adding lifecycle methods to a Class"></a>1.4.2 Adding lifecycle methods to a Class</h3><p>In applications with many components, it’s very important to free up resources taken by the components when they are destroyed. </p><ol><li><p>componentDidMount()<br>It runs after the component output has been rendered to the DOM</p></li><li><p>componentWillUnmount() </p></li><li><p>Runs when the DOM need to be removed </p></li></ol><h3 id="1-4-3-State-Using-tips"><a href="#1-4-3-State-Using-tips" class="headerlink" title="1.4.3 State Using tips"></a>1.4.3 State Using tips</h3><ol><li>Do not modify state directly, instead, use setState</li><li>state updates may be asynchronous , props and state may be updated asynchronously, should not rely on their values for calculating the next state. </li></ol><pre><code>// Correctthis.setState((state, props) =&gt; ({  counter: state.counter + props.increment}));</code></pre><p>In this way, That function will receive the previous state as the first argument, and the props at the time the update is applied as the second argument</p><ol start="3"><li>State updates are merged </li></ol><h3 id="1-4-4-The-data-flow-down"><a href="#1-4-4-The-data-flow-down" class="headerlink" title="1.4.4 The data flow down"></a>1.4.4 The data flow down</h3><p>This is commonly called a “top-down” or “unidirectional” data flow. Any state is always owned by some specific component, and any data or UI derived from that state can only affect components “below” them in the tree.</p><blockquote><p>If you imagine a component tree as a waterfall of props, each component’s state is like an additional water source that joins it at an arbitrary point but also flows down.</p></blockquote><h2 id="1-5-Handling-Events"><a href="#1-5-Handling-Events" class="headerlink" title="1.5 Handling Events"></a>1.5 Handling Events</h2><p>Quite similar to handling methods in DOM, some differences: </p><ol><li><p>Syntax: </p> <button onClick={activateLasers}>   Activate Lasers </button></li></ol><p>Use {}, <code>activateLasers</code> here means a function name</p><ol start="2"><li>use <code>e.preventDefault()</code> to block the default behavior</li><li>when using React, you should generally not need to call <code>addEventListener</code> to add listeners to a DOM element after it is created. Instead, just provide a listener when the element is initially rendered. </li></ol><pre><code>class Toggle extends React.Component {  constructor(props) {    super(props);    this.state = {isToggleOn: true};    // This binding is necessary to make `this` work in the callback    this.handleClick = this.handleClick.bind(this);  }  handleClick() {    this.setState(state =&gt; ({      isToggleOn: !state.isToggleOn    }));  }  render() {    return (      &lt;button onClick={this.handleClick}&gt;        {this.state.isToggleOn ? &#39;ON&#39; : &#39;OFF&#39;}      &lt;/button&gt;    );  }}ReactDOM.render(  &lt;Toggle /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><blockquote><p> Be careful of <code>this</code>, since class methods are not bound by default. Need to bind this.handleClick. </p></blockquote><ol start="4"><li>You can try to not bind this if you declare the method in such way!</li></ol><pre><code>class LoggingButton extends React.Component {  // This syntax ensures `this` is bound within handleClick.  // Warning: this is *experimental* syntax.  handleClick = () =&gt; {    console.log(&#39;this is:&#39;, this);  }  render() {    return (      &lt;button onClick={this.handleClick}&gt;        Click me      &lt;/button&gt;    );  }}</code></pre><p>Let’s figure out what’s <code>() =&gt; {}</code> means here: </p><p><strong><em>() contains some variables, used in an arrow function to return an object</em></strong></p><p><strong><em>{} contains some statement, actually, it’s a special syntax in JSX. It contains a JS expression, can be a variable</em></strong></p><h2 id="1-6-Conditional-Rendering"><a href="#1-6-Conditional-Rendering" class="headerlink" title="1.6  Conditional Rendering"></a>1.6  Conditional Rendering</h2><p>User can create distinct components that encapsulate behavior you need, ANd we can <strong>render only some of them</strong>. </p><ol><li>Using if to do conditional rendering</li><li>Inline if with Logical &amp;&amp; Operator </li></ol><pre><code>function Mailbox(props) {  const unreadMessages = props.unreadMessages;  return (    &lt;div&gt;      &lt;h1&gt;Hello!&lt;/h1&gt;      {unreadMessages.length &gt; 0 &amp;&amp;        &lt;h2&gt;          You have {unreadMessages.length} unread messages.        &lt;/h2&gt;      }    &lt;/div&gt;  );}const messages = [&#39;React&#39;, &#39;Re: React&#39;, &#39;Re:Re: React&#39;];ReactDOM.render(  &lt;Mailbox unreadMessages={messages} /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><p>It works because in JS, <code>true &amp;&amp; expression</code> always evaluateds to <code>expression</code>, and <code>false &amp;&amp; expression</code> always evaluates to <code>false</code>. </p><ol start="3"><li><p>Inline if-else with conditional operator </p><p> <code>condition ? true : false</code></p></li><li><p>Return null will prevent a component from render, but it will not affect the component’s lifecycle methods. </p></li></ol><h2 id="1-7-Lists-and-Keys"><a href="#1-7-Lists-and-Keys" class="headerlink" title="1.7 Lists and Keys"></a>1.7 Lists and Keys</h2><h3 id="1-7-1-Rendering-Multiple-Components"><a href="#1-7-1-Rendering-Multiple-Components" class="headerlink" title="1.7.1 Rendering Multiple Components"></a>1.7.1 Rendering Multiple Components</h3><pre><code>const numbers = [1, 2, 3, 4, 5];const listItems = numbers.map((number) =&gt;  &lt;li&gt;{number}&lt;/li&gt;);// warning will be shown indicating you need provide key     function NumberList(props) {  const numbers = props.numbers;  const listItems = numbers.map((number) =&gt;    &lt;li&gt;{number}&lt;/li&gt;  );  return (    &lt;ul&gt;{listItems}&lt;/ul&gt;  );}const numbers = [1, 2, 3, 4, 5];ReactDOM.render(  &lt;NumberList numbers={numbers} /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><p>A “key” is a special string attribute you need to include when creating lists of elements. </p><pre><code>function NumberList(props) {  const numbers = props.numbers;  const listItems = numbers.map((number) =&gt;    &lt;li key={number.toString()}&gt;      {number}    &lt;/li&gt;  );  return (    &lt;ul&gt;{listItems}&lt;/ul&gt;  );}const numbers = [1, 2, 3, 4, 5];ReactDOM.render(  &lt;NumberList numbers={numbers} /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><h2 id="1-7-2-Keys"><a href="#1-7-2-Keys" class="headerlink" title="1.7.2 Keys"></a>1.7.2 Keys</h2><p>It helps React identify which items have changed, are added, or are removed. Keys should be given to the elements inside the array to give the elements a stable identity. </p><pre><code>const todoItems = todos.map((todo, index) =&gt;  // Only do this if items have no stable IDs  &lt;li key={index}&gt;    {todo.text}  &lt;/li&gt;);</code></pre><p>Using index as key might have some negative influence, thus we’d better find some other specific string as the key. </p><p>!!! Keys only make sense in the context of the surrounding array. </p><pre><code>function ListItem(props) {  const value = props.value;  return (    // Wrong! There is no need to specify the key here:    &lt;li key={value.toString()}&gt;      {value}    &lt;/li&gt;  );}function NumberList(props) {  const numbers = props.numbers;  const listItems = numbers.map((number) =&gt;    // Wrong! The key should have been specified here:    &lt;ListItem value={number} /&gt;  );  return (    &lt;ul&gt;      {listItems}    &lt;/ul&gt;  );}const numbers = [1, 2, 3, 4, 5];ReactDOM.render(  &lt;NumberList numbers={numbers} /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><p>Correct Version: </p><pre><code>function ListItem(props) {  // Correct! There is no need to specify the key here:  return &lt;li&gt;{props.value}&lt;/li&gt;;}function NumberList(props) {  const numbers = props.numbers;  const listItems = numbers.map((number) =&gt;    // Correct! Key should be specified inside the array.    &lt;ListItem key={number.toString()}              value={number} /&gt;  );  return (    &lt;ul&gt;      {listItems}    &lt;/ul&gt;  );}const numbers = [1, 2, 3, 4, 5];ReactDOM.render(  &lt;NumberList numbers={numbers} /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><h2 id="1-7-3-Embedding-map-in-JSX"><a href="#1-7-3-Embedding-map-in-JSX" class="headerlink" title="1.7.3 Embedding map() in JSX"></a>1.7.3 Embedding map() in JSX</h2><pre><code>function NumberList(props) {  const numbers = props.numbers;  const listItems = numbers.map((number) =&gt;    &lt;ListItem key={number.toString()}              value={number} /&gt;  );  return (    &lt;ul&gt;      {listItems}    &lt;/ul&gt;  );}</code></pre><p>After map:</p><pre><code>    function NumberList(props) {  const numbers = props.numbers;  return (    &lt;ul&gt;      {numbers.map((number) =&gt;        &lt;ListItem key={number.toString()}                  value={number} /&gt;      )}    &lt;/ul&gt;  );}</code></pre><h2 id="1-8-Forms"><a href="#1-8-Forms" class="headerlink" title="1.8 Forms"></a>1.8 Forms</h2><p>Form elements natuarlly keep some internal state.</p><pre><code>&lt;form&gt;  &lt;label&gt;    Name:    &lt;input type=&quot;text&quot; name=&quot;name&quot; /&gt;  &lt;/label&gt;  &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;&lt;/form&gt;</code></pre><p>React can use controlled components to achieve this. </p><h3 id="1-8-1-Controlled-Components-–-Form"><a href="#1-8-1-Controlled-Components-–-Form" class="headerlink" title="1.8.1 Controlled Components – Form"></a>1.8.1 Controlled Components – Form</h3><p>In HTML, input, textaream select typically <strong>maintain their own state and update it based on user input</strong>. In React, mutable state is typically kept in the state property of components, and only updated with <code>setState()</code>.</p><pre><code>class NameForm extends React.Component {  constructor(props) {    super(props);    this.state = {value: &#39;&#39;};    this.handleChange = this.handleChange.bind(this);    this.handleSubmit = this.handleSubmit.bind(this);  }  handleChange(event) {    this.setState({value: event.target.value});  }  handleSubmit(event) {    alert(&#39;A name was submitted: &#39; + this.state.value);    event.preventDefault();  }  render() {    return (      &lt;form onSubmit={this.handleSubmit}&gt;        &lt;label&gt;          Name:          &lt;input type=&quot;text&quot; value={this.state.value} onChange={this.handleChange} /&gt;        &lt;/label&gt;        &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;      &lt;/form&gt;    );  }}</code></pre><p>Controlled Component, in this way, use <code>state</code> in React to control the change of text. With a controlled component, <strong><em>every state mutaion will have an associated handler function</em></strong>, This makes it straightforward to modify or validate user input. </p><h3 id="1-8-2-Controlled-Components-–-textarea"><a href="#1-8-2-Controlled-Components-–-textarea" class="headerlink" title="1.8.2 Controlled Components – textarea"></a>1.8.2 Controlled Components – textarea</h3><pre><code>class EssayForm extends React.Component {  constructor(props) {    super(props);    this.state = {      value: &#39;Please write an essay about your favorite DOM element.&#39;    };    this.handleChange = this.handleChange.bind(this);    this.handleSubmit = this.handleSubmit.bind(this);  }  handleChange(event) {    this.setState({value: event.target.value});  }  handleSubmit(event) {    alert(&#39;An essay was submitted: &#39; + this.state.value);    event.preventDefault();  }  render() {    return (      &lt;form onSubmit={this.handleSubmit}&gt;        &lt;label&gt;          Essay:          &lt;textarea value={this.state.value} onChange={this.handleChange} /&gt;        &lt;/label&gt;        &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;      &lt;/form&gt;    );  }}</code></pre><p>Have the value property, and associate it with state. change it by handler function, and deal with it with a chain of handlers. </p><h3 id="1-8-3-Controlled-Components-–-select"><a href="#1-8-3-Controlled-Components-–-select" class="headerlink" title="1.8.3 Controlled Components – select"></a>1.8.3 Controlled Components – select</h3><pre><code>&lt;select&gt;  &lt;option value=&quot;grapefruit&quot;&gt;Grapefruit&lt;/option&gt;  &lt;option value=&quot;lime&quot;&gt;Lime&lt;/option&gt;  &lt;option selected value=&quot;coconut&quot;&gt;Coconut&lt;/option&gt;  &lt;option value=&quot;mango&quot;&gt;Mango&lt;/option&gt;&lt;/select&gt;</code></pre><p>coconut has been selected with the selected property </p><pre><code>class FlavorForm extends React.Component {  constructor(props) {    super(props);    this.state = {value: &#39;coconut&#39;};    this.handleChange = this.handleChange.bind(this);    this.handleSubmit = this.handleSubmit.bind(this);  }  handleChange(event) {    this.setState({value: event.target.value});  }  handleSubmit(event) {    alert(&#39;Your favorite flavor is: &#39; + this.state.value);    event.preventDefault();  }  render() {    return (      &lt;form onSubmit={this.handleSubmit}&gt;        &lt;label&gt;          Pick your favorite flavor:          &lt;select value={this.state.value} onChange={this.handleChange}&gt;            &lt;option value=&quot;grapefruit&quot;&gt;Grapefruit&lt;/option&gt;            &lt;option value=&quot;lime&quot;&gt;Lime&lt;/option&gt;            &lt;option value=&quot;coconut&quot;&gt;Coconut&lt;/option&gt;            &lt;option value=&quot;mango&quot;&gt;Mango&lt;/option&gt;          &lt;/select&gt;        &lt;/label&gt;        &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;      &lt;/form&gt;    );  }}</code></pre><p>By setting the start state as cconut, we realize the same function as you see in the HTML part. But come to be more extenable since when we want to change its states, we only need to change this component’s state. </p><h3 id="1-8-4-Handling-multiple-inputs"><a href="#1-8-4-Handling-multiple-inputs" class="headerlink" title="1.8.4 Handling multiple inputs"></a>1.8.4 Handling multiple inputs</h3><p>when need to handle multiple controlled input elements, you can add a name attribute to each element and let the handler function choose what to do based on the value of <code>event.target.name</code>.</p><pre><code>class Reservation extends React.Component {  constructor(props) {    super(props);    this.state = {      isGoing: true,      numberOfGuests: 2    };    this.handleInputChange = this.handleInputChange.bind(this);  }  handleInputChange(event) {    const target = event.target;    const value = target.type === &#39;checkbox&#39; ? target.checked : target.value;    const name = target.name;    this.setState({      [name]: value    });  }  render() {    return (      &lt;form&gt;        &lt;label&gt;          Is going:          &lt;input            name=&quot;isGoing&quot;            type=&quot;checkbox&quot;            checked={this.state.isGoing}            onChange={this.handleInputChange} /&gt;        &lt;/label&gt;        &lt;br /&gt;        &lt;label&gt;          Number of guests:          &lt;input            name=&quot;numberOfGuests&quot;            type=&quot;number&quot;            value={this.state.numberOfGuests}            onChange={this.handleInputChange} /&gt;        &lt;/label&gt;      &lt;/form&gt;    );  }}</code></pre><p><code>handleInputChange</code> here controls two input, one is a checkbox, another is a scrolled banner. That’s the reason we need to judge target type in function. However, I do think there is no need to combine those two sub component, and use one handler function, at least in this example. </p><blockquote><p>Notice: in <code>setState</code>, we use <code>[name] : value</code>. It’s because <strong><em>name is a computed property, [] means need to compute here</em></strong>. </p></blockquote><h2 id="1-9-Lifting-state-up"><a href="#1-9-Lifting-state-up" class="headerlink" title="1.9 Lifting state up"></a>1.9 Lifting state up</h2><p>Happen when several components need to reflext the same changing data. Need to lifting the shared state up to their closest common ancestor. </p><pre><code>const scaleNames = {  c: &#39;Celsius&#39;,  f: &#39;Fahrenheit&#39;};function toCelsius(fahrenheit) {  return (fahrenheit - 32) * 5 / 9;}function toFahrenheit(celsius) {  return (celsius * 9 / 5) + 32;}function tryConvert(temperature, convert) {  const input = parseFloat(temperature);  if (Number.isNaN(input)) {    return &#39;&#39;;  }  const output = convert(input);  const rounded = Math.round(output * 1000) / 1000;  return rounded.toString();}function BoilingVerdict(props) {  if (props.celsius &gt;= 100) {    return &lt;p&gt;The water would boil.&lt;/p&gt;;  }  return &lt;p&gt;The water would not boil.&lt;/p&gt;;}class TemperatureInput extends React.Component {  constructor(props) {    super(props);    this.handleChange = this.handleChange.bind(this);  }  handleChange(e) {    this.props.onTemperatureChange(e.target.value);  }  render() {    const temperature = this.props.temperature;    const scale = this.props.scale;    return (      &lt;fieldset&gt;        &lt;legend&gt;Enter temperature in {scaleNames[scale]}:&lt;/legend&gt;        &lt;input value={temperature}               onChange={this.handleChange} /&gt;      &lt;/fieldset&gt;    );  }}class Calculator extends React.Component {  constructor(props) {    super(props);    this.handleCelsiusChange = this.handleCelsiusChange.bind(this);    this.handleFahrenheitChange = this.handleFahrenheitChange.bind(this);    this.state = {temperature: &#39;&#39;, scale: &#39;c&#39;};  }  handleCelsiusChange(temperature) {    this.setState({scale: &#39;c&#39;, temperature});  }  handleFahrenheitChange(temperature) {    this.setState({scale: &#39;f&#39;, temperature});  }  render() {    const scale = this.state.scale;    const temperature = this.state.temperature;    const celsius = scale === &#39;f&#39; ? tryConvert(temperature, toCelsius) : temperature;    const fahrenheit = scale === &#39;c&#39; ? tryConvert(temperature, toFahrenheit) : temperature;    return (      &lt;div&gt;        &lt;TemperatureInput          scale=&quot;c&quot;          temperature={celsius}          onTemperatureChange={this.handleCelsiusChange} /&gt;        &lt;TemperatureInput          scale=&quot;f&quot;          temperature={fahrenheit}          onTemperatureChange={this.handleFahrenheitChange} /&gt;        &lt;BoilingVerdict          celsius={parseFloat(celsius)} /&gt;      &lt;/div&gt;    );  }}ReactDOM.render(  &lt;Calculator /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><ol><li>Lifting state, React calls the function specified as onChange on the DOM <input>. In our case, this is the handleChange method in the TemperatureInput component.</li><li>The handleChange method in the TemperatureInput component calls <strong>this.props.onTemperatureChange()</strong> with the new desired value. Its props, including onTemperatureChange, were provided by its parent component, the Calculator.</li><li>When it previously rendered, the Calculator has specified that onTemperatureChange of the Celsius TemperatureInput is the Calculator’s handleCelsiusChange method, and onTemperatureChange of the Fahrenheit TemperatureInput is the Calculator’s handleFahrenheitChange method. So either of these two Calculator methods gets called depending on which input we edited.</li><li>Inside these methods, the Calculator component asks React to re-render itself by calling this.setState() with the new input value and the current scale of the input we just edited.</li><li>React calls the Calculator component’s render method to learn what the UI should look like. The values of both inputs are recomputed based on the current temperature and the active scale. The temperature conversion is performed here.</li><li>React calls the render methods of the individual TemperatureInput components with their new props specified by the Calculator. It learns what their UI should look like.</li><li>React calls the render method of the BoilingVerdict component, passing the temperature in Celsius as its props.</li><li>React DOM updates the DOM with the boiling verdict and to match the desired input values. The input we just edited receives its current value, and the other input is updated to the temperature after conversion.</li></ol><p>Usually, the state is first added to the component that needs it for rendering, Then it other components also need it, you can lift it up to their closest common ancestor. </p><h2 id="1-10-Compisition-vs-Inheritance"><a href="#1-10-Compisition-vs-Inheritance" class="headerlink" title="1.10 Compisition vs Inheritance"></a>1.10 Compisition vs Inheritance</h2><p>React has a powerful composition model, and we recommend <strong>using composition</strong> instead of inheritance to <strong>reuse code</strong> between components. </p><h3 id="1-10-1-Containment"><a href="#1-10-1-Containment" class="headerlink" title="1.10.1 Containment"></a>1.10.1 Containment</h3><p>Some component don’t know their children ahead of time. This is especially common for components like SideBar or Dialog that represent generic boxes. </p><p>We can use <code>children</code> props to pass children elements derectly into their output. </p><pre><code>function FancyBorder(props) {  return (    &lt;div className={&#39;FancyBorder FancyBorder-&#39; + props.color}&gt;      {props.children}    &lt;/div&gt;  );}function WelcomeDialog() {  return (    &lt;FancyBorder color=&quot;blue&quot;&gt;      &lt;h1 className=&quot;Dialog-title&quot;&gt;        Welcome      &lt;/h1&gt;      &lt;p className=&quot;Dialog-message&quot;&gt;        Thank you for visiting our spacecraft!      &lt;/p&gt;    &lt;/FancyBorder&gt;  );}</code></pre><p>Anything inside the <code>&lt;FancyBorder&gt;</code> JSX tag gets passed into the FancyBorder component as a children prop. Since FancyBorder renders <code>{props.children}</code> inside a <code>&lt;div&gt;</code>, then passed elements appear in the final output. </p><p>And also, we can use your own props and pass it inside. </p><pre><code>function SplitPane(props) {  return (    &lt;div className=&quot;SplitPane&quot;&gt;      &lt;div className=&quot;SplitPane-left&quot;&gt;        {props.left}      &lt;/div&gt;      &lt;div className=&quot;SplitPane-right&quot;&gt;        {props.right}      &lt;/div&gt;    &lt;/div&gt;  );}function App() {  return (    &lt;SplitPane      left={        &lt;Contacts /&gt;      }      right={        &lt;Chat /&gt;      } /&gt;  );}</code></pre><h3 id="1-10-2-Specialization"><a href="#1-10-2-Specialization" class="headerlink" title="1.10.2 Specialization"></a>1.10.2 Specialization</h3><p>A more specific component renders a more generic one and configures it with props: </p><pre><code>function Dialog(props) {  return (    &lt;FancyBorder color=&quot;blue&quot;&gt;      &lt;h1 className=&quot;Dialog-title&quot;&gt;        {props.title}      &lt;/h1&gt;      &lt;p className=&quot;Dialog-message&quot;&gt;        {props.message}      &lt;/p&gt;    &lt;/FancyBorder&gt;  );}function WelcomeDialog() {  return (    &lt;Dialog      title=&quot;Welcome&quot;      message=&quot;Thank you for visiting our spacecraft!&quot; /&gt;  );</code></pre><h3 id="1-10-3-Example"><a href="#1-10-3-Example" class="headerlink" title="1.10.3 Example"></a>1.10.3 Example</h3><pre><code>function Dialog(props) {  return (    &lt;FancyBorder color=&quot;blue&quot;&gt;      &lt;h1 className=&quot;Dialog-title&quot;&gt;        {props.title}      &lt;/h1&gt;      &lt;p className=&quot;Dialog-message&quot;&gt;        {props.message}      &lt;/p&gt;      {props.children}    &lt;/FancyBorder&gt;  );}class SignUpDialog extends React.Component {  constructor(props) {    super(props);    this.handleChange = this.handleChange.bind(this);    this.handleSignUp = this.handleSignUp.bind(this);        this.state = {login: &#39;&#39;};      }      render() {        return (          &lt;Dialog title=&quot;Mars Exploration Program&quot;                  message=&quot;How should we refer to you?&quot;&gt;            &lt;input value={this.state.login}                   onChange={this.handleChange} /&gt;            &lt;button onClick={this.handleSignUp}&gt;              Sign Me Up!            &lt;/button&gt;          &lt;/Dialog&gt;        );      }      handleChange(e) {        this.setState({login: e.target.value});      }      handleSignUp() {        alert(`Welcome aboard, ${this.state.login}!`);      }    }</code></pre><h1 id="2-Thinking-How-to-build-an-product-from-scratch"><a href="#2-Thinking-How-to-build-an-product-from-scratch" class="headerlink" title="2. Thinking - How to build an product from scratch"></a>2. Thinking - How to build an product from scratch</h1><ol><li><p>Start with a mock: UI + Json API</p></li><li><p>Break the UI into a Component Hierarchy </p></li><li><p>Separate to different components, following <strong><em>single responsibility principle</em></strong>. A component should ideally only do one thing. </p></li><li><p>Build a static version in react </p><ul><li>decouple styling and interactivity </li><li>static version always use props, since state is reserved only for interactivity </li><li>Larger project, easier bottom up. </li><li>Don’t repeat yourself</li></ul></li><li><p>Identify the minimal representation of UI state</p><ul><li>Is it passed in from a parent via props? If so, it probably isn’t state.</li><li>Does it remain unchanged over time? If so, it probably isn’t state.</li><li>Can you compute it based on any other state or props in your component? If so, it isn’t state.</li></ul></li><li><p>Idenfify where your state should live </p></li></ol><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://reactjs.org/docs/hello-world.html" target="_blank" rel="noopener">REACT DOC</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pupperteer Tutorial</title>
      <link href="/Pupperteer-Tutorial/"/>
      <url>/Pupperteer-Tutorial/</url>
      
        <content type="html"><![CDATA[<p>This post is merely some notes when I learnt pupperteer, basically contain similar info from google developer webpage. Try to organize those info in a personal understandable way here. </p><h1 id="1-What-is-Pupperteer"><a href="#1-What-is-Pupperteer" class="headerlink" title="1. What is Pupperteer"></a>1. What is Pupperteer</h1><p>Most thins you can do manually in the browser now can be done with puppeteer. </p><h1 id="2-Usage"><a href="#2-Usage" class="headerlink" title="2. Usage"></a>2. Usage</h1><h2 id="2-1-General"><a href="#2-1-General" class="headerlink" title="2.1 General"></a>2.1 General</h2><ul><li>Create an instance of Browser </li><li>Open pages </li><li>manipulate them with Puppeteer’s API </li></ul><h1 id="3-Learn-by-doing"><a href="#3-Learn-by-doing" class="headerlink" title="3. Learn by doing"></a>3. Learn by doing</h1><h2 id="3-1-See-an-example-to-learn-how-the-thing-works"><a href="#3-1-See-an-example-to-learn-how-the-thing-works" class="headerlink" title="3.1 See an example to learn how the thing works"></a>3.1 See an example to learn how the thing works</h2><pre><code>/** * Copyright 2018 Google Inc. All rights reserved. * * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * * @author ebidel@ (Eric Bidelman) *//** * Takes a screenshot of the latest tweet in a user&#39;s timeline and creates a * PDF of it. Shows how to use Puppeteer to: * *   1. screenshot a DOM element *   2. craft an HTML page on-the-fly *   3. produce an image of the element and PDF of the page with the image embedded * * Usage: *   node element-to-pdf.js *   USERNAME=ChromiumDev node element-to-pdf.js * *   --searchable makes &quot;find in page&quot; work: *   node element-to-pdf.js --searchable * * Output: *   tweet.png and tweet.pdf */// Include modules that exist in separate files, basically it reads a js file, executes the // file and then proceed to return the exports object const puppeteer = require(&#39;puppeteer&#39;);// process.env is a global variable, injected by node at runtime // represent the state of the system environment application // it will try to get from process env, if cannot get there, will fallback to default// here, means fallback to &#39;ebidel&#39;const username = process.env.USERNAME || &#39;ebidel&#39;;const searchable = process.argv.includes(&#39;--searchable&#39;);(async() =&gt; {// launch a chromium instance const browser = await puppeteer.launch();// launch a new page const page = await browser.newPage();// set a screen size await page.setViewport({width: 1200, height: 800, deviceScaleFactor: 2});await page.goto(`https://twitter.com/${username}`);// Can&#39;t use elementHandle.click() because it clicks the center of the element// with the mouse. On tweets like https://twitter.com/ebidel/status/915996563234631680// there is an embedded card link to another tweet that it clicks.// find the component, and do some function thereawait page.$eval(`.tweet[data-screen-name=&quot;${username}&quot;]`, tweet =&gt; tweet.click());// wait for it to be availableawait page.waitForSelector(&#39;.tweet.permalink-tweet&#39;, {visible: true});// run document.querySelector within the page. If no element matches the selector, return // value will be resolved to nullconst overlay = await page.$(&#39;.tweet.permalink-tweet&#39;);const screenshot = await overlay.screenshot({path: &#39;tweet.png&#39;});if (searchable) {  await page.evaluate(tweet =&gt; {    const width = getComputedStyle(tweet).width;    tweet = tweet.cloneNode(true);    tweet.style.width = width;    document.body.innerHTML = `      &lt;div style=&quot;display:flex;justify-content:center;align-items:center;height:100vh;&quot;&gt;;        ${tweet.outerHTML}      &lt;/div&gt;    `;  }, overlay);} else {  await page.setContent(`    &lt;!DOCTYPE html&gt;    &lt;html&gt;      &lt;head&gt;        &lt;style&gt;          html, body {            height: 100vh;            margin: 0;            display: flex;            justify-content: center;            align-items: center;            background: #fafafa;          }          img {            max-width: 60%;            box-shadow: 3px 3px 6px #eee;            border-radius: 6px;          }        &lt;/style&gt;      &lt;/head&gt;      &lt;body&gt;        &lt;img src=&quot;data:img/png;base64,${screenshot.toString(&#39;base64&#39;)}&quot;&gt;      &lt;/body&gt;    &lt;/html&gt;  `);}await page.pdf({path: &#39;tweet.pdf&#39;, printBackground: true});await browser.close();})();</code></pre><h2 id="3-2-crawlsite-js"><a href="#3-2-crawlsite-js" class="headerlink" title="3.2 crawlsite.js"></a>3.2 crawlsite.js</h2><pre><code>/** * Copyright 2018 Google Inc. All rights reserved. * * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * *     http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. * * @author ebidel@ (Eric Bidelman) */ /**  * Discovers all the pages in site or single page app (SPA) and creates  * a tree of the result in ./output/&lt;site slug/crawl.json. Optionally  * takes screenshots of each page as it is visited.  *  * Usage:  *   node crawlsite.js  *   URL=https://yourspa.com node crawlsite.js  *   URL=https://yourspa.com node crawlsite.js --screenshots  *  * Then open the visualizer in a browser:  *   http://localhost:8080/html/d3tree.html  *   http://localhost:8080/html/d3tree.html?url=../output/https___yourspa.com/crawl.json  *  *Start Server:  *   node server.js  *  */// provides an API for interacting with the file system const fs = require(&#39;fs&#39;);// delete files const del = require(&#39;del&#39;);// nodeJS util moduleconst util = require(&#39;util&#39;);const puppeteer = require(&#39;puppeteer&#39;);// high performance Node.js image proccessing, fastest module to resize JPEG, PNG, etc. const sharp = require(&#39;sharp&#39;);const URL = process.env.URL || &#39;https://news.polymer-project.org/&#39;;const SCREENSHOTS = process.argv.includes(&#39;--screenshots&#39;);const DEPTH = parseInt(process.env.DEPTH) || 2;const VIEWPORT = SCREENSHOTS ? {width: 1028, height: 800, deviceScaleFactor: 2} : null;const OUT_DIR = process.env.OUTDIR || `output/${slugify(URL)}`;const crawledPages = new Map();const maxDepth = DEPTH; // Subpage depth to crawl site.function slugify(str) {  return str.replace(/[\/:]/g, &#39;_&#39;);}function mkdirSync(dirPath) {  try {    dirPath.split(&#39;/&#39;).reduce((parentPath, dirName) =&gt; {      const currentPath = parentPath + dirName;      if (!fs.existsSync(currentPath)) {        fs.mkdirSync(currentPath);      }      return currentPath + &#39;/&#39;;    }, &#39;&#39;);  } catch (err) {    if (err.code !== &#39;EEXIST&#39;) {      throw err;    }  }}/** * Finds all anchors on the page, inclusive of those within shadow roots. * Note: Intended to be run in the context of the page. * @param {boolean=} sameOrigin When true, only considers links from the same origin as the app. * @return {!Array&lt;string&gt;} List of anchor hrefs. */function collectAllSameOriginAnchorsDeep(sameOrigin = true) {  const allElements = [];  const findAllElements = function(nodes) {    for (let i = 0, el; el = nodes[i]; ++i) {      allElements.push(el);      // If the element has a shadow root, dig deeper.      if (el.shadowRoot) {        findAllElements(el.shadowRoot.querySelectorAll(&#39;*&#39;));      }    }  };  findAllElements(document.querySelectorAll(&#39;*&#39;));  const filtered = allElements    .filter(el =&gt; el.localName === &#39;a&#39; &amp;&amp; el.href) // element is an anchor with an href.    .filter(el =&gt; el.href !== location.href) // link doesn&#39;t point to page&#39;s own URL.    .filter(el =&gt; {      if (sameOrigin) {        return new URL(location).origin === new URL(el.href).origin;      }      return true;    })    .map(a =&gt; a.href);  return Array.from(new Set(filtered));}/** * Crawls a URL by visiting an url, then recursively visiting any child subpages. * @param {!Browser} browser * @param {{url: string, title: string, img?: string, children: !Array<!Object>}} page Current page. * @param {number=} depth Current subtree depth of crawl. */async function crawl(browser, page, depth = 0) {  if (depth &gt; maxDepth) {    return;  }  // If we&#39;ve already crawled the URL, we know its children.  if (crawledPages.has(page.url)) {    console.log(`Reusing route: ${page.url}`);    const item = crawledPages.get(page.url);    page.title = item.title;    page.img = item.img;    page.children = item.children;    // Fill in the children with details (if they already exist).    page.children.forEach(c =&gt; {      const item = crawledPages.get(c.url);      c.title = item ? item.title : &#39;&#39;;      c.img = item ? item.img : null;    });    return;  } else {    console.log(`Loading: ${page.url}`);    const newPage = await browser.newPage();    await newPage.goto(page.url, {waitUntil: &#39;networkidle2&#39;});    let anchors = await newPage.evaluate(collectAllSameOriginAnchorsDeep);    anchors = anchors.filter(a =&gt; a !== URL) // link doesn&#39;t point to start url of crawl.    page.title = await newPage.evaluate(&#39;document.title&#39;);    page.children = anchors.map(url =&gt; ({url}));    if (SCREENSHOTS) {      const path = `./${OUT_DIR}/${slugify(page.url)}.png`;      let imgBuff = await newPage.screenshot({fullPage: false});      imgBuff = await sharp(imgBuff).resize(null, 150).toBuffer(); // resize image to 150 x auto.      util.promisify(fs.writeFile)(path, imgBuff); // async      page.img = `data:img/png;base64,${imgBuff.toString(&#39;base64&#39;)}`;    }    crawledPages.set(page.url, page); // cache it.    await newPage.close();  }  // Crawl subpages.  for (const childPage of page.children) {    await crawl(browser, childPage, depth + 1);  }}(async() =&gt; {mkdirSync(OUT_DIR); // create output dir if it doesn&#39;t exist.await del([`${OUT_DIR}/*`]); // cleanup after last run.const browser = await puppeteer.launch();const page = await browser.newPage();if (VIEWPORT) {  await page.setViewport(VIEWPORT);}const root = {url: URL};await crawl(browser, root);await util.promisify(fs.writeFile)(`./${OUT_DIR}/crawl.json`, JSON.stringify(root, null, &#39; &#39;));await browser.close();})();</code></pre>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> UI Test </tag>
            
            <tag> Puppeteer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NightWatch JavaScript Tutorial</title>
      <link href="/NightWatch-JavaScript-Tutorial/"/>
      <url>/NightWatch-JavaScript-Tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><ul><li>Complete end-to-end testing solition </li><li>written in nodejs and using the WebDriver </li><li>WebDriver <ul><li>Library for automating web browsers  </li><li>A remote control interface that enables intrpspection and controls of user agents. Provides a platform and a restful HTTP api as a way for web browsers to be remotely controlled. </li></ul></li></ul><h1 id="2-How-to-use"><a href="#2-How-to-use" class="headerlink" title="2. How to use"></a>2. How to use</h1><h2 id="2-1-Writing-tests-in-general-way"><a href="#2-1-Writing-tests-in-general-way" class="headerlink" title="2.1 Writing tests in general way"></a>2.1 Writing tests in general way</h2><ul><li>use the preferred CSS selector model to locate elements on a page</li><li>create a separate folder for tests in the project </li></ul><p>E.G we could set couple different steps to interact with the page in multiple ways. </p><pre><code>module.exports = {  &#39;step 1&#39; : function (browser) {    browser      .url(&#39;https://www.google.com&#39;)      .waitForElementVisible(&#39;body&#39;)      .setValue(&#39;input[type=text]&#39;, &#39;nightwatch&#39;)      .waitForElementVisible(&#39;input[name=btnK]&#39;)      .click(&#39;input[name=btnK]&#39;)      .pause(1000)      .assert.containsText(&#39;#main&#39;, &#39;Night Watch&#39;)      .end();  },       &#39;step 2&#39; : function (browser) {        browser          .click(&#39;input[name=btnK]&#39;)          .pause(1000)          .assert.containsText(&#39;#main&#39;, &#39;Night Watch&#39;)          .end();      }};</code></pre><h2 id="2-2-Writing-tests-in-ES6-with-async-await"><a href="#2-2-Writing-tests-in-ES6-with-async-await" class="headerlink" title="2.2 Writing tests in ES6 with async/ await"></a>2.2 Writing tests in ES6 with async/ await</h2><ul><li>improves the readability and ease of writing of tests</li><li>no longer be available to chain the API commands when using an async function </li></ul><pre><code>module.exports = {  &#39;demo test async&#39;: async function (browser) {    // get the available window handles    const result = await browser.windowHandles();    console.log(&#39;result&#39;, result);    // switch to the second window    // await is not necessary here since we&#39;re not interested in the result    browser.switchWindow(result.value[1]);  }};</code></pre><h2 id="2-3-Expect-Assertions"><a href="#2-3-Expect-Assertions" class="headerlink" title="2.3 Expect Assertions"></a>2.3 Expect Assertions</h2><pre><code>module.exports = {  &#39;Demo test Google&#39; : function (browser) {    browser      .url(&#39;https://google.no&#39;)      .pause(1000);    // expect element &lt;body&gt; to be present in 1000ms    browser.expect.element(&#39;body&#39;).to.be.present.before(1000);    // expect element &lt;#lst-ib&gt; to have css property &#39;display&#39;    browser.expect.element(&#39;#lst-ib&#39;).to.have.css(&#39;display&#39;);    // expect element &lt;body&gt; to have attribute &#39;class&#39; which contains text &#39;vasq&#39;    browser.expect.element(&#39;body&#39;).to.have.attribute(&#39;class&#39;).which.contains(&#39;vasq&#39;);    // expect element &lt;#lst-ib&gt; to be an input tag    browser.expect.element(&#39;#lst-ib&#39;).to.be.an(&#39;input&#39;);    // expect element &lt;#lst-ib&gt; to be visible    browser.expect.element(&#39;#lst-ib&#39;).to.be.visible;    browser.end();  }};</code></pre><h2 id="2-4-before-after-beforeEach-afterEach"><a href="#2-4-before-after-beforeEach-afterEach" class="headerlink" title="2.4 before, after, beforeEach, afterEach"></a>2.4 before, after, beforeEach, afterEach</h2><ul><li>standard hook </li><li>before and after will run before and after the test suite</li><li>beforeEach and afterEach will run before and after each test case </li></ul><pre><code>module.exports = {  before : function(browser) {    console.log(&#39;Setting up...&#39;);  },  after : function(browser) {    console.log(&#39;Closing down...&#39;);  },  beforeEach : function(browser) {  },  afterEach : function(browser) {  },  &#39;step one&#39; : function (browser) {    browser     // ...  },  &#39;step two&#39; : function (browser) {    browser    // ...      .end();  }};</code></pre><h2 id="2-5-Controlling-the-done-invocation-timeout"><a href="#2-5-Controlling-the-done-invocation-timeout" class="headerlink" title="2.5 Controlling the done invocation timeout"></a>2.5 Controlling the done invocation timeout</h2><p>Increase the timeout by defining an <code>ayncHootTimeout</code> property in the external globals file. We should set a global module somewhere for all to use </p><p><a href="https://github.com/nightwatchjs/nightwatch/blob/master/examples/globalsModule.js#L20" target="_blank" rel="noopener">globalModule</a></p><h2 id="2-6-Test-Env"><a href="#2-6-Test-Env" class="headerlink" title="2.6 Test Env"></a>2.6 Test Env</h2><ul><li>we could define multiple sections of test settings so you could overwrite specific values per env. </li></ul><pre><code>{  ...  &quot;test_settings&quot; : {    &quot;default&quot; : {      &quot;launch_url&quot; : &quot;http://localhost&quot;,      &quot;globals&quot; : {        &quot;myGlobalVar&quot; : &quot;some value&quot;,        &quot;otherGlobal&quot; : &quot;some other value&quot;      }    },    &quot;integration&quot; : {      &quot;launch_url&quot; : &quot;http://staging.host&quot;,      &quot;globals&quot; : {        &quot;myGlobalVar&quot; : &quot;other value&quot;      }    }  }}</code></pre><h2 id="2-7-Test-Groups"><a href="#2-7-Test-Groups" class="headerlink" title="2.7 Test Groups"></a>2.7 Test Groups</h2><ul><li>we could organize test into groups and run tem as needed.</li><li>just place them in sub-folders if you want to run them together.</li></ul><h2 id="2-8-Using-Page-Objects"><a href="#2-8-Using-Page-Objects" class="headerlink" title="2.8 Using Page Objects"></a>2.8 Using Page Objects</h2><ul><li>Wrap the pages or page fragments of a web app into objects. </li><li>Allow a software client to do anything and see anything that a human can be abstracting away the underlying html actions needed to access and manipulate the page </li><li>page objects are read from the folder specified in the <code>page_objects_path</code> configuration property</li></ul><h2 id="2-9-Define-Elements"><a href="#2-9-Define-Elements" class="headerlink" title="2.9 Define Elements"></a>2.9 Define Elements</h2><pre><code>module.exports = {  elements: {    searchBar: {      selector: &#39;input[type=text]&#39;    },    submit: {      selector: &#39;//[@name=&quot;q&quot;]&#39;,      locateStrategy: &#39;xpath&#39;    }  }};</code></pre><ul><li>allow you to refer to the element by its name with an “@” prefix, rather than selector</li></ul><h3 id="2-9-1-Element-Properties"><a href="#2-9-1-Element-Properties" class="headerlink" title="2.9.1 Element Properties"></a>2.9.1 Element Properties</h3><p>An element can be specified as an object with <code>selector</code> property</p><ul><li>selector  </li><li>localeStrategy  ‘css’</li><li>index <ul><li>used to target a specific element in a query that results in multiple elements returned</li></ul></li><li>abortOnFailure</li><li>timeout </li><li>retryInterval </li><li>suppressNotFoundErrors </li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://nightwatchjs.org/api/#expect-api" target="_blank" rel="noopener">https://nightwatchjs.org/api/#expect-api</a></li><li><a href="https://nightwatchjs.org/guide" target="_blank" rel="noopener">https://nightwatchjs.org/guide</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> JavaScript </tag>
            
            <tag> NightWatch </tag>
            
            <tag> UI Test </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Typescript Tutorial</title>
      <link href="/Typescript-Tutorial/"/>
      <url>/Typescript-Tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><ul><li>A typed superset of JavaScript that compiles to plain JavaScript</li><li>Pure object oriented with classes, interfaces </li><li>for application scale development </li><li>benefits<ul><li>provides the error checking feature </li><li>will compile the code and generate compilation errors </li><li>strong static typing </li><li>supports type definitions for existing JS libraries<ul><li>TS definition file (with <code>.d.ts</code> extension) provides definition for external JS libraries</li></ul></li></ul></li><li>components<ul><li>language <ul><li>comprises of <ul><li>syntax</li><li>keywords</li><li>type annotations</li></ul></li></ul></li><li>the typeScript Compiler <ul><li>The TypeScript Comiler converts the instructions written in TypeScript to its JavaScript equivalent </li></ul></li><li>the typeScript Language Service<ul><li>expose an additional layer around the core compiler pipeline that are editor-like applications</li><li>language service supports <ul><li>statement completions</li><li>signature help</li><li>code formatting and outlining</li><li>colorization </li></ul></li></ul></li></ul></li><li>declaration files <ul><li>declaration file <ul><li>interface to the components in the compiled javaScript</li><li>analogous to the header files </li></ul></li></ul></li></ul><h1 id="2-Basic-Syntax"><a href="#2-Basic-Syntax" class="headerlink" title="2. Basic Syntax"></a>2. Basic Syntax</h1><ul><li>composed of <ul><li>module </li><li>fucntions </li><li>variables</li><li>statements and expressions</li><li>comments</li></ul></li><li>tsc will translate ts file to js </li><li>ts and oop<ul><li>object <ul><li>state </li><li>behavior </li><li>identity </li></ul></li><li>class</li><li>method</li></ul></li></ul><pre><code>class Greeting {    greet():void {       console.log(&quot;Hello World!!!&quot;)    } } var obj = new Greeting(); obj.greet();</code></pre><h2 id="2-1-Types"><a href="#2-1-Types" class="headerlink" title="2.1 Types"></a>2.1 Types</h2><p>Represents the different types of values supported by the language, The type system checks the validity of the supplied values, before they are stored or manipulated by the program. </p><p>The type system further allows for <strong>richer code hinting</strong> and <strong>automated documentation</strong> too. </p><ul><li>any type<ul><li>super type of all types in TS </li><li>denotes a dynamic type </li><li>use the any type is equivalent to opting out of type checking for a variable </li></ul></li><li>built-in types<ul><li>Number <ul><li>double precision 64 bit floating point values </li></ul></li><li>String <ul><li>a sequence of Unicode characters </li></ul></li><li>Boolean <ul><li>logical values </li></ul></li><li>Void <ul><li>used on function return types to represent non-returning functions </li></ul></li><li>Null <ul><li>represents an intentional absense of an object value </li></ul></li><li>Undefined <ul><li>denotes value given to all uninitialized variables </li></ul></li></ul></li></ul><h2 id="2-2-Variables"><a href="#2-2-Variables" class="headerlink" title="2.2 Variables"></a>2.2 Variables</h2><ul><li>Variable - name space in the memory that stores values.</li><li>acts as a container for values in a program </li><li>use the <code>var</code> keyword to declare variables </li></ul><pre><code>var [identifier] : [type-annotation] = value;</code></pre><h3 id="2-2-1-Type-assertion"><a href="#2-2-1-Type-assertion" class="headerlink" title="2.2.1 Type assertion"></a>2.2.1 Type assertion</h3><ul><li>to change a variable from one type to another </li></ul><pre><code>var str = &#39;1&#39;;var str:number = &lt;number&gt; str;</code></pre><ul><li>if you doesn’t add type for variables, ts will determine the type of the variable on the basis of the value assigned to it</li></ul><h3 id="2-2-2-Variable-Scope"><a href="#2-2-2-Variable-Scope" class="headerlink" title="2.2.2 Variable Scope"></a>2.2.2 Variable Scope</h3><ul><li>global scope<ul><li>declare outside the programming constructs</li><li>can be accessed from anywhere within code</li></ul></li><li>class scope<ul><li>called fields </li><li>are declared within the class but outside the methods </li><li>can be accessed using the object of the class </li></ul></li></ul><pre><code>var global_num = 12          //global variable class Numbers {    num_val = 13;             //class variable    static sval = 10;         //static field    storeNum():void {       var local_num = 14;    //local variable    } } console.log(&quot;Global num: &quot;+global_num)  console.log(Numbers.sval)   //static variable  var obj = new Numbers(); console.log(&quot;Global num: &quot;+obj.num_val) </code></pre><h2 id="2-3-Operators"><a href="#2-3-Operators" class="headerlink" title="2.3 Operators"></a>2.3 Operators</h2><ul><li>Defines some function that will be performed on the data <ul><li>arithmetic operators </li><li>relational operators </li><li>logical operators </li><li>bitwise operators </li><li>assignment operators </li><li>type operators<ul><li>typeof <ul><li>return the type of variable</li></ul></li><li>instance of <ul><li>return the class of an object  </li></ul></li></ul></li></ul></li></ul><h2 id="2-4-Functions"><a href="#2-4-Functions" class="headerlink" title="2.4 Functions"></a>2.4 Functions</h2><ul><li>building blocks of readable, maintainable and reusable code </li><li>organize the program into logical blocks of code </li><li>function declaration tells the compiler about a function’s name, return type, and parameters </li></ul><h3 id="2-4-1-Optional-Parameters"><a href="#2-4-1-Optional-Parameters" class="headerlink" title="2.4.1 Optional Parameters"></a>2.4.1 Optional Parameters</h3><ul><li>Add a question mark to its name indicating as optional </li><li>should be set as the last argument in a function </li></ul><pre><code>function disp_details(id:number,name:string,mail_id?:string) {    console.log(&quot;ID:&quot;, id);    console.log(&quot;Name&quot;,name);    if(mail_id!=undefined)     console.log(&quot;Email Id&quot;,mail_id); }disp_details(123,&quot;John&quot;);disp_details(111,&quot;mary&quot;,&quot;mary@xyz.com&quot;);</code></pre><h3 id="2-4-2-Rest-Parameters"><a href="#2-4-2-Rest-Parameters" class="headerlink" title="2.4.2 Rest Parameters"></a>2.4.2 Rest Parameters</h3><ul><li>not restrict the number of values that you can pass to a function </li><li>values passed in mush be the same type </li><li>parameter is prefixed with three periods , non rest parameters should come before the rest parameter </li><li>a function can have at most one rest parameter </li></ul><pre><code>function addNumbers(...nums:number[]) {    var i;    var sum:number = 0;    for (i = 0; i &lt; nums.length; i++) {        sum += nums[i];    }    console.log(&quot;sum of numbers&quot;, sum);}</code></pre><h3 id="2-4-3-Default-Parameters"><a href="#2-4-3-Default-Parameters" class="headerlink" title="2.4.3 Default Parameters"></a>2.4.3 Default Parameters</h3><ul><li>you could assign paramters with default values  </li></ul><pre><code>function calculate_discount(price:number,rate:number = 0.50) {    var discount = price * rate;    console.log(&quot;Discount Amount: &quot;,discount); } calculate_discount(1000) calculate_discount(1000,0.30)</code></pre><h3 id="2-4-4-Function-Overloads"><a href="#2-4-4-Function-Overloads" class="headerlink" title="2.4.4 Function Overloads"></a>2.4.4 Function Overloads</h3><ul><li>have different data type </li><li>have different number of parameters </li></ul><pre><code>function disp(string):void; function disp(number):void;function disp(n1:number):void; function disp(x:number,y:number):void;function disp(n1:number,s1:string):void; function disp(s:string,n:number):void;</code></pre><h2 id="2-5-Numbers"><a href="#2-5-Numbers" class="headerlink" title="2.5 Numbers"></a>2.5 Numbers</h2><ul><li>Number class acts as a wrapper and enables manipulation of numeric literals as they are objects </li><li><code>var var_name = new Number(value)</code></li><li>property <ul><li>MAX_VALUE</li><li>MIN_VALUE</li><li>NaN</li><li>NEGATIVE_INFINITY</li><li>POSITIVE_INFINITY</li><li>prototype <ul><li>a static property of the Number object </li><li>use the prototype property to assign new properties and methods to the Number object in the current document </li></ul></li><li>constructor <ul><li>returns the function that created this object’s instance</li></ul></li></ul></li><li>method <ul><li>toExponential()</li><li>toFixed()<ul><li>formats a number with a specific number of digits to the right of the decimal </li></ul></li><li>toLocaleString()</li><li>toPrecision()</li><li>toString()</li><li>valueOf() </li></ul></li></ul><h2 id="2-6-Strings"><a href="#2-6-Strings" class="headerlink" title="2.6 Strings"></a>2.6 Strings</h2><ul><li>String objects lets you work with a series of characters.</li><li>Wraps the string primitive data type with a number of helper methods </li><li><code>var var_name = new String(string)</code></li><li>property <ul><li>constructor </li><li>length</li><li>prototype <ul><li>allow you to add properties and methods to an object </li></ul></li></ul></li><li>method<ul><li>charAt()</li><li>charCodeAt()</li><li>concat()</li><li>indexOf()</li><li>lastIndexOf()</li><li>localeCompare()</li><li>match()<ul><li>use to match a regular expression against a string </li></ul></li><li>replace()</li><li>search()</li><li>slice()</li><li>split()</li><li>substr()</li><li>substring()</li><li>toLocaleLowerCase()</li><li>toLocaleUpperCase()</li><li>toString()</li><li>toUpperCase()</li><li>valueOf()</li></ul></li></ul><h2 id="2-7-Arrays"><a href="#2-7-Arrays" class="headerlink" title="2.7 Arrays"></a>2.7 Arrays</h2><ul><li>array is a collection of values of the <strong>same</strong> data type </li><li>features <ul><li>allocates sequential memory blocks </li><li>arrays are static, once initialized cannot be resized </li><li>each memory block represents an array element </li><li>array elements are identified by a unique integer called as the subscript/ index of the element </li><li>should be declared before they are used with <code>var</code></li><li>array element values can be updated or modified but cannot be deleted </li></ul></li></ul><pre><code>var arr_name:number[] = [2,4,6];var arr_name:number[] = new Array(4);</code></pre><ul><li><p>methods</p><ul><li>concat() </li><li>every()<ul><li>return true if every element in this array satisfies the provided testing function </li></ul></li><li>filter()</li><li>forEach()</li><li>indexOf()</li><li>join()</li><li>lastIndexOf()</li><li>map()</li><li>pop()</li><li>push()</li><li>reduce()<ul><li>apply a function simultaneously against two values of the array as to reduce it to a single value - from left to right</li></ul></li><li>reduceRight()<ul><li>from right to left</li></ul></li><li>reverse()</li><li>shift()<ul><li>removes the first element from an array and returns the element </li></ul></li><li>slice()</li><li>some()<ul><li>Returns true if at least one element in this array satisfies the provided testing function </li></ul></li><li>sort()</li><li>splice()<ul><li>add or remove elements from an array </li></ul></li><li>toString()</li><li>unshift()<h2 id="2-8-Tuples"><a href="#2-8-Tuples" class="headerlink" title="2.8 Tuples"></a>2.8 Tuples</h2></li></ul></li><li><p>To store a collection of values of varied types </p></li><li><p>represents a heterogeneous collection of values </p></li></ul><pre><code>// accessing var tuple1 = [10, &quot;hello&quot;];</code></pre><h2 id="2-9-Union"><a href="#2-9-Union" class="headerlink" title="2.9 Union"></a>2.9 Union</h2><ul><li>Give program the ability to combine one or two types </li><li>Union can be used to express a value that can be one of the several types </li><li>two or more types are combined with <code>|</code></li></ul><h1 id="3-OOP-related"><a href="#3-OOP-related" class="headerlink" title="3. OOP related"></a>3. OOP related</h1><h2 id="3-1-Interfaces"><a href="#3-1-Interfaces" class="headerlink" title="3.1 Interfaces"></a>3.1 Interfaces</h2><p>An interface defines the syntex that any entity must adhere to.</p><ul><li>Interface define properties, methods and events</li><li>only contain the decalration of the members </li><li>responsibility of the deriving class to define the members </li></ul><pre><code>interface IPerson {    firstName:string,    lastName:string,    sayHi: ()=&gt;string } var customer:IPerson = {    firstName:&quot;Tom&quot;,   lastName:&quot;Hanks&quot;,    sayHi: ():string =&gt;{return &quot;Hi there&quot;} } console.log(&quot;Customer Object &quot;) console.log(customer.firstName) console.log(customer.lastName) console.log(customer.sayHi())  var employee:IPerson = {    firstName:&quot;Jim&quot;,   lastName:&quot;Blakes&quot;,    sayHi: ():string =&gt;{return &quot;Hello!!!&quot;} } console.log(&quot;Employee  Object &quot;) console.log(employee.firstName);console.log(employee.lastName);</code></pre><ul><li>An interface can be extended by other interfaces </li><li>an interface can inherit from other interface </li></ul><pre><code>interface Person {    age:number } interface Musician extends Person {    instrument:string } var drummer = &lt;Musician&gt;{}; drummer.age = 27 drummer.instrument = &quot;Drums&quot; console.log(&quot;Age:  &quot;+drummer.age) console.log(&quot;Instrument:  &quot;+drummer.instrument)</code></pre><h2 id="3-2-Classes"><a href="#3-2-Classes" class="headerlink" title="3.2 Classes"></a>3.2 Classes</h2><ul><li>Object oriented JavaScript </li><li>class can contain<ul><li>fields</li><li>constructors </li><li>functions </li></ul></li><li>class Inheritance <ul><li>create new class from an existing one </li><li>the class that is extended to create newer classes is called the parent class/ super class </li><li>child class inherit all properties and methods except private members and constructors from the parent class </li></ul></li><li>data hiding <ul><li>public </li><li>private <ul><li>only accessible within the class that defines these members  </li></ul></li><li>protected <ul><li>A protected data member is accessible by the members within the same class as that of the former and also by the members of the child classes.</li></ul></li></ul></li></ul><h2 id="3-3-Objects"><a href="#3-3-Objects" class="headerlink" title="3.3 Objects"></a>3.3 Objects</h2><ul><li>Object is an instance which contains set of key value pairs</li><li>the values can be scalar values or functions or even array of other objects </li></ul><h2 id="3-4-namespace"><a href="#3-4-namespace" class="headerlink" title="3.4 namespace"></a>3.4 namespace</h2><ul><li>a way to logically group related code </li><li>resolve the possibility of overwriting or miscontrucing the same variables </li></ul><pre><code>namespace SomeNameSpaceName {    export interface ISomeInterfaceName {      }     export class SomeClassName {      }  } </code></pre><ul><li>marked classes or interfaces with keyword export to indicate they should be accessed outside the namespace </li></ul><h2 id="3-5-Modules"><a href="#3-5-Modules" class="headerlink" title="3.5 Modules"></a>3.5 Modules</h2><p>Module is designed to organize code written in typeScript. Divided into Internal Modules and External Modules. </p><ul><li>Internal Modules<ul><li>logically group classes, interfaces, functions into one unit and can be exported in another module </li><li>now it names namespace in new version of ts</li></ul></li><li>External Module <ul><li>exist to specify and load dependencies between multiple external js files  </li></ul></li></ul><h3 id="3-5-1-Selecting-a-Module-Loader"><a href="#3-5-1-Selecting-a-Module-Loader" class="headerlink" title="3.5.1 Selecting a Module Loader"></a>3.5.1 Selecting a Module Loader</h3><ul><li>for browser <ul><li>RequireJS <ul><li>an implementation of AMD (asynchronous module definition) specification </li><li>AMD can load js files all separately </li></ul></li></ul></li></ul><h3 id="3-5-2-Defining-external-Module"><a href="#3-5-2-Defining-external-Module" class="headerlink" title="3.5.2 Defining external Module"></a>3.5.2 Defining external Module</h3><p>syntax for declaring an external module is using keyword export and import </p><h2 id="3-6-Ambient"><a href="#3-6-Ambient" class="headerlink" title="3.6 Ambient"></a>3.6 Ambient</h2><ul><li>tell the TS compiler that the actual source code exists elsewhere </li><li>kept in extension <code>d.ts</code></li><li>When you are consuming a bunch of third party js libraries like jquery/angularjs/nodejs you can’t rewrite it in TypeScript.</li></ul>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> TypeScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript 教程 - part 3</title>
      <link href="/JavaScript-%E6%95%99%E7%A8%8B-part-3/"/>
      <url>/JavaScript-%E6%95%99%E7%A8%8B-part-3/</url>
      
        <content type="html"><![CDATA[<h1 id="1-事件"><a href="#1-事件" class="headerlink" title="1. 事件"></a>1. 事件</h1><h2 id="1-1-EventTarget-接口"><a href="#1-1-EventTarget-接口" class="headerlink" title="1.1 EventTarget 接口"></a>1.1 EventTarget 接口</h2><p>事件本质是程序各个组成部分之间的一种通信方式。DOM的事件触发都定义在EventTarget接口当中，所有节点对象都部署了这个接口 </p><p>该接口主要提供了三个实例方法: </p><ul><li>addEventListener  绑定事件的监听函数</li><li>removeEventListener 移除事件的监听函数</li><li>dispatchEvent  触发事件</li></ul><h3 id="1-1-1-EventTarget-addEventListener"><a href="#1-1-1-EventTarget-addEventListener" class="headerlink" title="1.1.1 EventTarget.addEventListener()"></a>1.1.1 EventTarget.addEventListener()</h3><ul><li>用于在当前节点或对象上，定义一个特定的时间的监听函数，一旦这个事件发生，就会执行监听函数</li><li>没有返回值</li><li><code>target.addEventListener(type, listener, [useCapture])</code><ul><li>type 事件名称</li><li>listener  监听函数  事件发生，就调用这个监听函数</li><li>useCapture  表示监听函数是否在捕获阶段触发，默认为false (只在冒泡阶段被触发)<ul><li>捕获指的是事件从最外层开始发生，直到最具体的元素</li><li>冒泡指从最内层开始发生</li></ul></li><li>第三个参数 – 是个属性配置对象，即除了useCapture 你还可以配置很多其他属性的<ul><li>capture  是否在捕获阶段触发监听函数</li><li>once  是否只触发一次，然后就自动移除</li><li>passive  表示监听函数不会调用事件的preventDefault方法，如果监听函数调用了，浏览器就会忽略这个要求，并在监控台上输出一行警告</li></ul></li></ul></li></ul><pre><code>function hello() {  console.log(&#39;Hello world&#39;);}var button = document.getElementById(&#39;btn&#39;);button.addEventListener(&#39;click&#39;, hello, false);</code></pre><h3 id="1-1-2-EventTarget-removeEventListener"><a href="#1-1-2-EventTarget-removeEventListener" class="headerlink" title="1.1.2 EventTarget.removeEventListener()"></a>1.1.2 EventTarget.removeEventListener()</h3><p>用来移除addEventListener方法添加的事件监听函数，该方法没有返回值。</p><ul><li>removeEnventListener方法移除的监听函数必须是addEventListener方法已经添加过得，而且必须在同一个元素节点上，否则无效</li></ul><h3 id="1-1-3-EventTarget-dispatchEvent"><a href="#1-1-3-EventTarget-dispatchEvent" class="headerlink" title="1.1.3 EventTarget.dispatchEvent()"></a>1.1.3 EventTarget.dispatchEvent()</h3><ul><li>在当前节点触发指定事件，从而触发监听函数的执行  返回一个布尔值</li><li>只要有一个监听函数调用了<code>Event.preventDefault()</code>,返回值为false，否则为true</li></ul><pre><code>para.addEventListener(&#39;click&#39;, hello, false);var event = new Event(&#39;click&#39;);para.dispatchEvent(event);</code></pre><h2 id="1-2-事件模型"><a href="#1-2-事件模型" class="headerlink" title="1.2 事件模型"></a>1.2 事件模型</h2><p>这一部分想要解决的问题是JS作为使用事件驱动编程模式(event-driven)的编程语言，是怎么样给事件绑定监听函数的。</p><h3 id="1-2-1-绑定监听函数"><a href="#1-2-1-绑定监听函数" class="headerlink" title="1.2.1 绑定监听函数"></a>1.2.1 绑定监听函数</h3><h4 id="1-2-1-1-使用html-on属性"><a href="#1-2-1-1-使用html-on属性" class="headerlink" title="1.2.1.1 使用html on属性"></a>1.2.1.1 使用html on属性</h4><p>HTML允许在元素属性当中，直接定义某些事件的监听代码</p><pre><code>&lt;body onload=&quot;doSomething()&quot;&gt;</code></pre><ul><li>元素的监听属性，都是on加上事件名</li><li>属性的值为将要执行的代码，单单函数名是不被允许的</li><li>该种方式的监听代码，只会在<strong>冒泡阶段被触发</strong></li></ul><pre><code>// 先输出1 再输出2&lt;div onClick=&quot;console.log(2)&quot;&gt;  &lt;button onClick=&quot;console.log(1)&quot;&gt;点击&lt;/button&gt;&lt;/div&gt;</code></pre><h4 id="1-2-1-2-使用元素节点的事件属性"><a href="#1-2-1-2-使用元素节点的事件属性" class="headerlink" title="1.2.1.2 使用元素节点的事件属性"></a>1.2.1.2 使用元素节点的事件属性</h4><ul><li>也是只可以在冒泡阶段进行触发</li></ul><pre><code>window.onload = doSomething;div.onclick = function (event) {  console.log(&#39;触发事件&#39;);};</code></pre><h4 id="1-2-1-3-使用addEventListener"><a href="#1-2-1-3-使用addEventListener" class="headerlink" title="1.2.1.3 使用addEventListener()"></a>1.2.1.3 使用addEventListener()</h4><p>用来为该节点定义事件的监听函数</p><h3 id="1-2-2-事件的传播"><a href="#1-2-2-事件的传播" class="headerlink" title="1.2.2 事件的传播"></a>1.2.2 事件的传播</h3><p>事件发生后，会在子元素和父元素之间进行传播，分为以下几个阶段:</p><ol><li>从window对象传导到目标节点(上层传到底层)，成为捕获阶段(capture phase)</li><li>在目标节点上触发，称为目标阶段</li><li>从目标节点传导会window对象，称为冒泡阶段 - bubbling phase</li></ol><p>这种三阶段的传播模型，使得同一个事件会在多个节点上触发。</p><pre><code>&lt;div&gt;  &lt;p&gt;点击&lt;/p&gt;&lt;/div&gt;var phases = {  1: &#39;capture&#39;,  2: &#39;target&#39;,  3: &#39;bubble&#39;};var div = document.querySelector(&#39;div&#39;);var p = document.querySelector(&#39;p&#39;);div.addEventListener(&#39;click&#39;, callback, true);p.addEventListener(&#39;click&#39;, callback, true);div.addEventListener(&#39;click&#39;, callback, false);p.addEventListener(&#39;click&#39;, callback, false);function callback(event) {  var tag = event.currentTarget.tagName;  var phase = phases[event.eventPhase];  console.log(&quot;Tag: &#39;&quot; + tag + &quot;&#39;. EventPhase: &#39;&quot; + phase + &quot;&#39;&quot;);}// 点击以后的结果// Tag: &#39;DIV&#39;. EventPhase: &#39;capture&#39;// Tag: &#39;P&#39;. EventPhase: &#39;target&#39;// Tag: &#39;P&#39;. EventPhase: &#39;target&#39;// Tag: &#39;DIV&#39;. EventPhase: &#39;bubble&#39;</code></pre><h3 id="1-2-3-事件的代理"><a href="#1-2-3-事件的代理" class="headerlink" title="1.2.3 事件的代理"></a>1.2.3 事件的代理</h3><p>因为事件会在冒泡阶段向上传播到父节点，因此可以将子节点的监听函数定义在父节点上，由父节点的监听函数统一处理多个子元素的事件，这种方式称为事件的代理</p><pre><code>var ul = document.querySelector(&#39;ul&#39;);ul.addEventListener(&#39;click&#39;, function (event) {  if (event.target.tagName.toLowerCase() === &#39;li&#39;) {    // some code  }});</code></pre><p>上面代码中，click事件的监听函数定义在<code>&lt;ul&gt;</code>节点，但是实际上，它处理的是子节点<code>&lt;li&gt;</code>的click事件。这样做的好处是，只要定义一个监听函数，就能处理多个子节点的事件，而不用在每个<code>&lt;li&gt;</code>节点上定义监听函数。而且以后再添加子节点，监听函数依然有效。</p><p>另外，我们可以使用<code>stopPorpagation</code>方法来使事件传播到某个节点就停下来，不再传播</p><pre><code>// stopPropagation不会停止在同一个element上的其他事件的执行p.addEventListener(&#39;click&#39;, function (event) {  event.stopPropagation();  console.log(1);});p.addEventListener(&#39;click&#39;, function(event) {  // 会触发  console.log(2);});</code></pre><ul><li>如果我们想不触发同一个element上的其他监听函数，可以使用<code>stopImmediatePropogation()</code>方法</li></ul><h2 id="1-3-事件对象"><a href="#1-3-事件对象" class="headerlink" title="1.3 事件对象"></a>1.3 事件对象</h2><p>事件发生以后，会产生一个事件对象，作为参数传给监听函数。浏览器原生提供一个Event对象，所有事件都是这个对象的实例，即继承了Event.prototype</p><ul><li>Event构造函数: <code>event = new Event(type, option);</code><ul><li>type 一个字符串，表示事件的名称</li><li>options 一个对象，表示事件对象的配置<ul><li>bubbles  boolean  <ul><li>default to false</li><li>表示对象是否冒泡</li></ul></li><li>cancelable boolean <ul><li>default to false</li><li>表示事情能否被取消，即能否用event.preventDefault()取消这个时间</li></ul></li></ul></li></ul></li></ul><h3 id="1-3-1-实例属性"><a href="#1-3-1-实例属性" class="headerlink" title="1.3.1 实例属性"></a>1.3.1 实例属性</h3><ul><li>Event.bubbles <ul><li>boolean</li><li>表示当前事件是否会冒泡</li><li>只读属性，用于了解Event实例是否可以冒泡</li></ul></li><li>Event.eventPhase <ul><li>返回当前事件所处的阶段，该属性只读<ul><li>0 还没有发生</li><li>1 捕获阶段  处于从祖先节点向目标节点的传播过程当中</li><li>2 事件到达目标节点</li><li>3 事件处于冒泡阶段</li></ul></li></ul></li><li>Event.currentTarget<ul><li>正在通过的节点</li></ul></li><li>Event.target <ul><li>事件的原始触发节点</li></ul></li><li>Event.timeStamp</li><li>Event.isTrusted<ul><li>表示该事件是否由一个真实的用户行为产生</li></ul></li><li>Event.detail<ul><li>只有浏览器的UI事件才具有</li><li>返回一个数值表示事件的某种信息</li><li>具体含义与事件类型相关<ul><li>点击 次数</li><li>鼠标滚轮 距离</li></ul></li></ul></li></ul><h3 id="1-3-2-实例方法"><a href="#1-3-2-实例方法" class="headerlink" title="1.3.2 实例方法"></a>1.3.2 实例方法</h3><ul><li>event.preventDefault()<ul><li>取消浏览器对当前事件的默认行为</li><li>生效的前提是事件对象的cancelable属性为true</li></ul></li></ul><pre><code>// HTML 代码为// &lt;input type=&quot;text&quot; id=&quot;my-input&quot; /&gt;// 实现只接受小写的功能var input = document.getElementById(&#39;my-input&#39;);input.addEventListener(&#39;keypress&#39;, checkName, false);function checkName(e) {  if (e.charCode &lt; 97 || e.charCode &gt; 122) {    e.preventDefault();  }}</code></pre><ul><li>event.stopPropagation()<ul><li>阻止事件在DOM中继续传播，防止再触发定义在别的节点上的监听函数，但是不包括在当前节点上其他的事件监听函数</li></ul></li><li>event.stopImmediatePropogation()<ul><li>阻止同一个事件的其他监听函数被调用</li><li>更彻底的阻止事件的传播</li></ul></li><li>event.composedPath() <ul><li>返回一个数组</li><li>成员是事件的最底层节点和依次冒泡经过的所有上层节点</li></ul></li></ul><pre><code>// HTML 代码如下// &lt;div&gt;//   &lt;p&gt;Hello&lt;/p&gt;// &lt;/div&gt;var div = document.querySelector(&#39;div&#39;);var p = document.querySelector(&#39;p&#39;);div.addEventListener(&#39;click&#39;, function (e) {  console.log(e.composedPath());}, false);// [p, div, body, html, document, Window]</code></pre><h2 id="1-4-各类事件的描述"><a href="#1-4-各类事件的描述" class="headerlink" title="1.4 各类事件的描述"></a>1.4 各类事件的描述</h2><h3 id="1-4-1-鼠标事件"><a href="#1-4-1-鼠标事件" class="headerlink" title="1.4.1 鼠标事件"></a>1.4.1 <a href="https://wangdoc.com/javascript/events/mouse.html" target="_blank" rel="noopener">鼠标事件</a></h3><ul><li>继承MouseEvent接口<ul><li>click<ul><li>mouseDown + mouseUp </li></ul></li><li>dblclick 在用一个元素上双击鼠标时触发<ul><li>mouseDown + mouseUp + click  </li></ul></li><li>mousedown 按下鼠标键时触发</li><li>mouseup 释放按下的鼠标键的时候触发</li><li>mousemove <ul><li>当鼠标在一个结点内部移动的时候触发</li><li>当鼠标持续移动时，就会持续触发</li><li>应当对该事件的监听函数做一些限定，比如一定时间内只能运行一次</li></ul></li><li>mouseenter <ul><li>进入一个节点时触发</li></ul></li><li>mouseover<ul><li>鼠标进入一个节点时触发，进入子节点会再一次触发这个事件</li></ul></li><li>mouseout<ul><li>鼠标离开一个节点的时候触发，离开父节点也会触发</li></ul></li><li>mouseleave<ul><li>鼠标离开一个节点时触发，离开父节点不会触发这个事件 </li></ul></li><li>contextmenu<ul><li>按下鼠标右键时触发的</li></ul></li><li>wheel<ul><li>滚动鼠标的滚轮时触发的，该事件继承的是WheelEvent接口 </li></ul></li></ul></li><li>mouseEvent<ul><li>浏览器提供一个MouseEvent构造函数，用于新建一个MouseEvent实例</li><li><code>var event = new MouseEvent(type, options);</code></li><li>第一个参数为字符串，表示事件名称</li><li>第二个参数是一个事件配置对象，可以配一些不同的属性<ul><li>screenX</li><li>screenY</li><li>clientX<ul><li>相对于程序窗口的水平位置</li></ul></li><li>clientY<ul><li>相对于程序窗口的垂直位置</li></ul></li><li>ctrlKey</li><li>shiftKey</li><li>altKey</li><li>metaKey </li><li>button <ul><li>0 按下主键</li><li>1 按下辅助键</li><li>2 按下次要键</li></ul></li><li>buttons</li></ul></li></ul></li></ul><h3 id="1-4-2-键盘事件"><a href="#1-4-2-键盘事件" class="headerlink" title="1.4.2 键盘事件"></a>1.4.2 键盘事件</h3><ul><li><p>键盘事件的种类</p><ul><li><p>keydown</p><ul><li>按下键盘的时候触发</li></ul></li><li><p>keypress</p><ul><li>按下有值的键再触发，即按下Ctrl, Alt, Shift, Meta这样的无值的键不会触发 </li><li>对于有值的键，还是会先触发keydown事件，再触发这个事件</li></ul></li><li><p>keyup</p><ul><li>松开键盘的时候触发该事件</li><li>如果一直不松开按键，那么就会连续触发键盘事件<ul><li>触发顺序：<ul><li>keydown</li><li>keypress</li><li>keydown</li><li>keypress</li><li>….</li><li>放开 -&gt; keyup</li></ul></li></ul></li></ul></li></ul></li><li><p>KeyboardEvent 接口概述</p><ul><li>描述用户与键盘的互动</li><li>继承了Event接口，并且定义了自己的实例属性和实例方法</li><li>浏览器原生提供KeyboardEvent构造函数，用来新建键盘事件的实例</li><li><code>new KeyboardEvent(type, options)</code></li><li>第一个参数为字符串，表示事件类型</li><li>第二个参数为一个事件配置对象，参数可选<ul><li>key</li><li>code<ul><li>0-9   digital0-digital9</li><li>A-Z   KeyA - KeyZ</li><li>F1 - F12</li><li>方向键<ul><li>ArrowDown</li><li>ArrowUp</li><li>ArrowLeft</li><li>ArrowRight</li></ul></li><li>Alt<ul><li>AltLeft/ AltRight</li><li>similar to shift, ctrl</li></ul></li></ul></li><li>location<ul><li>返回键盘的区域 </li></ul></li><li>ctrlKey</li><li>shiftKey</li><li>altKey</li><li>metaKey</li><li>repeat <ul><li>看该案件是否被按着不放，以便判断是否重复这个键</li></ul></li></ul></li></ul></li><li><p>KeyboardEvent实例方法</p><ul><li>getModifierState() <ul><li>返回一个布尔值，表示是否按下或激活指定的功能键<ul><li>alt</li><li>capslock</li><li>control</li><li>meta</li><li>numlock</li><li>shift</li></ul></li></ul></li></ul></li></ul><h3 id="1-4-3-进度事件"><a href="#1-4-3-进度事件" class="headerlink" title="1.4.3 进度事件"></a>1.4.3 进度事件</h3><p>用来描述资源加载的进度，主要由:</p><ul><li>AJAX请求</li><li><code>&lt;img&gt;</code></li><li><code>&lt;audio&gt;</code></li><li><code>&lt;video&gt;</code></li><li><code>&lt;style&gt;</code></li><li><code>&lt;link&gt;</code></li></ul><p>该类外部资源的加载触发，继承了ProgressEvent接口。主要包含以下几种事件：</p><ul><li>abort  外部资源中止加载时被触发</li><li>error  由于错误导致外部资源无法加载时触发</li><li>load   外部资源加载成功时触发</li><li>loadstart  外部资源开始加载时触发</li><li>loadend  外部资源停止加载时触发</li><li>progress  外部资源加载过程中不断触发</li><li>timeout  加载超时时触发</li></ul><ul><li><p>ProgressEvent接口</p><ul><li>用来描述外部资源加载的进度</li><li><code>new ProgressEvent(type, options)</code><ul><li>types 事件类型</li><li>options - 配置对象<ul><li>lengthComputable 布尔值，表示加载的总量是否可以计算，默认为false</li><li>loaded 表示已经加载的量</li><li>total 表示需要加载的量<h3 id="1-4-4-表单事件"><a href="#1-4-4-表单事件" class="headerlink" title="1.4.4 表单事件"></a>1.4.4 表单事件</h3></li></ul></li></ul></li></ul></li><li><p>表单事件的种类</p><ul><li>input<ul><li>当<code>&lt;input&gt;, &lt;select&gt;, &lt;textarea&gt;</code>的值发生变化时触发</li><li>input事件会连续触发，每按下一个键，都会触发一次input事件的</li></ul></li><li>select<ul><li>是在<code>&lt;input&gt; &lt;select&gt; &lt;textarea&gt;</code>里面的值发生变化的时候触发 </li></ul></li><li>change<ul><li>在元素失去焦点时发生</li><li>即当有连续变化的时候，input事件会被触发很多次，而change事件只在失去焦点的时候被触发一次。</li><li>换个角度看，input事件是一定伴随着change事件的，具体分为以下几种情况<ul><li>激活单选框或复选框时触发</li><li>用户提交时触发</li><li>当文本框或textarea元素的值发生改变，并且失去焦点的时候触发</li></ul></li></ul></li><li>invalid<ul><li>用户提交表单，当表单元素的值不满足校验条件，就会触发invalid事件 </li></ul></li><li>reset<ul><li>发生在表单对象上</li><li>表示表单重置时锁触发的事件</li></ul></li><li>submit<ul><li>当表单数据向服务器提交时触发</li></ul></li></ul></li><li><p>inputEvent接口</p><ul><li><code>new InputEvent(type, options)</code></li><li>type 字符串，表示事件名称</li><li>options 配置对象<ul><li>inputType</li><li>data  表示插入的字符串</li><li>dataTransfer </li></ul></li></ul></li></ul><h3 id="1-4-5-触摸事件"><a href="#1-4-5-触摸事件" class="headerlink" title="1.4.5 触摸事件"></a>1.4.5 触摸事件</h3><ul><li><p>触摸操作</p><ul><li>touch  一个触摸点<ul><li>位置</li><li>大小</li><li>形状</li><li>压力</li><li>目标元素</li></ul></li><li>touchList  多个触摸点的集合<ul><li>成员为Touch的实例对象</li><li>属性<ul><li>length  表示触摸点的数量</li><li>item() 返回指定的成员</li></ul></li></ul></li><li>touchEvent  触摸引发的事件实例</li></ul></li><li><p>Touch 接口概述</p><ul><li><code>var touch = new Touch(touchOptions)</code> </li><li>touchOptions<ul><li>identifier <ul><li>触摸点的唯一ID</li></ul></li><li>target</li><li>clientX</li><li>clientY</li><li>screenX</li><li>screenY</li><li>pageX</li><li>pageY</li><li>radiusX </li><li>radiusY</li><li>rotationAngle</li><li>force <ul><li>0 -1 范围</li><li>表示触摸压力</li></ul></li></ul></li></ul></li><li><p>触摸事件的种类</p><ul><li>touchstart</li><li>touchend</li><li>touchmove</li><li>touchcancel <h3 id="1-4-6-拖拉事件"><a href="#1-4-6-拖拉事件" class="headerlink" title="1.4.6 拖拉事件"></a>1.4.6 拖拉事件</h3></li></ul></li><li><p>拖拉定义</p><ul><li>用户在某个对象上按下鼠标键不放，拖动它到另一个位置，然后释放鼠标键，将该对象放在那里</li></ul></li><li><p>拖拉的对象</p><ul><li>元素节点</li><li>图片</li><li>链接</li><li>选中的文字</li></ul></li></ul><h3 id="1-4-7-其他常见事件"><a href="#1-4-7-其他常见事件" class="headerlink" title="1.4.7 其他常见事件"></a>1.4.7 其他常见事件</h3><ul><li>资源事件<ul><li>beforeunload <ul><li>在窗口，文档，各种资源将要卸载前触发</li><li>用于防止用户不小心卸载资源</li></ul></li><li>unload<ul><li>在窗口关闭或者document对象将要卸载时触发</li><li>触发顺序排在beforeunload, pagehide事件后面</li></ul></li><li>load<ul><li>在页面或者某个资源加载成功时触发</li><li>页面或者资源从浏览器缓存加载，并不会触发load事件</li></ul></li></ul></li><li>session历史事件<ul><li>pageshow<ul><li>页面加载时触发，如果要指定页面每次加载时都运行的打字吗，可以放在这个事件的监听函数当中 </li></ul></li><li>pagehide</li><li>popstate<ul><li>在浏览器的history对象的当前记录发生显式切换时触发</li></ul></li><li>hashchange<ul><li>URL的hash部分发生变化的时候触发 </li></ul></li></ul></li><li>网页状态事件 <ul><li>DOMContentLoaded 事件<ul><li>网页下载并解析完成以后在document对象上触发该事件  </li></ul></li></ul></li><li>窗口事件<ul><li>scroll <ul><li>用户拖动滚动条</li></ul></li><li>resize</li><li>fullscreenchange</li><li>fullscreenerror </li></ul></li><li>焦点事件<ul><li>focus 获得焦点以后触发</li><li>blur  失去焦点以后触发</li><li>focusin  将要获得焦点时触发</li><li>focusout 将要失去焦点时触发</li></ul></li></ul><h1 id="2-浏览器模型"><a href="#2-浏览器模型" class="headerlink" title="2. 浏览器模型"></a>2. 浏览器模型</h1><p>主要来介绍浏览器提供的各种JS接口</p><h2 id="2-1-浏览器环境概述"><a href="#2-1-浏览器环境概述" class="headerlink" title="2.1 浏览器环境概述"></a>2.1 浏览器环境概述</h2><ul><li>代码嵌入网页方法<ul><li><script> 直接嵌入代码  + type属性  用来指定脚本类型      + text/javascript      + application/javascript</li><li><script> 标签加载外部脚本  + 为了防止攻击者篡改外部脚本，script标签允许设置一个`integrity`属性，写入外部脚本的Hash签名，用来验证脚本的一致性 </li><li>事件属性<ul><li>网页元素的事件  比如onclick  onmouseover 可以写入JS代码 </li></ul></li><li>URL协议<ul><li>在URL的位置写入代码，使用这个URL的时候就会执行JS代码了 </li></ul></li></ul></li></ul><pre><code>&lt;script src=&quot;/assets/application.js&quot;  integrity=&quot;sha256-TvVUHzSfftWg1rcfL6TIJ0XKEGrgLyEq6lEpcmrG9qs=&quot;&gt;&lt;/script&gt;&lt;a href=&quot;javascript:console.log(&#39;Hello&#39;)&quot;&gt;点击&lt;/a&gt;</code></pre><h3 id="2-1-1-script工作原理"><a href="#2-1-1-script工作原理" class="headerlink" title="2.1.1 script工作原理"></a>2.1.1 script工作原理</h3><ul><li>网页加载流程<ul><li>浏览器一边下载HTML网页，一边开始解析 </li><li>当发现<code>&lt;script&gt;</code>元素的时候，就暂停解析，将网页渲染的控制权交给JavaScript引擎</li><li>如果<code>&lt;script&gt;</code>元素引用了外部脚本，就下载该脚本再执行，否则就直接执行代码</li><li>JS引擎执行完毕，控制权交还给渲染引擎，恢复往下解析HTML网页</li></ul></li><li>为什么加载脚本的时候会停止页面渲染？<ul><li>因为JS代码可以修改DOM，所以需要将DOM控制权给它，否则会出现线程竞争的问题</li><li>问题点在于如果外部脚本加载时间非常长，那么浏览器会一直等待脚本下载完成，造成网页长时间失去响应，浏览器就会呈现出假死状态，称为阻塞效应。</li><li>因为相对较好的做法是将Script标签放在页面底部，这样即使遇到脚本失去响应，网页主体的渲染已经完成，用户就可以看到内容的。</li></ul></li><li>脚本是有执行顺序的<ul><li>执行顺序由在页面中出现的顺序决定，为了保证脚本之间的依赖关系不受到破坏</li><li>加载脚本都会产生阻塞效应，需要等他们都加载完成浏览器才能继续页面渲染</li></ul></li><li>此外，对于来自<strong>同一个域名的资源</strong>，比如脚本文件、样式表文件、图片文件等，浏览器一般有限制，同时最多下载6～20个资源，即最多同时打开的 TCP 连接有限制，这是为了防止对服务器造成太大压力。如果是来自不同域名的资源，就没有这个限制。所以，通常把静态文件放在不同的域名之下，以加快下载速度。<h3 id="2-1-2-defer属性"><a href="#2-1-2-defer属性" class="headerlink" title="2.1.2 defer属性"></a>2.1.2 defer属性</h3></li><li>为了解决脚本文件下载阻塞网页渲染的问题</li><li>在<code>&lt;script&gt;</code>当中加入defer属性，作用是延迟脚本的执行，等到DOM加载生成后，再执行脚本 </li><li>运行流程<ul><li>浏览器开始解析HTML网页</li><li>发现带有defer属性的script标签</li><li>继续往下解析HTML网页，并且并行下载script元素加载外部脚本</li><li>完成解析HTML网页，回头再执行已经下载了的脚本</li></ul></li></ul><h3 id="2-1-3-async属性"><a href="#2-1-3-async属性" class="headerlink" title="2.1.3 async属性"></a>2.1.3 async属性</h3><p>async属性的作用在于使用另一个进程下载脚本，下载时不会阻塞渲染</p><ul><li>浏览器开始解析HTML网页</li><li>解析过程中，发现带有async属性的script标签</li><li>继续向下解析，同时并行下载script标签当中的外部脚本</li><li>脚本下载完成，浏览器暂停解析HTML网页，开始执行下载的脚本</li><li>脚本执行完毕，浏览器恢复解析HTML网页</li></ul><p>aync属性可以保证脚本下载的同时，浏览器继续渲染。  注意: 一旦采用，脚本执行顺序就无法确定了</p><h3 id="2-1-4-脚本动态加载"><a href="#2-1-4-脚本动态加载" class="headerlink" title="2.1.4 脚本动态加载"></a>2.1.4 脚本动态加载</h3><p>script元素可以动态生成，再插入页面，从而实现脚本的动态加载。</p><pre><code>[&#39;a.js&#39;, &#39;b.js&#39;].forEach(function(src) {  var script = document.createElement(&#39;script&#39;);  script.src = src;  document.head.appendChild(script);});</code></pre><p>动态生成的script标签不会阻塞页面渲染，也就不会造成浏览器假死。但是问题在于，这种方法无法保证脚本的执行顺序，哪个脚本文件先下载完成，就先执行哪个</p><ul><li><p>另外我们可以指定我们需要加载的协议，可以使用HTTP或者HTTPS。默认是HTTP的，如果想使用HTTPS，需要做指定 – <code>&lt;script src=&quot;https://example.js&quot;&gt;&lt;/script&gt;</code></p><h3 id="2-1-5-浏览器组成"><a href="#2-1-5-浏览器组成" class="headerlink" title="2.1.5 浏览器组成"></a>2.1.5 浏览器组成</h3></li><li><p>渲染引擎</p><ul><li>将网页代码渲染为用户视觉可以感知的平面文档</li><li>渲染的步骤<ul><li>解析代码<ul><li>将HTML代码解析为DOM，CSS解析为CSSOM (CSS Object Model)</li></ul></li><li>对象合成<ul><li>将DOM和CSSOM合成一棵渲染树 (render tree)</li></ul></li><li>布局<ul><li>计算出渲染树的布局</li></ul></li><li>绘制<ul><li>将渲染树绘制到屏幕上</li></ul></li></ul></li></ul></li><li><p>重流 vs 重绘</p><ul><li>重流必然导致重绘</li><li>重绘不一定导致重流</li><li>尽量减少重流</li><li>优化技巧<ul><li>DOM尽量写在一起，不要读取一个节点就写入一个</li><li>缓存DOM信息</li><li>动画使用absolute定位或者fixed定位，可以减少对其他元素的影响</li><li>只有必要时才显示隐藏元素</li></ul></li></ul></li><li><p>JavaScript解释器</p><ul><li>读取网页中的JS代码，处理后运行</li><li>js不需要编译，由解释器实时运行  这样的好处是运行和修改都比较方便，刷新页面就可以重新解释；缺点是每次运行都要调用解释器，系统开销较大，运行速度慢于编译型语言</li><li>为加快速度，浏览器一般会进行预编译，生成类似字节码的中间代码</li><li>即时编译  Just in time 编译器直接把源码编译成机器码来运行 <ul><li>字节码只在运行时编译，用到哪一行就编译哪一行，然后把编译结果缓存 </li></ul></li></ul></li></ul><h2 id="2-2-Window对象"><a href="#2-2-Window对象" class="headerlink" title="2.2 Window对象"></a>2.2 Window对象</h2><h3 id="2-2-1-属性"><a href="#2-2-1-属性" class="headerlink" title="2.2.1 属性"></a>2.2.1 属性</h3><p>window指当前的浏览器窗口，是当前页面的顶层对象，所有的其他对象都是其下属。如果一个变量未声明，那么默认就是顶层对象的属性。</p><pre><code>a = 1;window.a // 1</code></pre><ul><li><p>window.name  </p><ul><li>表示当前窗口的名字</li></ul></li><li><p>window.closed </p><ul><li>检查当前窗口是否关闭</li></ul></li><li><p>window.opener </p><ul><li>表示打开当前窗口的父窗口 </li></ul></li><li><p>window.window   window.window</p><ul><li>指向窗口本身，这两个属性都只读</li></ul></li><li><p>window.frames  window,length </p><ul><li>frames返回一个类似数组的对象，成员为页面内所有框架窗口</li></ul></li><li><p>window.screenX window.screenY</p></li><li><p>window.innerHeight  window.innerWidth </p><ul><li>可见部分的高度宽度</li></ul></li><li><p>window.outerHeight  window.outerWidth </p></li><li><p>window.scrollX  window.scrollY</p></li><li><p>组件属性</p><ul><li>window.locationbar  地址栏对象</li><li>window.menubar  菜单栏对象</li><li>window.scrollbars 窗口的滚动条对象</li><li>window.toolbar 工具栏对象</li><li>window.statusbar 状态栏对象</li><li>window.personalbar 个人安装的工具栏对象</li></ul></li><li><p>全局对象属性</p><ul><li>document </li><li>location </li><li>navigator </li><li>history</li><li>localStorage </li><li>sessionStorage </li><li>console </li><li>screen </li></ul></li><li><p>常用方法</p><ul><li><p>window.open(url, windowName, [windowFeatures])</p><ul><li>打开一个新的浏览器窗口</li></ul></li><li><p>window.close()</p></li><li><p>window.stop()</p><ul><li>相当于点击浏览器的停止按钮，会停止加载图像等正在加载的对象</li></ul></li><li><p>window.focus()  获得焦点</p></li><li><p>window.blur()  失去焦点</p></li><li><p>window.getSelection()   表示用户现在选中的文本</p><p>var popup = window.open(<br>‘somepage.html’,<br>‘DefinitionsWindows’,<br>‘height=200,width=200,location=no,status=yes,resizable=yes,scrollbars=yes’<br>);</p></li></ul></li><li><p>事件</p><ul><li>load onload</li><li>error  onerror </li></ul></li></ul><h2 id="2-3-Navigator对象"><a href="#2-3-Navigator对象" class="headerlink" title="2.3 Navigator对象"></a>2.3 Navigator对象</h2><p><a href="https://wangdoc.com/javascript/bom/navigator.html" target="_blank" rel="noopener">https://wangdoc.com/javascript/bom/navigator.html</a></p><h2 id="2-4-Cookie对象"><a href="#2-4-Cookie对象" class="headerlink" title="2.4 Cookie对象"></a>2.4 Cookie对象</h2><h3 id="2-4-1-概述"><a href="#2-4-1-概述" class="headerlink" title="2.4.1 概述"></a>2.4.1 概述</h3><p>Cookie是服务器保存在浏览器的一小段文本信息，浏览器每次向服务器发出请求的时候，就会自动附上这段信息</p><ul><li>用途<ul><li>session 对话管理，保存登录，购物车等等需要记录的信息</li><li>个性化信息  用户偏好等</li><li>追踪用户  记录和分析用户的行为</li></ul></li><li>元数据<ul><li>cookie名字</li><li>cookie值</li><li>到期时间</li><li>所属域名</li><li>生效路径<h2 id="2-5-Location对象"><a href="#2-5-Location对象" class="headerlink" title="2.5 Location对象"></a>2.5 Location对象</h2></li></ul></li></ul><h3 id="2-5-1-Location对象"><a href="#2-5-1-Location对象" class="headerlink" title="2.5.1 Location对象"></a>2.5.1 Location对象</h3><ul><li><code>window.location</code> or <code>document.location</code>去拿到这个对象</li><li>属性<ul><li>Location.href  整个URL</li><li>Location.protocol  当前URL的协议，包括冒号</li><li>Location.host 主机  </li><li>Location.hostname  主机  不包括端口号</li><li>Location.port  端口号</li><li>Location.pathname  URL的路径部分，从根目录的<code>/</code>开始</li><li>Location.search  查询字符串部分，从问号?开始</li><li>Location.hash 片段字符串部分  从#开始</li><li>Location.username </li><li>Location.password </li><li>Location.origin  URL的协议，主机名和端口</li></ul></li></ul><pre><code>// 当前网址为// http://user:passwd@www.example.com:4097/path/a.html?x=111#part1document.location.href// &quot;http://user:passwd@www.example.com:4097/path/a.html?x=111#part1&quot;document.location.protocol// &quot;http:&quot;document.location.host// &quot;www.example.com:4097&quot;document.location.hostname// &quot;www.example.com&quot;document.location.port// &quot;4097&quot;document.location.pathname// &quot;/path/a.html&quot;document.location.search// &quot;?x=111&quot;document.location.hash// &quot;#part1&quot;document.location.username// &quot;user&quot;document.location.password// &quot;passwd&quot;document.location.origin// &quot;http://user:passwd@www.example.com:4097&quot;</code></pre><p>Location.href属性是浏览器唯一允许跨域写入的属性，即非同源的窗口可以改写另一个窗口的location.href属性，导致后者的网址跳转。location的其他属性都不允许跨域写入的。</p><h3 id="2-5-2-方法"><a href="#2-5-2-方法" class="headerlink" title="2.5.2 方法"></a>2.5.2 方法</h3><ul><li>location.assgin() <ul><li>接受一个URL字符串作为参数，使得浏览器立刻跳转到新的URL。如果参数不是有效的URL，则会报错</li></ul></li><li>location.replace()<ul><li>接受一个URL字符串作为参数，使得浏览器立刻跳转到新的URL</li><li>与assign的不同在于会在浏览历史里删除掉当前网址</li><li>一个应用在于当脚本发现当前是移动设备时，就立刻跳转到移动版网页当中</li></ul></li><li>location.reload()<ul><li>一个布尔值的参数</li><li>true - 向服务器重新请求这个网页，重新加载后，网页将滚动到头部</li><li>false - 从本地缓存重新加载该页面，并且重新加载后，网页的位置是重新加载前的位置</li></ul></li><li>location.toString()<ul><li>返回整个URL字符串 </li></ul></li></ul><h3 id="2-5-3-URL的编码和解码"><a href="#2-5-3-URL的编码和解码" class="headerlink" title="2.5.3 URL的编码和解码"></a>2.5.3 URL的编码和解码</h3><p>除去URL元字符和语义字符以外的其他字符是需要转义的，比如中文都需要进行转义，转义的时候在每个字节前面都会加上百分号，这就构成了URL的编码/解码语法。</p><ul><li>encodeURI()<ul><li>转码整个URL </li><li>参数为一个字符串，代表整个URL </li><li>会将元字符和语义字符之外的字符都进行转义</li></ul></li><li>encodeURIComponent()<ul><li>用于转码URL的组成部分，会转码除了语义字符之外的所有字符，即元字符也会被转码</li></ul></li><li>decodeURI()<ul><li>解码整个URL </li></ul></li><li>decodeURIComponent()<ul><li>解码片段</li></ul></li></ul><pre><code>encodeURI(&#39;http://www.example.com/q=春节&#39;)// &quot;http://www.example.com/q=%E6%98%A5%E8%8A%82&quot;encodeURIComponent(&#39;春节&#39;)// &quot;%E6%98%A5%E8%8A%82&quot;encodeURIComponent(&#39;http://www.example.com/q=春节&#39;)// &quot;http%3A%2F%2Fwww.example.com%2Fq%3D%E6%98%A5%E8%8A%82&quot;decodeURI(&#39;http://www.example.com/q=%E6%98%A5%E8%8A%82&#39;)// &quot;http://www.example.com/q=春节&quot;decodeURIComponent(&#39;%E6%98%A5%E8%8A%82&#39;)// &quot;春节&quot;</code></pre><h3 id="2-5-4-接口"><a href="#2-5-4-接口" class="headerlink" title="2.5.4 接口"></a>2.5.4 接口</h3><ul><li><code>var url = new URL(&#39;http://www.example.com/index.html&#39;);</code></li><li>接受两个参数，第一个参数表示相对路径，第二个参数表示绝对路径</li></ul><pre><code>var url1 = new URL(&#39;index.html&#39;, &#39;http://example.com&#39;);url1.href// &quot;http://example.com/index.html&quot;var url2 = new URL(&#39;page2.html&#39;, &#39;http://example.com/page1.html&#39;);url2.href// &quot;http://example.com/page2.html&quot;var url3 = new URL(&#39;..&#39;, &#39;http://example.com/a/b.html&#39;)url3.href// &quot;http://example.com/&quot;</code></pre><ul><li>方法<ul><li>url.createObjectURL() <ul><li>用来为上传下载文件，流媒体文件生成一个URL字符串。这个字符串代表了FIle对象或Blob对象的URL</li></ul></li><li>url.revokeObjectURL() </li></ul></li></ul><h3 id="2-5-5-URLSearchParams对象"><a href="#2-5-5-URLSearchParams对象" class="headerlink" title="2.5.5 URLSearchParams对象"></a>2.5.5 URLSearchParams对象</h3><ul><li>用来构造，解析，处理URL的查询字符串 </li></ul><pre><code>var params = new URLSearchParams(&#39;?foo=1&amp;bar=2&#39;);// 等同于var params = new URLSearchParams(document.location.search);// 方法二：传入数组var params = new URLSearchParams([[&#39;foo&#39;, 1], [&#39;bar&#39;, 2]]);// 方法三：传入对象var params = new URLSearchParams({&#39;foo&#39; : 1 , &#39;bar&#39; : 2});</code></pre><h2 id="2-6-Blob对象"><a href="#2-6-Blob对象" class="headerlink" title="2.6 Blob对象"></a>2.6 Blob对象</h2><p>ArrayBuffer对象表示一段二进制数据，用来模拟内存里的数据</p><p>Blob对象表示一个二进制文件的数据内容，- Binary Large Object.Blob用于操作二进制文件。</p><ul><li>Blob构造函数<ul><li><code>new Blob(array [, options])</code></li><li>第一个参数 数组 成员是字符串或二进制对象，表示新生成的Blob实例对象的内容</li><li>第二个参数  配置对象<ul><li>type 表示数据的MIME类型，默认是空字符串</li></ul></li></ul></li></ul><pre><code>var htmlFragment = [&#39;&lt;a id=&quot;a&quot;&gt;&lt;b id=&quot;b&quot;&gt;hey!&lt;/b&gt;&lt;/a&gt;&#39;];var myBlob = new Blob(htmlFragment, {type : &#39;text/html&#39;});var obj = { hello: &#39;world&#39; };var blob = new Blob([ JSON.stringify(obj) ], {type : &#39;application/json&#39;});</code></pre><h3 id="2-6-1-实例对象和实例方法"><a href="#2-6-1-实例对象和实例方法" class="headerlink" title="2.6.1 实例对象和实例方法"></a>2.6.1 实例对象和实例方法</h3><ul><li>size<ul><li>数据大小</li></ul></li><li>type<ul><li>数据类型<ul><li>text/html </li></ul></li></ul></li><li>slice(start, end, contentType)<ul><li>用来拷贝原来的数据，返回的也是一个Blob实例 </li><li>起始的字节位置，结束的字节位置，新实例的数据类型</li></ul></li></ul><h3 id="2-6-2-获取文件信息"><a href="#2-6-2-获取文件信息" class="headerlink" title="2.6.2 获取文件信息"></a>2.6.2 获取文件信息</h3><ul><li>文件选择器 <code>&lt;input type=&quot;file&quot;&gt;</code>用来让用户选取文件</li><li>出于安全考虑，浏览器不允许脚本自行设置其value属性，必须手动选取</li><li>文件选择器返回一个FileList对象，每个成员都是一个File实例对象。其为一个特殊的Blob实例，增加了name和lastModifiedDate属性。</li></ul><h3 id="2-6-3-下载文件"><a href="#2-6-3-下载文件" class="headerlink" title="2.6.3 下载文件"></a>2.6.3 下载文件</h3><p>AJAX 请求时，如果指定responseType属性为blob，下载下来的就是一个 Blob 对象。</p><pre><code>function getBlob(url, callback) {  var xhr = new XMLHttpRequest();  xhr.open(&#39;GET&#39;, url);  xhr.responseType = &#39;blob&#39;;  xhr.onload = function () {    callback(xhr.response);  }  xhr.send(null);}</code></pre><h3 id="2-6-4-生成URL"><a href="#2-6-4-生成URL" class="headerlink" title="2.6.4 生成URL"></a>2.6.4 生成URL</h3><ul><li>可以通过使用<code>URL.createObjectURL()</code>方法，针对Blob对象生成一个临时URL，以便于某些API使用</li><li>URL以<code>Blob://</code>开头，表明对应一个Blob对象，协议头后面是一个识别符，用来唯一对应内存的Blob对象</li></ul><pre><code>var droptarget = document.getElementById(&#39;droptarget&#39;);droptarget.ondrop = function (e) {  var files = e.dataTransfer.files;  for (var i = 0; i &lt; files.length; i++) {    var type = files[i].type;    if (type.substring(0,6) !== &#39;image/&#39;)      continue;    var img = document.createElement(&#39;img&#39;);    img.src = URL.createObjectURL(files[i]);    img.onload = function () {      this.width = 100;      document.body.appendChild(this);      URL.revokeObjectURL(this.src);    }  }}</code></pre><p>该段代码通过为拖放的图片文件生成一个URL，产生他们的缩略图，从而使得用户可以预览选择的文件。</p><h3 id="2-6-5-读取文件"><a href="#2-6-5-读取文件" class="headerlink" title="2.6.5 读取文件"></a>2.6.5 读取文件</h3><p>获取Blob对象以后，通过FileReader对象，读取Blob对象的内容。Blob对象作为参数传入FilreReader提供的处理方法当中，然后以指定的格式返回</p><ul><li>FileReader.readAsText()   返回文本，需要指定文本编码</li><li>FileReader.readAsArrayBuffer()   返回ArrayBuffer对象</li><li>FileReader.readAsDataURL()  返回Data URL</li><li>FileReader.readAsBinaryString()  返回原始的二进制字符串</li></ul><h2 id="2-7-表单-FormData对象"><a href="#2-7-表单-FormData对象" class="headerlink" title="2.7 表单 FormData对象"></a>2.7 表单 FormData对象</h2><h3 id="2-7-1-General"><a href="#2-7-1-General" class="headerlink" title="2.7.1 General"></a>2.7.1 General</h3><p>表单对象用来收集用户提交的数据，发送到服务器。</p><pre><code>&lt;form action=&quot;/handling-page&quot; method=&quot;post&quot;&gt;  &lt;div&gt;    &lt;label for=&quot;name&quot;&gt;用户名：&lt;/label&gt;    &lt;input type=&quot;text&quot; id=&quot;name&quot; name=&quot;user_name&quot; /&gt;  &lt;/div&gt;  &lt;div&gt;    &lt;label for=&quot;passwd&quot;&gt;密码：&lt;/label&gt;    &lt;input type=&quot;password&quot; id=&quot;passwd&quot; name=&quot;user_passwd&quot; /&gt;  &lt;/div&gt;  &lt;div&gt;    &lt;input type=&quot;submit&quot; id=&quot;submit&quot; name=&quot;submit_button&quot; value=&quot;提交&quot; /&gt;  &lt;/div&gt;&lt;/form&gt;</code></pre><p>键值对会提高到服务器当中，提交的数据格式跟form元素的method属性有关，该属性指定了提交数据的HTTP方法。如果是GET方法，所有键值对会以URL的查询字符串形式，提交到服务器当中。</p><p>如果是post请求，所有键值对会连接成一行，作为HTTP请求的数据体发送到服务器</p><pre><code>GET /handling-page?user_name=张三&amp;user_passwd=123&amp;submit_button=提交Host: example.comPOST /handling-page HTTP/1.1Host: example.comContent-Type: application/x-www-form-urlencodedContent-Length: 74user_name=张三&amp;user_passwd=123&amp;submit_button=提交</code></pre><p>注意如果提交的时候，如果键值不是URL的合法字符，浏览器就会自动对其进行编码。</p><p>点击submit控件就可以提交表单了。</p><h3 id="2-7-2-FormData对象"><a href="#2-7-2-FormData对象" class="headerlink" title="2.7.2 FormData对象"></a>2.7.2 FormData对象</h3><p>通过脚本完成对于表单键值对的构建，然后通过<code>XMLHttpRequest.send()</code>方式来进行发送，浏览器原生提供了FormData对象来完成这项工作。</p><ul><li>FormData() 构造函数的参数是一个表单元素，这个参数是可选的，如果省略参数，就表示一个空的表单，否则就会处理表单元素里面的键值对。</li></ul><pre><code>&lt;form id=&quot;myForm&quot; name=&quot;myForm&quot;&gt;  &lt;div&gt;    &lt;label for=&quot;username&quot;&gt;用户名：&lt;/label&gt;    &lt;input type=&quot;text&quot; id=&quot;username&quot; name=&quot;username&quot;&gt;  &lt;/div&gt;  &lt;div&gt;    &lt;label for=&quot;useracc&quot;&gt;账号：&lt;/label&gt;    &lt;input type=&quot;text&quot; id=&quot;useracc&quot; name=&quot;useracc&quot;&gt;  &lt;/div&gt;  &lt;div&gt;    &lt;label for=&quot;userfile&quot;&gt;上传文件：&lt;/label&gt;    &lt;input type=&quot;file&quot; id=&quot;userfile&quot; name=&quot;userfile&quot;&gt;  &lt;/div&gt;&lt;input type=&quot;submit&quot; value=&quot;Submit!&quot;&gt;&lt;/form&gt;var myForm = document.getElementById(&#39;myForm&#39;);var formData = new FormData(myForm);// 获取某个控件的值formData.get(&#39;username&#39;) // &quot;&quot;// 设置某个控件的值formData.set(&#39;username&#39;, &#39;张三&#39;);formData.get(&#39;username&#39;) // &quot;张三&quot;</code></pre><ul><li>FormData.get(key)</li><li>FormData.getAll(key)</li><li>FormData.set(key, value)</li><li>FormData.delete(key)</li><li>FormData.append(key, value)</li><li>FormData.has(key)</li><li>FormData.keys()  </li><li>FormData.values()</li><li>FormData.entries() </li></ul><h3 id="2-7-3-表单的内置验证"><a href="#2-7-3-表单的内置验证" class="headerlink" title="2.7.3 表单的内置验证"></a>2.7.3 表单的内置验证</h3><ul><li>自动校验<ul><li>可以在表单提交的时候指定一些条件，来自动验证各个表单控件的值是否符合条件</li></ul></li></ul><pre><code>&lt;!-- 必填 --&gt;&lt;input required&gt;&lt;!-- 必须符合正则表达式 --&gt;&lt;input pattern=&quot;banana|cherry&quot;&gt;&lt;!-- 字符串长度必须为6个字符 --&gt;&lt;input minlength=&quot;6&quot; maxlength=&quot;6&quot;&gt;&lt;!-- 数值必须在1到10之间 --&gt;&lt;input type=&quot;number&quot; min=&quot;1&quot; max=&quot;10&quot;&gt;&lt;!-- 必须填入 Email 地址 --&gt;&lt;input type=&quot;email&quot;&gt;&lt;!-- 必须填入 URL --&gt;&lt;input type=&quot;URL&quot;&gt;// 通过CSS伪类来控制整个input:invalid {  border-color: red;}input,input:valid {  border-color: #ccc;}</code></pre><ul><li>checkValidity() <ul><li>用于手动触发表单的校验</li><li>表单元素和表单控件都有checkValidity()方法，用于手动触发校验</li></ul></li></ul><pre><code>function submitForm(action) {  var form = document.getElementById(&#39;form&#39;);  form.action = action;  if (form.checkValidity()) {    form.submit();  }}</code></pre><ul><li>validationMessage 属性<ul><li>返回一个字符串，表示控件不满足校验条件时，浏览器显示的提示文本</li></ul></li></ul><pre><code>var myInput = document.getElementById(&#39;myinput&#39;);if (!myInput.checkValidity()) {  document.getElementById(&#39;prompt&#39;).innerHTML = myInput.validationMessage;}</code></pre><ul><li><p>validity属性</p><ul><li>返回一个validityState对象，包含当前校验状态的信息</li><li>属性<ul><li>validityState.badInput</li><li>validityState.customError </li><li>validityState.patternMismatch</li><li>validityState.rangeOverflow </li><li>validityState.rangeUnderflow </li><li>validityState.stepMismatch </li><li>validityState.tooLong</li><li>validityState.tooShort </li><li>validityState.typeMismatch </li><li>validityState.valid</li><li>valitityState.valueMising </li></ul></li></ul></li><li><p>表单novalide属性</p><ul><li>可以关闭浏览器的自动校验</li></ul></li></ul><h3 id="2-7-4-enctype属性"><a href="#2-7-4-enctype属性" class="headerlink" title="2.7.4 enctype属性"></a>2.7.4 enctype属性</h3><ul><li>GET - URL查询字符串<ul><li>enctype属性无效 </li></ul></li><li>POST - <code>application/x-www-form-yrlencoded</code><ul><li>当省略enctype属性的时候，数据会以默认的<code>application/x-www-form-urlencoded</code>格式进行发送 </li></ul></li><li>POST - <code>text/plain</code></li></ul><pre><code>&lt;form  action=&quot;register.php&quot;  method=&quot;post&quot;  enctype=&quot;text/plain&quot;  onsubmit=&quot;AJAXSubmit(this); return false;&quot;&gt;&lt;/form&gt;</code></pre><ul><li>POST - <code>multipart/form-data</code><ul><li>数据以混合的方式来发送出去</li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://wangdoc.com/javascript/events/index.html" target="_blank" rel="noopener">https://wangdoc.com/javascript/events/index.html</a> </li><li><a href="https://segmentfault.com/a/1190000008227026" target="_blank" rel="noopener">https://segmentfault.com/a/1190000008227026</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript 教程 - part 2</title>
      <link href="/JavaScript-%E6%95%99%E7%A8%8B-part-2/"/>
      <url>/JavaScript-%E6%95%99%E7%A8%8B-part-2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-面向对象编程"><a href="#1-面向对象编程" class="headerlink" title="1. 面向对象编程"></a>1. 面向对象编程</h1><h2 id="1-1-实例对象与New命令"><a href="#1-1-实例对象与New命令" class="headerlink" title="1.1 实例对象与New命令"></a>1.1 实例对象与New命令</h2><ul><li><p>对象</p><ul><li>对世界各种复杂关系的抽象</li><li>是一个容器，封装了属性和方法</li></ul></li><li><p>构造函数</p><ul><li>java c++是通过类的概念来作为对象的模板，而对象就是类的实例</li><li>而在js当中，对象体系是基于构造函数和原型链的<h3 id="1-1-1-构造函数"><a href="#1-1-1-构造函数" class="headerlink" title="1.1.1 构造函数"></a>1.1.1 构造函数</h3>构造函数是用来专门生成实例对象的函数，它就是对象的模板，描述了对象的基本结构。</li></ul></li><li><p>构造函数的特点：</p><ul><li>函数体内部使用<strong>this关键字</strong>，代表了所要生成的对象实例</li><li>生成对象的时候，必须使用new命令</li></ul></li></ul><pre><code>var Vehicle = function () {  this.price = 1000;};</code></pre><h3 id="1-1-2-New"><a href="#1-1-2-New" class="headerlink" title="1.1.2 New"></a>1.1.2 New</h3><ul><li>new命令的作用就是执行构造函数返回一个实例对象</li><li>new指令执行的时候，构造函数内部的this就代表了新生成的实例对象</li><li>new指令的原理<ul><li>构建一个空对象，作为要返回的对象的实例</li><li>将这个空对象的原型，指向构造函数的prototype属性</li><li>将这个空对象赋值给函数内部的this关键字</li><li>开始执行构造函数内部的代码</li></ul></li></ul><pre><code>var Vehicle = function () {  this.price = 1000;};var v = new Vehicle();v.price // 1000</code></pre><ul><li>new.target<ul><li>使用new.target关键字</li><li>如果当前函数式new命令调用的，指向当前函数，否则为undefined</li></ul></li><li><code>Object.create()</code>创建实例对象<ul><li>构造函数作为模板，可以生成实例对象。但是，有时拿不到构造函数，只能拿到一个现有的对象。我们希望以这个现有的对象作为模板，生成新的实例对象，这时就可以使用Object.create()方法。</li></ul></li></ul><pre><code>var person1 = {  name: &#39;张三&#39;,  age: 38,  greeting: function() {    console.log(&#39;Hi! I\&#39;m &#39; + this.name + &#39;.&#39;);  }};var person2 = Object.create(person1);person2.name // 张三person2.greeting() // Hi! I&#39;m 张三.</code></pre><h2 id="1-2-this关键字"><a href="#1-2-this关键字" class="headerlink" title="1.2 this关键字"></a>1.2 this关键字</h2><p>this是属性或者方法当前所在的对象。</p><p>对象的属性可以赋给另外一个对象，所以属性所在的当前对象是可变的，this的指向是可变的</p><pre><code>function f() {  return &#39;姓名：&#39;+ this.name;}var A = {  name: &#39;张三&#39;,  describe: f};var B = {  name: &#39;李四&#39;,  describe: f};A.describe() // &quot;姓名：张三&quot;B.describe() // &quot;姓名：李四&quot;&lt;input type=&quot;text&quot; name=&quot;age&quot; size=3 onChange=&quot;validate(this, 18, 99);&quot;&gt;&lt;script&gt;function validate(obj, lowval, hival){  if ((obj.value &lt; lowval) || (obj.value &gt; hival))    console.log(&#39;Invalid Value!&#39;);}&lt;/script&gt;</code></pre><ul><li>JS当中一切都是对象，运行环境也是对象，所以函数总归是在某个对象之中运行的，this就是函数运行时所在的对象</li><li>this为的是在函数体内可以获得函数的当前运行环境的相关信息</li></ul><h3 id="1-2-1-this实质"><a href="#1-2-1-this实质" class="headerlink" title="1.2.1 this实质"></a>1.2.1 this实质</h3><ul><li>首先需要看我们是如何在内存当中进行数据存储的<ul><li><code>var obj = { foo: 5}</code>;<ul><li>将一个对象赋值给变量obj</li><li>JS引擎会先在内存里面生成一个对象</li><li>将这个对象的内存地址赋值给变量obj</li><li>—-&gt; 变量obj是一个地址 reference。后面如果要读取obj.foo， 引擎先从obj拿到内存地址，然后再从该地址读出原始对象，返回其foo属性</li></ul></li><li>原始的对象以字典结构存储，每一个属性名都对应一个属性描述对象<ul><li>如果对象的属性是一个函数的话</li><li>JS引擎会将函数单独保存在内存当中，然后将函数的地址赋值给foo的value属性</li><li>因为<strong>函数是一个单独的值，所以它可以在不同的上下文去执行</strong></li></ul></li><li>this的想法，或者说目的就是在函数体内部，指代函数当前的运行环境</li></ul></li></ul><pre><code>// 对象的实际保存形式{  foo: {    [[value]]: 5    [[writable]]: true    [[enumerable]]: true    [[configurable]]: true  }}var f = function () {    console.log(this.x);}</code></pre><h3 id="1-2-2-使用场合"><a href="#1-2-2-使用场合" class="headerlink" title="1.2.2 使用场合"></a>1.2.2 使用场合</h3><ul><li>全局环境<ul><li>指顶层对象window</li></ul></li><li>构造函数<ul><li>指实例对象 </li><li>在构造函数当中使用this，定义了属性，那就意味着定义了实例对象有一个p属性</li></ul></li></ul><pre><code>// this指实例对象，这个时候为实例对象定义了p属性var Obj = function(p) {    this.p = p;};</code></pre><ul><li>对象方法<ul><li>this指向是方法运行时所在的对象，该方法赋值给另一个对象，就会改变this的指向</li><li>这是因为obj.foo就是一个值，这个值真正调用的时候，运行环境已经不是obj了，而是全局环境，所以this不再指向obj</li></ul></li></ul><pre><code>// 指向objvar obj ={  foo: function () {    console.log(this);  }};obj.foo() // obj// 以下情况都会改变this的指向// 情况一(obj.foo = obj.foo)() // window// 情况二(false || obj.foo)() // window// 情况三(1, obj.foo)() // window</code></pre><h3 id="1-2-3-Tips"><a href="#1-2-3-Tips" class="headerlink" title="1.2.3 Tips"></a>1.2.3 Tips</h3><ul><li>避免多层this<ul><li>因为this的指向是不确定的，所以不应该在函数当中包含多层的this</li><li>如果是多层的话，可以在第二层增加一个指向外层this的变量来做</li></ul></li></ul><pre><code>var o = {  f1: function () {    console.log(this);    var f2 = function () {      console.log(this);    }();  }}o.f1()// Object// Windowvar o = {  f1: function() {    console.log(this);    var that = this;    var f2 = function() {      console.log(that);    }();  }}o.f1()// Object// Object</code></pre><ul><li>数组处理方法当中的this<ul><li>还是需要使用中间变量来固定住this </li></ul></li></ul><h3 id="1-2-4-绑定this的方法"><a href="#1-2-4-绑定this的方法" class="headerlink" title="1.2.4 绑定this的方法"></a>1.2.4 绑定this的方法</h3><p>this的动态切换，可以为JS提供灵活性，但也使得编程变得困难和模糊，因此我们需要将this固定下来，避免出现意想不到的情况。JS提供了call, apply, bind三个方法，来切换和固定this的指向</p><ul><li><code>Function.prototype.call()</code><ul><li>call方法可以指定函数内部的this的指向，(函数执行时所在的作用域)，然后在所指定的作用域当中，调用该函数</li><li>call可以接受多个参数 <code>func.call(thisValue, arg1, arg2)</code> </li><li>第一个参数是this所要指向的那个对象，后面的参数则是函数调用时所需的参数</li></ul></li></ul><pre><code>var obj = {};var f = function () {  return this;};f() === window // true// call可以带个对象，然后这个时候就将this的指向固定下来了f.call(obj) === obj // true</code></pre><ul><li><code>Function.prototype.apply()</code><ul><li>apply接收一个数组作为函数执行时的参数，其他和call函数是一致的</li><li><code>func.apply(thisValue, [arg1, arg2, ...])</code></li></ul></li></ul><pre><code>function f(x, y){  console.log(x + y);}f.call(null, 1, 1) // 2f.apply(null, [1, 1]) // 2</code></pre><ul><li><code>Function.prototype.bind()</code><ul><li>bind方法用于将函数体内的this绑定到某个对象，然后返回一个新函数</li><li>bind方法每次都会返回一个新函数</li></ul></li></ul><pre><code>// 上面代码中，bind方法将getTime方法内部的this绑定到d对象，这时就可以安全地将这个方法赋值给其他变量了。var d = new Date();d.getTime() // 1481869925657var print = d.getTime;print() // Uncaught TypeError: this is not a Date object.var print = d.getTime.bind(d);print() // 1481869925657</code></pre><h2 id="1-3-对象的继承"><a href="#1-3-对象的继承" class="headerlink" title="1.3 对象的继承"></a>1.3 对象的继承</h2><p>A对象通过继承B对象，就能直接拥有B对象的所有属性和方法，这对于代码的复用很有帮助。JavaScript通过原型对象(prototype)来实现继承关系。</p><p>注意ES6当中引入了class语法，可以做基于class的继承了</p><h3 id="1-3-1-原型对象概述"><a href="#1-3-1-原型对象概述" class="headerlink" title="1.3.1 原型对象概述"></a>1.3.1 原型对象概述</h3><ul><li><p>构造函数</p><ul><li><p>JS通过构造函数生成新对象，因此构造函数可以视为对象的模板</p></li><li><p>实例对象的属性和方法定义在构造函数的内部</p></li><li><p>属性实际上是定义在了实例对象上的，但是同一个构造函数的多个实例之间，无法共享属性，从而造成了资源的浪费</p></li><li><p>JavaScript使用原型对象来解决这个问题  – prototype </p><ul><li>其作用就是定义所有实例对象共享的属性和方法 </li></ul><p>function Cat (name, color) {<br>this.name = name;<br>this.color = color;<br>}</p><p>var cat1 = new Cat(‘大毛’, ‘白色’);</p><p>cat1.name // ‘大毛’<br>cat1.color // ‘白色’</p></li></ul></li><li><p>prototype属性的作用</p><ul><li>原型对象的所有属性和方法都能被实例对象共享</li><li>如果属性和方法定义在原型上，那么所有实例对象都能共享<ul><li>节省内存</li><li>体现实例对象之间的联系</li></ul></li><li>原型对象的属性不是实例对象自身的属性，只要修改原型对象，变动就立刻会体现在所有实例对象上</li><li>当实例对象没有某个属性或者方法的时候，会与原型对象上去找，如果有，就用自己的</li></ul></li></ul><pre><code>function Animal(name) {  this.name = name;}Animal.prototype.color = &#39;white&#39;;var cat1 = new Animal(&#39;大毛&#39;);var cat2 = new Animal(&#39;二毛&#39;);cat1.color // &#39;white&#39;cat2.color // &#39;white&#39;cat1.color = &#39;black&#39;;cat1.color // &#39;black&#39;</code></pre><ul><li>原型链<ul><li>JS规定所有对象都有自己的原型对象(prototype)</li><li>一层层回溯，所有对象的原型最终上溯到Object.prototype,即Object构造函数的prototype属性</li><li>而Object.prototype的原型是null</li><li>读取对象的某个属性时，先寻找对象本身的属性，如果找不到，就去原型找，如果还是找不到，就去原型的原型，一层层溯源。一直没有就返回undefined</li><li>如果对象自身和它的原型<strong>都定义了同名属性，那么优先读取对象自身的属性</strong>， – overriding </li></ul></li></ul><pre><code>var MyArray = function () {};MyArray.prototype = new Array();MyArray.prototype.constructor = MyArray;// mine是MyArray的一个实例对象，由于MyArray.protutype指向一个数组实例，使得mine可以调用数组方法var mine = new MyArray();mine.push(1, 2, 3);mine.length // 3mine instanceof Array // true</code></pre><ul><li><p>constructor属性</p><ul><li>prototype对象的constructor属性，默认指向prototype对象所在的构造函数</li><li>constructor属性的作用是可以得知某个是力度向，到底是哪一个构造函数产生的</li></ul></li><li><p>instanceof运算符</p><ul><li>返回一个布尔值，表示对象是否为某个构造函数的实例 </li></ul></li><li><p>构造函数的继承</p><ul><li>让一个构造函数继承另一个构造函数<ul><li>在子类的构造函数当中，调用父类的构造函数</li><li>让子类的原型指向父类的原型，使得子类继承父类的原型</li></ul></li></ul></li></ul><pre><code>// Sub是构造函数，this是子类的实例// 子类上调用父类的构造函数super，使得子类实例具有父类实例的属性function Sub(value) {  Super.call(this);  this.prop = value;}// 让子类的原型指向父类的原型，使得子类继承父类的原型// 使用Object.create是为了不对父类原型造成修改Sub.prototype = Object.create(Super.prototype);Sub.prototype.constructor = Sub;Sub.prototype.method = &#39;...&#39;;</code></pre><p>一个继承的实例:</p><pre><code>function Shape() {  this.x = 0;  this.y = 0;}Shape.prototype.move = function (x, y) {  this.x += x;  this.y += y;  console.info(&#39;Shape moved.&#39;);};// 第一步，子类继承父类的实例function Rectangle() {  Shape.call(this); // 调用父类构造函数}// 另一种写法function Rectangle() {  this.base = Shape;  this.base();}// 第二步，子类继承父类的原型Rectangle.prototype = Object.create(Shape.prototype);Rectangle.prototype.constructor = Rectangle;</code></pre><h2 id="1-4-Object对象的相关方法"><a href="#1-4-Object对象的相关方法" class="headerlink" title="1.4 Object对象的相关方法"></a>1.4 Object对象的相关方法</h2><ul><li>Object.getPrototypeOf()<ul><li>返回参数对象的原型</li></ul></li></ul><pre><code>// 空对象的原型是 Object.prototypeObject.getPrototypeOf({}) === Object.prototype // true// Object.prototype 的原型是 nullObject.getPrototypeOf(Object.prototype) === null // true// 函数的原型是 Function.prototypefunction f() {}Object.getPrototypeOf(f) === Function.prototype // true</code></pre><ul><li>Object.setPrototypeOf() <ul><li>为参数对象设置原型，返回该参数的对象</li><li>第一个参数为现有对象，第二个为原型对象</li></ul></li></ul><pre><code>var a = {};var b = {x: 1};Object.setPrototypeOf(a, b);Object.getPrototypeOf(a) === b // truea.x // 1</code></pre><ul><li>Object.create()<ul><li>接受一个对象作为参数，然后以它为原型，返回一个实例对象。该实例完全继承原型对象的属性</li></ul></li><li>Object.prototype.<strong>proto</strong><ul><li>实例对象的该属性，返回该对象的原型 </li></ul></li></ul><h2 id="1-5-严格模式"><a href="#1-5-严格模式" class="headerlink" title="1.5 严格模式"></a>1.5 严格模式</h2><p>该种模式采用更加严格的JavaScript语法</p><ul><li>明确机制不合理，不严谨的语法</li><li>增加更多的报错场合，消除代码运行的不安全之处，保证代码的运行安全</li><li>提高编译器效率，增加运行速度</li></ul><p>开启的话，使用<code>use strict</code></p><ul><li>use strict放在脚本的第一行，整个脚本都将以严格模式来运行，如果不在第一行就无效，会以正常模式运行</li><li>显式报错<ul><li>只读属性不可写</li><li>只设置了getter的不可写</li></ul></li><li>安全措施<ul><li>全局变量显式声明</li><li>禁止this关键字指向全局对象</li></ul></li></ul><h1 id="2-异步操作"><a href="#2-异步操作" class="headerlink" title="2. 异步操作"></a>2. 异步操作</h1><h2 id="2-1-General"><a href="#2-1-General" class="headerlink" title="2.1 General"></a>2.1 General</h2><h3 id="2-1-1-单线程模型"><a href="#2-1-1-单线程模型" class="headerlink" title="2.1.1 单线程模型"></a>2.1.1 单线程模型</h3><p>JS只在一个线程上运行的  单个脚本只能在一个线程上运行，其他线程都是在后台配合的</p><p>好吃执行简单，坏处就是慢，只要一个任务耗时很长，那么后面的任务就都需要排队等着，会拖延整个程序的执行。</p><p>JS本身不慢，慢的是读写外部数据，等待Ajax请求返回结果。这个时候如果对方服务器一直没有反应，或者网络不通畅，就会导致脚本的长时间停滞。</p><p>因为很多时候慢在IO操作，而CPU实际上是处于闲置状态的，因此CPU这个时候完全可以不管IO操作，挂起处于等待中的任务，先运行排在后面的任务，等到IO操作返回结果，再回头将挂起的任务继续执行下去</p><h3 id="2-1-2-同步任务与异步任务"><a href="#2-1-2-同步任务与异步任务" class="headerlink" title="2.1.2 同步任务与异步任务"></a>2.1.2 同步任务与异步任务</h3><ul><li>同步任务<ul><li>没有被引擎挂起，在主线程上排队执行的任务</li><li>只有前一个任务执行完毕，后一个任务才能开始执行</li></ul></li><li>异步任务<ul><li>被引擎放在一边，不进入主线程，而进入任务队列的任务</li><li>只有引擎认为某个异步任务可以执行了，该任务才会进入主线程执行</li><li>排在异步任务后面的代码。不用等待异步任务结束会马上运行，也就是说，异步任务不具有堵塞效应</li></ul></li></ul><h3 id="2-1-3-任务队列和事件循环"><a href="#2-1-3-任务队列和事件循环" class="headerlink" title="2.1.3 任务队列和事件循环"></a>2.1.3 任务队列和事件循环</h3><ul><li>任务队列<ul><li>存储需要当前程序处理的异步任务</li><li>主线程会执行所有的同步任务，等到同步任务执行完以后，就会去看任务队列里面的异步任务</li><li>如果满足条件，异步任务就重新进入主线程进行执行，此时变成了同步任务了</li><li>异步任务的写法即回调函数</li></ul></li><li>事件循环<ul><li>主线程来看异步任务是否有结果的方式</li><li>就是不断检查，去看挂起来的任务们有没有结果了</li></ul></li></ul><h1 id="2-1-4-异步操作的模式"><a href="#2-1-4-异步操作的模式" class="headerlink" title="2.1.4 异步操作的模式"></a>2.1.4 异步操作的模式</h1><ul><li>回调函数</li></ul><pre><code>function f1(callback) {  // ...  callback();}function f2() {  // ...}f1(f2);</code></pre><ul><li>事件监听<ul><li>异步任务的执行不取决于代码的顺序，而取决于某个事件是否发生</li></ul></li></ul><pre><code>f1.on(&#39;done&#39;, f2);function f1() {  setTimeout(function () {    // ...    f1.trigger(&#39;done&#39;);  }, 1000);}</code></pre><ul><li>发布订阅<ul><li>某个任务执行完成，向信号中心发布一个信号</li><li>其他任务向信号中心订阅这个信号，来知道什么时候自己可以开始执行</li></ul></li></ul><pre><code>jQuery.subscribe(&#39;done&#39;, f2);function f1() {  setTimeout(function () {    // ...    jQuery.publish(&#39;done&#39;);  }, 1000);}</code></pre><h3 id="2-1-5-异步操作的流程控制"><a href="#2-1-5-异步操作的流程控制" class="headerlink" title="2.1.5 异步操作的流程控制"></a>2.1.5 异步操作的流程控制</h3><ul><li>串行执行</li></ul><pre><code>var items = [ 1, 2, 3, 4, 5, 6 ];var results = [];function async(arg, callback) {  console.log(&#39;参数为 &#39; + arg +&#39; , 1秒后返回结果&#39;);  setTimeout(function () { callback(arg * 2); }, 1000);}function final(value) {  console.log(&#39;完成: &#39;, value);}function series(item) {  if(item) {    async( item, function(result) {      results.push(result);      return series(items.shift());    });  } else {    return final(results[results.length - 1]);  }}series(items.shift());</code></pre><ul><li>并行执行<ul><li>并行会快，但是如果并行任务太多，很容易耗尽系统的资源，拖慢运行速度 </li></ul></li></ul><pre><code>var items = [ 1, 2, 3, 4, 5, 6 ];var results = [];function async(arg, callback) {  console.log(&#39;参数为 &#39; + arg +&#39; , 1秒后返回结果&#39;);  setTimeout(function () { callback(arg * 2); }, 1000);}function final(value) {  console.log(&#39;完成: &#39;, value);}items.forEach(function(item) {  async(item, function(result){    results.push(result);    if(results.length === items.length) {      final(results[results.length - 1]);    }  })});</code></pre><ul><li>并行与串行相结合!!!!!<ul><li>设置一个门槛，每次最多只能并行执行n个异步任务</li></ul></li></ul><pre><code>var items = [ 1, 2, 3, 4, 5, 6 ];var results = [];var running = 0;var limit = 2;function async(arg, callback) {  console.log(&#39;参数为 &#39; + arg +&#39; , 1秒后返回结果&#39;);  setTimeout(function () { callback(arg * 2); }, 1000);}function final(value) {  console.log(&#39;完成: &#39;, value);}function launcher() {  while(running &lt; limit &amp;&amp; items.length &gt; 0) {    var item = items.shift();    async(item, function(result) {      results.push(result);      running--;      if(items.length &gt; 0) {        launcher();      } else if(running == 0) {        final(results);      }    });    running++;  }}launcher();</code></pre><h2 id="2-2-定时器"><a href="#2-2-定时器" class="headerlink" title="2.2 定时器"></a>2.2 定时器</h2><p>JS提供定时执行代码的功能，由setTimeout()以及setInterval()两个函数来完成，它们可以向任务队列添加定时任务。</p><ul><li>setTimeout()<ul><li>指定某个函数或者某段代码，在多少毫秒之后执行</li><li>返回一个整数，表示定时器的编号</li><li><code>var timerId = setTimeout(func|code, delay)</code></li></ul></li></ul><pre><code>// 1,1是回调函数的参数setTimeout(function (a,b) {  console.log(a + b);}, 1000, 1, 1);</code></pre><ul><li>setInterval()<ul><li>setInterval是设置某个任务每隔一段时间就执行一次，为无限次的执行的</li><li>指定的是开始执行之间的间隔，没有考虑每次任务执行本身所消耗的时间</li><li>为了确定两次执行之间的固定间隔，可以使用setTimeout来指定下一次执行的具体时间</li></ul></li></ul><pre><code>var i = 1;var timer = setTimeout(function f() {  // ...  timer = setTimeout(f, 2000);}, 2000);</code></pre><ul><li>clearTimeout() clearInterval()<ul><li>传入对应的计数器编号，就可以取消对应的定时器了</li></ul></li></ul><h3 id="2-2-1-Debounce-函数"><a href="#2-2-1-Debounce-函数" class="headerlink" title="2.2.1 Debounce 函数"></a>2.2.1 Debounce 函数</h3><p>想要解决的问题：不希望回调函数被频繁调用，即当用户填入网页输入框的内容以后，用户会点击button希望能传回数据，但是很有可能是在多次重复相同的信息的。</p><p>因此我们应该加一个门槛，表示两次Ajax通信的最小间隔时间。如果在间隔时间内发生了新的keydown时间，就不触发Ajax通信，并且开始重新计时。如果过了指定时间，没有发生新的keydown事件，再将数据发送出去。</p><pre><code>// 在2.5秒内，当用户再次敲击的时候，会取消上次定时器，然后再新建一个定时器$(&#39;textarea&#39;).on(&#39;keydown&#39;, debounce(ajaxAction, 2500));function debounce(fn, delay){  var timer = null; // 声明计时器  return function() {    var context = this;    var args = arguments;    clearTimeout(timer);    timer = setTimeout(function () {      fn.apply(context, args);    }, delay);  };}</code></pre><h3 id="2-2-2-运行机制"><a href="#2-2-2-运行机制" class="headerlink" title="2.2.2 运行机制"></a>2.2.2 运行机制</h3><p>setTimeout和setInterval都是将指定的代码移出本轮事件循环，等到下一轮事件循环，再检查时间是否到了指定的时间。如果到了，就执行对应的代码，如果不到，就继续等待。</p><p>这意味着，setTimeout 和 setInterval指定的回调函数，必须等到<strong>本轮事件循环</strong>的所有同步任务都执行完. 由于前面的任务到底需要多少时间执行完，是不确定的，所以我们是无法保证二者指定的任务一定会按照预定时间执行</p><pre><code>setInterval(function () {  console.log(2);}, 1000);sleep(3000);function sleep(ms) {  var start = Date.now();  while ((Date.now() - start) &lt; ms) {  }}</code></pre><p>上面例子会先sleep 3秒然后才会输出2，注意是不累计的，即只输出一个2的</p><h3 id="2-2-3-setTimeout-f-0-及其应用"><a href="#2-2-3-setTimeout-f-0-及其应用" class="headerlink" title="2.2.3 setTimeout(f,0) 及其应用"></a>2.2.3 setTimeout(f,0) 及其应用</h3><p>setTimeout(f,0)也不会直接执行的，因为它必须要等待当前脚本的同步任务全部处理完以后，才会执行setTimeout指定的回调函数f，即setTimeout(f,0)会在下一轮事件循环开始的时候执行</p><pre><code>setTimeout(function () {  console.log(1);}, 0);console.log(2);// 2// 1</code></pre><p><strong>setTimeout的应用</strong></p><ul><li>调整事件的发生顺序</li><li>调整用户自定义的回调函数和浏览器默认动作之间的执行顺序</li><li>setTimeout(f,0)意味着将任务放到浏览器最早可得的空闲时段执行，所以那些计算量大，耗时长的任务通常可以分成几个小部分分别方法这个方法当中去</li></ul><pre><code>// HTML 代码如下// &lt;input type=&quot;button&quot; id=&quot;myButton&quot; value=&quot;click&quot;&gt;var input = document.getElementById(&#39;myButton&#39;);input.onclick = function A() {  setTimeout(function B() {    input.value +=&#39; input&#39;;  }, 0)};document.body.onclick = function C() {  input.value += &#39; body&#39;};// HTML 代码如下// &lt;input type=&quot;text&quot; id=&quot;input-box&quot;&gt;document.getElementById(&#39;input-box&#39;).onkeypress = function (event) {  this.value = this.value.toUpperCase();}document.getElementById(&#39;input-box&#39;).onkeypress = function() {  var self = this;  setTimeout(function() {    self.value = self.value.toUpperCase();  }, 0);}var div = document.getElementsByTagName(&#39;div&#39;)[0];// 写法一for (var i = 0xA00000; i &lt; 0xFFFFFF; i++) {  div.style.backgroundColor = &#39;#&#39; + i.toString(16);}// 写法二var timer;var i=0x100000;function func() {  timer = setTimeout(func, 0);  div.style.backgroundColor = &#39;#&#39; + i.toString(16);  if (i++ == 0xFFFFFF) clearTimeout(timer);}timer = setTimeout(func, 0);</code></pre><h2 id="2-3-Promise对象"><a href="#2-3-Promise对象" class="headerlink" title="2.3 Promise对象"></a>2.3 Promise对象</h2><p>JS的异步操作解决方案，为异步操作提供统一的接口，起到代理的作用，充当异步操作与回调函数之间的中介，使得异步操作具备同步操作的接口。Promise可以让异步操作写法和写同步操作相似，不必一层层地嵌套回调函数</p><pre><code>function f1(resolve, reject) {    // 异步代码}var p1 = new Promise(f1);</code></pre><p>上述例子当中接受一个回调函数f1作为参数，f1里面是异步操作的代码，然后返回p1为一个Promise实例。</p><p>所有异步任务都返回一个Promise实例，然后通过自带的then方法，来指定下一步的回调函数。通过then的写法，来减少函数和函数之间的嵌套的写法。</p><h3 id="2-3-1-Promise对象的状态"><a href="#2-3-1-Promise对象的状态" class="headerlink" title="2.3.1 Promise对象的状态"></a>2.3.1 Promise对象的状态</h3><ul><li>异步操作未完成 - pending</li><li>resolved<ul><li>异步操作成功 - fulfilled</li><li>异步操作失败 - rejected</li></ul></li></ul><p>一旦状态发生变化，就不会再有新的状态变化了，即Promise的实例的状态变化只可能发生一次</p><p>Promise原生构造函数接受一个函数作为参数，有两个参数，分别为resolve还有reject。</p><h3 id="2-3-2-Promise-prototype-then"><a href="#2-3-2-Promise-prototype-then" class="headerlink" title="2.3.2 Promise.prototype.then()"></a>2.3.2 Promise.prototype.then()</h3><ul><li>then方法用来添加回调函数<ul><li>第一个回调函数是异步操作成功用的</li><li>第二个是异步操作失败使用</li></ul></li><li>Promise的报错具有传递性</li></ul><pre><code>p1  .then(step1)  .then(step2)  .then(step3)  .then(    console.log,    console.error  );</code></pre><p>在上述的例子里面，console.log 只显示step3的内容，但是console.error会显示出step1，2，3出现的任意错误。Promise对象的报错具有传递性 </p><h1 id="3-DOM"><a href="#3-DOM" class="headerlink" title="3. DOM"></a>3. DOM</h1><h2 id="3-1-Intro"><a href="#3-1-Intro" class="headerlink" title="3.1 Intro"></a>3.1 Intro</h2><p>DOM是JavaScript操作网页的接口，全称为文档对象模型(Document Object Model).它的作用是将网页转为一个JavaScript对象，从而可以用脚本进行各种操作。</p><p>浏览器根据DOM模型，将结构化文档解析成一系列的节点，再由这些节点组成一个树状结构 - DOM tree。所有的节点和最终的树状架构，都有规范的对外接口。</p><ul><li><p>节点  </p><ul><li>DOM的最小组成单位</li></ul></li><li><p>节点类型</p><ul><li>Document 文档树的顶层节点</li><li>DocumentType doctype标签，比如    <code>&lt;!DOCTYPE html&gt;</code></li><li>Element 网页的各种HTML标签</li><li>Attribute  网页元素的属性</li><li>Text  标签之间或标签包含的文本</li><li>comment 注释</li><li>DocumentFragment  文档片段<h2 id="3-2-Node简述"><a href="#3-2-Node简述" class="headerlink" title="3.2 Node简述"></a>3.2 Node简述</h2><h3 id="3-2-1-Node接口"><a href="#3-2-1-Node接口" class="headerlink" title="3.2.1 Node接口"></a>3.2.1 Node接口</h3></li></ul></li><li><p>nodeType </p><ul><li>返回一个整数值，表示节点的类型<ul><li>document 9 </li><li>element  1</li><li>attr     2</li><li>text     3</li><li>documentFragment 11 </li><li>documentType     10</li><li>Comment          8</li></ul></li></ul></li><li><p>nodeName</p><ul><li>返回节点的名称</li></ul></li><li><p>nodeValue</p><ul><li>返回一个字符串，表示当前节点本身的文本值，该属性可读写</li></ul></li></ul><pre><code>var div = document.getElementById(&#39;d1&#39;);div.nodeValue // nulldiv.firstChild.nodeValue // &quot;hello world&quot;</code></pre><ul><li>Node.prototype.textContent<ul><li>textContent属性返回当前节点和它的所有后代节点的文本内容</li><li>该属性是可读写的，设置该属性的值，会用一个新的文本节点代替原有的子节点</li><li>注意转译的时候HTML标签会被忽略掉的</li></ul></li></ul><pre><code>document.getElementById(&#39;foo&#39;).textContent = &#39;&lt;p&gt;GoodBye!&lt;/p&gt;&#39;;</code></pre><ul><li>Node.prototype.baseURI<ul><li>返回一个字符串，表示当前网页的绝对路径</li><li>浏览器会根据这个属性计算网页上的相对路径的URL  </li><li>该属性为只读 </li></ul></li></ul><pre><code>document.baseURI// &quot;http://www.example.com/index.html&quot;</code></pre><ul><li><p>Node.prototype.ownerDocument </p><ul><li>返回当前节点所在的顶层文档对象，即document对象</li></ul></li><li><p>Node.prototype.nextSibling </p><ul><li>返回紧跟在当前节点后面的第一个同级节点 </li><li>如果当前节点后面没有同级节点，就返回null </li><li>该属性可以用来遍历所有子节点</li></ul></li></ul><pre><code>var d1 = document.getElementById(&#39;d1&#39;);var d2 = document.getElementById(&#39;d2&#39;);d1.nextSibling === d2 // true// 遍历所有同级节点var el = document.getElementById(&#39;div1&#39;).firstChild;while (el !== null) {  console.log(el.nodeName);  el = el.nextSibling;}</code></pre><ul><li>Node.prototype.previousSibling <ul><li>返回倩倩节点前面的，距离最近的，同级的节点</li><li>如果没有同级节点，就返回null </li></ul></li><li>Node.prototype.parentNode<ul><li>返回当前节点的父节点</li><li>对于一个节点来说，其父节点可能为：<ul><li>element </li><li>document </li><li>documentFragment </li></ul></li></ul></li><li>Node.prototype.parentElement </li><li>Node.prototype.firstChild</li><li>Node.prototype.lastChild</li><li>Node.prototype.childNodes<ul><li>返回Nodelist集合，包括当前节点的所有子节点</li></ul></li><li>Node.prototype.isConnected<ul><li>返回一个布尔值，表示当前节点是否在文档当中</li></ul></li></ul><h3 id="3-2-2-node方法"><a href="#3-2-2-node方法" class="headerlink" title="3.2.2 node方法"></a>3.2.2 node方法</h3><ul><li>appendChild()<ul><li>接受一个节点对象作为参数，将其作为最后一个子节点，插入当前节点</li><li>如果参数节点是DOM已经存在的节点，appendChild方法会将其从原来的位置移动到新位置</li></ul></li><li>hasChildNodes()<ul><li>返回一个布尔值，表示当前节点是否有子节点</li></ul></li><li>cloneNode()<ul><li>克隆一个节点，接受一个布尔值作为参数， 表示是否同时克隆子节点</li><li>返回值为一个克隆出来的新节点</li></ul></li><li>insertBefore()<ul><li>用来将某个节点插入父节点内部的指定位置</li><li><code>var insertedNode = parentNode.insertBefore(newNode, referenceNode);</code></li></ul></li><li>removeChild()<ul><li>接受一个子节点作为参数，用于从当前节点移除该子节点</li></ul></li><li>replaceChild()<ul><li>用于将一个新的节点替换当前节点的某一个子节点</li></ul></li><li>contains()<ul><li>返回布尔值，看参数节点是否满足以下条件<ul><li>参数节点为当前节点</li><li>为当前节点的子节点</li><li>为当前节点的后代节点</li></ul></li></ul></li><li>getRootNode()<ul><li>返回当前节点所在文档的根节点document,与ownerDocument属性的作用相同 </li></ul></li></ul><h2 id="3-3-Document节点"><a href="#3-3-Document节点" class="headerlink" title="3.3 Document节点"></a>3.3 Document节点</h2><p>document节点对象代表整个文档，每个网页都有自己的document对象，<code>window.document</code>属性就指向这个对象</p><ul><li>正常网页可以直接使用docuemnt 还有window.document</li><li>iframe框架里面的网页，使用iframe节点的contentDocument属性</li><li>Ajax操作返回的文档，使用XMLHttpRequest对象的responseXML属性</li></ul><h3 id="3-3-1-快捷方式属性"><a href="#3-3-1-快捷方式属性" class="headerlink" title="3.3.1 快捷方式属性"></a>3.3.1 快捷方式属性</h3><ul><li>document.defaultView <ul><li>返回document对象所属的window对象</li></ul></li><li>document.doctype</li></ul><pre><code>var doctype = document.doctype;doctype // &quot;&lt;!DOCTYPE html&gt;&quot;doctype.name // &quot;html&quot;</code></pre><ul><li>document.documentElement <ul><li>返回当前文档的根元素节点</li><li>通常为document节点的第二个子节点，紧跟在document.doctype节点后面</li></ul></li><li>document.body<ul><li>指向body节点</li></ul></li><li>document.head<ul><li>指向head节点</li></ul></li><li>document.scrollingElement <ul><li>返回文档的滚动元素</li></ul></li><li>document.activeElement <ul><li>返回获得当前焦点的DOM元素</li><li>通常这个属性返回的是<code>&lt;input&gt; &lt;textarea&gt; &lt;select&gt;</code>这类表单元素</li></ul></li><li>document.fullscreenElement <ul><li>返回当前以全屏状态展示的DOM元素 </li></ul></li></ul><h3 id="3-3-2-节点集合属性"><a href="#3-3-2-节点集合属性" class="headerlink" title="3.3.2 节点集合属性"></a>3.3.2 节点集合属性</h3><p>返回一个HTMLCollection实例，表示文档内部特定元素的集合。这些集合是动态的，原节点有任何变化，立刻会反映在集合当中 </p><ul><li>document.links </li><li>document.forms</li><li>document.images </li><li>document.embeds  / document.plugins <ul><li>返回所有<embed>节点</li></ul></li><li>document.scripts</li><li>document.styleSheets</li></ul><h3 id="3-3-3-文档静态信息属性"><a href="#3-3-3-文档静态信息属性" class="headerlink" title="3.3.3 文档静态信息属性"></a>3.3.3 文档静态信息属性</h3><ul><li>document.documentURI / document.URL<ul><li>返回一个字符串，表示当前文档的网址</li><li>不同之处在于他们继承自不同的接口</li><li>documentURI 继承自Document接口，可用于所有文档</li><li>URL 继承自HTMLDocument接口，只可用于HTML文档</li></ul></li><li>document.domain<ul><li>返回当前文档的域名 </li><li>比如，网页的网址是<a href="http://www.example.com:80/hello.html，那么document.domain属性就等于www.example.com" target="_blank" rel="noopener">http://www.example.com:80/hello.html，那么document.domain属性就等于www.example.com</a></li></ul></li><li>document.location <ul><li>浏览器原生对象，提供URL相关的信息和操作方法</li><li>通过window.location 和document.location属性，可以拿到这个对象</li></ul></li><li>document.lastModified <ul><li>返回当前文档的问候修改时间</li></ul></li><li>document.title </li><li>document.characterSet <ul><li>UTF-8</li><li>ISO-8859-1</li><li>etc.</li></ul></li><li>document.referrer <ul><li>返回字符串，表示当前文档的访问者来的地方</li></ul></li><li>document.dir <ul><li>返回一个字符串<ul><li>rtl</li><li>ltr</li></ul></li></ul></li><li>document.compatMode<ul><li>返回浏览器处理文档的模式 </li><li>BackCompat 向后兼容模式</li><li>CSS1Compat 严格模式</li></ul></li></ul><h3 id="3-3-4-文档状态属性"><a href="#3-3-4-文档状态属性" class="headerlink" title="3.3.4 文档状态属性"></a>3.3.4 文档状态属性</h3><ul><li>hidden<ul><li>返回一个布尔值</li></ul></li><li>visibilityState  返回当前文档的可见状态<ul><li>visible</li><li>hidden</li><li>prerender 正在渲染的状态，对于用户来说，这个页面不可见</li><li>unloaded 从内存中卸载了</li></ul></li><li>readyState  返回当前文档的状态<ul><li>loading 加载HTML代码阶段</li><li>interactive  加载外部资源阶段</li><li>complete  加载完成</li></ul></li><li>cookie</li><li>designMode <ul><li>on/ off</li><li>当开启以后，用户就可以编辑整个文档的内容了</li></ul></li><li>implementation <ul><li>返回一个DOMImplementation对象 </li><li>DOMImplementation.createDocument()</li><li>DOMImplementation.createHTMLDocument()</li><li>DOMImplementation.createDocumentType() </li></ul></li></ul><h3 id="3-3-5-Document相关方法"><a href="#3-3-5-Document相关方法" class="headerlink" title="3.3.5 Document相关方法"></a>3.3.5 Document相关方法</h3><ul><li>document.open()  document.close() <ul><li>open用来清除当前文档的所有内容，使得文档处于可写状态</li><li>document.close用来关闭打开的文档</li></ul></li><li>document.write()  document.writeln()<ul><li>write用于向当前文档写入内容</li><li>当页面已经解析完成以后，再调用write会先调用open方法，这样所有文档的内容就已经被擦除了</li><li>在页面渲染过程中的调用write方法，并不会自动调用open方法</li><li>writeln是在末尾会添加换行符</li></ul></li></ul><pre><code>document.addEventListener(&#39;DOMContentLoaded&#39;, function (event) {  document.write(&#39;&lt;p&gt;Hello World!&lt;/p&gt;&#39;);});// 等同于document.addEventListener(&#39;DOMContentLoaded&#39;, function (event) {  document.open();  document.write(&#39;&lt;p&gt;Hello World!&lt;/p&gt;&#39;);  document.close();});</code></pre><ul><li>document.querySelector()  document.querySelectorAll()<ul><li>接受一个CSS选择器作为参数，返回匹配该选择器的元素节点。如果多个节点满足匹配条件，则返回第一个匹配的节点。如果没有发现匹配的节点，则返回null</li><li>querySelectorAll方法与querySelector类似，区别在于返回的是NodeList对象，包含所有匹配给定选择器的节点</li></ul></li></ul><pre><code>var el1 = document.querySelector(&#39;.myclass&#39;);var el2 = document.querySelector(&#39;#myParent &gt; [ng-click]&#39;);// 选中 data-foo-bar 属性等于 someval 的元素document.querySelectorAll(&#39;[data-foo-bar=&quot;someval&quot;]&#39;);// 选中 myForm 表单中所有不通过验证的元素document.querySelectorAll(&#39;#myForm :invalid&#39;);// 选中div元素，那些 class 含 ignore 的除外document.querySelectorAll(&#39;DIV:not(.ignore)&#39;);// 同时选中 div，a，script 三类元素document.querySelectorAll(&#39;DIV, A, SCRIPT&#39;);</code></pre><ul><li>document.getElementsByTagName()<ul><li>搜索HTML标签名，返回符合条件的元素</li><li>返回的为一个HTMLCollection对象</li><li>可以实时反映HTML文档的变化</li></ul></li><li>document.getElementsByClassName()<ul><li>返回一个类似数组的对象，包括了所有class名字符合指定条件的元素，元素的变化实时反映在返回结果当中</li></ul></li><li>document.getElementsByName()<ul><li>用于选择拥有name属性的HTML元素，返回一个类似数组的对象</li></ul></li><li>document.getElementById()<ul><li>返回匹配指定id属性的元素节点</li><li>如果没有发现匹配的节点，则返回null</li></ul></li><li>document.elementFromPoint()  document.elementsFromPoint()<ul><li>返回位于页面指定位置最上层的元素节点 </li><li><code>var element = document.elementFromPoint(50, 50);</code></li><li>该代码就会选中在这个坐标上的最上层的HTML元素</li><li>两个参数是相对于左上角的横坐标和纵坐标，单位是像素</li></ul></li><li>document.createElement()<ul><li>用来生成元素节点，并返回该节点</li><li>方法的参数为元素的标签名，即元素节点的tagName属性</li></ul></li><li>document.createTextNode()<ul><li>用来生成文本节点，并返回该节点</li><li>参数是文本节点的内容</li></ul></li></ul><pre><code>var newDiv = document.createElement(&#39;div&#39;);var newContent = document.createTextNode(&#39;Hello&#39;);newDiv.appendChild(newContent);</code></pre><ul><li>document.createAttribute() <ul><li>生成一个新的属性节点</li></ul></li></ul><pre><code>var node = document.getElementById(&#39;div1&#39;);var a = document.createAttribute(&#39;my_attrib&#39;);a.value = &#39;newVal&#39;;node.setAttributeNode(a);// 或者node.setAttribute(&#39;my_attrib&#39;, &#39;newVal&#39;);</code></pre><ul><li>document.createComment() </li><li>document.createDocumentFragment()<ul><li>生成一个空的文档片段对象 </li><li>是存于内存的DOM片段，不属于当前文档，常常用来生成一段较为复杂的DOM结构，然后再插入到文档当中</li><li>因为DocumentFragment不属于当前文档，对其任何改动都不会引发网页的重新渲染，比直接修改当前文档的DOM有更好的性能表现</li></ul></li></ul><ul><li>document.createEvent() <ul><li>生成一个事件对象</li><li>其参数为事件类型，比如<ul><li>MouseEvents</li><li>MutationEvents</li><li>HTMLEvents </li></ul></li></ul></li></ul><pre><code>var event = document.createEvent(&#39;Event&#39;);event.initEvent(&#39;build&#39;, true, true);document.addEventListener(&#39;build&#39;, function (e) {  console.log(e.type); // &quot;build&quot;}, false);document.dispatchEvent(event);</code></pre><ul><li>document.addEventListener() <ul><li>添加事件监听函数 </li></ul></li><li>document.removeEventListner()<ul><li>移除事件监听函数 </li></ul></li><li>document.dispatchEvent()<ul><li>触发事件</li></ul></li><li>document.hasFocus()<ul><li>返回一个布尔值，表示当前文档是否有元素被激活或者获得了焦点</li></ul></li><li>document.adoptNode()<ul><li>document.adoptNode方法将某个节点及其子节点，从原来所在的文档或DocumentFragment里面移除，归属当前document对象，返回插入后的新节点。插入的节点对象的ownerDocument属性，会变成当前的document对象，而parentNode属性是null</li></ul></li></ul><pre><code>var node = document.adoptNode(externalNode);document.appendChild(node);</code></pre><h2 id="3-4-Element-节点"><a href="#3-4-Element-节点" class="headerlink" title="3.4 Element 节点"></a>3.4 Element 节点</h2><p>Element结点对应网页的HTML元素，每个HTML原色，在DOM树上都会转化成一个ELement节点对象</p><h3 id="3-4-1-实例属性"><a href="#3-4-1-实例属性" class="headerlink" title="3.4.1 实例属性"></a>3.4.1 实例属性</h3><ul><li>Element.id</li><li>Element.tagName <ul><li>返回指定元素的大写标签名</li></ul></li><li>Element.dir<ul><li>用于读写当前元素的文字方向</li></ul></li><li>Element.accessKey<ul><li>用于读写分配给当前元素的快捷键</li></ul></li></ul><pre><code>// HTML 代码为 &lt;p id=&quot;foo&quot;&gt;var p = document.querySelector(&#39;p&#39;);p.id // &quot;foo&quot;// HTML代码为// &lt;span id=&quot;myspan&quot;&gt;Hello&lt;/span&gt;var span = document.getElementById(&#39;myspan&#39;);span.id // &quot;myspan&quot;span.tagName // &quot;SPAN&quot;// HTML 代码如下// &lt;button accesskey=&quot;h&quot; id=&quot;btn&quot;&gt;点击&lt;/button&gt;var btn = document.getElementById(&#39;btn&#39;);btn.accessKey // &quot;h&quot;</code></pre><ul><li><p>Element.draggable</p><ul><li>返回一个布尔值，表示当前元素是否可拖动，该属性可读写</li></ul></li><li><p>Element.lang</p><ul><li>返回当前元素的语言设置 </li></ul></li><li><p>Element.tabIndex</p><ul><li>返回一个整数值，表示当前元素在tab键遍历的时候的顺序</li><li>如果为负值，在tab不会遍历到这个原色</li><li>对于正整数，按照顺序从小到大进行遍历</li></ul></li><li><p>Element.title</p><ul><li>用于读写当前元素HTML属性的title </li><li>用于指定鼠标悬浮时弹出的文字提示框</li></ul></li><li><p>Element.hidden</p><ul><li>控制当前元素是否可见</li><li>CSS的设置高于hidden  即如果css层规定了<code>display:none</code>或者<code>display:hidden</code> 那么element.hidden是无法改变其可见性的</li></ul></li><li><p>Element.contentEditable  Element.isContentEditable </p></li><li><p>Element.attributes </p><ul><li>返回一个类似数组的对象，成员是当前元素节点的所有属性节点</li></ul></li><li><p>Element.className Element.classList</p><ul><li>用来读写当前原色节点的class属性</li><li>其值为一个字符串，每个class之间用空格来分割</li><li>st</li><li>返回一个类似数组的对象</li></ul></li></ul><pre><code>// HTML 代码 &lt;div class=&quot;one two three&quot; id=&quot;myDiv&quot;&gt;&lt;/div&gt;var div = document.getElementById(&#39;myDiv&#39;);div.className// &quot;one two three&quot;div.classList// {//   0: &quot;one&quot;//   1: &quot;two&quot;//   2: &quot;three&quot;//   length: 3// }</code></pre><ul><li>Element.innerHTML <ul><li>返回一个字符串，等同于该元素包含的所有HTML代码</li><li>可以读写</li><li>用于设定某个节点的内容</li><li>能够改变所有元素结点的内容，包括HTML body这类元素</li></ul></li></ul><pre><code>// HTML代码如下 &lt;p id=&quot;para&quot;&gt; 5 &gt; 3 &lt;/p&gt;document.getElementById(&#39;para&#39;).innerHTML// 5 &amp;gt; 3</code></pre><ul><li>Element.outerHTML <ul><li>返回一个字符串，表示当前元素结点的所有HTML代码，包括该元素本身和所有子元素</li></ul></li><li>Element.clientHeight Element.clientWidth<ul><li>返回一个整数值表示元素节点的CSS高度和宽度</li></ul></li></ul><h3 id="3-4-2-实例方法"><a href="#3-4-2-实例方法" class="headerlink" title="3.4.2 实例方法"></a>3.4.2 实例方法</h3><ul><li>getAttribute()</li><li>getAttributeNames() </li><li>setAttribute()</li><li>hasAttribute()</li><li>hasAttributes()</li><li>removeAttribute() </li></ul><h3 id="3-4-3-事件相关方法"><a href="#3-4-3-事件相关方法" class="headerlink" title="3.4.3 事件相关方法"></a>3.4.3 事件相关方法</h3><ul><li>Element.addEventListener()</li><li>Element.removeEventListener()</li><li>Element.dispatchEvent()</li></ul>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> JavaScript </tag>
            
            <tag> Object Oriented </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript教程 Part 1</title>
      <link href="/JavaScript%E6%95%99%E7%A8%8B-Part-1/"/>
      <url>/JavaScript%E6%95%99%E7%A8%8B-Part-1/</url>
      
        <content type="html"><![CDATA[<p>发现前面看的JS还是不太成系统，遇到的这方面的问题越来越多，需要好好的深入研究下这块内容了。</p><h1 id="1-Basic"><a href="#1-Basic" class="headerlink" title="1. Basic"></a>1. Basic</h1><h2 id="1-1-概览"><a href="#1-1-概览" class="headerlink" title="1.1 概览"></a>1.1 概览</h2><ul><li>嵌入式语言</li><li>本身的核心语法只有数学逻辑运算相关的</li><li>靠宿主环境提供各种输入输出相关的API<ul><li>浏览器</li><li>服务器环境 - nodejs</li></ul></li><li>JS的核心语法部分<ul><li>基本语法构造<ul><li>操作符</li><li>控制结构</li><li>语句</li></ul></li><li>标准库<ul><li>Array</li><li>Date </li><li>Math</li><li>…</li></ul></li></ul></li><li>除此以外，便是其宿主环境提供的各种不同的API了</li><li>浏览器<ul><li>浏览器控制类 </li><li>DOM类  html</li><li>Web类  ajax call</li></ul></li></ul><p>本文会从基本语法，标准库，浏览器API以及DOM四个大方面来解释整个js的运行。大部分内容出自阮一峰的电子书，其中加了一下自己认为不错的例子。</p><ul><li>JS性能<ul><li>JS基本上都是编译运行，运行效率很高</li><li>采取事件驱动 event-driven </li><li>非阻塞式 non-blocking </li></ul></li></ul><h2 id="1-2-基本语法"><a href="#1-2-基本语法" class="headerlink" title="1.2 基本语法"></a>1.2 基本语法</h2><ul><li>变量提升<ul><li>JS引擎会先解析代码，获取所有被声明的变量，然后再一行一行的运行。</li><li>即所有的变量的声明语句都会被提升到代码的头部。</li></ul></li><li>使用label<ul><li>定位符，用于跳转到程序的任意位置</li><li>比较常用的场景：可以跳出双重循环 - 直接</li></ul></li></ul><pre><code>outOfTwoLoops:    for (let i = 0; i &lt; 10; i ++) {        for (let j = 0; j &lt; 10; j ++) {            if (i*j &lt; 99) break outOfTwoLoops;        }    }</code></pre><h2 id="1-3-数据类型概述"><a href="#1-3-数据类型概述" class="headerlink" title="1.3 数据类型概述"></a>1.3 数据类型概述</h2><ul><li>基本数据类型<ul><li>number</li><li>string</li><li>boolean</li><li>undefined<ul><li>nothing defined (value)</li><li>when switch to number, come to be NaN </li><li>表示未定义</li></ul></li><li>null <ul><li>empty object </li><li>when switch to number, come to be 0</li><li>表示为空</li></ul></li><li>object<ul><li>狭义的对象</li><li>array</li><li>function</li></ul></li></ul></li></ul><p>JS里面将函数function也作为一种对象来进行处理，好处是可以做函数式的编程了，即可以将整个函数赋给一个变量，这就可以为编程带来非常大的灵活性了。</p><ul><li><p>typeof</p><ul><li><code>function f() {}</code></li><li><code>typeof f // function</code></li><li><code>typeof d // undefined</code></li><li><code>typeof [] // object</code></li><li><code>typeof {} // object</code></li></ul></li><li><p>数值</p><ul><li>所有数字都是以64位浮点数形式储存的，即使整数也是如此</li><li>浮点数本身就是不精确的，涉及小数的运算需要非常小心</li><li>相关方法</li></ul></li></ul><pre><code>// 字符串转化为整数parseInt(&#39;123&#39;)  // 123parseInt(&#39;123CannotProcessString&#39;)  // 123parseInt(&#39;12.343&#39;)  // 12parseInt(&#39;1.99&#39;)  // 1parseInt(&#39;hahah&#39;)  // NaN // parseInt第二个参数表示被解析的值得进制，返回的值是10进制的parseInt(&#39;1000&#39;, 2)  // 8// parseFloat same pattern with parseIntparseFloat(&#39;&#39;) // NaNparseFloat(&#39;123.45&#39;) // 123.45// 判断一个值是否为NaN, 只对数值有效，对于其他类型，首先转化为数值的时候就变成NaN了isNaN(123)  // false</code></pre><ul><li><p>NaN</p><ul><li>not a number</li><li>主要出现在将字符串解析成数组出错的场合</li><li><code>typeof NaN    // &#39;number&#39;</code></li></ul></li><li><p>字符串</p><ul><li>默认只能写在一行当中，多行会报错</li><li>如果想分在多行，需要在每一行的尾部使用反斜杠 <code>\</code></li><li>转义 <ul><li>\0 nukk</li><li>\b 后退</li><li>\f 换页</li><li>\n 换行</li><li>\r 回车</li><li>\t 制表</li><li>\v 垂直制表</li><li>&#39; 单引号</li><li>&quot; 双引号</li><li>\ 反斜杠</li></ul></li><li>字符串与数组<ul><li>字符串可以视为字符数组，因此可以使用数组的方括号运算符，用来返回某个位置的字符</li><li>但是字符串里面的单个字符无法改变和增删的，无法通过数组的形式来做这个</li><li><code>str.length</code>返回字符串的长度</li></ul></li></ul></li></ul><pre><code>var s = &#39;hello&#39;;s[0] // &quot;h&quot;s[1] // &quot;e&quot;s[4] // &quot;o&quot;// 直接对字符串使用方括号运算符&#39;hello&#39;[1] // &quot;e&quot;</code></pre><ul><li>字符集 <ul><li>JS使用Unicode字符集，JS引擎内部所有字符都是使用Unicode来进行表示的。 </li><li>因此可以直接将字符写成 <code>\uxxxx</code>的形式，后四位是该字符的Unicode码点</li></ul></li><li>Base64转码<ul><li>做转码是因为文本里面有时会有一些不可打印的符号，不是为了加密，就是为了简化程序的处理过程</li><li>Base64可以将其转化成可以打印的字符</li><li>有时也需要以文本的格式传递二进制数据，也可以使用Base64编码</li><li>btoa() 任意值转化为base64编码  binary to ASCII</li><li>atob() Base64编码转为原来的值  ASCII to binary </li><li>对于ASCII无法表示的字符，我们需要加一个encodeURIComponent的指令，来编码Uniform Resource Identifier（URI）</li></ul></li></ul><ul><li>对象<ul><li>对象是键值对的集合，是一种无序的复合数据集合</li><li>对象的所有键名都是字符串，所以可以选择不加引号</li><li>对象的每一个键名称为一个属性 property <ul><li>其键值可以是任何数据类型，如果一个属性的值为函数，那么就可以将这个属性称为方法，可以像函数那样来做调用 </li></ul></li><li>属性是可以<strong>动态创建</strong>的，不必在对象声明的时候就指定</li><li>查看对象本身的属性 <code>Object.keys</code></li><li>删除属性  <code>delete obj.p</code>     </li><li>属性是否存在 - 检查键名  <code>&#39;p&#39; in obj</code></li></ul></li></ul><pre><code>var obj = {    foo: &#39;hello&#39;,    bar: &#39;world&#39;};</code></pre><ul><li><p>表达式 or  语句</p><ul><li><code>{foo: 123}</code></li><li>这样子可以理解为一个表达式，也可以理解为一个语句，foo是个标签，指向123.</li><li>JS引擎的做法是一律解释为代码块</li><li>因此如果想要表示成一个表达式，那么我们就应该在想要表达的东西的外部加上一对小括号以撇清关系</li><li>语句 用分号进行分隔 做某种行为</li><li>表达式 由运算符构成，并运算产生结果的语法结构，用逗号进行分割 是会生成一个值得</li><li>当JS期待得到一个语句的时候，你可以使用一个表达式语句来做；但是当JS期待一个表达式的时候，你是无法带入一个语句的，比如if 语句就无法作为一个方法的参数</li></ul></li><li><p>函数</p><ul><li>可以反复调用的代码块</li><li>可以接受输入的参数，</li><li>三种声明函数的方式：<ul><li>function </li><li>函数表达式<ul><li>函数表达式的等号右侧是可以有函数名的，但是这个函数名只在这个函数体内有效，其他是无效的 </li></ul></li><li>function构造函数</li></ul></li><li>函数重复声明，后声明的会覆盖前面声明的</li><li>调用函数，使用圆括号</li><li>在JS中，凡是可以使用值的地方，就可以使用函数</li><li>因为将函数名视为变量名，所有采用function命令声明函数时，整个函数会像变量声明一样，提升到代码的头部。</li><li>函数的属性与方法<ul><li>name<ul><li>根据定义的方法的不同，返回不同值<ul><li>函数定义  返回函数名</li><li>函数表达式定义  返回变量名</li></ul></li></ul></li><li>length<ul><li>返回函数定义之中的参数个数</li><li>length属性提供了一种机制，来判断定义的时候和调用参数的差异，以便实现面向对象编程的方法重载</li></ul></li><li>toString()<ul><li>返回一个字符串，内容是函数的源码 </li></ul></li></ul></li><li>函数作用域<ul><li>global variable</li><li>local variable</li><li>函数执行时所在的作用域，是定义时的作用域，而不是调用的时候所在的作用域</li></ul></li><li>传递方式<ul><li>对于原始类型来说，是值传递的 (pass by value)，也就是说，在函数体内修改参数值，不会影响到函数的外部。</li><li>如果函数参数是复合类型的值(数组、对象、函数),那么传递方式就是传址传递 (pass by reference)。也就是说，传入函数的原始值的地址，因此在函数内部修改参数，将会影响到原始值。</li></ul></li><li>arguments对象<ul><li>因为JS当中允许函数有不同数目的参数，因此需要有一种机制能够在函数体内部读取所有的参数，因此定义了arguments对象来做这件事</li><li>arguments对象包含了函数运行时的所有参数</li><li>而且注意arguments对象与函数参数并不具有联动关系。</li><li>arguments.length 返回函数实际传入的参数的数量</li></ul></li><li>闭包<ul><li>JS的链式作用域，子对象会逐级向上寻找所有父对象的变量，因此父对象的所有变量对子对象而言都是可见的，反之不成立</li><li>闭包就是函数f2，为的是能读取函数内部的变量，并将其传递出去。</li><li>是将函数内部和函数外部连接起来的一座桥梁</li></ul></li></ul></li></ul><pre><code>function f1() {  var n = 999;  function f2() {    console.log(n);  }  return f2;}var result = f1();result(); // 999// functionfunction sayHello(var name) {    console.log(&quot;Hello&quot; + name);}// function expression var sayHello = function(var name) {    console.log(&quot;Hello&quot; + name);};// function constructor var add = new Function(    &#39;x&#39;,    &#39;y&#39;,    &#39;return x + y&#39;);// arguments var f = function(a,b) {    arguments[0] = 2;    arguments[1] = 10;    return a + b;}// f(1, 2) ----&gt; 12 </code></pre><ul><li>立即调用的函数表达式(IIFE) - immediately invoked function expression<ul><li>在JS当中，圆括号本身就是运算符，跟在函数名之后，表示调用了这个函数</li><li>有时，我们需要在定义函数之后，立即调用该函数。这时，你不能在函数的定义之后加上圆括号，这会产生语法错误。</li><li><code>function(){ /* code */ }(); // SyntaxError: Unexpected token</code></li><li>产生这个错误的原因是因为function这个关键字既可以作为语句也可以作为表达式，JS引擎为了避免歧义，就规定只要function关键字出现在行首，就一律解释为语句。</li><li><code>(function(){}());</code> 通过这种方式来进行直接的运行</li></ul></li><li>eval 指令<ul><li>用于在当前作用域当中，注入代码</li><li>但是因为安全风险和不利于JS引擎去优化执行速度，所以一般不推荐使用</li><li>最常见的场合是解析JSON数据的字符串，但一般用JSON.parse会更加合适</li></ul></li><li>数组<ul><li>任何类型的数据都可以放入数组</li><li>数组本身是一种特殊的对象</li><li>length 属性  = 键名中的最大整数加上1</li><li>数组的数字键不需要连续，length属性的值总是比最大的整数键大1</li><li>即数组是一个动态的数据结构，可以随时增减数组的成员</li><li>清空数组可以通过将数组的长度设为0来实现的</li></ul></li></ul><pre><code>var arr = [&#39;a&#39;, &#39;b&#39;];arr.length // 2arr[2] = &#39;c&#39;;arr.length // 3arr[9] = &#39;d&#39;;arr.length // 10arr[1000] = &#39;e&#39;;arr.length // 1001</code></pre><h2 id="1-4-运算符"><a href="#1-4-运算符" class="headerlink" title="1.4 运算符"></a>1.4 运算符</h2><ul><li>算数运算符<ul><li>对象的相加<ul><li>对象转成原始类型的值的规则为：</li><li>首先自动调用对象的valueOf方法，一般会返回对象本身</li><li>再自动调用对象的toString方法，将其转为字符串</li></ul></li></ul></li></ul><pre><code>var obj = {p: 1}obj + 2 // [object Object]2  ----&gt; obj.valueOf().toString()//可以自定义valueOf方法的var obj = {    valueOf: function() {        return 1;    }};obj + 2 // 3</code></pre><ul><li>比较运算符</li><li>布尔运算符<ul><li>!</li><li>&amp;&amp; </li><li>|| </li><li>?:</li></ul></li><li>二进制位运算符</li><li>其他运算符<ul><li>void<ul><li>作用是执行一个表达式，但是不返回任何值(undefined)</li><li>主要目的是为了在超级链接当中可以插入代码，但是又不产生跳转</li></ul></li><li>逗号运算符<ul><li>用于对两个表达式求值，并且返回后一个表达式的值 </li></ul></li></ul></li></ul><pre><code>// 下述代码因为onclick return false所以不会产生跳转的&lt;script&gt;function f() {  console.log(&#39;Hello World&#39;);}&lt;/script&gt;&lt;a href=&quot;http://example.com&quot; onclick=&quot;f(); return false;&quot;&gt;点击&lt;/a&gt;// 可以直接用void function来取代 return false的操作  显得清晰简洁很多的&lt;a href=&quot;javascript: void(f())&quot;&gt;文字&lt;/a&gt;</code></pre><h1 id="2-常用语法"><a href="#2-常用语法" class="headerlink" title="2. 常用语法"></a>2. 常用语法</h1><h2 id="2-1-数据类型的转换"><a href="#2-1-数据类型的转换" class="headerlink" title="2.1 数据类型的转换"></a>2.1 数据类型的转换</h2><p>变量没有类型限制，e.g: <code>var x = y ? 1 : &#39;a&#39;</code></p><p>在上述的例子当中，我们在编译的时候是不知道到底x是个数值还是个字符的，必须等到运行的时候才可以有数据。而JS当进行运算的时候，如果发现实际的类型和期待的不相符，会直接将其转化为期待的类型的。</p><ul><li>强制转换<ul><li><code>Number()</code><ul><li>可以将任意类型的值转化为数值</li><li>Number函数将字符串转为数值，要比<code>parseInt</code>严格非常多，只要有一个字符无法转成数值，整个字符串就只能被转化为NaN了</li><li>Number进行转化的规则为：<ul><li>调用对象自身的valueOf；如果为原始类型，直接对该值使用Number函数</li><li>如果valueOf返回的还是对象，那么改成调用对象的toString方法，如果toString方法返回原始类型的值，就对该值使用Number函数，不再进行后续操作</li><li>如果toString方法返回的是对象，就报错</li></ul></li></ul></li><li><code>String()</code><ul><li>原始类型值<ul><li>undefined -&gt; “undefined”</li><li>null -&gt; “null”</li></ul></li><li>对象<ul><li>对象返回类型字符串   <code>String({a: 1}) // &quot;[object Object]&quot;</code></li><li>数组返回其字符串形式 <code>String([1, 2, 3]) // &quot;1,2,3&quot;</code></li></ul></li></ul></li><li><code>Boolean()</code><ul><li>只有以下五个值的转换结果为false,其余全部为true<ul><li>undefined </li><li>null</li><li>0</li><li>NaN</li><li>‘’</li></ul></li></ul></li></ul></li></ul><h2 id="2-2-错误处理机制"><a href="#2-2-错误处理机制" class="headerlink" title="2.2 错误处理机制"></a>2.2 错误处理机制</h2><h3 id="2-2-1-Error实例对象"><a href="#2-2-1-Error实例对象" class="headerlink" title="2.2.1 Error实例对象"></a>2.2.1 Error实例对象</h3><p>JS解析或运行时发生错误，引擎就会抛出一个错误对象。JS原生提供Error构造函数，所有抛出的错误都是这个构造函数的实例。</p><pre><code>var error = new Error(&#39;Some error occur&#39;);error.message // &quot;Some error occur&quot;</code></pre><p>Error构造函数接受一个参数，表示错误提示，可以从实例的message属性读到这个参数。抛出Error实例对象以后，整个程序就中断在发生错误的地方，不再往下执行。</p><p>JS当中只有Error的message属性是必带的，但是一般来说，还会携带有<code>name</code>以及<code>stack</code>的信息，分别表示错误的名称和错误的堆栈</p><h3 id="2-2-2-原生错误类型"><a href="#2-2-2-原生错误类型" class="headerlink" title="2.2.2 原生错误类型"></a>2.2.2 原生错误类型</h3><p>下述错误类型都是构造函数，可以直接使用它来手动生成错误对象。这些构造函数都接收一个参数，代表错误提示信息</p><ul><li>SyntaxError <ul><li>解析代码时发生的语法错误</li></ul></li><li>ReferenceError<ul><li>引用一个不存在的变量</li><li>或者将一个值分配给无法分配的对象</li></ul></li><li>RangeError<ul><li>值超出有效范围时发生的错误<ul><li>数组长度为负</li><li>对象方法参数超出范围</li><li>函数堆栈超过最大值</li></ul></li></ul></li><li>TypeError <ul><li>变量或者参数不是预期类型时发生的错误 </li></ul></li><li>URIError<ul><li>是URI相关的函数的参数不正确时抛出的错误<ul><li>encodeURI()</li><li>decodeURI()</li><li>encodeURIComponent()</li><li>decodeURIComponent()</li><li>escape()</li><li>unescape() </li></ul></li></ul></li><li>EvalError<ul><li>eval函数没有被正确执行 </li></ul></li></ul><h3 id="2-2-3-自定义错误"><a href="#2-2-3-自定义错误" class="headerlink" title="2.2.3 自定义错误"></a>2.2.3 自定义错误</h3><pre><code>function UserError(msg) {    this.message = msg;    this.name = &quot;UserError&quot;;}// 继承了Error对象，声明其构造器UserError.prototype = new Error();UserError.prototype.constructor = UserError;</code></pre><p>而后我们也可以使用<code>throw</code> 抛出任何我们想抛出的值或者对象，程序运行到throw这里会终止。</p><h3 id="2-2-4-try-catch-finally"><a href="#2-2-4-try-catch-finally" class="headerlink" title="2.2.4 try - catch - finally"></a>2.2.4 try - catch - finally</h3><p>这里注意三者之间的执行顺序 </p><p>先try，捕获异常，而后finally代码块是不管是否出现错误，都必须最后运行的语句</p><pre><code>function cleansUp() {  try {    throw new Error(&#39;出错了……&#39;);    console.log(&#39;此行不会执行&#39;);  } finally {    console.log(&#39;完成清理工作&#39;);  }}cleansUp()// 完成清理工作// Uncaught Error: 出错了……//    at cleansUp (&lt;anonymous&gt;:3:11)//    at &lt;anonymous&gt;:10:1</code></pre><p>上述例子当中，中断执行了，会先执行finally代码块，再向用户提示报错信息。但是实际上try是已经执行完了的，finally代码块的运行不能改变try里面的输出或者function </p><pre><code>var count = 0;function countUp() {  try {    return count;  } finally {    count++;  }}countUp()// 0count// 1</code></pre><p>上述例子证明了try先执行完，才轮到finally，但是是finally先进行输出的。</p><p>finally的经典应用场景一般设计文件描述符的关闭：</p><pre><code>openFile();try {  writeFile(Data);} catch(e) {  handleError(e);} finally {  closeFile();}// try catch finally 执行顺序的反应function f() {  try {    console.log(0);    throw &#39;bug&#39;;  } catch(e) {    console.log(1);    return true; // 这句原本会延迟到 finally 代码块结束再执行    console.log(2); // 不会运行  } finally {    console.log(3);    return false; // 这句会覆盖掉前面那句 return    console.log(4); // 不会运行  }  console.log(5); // 不会运行}var result = f();// 0// 1// 3result// false</code></pre><h2 id="2-3-编程风格"><a href="#2-3-编程风格" class="headerlink" title="2.3 编程风格"></a>2.3 编程风格</h2><p>对于区块，大括号应该跟在这一行里面，不要另外起一行，因为JavaScript会自动添加句末的分号，导致一些难以察觉的错误。</p><ul><li>分号的使用<ul><li>不使用分号的情况<ul><li>for/ while</li><li>if/ switch/ try</li><li>函数的声明语句</li></ul></li><li>分号的自动添加<ul><li>js会自动添加，但是还会看下一行能否连接起来成一条语句，或者表达式，如果可以的话，会直接来做连接的 </li><li>一行的起首为自增或者自减运算符，那么其前面会自动添加分号</li><li>continue, break, return, throw这几个语句后面如果直接跟了换行符，都是会直接添加分号的</li></ul></li></ul></li><li>switch - case <ul><li>可以将其重写成对象的格式，<a href="https://medium.com/chrisburgin/rewriting-javascript-replacing-the-switch-statement-cfff707cf045" target="_blank" rel="noopener">medium上的例子</a></li><li>switch case 不利于格式统一，有点太冗长，而且很容易忘记break，用对象是个很好地选择实际上</li></ul></li></ul><pre><code>function doAction(action) {  switch (action) {    case &#39;hack&#39;:      return &#39;hack&#39;;    case &#39;slash&#39;:      return &#39;slash&#39;;    case &#39;run&#39;:      return &#39;run&#39;;    default:      throw new Error(&#39;Invalid action.&#39;);  }}function doAction(action) {  var actions = {    &#39;hack&#39;: function () {      return &#39;hack&#39;;    },    &#39;slash&#39;: function () {      return &#39;slash&#39;;    },    &#39;run&#39;: function () {      return &#39;run&#39;;    }  };  if (typeof actions[action] !== &#39;function&#39;) {    throw new Error(&#39;Invalid action.&#39;);  }  return actions[action]();}</code></pre><h2 id="2-4-console对象与控制台"><a href="#2-4-console对象与控制台" class="headerlink" title="2.4 console对象与控制台"></a>2.4 console对象与控制台</h2><ul><li>console<ul><li>JS的原生对象，可以输出各种信息到控制台，并提供了很多有用的辅助方法</li><li>用于调试程序，提供网页代码运行时的错误信息</li><li>提供一个命令行接口，用来和网页代码互动</li><li>console.log()<ul><li>占位符<ul><li>%s</li><li>%d</li><li>%i 整数</li><li>%f</li><li>%o 对象的链接</li><li>%c css格式的字符串<ul><li>对应的参数必须是CSS代码，用来对输出内容进行CSS的渲染</li></ul></li></ul></li></ul></li><li>console.table()<ul><li>输出复合类型的数据，以表格形式进行显示</li></ul></li><li>console.count()<ul><li>记录被调用了多少次</li></ul></li><li>console.dir()<ul><li>对一个对象进行检查，以便于阅读和打印的格式显示出来</li></ul></li><li>console.dirxml()<ul><li>用于以目录树的形式，显示一个DOM节点</li></ul></li><li>console.time()  console.timeEnd()<ul><li>用来看一个操作所花费的准确时间、</li></ul></li><li>console.trace()<ul><li>显示当前执行的代码在堆栈中的调用路径 <h1 id="3-标准库"><a href="#3-标准库" class="headerlink" title="3. 标准库"></a>3. 标准库</h1></li></ul></li></ul></li></ul><h2 id="3-1-Object对象"><a href="#3-1-Object对象" class="headerlink" title="3.1 Object对象"></a>3.1 Object对象</h2><pre><code>Object.prototype.print = function () {  console.log(this);};var obj = new Object();obj.print() // Object</code></pre><p>凡是定义在Object.prototype对象上面的属性和方法，将被所有实例对象共享。<code>Object.prototype</code>叫做原型对象</p><h3 id="3-1-1-Object静态方法"><a href="#3-1-1-Object静态方法" class="headerlink" title="3.1.1 Object静态方法"></a>3.1.1 Object静态方法</h3><p>Object静态方法指的是部署在Object对象自身的方法。</p><ul><li>Object.keys<ul><li>方法参数为一个对象</li><li>返回一个数组，该数组的成员都是该对象自身的(非继承的)所有属性名</li></ul></li><li>Object.getOwnPropertyNames<ul><li>与Object.keys一样的用法</li><li>不同之处在于这个也会返回不可枚举的属性名</li></ul></li><li>如何计算对象的属性个数？<ul><li>Object.keys(obj).length </li></ul></li><li>对象属性模型的相关方法<ul><li>Object.getOwnPropertyDescriptor() <ul><li>获取某个属性的描述对象</li></ul></li><li>Object.defineProperty()<ul><li>通过描述对象，定义某个属性 </li></ul></li><li>Object.defineProperties()</li></ul></li><li>控制对象状态的方法<ul><li>Object.preventExtensions()<ul><li>防止对象扩展</li><li>使得一个对象无法再添加新的属性</li></ul></li><li>Object.isExtensible()<ul><li>判断对象是否扩展</li></ul></li><li>Object.seal()<ul><li>禁止对象的配置</li><li>无法添加也无法删除属性</li></ul></li><li>Object.isSealed()</li><li>Object.freeze()<ul><li>冻结一个对象</li><li>无法添加</li><li>无法删除</li><li>无法修改</li></ul></li><li>Object.isFrozen()<ul><li>判断一个对象是否冻结</li></ul></li></ul></li><li>原型链相关方法<ul><li>Object.create()<ul><li>指定原型对象和属性，返回一个新的对象</li></ul></li><li>Object.getPrototypeOf()<ul><li>获取对象的prototype对象 </li></ul></li></ul></li></ul><pre><code>var obj = {  p1: 123,  p2: 456};Object.keys(obj) // [&quot;p1&quot;, &quot;p2&quot;]var a = [&#39;Hello&#39;, &#39;World&#39;];Object.keys(a) // [&quot;0&quot;, &quot;1&quot;]Object.getOwnPropertyNames(a) // [&quot;0&quot;, &quot;1&quot;, &quot;length&quot;]</code></pre><h3 id="3-1-2-Object的实例方法"><a href="#3-1-2-Object的实例方法" class="headerlink" title="3.1.2 Object的实例方法"></a>3.1.2 Object的实例方法</h3><p>指的是定义在Object.prototype对象的方法，称为实例方法。所有的Object对象都继承了这几个方法。</p><ul><li><code>Object.prototype.valueOf()</code>：返回当前对象对应的值。</li></ul><pre><code>// Object.prototype.valueOf()  返回对象本身var obj = new Object();obj.valueOf() === obj; // true</code></pre><ul><li><code>Object.prototype.toString()</code>：返回当前对象对应的字符串形式。<ul><li>toString本身是返回一个对象的字符串形式，默认情况下返回类型字符串</li><li>当对一个对象调用这个方法的时候，会返回字符串<code>[object Object]</code></li><li>可以自定义方法来返回更多的有用信息</li><li>数组，字符串，函数，Date对象都有自己的自定义的tostring方法的</li><li>我们可以用过<code>Object.prototype.toString.call(value)</code>来判断出一个值到底是什么类型的</li></ul></li></ul><pre><code>var o1 = new Object();o1.toString() // &quot;[object Object]&quot;var o2 = {a:1};o2.toString() // &quot;[object Object]&quot;var obj = new Object();obj.toString = function () {    return &quot;hello, I rewrite the toString() function&quot;;}Object.prototype.toString.call(2) // &quot;[object Number]&quot;Object.prototype.toString.call(&#39;&#39;) // &quot;[object String]&quot;Object.prototype.toString.call(true) // &quot;[object Boolean]&quot;Object.prototype.toString.call(undefined) // &quot;[object Undefined]&quot;Object.prototype.toString.call(null) // &quot;[object Null]&quot;Object.prototype.toString.call(Math) // &quot;[object Math]&quot;Object.prototype.toString.call({}) // &quot;[object Object]&quot;Object.prototype.toString.call([]) // &quot;[object Array]&quot;</code></pre><ul><li><code>Object.prototype.toLocaleString()</code>：返回当前对象对应的本地字符串形式。<ul><li>为的就是留出一个接口，让各种不同的对象实现自己的版本的toLocaleString,用来返回针对某些特定地域的特定的值 </li></ul></li><li><code>Object.prototype.hasOwnProperty()</code>：判断某个属性是否为当前对象自身的属性，还是继承自原型对象的属性。<ul><li>接受一个字符串作为参数，返回一个布尔值，表示该实例对象自身是否有该属性 </li></ul></li><li><code>Object.prototype.isPrototypeOf()</code>：判断当前对象是否为另一个对象的原型。</li><li><code>Object.prototype.propertyIsEnumerable()</code>：判断某个属性是否可枚举。 </li></ul><h3 id="3-1-3-Attributes-Object"><a href="#3-1-3-Attributes-Object" class="headerlink" title="3.1.3 Attributes Object"></a>3.1.3 Attributes Object</h3><p>属性描述对象，控制其行为，比如该属性是否可写。可遍历等等。</p><p>属性描述对象提供了6个元属性</p><ul><li>value </li><li>writable </li><li>enumerable 布尔值，表示该属性是否可遍历</li><li>configurable 可配置性 <ul><li>如果设置为false, 将组织某些操作改写该属性，比如无法删除，也不得改变该属性的属性描述对象</li></ul></li><li>get<ul><li>取值函数</li></ul></li><li>set<ul><li>存值函数</li></ul></li></ul><p>属性可以通过存取器来进行定义  </p><p>存值函数称为setter，取值函数称为getter </p><pre><code>var obj = Object.defineProperty({}, &#39;p&#39;, {  get: function () {    return &#39;getter&#39;;  },  set: function (value) {    console.log(&#39;setter: &#39; + value);  }});obj.p // &quot;getter&quot;obj.p = 123 // &quot;setter: 123&quot;</code></pre><h1 id="3-2-Array对象"><a href="#3-2-Array对象" class="headerlink" title="3.2 Array对象"></a>3.2 Array对象</h1><h3 id="3-2-1-构造函数与静态方法"><a href="#3-2-1-构造函数与静态方法" class="headerlink" title="3.2.1 构造函数与静态方法"></a>3.2.1 构造函数与静态方法</h3><p>Array是JS的原生对象，也是一个构造函数，可以用其直接生成新的数组</p><pre><code>var arr = new Array(2);arr.length // 2</code></pre><ul><li>Array.isArray()<ul><li>判断一个obj是否为数组</li><li>这样做的原因是为了弥补<code>typeof</code>的缺陷，typeof只能返回是否一个object的这种信息</li></ul></li></ul><h3 id="3-2-2-实例方法"><a href="#3-2-2-实例方法" class="headerlink" title="3.2.2  实例方法"></a>3.2.2  实例方法</h3><ul><li>valueOf()<ul><li>返回数组本身 </li></ul></li><li>toString() <ul><li>返回数组的字符串形式</li></ul></li><li>push()<ul><li>在数组的末端加一个或者多个元素，并返回添加新元素以后的数组长度 </li></ul></li><li>pop()<ul><li>pop方法用于删除数组的最后一个元素，并返回该元素。注意，该方法会改变原数组。</li></ul></li><li>shift()<ul><li>用于删除数组的第一个元素，并且返回该元素</li><li>可以用来遍历并且清空一个数组</li></ul></li></ul><pre><code>var list = [1,2,3,4];var item;while (item = list.shift()) {    console.log(item);}</code></pre><ul><li>unshift()<ul><li>用于在数组的第一个位置添加元素，并且返回新元素添加以后的数组长度</li></ul></li><li>join()<ul><li>以指定参数作为分隔符，将所有数组成员连接为一个字符串并返回</li><li>如果数组成员是undefined/ null/ blank, 会被转成空字符串</li><li>join默认是用逗号来连接的</li></ul></li></ul><pre><code>var a = [1, 2, 3, 4];a.join(&#39; &#39;) // &#39;1 2 3 4&#39;a.join(&#39; | &#39;) // &quot;1 | 2 | 3 | 4&quot;a.join() // &quot;1,2,3,4&quot;</code></pre><ul><li>concat()<ul><li>用于多个数组的合并</li><li>将新数组的成员，添加到原数组成员的后面，然后返回一个新数组，原数组不变</li></ul></li><li>reverse()</li><li>slice()<ul><li>用于提取目标数组的一部分，返回一个新数组，原数组并不发生改变</li><li>第一个参数为起始位置，第二个参数为终止位置，但是这个位置并不包含在内</li><li>如果第二个参数省略，那就一直返回到原数组的最后一个成员</li><li>slice的一个重要应用时将类似数组的对象转为真正的数组</li></ul></li></ul><pre><code>Array.prototype.slice.call({ 0: &#39;a&#39;, 1: &#39;b&#39;, length: 2 })// [&#39;a&#39;, &#39;b&#39;]Array.prototype.slice.call(document.querySelectorAll(&quot;div&quot;));Array.prototype.slice.call(arguments);</code></pre><ul><li>splice()<ul><li>删除原数组的一部分成员，并可以在删除的位置添加新的数组成员，返回值是被删除的元素</li><li><code>arr.splice(start, count, addElement1, addElement2, ...);</code></li></ul></li><li>sort()</li><li>map()<ul><li>将数组的所有成员依次传入参数函数，然后将每一次的执行结果组成一个新数组返回</li></ul></li></ul><pre><code>var numbers = [1, 2, 3];numbers.map(function (n) {  return n + 1;});// [2, 3, 4]numbers// [1, 2, 3]</code></pre><ul><li>forEach()<ul><li>与map方法类似，对数组的所有成员依次执行参数函数。但是forEach不返回值，只用来操作数据 </li><li>forEach接收第二个参数，绑定参数函数的this变量</li><li>forEacg方法无法中断执行，总是会把所有成员遍历完，如果希望符合某种条件就中断遍历，那需要使用for循环</li></ul></li></ul><pre><code>var out = [];[1, 2, 3].forEach(function(elem) {  this.push(elem * elem);}, out);out // [1, 4, 9]</code></pre><ul><li>filter()<ul><li>用于过滤数组成员，满足条件的成员组成一个新数组返回 </li><li>参数是一个函数，返回结果为true的成员组成一个新数组返回</li></ul></li></ul><pre><code>// 当前成员，当前位置，整个数组[1, 2, 3, 4, 5].filter(function (elem, index, arr) {  return index % 2 === 0;});// [1, 3, 5]var obj = { MAX: 3 };var myFilter = function (item) {  if (item &gt; this.MAX) return true;};var arr = [2, 8, 3, 4, 1, 3, 2, 9];arr.filter(myFilter, obj) // [8, 4, 9]</code></pre><ul><li>some()<ul><li>有满足条件的就返回true </li></ul></li><li>every()<ul><li>全都满足条件才返回true</li></ul></li><li>reduce(), reduceRight()<ul><li>依次处理数组的每一个成员，最终累计为一个值</li><li>reduce从左到右进行处理</li><li>reduceRight从右向左进行处理</li><li>四个参数<ul><li>累积变量</li><li>当前变量</li><li>当前位置</li><li>原数组</li></ul></li></ul></li></ul><pre><code>function findLongest(entries) {  return entries.reduce(function (longest, entry) {    return entry.length &gt; longest.length ? entry : longest;  }, &#39;&#39;);}findLongest([&#39;aaa&#39;, &#39;bb&#39;, &#39;c&#39;]) // &quot;aaa&quot;</code></pre><ul><li>indexOf()<ul><li>返回给定元素在数组中第一次出现的位置，如果没有出现就返回-1 </li></ul></li><li>lastIndexOf()<ul><li>返回给定元素在数组中最后一次出现的位置，如果没有出现就返回-1 </li></ul></li></ul><h2 id="3-3-包装对象"><a href="#3-3-包装对象" class="headerlink" title="3.3 包装对象"></a>3.3 包装对象</h2><p>三种原始类型的值 - 数值，字符串，布尔值在一定条件下也会自动转为对象，称为原始类型的包装对象 - wrapper</p><pre><code>var v1 = new Number(123);var v2 = new String(&#39;abc&#39;);var v3 = new Boolean(true);typeof v1 // &quot;object&quot;typeof v2 // &quot;object&quot;typeof v3 // &quot;object&quot;v1 === 123 // falsev2 === &#39;abc&#39; // falsev3 === true // false</code></pre><ul><li>valueOf()<ul><li>返回包装对象实例对应的原始类型的值</li></ul></li><li>toString()<ul><li>返回对应的字符串形式</li></ul></li><li>原始类型与实例对象的自动转换<ul><li>一些时候我们将原始类型的值自动当做包装对象来调用了，这时JS引擎会自动将原始类型的值转为包装对象实例，并在使用后立刻销毁实例。</li><li><code>&#39;abc&#39;.length // 3</code></li><li>abc是字符串，但是js直接将其转化为了其包装对象，并在调用结束后，直接销毁这个临时对象，以此完成整个自动转换的过程</li></ul></li></ul><h3 id="3-3-1-Boolean对象"><a href="#3-3-1-Boolean对象" class="headerlink" title="3.3.1 Boolean对象"></a>3.3.1 Boolean对象</h3><pre><code>Boolean(undefined) // falseBoolean(null) // falseBoolean(0) // falseBoolean(&#39;&#39;) // falseBoolean(NaN) // falseBoolean(1) // trueBoolean(&#39;false&#39;) // trueBoolean([]) // trueBoolean({}) // trueBoolean(function () {}) // trueBoolean(/foo/) // true</code></pre><h3 id="3-3-2-Number对象"><a href="#3-3-2-Number对象" class="headerlink" title="3.3.2 Number对象"></a>3.3.2 Number对象</h3><ul><li>静态属性<ul><li>Number.POSITIVE_INFINITY</li><li>Number.NEGATIVE_INFINITY</li><li>Number.NaN</li><li>Number.MIN_VALUE</li><li>Number.MAX_SAFE_INTEGER</li><li>Number.MIN_SAFE_INTEGER</li></ul></li><li>实例方法<ul><li>Number.prototype.toString()</li><li>Number.prototype.toFixed()<ul><li>将一个数转为指定位数的小数，然后返回这个小数对应的字符串</li><li><code>(10).toFixed(2) // &quot;10.00&quot;</code></li></ul></li><li>Number.prototype.toExponential()<ul><li><code>(10).toExponential()  // &quot;1e+1&quot;</code></li><li>参数是小数点后有效数字的位数</li></ul></li><li>Number.prototype.toPrecision()<ul><li><code>(12.34).toPrecision(2) // &quot;12&quot;</code></li><li>将数字转为指定位数的有效数字</li></ul></li></ul></li></ul><h3 id="3-3-3-String对象"><a href="#3-3-3-String对象" class="headerlink" title="3.3.3 String对象"></a>3.3.3 String对象</h3><p>用来生成字符串对象，会生成一个非常类似数组的对象</p><pre><code>new String(&#39;abc&#39;)// String {0: &quot;a&quot;, 1: &quot;b&quot;, 2: &quot;c&quot;, length: 3}</code></pre><ul><li>静态方法<ul><li>String.fromCharCode()<ul><li>数值代表Unicode码点，返回值是这些码点组成的字符串</li></ul></li></ul></li><li>实例方法<ul><li>String.prototype.charAt()</li><li>String.prototype.charCodeAt()<ul><li>返回的是字符串指定位置的Unicode码点</li></ul></li><li>String.prototype.concat()<ul><li>用来连接两个字符串，返回一个新的字符串，并不改变原来的字符串</li><li><code>&#39;a&#39;.concat(&#39;b&#39;, &#39;c&#39;) // &quot;abc&quot;</code></li></ul></li><li>String.prototype.slice()<ul><li>用于从原字符串去除子字符串并返回，不改变原字符串。它的第一个参数是子字符串的开始位置，第二个参数是子字符串的结束位置（不含该位置）。 </li></ul></li><li>String.prototype.substr()<ul><li>从原字符串取出子字符串并返回，不改变原字符串</li><li>第一个参数为子字符串的开始位置，第二个参数为子字符串的长度</li></ul></li><li>String.prototype.indexOf()，String.prototype.lastIndexOf()</li><li>String.prototype.trim()<ul><li>去除字符串两端的空格，返回一个新的字符串，不改变原字符串</li><li>还包括 \t \v \n \r</li></ul></li><li>String.prototype.toLowerCase()，String.prototype.toUpperCase()</li><li>String.prototype.match()</li><li>String.prototype.search()<ul><li>返回值为匹配的第一个位置，如果没有找到匹配则返回 -1</li></ul></li><li>String.prototype.replace()</li><li>String.prototype.split()<ul><li>按照给定规则分割字符串，返回一个由分割出来的子字符串组成的数组</li></ul></li></ul></li></ul><pre><code>&#39;a|b|c&#39;.split(&#39;|&#39;) // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]&#39;a||c&#39;.split(&#39;|&#39;) // [&#39;a&#39;, &#39;&#39;, &#39;c&#39;]&#39;a|b|c&#39;.split(&#39;|&#39;, 0) // []&#39;a|b|c&#39;.split(&#39;|&#39;, 1) // [&quot;a&quot;]&#39;a|b|c&#39;.split(&#39;|&#39;, 2) // [&quot;a&quot;, &quot;b&quot;]&#39;a|b|c&#39;.split(&#39;|&#39;, 3) // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]&#39;a|b|c&#39;.split(&#39;|&#39;, 4) // [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]</code></pre><h2 id="3-4-Math对象"><a href="#3-4-Math对象" class="headerlink" title="3.4 Math对象"></a>3.4 Math对象</h2><p>JS的原生对象，不是构造函数，无法生成对象，所有的属性和方法都需要在Math对象上进行调用</p><ul><li>静态属性<ul><li>Math.E</li><li>Math.LN2</li><li>Math.LN10</li><li>Math.LOG2E</li><li>Math.PI</li></ul></li><li>静态方法<ul><li>Math.abs()</li><li>Math.ceil()<ul><li>向上取整 </li></ul></li><li>Math.floor()<ul><li>向下取整</li></ul></li><li>Math.max()</li><li>Math.min()</li><li>Math.pow() 指数运算</li><li>Math.sqrt()</li><li>Math.log()</li><li>Math.exp() e的指数</li><li>Math.round() 四舍五入</li><li>Math.random() 随机数</li></ul></li></ul><h2 id="3-5-Date对象"><a href="#3-5-Date对象" class="headerlink" title="3.5 Date对象"></a>3.5 Date对象</h2><p>以UTC时间1970年1月1日00:00:00作为时间元点。</p><ul><li>直接调用Date() 返回当前时间</li><li>构造函数<ul><li>如果带参数，就转化那个时间</li><li>不带，就是当前时间</li></ul></li><li>静态方法<ul><li>Date.now() <ul><li>返回当前时间距离时间零点的毫秒数</li></ul></li><li>Date.parse()<ul><li>解析日期字符串，返回该时间距离时间零点的毫秒数</li><li>日期字符串需要符合RFC 2822和 ISO8061 两个标准</li></ul></li><li>Date.UTC()<ul><li>接收年月日等变量作为参数，返回该时间距离时间零点的毫秒数 </li></ul></li></ul></li><li>to see doc <a href="https://wangdoc.com/javascript/stdlib/date.html" target="_blank" rel="noopener">https://wangdoc.com/javascript/stdlib/date.html</a></li><li>get see doc <a href="https://wangdoc.com/javascript/stdlib/date.html" target="_blank" rel="noopener">https://wangdoc.com/javascript/stdlib/date.html</a></li><li>set see doc <a href="https://wangdoc.com/javascript/stdlib/date.html" target="_blank" rel="noopener">https://wangdoc.com/javascript/stdlib/date.html</a> </li></ul><h2 id="3-6-RegExp对象"><a href="#3-6-RegExp对象" class="headerlink" title="3.6 RegExp对象"></a>3.6 RegExp对象</h2><p>提供正则表达式的功能。表达文本模式的方法，可以使用字面量，以斜杠表示开始和结束，也可以使用RegExp构造函数</p><pre><code>// 引擎编译代码的时候，就新建正则表达式了var regex = /xyz/;// 运行的时候建立var regex = new RegExp(&#39;xyz&#39;);</code></pre><h3 id="3-6-1-实例属性"><a href="#3-6-1-实例属性" class="headerlink" title="3.6.1 实例属性"></a>3.6.1 实例属性</h3><ul><li>RegExp.prototype.ignoreCase：返回一个布尔值，表示是否设置了i修饰符。</li><li>RegExp.prototype.global：返回一个布尔值，表示是否设置了g修饰符。</li><li>RegExp.prototype.multiline：返回一个布尔值，表示是否设置了m修饰符。</li><li>RegExp.prototype.flags：返回一个字符串，包含了已经设置的所有修饰符，按字母排序。</li></ul><h3 id="3-6-2-实例方法"><a href="#3-6-2-实例方法" class="headerlink" title="3.6.2 实例方法"></a>3.6.2 实例方法</h3><ul><li>RegExp.prototype.test()<ul><li>返回一个布尔值，表示当前模式是否能匹配参数字符串</li><li><code>/cat/.test(&#39;cats and dogs&#39;)  // true</code></li></ul></li><li>RegExp.prototype.exec()<ul><li>返回匹配结果，如果匹配，就返回一个数组，成员是匹配成功的子字符串，否则返回null </li></ul></li><li>String.prototype.match()<ul><li>所有匹配的子字符串</li></ul></li><li>String.prototype.search()<ul><li>按照给定的正则表达式进行搜索，返回一个整数，表示匹配开始的位置</li></ul></li><li>String.prototype.replace()<ul><li>按照给定的正则表达式进行替换，返回替换后的字符串</li></ul></li><li>String.prototype.split()<ul><li>按照给定规则进行字符串分割，返回一个数组，包含分割后的各个成员。</li></ul></li></ul><h3 id="3-6-3-各种符号表示"><a href="#3-6-3-各种符号表示" class="headerlink" title="3.6.3 各种符号表示"></a>3.6.3 各种符号表示</h3><ul><li>/g<ul><li>匹配所有符合正则表达式的值，如果没有，成功一次以后就停止了</li></ul></li><li>小括号 </li></ul><pre><code>// 如果带括号，括号本身的也会返回的&#39;aaa*a*&#39;.split(/(a*)/)// [ &#39;&#39;, &#39;aaa&#39;, &#39;*&#39;, &#39;a&#39;, &#39;*&#39; ]</code></pre><ul><li>字面量字符<ul><li>就是一对一的匹配</li><li>比如 /dog/ 只匹配包含dog的</li></ul></li><li>元字符<ul><li>点字符  匹配一个<ul><li>匹配出了回车\r, 换行\n, 行分隔符 \u2028, 段分隔符\u2029之外的所有字符</li></ul></li><li>位置字符<ul><li>^<ul><li>表示字符串开始的位置 </li></ul></li><li>$<ul><li>表示字符串结束的位置</li></ul></li></ul></li><li>选择符 | <ul><li>表示or的关系 </li><li>e.g <code>cat|dog</code>表示cat or dog都匹配</li></ul></li></ul></li><li>转义符<ul><li>对于正则表达式当中本身就具有特殊含义的元字符的处理，当需要匹配自身的时候，在它们的前面加上反斜杠 </li></ul></li><li>字符类 <ul><li>表示有一系列字符可供选择，只要匹配其中一个就可以了 都放到方括号当中 <code>[]</code></li><li>脱字符 <code>^</code><ul><li>若方括号内第一个字符是[^]，则是求反，即除了中括号之内的字符以外都可以进行匹配</li><li>如果方括号内没有其他字符，就表示匹配一切字符了，包括换行符</li><li>注意脱字符只有在字符类的第一个位置才有特殊含义，否则就是字面含义</li></ul></li><li>连字符 <code>-</code><ul><li>对于连续序列的字符，用连字符来进行简写 </li></ul></li></ul></li><li>预定义模式 - 常见模式的简写方式<ul><li><code>\d</code><ul><li>匹配 0-9之间的任意数字，相当于<code>[0-9]</code> </li></ul></li><li><code>\D</code><ul><li>匹配所有 0-9之外的字符 相当于 <code>[^0-9]</code> </li></ul></li><li><code>\w</code><ul><li>匹配任意的字母、数字和下划线， 相当于<code>[A-Za-z0-9]</code> </li></ul></li><li><code>\W</code><ul><li>匹配除了字母数字和下划线以外的内容,  相当于<code>[^A-Za-z0-9]</code> </li></ul></li><li><code>\s</code><ul><li>匹配空格，包括换行符，制表符以及空格符，相当于<code>[\t\r\n\v\f]</code> </li></ul></li><li><code>\S</code><ul><li>匹配非空格的字符，相当于 <code>[^\t\r\n\v\f]</code> </li></ul></li><li><code>\b</code><ul><li>匹配词的边界 </li></ul></li><li><code>\B</code><ul><li>匹配词的内部 </li></ul></li></ul></li></ul><pre><code>// test必须出现在开始位置/^test/.test(&#39;test123&#39;) // true// test必须出现在结束位置/test$/.test(&#39;new test&#39;) // true// 从开始位置到结束位置只有test/^test$/.test(&#39;test&#39;) // true/^test$/.test(&#39;test test&#39;) // false/[abc]/.test(&#39;hello world&#39;) // false/[abc]/.test(&#39;apple&#39;) // truevar s = &#39;Please yes\nmake my day!&#39;;s.match(/yes.*day/) // nulls.match(/yes[^]*day/) // [ &#39;yes\nmake my day&#39;]// \s 的例子/\s\w*/.exec(&#39;hello world&#39;) // [&quot; world&quot;]// \b 的例子/\bworld/.test(&#39;hello world&#39;) // true/\bworld/.test(&#39;hello-world&#39;) // true/\bworld/.test(&#39;helloworld&#39;) // false// \B 的例子/\Bworld/.test(&#39;hello-world&#39;) // false/\Bworld/.test(&#39;helloworld&#39;) // true</code></pre><ul><li>重复类 - <code>{}</code><ul><li>模式的精准次数匹配，使用大括号表示</li><li><code>{n}</code> <ul><li>恰好重复n次 </li></ul></li><li><code>{n,}</code><ul><li>至少重复n次 </li></ul></li><li><code>{n,m}</code><ul><li>重复不少于n次不多于m次</li></ul></li></ul></li><li>量词符 - 用来设定某个模式出现的次数<ul><li><code>?</code><ul><li>出现0次或者1次</li><li>{0,1}</li></ul></li><li><code>*</code><ul><li>出现0次或多次</li><li>{0,}</li></ul></li><li><code>+</code><ul><li>出现1次或多次</li><li>{1,}</li></ul></li></ul></li><li>贪婪模式<ul><li>通过在量词符后面加问号，从贪婪模式转化为非贪婪模式</li></ul></li></ul><pre><code>&#39;abb&#39;.match(/ab*b/) // [&quot;abb&quot;]&#39;abb&#39;.match(/ab*?b/) // [&quot;ab&quot;]&#39;abb&#39;.match(/ab?b/) // [&quot;abb&quot;]&#39;abb&#39;.match(/ab??b/) // [&quot;ab&quot;]</code></pre><ul><li>修饰符<ul><li>表示模式的附加规则，放在正则模式的最尾部</li><li>修饰符可以单个使用，也可以多个使用</li><li>g修饰符<ul><li>默认情况下，如果第一次匹配成功了，那么正则对象就会停止向下匹配了</li><li>g修饰符代表全局匹配，加上他之后，正则对象将匹配全部符合条件的结果，主要用于搜索替换</li></ul></li><li>i修饰符<ul><li>表示忽略大小写 </li></ul></li><li>m修饰符<ul><li>m修饰符表示多行模式（multiline），会修改^和$的行为。默认情况下（即不加m修饰符时），^和$匹配字符串的开始处和结尾处，加上m修饰符以后，^和$还会匹配行首和行尾，即^和$会识别换行符（\n）。 </li></ul></li></ul></li></ul><pre><code>var regex = /b/g;var str = &#39;abba&#39;;regex.test(str); // trueregex.test(str); // trueregex.test(str); // false/abc/.test(&#39;ABC&#39;) // false/abc/i.test(&#39;ABC&#39;) // true/world$/.test(&#39;hello world\n&#39;) // false/world$/m.test(&#39;hello world\n&#39;) // true</code></pre><ul><li>组匹配<ul><li>括号表示分组匹配，括号中的模式用来匹配分组的内容 + 可以用\n表示第n个括号里面的内容</li><li>非捕获组 <code>(?:x)</code><ul><li>表示不返回该组匹配的内容 </li></ul></li><li>先行断言 <code>x(?=y)</code><ul><li>表示只有x在y前面才匹配，y不会被计入返回结果</li></ul></li><li>先行否定断言 <code>x(?!y)</code><ul><li>x只有不在y前面才匹配，y不会被计入返回结果 </li></ul></li></ul></li></ul><pre><code>var m = &#39;abcabc&#39;.match(/(.)b(.)/);m // [&#39;abc&#39;, &#39;a&#39;, &#39;c&#39;]/y(..)(.)\2\1/.test(&#39;yabccab&#39;) // truevar m = &#39;abc&#39;.match(/(?:.)b(.)/);m // [&quot;abc&quot;, &quot;c&quot;]</code></pre><h2 id="3-7-JSON对象"><a href="#3-7-JSON对象" class="headerlink" title="3.7 JSON对象"></a>3.7 JSON对象</h2><h3 id="3-7-1-JSON格式"><a href="#3-7-1-JSON格式" class="headerlink" title="3.7.1 JSON格式"></a>3.7.1 JSON格式</h3><ol><li>复合类型的值只能是数组或对象</li><li>原始类型只有四种：字符串，数值，布尔值和null</li><li>字符串必须使用双引号表示，不能使用单引号</li><li>对象的键名必须放在双引号里面</li><li>数组或对象最后一个成员的后面，不可以加逗号</li></ol><h3 id="3-7-2-JSON对象"><a href="#3-7-2-JSON对象" class="headerlink" title="3.7.2 JSON对象"></a>3.7.2 JSON对象</h3><ul><li>JSON.stringify()<ul><li>将一个值转为JSON字符串</li><li>会忽略对象的不可遍历的属性</li></ul></li><li>JSON.parse()<ul><li>将JSON字符串转成对应的值 </li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul><li><a href="https://wangdoc.com/javascript/" target="_blank" rel="noopener">https://wangdoc.com/javascript/</a> </li><li>表达式和语句 <a href="https://www.cnblogs.com/ziyunfei/archive/2012/09/16/2687589.html" target="_blank" rel="noopener">https://www.cnblogs.com/ziyunfei/archive/2012/09/16/2687589.html</a> </li><li>statement and expressions <a href="https://2ality.com/2012/09/expressions-vs-statements.html" target="_blank" rel="noopener">https://2ality.com/2012/09/expressions-vs-statements.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JavaScript - callback function</title>
      <link href="/JavaScript-callback-function/"/>
      <url>/JavaScript-callback-function/</url>
      
        <content type="html"><![CDATA[<h1 id="1-What-is"><a href="#1-What-is" class="headerlink" title="1. What is"></a>1. What is</h1><ul><li>A function that is to be executed after another function has finished executing – hence the name call back </li><li>In JavaScript, functions are <strong>objects</strong>. Because of this, <strong>functions can take functions as arguments</strong>, and can be returned by other functions. Functions that do this are called <strong>higher-order functions</strong>. Any function that is passed as an argument is called a callback function.</li></ul><h1 id="2-Why-need"><a href="#2-Why-need" class="headerlink" title="2. Why need"></a>2. Why need</h1><p>JS is an event driven language, instead of waiting for a response before moving on, JS will keep executing while listening for other events. </p><pre><code>function first(){  // Simulate a code delay  setTimeout( function(){    console.log(1);  }, 500 );}function second(){  console.log(2);}first();second();// 2, 1</code></pre><p>The above example shows JS didn’t wait for a response from first() before moving on to execute second() </p><h1 id="3-How-to"><a href="#3-How-to" class="headerlink" title="3. How to"></a>3. How to</h1><pre><code>function doHomework(subject, callback) {  alert(`Starting my ${subject} homework.`);  callback();}doHomework(&#39;math&#39;, function() {  alert(&#39;Finished my homework&#39;);});</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://developer.mozilla.org/en-US/docs/Glossary/Callback_function" target="_blank" rel="noopener">https://developer.mozilla.org/en-US/docs/Glossary/Callback_function</a></p>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> JavaScript </tag>
            
            <tag> Callback </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>i18next tutorial</title>
      <link href="/i18next-tutorial/"/>
      <url>/i18next-tutorial/</url>
      
        <content type="html"><![CDATA[<h1 id="0-Lessons-SkipInterpolation-option-in-i18next-icu"><a href="#0-Lessons-SkipInterpolation-option-in-i18next-icu" class="headerlink" title="0. Lessons - SkipInterpolation option in i18next-icu"></a>0. Lessons - SkipInterpolation option in i18next-icu</h1><p>Overall it works fine for me, one issue I want to highlight is: currently the skipInterpolication option in i18next-icu is not working, insteand, you could leverage on getResource <a href="https://www.i18next.com/overview/api#getresource" target="_blank" rel="noopener">API</a> to get raw data, and define your own substitution logic with regex. <a href="https://github.com/i18next/i18next-icu/issues/11" target="_blank" rel="noopener">Related github issue</a></p><h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><ul><li>highlights<ul><li>both for front end and back end<ul><li>can be used in nodejs, PHP, IOS, Android, etc. </li></ul></li><li>thorough solution <ul><li>detect the user language </li><li>load the translation </li><li>optionally cache the translation </li><li>extension support <ul><li><a href="https://www.i18next.com/overview/configuration-options" target="_blank" rel="noopener">personalization</a></li></ul></li></ul></li><li>scalability <ul><li>we could separate translations into multiple files and load them on demand  </li></ul></li></ul></li></ul><h1 id="2-Starting-from-Scratch"><a href="#2-Starting-from-Scratch" class="headerlink" title="2. Starting from Scratch"></a>2. Starting from Scratch</h1><h2 id="2-1-Basic-Example"><a href="#2-1-Basic-Example" class="headerlink" title="2.1 Basic Example"></a>2.1 Basic Example</h2><pre><code>// with callback functionimport i18next from &#39;i18next&#39;;i18next.init({  lng: &#39;en&#39;,  debug: true,  resources: {    en: {      translation: {        &quot;key&quot;: &quot;hello world&quot;      }    }  }}, function(err, t) {  // initialized and ready to go!  document.getElementById(&#39;output&#39;).innerHTML = i18next.t(&#39;key&#39;);});// with promisei18next.init({  lng: &#39;en&#39;,  debug: true,  resources: {    en: {      translation: {        &quot;key&quot;: &quot;hello world&quot;      }    }  }}).then(function(t) {  // initialized and ready to go!  document.getElementById(&#39;output&#39;).innerHTML = i18next.t(&#39;key&#39;);});</code></pre><h2 id="2-2-Configuration"><a href="#2-2-Configuration" class="headerlink" title="2.2 Configuration"></a>2.2 Configuration</h2><p>Record options when calling <code>i18next.init(options, callback)</code></p><ul><li>resources </li><li>lng </li><li>fallbackLng<ul><li>language to use if translation in user language are not available </li></ul></li><li>whitelist<ul><li>array of allowed languages </li></ul></li><li>ns <ul><li>string or array of namespaces to load  </li></ul></li><li>detection <ul><li>options for language detection </li></ul></li><li>backend <ul><li>option for backend </li></ul></li><li>cache <ul><li>option for cache layer  </li></ul></li></ul><h1 id="3-API"><a href="#3-API" class="headerlink" title="3. API"></a>3. API</h1><h2 id="3-1-General"><a href="#3-1-General" class="headerlink" title="3.1 General"></a>3.1 General</h2><ul><li>init <ul><li><code>i18next.init(options, callback)</code></li><li>Initialize an i18next instance </li><li>callback will be called after all translations were loaded </li></ul></li><li>use <ul><li><code>i18next.use(module)</code></li><li>load additional plugins to i18next </li></ul></li><li>t <ul><li><code>i18next.t(keys, options)</code></li><li>do translation, we could either use one key as a string or multiple keys as an Array of String. </li></ul></li></ul><pre><code>i18next.t(&#39;my.key&#39;); // -&gt; will return value in set languagei18next.t([&#39;unknown.key&#39;, &#39;my.key&#39;]); // -&gt; will return value for &#39;my.key&#39; in set language</code></pre><ul><li>exists<ul><li><code>i18next.exists(key, options)</code></li><li>same resolve function as t function, return true if a key exists </li></ul></li><li>getFixedT <ul><li><code>i18next.getFixedT(lng, ns)</code></li><li>return a t function that defaults to given language or namespace </li></ul></li></ul><pre><code>// fix language to germanconst de = i18next.getFixedT(&#39;de&#39;);de(&#39;myKey&#39;);// or fix the namespace to anotherNamespaceconst anotherNamespace = i18next.getFixedT(null, &#39;anotherNamespace&#39;);anotherNamespace(&#39;anotherNamespaceKey&#39;); // no need to prefix ns i18n.t(&#39;anotherNamespace:anotherNamespaceKey&#39;);</code></pre><ul><li>changeLanguage <ul><li><code>i18next.changeLanguage(lng, callback)</code></li><li>change the language, the callback will be called as soon translation were loaded or an error occurs while loading </li></ul></li><li>languages <ul><li><code>i18next.languages</code></li><li>a set, that will be used to look up the translation value </li></ul></li><li>loadNamespaces<ul><li><code>i18next.loadNamespaces(ns, callback)</code></li><li>load additional namespaces not defined in init options </li></ul></li></ul><pre><code>i18next.loadNamespaces(&#39;myNamespace&#39;, (err) =&gt; { /* resources have been loaded */ });i18next.loadNamespaces([&#39;myNamespace1&#39;, &#39;myNamespace2&#39;], (err) =&gt; { /* resources have been loaded */ });// using Promisesi18next  .loadNamespaces([&#39;myNamespace1&#39;, &#39;myNamespace2&#39;])  .then(() =&gt; {});</code></pre><ul><li><p>loadLanguages</p><ul><li><code>i18next.loadLanguages(lngs, callbak)</code></li><li>load additional languages not defined in init options </li></ul></li><li><p>reloadResources </p></li><li><p>setDefaultNamespace </p><ul><li>change the default namespace </li></ul></li><li><p>dir </p><ul><li><code>i18next.dir(lng)</code></li><li>return rtl or ltr depending on languages read direction </li></ul></li><li><p>format </p><ul><li><code>i18next.format(data, format, lng)</code></li><li>interpolation.format function exposure on init </li></ul></li></ul><h2 id="3-2-Instance-Creation"><a href="#3-2-Instance-Creation" class="headerlink" title="3.2 Instance Creation"></a>3.2 Instance Creation</h2><ul><li>createInstance <ul><li><code>i18next.createInstance(options, callback)</code></li><li>return a new i18next instance </li></ul></li></ul><pre><code>const newInstance = i18next.createInstance({  fallbackLng: &#39;en&#39;,  ns: [&#39;file1&#39;, &#39;file2&#39;],  defaultNS: &#39;file1&#39;,  debug: true}, (err, t) =&gt; {  if (err) return console.log(&#39;something went wrong loading&#39;, err);  t(&#39;key&#39;); // -&gt; same as i18next.t}));// is the same asconst newInstance = i18next.createInstance();newInstance.init({  fallbackLng: &#39;en&#39;,  ns: [&#39;file1&#39;, &#39;file2&#39;],  defaultNS: &#39;file1&#39;,  debug: true}, (err, t) =&gt; {  if (err) return console.log(&#39;something went wrong loading&#39;, err);  t(&#39;key&#39;); // -&gt; same as i18next.t}));</code></pre><ul><li>cloneInstance <ul><li><code>i18next,cloneInstance(options)</code></li><li>create a clone of the current instance</li><li>share store, plugins, and initial configuration </li><li>can be used to create an instance sharing storage but being independent on set language or default namespaces </li></ul></li></ul><h2 id="3-3-Events"><a href="#3-3-Events" class="headerlink" title="3.3 Events"></a>3.3 Events</h2><ul><li>onInitialized <ul><li><code>i18next.on(&#39;initialized&#39;, function(options){})</code></li><li>get fired after initialization </li></ul></li><li>onLanguageChanged<ul><li><code>i18next.on(&#39;languageChanged&#39;, function(lng){}</code></li><li>get fired when changeLanguage got called </li></ul></li><li>onLoaded <ul><li><code>i18next.on(&#39;loaded&#39;, function(loaded) {})</code></li><li>get fired when loading resources</li></ul></li><li>onFailedLoading<ul><li><code>i18next.on(&#39;failedLoading&#39;, function(lng, ns, msg) {})</code> </li><li>get fired if loading resources failed </li></ul></li><li>onMissingKey<ul><li><code>i18next.on(&#39;missingKey&#39;, function(lngs, namespace, key, res) {})</code></li></ul></li></ul><h2 id="3-4-Store-Events"><a href="#3-4-Store-Events" class="headerlink" title="3.4 Store Events"></a>3.4 Store Events</h2><ul><li>onAdded<ul><li><code>i18next.store.on(&#39;added&#39;, function(lng, ns) {})</code> </li></ul></li><li>onRemoved<ul><li><code>i18next.store.on(&#39;removed&#39;, function(lng, ns) {})</code></li></ul></li></ul><h2 id="3-5-Resource-Handling"><a href="#3-5-Resource-Handling" class="headerlink" title="3.5 Resource Handling"></a>3.5 Resource Handling</h2><p>can be accessed on i18next or i18next.services.resourceStore </p><ul><li>getResource <ul><li><code>i18next.getResource(lng, ns, key, options)</code> </li></ul></li><li>addResource <ul><li><code>i18next.addResource(lng, ns, key, value, options)</code></li></ul></li><li>addResourceBundle<ul><li><code>i18next.addResourceBundle(lng, ns, resources, deep, overwrite)</code></li><li>add a complete bundle </li></ul></li><li>hasResourceBundle </li><li>getDataByLanguage</li><li>getResourceBundle</li><li>removeResourceBUndle </li></ul><h1 id="4-Translation-Function"><a href="#4-Translation-Function" class="headerlink" title="4. Translation Function"></a>4. Translation Function</h1><h2 id="4-1-Essentials"><a href="#4-1-Essentials" class="headerlink" title="4.1 Essentials"></a>4.1 Essentials</h2><h3 id="4-1-1-Accessing-Keys"><a href="#4-1-1-Accessing-Keys" class="headerlink" title="4.1.1 Accessing Keys"></a>4.1.1 Accessing Keys</h3><pre><code>{    &quot;key&quot;: &quot;value of key&quot;,    &quot;look&quot;: {        &quot;deep&quot;: &quot;value of look deep&quot;    }}// use key for translation, then return its valuei18next.t(&#39;key&#39;);// -&gt; &quot;value of key&quot;// key could have its own structure i18next.t(&#39;look.deep&#39;);// -&gt; &quot;value of look deep&quot;</code></pre><h3 id="4-1-2-Passing-default-value"><a href="#4-1-2-Passing-default-value" class="headerlink" title="4.1.2 Passing default value"></a>4.1.2 Passing default value</h3><pre><code>i18next.t(&#39;key&#39;, &#39;default value to show&#39;)</code></pre><h3 id="4-1-3-Accessing-keys-in-different-namespace"><a href="#4-1-3-Accessing-keys-in-different-namespace" class="headerlink" title="4.1.3 Accessing keys in different namespace"></a>4.1.3 Accessing keys in different namespace</h3><p>As mentioned in 5.1, namespace allow you to separate translations into multiple files </p><ul><li>init </li></ul><pre><code>i18next.init({  ns: [&#39;common&#39;, &#39;moduleA&#39;],  defaultNS: &#39;moduleA&#39;});{    &quot;name&quot;: &quot;Module A&quot;}{    &quot;button&quot;: {        &quot;save&quot;: &quot;save&quot;    }}i18next.t(&#39;name&#39;);// -&gt; &quot;Module A&quot;// as shown below, for not default ns, you have to specify the ns name i18next.t(&#39;common:button.save&#39;);// -&gt; &quot;save&quot;</code></pre><h3 id="4-1-4-Multiple-Fallback-Keys"><a href="#4-1-4-Multiple-Fallback-Keys" class="headerlink" title="4.1.4 Multiple Fallback Keys"></a>4.1.4 Multiple Fallback Keys</h3><p>we could call t with an array of key, enable translation with dynamic keys, for a non specific fallback value </p><pre><code>{  &quot;error&quot;: {    &quot;unspecific&quot;: &quot;Something went wrong.&quot;,    &quot;404&quot;: &quot;The page was not found.&quot;  }}// const error = &#39;404&#39;;i18next.t([`error.${error}`, &#39;error.unspecific&#39;]); // -&gt; &quot;The page was not found&quot;// const error = &#39;502&#39;;i18next.t([`error.${error}`, &#39;error.unspecific&#39;]); // -&gt; &quot;Something went wrong&quot;</code></pre><h3 id="4-1-5-Overview-Options"><a href="#4-1-5-Overview-Options" class="headerlink" title="4.1.5 Overview Options"></a>4.1.5 Overview Options</h3><h2 id="4-2-Interpolation"><a href="#4-2-Interpolation" class="headerlink" title="4.2 Interpolation"></a>4.2 Interpolation</h2><p>It enables you to integrate dynamic values into translation. </p><p>Interpolation values get escaped to save you from possible xss attacks</p><h3 id="4-2-1-Basic"><a href="#4-2-1-Basic" class="headerlink" title="4.2.1 Basic"></a>4.2.1 Basic</h3><p>Key by default are strings surrounded by curly brackets</p><pre><code>{    &quot;key&quot;: &quot;{{what}} is {{how}}&quot;}i18next.t(&#39;key&#39;, { what: &#39;i18next&#39;, how: &#39;great&#39; });// -&gt; &quot;i18next is great&quot;// Working with data models{    &quot;key&quot;: &quot;I am {{author.name}}&quot;}const author = {     name: &#39;Jan&#39;,    github: &#39;jamuhl&#39;};i18next.t(&#39;key&#39;, { author });// -&gt; &quot;I am Jan&quot;</code></pre><h3 id="4-2-2-Unescape"><a href="#4-2-2-Unescape" class="headerlink" title="4.2.2 Unescape"></a>4.2.2 Unescape</h3><p>Per default the values get escaped to save you from possible xss attacks, you could toggle excaping off, by either putting <code>-</code> beofre the key, or set the <code>escapeValue</code> option to <code>false</code> when requesting a translation. </p><pre><code>{    &quot;keyEscaped&quot;: &quot;no danger {{myVar}}&quot;,    &quot;keyUnescaped&quot;: &quot;dangerous {{- myVar}}&quot;}i18next.t(&#39;keyEscaped&#39;, { myVar: &#39;&lt;img /&gt;&#39; });// -&gt; &quot;no danger &amp;lt;img &amp;#x2F;&amp;gt;&quot;i18next.t(&#39;keyUnescaped&#39;, { myVar: &#39;&lt;img /&gt;&#39; });// -&gt; &quot;dangerous &lt;img /&gt;&quot;i18next.t(&#39;keyEscaped&#39;, { myVar: &#39;&lt;img /&gt;&#39;, interpolation: { escapeValue: false } });// -&gt; &quot;no danger &lt;img /&gt;&quot; (obviously could be dangerous)</code></pre><h3 id="4-2-3-Additional-Options"><a href="#4-2-3-Additional-Options" class="headerlink" title="4.2.3 Additional Options"></a>4.2.3 Additional Options</h3><p>Prefix/ suffix for interpolation and other options can be overridden in the init options or by passing additional options to the <code>t</code> function. </p><pre><code>i18next.init({    interpolation: { ... }});i18next.t(&#39;key&#39;, {    interpolation: { ... }});</code></pre><ul><li>format </li><li>formatSeparator <ul><li>used to separate format from interpolation value </li></ul></li><li>excape <ul><li><code>function excape(str) {return str;}</code></li></ul></li><li>escapeValue<ul><li>escape passed in values to avoid xss injection </li></ul></li><li>useRawValueToEscape <ul><li>if true, then value passed into escape function is not casted to string, use with custom escape function that does its own type check </li></ul></li><li>prefix </li><li>suffix </li><li>prefixEscaped  escaped prefix for interpolation (regexSafe)</li><li>suffixEscaped  escaped suffix for interpolation (regexSafe)</li><li>unexcapeSuffix</li><li>unescapePrefix</li><li>nestingPrefix</li><li>nestingSuffix</li><li>nestingPrefixEscaped </li><li>nestingSuffixEscaped</li><li>defaultVariables<ul><li>global variables to use in interpolation replacements </li></ul></li><li>maxReplaces<ul><li>after how many interpolation runs to break out before throwing a stack overflow  </li></ul></li></ul><h2 id="4-3-Formatting"><a href="#4-3-Formatting" class="headerlink" title="4.3 Formatting"></a>4.3 Formatting</h2><p>Format numbers/ dates and you can also use this function for custom formattings. </p><h3 id="4-3-1-Basic"><a href="#4-3-1-Basic" class="headerlink" title="4.3.1 Basic"></a>4.3.1 Basic</h3><pre><code>{    &quot;key&quot;: &quot;The current date is {{date, MM/DD/YYYY}}&quot;,    &quot;key2&quot;: &quot;{{text, uppercase}} just uppercased&quot;}i18next.init({    interpolation: {        format: function(value, format, lng) {            if (format === &#39;uppercase&#39;) return value.toUpperCase();            if(value instanceof Date) return moment(value).format(format);            return value;        }    }});i18next.t(&#39;key&#39;, { date: new Date() });// -&gt; &quot;The current date is 07/13/2016&quot;i18next.t(&#39;key2&#39;, { text: &#39;can you hear me&#39; });// =&gt; &quot;CAN YOU HEAR ME just uppercased&quot;i18next.on(&#39;languageChanged&#39;, function(lng) {  moment.locale(lng);});</code></pre><h3 id="4-3-2-Additional-Options"><a href="#4-3-2-Additional-Options" class="headerlink" title="4.3.2 Additional Options"></a>4.3.2 Additional Options</h3><ul><li>format function <ul><li><code>function format(value, format, lng){}</code> </li></ul></li><li>formatSeparator<ul><li>used to separate format from interpolation value </li></ul></li></ul><h2 id="4-4-Plurals"><a href="#4-4-Plurals" class="headerlink" title="4.4 Plurals"></a>4.4 Plurals</h2><p>i18next support plurals by default. </p><pre><code>{  &quot;key&quot;: &quot;item&quot;,  &quot;key_plural&quot;: &quot;items&quot;,  &quot;keyWithCount&quot;: &quot;{{count}} item&quot;,  &quot;keyWithCount_plural&quot;: &quot;{{count}} items&quot;}i18next.t(&#39;key&#39;, {count: 0}); // -&gt; &quot;items&quot;i18next.t(&#39;key&#39;, {count: 1}); // -&gt; &quot;item&quot;i18next.t(&#39;key&#39;, {count: 5}); // -&gt; &quot;items&quot;i18next.t(&#39;key&#39;, {count: 100}); // -&gt; &quot;items&quot;i18next.t(&#39;keyWithCount&#39;, {count: 0}); // -&gt; &quot;0 items&quot;i18next.t(&#39;keyWithCount&#39;, {count: 1}); // -&gt; &quot;1 item&quot;i18next.t(&#39;keyWithCount&#39;, {count: 5}); // -&gt; &quot;5 items&quot;i18next.t(&#39;keyWithCount&#39;, {count: 100}); // -&gt; &quot;100 items&quot;</code></pre><p>Usually the plural suffix could be key_plural directly, but you could find more accurate answer <a href="https://jsfiddle.net/sm9wgLze" target="_blank" rel="noopener">here</a></p><h3 id="4-4-1-Interval-Plurals"><a href="#4-4-1-Interval-Plurals" class="headerlink" title="4.4.1 Interval Plurals"></a>4.4.1 Interval Plurals</h3><p>We could define phrases expressing the number of items lies in a range in following ways </p><pre><code>// add a post processor import i18next from &#39;i18next&#39;;import intervalPlural from &#39;i18next-intervalplural-postprocessor&#39;;i18next  .use(intervalPlural)  .init(i18nextOptions); // define all the keys needed {  &quot;key1&quot;: &quot;{{count}} item&quot;,  &quot;key1_plural&quot;: &quot;{{count}} items&quot;,  &quot;key1_interval&quot;: &quot;(1){one item};(2-7){a few items};(7-inf){a lot of items};&quot;,  &quot;key2&quot;: &quot;{{count}} item&quot;,  &quot;key2_plural&quot;: &quot;{{count}} items&quot;,  &quot;key2_interval&quot;: &quot;(1){one item};(2-7){a few items};&quot;}// sample - running code i18next.t(&#39;key1_interval&#39;, {postProcess: &#39;interval&#39;, count: 1}); // -&gt; &quot;one item&quot;i18next.t(&#39;key1_interval&#39;, {postProcess: &#39;interval&#39;, count: 4}); // -&gt; &quot;a few items&quot;i18next.t(&#39;key1_interval&#39;, {postProcess: &#39;interval&#39;, count: 100}); // -&gt; &quot;a lot of items&quot;// not matching into a range it will fallback to// the regular plural formi18next.t(&#39;key2_interval&#39;, {postProcess: &#39;interval&#39;, count: 1}); // -&gt; &quot;one item&quot;i18next.t(&#39;key2_interval&#39;, {postProcess: &#39;interval&#39;, count: 4}); // -&gt; &quot;a few items&quot;i18next.t(&#39;key2_interval&#39;, {postProcess: &#39;interval&#39;, count: 100}); // -&gt; &quot;100 items&quot;</code></pre><h2 id="4-5-Nesting"><a href="#4-5-Nesting" class="headerlink" title="4.5 Nesting"></a>4.5 Nesting</h2><h3 id="4-5-1-Basic"><a href="#4-5-1-Basic" class="headerlink" title="4.5.1 Basic"></a>4.5.1 Basic</h3><p>Allow you to reference other keys in a translation, could be useful to build glossary terms. </p><pre><code>{    &quot;nesting1&quot;: &quot;1 $t(nesting2)&quot;,    &quot;nesting2&quot;: &quot;2 $t(nesting3)&quot;,    &quot;nesting3&quot;: &quot;3&quot;,}i18next.t(&#39;nesting1&#39;); // -&gt; &quot;1 2 3&quot;</code></pre><p>we could also reference keys from other namespaces by prepending the namespace</p><pre><code>&quot;nesting1&quot;: &quot;1 $t(common:nesting2)&quot;</code></pre><h3 id="4-5-2-Passing-Options-to-nestings"><a href="#4-5-2-Passing-Options-to-nestings" class="headerlink" title="4.5.2 Passing Options to nestings"></a>4.5.2 Passing Options to nestings</h3><pre><code>{      &quot;girlsAndBoys&quot;: &quot;$t(girls, {&#39;count&#39;: {{girls}} }) and {{count}} boy&quot;,      &quot;girlsAndBoys_plural&quot;: &quot;$t(girls, {&#39;count&#39;: {{girls}} }) and {{count}} boys&quot;,      &quot;girls&quot;: &quot;{{count}} girl&quot;,      &quot;girls_plural&quot;: &quot;{{count}} girls&quot;}i18next.t(&#39;girlsAndBoys&#39;, {count: 2, girls: 3});// -&gt; &quot;3 girls and 2 boys&quot;</code></pre><h3 id="4-5-3-Passing-nesting-to-interpolated"><a href="#4-5-3-Passing-nesting-to-interpolated" class="headerlink" title="4.5.3 Passing nesting to interpolated"></a>4.5.3 Passing nesting to interpolated</h3><pre><code>{      &quot;key1&quot;: &quot;hello world&quot;,      &quot;key2&quot;: &quot;say: {{val}}&quot;}i18next.t(&#39;key2&#39;, {val: &#39;$t(key1)&#39;});// -&gt; &quot;say: hello world&quot;</code></pre><h2 id="4-6-Context"><a href="#4-6-Context" class="headerlink" title="4.6 Context"></a>4.6 Context</h2><p>Differ translations by providing a context  – useful to provide gender specific translations </p><pre><code>{      &quot;friend&quot;: &quot;A friend&quot;,      &quot;friend_male&quot;: &quot;A boyfriend&quot;,      &quot;friend_female&quot;: &quot;A girlfriend&quot;}i18next.t(&#39;friend&#39;); // -&gt; &quot;A friend&quot;i18next.t(&#39;friend&#39;, { context: &#39;male&#39; }); // -&gt; &quot;A boyfriend&quot;i18next.t(&#39;friend&#39;, { context: &#39;female&#39; }); // -&gt; &quot;A girlfriend&quot;{      &quot;friend_male&quot;: &quot;A boyfriend&quot;,      &quot;friend_female&quot;: &quot;A girlfriend&quot;,      &quot;friend_male_plural&quot;: &quot;{{count}} boyfriends&quot;,      &quot;friend_female_plural&quot;: &quot;{{count}} girlfriends&quot;}i18next.t(&#39;friend&#39;, {context: &#39;male&#39;, count: 1}); // -&gt; &quot;A boyfriend&quot;i18next.t(&#39;friend&#39;, {context: &#39;female&#39;, count: 1}); // -&gt; &quot;A girlfriend&quot;i18next.t(&#39;friend&#39;, {context: &#39;male&#39;, count: 100}); // -&gt; &quot;100 boyfriends&quot;i18next.t(&#39;friend&#39;, {context: &#39;female&#39;, count: 100}); // -&gt; &quot;100 girlfriends&quot;</code></pre><h2 id="4-7-Objects-and-Arrays"><a href="#4-7-Objects-and-Arrays" class="headerlink" title="4.7 Objects and Arrays"></a>4.7 Objects and Arrays</h2><p>You could return objects or arrays to be used by 3rd party modules localization</p><pre><code>{    &quot;tree&quot;: {        &quot;res&quot;: &quot;added {{something}}&quot;    },    &quot;array&quot;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]}i18next.t(&#39;tree&#39;, { returnObjects: true, something: &#39;gold&#39; });// -&gt; { res: &#39;added gold&#39; }i18next.t(&#39;array&#39;, { returnObjects: true });// -&gt; [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]</code></pre><h1 id="5-Principles"><a href="#5-Principles" class="headerlink" title="5. Principles"></a>5. Principles</h1><h2 id="5-1-Namespace"><a href="#5-1-Namespace" class="headerlink" title="5.1 Namespace"></a>5.1 Namespace</h2><ul><li>allow you to separate translations thatget loaded into multiple files </li><li>separate files could benefits<ul><li>too many segments in a file make you lose the overview</li><li>not every translation needs to be loaded on the first page, speed up load time </li></ul></li><li>good practice<ul><li>namespace per view/ page</li><li>namespace per application section </li><li>namespace per module which gets lazy loaded </li></ul></li></ul><pre><code>i18next.init({  ns: [&#39;common&#39;, &#39;moduleA&#39;, &#39;moduleB&#39;],  defaultNS: &#39;moduleA&#39;}, (err, t) =&gt; {  i18next.t(&#39;myKey&#39;); // key in moduleA namespace (defined default)  i18next.t(&#39;common:myKey&#39;); // key in common namespace});// load additional namespaces after initializationi18next.loadNamespaces(&#39;anotherNamespace&#39;, (err, t) =&gt; { /* ... */ });</code></pre><h2 id="5-2-Translation-Resolution"><a href="#5-2-Translation-Resolution" class="headerlink" title="5.2 Translation Resolution"></a>5.2 Translation Resolution</h2><p>A overall process on how i18next attempts to translate your keys into the appropriate content for a given location. </p><h3 id="5-2-1-Concepts"><a href="#5-2-1-Concepts" class="headerlink" title="5.2.1 Concepts"></a>5.2.1 Concepts</h3><ul><li>Keys<ul><li>A key is a specific set to text than provides a corresponding value when look up </li></ul></li><li>Languages <ul><li>Language to be used for translating a key </li><li>If a key is not found, you could gracefully fall back to other languages </li></ul></li></ul><h3 id="5-2-2-Resolution-Order"><a href="#5-2-2-Resolution-Order" class="headerlink" title="5.2.2 Resolution Order"></a>5.2.2 Resolution Order</h3><p>When translating a key, i18next tries the first combination of <strong>namespace, language, and key</strong>.  If that doesn’t work, i18next will try to match with a similar key, looking for a key that best fits the plural form, context and singular form in that order. </p><ul><li>similar keys <ul><li>If the specific key is not found, i18next tries to match the key you are looking for with a similar key, looking for a key that best fits the plural form, context, and singular form in that order.</li></ul></li><li>languages<ul><li>i18next will walk through the list of languages, which consists of the current language and the fallback languages.  </li></ul></li><li>namespaces<ul><li>walk through current namespaces and the fallback namespaces </li></ul></li><li>fallback keys <ul><li>if that key is still not found, i18n will walk through the process with the fallbak keys if specified  </li></ul></li><li>key not found <ul><li>will then return the key itself, that being the first key specified if you also specified fallback keys </li></ul></li></ul><h2 id="5-3-Fallback"><a href="#5-3-Fallback" class="headerlink" title="5.3 Fallback"></a>5.3 Fallback</h2><pre><code>{  &quot;error&quot;: {    &quot;unspecific&quot;: &quot;Something went wrong.&quot;,    &quot;404&quot;: &quot;The page was not found.&quot;  }}// const error = &#39;404&#39;;i18next.t([`error.${error}`, &#39;error.unspecific&#39;]) // -&gt; &quot;The page was not found&quot;// const error = &#39;502&#39;;i18next.t([`error.${error}`, &#39;error.unspecific&#39;]) // -&gt; &quot;Something went wrong&quot;</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.i18next.com/" target="_blank" rel="noopener">https://www.i18next.com/</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> JavaScript </tag>
            
            <tag> i18next </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CSS pseudo class selectors</title>
      <link href="/CSS-pseudo-class-selectors/"/>
      <url>/CSS-pseudo-class-selectors/</url>
      
        <content type="html"><![CDATA[<h1 id="1-What-is-pseudo-selectors"><a href="#1-What-is-pseudo-selectors" class="headerlink" title="1. What is pseudo selectors?"></a>1. What is pseudo selectors?</h1><blockquote><p>Used to style specified parts of an element: </p><ol><li>Style the first letter, or line of an element </li><li>Insert content before, or after the content of an element </li></ol></blockquote><h1 id="2-Why-you-wanna-use-it"><a href="#2-Why-you-wanna-use-it" class="headerlink" title="2. Why you wanna use it?"></a>2. Why you wanna use it?</h1><ul><li>Realize some fancy styling, like you want to highlight the first line or first character in an element </li><li>You want to insert some common element before/after each specific element</li></ul><h1 id="3-How-to-use-it"><a href="#3-How-to-use-it" class="headerlink" title="3. How to use it?"></a>3. How to use it?</h1><pre><code>p::first-line {  color: #ff0000;  font-variant: small-caps;}p::first-letter {  color: #ff0000;  font-size: xx-large;}// you insert gif before every h1h1::before {  content: url(smiley.gif);}h1::after {  content: url(smiley.gif);}::selection {  color: red;  background: yellow;}</code></pre><h1 id="4-Tips"><a href="#4-Tips" class="headerlink" title="4. Tips"></a>4. Tips</h1><h2 id="4-1-Double-colon-versus-single"><a href="#4-1-Double-colon-versus-single" class="headerlink" title="4.1 Double colon versus single"></a>4.1 Double colon versus single</h2><p>The double colon replaced the single-colon notation for pseudo-elements in CSS3. This was an attempt from W3C to distinguish between pseudo-classes and pseudo-elements.</p><p>The single-colon syntax was used for both pseudo-classes and pseudo-elements in CSS2 and CSS1.</p><p>For backward compatibility, the single-colon syntax is acceptable for CSS2 and CSS1 pseudo-elements.</p><p>*<em>Please try to use single instead of double thus it could support almost all browsers *</em></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.w3schools.com/css/css_pseudo_elements.asp" target="_blank" rel="noopener">https://www.w3schools.com/css/css_pseudo_elements.asp</a></li><li><a href="https://css-tricks.com/almanac/selectors/a/after-and-before/" target="_blank" rel="noopener">https://css-tricks.com/almanac/selectors/a/after-and-before/</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> CSS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux性能优化(4)-CPU使用率</title>
      <link href="/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-4-CPU%E4%BD%BF%E7%94%A8%E7%8E%87/"/>
      <url>/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-4-CPU%E4%BD%BF%E7%94%A8%E7%8E%87/</url>
      
        <content type="html"><![CDATA[<p>衡量CPU的方式，可以使用：</p><ul><li>平均负载</li><li>CPU上下文切换</li><li>CPU使用率</li></ul><h1 id="1-CPU使用率"><a href="#1-CPU使用率" class="headerlink" title="1. CPU使用率"></a>1. CPU使用率</h1><h2 id="1-1-概念"><a href="#1-1-概念" class="headerlink" title="1.1 概念"></a>1.1 概念</h2><p>Linux作为一个多任务操作系统，将每个CPU的时间划分为很短的时间片，再通过调度器轮流分配给各个人物使用，因此造成多任务同时运行的错觉。</p><p>为了维护CPU时间，Linux通过事先定义的节拍率，触发时间中断，并使用全局变量Jiffies记录了开机以来的节拍数，每发生一次时间中断，Jiffies的值就加1.可以通过查询<code>/boot/config</code>内核选项来查看其配置，一般来说设置为100，250， 1000等数值。比如对于100来说，就是每秒触发250次时间中断。</p><p>Linux通过<code>/proc</code>虚拟文件系统，向用户空间提供系统内部状态的信息，而<code>/proc/stat</code>提供的就是系统的CPU和任务统计信息</p><ul><li>使用man proc 查询, 都是和CPU使用率相关的重要指标<ul><li>user: 用户态CPU时间</li><li>nice: 低优先级用户态时间</li><li>system: 内核态CPU时间</li><li>idle: 空闲时间</li><li>iowait: 等待I/O的CPU时间</li><li>irq: 处理硬中断的CPU时间</li><li>softirq: 处理软中断的CPU时间</li><li>steal: 运行在虚拟机当中，被其他虚拟机占用的CPU时间</li><li>guest: 运行虚拟机的CPU时间</li><li>guest_nice: 以低优先级运行虚拟机的时间</li></ul></li></ul><p><img src="https://i.loli.net/2020/01/31/vbKiQhfYDls4XrH.png" alt="fig1.png"></p><h2 id="1-2-如何查看"><a href="#1-2-如何查看" class="headerlink" title="1.2 如何查看"></a>1.2 如何查看</h2><ul><li>top<ul><li>显示系统总体的CPU和内存使用的情况，以及各个进程的资源使用情况 </li></ul></li><li>ps<ul><li>显示每个进程的资源使用情况 </li></ul></li><li>pidstat<ul><li>分析每个进程的CPU使用率 </li></ul></li></ul><h2 id="1-3-如何分析"><a href="#1-3-如何分析" class="headerlink" title="1.3 如何分析"></a>1.3 如何分析</h2><ul><li>使用Perf<ul><li>perf top<ul><li>显示占用CPU时钟最多的函数或者指令 </li></ul></li><li>perf record<ul><li>可以保存数据 </li></ul></li><li>perf report</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> CPU Utilization </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux性能优化(3)-CPU 上下文切换</title>
      <link href="/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-3-CPU-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/"/>
      <url>/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-3-CPU-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>多个进程竞争CPU会导致系统的负载升高，这是因为CPU会进行上下文切换。Linux是一个多任务操作系统，它可以支持远大于CPU数量的任务同时进行，然而，并不是真的同时运行，而是系统在很短的时间内，将CPU轮流分配给它们，造成多任务同时运行的错觉。</p><p>而在每个任务运行之前，CPU需要知道任务从哪里加载，又从哪里开始运行的。即<strong><em>系统需要事先设置好CPU寄存器和程序计数器</em></strong>。</p><p>CPU 寄存器，是 CPU 内置的容量小、但速度极快的内存。而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此也被叫做 CPU上下文。</p><p><img src="https://i.loli.net/2020/01/31/3jaulkJAZwrsYBm.png" alt="fig1.png"></p><p>而CPU上下文切换，就是先把前一个任务的CPU上下文，(CPU寄存器和程序计数器)保存起来,然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。</p><p>而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。</p><p>而CPU的上下文切换，可以分为几个不同的场景，进程上下文切换，线程上下文切换以及中断上下文切换。</p><h1 id="2-系统调用"><a href="#2-系统调用" class="headerlink" title="2 系统调用"></a>2 系统调用</h1><p>Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。</p><p><img src="https://i.loli.net/2020/01/31/itzhDSE6eTcVOGP.png" alt="fig2.png"></p><ul><li>内核空间具有最高权限，可以直接访问所有资源</li><li>用户空间只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入内核状态中，才能访问这些特权资源。</li></ul><blockquote><p>进程既可以在用户空间运行，也可以在内核空间中运行。分别称为进程的用户态和内核态。</p></blockquote><p>从用户态到内核态的转变，需要通过系统调用来完成。而这实际上也发生了CPU的上下文切换，CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。</p><p>而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。所以一次系统调用的过程，实际上是发生了两次CPU上下文切换。</p><p>系统调用过程，不会切换进程的，不涉及到虚拟内存等进程用户态的资源，也不会切换进程。</p><ul><li>进程的上下文切换，是指从一个进程切换到另一个进程运行。</li><li>系统调用过程一直在同一个进程当中</li></ul><h1 id="3-进程上下文切换"><a href="#3-进程上下文切换" class="headerlink" title="3. 进程上下文切换"></a>3. 进程上下文切换</h1><h2 id="3-1-进程上下文切换和系统调用的区别"><a href="#3-1-进程上下文切换和系统调用的区别" class="headerlink" title="3.1 进程上下文切换和系统调用的区别"></a>3.1 进程上下文切换和系统调用的区别</h2><ul><li>进程是由内核来管理和调度的，<strong>进程的切换只能发生在内核态</strong>。所以，进程的上下文不仅包括了<strong>虚拟内存、栈、全局变量</strong>等用户空间的资源，还包括了<strong>内核堆栈、寄存器</strong>等内核空间的状态。</li><li>因此，进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈。</li></ul><p><img src="https://i.loli.net/2020/01/31/qum5ICSpUbZcjyR.png" alt="fig3.png"></p><p>每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是上一节中我们所讲的，导致平均负载升高的一个重要因素。</p><p>另外，我们知道， <strong>Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系</strong>。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。</p><h2 id="3-2-何时需要进程切换"><a href="#3-2-何时需要进程切换" class="headerlink" title="3.2 何时需要进程切换"></a>3.2 何时需要进程切换</h2><p>进程调度的时候，按照优先级和等待的时间进行排序，对CPU的使用进行分配。</p><ol><li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。</li><li><strong>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行</strong>，这个时候进程也会被挂起，并由系统调度其他进程运行。</li><li>当进程通过睡眠函数  sleep 这样的方法将自己主动挂起时，自然也会重新调度。</li><li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。</li><li>发生<strong>硬件中断</strong>时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。</li></ol><h1 id="4-线程上下文切换"><a href="#4-线程上下文切换" class="headerlink" title="4. 线程上下文切换"></a>4. 线程上下文切换</h1><h2 id="4-1-线程-vs-进程"><a href="#4-1-线程-vs-进程" class="headerlink" title="4.1 线程 vs 进程"></a>4.1 线程 vs 进程</h2><blockquote><p>线程是调度的基本单温，而进程是资源拥有的基本单位。</p></blockquote><ul><li>内核当中的任务调度，实际上的调用对象是线程</li><li>进程在为线程提供虚拟内存，全局变量等资源</li><li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换的时候是不需要修改的</li><li>线程自己的私有数据比如栈还有寄存器，在上下文切换的时候是需要保存的</li></ul><h2 id="4-2-线程切换"><a href="#4-2-线程切换" class="headerlink" title="4.2 线程切换"></a>4.2 线程切换</h2><p>两种情况：</p><ul><li>两个线程属于不同进程，因为资源不共享，所以切换过程跟进程上下文切换时一样的</li><li>两个线程属于同一个进程，虚拟内存是共享的，在切换的时候，虚拟内存等资源保持不动，只需要切换线程的私有数据，寄存器等不共享的数据</li></ul><h1 id="5-中断上下文切换"><a href="#5-中断上下文切换" class="headerlink" title="5. 中断上下文切换"></a>5. 中断上下文切换</h1><p>快速响应硬件时间的方式，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，需要将进程当前的状态保存下来，这样在中断结束以后，进程仍可以从原来的状态恢复运行。</p><p>跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。</p><p>对同一个 CPU 来说，中断处理比进程拥有更高的优先级。，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。</p><h1 id="5-实践"><a href="#5-实践" class="headerlink" title="5. 实践"></a>5. 实践</h1><h2 id="5-1-使用vmstat分析内存使用情况"><a href="#5-1-使用vmstat分析内存使用情况" class="headerlink" title="5.1 使用vmstat分析内存使用情况"></a>5.1 使用<code>vmstat</code>分析内存使用情况</h2><pre><code># 每隔 5 秒输出 1 组数据$ vmstat 5procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 0  0      0 7005360  91564 818900    0    0     0     0   25   33  0  0 100  0  0</code></pre><ul><li>cs: 每秒上下文切换的次数</li><li>in: 每秒中断的次数</li><li>r (Running or Runnable): 就绪队列的长度，即正在运行和等待CPU的进程数</li><li>b (Blocked) 处于不可中断睡眠状态的进程数</li></ul><h2 id="5-2-使用pidstat-w-查看每个进程的上下文切换情况"><a href="#5-2-使用pidstat-w-查看每个进程的上下文切换情况" class="headerlink" title="5.2 使用pidstat -w 查看每个进程的上下文切换情况"></a>5.2 使用<code>pidstat -w</code> 查看每个进程的上下文切换情况</h2><pre><code># 每隔 5 秒输出 1 组数据$ pidstat -w 5Linux 4.15.0 (ubuntu)  09/23/18  _x86_64_  (2 CPU)08:18:26      UID       PID   cswch/s nvcswch/s  Command08:18:31        0         1      0.20      0.00  systemd08:18:31        0         8      5.40      0.00  rcu_sched...</code></pre><ul><li>cswch: 每秒资源上下文切换<ul><li>指进程无法获取所需的资源，导致的上下文切换</li></ul></li><li>nvcswch: 每秒非资源上下文切换<ul><li>指进程由于时间片已经到了等原因，被系统强制调度，进而发生的上下文切换</li></ul></li></ul><h2 id="5-3-从-proc-interrupts读取中断信息"><a href="#5-3-从-proc-interrupts读取中断信息" class="headerlink" title="5.3 从/proc/interrupts读取中断信息"></a>5.3 从<code>/proc/interrupts</code>读取中断信息</h2><p>/proc是Linux的一个虚拟文件系统，用于内核空间与用户空间之间的通信。/proc/interrupts是这种通信机制的一部分，提供了一个只读的中断使用情况。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Context Switch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux性能优化(2)-平均负载</title>
      <link href="/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-2-%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD/"/>
      <url>/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-2-%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="1-如何理解平均负载"><a href="#1-如何理解平均负载" class="headerlink" title="1. 如何理解平均负载"></a>1. 如何理解平均负载</h1><pre><code>$uptime14:35:36 up 62 days,  2:51,  2 users,  load average: 0.02, 0.70, 1.06</code></pre><p>当前时间，系统运行时间，正在登录用户数</p><p>后面的三个数字是过去1min, 5min, 15min的平均负载。</p><blockquote><p>平均负载时指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和CPU使用率没有直接关系。</p></blockquote><blockquote><p>可运行状态的进程：指正在使用CPU或者正在等待CPU的进程, 也就是我们用<code>ps</code>看到的处于Running/ Runnable状态的进程。</p></blockquote><blockquote><p>不可中断状态的进程：指正处于内核态关键流程中的进程，并且这些进程是不可以被打断的。比如等待硬件设备的I/O响应，即我们在<code>ps</code>命令下看到的D(Uninerruptible Sleep/ Disk Sleep)状态.</p></blockquote><p>例如当一个进程向磁盘读写数据时，为了一致，在得到磁盘回复之前，是不能被其他进程或者中断打断的。否则容易出现磁盘数据与进程数据不一致的问题。</p><p>不可中断状态实际上是系统对进程和硬件设备的一种保护机制。</p><p>平均负载 -&gt; 平均活跃进程数 -&gt; 单位时间内的活跃进程数.最理想的情况就是每个CPU都刚好运行着一个进程，这样每一个CPU都能得到充分的利用。</p><h1 id="2-平均负载为多少时比较合理？"><a href="#2-平均负载为多少时比较合理？" class="headerlink" title="2. 平均负载为多少时比较合理？"></a>2. 平均负载为多少时比较合理？</h1><p>首先需要知道系统有几个CPU，可以通过top命令或者从文件/proc/cpuinfo中读取</p><pre><code>$grep &#39;model name&#39; /proc/cpuinfo | wc -l</code></pre><p>当平均负载高于CPU数量70%的时候，就应该分析和排查负载高的问题了。</p><h1 id="3-平均负载与CPU使用率"><a href="#3-平均负载与CPU使用率" class="headerlink" title="3. 平均负载与CPU使用率"></a>3. 平均负载与CPU使用率</h1><p>二者不一定会完全一致，因为平均负载指单位时间内处于可运行状态和不可中断状态的进程数，不仅包括了<strong><em>正在使用CPU的进程，还包括等待CPU和等待I/O的进程</em></strong>。</p><p>而CPU使用率，是根据单位时间内CPU的繁忙情况进行统计的，举例：</p><ul><li>CPU密集进程</li></ul><p>使用大量CPU使得平均负载升高，此时二者是一致的</p><ul><li>IO密集型进程</li></ul><p>等待I/O也会导致平均负载升高，但CPU使用率不一定会很高</p><h1 id="4-案例分析"><a href="#4-案例分析" class="headerlink" title="4. 案例分析"></a>4. 案例分析</h1><h2 id="4-1-使用工具"><a href="#4-1-使用工具" class="headerlink" title="4.1 使用工具"></a>4.1 使用工具</h2><h3 id="4-1-1-stress"><a href="#4-1-1-stress" class="headerlink" title="4.1.1 stress"></a>4.1.1 stress</h3><p>Linux 系统压力测试工具，可以用作异常进程模拟平均负载升高的场景。</p><h3 id="4-1-2-sysstat"><a href="#4-1-2-sysstat" class="headerlink" title="4.1.2 sysstat"></a>4.1.2 sysstat</h3><p>包含了常用的多核CPU性能分析工具，用来实时查看进程的CPU、内存、I/O以及上下文切换等性能指标。</p><h2 id="4-2-场景分析-CPU密集型进程"><a href="#4-2-场景分析-CPU密集型进程" class="headerlink" title="4.2 场景分析-CPU密集型进程"></a>4.2 场景分析-CPU密集型进程</h2><p>terminal 1: </p><pre><code>$ stress --cpu 1 --timeout 600</code></pre><p>terminal 2: </p><pre><code># -d 参数表示高亮显示变化的区域$ watch -d uptime...,  load average: 1.00, 0.75, 0.39</code></pre><p>terminal 3: run mpstat to see CPU usage </p><pre><code># -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据$ mpstat -P ALL 5Linux 4.15.0 (ubuntu) 09/22/18 _x86_64_ (2 CPU)13:30:06     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle13:30:11     all   50.05    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   49.9513:30:11       0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.0013:30:11       1  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00</code></pre><p>Use pidstat to see process usage </p><pre><code># 间隔 5 秒后输出一组数据$ pidstat -u 5 113:37:07      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command13:37:12        0      2962  100.00    0.00    0.00    0.00  100.00     1  stress</code></pre><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1><ol><li>mpstat -P ALL 5</li><li>pidstat -u 5 1</li></ol><ul><li>-u : cpu usage</li><li>-r : memory usage</li><li>-d : I/O usage</li><li>-p : specific process id </li></ul><ol start="3"><li>watch -d uptime </li></ol><p>watch可以帮你检测一个命令的运行结果，在Linux下，watch是周期性的执行下个程序，并全屏显示执行结果。你可以拿他来监测你想要的一切命令的结果变化，比如 tail 一个 log 文件，ls 监测某个文件的大小变化。</p><ul><li>-n : interval</li><li>-d : highlight </li><li>‘’ : command</li></ul><p>e.g : <code>watch -n 1 -d &#39;pstree|grep http&#39;</code></p><ol start="4"><li>uptime </li></ol><h1 id="6-Reference"><a href="#6-Reference" class="headerlink" title="6. Reference"></a>6. Reference</h1><ol><li><a href="https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858775.html" target="_blank" rel="noopener">Linux CPU 实时监控mpstat命令详解</a></li><li><a href="http://www.cnblogs.com/peida/archive/2012/12/31/2840241.html" target="_blank" rel="noopener">watch命令</a></li><li><a href="https://www.cnblogs.com/ggjucheng/archive/2013/01/13/2858874.html" target="_blank" rel="noopener">Linux运行进程实时监控pidstat命令详解</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 平均负载 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux性能优化(1)-概述</title>
      <link href="/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-1-%E6%A6%82%E8%BF%B0/"/>
      <url>/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96-1-%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-性能问题"><a href="#1-性能问题" class="headerlink" title="1. 性能问题"></a>1. 性能问题</h1><p>性能调优的困难主要在于：其与系统原理相联系，把系统从应用程序、库函数、系统调用、再到内核和硬件等不同的层级贯穿起来。</p><p>这个系列会讲Linux性能的基本指标，工具，相应的观测、分析和调优方法。主要研究CPU性能、磁盘I/O性能、内存性能以及网络性能四个方面的内容。</p><p>对于自己来说，其实遇到过一些性能上的问题了，但是颇有点不求甚解，有stackoverflow这个工具以后，就有点难脱离这个脚手架了。学习方法上有问题，这也是想写这么个系列，学习这样的课程的初衷。需要去了解应用程序和系统的基本原理，进行实战练习，建立一个整体性能的全局观。</p><p>想要调整性能，可能不需要了解每个组件的所有实现细节，只要能理解他们最基本的工作原理和协作方式就可以了。</p><h1 id="2-性能指标"><a href="#2-性能指标" class="headerlink" title="2. 性能指标"></a>2. 性能指标</h1><p>高并发(吞吐)，响应快(延迟)。这两个指标是从应用负载的角度来考察性能的，从系统资源的视角出发的指标，就是资源使用率，饱和度等。</p><p><img src="https://i.loli.net/2020/01/31/rvfmJx3eMwdntlW.png" alt="1.png"></p><p>随着应用负载的增加，系统资源的使用也会升高，甚至达到极限。而性能问题的本质，就是<strong>系统资源已经达到瓶颈，但请求的处理还不够快，无法支撑更多的请求</strong>。</p><p>性能分析，就是找出应用或者系统的瓶颈，并设法去避免或者缓解它们。包含一系列步骤：</p><ol><li>选择指标评估应用程序和系统的性能</li><li>为应用程序和系统设置性能目标</li><li>进行性能基准测试</li><li>性能分析定位瓶颈</li><li>优化系统和应用程序</li><li>性能监控和告警</li></ol><h1 id="3-性能工具"><a href="#3-性能工具" class="headerlink" title="3. 性能工具"></a>3. 性能工具</h1><p><img src="https://i.loli.net/2020/01/31/5uRyNxQUhdpWAOY.png" alt="2.png"><br>Brendan Greff的性能工具图谱</p><p><img src="https://i.loli.net/2020/01/31/TtXop59L7BwxmFY.png" alt="3.png"><br>性能优化思维导图</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 常用指令(3) - Inspired by THE ART OF COMMAND LINE</title>
      <link href="/Linux-%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-3-Inspired-by-THE-ART-OF-COMMAND-LINE/"/>
      <url>/Linux-%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-3-Inspired-by-THE-ART-OF-COMMAND-LINE/</url>
      
        <content type="html"><![CDATA[<h1 id="1-基础"><a href="#1-基础" class="headerlink" title="1. 基础"></a>1. 基础</h1><ul><li><code>apropos</code>查找文档</li><li><code>type [cmd]</code> 看这个命令是可执行文件、shell还是别名</li><li>任务管理工具们<ul><li>&amp;</li><li>ctrl + z</li><li>ctrl + c</li><li>jobs</li><li>fg</li><li>bg</li><li>kill</li></ul></li><li>文件管理工具<ul><li>ls    ls -l</li><li>less </li><li>head</li><li>tail   tail -f</li><li>chown </li><li>chmod </li><li>du -hs*</li></ul></li><li>文件系统管理<ul><li>df</li><li>mount </li><li>fdisk</li><li>mkfs</li><li>lsblk</li></ul></li><li>网络知识<ul><li>ip</li><li>ipconfig</li><li>dig</li></ul></li><li>grep<ul><li>-i</li><li>-o</li><li>-v</li><li>-A</li><li>-B</li><li>-C</li></ul></li></ul><h1 id="2-日常使用"><a href="#2-日常使用" class="headerlink" title="2. 日常使用"></a>2. 日常使用</h1><ul><li>补全<ul><li>tab 自动补全</li><li>ctrl-r 搜索命令行历史记录 <ul><li>enter 执行</li><li>鼠标右键 edit</li></ul></li></ul></li><li>删除 &amp; 移动<ul><li>ctrl-w 删除键入的最后一个单词</li><li>ctrl-u 删除行内光标所在位置之前的内容</li><li>alt-b alt-f以单词为单位移动光标</li><li>ctrl-a 到行的开始</li><li>ctrl-e 到行的结尾</li></ul></li><li>xargs <ul><li>接收pipeline的输入，然后用这个输入继续做操作</li></ul></li><li>pgrep, pkill <ul><li>通过名字或者属性来找到进程</li></ul></li><li>netstat -ltnp <ul><li>看现在处在listening 状态下的进程们 </li></ul></li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.quora.com/Linux/What-are-some-time-saving-tips-that-every-Linux-user-should-know#" target="_blank" rel="noopener">https://www.quora.com/Linux/What-are-some-time-saving-tips-that-every-Linux-user-should-know#</a></li><li><a href="https://coolshell.cn/articles/7829.html" target="_blank" rel="noopener">https://coolshell.cn/articles/7829.html</a></li><li><a href="https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md" target="_blank" rel="noopener">https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Cli </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux常用指令(2)</title>
      <link href="/Linux%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-2/"/>
      <url>/Linux%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-2/</url>
      
        <content type="html"><![CDATA[<p>继续上篇来介绍一些基本的指令</p><h1 id="1-tr指令"><a href="#1-tr指令" class="headerlink" title="1. tr指令"></a>1. tr指令</h1><ul><li>tr是用来对从stdin进入的字符进行相关的翻译和转换的，并且将其呈现在stdout当中</li><li>tr会接收两个字符set，然后用第二个set里面的字符来替换第一个set里面的字符</li><li>tr预定义了一些sets供用户来直接使用<ul><li>alnum: 字母数字组成的字符集</li><li>alpha：按字母顺序的字符集</li><li>blank: 空白字符集</li><li>cntrl: 控制字符集</li><li>digit: 数字字符集</li><li>graph: 图像字符集</li><li>lower: 小写字母字符集</li><li>print: 可以写出的字符集</li><li>punct: 标点符号字符集</li><li>space: 空格字符集</li><li>upper: 大写字母字符集</li><li>xdigit: 十六进制字符集</li></ul></li><li>tr -d [blabla] 删除[]里面定义的字符</li></ul><h1 id="2-colrm-指令"><a href="#2-colrm-指令" class="headerlink" title="2. colrm 指令"></a>2. colrm 指令</h1><ul><li>用来删除行的指令</li></ul><pre><code>// 删除从第四行开始到末尾的所有$ cat grocery.list | colrm 4 </code></pre><h1 id="3-expand-和-unexpand-指令"><a href="#3-expand-和-unexpand-指令" class="headerlink" title="3. expand 和 unexpand 指令"></a>3. expand 和 unexpand 指令</h1><ul><li>expand指令能够将tabs变成空格</li><li>unexpand 指令能够将空格变成tab</li></ul><h1 id="4-comm-cmp以及diff指令"><a href="#4-comm-cmp以及diff指令" class="headerlink" title="4. comm, cmp以及diff指令"></a>4. comm, cmp以及diff指令</h1><ul><li>diff指令比较两个文件，并且告知二者之间的不同<ul><li>-w 忽视空格上的不同</li><li>-i 忽视大小写的不同</li></ul></li><li>comm 也是比较两个文件，但是行为不太一样。会生成三行输出<ul><li>只在第一个文件当中出现的行</li><li>只在第二个文件当中出现的行</li><li>在两个文件当中都出现的行</li></ul></li><li>cmp 比较两个文件<ul><li>显示出两个文件不同的byte和行号 </li></ul></li></ul><h1 id="5-bc指令"><a href="#5-bc指令" class="headerlink" title="5. bc指令"></a>5. bc指令</h1><ul><li>使用bc来做基础运算 - basic calculator </li></ul><pre><code>$ echo 2+3 | bc </code></pre><h1 id="6-sed-指令"><a href="#6-sed-指令" class="headerlink" title="6. sed 指令"></a>6. sed 指令</h1><p><a href="https://coolshell.cn/articles/9104.html" target="_blank" rel="noopener">https://coolshell.cn/articles/9104.html</a></p><ul><li><p>sed指令可以用来对文件或者数据流进行转化</p><ul><li>一次读取一行的数据</li><li>对这一行数据实行特定的操作</li><li>一般来说输出到stdout</li></ul></li><li><p>功能</p><ul><li>从buffer里面删除文字</li><li>在buffer附上文本或者插入文本</li><li>写入文件</li><li>用regex定义的规则来转化文本</li></ul></li><li><p>-e: 指定表达式或者编辑的脚本   用来做替换</p><ul><li>s 表示这是个替换命令</li><li>用 / 作为分隔符 </li><li>前面是待替换的文本，后面是替换的文本</li><li>g 便是让这个替换在现在的整个buffer里都生效</li></ul></li></ul><pre><code>$ echo &quot;IBM 174.99&quot; |sed –e &#39;s/IBM/International Business Machines/g&#39; International Business Machines 174.99$ echo &quot;Oracle DB&quot;|sed -e &#39;s/Oracle/IBM/g&#39; -e &#39;s/DB/DB2/g&#39;IBM DB2$ echo &quot;C:\Program Files\PuTTY\putty.exe&quot;| sed -e &#39;s/\\/\//g&#39; -e &#39;s/ /_/g&#39; -e &#39;s/://g&#39;C/Program_Files/PuTTY/putty.exe</code></pre><ul><li>用来做漏斗<ul><li>d 表示要删除的东西</li><li>然后中间跟着的是正则表达式 表示的一个string pattern</li></ul></li></ul><pre><code>cat &lt;&lt; EOF &gt; dummy_sed.txt# top of file  # the next line here# Last Name, PhoneSmith, 555-1212Jones, 555-5555 # last numberEOF$ sed &#39;/^[[:space:]]*#/d&#39; dummy_sed.txtSmith, 555-1212Jones, 555-5555 # last number$ grep -v  ^[[:space:]]*# dummy_sed.txtSmith, 555-1212Jones, 555-5555 # last number</code></pre><h1 id="7-awk指令"><a href="#7-awk指令" class="headerlink" title="7. awk指令"></a>7. awk指令</h1><h2 id="7-1-指令范式"><a href="#7-1-指令范式" class="headerlink" title="7.1 指令范式"></a>7.1 指令范式</h2><pre><code>// $1 表示第1列，$4表示第4列  注意$0表示整行$ awk &#39;{print $1, $4}&#39;  netstat.txt </code></pre><p><a href="https://coolshell.cn/tag/awk" target="_blank" rel="noopener">https://coolshell.cn/tag/awk</a> </p><ul><li>用来做转换，漏斗，格式化等</li><li>从stdin拿数据，然后展示在stdout当中</li></ul><h2 id="7-2-格式化输出"><a href="#7-2-格式化输出" class="headerlink" title="7.2 格式化输出"></a>7.2 格式化输出</h2><p>格式化输出的样式基本上和c语言的一样</p><pre><code>$ awk &#39;{printf &quot;%-8s %-8s %-8s %-18s %-22s %-15s\n&quot;,$1,$2,$3,$4,$5,$6}&#39; netstat.txt</code></pre><h2 id="7-3-过滤记录的功能"><a href="#7-3-过滤记录的功能" class="headerlink" title="7.3 过滤记录的功能"></a>7.3 过滤记录的功能</h2><pre><code>$ awk &#39;$3==0 &amp;&amp; $6==&quot;LISTEN&quot; &#39; netstat.txt// 内建变量NR来展示表头$ awk &#39;$3==0 &amp;&amp; $6==&quot;LISTEN&quot; || NR==1 &#39; netstat.txt$ awk &#39;$3==0 &amp;&amp; $6==&quot;LISTEN&quot; || NR==1 {printf &quot;%-20s %-20s %s\n&quot;,$4,$5,$6}&#39; netstat.txt</code></pre><h2 id="7-4-awk的内建变量"><a href="#7-4-awk的内建变量" class="headerlink" title="7.4 awk的内建变量"></a>7.4 awk的内建变量</h2><ul><li>$0 当前记录 </li><li>$1 - $n 当前记录的第n个字段</li><li>FS  输入字段分隔符，默认是空格或者Tab</li><li>NF  当前记录当中的字段个数</li><li>NR  已经读出的记录数，行号</li><li>FNR 当前记录数，与NR不同的是，这个值会是各个文件自己的行号</li><li>RS  输入的记录分隔符，默认为换行符</li><li>OFS 输出字段分隔符，默认空格</li><li>ORS 输出记录分隔符，默认换行符</li><li>FILENAME 当前输入文件的名字</li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Cli </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 常用指令(1)</title>
      <link href="/Linux-%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-1/"/>
      <url>/Linux-%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4-1/</url>
      
        <content type="html"><![CDATA[<p>Unix的一大哲学就是创建只做一件事情的程序块，并且将这件事情做好。在这种哲学下，仔细思考需要的接口，并且用pipeline联结起来并最终产生了有用的结果就变成一件很重要的事情了。想象一下数据通过管道在不同的指令之间流动的过程，很难不用优美来形容，哈哈。本文总结一些基本的文本处理的命令，注意这些命令一般来说也是可以串联起来实现一些相对复杂且完成度比较高的功能的。</p><p>下面将逐个介绍各个指令：</p><h1 id="1-Cat"><a href="#1-Cat" class="headerlink" title="1. Cat"></a>1. Cat</h1><ul><li>用来创建，连接，展示文件的</li></ul><pre><code>// 创建新文件，在本行命令以后就可以输入想存储的内容了$ cat &gt; grocery.list// 将新输入的内容附在原文件尾$ cat &gt;&gt; grocery.list // 查看文件当中的内容$ cat grocery.list// 查看文件当中的内容，带行数的$ cat -n grocery.list </code></pre><h1 id="2-nl"><a href="#2-nl" class="headerlink" title="2. nl"></a>2. nl</h1><p>nl可以从stdin或者文件里读取行。输出会写到stdout或者重指向到一个文件，或者通过管道将内容传输到其他指令处。</p><ul><li><p>nl</p><ul><li><p>-b 指定要计数的行</p><ul><li>a : 所有行都算</li><li>t : 不计空行，或者只有空格的行</li><li>n : 全都不计</li><li>p : 根据某种特征</li></ul></li><li><p>-s 指定行号和具体内容的分隔符</p><p>// nl 类似于 cat -n<br>$ nl grocery.list </p><p>// 根据 p定义的特征：这里是只记录起始字母为a或b的<br>$ nl -b p^[ba] grocery.list</p><p>// 让行号和具体内容之间的分隔符变成等号<br>$ nl -s= grocery.list </p></li></ul></li></ul><h1 id="3-wc"><a href="#3-wc" class="headerlink" title="3. wc"></a>3. wc</h1><p>wc是wordcount的简称，顾名思义，用来统计行数，词语数量，或者是字母的数量</p><ul><li>wc<ul><li>-l 行数</li><li>-w 词语数</li><li>-c 字母数</li></ul></li></ul><h1 id="4-grep"><a href="#4-grep" class="headerlink" title="4. grep"></a>4. grep</h1><p>会搜索特定的文件，或者从stdin里，去寻找符合定义的某种特征的表达</p><ul><li>grep<ul><li>-c 统计出现了的行数</li><li>-h 搜索多个文件的时候不再显示出文件名字</li><li>-i 忽略大小写的不同</li><li>-l 只打印满足指定特征的文件名</li><li>-n 打印所在的行位置</li><li>-v 输出所有不满足特征的行</li><li>-w </li></ul></li></ul><h1 id="5-streams-pipes-redirects-tee"><a href="#5-streams-pipes-redirects-tee" class="headerlink" title="5. streams, pipes, redirects, tee"></a>5. streams, pipes, redirects, tee</h1><p>在Unix当中，一个terminal常规是包含三个流的，一个为了输入，两个为了输出。输入流，指的是stdin,一般来说是指向keyboard的；标准输出流一般指的是stdout， 会将结果输出到terminal。每个流都有自己的文件描述符，每一个都可以做管道化，分开来做重定向到其他命令当中去。 </p><ul><li>stdin 0  &lt; </li><li>stdout 1 &gt; </li><li>stderr 2 </li></ul><p>“|” 指一个管道，会将前一个指令的输出作为下一个指令的输入</p><pre><code>$ cat grocery.list | nl </code></pre><ul><li>&lt;&lt; <ul><li>可以进行多行的输入</li></ul></li></ul><h1 id="6-Using-head-and-tail"><a href="#6-Using-head-and-tail" class="headerlink" title="6. Using head and tail"></a>6. Using head and tail</h1><p>这两个指令是用来看一个文件的头部或者尾部的部分</p><ul><li><p>-n</p><ul><li>用上述指令加想要显示的行数</li></ul></li><li><p>-c</p><ul><li><p>显示的字符的数量 </p><p>//显示grocery文件的前10行<br>$ head -n10 grocery.list</p><p>//显示grocery文件最后12的个字符<br>$ tail -c12 grocery.list</p></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Cli </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Curl tutorial</title>
      <link href="/Curl-tutorial/"/>
      <url>/Curl-tutorial/</url>
      
        <content type="html"><![CDATA[<p>curl = client url, used to make requests to web server in client side. </p><h4 id="Send-GET-request-to-the-url"><a href="#Send-GET-request-to-the-url" class="headerlink" title="Send GET request to the url"></a>Send GET request to the url</h4><pre><code>curl https://www.google.com </code></pre><h4 id="A-Define-client’s-agent-header-—-User-Agent"><a href="#A-Define-client’s-agent-header-—-User-Agent" class="headerlink" title="-A Define client’s agent header —- User-Agent"></a>-A Define client’s agent header —- <code>User-Agent</code></h4><pre><code>curl -A &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36&#39; https://google.com</code></pre><h4 id="b-pass-cookie-to-server"><a href="#b-pass-cookie-to-server" class="headerlink" title="-b pass cookie to server"></a>-b pass cookie to server</h4><pre><code>curl -b &#39;foo=bar&#39; https://www.google.com</code></pre><h4 id="d-send-the-data-body-needed-when-sending-POST-request"><a href="#d-send-the-data-body-needed-when-sending-POST-request" class="headerlink" title="-d send the data body needed when sending POST request"></a>-d send the data body needed when sending POST request</h4><pre><code>curl -d &#39;login=leilei&amp;pwd=test&#39; -X POST https://www.google.com curl -d &#39;@data.txt&#39; -X POST https://www.google.com </code></pre><h4 id="e-set-header’s-Referer"><a href="#e-set-header’s-Referer" class="headerlink" title="-e set header’s Referer"></a>-e set header’s Referer</h4><pre><code>curl -e &#39;https://google.com?q=example&#39; https://www.example.com</code></pre><h4 id="–data-urlencode"><a href="#–data-urlencode" class="headerlink" title="–data-urlencode"></a>–data-urlencode</h4><p>similar to <code>-d</code>, the difference is <strong>it could do URL encode for sent data</strong></p><pre><code>curl --data-urlencode &#39;comment=hello world&#39; https://google.com/login</code></pre><h4 id="F-send-binary-file-to-server"><a href="#F-send-binary-file-to-server" class="headerlink" title="-F  send binary file to server"></a>-F  send binary file to server</h4><pre><code>curl -F &#39;file=@photo.png;type=image/png&#39; https://google.com/profile</code></pre><h4 id="G-create-the-search-string-needed"><a href="#G-create-the-search-string-needed" class="headerlink" title="-G create the search string needed"></a>-G create the search string needed</h4><pre><code>curl -G -d &#39;q=kitties&#39; -d &#39;count=20&#39; https://google.com/search</code></pre><h4 id="H-Add-HTTP-header"><a href="#H-Add-HTTP-header" class="headerlink" title="-H Add HTTP header"></a>-H Add HTTP header</h4><pre><code>curl -H &#39;Accept-Language: en-US&#39; https://google.com</code></pre><h4 id="–limit-reate"><a href="#–limit-reate" class="headerlink" title="–limit-reate"></a>–limit-reate</h4><p>Limit the speed, simulate env with low speed internet </p><pre><code>curl --limit-rate 200k https://google.com</code></pre><h4 id="u-set-username-and-pwd-for-server-authentication"><a href="#u-set-username-and-pwd-for-server-authentication" class="headerlink" title="-u set username and pwd for server authentication"></a>-u set username and pwd for server authentication</h4><pre><code>curl -u &#39;bob:12345&#39; https://google.com/login</code></pre><h4 id="X-method-for-make-request"><a href="#X-method-for-make-request" class="headerlink" title="-X method for make request"></a>-X method for make request</h4><pre><code>curl -X POST https://www.example.com</code></pre><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.ruanyifeng.com/blog/2019/09/curl-reference.html" target="_blank" rel="noopener">https://www.ruanyifeng.com/blog/2019/09/curl-reference.html</a></li><li><a href="https://catonmat.net/cookbooks/curl" target="_blank" rel="noopener">https://catonmat.net/cookbooks/curl</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Curl </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何提高GPS精度</title>
      <link href="/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98GPS%E7%B2%BE%E5%BA%A6/"/>
      <url>/%E5%A6%82%E4%BD%95%E6%8F%90%E9%AB%98GPS%E7%B2%BE%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<p>这是Uber18年更的一篇文章，里面详细描述了优步的做法，如何从软件角度来提高GPS的精度。</p><h1 id="1-概览"><a href="#1-概览" class="headerlink" title="1. 概览"></a>1. 概览</h1><p>定位和导航所使用的全球定位系统(GPS)已然深深嵌入进了我们的生活当中，对于Uber尤其重要。Uber需要通过GPS系统知道乘车人和司机所在的位置，还要给出如何从司机所在的位置到乘车人所在位置的导航，路径规划。为了能够带来更好的用户体验，那么位置的估计就需要尽可能的精确。</p><p>GPS从出现到现在其工作原理并没有出现太大的变化，这带来了不小的表现瓶颈。而相较于1973年的技术条件，以及当时做出的我们会何时何地使用GPS的假设，我们有足够理由去考虑基于现在的技术条件去想办法改进其精度。</p><p>尽管GPS在相对空旷的地方工作的非常不错，但是在城市里，面对高楼大厦以及高密度的人群，其误差可以高达50米。</p><p>Uber开发了一个软件来升级安卓的GPS性能，通过使用client-server架构，使用3D地图，经由GNSS API来做复杂的基于GPS数据的概率运算。</p><p>本文我们会先说明下为什么GPS在现代城市当中表现很差，而后给出一个概览 - 我们是如何通过信号处理算法来解决这个问题的。</p><h1 id="2-GPS-GNSS-背景"><a href="#2-GPS-GNSS-背景" class="headerlink" title="2. GPS/ GNSS 背景"></a>2. GPS/ GNSS 背景</h1><p>GPS是被美国政府所操作的30颗卫星，在距离地球大约2万公里的地方环绕地球。这些卫星会发出信号，而我们的手机会作为接收器接收到这些信号,比较重要的一点信息是这些卫星发出的信号里面也包含了他们的发送时间。</p><p>而接收时间和发出时间的差值乘上光速就是卫星和接受者之间的距离，成为pseudorange. 如果说二者时间是同步的话，信号的传输是直线的话，那么这就会是二者之间的实际直线距离。但是在现实生活中，二者的时间往往不是同步的，因此接受者需要解决四个unknown。他自己的3d坐标以及时间差。对于四个变量，那我们就需要有四个卫星发出的信号来解决这个问题了。</p><p>在实际生活中，我们往往会用更多的卫星来计算，这样来使结果更鲁棒。</p><h1 id="3-为什么在城市环境中定位变得不够准确？"><a href="#3-为什么在城市环境中定位变得不够准确？" class="headerlink" title="3. 为什么在城市环境中定位变得不够准确？"></a>3. 为什么在城市环境中定位变得不够准确？</h1><p>基于GNSS定位的一大假设就是接收人是可以直面每个卫星的，即是直线，然后我们通过直线来接收信号，处理，做出定位。但是在城市当中，很容易因为镜面的反射等原因，我们的手机依旧能接到卫星发出的信号，但是是经由反射，因此时间差要比实际的要大。这种现象导致了在城市区域误差可能达到50米的程度。</p><h1 id="4-优化"><a href="#4-优化" class="headerlink" title="4. 优化"></a>4. 优化</h1><p>我们的方法利用了GNSS信号易被阻碍的特性。对于安卓手机来说，LocationManager API不仅提供了手机位置的估计，也提供了对于每个卫星针对当前位置的信噪比。如果我们使用这个信号强度的信息，加入到3D地图当中，那么我们就能得到很有价值的地点信息了。如果信噪值比较低，那很有可能当前卫星被阻挡了；相反的，就证明当前位置尚佳。这是基本的原理，但是还有些问题，比如有些时候，即便是没有被高楼阻挡，但是你站在遮挡物下边，也会对信号造成影响。另外，3D地图本身的精确度也存疑，更别提我们无法辨别当前数据是否受到随机的大型移动物体的影响。这也给整个过程增加了不确定性。</p><p>为了解决此类问题，Uber使用了概率模型，对于接收者可能在的任何位置，我们会用3D地图来检查，是否从接收者到卫星的信号会被物体阻挡。通过这种方式我们可以计算得到获得的信噪比信息的可信程度。然后通过一系列地点的对比，我们就能获得一张热力图，反映了用户最可能在的地方。</p><p>这张局部热点图经常会有多个局部最优解，这个时候我们就要借助手机本身的基于wifi的定位功能了。</p><p>基本上Uber就是通过上述的方式来做优化，使之能拿到更准确的定位结果的。</p><p><a href="https://eng.uber.com/rethinking-gps/" target="_blank" rel="noopener">https://eng.uber.com/rethinking-gps/</a> </p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GPS </tag>
            
            <tag> Uber </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Google搜索技巧</title>
      <link href="/Google%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7/"/>
      <url>/Google%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="1-使用-tabs"><a href="#1-使用-tabs" class="headerlink" title="1. 使用 tabs"></a>1. 使用 tabs</h2><p>在google的搜索栏下方是有分类的，使用特定的分类可以给我们更好的结果</p><h2 id="2-使用双引号"><a href="#2-使用双引号" class="headerlink" title="2. 使用双引号"></a>2. 使用双引号</h2><p>双引号内的词语会成为一个特定的搜索词语，比如你搜索”Hello World”， 没有双引号的话goole会搜索包含这两个词语的link，但是有了双引号就会搜索按照这样的顺序，并且是连在一起的出现的link。</p><h2 id="3-使用连字符去排除关键字"><a href="#3-使用连字符去排除关键字" class="headerlink" title="3. 使用连字符去排除关键字"></a>3. 使用连字符去排除关键字</h2><p>比如搜索mustang -cars 表示希望搜真的马，不能包括车这个关键字</p><h2 id="4-使用冒号去搜索特定的网站"><a href="#4-使用冒号去搜索特定的网站" class="headerlink" title="4. 使用冒号去搜索特定的网站"></a>4. 使用冒号去搜索特定的网站</h2><pre><code>leileichen site:llchen60.com</code></pre><p>表示只在llchen60.com这个网址搜索leileichen这个关键字</p><h2 id="5-找到一个link到其他页面的页面"><a href="#5-找到一个link到其他页面的页面" class="headerlink" title="5. 找到一个link到其他页面的页面"></a>5. 找到一个link到其他页面的页面</h2><p>用来找到谁引用了这个页面</p><pre><code>link:llchen60.com</code></pre><p>来找到那些引用了这个网址的页面们</p><h2 id="6-使用星号通配符"><a href="#6-使用星号通配符" class="headerlink" title="6. 使用星号通配符"></a>6. 使用星号通配符</h2><pre><code>来自*的你</code></pre><p>google会帮你找到符合上述通配符的词条/ 页面。</p><h2 id="7-找到与一个网站相似的网站"><a href="#7-找到与一个网站相似的网站" class="headerlink" title="7. 找到与一个网站相似的网站"></a>7. 找到与一个网站相似的网站</h2><pre><code>related:llchen60.com</code></pre><p>找到和这个网站类似的网站们 </p><h2 id="8-同时寻找多个关键词"><a href="#8-同时寻找多个关键词" class="headerlink" title="8. 同时寻找多个关键词"></a>8. 同时寻找多个关键词</h2><pre><code>“first word&quot; OR &quot;second word&quot;</code></pre><h2 id="9-搜索一系列的数据"><a href="#9-搜索一系列的数据" class="headerlink" title="9. 搜索一系列的数据"></a>9. 搜索一系列的数据</h2><pre><code>nba championship ..2008nba chanpionship 2006..2008</code></pre><p>第一个是只搜索2008年的nba冠军，第二个是搜索2006到2008年的nba冠军</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.lifehack.org/articles/technology/20-tips-use-google-search-efficiently.html" target="_blank" rel="noopener">https://www.lifehack.org/articles/technology/20-tips-use-google-search-efficiently.html</a></p>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Tips </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>硅谷增长黑客实战笔记</title>
      <link href="/%E7%A1%85%E8%B0%B7%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/"/>
      <url>/%E7%A1%85%E8%B0%B7%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-增长黑客的理念"><a href="#1-增长黑客的理念" class="headerlink" title="1. 增长黑客的理念"></a>1. 增长黑客的理念</h1><h2 id="1-1-基本的定义"><a href="#1-1-基本的定义" class="headerlink" title="1.1 基本的定义"></a>1.1 基本的定义</h2><p>需求在于：需要一个新的市场营销的角色，要有企业家的精神，有强大的内在动力能挑起增长的责任，迫不及待想将产品推广给更多客户；创造性尝试新方法，对新技术充满好奇；应用数据需要得心应手，通过数据分析来寻找好的想法，并且按照科学实验的方法论，对这些想法进行测试。</p><p>需要增长团队，让企业快速增长 – growth hacking </p><h2 id="1-2-What-does-a-growth-manager-do"><a href="#1-2-What-does-a-growth-manager-do" class="headerlink" title="1.2 What does a growth manager do?"></a>1.2 What does a growth manager do?</h2><p>负责：</p><ul><li>搭建数据基础设施</li><li>定义增长目标</li><li>提供用户洞察</li><li>排序增长项目</li><li>设计并上线实验</li></ul><p>growth manager需要将原先各自为政的产品开发和营销职能有机整合起来。</p><p>传统的产品经理负责产品的开发流程，更多的是以解决方案为导向；而增长产品经理，虽然遵循类似的流程，但是出发点是增长—-即通过用户行为的改变，来推动某个业务指标的增长。</p><blockquote><p>增长产品经理，就是处在产品和营销的交界点上，负责用产品的手段达到营销的目的。 </p></blockquote><h2 id="1-3-Pirate-Metrics"><a href="#1-3-Pirate-Metrics" class="headerlink" title="1.3 Pirate Metrics"></a>1.3 Pirate Metrics</h2><ul><li>Acquisition: 用户获取</li><li>Activation: 用户激活</li><li>Retention: 用户留存</li><li>Refereal: 用户推荐</li><li>Revenue: 盈利</li><li>Resurrection: 挽回流失客户</li></ul><p>可以看出增长黑客在关注一个用户生命周期的各个环节。</p><h1 id="2-增长方法论"><a href="#2-增长方法论" class="headerlink" title="2. 增长方法论"></a>2. 增长方法论</h1><h2 id="2-1-增长实验"><a href="#2-1-增长实验" class="headerlink" title="2.1 增长实验"></a>2.1 增长实验</h2><p>就是实验，针对一个目标，产生一个实验假设，设计实验，分析结果，看看假设是对是错。</p><p>增长方法论的精髓就是<strong><em>按照科学实验的原则，尽量准确的设计实验和测量结果，从而建立起一个“开发-测试-学习”的反馈闭环</em></strong></p><blockquote><p>假设 -&gt; 开发 -&gt; 测试 -&gt; 测量 -&gt; 数据 -&gt; 学习 -&gt; 假设</p></blockquote><p>这里的实验指的是A/ B测试</p><p>要不停的在线做AB测试，知道什么样的方式会更加有利于公司的发展。</p><h2 id="2-2-增长流程"><a href="#2-2-增长流程" class="headerlink" title="2.2 增长流程"></a>2.2 增长流程</h2><p>增长关注的范围很广，但应该有的放矢，要有策略有重点地按流程进行。</p><p>给出增长目标，聚焦增长领域，产生想法，想法执行顺序，实验，结果，反馈，调整与优化，产生良性循环。</p><p>任何事情都是一个实验，通过它，你或者实现增长，或者学到经验。</p><h2 id="2-3-面对的挑战"><a href="#2-3-面对的挑战" class="headerlink" title="2.3 面对的挑战"></a>2.3 面对的挑战</h2><ol><li>在低垂的果实被慢慢摘掉以后，如何持续保证产生好的实验结果，驱动增长指标呢？</li><li>面对激烈的竞争和变化的环境，如何离用户更近、如何持续创新让增长实验成为产品的竞争优势？</li><li>如何保证增长流程高效运作、增长团队内部紧密合作，有主人翁的感觉？</li><li>如何确保和其他团队以及管理层的良好沟通和合作，得到大家的支持，达成共赢？ </li><li>如何让增长实验和数据驱动成为公司文化的一部分呢？ </li></ol><h1 id="3-用户获取，推荐，激活，留存等不同阶段的增长技巧"><a href="#3-用户获取，推荐，激活，留存等不同阶段的增长技巧" class="headerlink" title="3. 用户获取，推荐，激活，留存等不同阶段的增长技巧"></a>3. 用户获取，推荐，激活，留存等不同阶段的增长技巧</h1><h2 id="3-1-用户获取"><a href="#3-1-用户获取" class="headerlink" title="3.1 用户获取"></a>3.1 用户获取</h2><p>Flikr 和 instagram -&gt; 真正独特的点子是很少见的</p><p>如今一款产品能否成功越来越少依靠让人耳目一新的功能，而是越来越多地依靠成功的增长策略。</p><h3 id="3-1-1-新用户获取的永恒公式-LTV-gt-CAC"><a href="#3-1-1-新用户获取的永恒公式-LTV-gt-CAC" class="headerlink" title="3.1.1 新用户获取的永恒公式  LTV &gt; CAC"></a>3.1.1 新用户获取的永恒公式  LTV &gt; CAC</h3><p>Life Time Value &gt; Customer Acquisition Cost （获取用户的成本）</p><p>一般来说希望比例能够大于3.</p><p>CAC = （营销总费用 + 销售总费用）、同时期新增用户数</p><h3 id="3-1-2-用户获取过程中的术语"><a href="#3-1-2-用户获取过程中的术语" class="headerlink" title="3.1.2 用户获取过程中的术语"></a>3.1.2 用户获取过程中的术语</h3><ol><li>混合CAC(Blended CAC) - 将付费渠道和天然渠道混在一起计算的CAC</li><li>付费CAC - 付费渠道的平均顾客获取成本  这个数值代表了你可以控制的渠道效率，可以理解为如果风险投资给你钱，在一段时间内就可以通过加大投入而持续以这个成本获取新用户。</li><li>满载CAC - 加上所有市场和销售相关人员的薪酬，工具，设备等花费而计算出来的用户获取成本。</li></ol><h3 id="3-1-3-如何计算用户生命周期的价值"><a href="#3-1-3-如何计算用户生命周期的价值" class="headerlink" title="3.1.3 如何计算用户生命周期的价值"></a>3.1.3 如何计算用户生命周期的价值</h3><p>基本思路： </p><ol><li>用户会使用多少个月</li><li>平均每个月你能从用户身上赚多少钱</li></ol><p>对于有高LTV的产品才会去请销售团队，对于LTV很小的，更多是需要进行病毒传播这样子。</p><p>一个产品想要做大，仅仅有产品市场的契合是不够的，而是需要市场、产品、模型、渠道四者之间的契合。</p><ul><li>市场-产品契合： 有一个目标客户群存在，对这样一个产品有需要。</li><li>产品-渠道契合： 能够在特定的渠道商找到该产品的目标客户群</li><li>渠道-模型契合： 产品的盈利模型和用户生命周期价值能够支持使用这些渠道的成本</li><li>模型-市场契合： 目标客户群愿意为这个产品肤浅，支持产品的盈利模型。</li></ul><h2 id="3-2-如何选择用户获取渠道？"><a href="#3-2-如何选择用户获取渠道？" class="headerlink" title="3.2 如何选择用户获取渠道？"></a>3.2 如何选择用户获取渠道？</h2><h3 id="3-2-1-了解产品特点"><a href="#3-2-1-了解产品特点" class="headerlink" title="3.2.1 了解产品特点"></a>3.2.1 了解产品特点</h3><ul><li>面向对象： 消费者，中小型企业，大型企业</li><li>产品形态： 移动应用，SaaS软件，硬件产品</li><li>所在行业： 社交、游戏、社群、金融</li><li>盈利模式： 免费、广告、月费、产品内购买</li><li>单位经济学： 用户平均生命周期价值</li></ul><p>对于大部分产品来说，真正能做大的一般是一到两个渠道，病毒传播并不适合所有的产品。</p><p>比如微信，没有使用门槛，免费，没有使用门槛，用户很快能得到价值，并且大家都需要。最重要的是用户使用之后，有动力来邀请他的亲朋好友来使用，使用的人越多，对产品的用户体验提升越多，这就是网络效应。</p><h3 id="3-2-2-了解用户群体"><a href="#3-2-2-了解用户群体" class="headerlink" title="3.2.2 了解用户群体"></a>3.2.2 了解用户群体</h3><ul><li>怎么样的人</li><li>生活节奏</li><li>什么时间做什么样的事情</li><li>喜欢用什么产品</li><li>去什么地方消费</li><li>有哪些兴趣</li><li>关注哪些名人</li></ul><h3 id="3-2-3-列出可能的备选渠道"><a href="#3-2-3-列出可能的备选渠道" class="headerlink" title="3.2.3 列出可能的备选渠道"></a>3.2.3 列出可能的备选渠道</h3><ul><li>付费渠道：通过付费广告获取用户的渠道</li><li>有机渠道：不需要直接花广告费用的获客渠道</li><li>其他渠道</li></ul><p>在当下的北美，能做到大体量的渠道有：</p><ul><li>付费增长<ul><li>facebook</li><li>instagram</li><li>google adwords购买关键字广告</li></ul></li><li>病毒传播<ul><li>产品本身有社交属性</li><li>功能涉及多人合作或共享的</li><li>hotmail/ dropbox/ slack</li></ul></li><li>搜索引擎优化<ul><li>产品能创造很多内容</li><li>将搜索引擎优化作为主要渠道</li></ul></li><li>销售<ul><li>人工宣讲，展示</li><li>建立一个重复的销售流程</li><li>招募销售团队并设计一套体系</li></ul></li></ul><p>为什么这几个渠道能做大呢？ </p><ol><li>都是反馈闭环，当你通过这些渠道获取了用户从用户身上赚到钱，都可以再进行投入的。</li><li>体量足够大。各大社交网络对用户免费，用户基数很大</li></ol><h3 id="3-2-4-筛选最初的获取渠道"><a href="#3-2-4-筛选最初的获取渠道" class="headerlink" title="3.2.4 筛选最初的获取渠道"></a>3.2.4 筛选最初的获取渠道</h3><ul><li>大体量的渠道优先</li><li>免费或便宜的渠道优先</li><li>可追踪的渠道优先</li><li>可以精准定位目标用户群的渠道</li><li>可以随时开始、随时结束的渠道优先</li></ul><p>需要了解各个渠道的特点，开始最初测试，然后追踪和分析结果，测试时需要观察以下两个指标：</p><ol><li>哪个渠道用户获取成本最低</li><li>哪个渠道获取的用户留存时间最长，LTV最高</li></ol><p>可以通过激活比例和付费比例来进行模拟</p><h3 id="3-2-5-运营、优化、拓展用户获取渠道"><a href="#3-2-5-运营、优化、拓展用户获取渠道" class="headerlink" title="3.2.5 运营、优化、拓展用户获取渠道"></a>3.2.5 运营、优化、拓展用户获取渠道</h3><p>在找到了最初的用户获取渠道以后，需要做：</p><ul><li>制定新用户获取目标</li><li>决定市场预算的分配和进行渠道的日常运营</li><li>通过广告设计测试和用户定位测试，优化已有渠道的表现</li><li>不断发现和探索新的渠道</li></ul><p>需要持续追踪已有渠道的成本，不断调整，测试并加入新的渠道</p><blockquote><p>过于依赖某个单一渠道是有风险的，一旦建立了一两个核心渠道，还需要主动尝试新的渠道。</p></blockquote><h2 id="3-3-最棒的获取渠道-用户推荐"><a href="#3-3-最棒的获取渠道-用户推荐" class="headerlink" title="3.3 最棒的获取渠道 - 用户推荐"></a>3.3 最棒的获取渠道 - 用户推荐</h2><p>用户推荐这个渠道十分受欢迎，原因为：</p><ol><li>获取成本低：老用户帮你带来新的用户</li><li>用户质量好：背景会和已有用户类似，因此更有可能成为你的产品的目标用户</li><li>转化比例高： 有好友推荐的信用背书</li></ol><h3 id="3-3-1-用户推荐的三个概念"><a href="#3-3-1-用户推荐的三个概念" class="headerlink" title="3.3.1 用户推荐的三个概念"></a>3.3.1 用户推荐的三个概念</h3><ul><li>用户推荐</li><li>病毒传播</li><li>网络效应 - 越多的用户，产品/服务更加完善，老用户得到的价值也提升了</li></ul><h3 id="3-3-2-用户推荐的类型"><a href="#3-3-2-用户推荐的类型" class="headerlink" title="3.3.2 用户推荐的类型"></a>3.3.2 用户推荐的类型</h3><ul><li>口口相传</li><li>展示相传</li><li>补贴推荐 - 双向补贴推荐 - 送产品功能比送钱好</li><li>社交网络用户推荐</li><li>病毒传播  有趣新颖 具有视觉感染力 容易分享的东西</li><li>产品内传播机制<ul><li>产品需求 - 功能本身是否需要用户邀请其他用户</li><li>内容分享 - 知乎，网易云音乐，喜马拉雅</li><li>人为制造 </li><li>欢乐时刻，最嗨的时候让用户分享</li><li>顺便接触 - 加水印，加一句话之类的</li></ul></li></ul><p>最成功的产品不是在上市之后才考虑增长的，而是在打磨产品的同时就开始设计和实验产品内病毒传播、用户推荐和网络效应的种种机制。</p><h3 id="3-3-3-衡量用户推荐的公式"><a href="#3-3-3-衡量用户推荐的公式" class="headerlink" title="3.3.3 衡量用户推荐的公式"></a>3.3.3 衡量用户推荐的公式</h3><p>K因子，就是看平均每个老用户可以带来几个新用户。如果K因子大于1，那么理论上这个产品就不需要再去人为推动增长了。</p><p>用户推荐共识</p><ul><li>通过邀请加入的新用户数 = <ul><li>潜在的推荐人总数 x<ul><li>总活跃用户基数</li><li>接触到邀请机会的比例</li></ul></li><li>推荐人转化率 x</li><li>分支因子 x</li><li>被推荐人转化率</li></ul></li></ul><p>新用户总数 = 总活跃用户基数 x 接触到邀请机会的比例 x 邀请机会页面的转化率 x 平均每人发出的邀请数量 x 被推荐人接受邀请的比例 x 接受邀请后完成注册的比例</p><p>这里面有多个转化漏斗，需要做针对性的分析，看瓶颈在哪里。</p><h2 id="3-4-用户激活：增长的关键转化点"><a href="#3-4-用户激活：增长的关键转化点" class="headerlink" title="3.4 用户激活：增长的关键转化点"></a>3.4 用户激活：增长的关键转化点</h2><p>一个公司应该花至少和新产品开发一样多的精力在新用户体验上，甚至更多。</p><p>新用户激活包含从新用户首次登录、完成账户注册和必要的设置到第一次使用产品关键功能的这段过程。因为它处于市场和产品之间，有点像两不管地带，很容易被忽略掉。</p><p>数据显示，大部分应用会在三天内流失掉超过75%的用户。</p><h3 id="3-4-1-如何定义用户激活"><a href="#3-4-1-如何定义用户激活" class="headerlink" title="3.4.1 如何定义用户激活"></a>3.4.1 如何定义用户激活</h3><p>Aha时刻，用户认识到这个产品的作用的那一时刻，通过认识到作用才会有可能留存下来的。没有经历这种时刻的用户，会流失掉的。</p><p>对于公司来说，定义用户激活，需要这样子来进行描述：<strong><em>谁在多长时间内完成了多少次的什么行为</em></strong></p><ul><li>定义一个关键行为</li><li>要找到这个关键行为的完成者</li><li>时间限度，以及完成次数的限定</li></ul><h3 id="3-4-2-理解关键行为"><a href="#3-4-2-理解关键行为" class="headerlink" title="3.4.2 理解关键行为"></a>3.4.2 理解关键行为</h3><p>关键行为：指让新用户通过采取某个特定行为迅速了解到产品的价值所在，到达Aha时刻。 </p><ul><li>列出可能的关键行为</li><li>通过数据分析筛选关键行为<ul><li>找到和长期用户存在正相关最强的行为</li></ul></li><li>通过定性用户调研进一步确定关键行为</li></ul><h3 id="3-4-3-衡量用户激活的常用指标和图表"><a href="#3-4-3-衡量用户激活的常用指标和图表" class="headerlink" title="3.4.3 衡量用户激活的常用指标和图表"></a>3.4.3 衡量用户激活的常用指标和图表</h3><ol><li>激活率 - 新用户在一定时间以内完成激活行为的比例。</li><li>激活漏斗转化率 - 追踪新用户注册和激活的全过程，看用户完成每一个步骤占进入这个步骤总人数的比例。</li><li>新用户留存指标 - 新用户经过一个月以后，还是否是活跃用户</li></ol><h3 id="3-4-4-激动指数模型"><a href="#3-4-4-激动指数模型" class="headerlink" title="3.4.4 激动指数模型"></a>3.4.4 激动指数模型</h3><p>代表用户有多大动力在某个时刻完成某件事情。新用户激活的过程就是在激动指数降为0之前完成整个过程，体会到产品的价值。</p><ol><li>要明确用户的初始激动指数  大公司or小公司？ 渠道？ </li><li>了解各个元素对激动指数的影响</li></ol><h3 id="3-4-5-新用户引导的原则"><a href="#3-4-5-新用户引导的原则" class="headerlink" title="3.4.5 新用户引导的原则"></a>3.4.5 新用户引导的原则</h3><ul><li>增强动力<ul><li>保持外部广告和新用户欢迎页面的前后一致性</li><li>向用户解释为什么要各种权限，而不是上来直接就要</li><li>利用社会信任，</li><li>让用户参与其中，完成一个引导互动的流程</li></ul></li><li>减少障碍<ul><li>推迟注册步骤，让用户先使用产品</li><li>移除多余步骤，隐藏过多信息</li><li>避免冷启动，预加载</li></ul></li><li>适时助推<ul><li>明确机会窗口  明确在哪个阶段需要给助力</li><li>灵活采用各种UX模式进行用户引导</li><li>利用邮件或移动推送等外部形式提醒用户完成了新用户的激活</li></ul></li><li>私人订制<ul><li>让用户自己选择兴趣和偏好</li><li>根据用户消费历史推荐</li><li>根据用户目的给予不同的引导</li><li>根据用户不同的群组给予不同的引导</li></ul></li></ul><p>注意避免： </p><ul><li>步骤太多，流程太长</li><li>没有聚焦到关键行为，想让新用户做的事情太多了</li><li>花太多时间教用户如何用界面，而没有让用户使用产品</li><li>太快完成设置，没有足够教育</li><li>注册太顺利，没有足够的障碍筛选掉不合格的用户</li><li>对每个用户都统一对待</li></ul><h3 id="3-4-6-新用户激活-系统工程"><a href="#3-4-6-新用户激活-系统工程" class="headerlink" title="3.4.6 新用户激活 - 系统工程"></a>3.4.6 新用户激活 - 系统工程</h3><p>新用户激活是整个增长过程中难度最大的，成功的用户激活需要</p><ul><li>帮助用户完成基本的账户设置</li><li>让用户对产品有一定的了解</li><li>让用户完成和长期留存息息相关的关键行为</li><li>令用户感受到产品的价值</li><li>需要新用户在有限时间内，在认识、体验、行动和情感四个方面都完成一次升级，变成产品的使用者</li></ul><p>新用户整个激活过程需要专门的团队，做专门的事情：</p><ul><li>多个团队<ul><li>产品，市场，增长，客户成功，销售，设计，工程人员</li></ul></li><li>新用户激活需要多个渠道配合<ul><li>广告</li><li>产品内新用户的引导</li><li>邮件推送</li><li>社交网络</li><li>公关</li><li>活动</li></ul></li><li>延长定义新用户激活的时间段</li></ul><h2 id="3-5-用户留存：增长的坚实根基"><a href="#3-5-用户留存：增长的坚实根基" class="headerlink" title="3.5 用户留存：增长的坚实根基"></a>3.5 用户留存：增长的坚实根基</h2><p>用户留存的影响：</p><ul><li>好留存会使用户付费周期变长，用户生命周期价值LTV升高</li><li>好留存可以使团队有预算测试更多，更贵的增长渠道</li><li>好留存能带来更多忠实的老用户，可以推荐更多新用户</li><li>强大之处在于其复利效应</li></ul><h3 id="3-5-1-定义留存"><a href="#3-5-1-定义留存" class="headerlink" title="3.5.1 定义留存"></a>3.5.1 定义留存</h3><p>如何定义留存：</p><ul><li>计算同一用户群不同时间的留存率(retension rate)</li><li>或者叫同期群分析</li><li>将同一时间加入的用户放在一起，横向追踪在接下来几个月，一年的时间里，是不是还持续使用这个产品，流失比例</li></ul><h3 id="3-5-2-留存的关键行为"><a href="#3-5-2-留存的关键行为" class="headerlink" title="3.5.2 留存的关键行为"></a>3.5.2 留存的关键行为</h3><ul><li>一定时间以后返回网站？ <ul><li>基于用户登录行为</li><li>要看产品特征，比如对于在线游戏，就很够；对于其他的，可能不够了</li></ul></li><li>用户留存应当和用户的关键行为挂钩</li><li>找到属于产品的天然使用周期<ul><li>上网找这个分类下的拳头产品的指标</li></ul></li><li>记录流程<ul><li>记录每一周首次完成关键行为的用户数，也就是激活用户数</li><li>追踪这些用户在接下来的每一周里继续完成关键行为的数量</li><li>通过1，2步，计算每一周有关键行为的用户占首周激活用户数的百分比</li></ul></li></ul><h3 id="3-5-3-分析留存曲线"><a href="#3-5-3-分析留存曲线" class="headerlink" title="3.5.3 分析留存曲线"></a>3.5.3 分析留存曲线</h3><p>从留存曲线上，可以看出：</p><ul><li>从不同时期的起始同期群的大小可以看到用户数的增长速度</li><li>从用户完成关键行为的比例可以看到用户对产品的参与度</li><li>从不同时期的同期群曲线可以看到用户的留存率是否有改善</li></ul><h3 id="3-5-4-留存的不同阶段"><a href="#3-5-4-留存的不同阶段" class="headerlink" title="3.5.4 留存的不同阶段"></a>3.5.4 留存的不同阶段</h3><ul><li>新用户激活阶段<ul><li>注册</li><li>激活</li><li>整体新用户体验</li></ul></li><li>中期留存阶段<ul><li>指用户完成了首次关键行为之后继续熟悉产品，发现更多价值</li></ul></li><li>长期留存阶段<ul><li>主要目标是让用户经常回来使用产品，感受到产品的核心价值</li></ul></li><li>流失用户阶段<ul><li>针对已经流失的用户，让用户重新发现产品价值，唤回用户</li></ul></li></ul><h3 id="3-5-5-用户分组"><a href="#3-5-5-用户分组" class="headerlink" title="3.5.5 用户分组"></a>3.5.5 用户分组</h3><ul><li>分组并对比不同群组的留存曲线</li><li>比较不同流量来源的用户留存曲线</li><li>比较不同用户特征的用户留存曲线</li><li>不同产品客户端</li><li>最好按照行为来进行划分</li></ul><h3 id="3-5-6-留存与长期留存（用户参与）"><a href="#3-5-6-留存与长期留存（用户参与）" class="headerlink" title="3.5.6 留存与长期留存（用户参与）"></a>3.5.6 留存与长期留存（用户参与）</h3><ul><li>用户留存率指过了一定时间后，有多少用户仍然在产品内进行关键行为</li><li>用户参与度指在一定时间内，用户平均有几个关键行为和有多少用户同时有超过一种以上的关键行为</li></ul><ul><li><p>按照用户参与度对用户进行分类</p><ul><li>消极用户 90%<ul><li>没有按照最理想的方式使用产品，但会按照自己的方式以比较正常的频率持续使用产品</li></ul></li><li>核心用户 9%<ul><li>以比较正常的频率和正确的方式使用产品，是活跃用户里的大多数</li></ul></li><li>超级用户 1%<ul><li>包括各种进阶功能 </li></ul></li></ul></li><li><p>留存模型</p><ul><li>增加参与用户数</li><li>长期留住用户</li><li>自我持续</li></ul></li><li><p>即要有好产品给用户带来价值</p></li><li><p>产品要能对用户的行为产生影响</p></li><li><p>反过来用户的行为也成为产品体验的一部分</p></li></ul><h3 id="3-5-7-完成关键行为：-BJ-Fogg的行为模型"><a href="#3-5-7-完成关键行为：-BJ-Fogg的行为模型" class="headerlink" title="3.5.7 完成关键行为： BJ Fogg的行为模型"></a>3.5.7 完成关键行为： BJ Fogg的行为模型</h3><p>B = MAT </p><p>行为的发生与否受到动力，能力，和触发的三个因素的影响。</p><ul><li>行为： 想让用户采取的行动</li><li>动力： 用户有多想完成这个行为</li><li>能力： 这个行为对用户来说有多容易</li><li>触发： 提醒用户采取行动</li></ul><h3 id="3-5-8-让用户养成习惯"><a href="#3-5-8-让用户养成习惯" class="headerlink" title="3.5.8 让用户养成习惯"></a>3.5.8 让用户养成习惯</h3><p>—–&gt;  《上瘾：让用户养成使用习惯的四大产品逻辑》</p><ul><li>给用户的单次行为提供奖励，并且这个奖励应当是不固定的</li><li>要求用户在产品当中投入一点努力，而这一点努力可以增加用户在产品里储藏的价值</li><li>要让外在的触发和用户的内在触发相结合</li><li>打造一个参与闭环，让用户的一个行为可以带来更多的行为</li></ul><h3 id="3-5-9-参与闭环：让行为带来更多的行为"><a href="#3-5-9-参与闭环：让行为带来更多的行为" class="headerlink" title="3.5.9 参与闭环：让行为带来更多的行为"></a>3.5.9 参与闭环：让行为带来更多的行为</h3><ul><li>参与闭环： 能够将行为放大的良性循环，一个行为可以带来另外一个行为，从而使得每个行为的价值都得到提升</li><li>通过产品设计让用户参与闭环，让每次行为都被放大，带来更多的行为，从而加深对产品的参与度。</li><li>从产品角度来说，要找到有效的钩子，通过有效触发让用户完成行为 </li><li>从用户角度看，产品的设计要和用户的内在动力相一致，并在用户行动后给予反馈和奖励，从而激励用户进行下一步行动。</li><li>触发 -&gt; 行动 -&gt; 反馈 -&gt; 动力</li></ul><h3 id="3-5-10-提高用户留存的8种武器"><a href="#3-5-10-提高用户留存的8种武器" class="headerlink" title="3.5.10 提高用户留存的8种武器"></a>3.5.10 提高用户留存的8种武器</h3><ul><li>产品改进<ul><li>产品团队往往更专注于开发和上线新的功能，往往会忽略如何让更多的用户在产品已有功能上得到更多的价值</li><li>增长团队的努力方向<ul><li>优化新用户引导</li><li>改善用户使用体验</li><li>加入持续引导机制</li><li>帮助用户形成使用习惯</li></ul></li></ul></li><li>新用户引导和教育</li><li>邮件</li><li>通知<ul><li>产品内信息的使用，忌信息轰炸<ul><li>推广新功能，新内容或者提高已有功能使用度</li><li>对时间敏感的信息</li><li>给用户提供信息，和用户互动，对话</li></ul></li></ul></li><li>推送<ul><li>RRF模型<ul><li>覆盖面 Reach<ul><li>由移动推送的触发情景和适用用户群决定 </li></ul></li><li>相关性 Relevance<ul><li>移动推送到达的及时性和内容的个人化 </li></ul></li><li>频率 Frequency <ul><li>触发推送的情景的发生频率</li></ul></li></ul></li><li>测试过程<ul><li>检测负面的影响，如用户取消推送权限的比率和应用卸载率</li><li>小比例用户测试</li><li>只有在最紧急的时候适用震动</li><li>在计划移动推送时，考虑用户的日常生活节奏</li><li>在文案中适用多种多样的个性化语言</li><li>通过深度链接让用户直接到达应用内指定的页面</li><li>不断测试，不断优化</li></ul></li></ul></li><li>客户服务</li><li>促销</li><li>忠诚客户计划</li><li>新产品</li></ul><h1 id="4-增长团队与增长流程"><a href="#4-增长团队与增长流程" class="headerlink" title="4. 增长团队与增长流程"></a>4. 增长团队与增长流程</h1><p>到底如何做增长？因为增长涉及的范围非常广泛，可以尝试的方向和技巧有很多，做增长的时候很容易陷入扔飞镖的陷阱当中去，就是希望有几个会被扔到靶子上没掉下来。但是—–二八定律，任何给定时刻，对增长推动最大的事情可能只有那么一两件。</p><blockquote><p>增长成功的秘诀不在于同时做很多事，而是在于能够找到目前影响增长率最关键的一两件事。</p></blockquote><h2 id="4-1-增长作战计划书"><a href="#4-1-增长作战计划书" class="headerlink" title="4.1 增长作战计划书"></a>4.1 增长作战计划书</h2><p>以这个计划书为蓝图问问题，做假设，做测试，得出结论，步步为营，不断调整和修正你的假设，揭示增长的问题和关键所在，从而最终达到目标。这张计划书需要有：</p><h3 id="4-1-1-方向标：北极星指标"><a href="#4-1-1-方向标：北极星指标" class="headerlink" title="4.1.1 方向标：北极星指标"></a>4.1.1 方向标：北极星指标</h3><p>给出关键性的指标，e.g  facebook: 活跃用户数量 vs MySpace 注册用户数量</p><p>这个指标代表了管理层对用户价值和公司成功关系之间的理解。敢不敢秀给投资者看，敢不敢直面问题，很关键了。比如京东的删掉自营数据，完全的骗自己；包括苹果不再公布手机销售数量… </p><p>如何定义北极星指标？</p><ul><li>你的产品的核心价值是什么？这个指标能让你知道你的用户体验到了这种价值么？</li><li>这个指标能够反映用户的活跃程度么？ </li><li>如果这个指标变好了，是不是能够说明整个公司是在向好的方向发展？ </li><li>这个指标是不是很容易被整个团队理解和交流呢？ </li><li>这个指标是一个先导指标还是一个滞后指标？</li></ul><p>滞后指标，比如按月付费，但是可能有些用户就是忘了取消了<br>先导指标： 月活跃用户数</p><ul><li>这个指标是不是一个可操作的指标？ </li></ul><h3 id="4-1-2-路线图：-增长模型"><a href="#4-1-2-路线图：-增长模型" class="headerlink" title="4.1.2 路线图： 增长模型"></a>4.1.2 路线图： 增长模型</h3><p>增长模型，类似于传统的商业模型，但是其重点在于增长，用户的增长和利润的增长。</p><p>增长模型的精髓是将生意提炼和总结成一个数学公式，从而帮助你用全面、简单和结构化的方式去思考增长。</p><p><strong><em>能用一个公式来描述我们部门的生意吗？</em></strong> </p><p>通过这种方式，可以帮助团队理解过去的一些产品决策，并且确定产品的优劣势，还可以揭示一些曾经成立但现在已经过时的假设。</p><p>当团队成员在每天决策中，都可以用同样的增长模型作为标准的时候，团队的方向和优先级就会变得更加一致。</p><p>打造增长模型的方式： </p><ol><li>数学模型当中的输入变量，方程，输出变量(北极星指标)</li><li>看user journey </li><li>给用户旅程的每一步都找到一个相应的指标，然后设置追踪来弥补这个漏斗，用这些指标作为增长模型的输入变量。同时，注意将各个输入变量不断分解到最小，这样子我们就能揭示出所有对增长有影响的单个输入变量，并且将数据记录下来 </li></ol><p>其实打造整个增长模型的目的就是揭示所有影响增长的输入变量，并且用量化的方式来指导实验。通过这种方式，<strong><em>将抽象的增长分解成一个个具体的影响增长的输入变量</em></strong>。当我们把所有的输入变量都列出来以后，就会发现增长的驱动力可以来自于用户声明周期的各个阶段，而不仅仅是新用户的获取了。</p><p>通过这种方式定量预测未来的增长趋势。</p><h3 id="4-1-3-仪表盘：-关键指标看板-dashboard"><a href="#4-1-3-仪表盘：-关键指标看板-dashboard" class="headerlink" title="4.1.3 仪表盘： 关键指标看板(dashboard)"></a>4.1.3 仪表盘： 关键指标看板(dashboard)</h3><p>关键行为漏斗，一般互联网公司的数据主要分为渠道数据、盈利数据和用户行为数据。用户行为数据由于其可操作性强，是增长团队找到机会的金矿。</p><p>事件Event用于描述用户的行为，一般是在网站、应用界面中发生的。</p><p>采取分级分步的方法，先定义出最重要的少数几个事件进行追踪。然后再做其次重要的时间，这样的好处是循序渐进，很快就可以得到最重要的数据。</p><p>如果从头建立用户行为追踪计划，找到三个最重要的一级事件，应该要<strong><em>代表用户从初次接触产品到最终成功使用产品的最重要的里程碑</em></strong>。</p><p>譬如在零售网站，那么重要的里程碑式行为应该有： 产品页面浏览；产品加入购物车；产品购买成功。</p><p>构建用户行为漏斗！！！</p><p>看板数据应包括：</p><ul><li>北极星指标 数值，趋势</li><li>增长模型关键指标：头部访客量，新用户激活率，老用户留存率，盈利情况等</li><li>关键细分指标：比如与关键行为相关的指标、一些重要流程的漏斗分解等</li><li>重要用户分组：按渠道分，按新老用户分，按产品平台分等</li></ul><h3 id="4-1-4-参考书：-用户心理决策地图-定型数据"><a href="#4-1-4-参考书：-用户心理决策地图-定型数据" class="headerlink" title="4.1.4 参考书： 用户心理决策地图(定型数据)"></a>4.1.4 参考书： 用户心理决策地图(定型数据)</h3><p>做增长，数据是非常有用的武器，但是有时候容易犯这样的错误：即总是从数据的角度想问题，却忽略了每个用户都是实实在在的大活人。其实，增长团队的最高境界就是能从用户第一人称视角看问题，将产品价值迅速为用户呈上。</p><p>增长模型从公司的角度来看，量化了影响增长的每一步的关键指标，只要转化率不是100%，就仍有优化空间。但是从用户角度来看，也代表了每一个用户的决策过程。通过转化率的总和数字，我们也要认识到每一个用户<strong>动机不同，背景不同，所处状态不同，思维模式不同，因此决策的过程</strong>不同。</p><p>需要深入了解用户心理学，才能有效地驱动增长。</p><p>需要了解用户在决策的不同阶段的心理学： </p><ul><li>访问阶段</li></ul><p>要解决的问题：用户会注意到这个产品么？ </p><p>由于用户给产品的注意力很少，增长团队需要在稍纵即逝的机会里抓住用户的注意力和情感，所以重点在于通过有冲击力的设计和文案吸引用户的眼球，引起用户的共鸣。Keep - 自律给我自由</p><ul><li>转化阶段</li></ul><p>需要帮助用户做出尝试的决定。这个时候机会窗口其实还是相对短暂的，需要用<strong><em>好的设计和故事</em></strong>引起用户的情感共鸣，通过清晰的文案描述产品的好处，给用户推荐个性化的内容和产品，以及通过各种心理学的方式，例如<strong><em>稀缺性、社交证据、紧迫感</em></strong>等，增强用户尝试的动力</p><ul><li>激活阶段</li></ul><p>引导用户尽快完成各种必须的步骤，进行关键动作，体验产品的核心价值。“我该如何使用这个产品”—-&gt; “我得到了我想要的了么”</p><p>这个时候用户对产品的关注度达到了峰值，在决策的过程中开始更多地运用逻辑学习新产品的使用。增长团队需要关注的重点是：通过各种方式引导，简化流程，去除阻碍行动的壁垒，适时提醒没有行动的用户，以及帮助用户设立一个向高级用户进发的目标和计划。</p><ul><li>留存阶段</li></ul><p>帮助用户形成使用习惯，引导用户继续使用更多功能，并感受到进展。</p><p>帮助解决的问题是：</p><ol><li>为什么要继续使用这个产品？</li><li>该什么场景下继续使用呢？</li><li>能继续发现新的价值么？</li></ol><p>通过各种机制留住用户，庆祝进展，里程碑，适时的提醒和沟通，向用户介绍新功能等。</p><ul><li>推荐阶段</li></ul><p>帮助用户回答 —- “我现在要把这个介绍给别人吗？”</p><p>情感决策（喜欢这个东西）还是逻辑决策（分享的各种奖励）</p><ul><li>变现阶段</li></ul><p>帮助用户回答 —- “我愿意为他付钱么？值得么？” </p><h2 id="4-2-移动应用的增长框架"><a href="#4-2-移动应用的增长框架" class="headerlink" title="4.2 移动应用的增长框架"></a>4.2 移动应用的增长框架</h2><ol><li>技术是最底层的基础</li><li>分析和洞察是指导增长策略的根本</li><li>用户获取、参与和留存，以及变现是用户生命周期的三个主要阶段</li><li>具体渠道的运用跨越了用户的不同生命周期。</li></ol><p><img src="%E7%A7%BB%E5%8A%A8%E5%BA%94%E7%94%A8%E5%A2%9E%E9%95%BF%E6%A1%86%E6%9E%B6%E5%9B%BE.jpg" alt="移动应用增长框架图"></p><h2 id="4-3-组建增长团队"><a href="#4-3-组建增长团队" class="headerlink" title="4.3 组建增长团队"></a>4.3 组建增长团队</h2><h3 id="4-3-1-架构"><a href="#4-3-1-架构" class="headerlink" title="4.3.1 架构"></a>4.3.1 架构</h3><ul><li>团队负责人直接汇报给CEO</li><li>将这种独立型的增长团队架构作为内部最重要的目标</li><li>专门团队用全部时间负责增长</li><li>分开的小增长团队<ul><li>新用户获取</li><li>用户激活</li><li>用户参与度提升</li><li>流失用户唤回</li></ul></li><li>团队人员构成，全才难求，但是增长是个很复合的过程<ul><li>产品经理</li><li>分析师</li><li>用户研究师</li><li>设计师</li><li>工程师</li></ul></li><li>运作流程<ul><li>理解数据</li><li>发现机会</li><li>执行计划</li></ul></li><li>团队每半年定一个增长目标</li><li>每8周作为一个增长周期<ul><li>2周 <ul><li>分析已有数据和头脑风暴决定做什么</li><li>制定增长规划图</li></ul></li><li>6周<ul><li>做开发和执行</li></ul></li><li>汇总分析结果并决定下一步的计划</li></ul></li></ul><h3 id="4-3-2-增长，产品，营销，运营的区别和联系"><a href="#4-3-2-增长，产品，营销，运营的区别和联系" class="headerlink" title="4.3.2 增长，产品，营销，运营的区别和联系"></a>4.3.2 增长，产品，营销，运营的区别和联系</h3><ul><li><p>增长团队本质上是一个以用户和利润增长为目标的产品团队。</p><ul><li>增长团队被允许在产品内部进行优化和改动</li><li>有工程师资源支持能够达到这个目的</li></ul></li><li><p>和产品团队的不同</p><ul><li>产品团队的日常活动围绕着产品和功能的开发展开</li><li>增长团队的目标是增长，追求的是影响力和结果</li><li>产品是价值创造，而增长是在向更多的人传播价值</li><li>增长团队更偏重指标为导向，其方法论更偏向数据驱动，更注重实验，并且常要求团队明确地在商业指标和用户体验之间做权衡。</li></ul></li><li><p>增长和运营</p><ul><li>产品团队负责界定和提供长期用户价值</li><li>运营团队负责创造短期用户价值和协助产品完善长期价值<ul><li>内容运营<ul><li>关注内容的传播效果 </li></ul></li><li>用户运营<ul><li>活跃用户指标，包括用户的新增、留存、活跃、传播以及用户之间价值的良性循环 </li></ul></li><li>活动运营<ul><li>关注活动的目标达成度和效果 </li></ul></li><li>产品运营<ul><li>通过各种运营手段去拉升某个产品的特定数据 </li></ul></li></ul></li></ul></li><li><p>增长团队的核心要素</p><ul><li>跨功能的团队： 打破产品和市场之间的隔阂</li><li>利用定性和定量的数据分析深入了解用户的行为</li><li>快速做产品迭代和测试新的想法，并使用深入的分析来指导行动</li></ul></li></ul><h3 id="4-3-3-增长团队的必备元素"><a href="#4-3-3-增长团队的必备元素" class="headerlink" title="4.3.3 增长团队的必备元素"></a>4.3.3 增长团队的必备元素</h3><ul><li>前提条件：<ul><li>产品：是否已经建立了核心价值</li><li>文化：是否能够得到领导层的支持<ul><li>是能够让增长变得更可预测，但是无法保证真的可以增长 </li></ul></li><li>资源： 合理的想要的资源和工具</li><li>流程： 增长团队的运作流程  开发-衡量-学习</li><li>人才： 合适的人才</li></ul></li><li>需要满足： <ul><li>文化</li><li>人员</li><li>流程</li><li>工具</li><li>资源</li></ul></li></ul><h3 id="4-3-4-如何配置增长团队"><a href="#4-3-4-如何配置增长团队" class="headerlink" title="4.3.4 如何配置增长团队"></a>4.3.4 如何配置增长团队</h3><ul><li>基本配置<ul><li>增长产品经理<ul><li>数据驱动 </li></ul></li><li>2-3 程序员<ul><li>增长基因</li><li>A/B测试技术难度其实不高，会喜欢么？</li><li>实验代码会被浪费</li><li>有商业和产品思维</li><li>沟通能力和项目管理能力</li></ul></li><li>1 数据分析师</li><li>1 设计师<ul><li>快速上线，不需要特别精益求精 </li></ul></li><li>0-1 定性用户研究<ul><li>测试用户心理</li><li>发现交互界面中的问题</li><li>给增长实验提供方向、线索和反馈</li></ul></li><li>市场渠道专家<ul><li>搜索引擎</li><li>付费广告</li><li>病毒传播</li><li>邮件</li></ul></li></ul></li><li>在达到产品和市场契合的时候，就开始建立增长团队</li></ul><h3 id="4-3-5-增长团队的组织架构"><a href="#4-3-5-增长团队的组织架构" class="headerlink" title="4.3.5 增长团队的组织架构"></a>4.3.5 增长团队的组织架构</h3><ul><li>独立特区的模式<ul><li>好处从头建立自己的流程</li><li>有自己的文化和基因</li><li>独立的模式能够保证增长团队能够真正建立起数据导向、数据驱动的运作体系，而不是试图融入公司团队已有的运作模式当中</li><li>强有力的支持</li><li>容易各个团队之间产生矛盾</li></ul></li><li>功能主导的模式<ul><li>归属于另外一个大的功能团队，以产品团队居多 </li></ul></li><li>内部咨询师的模式<ul><li>只负责产品的某部分的功能 </li></ul></li></ul><h3 id="4-3-6-增长团队工具箱"><a href="#4-3-6-增长团队工具箱" class="headerlink" title="4.3.6 增长团队工具箱"></a>4.3.6 增长团队工具箱</h3><ul><li>数据分析</li><li>A/B 测试</li><li>渠道管理以及营销自动化</li><li>项目管理和知识分享<h1 id="5-职业路径"><a href="#5-职业路径" class="headerlink" title="5. 职业路径"></a>5. 职业路径</h1></li></ul><h1 id="6-增长计划"><a href="#6-增长计划" class="headerlink" title="6.增长计划"></a>6.增长计划</h1><h2 id="6-1-增长黑客的最初90天计划：-第一周"><a href="#6-1-增长黑客的最初90天计划：-第一周" class="headerlink" title="6.1 增长黑客的最初90天计划： 第一周"></a>6.1 增长黑客的最初90天计划： 第一周</h2><ul><li>了解增长工具箱</li></ul><p>迅速熟悉公司内部使用的各种工具：例如渠道管理工具、邮件、移动推送等CRM(客户关系)工具，用户行为追踪，数据可视化看板等数据分析工具，A/B测试工具，以及项目管理工具。记录下来任何需要填补的漏洞</p><ul><li>深入研究历史数据</li></ul><p>全面了解历史数据，比如对于一个移动应用来说，看它的下载量，注册比例，激活用户比例，长期留存率，老用户推荐比例，盈利来源等。如果没有现成的数据看板，需要从不同的源头收集各种数据，将它们放在一起来看。收集所有关键数据点，可以帮助我从大框架上了解现状、发现问题</p><ul><li>和直接经理/ CEO会谈</li></ul><p>在会议上需要确定以下几件事情：</p><ol><li>了解工作背景信息</li><li>沟通双方的工作风格</li><li>讨论增长的计划和优先级</li><li>了解如何和工程师、设计师合作，以便上线实验</li></ol><p>讨论应该在哪个方面来进行实验</p><ul><li>和团队及合作者开会</li></ul><p>因为增长天然需要跨部门的合作，除了和自己的下属会谈之外，也应该安排时间来认识合作团队，了解事情是如何运转的，处理好和同事的关系。如同新用户激活对于用户的增长很重要一样，给大家的第一印象也很重要</p><ul><li>倾听用户的声音</li></ul><p>倾听用户的声音</p><h2 id="6-2-增长黑客的最初90天计划：-第一月"><a href="#6-2-增长黑客的最初90天计划：-第一月" class="headerlink" title="6.2 增长黑客的最初90天计划： 第一月"></a>6.2 增长黑客的最初90天计划： 第一月</h2><ul><li>确定增长指标</li></ul><p>并不需要必须是日均活跃用户，这个应用是每天都会使用的么？</p><p>如何定义活跃？打开？还是一些更有价值的行为？</p><p>留存率的北极星指标：North Star Metric（OMTM），就是最重要的一个指标，要对应你的产品给用户传输的价值。</p><ul><li>找到一个聚焦领域</li></ul><p>运用收集到的所有信息，深入分析各种数据，并且和团队讨论，战略性地选择第一个聚焦领域，理想情况下，在这个领域进行实验应该是潜在影响力最大的，资源要求少，成功概率高。</p><p>关于提升留存率，不一定是要通过邮件等方式找回流式的用户，也有可能从产品中寻找机会，让用户更愿意呆在这个平台里面。</p><p>寻找杠杆：finding leverage: 需要有明确的目标，然后针对这个目标，找到所有领域当中杠杆效应最明显的地方，然后针对这个地方进行试验改进。所谓的杠杆效应，就是性价比最高的地方。—–对于改善留存率而言，杠杆效应最大的点应该是在产品领域的。</p><ul><li>上线增长实验</li></ul><p>坚持推进直到第一个实验成功上线，希望通过之前的分析和准备工作，使这个实验能带来正面的结果</p><p>可能一些小文本的改变会给转化率带来很大的提高：</p><ol><li>你愿意开通每周10美元的定期投资么？</li><li>如果你每周存入10美元，5年后仅本金就可以积累2600美元。从今天开始每周投资10美元吧！（+40%）</li><li>你知道已经有n百万用户使用定期投资功能了么？从今天开始每周投资10美元吧！（+60%）</li></ol><p>—–&gt; 将小的结果积少成多呈现出来，或者强调有很多其他人在使用这个功能，对用户的心理有着强大的影响。</p><p>如何解决程序员们的困扰？不愿意做，为什么？</p><p>突然功能的取消；文本色彩的变化，无聊…</p><p>需要尽可能地将程序员从繁琐的文本测试和小改动中解放出来，让它们去做更复杂、更有挑战性的实验。采用提前埋点的方法或者第三方测试工具里面的高级功能，其实可以很有效的解决这个问题</p><p>程序员喜欢看到自己的工作的影响力，要调动它们的积极性，需要<strong>让他们参与到产生实验假设和实验设计的整个过程中</strong>去，并且及时把结果反馈给他们</p><p>不是所有程序员都适合在增长团队当中的，如果只是追求技术深度，在增长团队显然不是最合适的，但是对于有产品思维的，喜欢看到自己的工作对用户和业务有影响的程序员来说，增长团队的工作其实更有吸引力。</p><ul><li>定期与用户交流</li></ul><p>定期交流，很多问题是A/B测试做不了，验证不了的。不管是用户问卷调查，顾客发展电话还是用户社群，需要找到一个可以定期和用户对话的途径。对用户了解得越多，就能越好地找到用户的痛点和让用户惊喜的办法，实验成功率就会越高。</p><p>还有与内部的人员的交流，因为是单独成立了一个增长团队，而这个团队很多时候都需要调用整个公司各个部门的力量来一起做东西。每周实验分享会，疯狂的A/B测试，告诉大家结果，让各个部门的人都更加了解一些。</p><p>对应的email list,share实验心得</p><p>头脑风暴讨论会</p><ul><li>弥补工具，数据，基础设施的漏洞</li></ul><p>应该明确出现了哪些问题，哪些问题更加关键，以及如何去解决</p><h2 id="6-3-增长黑客的最初90天计划：-第一季度"><a href="#6-3-增长黑客的最初90天计划：-第一季度" class="headerlink" title="6.3 增长黑客的最初90天计划： 第一季度"></a>6.3 增长黑客的最初90天计划： 第一季度</h2><ul><li>搭建增长模型</li></ul><p>从同事和团队里，以及从数据和测试当中，对驱动公司增长的因素有了进一步的了解。接下来，需要后退一步，试着把所有的信息组装在一起，提炼成一个高度概括的增长模型。</p><p>增长模型是一个解释业务里不同的变量，以及它们如何互相影响转化成增长的数学公式，能够帮助你更有效地了解业务、协调团队、设计实验和衡量结果。</p><ul><li>设立增长实验流程</li></ul><p>当上线了最初的几个实验之后，应该开始建立一个增长实验流程，这个流程包括下面两个阶段： </p><ol><li>战略制定阶段：</li></ol><p>通过审视增长模型和指标，深入的数据分析，找到一个聚焦领域，<br>2. 战术执行阶段：</p><p>针对聚焦领域，快速进行 开发-衡量-学习的迭代流程，产生备选实验想法，排列优先级，上线实验，收集数据进行分析，然后应用实验结果，把心得用到下一个实验当中。</p><ul><li>选择实验记录系统</li></ul><p>共享的表格和文档，也可以使用公司内部的已有的项目管理软件</p><p>每个实验想法都应该记录下来，设计每个实验的时候都应该有清晰的假设和计划，每个结果都应该有分析，并存档。所有这些信息都应该存储在一个共享的系统当中作为历史记录，同时供现在的和未来的团队使用和学习</p><ul><li>组织增长会议</li></ul><p>可以省掉一些沟通成本，但是必要的会议也是需要的。从每周召开增长团队例会开始，帮助沟通增长目标，管理增长流程，促进团队成员间的交流，增强他们的参与感。在这个会议上，可以监测指标进展，回顾增长实验的上线情况，分析讨论结果等。其他可能有用的会议，可以视组里情况进行取舍： </p><ol><li>每日增长团队站立会议</li><li>每周增长细分团队间实验结果交流会议</li><li>每两周管理层交流会议</li><li>每月全公司想法收集午餐会</li><li>不定期设计冲刺会议</li></ol><ul><li>倡导增长文化</li></ul><p>增长文化，从最基本的两件事开始做起：</p><ol><li>将实验的结果和心得向全公司公开，让每个人都知道增长团队的进展，并且可以把这些心得应用在自己的工作当中</li><li>鼓励每个人都来贡献实验想法，因为即使是针对同一个问题，每个人也都是有自己的视角的。比如，销售团队和客户服务团队离用户更近，工程师团队对程序更熟悉，很多时候他们都会带来出其不意的想法的。</li></ol><h1 id="7-增长战略"><a href="#7-增长战略" class="headerlink" title="7. 增长战略"></a>7. 增长战略</h1><h2 id="7-1-设定增长目标"><a href="#7-1-设定增长目标" class="headerlink" title="7.1 设定增长目标"></a>7.1 设定增长目标</h2><ul><li>找到正确的增长KPI并设定一个清晰明确的目标。</li><li>北极星指标就是公司的核心增长KPI</li><li>费劲但是不是完全没有可能</li></ul><h2 id="7-2-指标分解"><a href="#7-2-指标分解" class="headerlink" title="7.2 指标分解"></a>7.2 指标分解</h2><ul><li>横向分解<ul><li>按照用户的群组，加法的方式来做分解</li></ul></li><li>纵向分解<ul><li>按照用户的生命旅程，通过乘法的方式将子目标进一步拆解为更细的漏斗步骤。</li></ul></li></ul><h2 id="7-3-找到聚焦领域"><a href="#7-3-找到聚焦领域" class="headerlink" title="7.3 找到聚焦领域"></a>7.3 找到聚焦领域</h2><ul><li>通过分析和研究，找到性价比最高的聚焦领域</li></ul><h2 id="7-4-增长战术执行"><a href="#7-4-增长战术执行" class="headerlink" title="7.4 增长战术执行"></a>7.4 增长战术执行</h2><ul><li>增长冲刺<ul><li>产生实验想法<ul><li>针对聚焦领域，通过数据分析指定探索方向，产生出一系列的备选试验想法，记录在增长规划图当中</li><li>将收集试验想法当做增长流程的常规组成部分</li></ul></li><li>决定优先级排序<ul><li>影响力 - 成功率 - 开发成本 </li></ul></li><li>设计和开发试验<ul><li>要有一个增长试验报告<ul><li>部分划分<ul><li>试验假设</li><li>试验设计</li><li>试验指标</li><li>试验打分</li><li>试验结果</li><li>试验心得</li><li>后续计划</li></ul></li></ul></li></ul></li><li>分析数据<ul><li>确保试验结果具有统计显著性</li><li>计算所需的样本量 – 样本计算器</li><li>设置参数<ul><li>基本的转化率</li><li>最小能监测到的改变幅度</li><li>统计显著值</li></ul></li></ul></li><li>应用结果<ul><li>应用结果</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thought </tag>
            
            <tag> Reading </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>程序员修炼之道</title>
      <link href="/%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/"/>
      <url>/%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%AE%E7%82%BC%E4%B9%8B%E9%81%93/</url>
      
        <content type="html"><![CDATA[<h1 id="1-注重实效方法论"><a href="#1-注重实效方法论" class="headerlink" title="1. 注重实效方法论"></a>1. 注重实效方法论</h1><h2 id="1-1-高效习惯"><a href="#1-1-高效习惯" class="headerlink" title="1.1 高效习惯"></a>1.1 高效习惯</h2><ul><li>不要害怕发生问题，不要推卸责任</li><li>对于一个事情是否能做到，提供各种选择，而不是借口</li><li>不要留着破窗户(低劣的设计，错误决策，糟糕代码)，将出问题的代码放入注释是个不错的选择。</li><li>参与正在发生的成功要更容易些，让他们瞥见未来，他们就会聚集在你的周围。</li></ul><h2 id="1-2-知识资产"><a href="#1-2-知识资产" class="headerlink" title="1.2 知识资产"></a>1.2 知识资产</h2><p>管理知识资产和管理金融资产非常相似：</p><ul><li>严肃的投资者定期投资 —— 作为习惯</li><li>多元化是长期成功的关键</li><li>聪明的投资者在保守的投资和高风险、高回报的投资之间平衡其资产</li><li>投资者设法低买高卖，以获取最大回报</li><li>应当周期性重新评估和平衡资产</li></ul><h2 id="1-3-交流"><a href="#1-3-交流" class="headerlink" title="1.3 交流"></a>1.3 交流</h2><ul><li>知道想说什么，有大纲</li><li>了解听众</li><li>让文档美观</li><li>让听众参与</li></ul><h1 id="2-注重实效的途径"><a href="#2-注重实效的途径" class="headerlink" title="2. 注重实效的途径"></a>2. 注重实效的途径</h1><h2 id="2-1-重复"><a href="#2-1-重复" class="headerlink" title="2.1 重复"></a>2.1 重复</h2><blockquote><p>DRY - Don’t repeat yourself!</p></blockquote><p>在不同的地方写相同的东西那在修改的时候就不能忘记每一处的修改，这是很crazy的做法了</p><h2 id="2-2-重复的发生"><a href="#2-2-重复的发生" class="headerlink" title="2.2 重复的发生"></a>2.2 重复的发生</h2><h2 id="2-2-1-强加的重复-似乎是环境要求"><a href="#2-2-1-强加的重复-似乎是环境要求" class="headerlink" title="2.2.1 强加的重复 - 似乎是环境要求"></a>2.2.1 强加的重复 - 似乎是环境要求</h2><h2 id="2-2-2-无意的重复-没有意识到"><a href="#2-2-2-无意的重复-没有意识到" class="headerlink" title="2.2.2 无意的重复 - 没有意识到"></a>2.2.2 无意的重复 - 没有意识到</h2><ul><li>注意数据之间的相互重复，如果有某个量值是可以通过其他数据计算得出的，那么就应该用计算得出的值</li><li>而由于性能原因，做cache引起的重复，需要将影响局部化，不要将其暴露给外界</li><li>像Java这样的面向对象的语言应当总是使用访问器函数来读写对象的属性</li></ul><h2 id="2-2-3-无耐性的重复-偷懒"><a href="#2-2-3-无耐性的重复-偷懒" class="headerlink" title="2.2.3 无耐性的重复 - 偷懒"></a>2.2.3 无耐性的重复 - 偷懒</h2><h2 id="2-2-4-开发者之间的重复-同一团队的几个人重复了同样的信息"><a href="#2-2-4-开发者之间的重复-同一团队的几个人重复了同样的信息" class="headerlink" title="2.2.4 开发者之间的重复 - 同一团队的几个人重复了同样的信息"></a>2.2.4 开发者之间的重复 - 同一团队的几个人重复了同样的信息</h2><ul><li>Make it easy to reuse </li></ul><h2 id="2-3-正交性"><a href="#2-3-正交性" class="headerlink" title="2.3 正交性"></a>2.3 正交性</h2><p>表示一种互不依赖，解耦性。指几个子系统之间互不依赖，例如数据库代码与用户界面代码应该为正交的</p><blockquote><p>Eliminate effects between unrelatd things </p></blockquote><p>使基础知识和应用分离，每个主要的基础设施组件(数据库、通信接口、中间件层)有自己的子团队</p><h2 id="2-4-设计"><a href="#2-4-设计" class="headerlink" title="2.4 设计"></a>2.4 设计</h2><p>做一个正交系统，关键指标！ </p><ul><li>模块化</li><li>基于组件</li><li>分层</li></ul><p>系统应该是由一组相互协作的模块组成，每个模块都实现不依赖于其他模块的功能。</p><p>通过分层使得每层都只使用在其下面的层次提供的抽象，在改动底层实现，而又不影响其他代码方面，就会有极大的灵活性了。</p><blockquote><p>对于正交性组件的测试方法 -&gt; 如果我显著改变某个特定功能背后的需求，有多少模块会受到影响呢？   需要是一个！</p></blockquote><h2 id="2-5-编码"><a href="#2-5-编码" class="headerlink" title="2.5 编码"></a>2.5 编码</h2><ul><li>让代码保持解耦<ul><li>不会没必要的想其他模块暴露任何借口</li></ul></li><li>避免使用全局数据</li><li>避免使用相似的函数</li></ul><blockquote><p>There are no final decisions </p></blockquote><h2 id="2-6-原型与便签"><a href="#2-6-原型与便签" class="headerlink" title="2.6 原型与便签"></a>2.6 原型与便签</h2><p>原型不需要总是以代码为基础，要看需求。比如为<strong>工作流和应用逻辑这样的动态事物制作原型，便签</strong>就非常好。用户界面的原型可以使白板上的图形，或者是永辉图程序或者界面构建器绘制的无功能的模型。</p><p>原型设计的目的就是为了去回答一些问题的，一些不在意的方面就可以不去管它。 </p><h3 id="2-6-1-什么时候使用原型"><a href="#2-6-1-什么时候使用原型" class="headerlink" title="2.6.1 什么时候使用原型"></a>2.6.1 什么时候使用原型</h3><ul><li>应制作原型的事物<ul><li>架构</li><li>已有系统中的新功能</li><li>外部数据的结构或内容</li><li>第三方工具或组件</li><li>性能问题</li><li>用户界面设计</li></ul></li></ul><h3 id="2-6-2-怎样使用原型"><a href="#2-6-2-怎样使用原型" class="headerlink" title="2.6.2 怎样使用原型"></a>2.6.2 怎样使用原型</h3><p>可以忽略一些细节</p><ul><li>正确性<ul><li>可以使用虚设的数据</li></ul></li><li>完整性<ul><li>原型也许只能在非常有限的意义上工作，也许只有一项预先选择的输入数据和菜单项</li></ul></li><li>健壮性<ul><li>错误检查可能会非常不完整，或者完全没有</li></ul></li><li>风格<ul><li>可能没有多少注释或者文档</li></ul></li></ul><h3 id="2-6-3-如何制作架构原型"><a href="#2-6-3-如何制作架构原型" class="headerlink" title="2.6.3 如何制作架构原型"></a>2.6.3 如何制作架构原型</h3><ul><li>在架构原型中寻求解答的一些问题<ul><li>主要组件的责任是否得到了良好的定义？ 是否适当？ </li><li>主要组件之间的协作是否得到良好的定义？ </li><li>耦合是否得以最小化？ </li><li>是否能确定重复的潜在来源？ </li><li>接口定义和各项约束是否可接受？ </li><li>每个模块在执行过程中是否能访问到其所需的数据？ 是否能在需要时进行访问？ </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thought </tag>
            
            <tag> Reading </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>说说日本</title>
      <link href="/%E8%AF%B4%E8%AF%B4%E6%97%A5%E6%9C%AC/"/>
      <url>/%E8%AF%B4%E8%AF%B4%E6%97%A5%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p>一衣带水的邻国，看上去像富士山一样，温润如玉，殊不知是座活火山，平静下酝酿着风暴。这是个很神奇的存在啊。有全世界独一无二的审慎与严谨，但也有战斗到死的癫狂。尽量不在这篇文章里输出自己的观点，只想说说关于日本，在自己了解以后，一些神奇的，令人惊叹的点。</p><h1 id="1-关于日本本身"><a href="#1-关于日本本身" class="headerlink" title="1. 关于日本本身"></a>1. 关于日本本身</h1><h2 id="1-1-地理位置-地理决定论？日本民族性格？"><a href="#1-1-地理位置-地理决定论？日本民族性格？" class="headerlink" title="1.1 地理位置-地理决定论？日本民族性格？"></a>1.1 地理位置-地理决定论？日本民族性格？</h2><p>千岛之国，日本国土由6852个小岛构成，四个最大的岛占了整个国土97%的面积，分别为： 北海道，本州，四国，九州。73% 森林覆盖率，世界顶级。108 座活火山，地震，从古至今，一直都在。<br><a href="https://en.wikipedia.org/wiki/List_of_countries_by_natural_disaster_risk" target="_blank" rel="noopener">natural disaster risk rank</a> 因为处于太平洋板块和亚欧板块交界处的消亡边界，每年都有上千次地震发生，其中不乏6级以上的<a href="https://www.livescience.com/30312-japan-earthquakes-top-10-110408.html" target="_blank" rel="noopener">大地震</a>。而如果统计1级以上的地震数量，日本<a href="http://blog.sciencenet.cn/blog-2277-1063374.html" target="_blank" rel="noopener">2016年达到了6566次</a>。</p><h2 id="1-2-教育水平"><a href="#1-2-教育水平" class="headerlink" title="1.2 教育水平"></a>1.2 教育水平</h2><p>日本教育水平世界前列，<a href="https://www.zhihu.com/question/21303431/answer/543321578" target="_blank" rel="noopener">OECD数据-知乎</a></p><h2 id="1-3-发迹史"><a href="#1-3-发迹史" class="headerlink" title="1.3 发迹史"></a>1.3 发迹史</h2><h3 id="1-3-0-明治维新"><a href="#1-3-0-明治维新" class="headerlink" title="1.3.0 明治维新"></a>1.3.0 明治维新</h3><h3 id="1-3-1-First-Sino-Japanese-War-甲午战争"><a href="#1-3-1-First-Sino-Japanese-War-甲午战争" class="headerlink" title="1.3.1 First Sino-Japanese War - 甲午战争"></a>1.3.1 First Sino-Japanese War - 甲午战争</h3><p>我国割让了辽东半岛（列强干预，未能得逞），台湾岛，澎湖列岛。增开沙市，重庆，苏州，杭州为商埠，并允许日本在中国的通商口岸投资办厂。</p><p>题外（待补充）：为什么会选择闭关锁国（稳定+可自给自足+南美，尤其秘鲁大量廉价银元的冲击）</p><ol start="2"><li>战争赔款的使用</li></ol><ul><li>一半用来扩充陆海军军备</li><li>币值改革的准备金 - 确立金本位的货币制度，融入世界经济体系</li><li>军舰水雷艇补充基金</li><li>灾害准备基金</li><li>教育基金</li><li>台湾经营费用</li></ul><p>吐槽： 定远舰建造花费约140万两白银，慈禧60大寿花费白银愈1000万两。<a href="http://blog.sina.com.cn/s/blog_7765a8070101e7mt.html?tj=1" target="_blank" rel="noopener">可能不太准确的数据源，(欢迎提供更准确的~)</a></p><h3 id="1-3-2-日俄战争"><a href="#1-3-2-日俄战争" class="headerlink" title="1.3.2 日俄战争"></a>1.3.2 日俄战争</h3><h3 id="1-3-3-一战与二战"><a href="#1-3-3-一战与二战" class="headerlink" title="1.3.3 一战与二战"></a>1.3.3 一战与二战</h3><p>说这方面的好文章太多，提一个日本战败后签订的跳月细文：<br><a href="https://en.wikipedia.org/wiki/Article_9_of_the_Japanese_Constitution" target="_blank" rel="noopener">日本放弃了宣布战争的权利- renounce the sovereign right of belligerency and aims at an international peace based on justice and order</a></p><h2 id="1-3-日本现在的问题"><a href="#1-3-日本现在的问题" class="headerlink" title="1.3 日本现在的问题"></a>1.3 日本现在的问题</h2><ol><li>人口老龄化</li></ol><p>根据2014年的估计，33%的日本人的年龄在60岁以上，25.9%在65岁以上，而这种老龄化的趋势正愈演愈烈。日本人口整体正在负增长中，2014年数据为127M，预计2040年会减到107M， 2050年会到97M，不足一亿。<a href="https://en.wikipedia.org/wiki/Aging_of_Japan" target="_blank" rel="noopener">(日本人口老龄化)</a></p><ol start="2"><li>自杀率 – related with 1.1?</li></ol><p>日本每年自杀人数30000左右，非常高的<a href="https://en.wikipedia.org/wiki/Suicide_in_Japan" target="_blank" rel="noopener">自杀率</a>。</p><ol start="3"><li>丧一代的年轻人？</li></ol><p><a href="https://en.wikipedia.org/wiki/Hikikomori" target="_blank" rel="noopener">Hikikpomori</a> 死肥宅? 大概应该这么翻译吧</p><p>沉溺于虚拟生活，摒弃一切社交活动，活在自己的世界里。</p><p>巨大的社会压力，<strong>有礼也束于礼</strong>。等级森严，职责分明。规则与秩序对于人的某些方面的束缚。</p><p>日本<a href="http://ihl.cankaoxiaoxi.com/2016/1122/1450130.shtml" target="_blank" rel="noopener">网吧难民</a>，这点可以和<a href="https://zh.wikipedia.org/wiki/%E4%B8%89%E5%92%8C%E5%A4%A7%E7%A5%9E" target="_blank" rel="noopener">三和大神</a>对应哎~  </p><h2 id="1-4-日本文化的宣扬-famous-for"><a href="#1-4-日本文化的宣扬-famous-for" class="headerlink" title="1.4 日本文化的宣扬/ famous for"></a>1.4 日本文化的宣扬/ famous for</h2><ol><li>浮世绘<br>很有意思，Japan means a hard, dark, enamellike varnish containing asphalt, used to give a black gloss to metal objects.漆器。</li></ol><p>中国日本在19世纪开始都会往欧洲出口很多瓷器，这里佩服下古代国人的智慧，我们撒黄豆浇水来保护瓷器，黄豆遇水发芽，与瓷器牢牢结合起来；日本选择用报纸包裹，浮世绘由此传入欧洲，深受喜爱~ (偏传说，没找到史实，但实在是很有意思啊！)</p><ol start="2"><li>动漫</li><li>音乐产业</li><li>电影</li><li>饮食</li><li>现代技术</li></ol><h1 id="2-与中国的关系"><a href="#2-与中国的关系" class="headerlink" title="2. 与中国的关系"></a>2. 与中国的关系</h1><h2 id="2-1-二战"><a href="#2-1-二战" class="headerlink" title="2.1 二战"></a>2.1 二战</h2><h2 id="2-2-对中援助"><a href="#2-2-对中援助" class="headerlink" title="2.2 对中援助"></a>2.2 对中援助</h2><p>日本在二战以后对中有大量经济援助，占到了中国接收的总经济援助的60%以上。</p><p>整个经济援助分为三部分：</p><ol><li>有偿资金协力</li><li>无偿资金赠与</li><li>技术指导培育协助</li></ol><p>整个经济援助从1979年开始，直到2007年12月结束。38年来对中政府开发援助的合约总额为3.64兆円，折合2852亿人民币。其中89.7%是有偿贷款，贷款利率最高3.5%,最低仅为0.65%，贷款周期是30~40年，前10年免还本金。日本的援助占到了中国政府接受总体外援的67.2%，位居24个帮助国和机构之首。高于第二名德国33倍之多。而在日本对外援助国当中中国则排在印尼和印度之后第三位。<a href="https://www.zhihu.com/question/40252945" target="_blank" rel="noopener">如何看待日本曾是中国的最大援助国？</a></p><p>这点很有意思，确实，我们免除了日本的战争赔款，但这不足以成为日本给予如此大量的援助的先决条件。尤其是在我们一穷二白，完全没有外汇储备，还需要对外招商引资的关键时刻，这笔钱会极大影响我们的发展速度。</p><p>因为歉意？ </p><p>因为免除战争赔款极大程度上维系了天皇的荣誉？</p><p>因为技术上经济上的援助可以加速了解中国？</p><p>因为经济上的援助，有息贷款同样给日本带来了很大的经济利益？这点实打实的，对日本从上世纪80年代开始就开放了市场。</p><p>因为政治上我们不知道的角力？ </p><h1 id="3-小总"><a href="#3-小总" class="headerlink" title="3. 小总"></a>3. 小总</h1><p>一个尚武且善武，自制且极端，有礼又束于礼，崇尚强者的民族。历史当鉴，未来已来。</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Thought </tag>
            
            <tag> Reading </tag>
            
            <tag> Japan </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重构笔记</title>
      <link href="/%E9%87%8D%E6%9E%84%E7%AC%94%E8%AE%B0/"/>
      <url>/%E9%87%8D%E6%9E%84%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="1-什么是重构？"><a href="#1-什么是重构？" class="headerlink" title="1. 什么是重构？"></a>1. 什么是重构？</h1><blockquote><p>在不改变软件可观察行为的前提下改善其内部结构，提高其可理解性，降低其修改成本</p></blockquote><p>当面对历史遗留问题的时候，规模很大，历史超久，使得增加单元测试或者理解逻辑成为不可能的任务，那么我们有的工具就是那些已经被证明是<strong>行为保持的重构手法</strong>，整理出可测试的接口，并添加测试，以此作为继续重构的立足点。</p><h2 id="1-1-Tips"><a href="#1-1-Tips" class="headerlink" title="1.1 Tips"></a>1.1 Tips</h2><ol><li>以微小的步伐修改程序，以期更好的发现错误。</li><li>代码应该表现自己的目的！！！</li><li>大多数情况下，函数应该放在它所使用的数据的所属对象当中</li><li>尽量去除临时变量，因为其很容易产生问题，导致大量参数被传来传去。  Replace Temp with Query </li><li>注意将变化的东西放到一块去，一块来解决</li></ol><h1 id="2-重构原则"><a href="#2-重构原则" class="headerlink" title="2. 重构原则"></a>2. 重构原则</h1><p>使用重构原则开发软件的时候，实质上是将自己的时间分配给了两种截然不同的行为：添加新功能以及重构。添加新功能的时候就不修改既有代码；重构时不添加新功能，只管改进程序结构。</p><h2 id="2-1-为何重构"><a href="#2-1-为何重构" class="headerlink" title="2.1 为何重构"></a>2.1 为何重构</h2><ul><li>改进软件设计<ul><li>整理代码，让代码回到应有的位置上去</li><li>减少代码量，消除重复代码</li></ul></li><li>使得软件更容易理解</li><li>更容易找到Big</li><li>提高编程速度<ul><li>良好的设计是快速开发的根本</li></ul></li></ul><blockquote><p>当重复做一件事情三次的时候，请重构。</p></blockquote><ul><li>在添加功能的时候重构<ul><li>帮助理解需要修改的代码</li></ul></li><li>修补错误时重构</li><li>修改接口<ul><li>当接口不得不被修改的时候</li><li>deprecate掉旧接口，并且让旧接口Internally调用新接口</li></ul></li></ul><h1 id="3-代码的坏味道"><a href="#3-代码的坏味道" class="headerlink" title="3. 代码的坏味道"></a>3. 代码的坏味道</h1><p>本章比较大概，但里面又提及了很多细节性的方法，建议先去了解这些方法，再来看这一章！ </p><p>量度规矩 vs 见识广博者的直觉</p><h2 id="3-1-Duplicated-Code-重复代码"><a href="#3-1-Duplicated-Code-重复代码" class="headerlink" title="3.1 Duplicated Code 重复代码"></a>3.1 Duplicated Code 重复代码</h2><ul><li>同一个类的两个函数有相同表达式<ul><li>extract method</li></ul></li><li>两个互为兄弟的子类内的相同表达式<ul><li>extract method to super class</li></ul></li><li>两个不相关的类， duplicate code<ul><li>对其中一个使用extract class，将重复代码提炼到一个独立类当中 </li></ul></li></ul><h2 id="3-2-Long-Method-过长函数"><a href="#3-2-Long-Method-过长函数" class="headerlink" title="3.2 Long Method (过长函数)"></a>3.2 Long Method (过长函数)</h2><p>间接层所能带来的全部利益 - 解释能力，共享能力，选择能力都是由小型函数支持的</p><p>给函数一个好名字，让代码阅读者可以很迅速地了解到这个函数是做什么的。</p><p>每当感觉需要以注释来说明点什么的时候，我们就需要把说明的东西写进一个独立函数中。</p><h2 id="3-3-Large-Class-过大的类"><a href="#3-3-Large-Class-过大的类" class="headerlink" title="3.3 Large Class (过大的类)"></a>3.3 Large Class (过大的类)</h2><p>如果用单个类做太多事情，往往会出现大量的实例变量，一旦如此，duplicated code也就会接踵而至了。</p><p>extract class or extract subclass </p><h2 id="3-4-Long-Parameter-List-过长参数列"><a href="#3-4-Long-Parameter-List-过长参数列" class="headerlink" title="3.4 Long Parameter List (过长参数列)"></a>3.4 Long Parameter List (过长参数列)</h2><p>replace parameter with method </p><p>introduce paramter object </p><h2 id="3-5-Divergent-Change-发散式变化"><a href="#3-5-Divergent-Change-发散式变化" class="headerlink" title="3.5 Divergent Change (发散式变化)"></a>3.5 Divergent Change (发散式变化)</h2><p>针对某一外界变化的所有的相应修改都只应该发生在单一类当中，并且新类内的所有内容都应该反应此变化。应找到导致变化的原因，然后运用Extact Class将其提炼到另一个类当中。</p><h2 id="3-6-Shotgun-Surgery"><a href="#3-6-Shotgun-Surgery" class="headerlink" title="3.6 Shotgun Surgery"></a>3.6 Shotgun Surgery</h2><p>如果每遇到某种变化，都必须在很多不同的类内做许多小修改，那么就应该使用move method和move field把所有需要的修改都放到一个类里去。努力使外界变化和需要修改的类能够一一对应。</p><h2 id="3-7-Feature-Envy"><a href="#3-7-Feature-Envy" class="headerlink" title="3.7 Feature Envy"></a>3.7 Feature Envy</h2><h2 id="3-8-Data-Clumps"><a href="#3-8-Data-Clumps" class="headerlink" title="3.8 Data Clumps"></a>3.8 Data Clumps</h2><p>将经常绑在一起出现的数据放到一起，创建属于他们的对象</p><h2 id="3-9-Primitive-Obsession"><a href="#3-9-Primitive-Obsession" class="headerlink" title="3.9 Primitive Obsession"></a>3.9 Primitive Obsession</h2><h2 id="3-10-switch"><a href="#3-10-switch" class="headerlink" title="3.10 switch"></a>3.10 switch</h2><p>少用switch，应该考虑用多态来做替换</p><h2 id="3-11-Parallel-Inheritance-Hierarchies-平行继承关系"><a href="#3-11-Parallel-Inheritance-Hierarchies-平行继承关系" class="headerlink" title="3.11 Parallel Inheritance Hierarchies (平行继承关系)"></a>3.11 Parallel Inheritance Hierarchies (平行继承关系)</h2><h2 id="3-12-Lazy-Class"><a href="#3-12-Lazy-Class" class="headerlink" title="3.12 Lazy Class"></a>3.12 Lazy Class</h2><h2 id="3-13-Speculative-Generality"><a href="#3-13-Speculative-Generality" class="headerlink" title="3.13 Speculative Generality"></a>3.13 Speculative Generality</h2><h2 id="3-14-Temporary-Field"><a href="#3-14-Temporary-Field" class="headerlink" title="3.14 Temporary Field"></a>3.14 Temporary Field</h2><h2 id="3-15-Message-Chains"><a href="#3-15-Message-Chains" class="headerlink" title="3.15 Message Chains"></a>3.15 Message Chains</h2><h2 id="3-16-Middle-Man"><a href="#3-16-Middle-Man" class="headerlink" title="3.16 Middle Man"></a>3.16 Middle Man</h2><h2 id="3-17-Inappropriate-Intimacy"><a href="#3-17-Inappropriate-Intimacy" class="headerlink" title="3.17 Inappropriate Intimacy"></a>3.17 Inappropriate Intimacy</h2><h2 id="3-18-Alternative-Classes-with-Different-Interfaces"><a href="#3-18-Alternative-Classes-with-Different-Interfaces" class="headerlink" title="3.18 Alternative Classes with Different Interfaces"></a>3.18 Alternative Classes with Different Interfaces</h2><h2 id="3-19-Incomplete-Library-Class"><a href="#3-19-Incomplete-Library-Class" class="headerlink" title="3.19 Incomplete Library Class"></a>3.19 Incomplete Library Class</h2><h2 id="3-20-Data-Class"><a href="#3-20-Data-Class" class="headerlink" title="3.20 Data Class"></a>3.20 Data Class</h2><h2 id="3-21-Refused-Bequest"><a href="#3-21-Refused-Bequest" class="headerlink" title="3.21 Refused Bequest"></a>3.21 Refused Bequest</h2><h2 id="3-22-Comments"><a href="#3-22-Comments" class="headerlink" title="3.22 Comments"></a>3.22 Comments</h2><h1 id="4-构筑测试体系"><a href="#4-构筑测试体系" class="headerlink" title="4. 构筑测试体系"></a>4. 构筑测试体系</h1><p>对于程序员来说，写代码的时间实际上很少，大部分时间是用在了调试代码上。实际上，每个类都应该有一个测试函数，并以它来测试自己。</p><p>写好一点功能就立即去进行测试。事实上，最好能在添加特性之前先写测试代码，使得将注意力集中于接口而非实现。</p><p>编写代码时，应该先让代码失败，以此证明测试机制的确可以运行，并且正确测试了其该测试的东西。</p><p>观察类该做的所有事情，然后针对任何一项功能的任何一种可能失败情况，进行测试。</p><h1 id="5-重构列表"><a href="#5-重构列表" class="headerlink" title="5. 重构列表"></a>5. 重构列表</h1><ul><li>方法</li><li>动机</li></ul><h1 id="6-重新组织函数"><a href="#6-重新组织函数" class="headerlink" title="6. 重新组织函数"></a>6. 重新组织函数</h1><p>重构手法大部分都针对函数，而问题往往源自于Long Methods。因为其包含了太多信息。</p><h2 id="6-1-Extract-Methods"><a href="#6-1-Extract-Methods" class="headerlink" title="6.1 Extract Methods"></a>6.1 Extract Methods</h2><ul><li>将一段代码放进一个独立函数当中，并且用函数名称来解释该函数的用途</li><li>动机  <ul><li>当函数过长，或者需要注释才能让人理解用途，就放到独立函数当中</li><li>函数粒度小意味着更容易进行复用</li><li>使得高层函数读起来就像一些列注释</li></ul></li><li>做法<ul><li>创造一个函数，根据这个函数的意图来对其进行命名，以做什么而不是怎么做来命名</li></ul></li></ul><h2 id="6-2-Inline-Method-内联函数"><a href="#6-2-Inline-Method-内联函数" class="headerlink" title="6.2 Inline Method 内联函数"></a>6.2 Inline Method 内联函数</h2><ul><li>在函数调用点插入函数本体，然后移除该函数</li><li>动机<ul><li>移除没有太大价值的间接层</li></ul></li></ul><h2 id="6-3-Inline-Temp-内联临时变量"><a href="#6-3-Inline-Temp-内联临时变量" class="headerlink" title="6.3 Inline Temp 内联临时变量"></a>6.3 Inline Temp 内联临时变量</h2><ul><li>你有一个临时变量，只被简单表达式赋值一次，而它妨碍了其他重构手法</li><li>动机<ul><li>一般作为Replace Temp with Query的一部分使用</li></ul></li></ul><h2 id="6-4-Replace-Temp-with-Query-以查询取代临时变量"><a href="#6-4-Replace-Temp-with-Query-以查询取代临时变量" class="headerlink" title="6.4 Replace Temp with Query  以查询取代临时变量"></a>6.4 Replace Temp with Query  以查询取代临时变量</h2><ul><li>现象<ul><li>你的程序以一个临时变量保存某一表达式的运算结果</li></ul></li><li>将这个表达式提炼到一个独立函数当中，将这个临时变量的所有引用点替换为对新函数的调用。此后，新函数就可以被其他函数调用了。</li><li>动机<ul><li>临时变量的问题是他们是暂时的，很可能你需要写出更长的函数来访问到需要的临时变量 </li></ul></li></ul><h2 id="6-5-Introduce-Explaining-Variable-引入解释性变量"><a href="#6-5-Introduce-Explaining-Variable-引入解释性变量" class="headerlink" title="6.5 Introduce Explaining Variable 引入解释性变量"></a>6.5 Introduce Explaining Variable 引入解释性变量</h2><ul><li>将该复杂表达式(或其中一部分)的结果放进一个临时变量，以此变量名称来解释表达式用途。</li><li>动机<ul><li>表达式有可能非常复杂且难以阅读，临时变量可以帮助你将表达式分解为比较容易管理的形式</li><li>这样子我们就可以运用临时变量来解释每一步的意义，在执行一些比较长的判断逻辑的时候很关键</li></ul></li><li>做法<ul><li>和 extract method 有可替换的潜在部分的</li><li>使用introduce explaining variable是在extract method需要花费更大工作量的时候</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reading </tag>
            
            <tag> rafactor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>明朝户籍制度</title>
      <link href="/%E6%98%8E%E6%9C%9D%E6%88%B7%E7%B1%8D%E5%88%B6%E5%BA%A6/"/>
      <url>/%E6%98%8E%E6%9C%9D%E6%88%B7%E7%B1%8D%E5%88%B6%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<p>从元朝的百废待兴到明太祖的休养生息，用一个个制度逐渐了解稳固自己统治的国家，户帖制，里甲制，鱼鳞图册，三位一体，奠定了一朝之基。似乎大家有点小觑了朱元璋啊。</p><h1 id="1-户籍的重要性"><a href="#1-户籍的重要性" class="headerlink" title="1. 户籍的重要性"></a>1. 户籍的重要性</h1><ul><li>壮丁数量<ul><li>能动员的士兵和民夫数量 </li></ul></li><li>牲畜数量<ul><li>运力的多寡与分配</li></ul></li><li>作物产量<ul><li>粮草征发</li></ul></li><li>地形图册<ul><li>决定用兵方略</li></ul></li><li>资源<ul><li>草药</li><li>矿物</li><li>etc.</li></ul></li></ul><p>田地数量和人口数量，掌握这两个才能稳定政权。</p><p><strong><em>收税有据，束民有方</em></strong></p><h1 id="2-户帖法"><a href="#2-户帖法" class="headerlink" title="2. 户帖法"></a>2. 户帖法</h1><h2 id="2-1-户帖制的流程"><a href="#2-1-户帖制的流程" class="headerlink" title="2.1 户帖制的流程"></a>2.1 户帖制的流程</h2><ol><li>皇帝下发圣旨到户部</li><li>户部设计出标准户籍格式尺寸，叫做户帖式。用纸长一尺三寸，宽一尺两寸。</li><li>户部将设计好的户帖式下发给官办印坊，批量印刷并分发</li><li>各地州县接到空白户帖知乎，必须由正印官员担任提调官，负责张贴文告，晓谕百姓</li><li>下级官吏执行落地</li><li>百姓多数不识字，故需要小吏现场填写各种资料，并由熟悉内情的里正审核并作保</li><li>所有填好的籍联，在衙门汇总统计，要算明户口，人口，丁口，田产几项数字的总和，连同原始资料一起上交</li><li>朱元璋动员了大批军队系统的文书人员，分散到各地区审核抽查</li></ol><h2 id="2-2-户帖正文格式"><a href="#2-2-户帖正文格式" class="headerlink" title="2.2 户帖正文格式"></a>2.2 户帖正文格式</h2><ul><li>分为左中右三块<ul><li>最右<ul><li>印制洪武皇帝的圣旨</li></ul></li><li>中间<ul><li>该户的乡贯</li><li>男子丁口</li><li>女子口</li><li>名岁</li><li>与户主关系</li><li>户种</li><li>事产</li><li>住址</li></ul></li><li>最左<ul><li>每一级经手官员的签押</li></ul></li></ul></li><li>每一份户帖，都要一式两联<ul><li>籍联 给官府留底</li><li>户联 给百姓留底</li><li>在二者的骑缝处，要印有字号以作为堪和之用</li><li>加盖户部骑缝章</li></ul></li></ul><h2 id="2-3-缺憾？"><a href="#2-3-缺憾？" class="headerlink" title="2.3 缺憾？"></a>2.3 缺憾？</h2><ul><li>只记录了土地多少，却没有统计田地的质量<ul><li>缺能够准确丈量土地的人才</li><li>且不清丈土地，百姓的抵触情绪就会小很多</li><li>！！鼓励垦荒，新开发的土地不予起科</li></ul></li><li>职业户制依旧<ul><li>维稳</li><li>国家政策的延续性</li><li>卫所制，军队不再退役，世代军人</li><li>粗略分类<ul><li>民户</li><li>军户</li><li>匠户</li><li>灶户</li></ul></li></ul></li></ul><p>一般来说，古代的中央政权为了减少管理成本，行政力量一般只会延伸到县一级，再往下，官府只控制地方上的财税，军权，意识形态解读权等大节，而将一部分的琐碎的事务管理权交给地方上自己解决  – 即交由当地的乡绅，豪强以及宗族。</p><p>户帖制十年后的再度改革，力求;</p><ol><li>击破横亘在朝廷和基层之间的利益集团，提高对基层的掌控力</li><li>避免高昂的管理成本</li></ol><h1 id="3-里甲制-–-小黄册"><a href="#3-里甲制-–-小黄册" class="headerlink" title="3. 里甲制 – 小黄册"></a>3. 里甲制 – 小黄册</h1><p>户帖制刚开始就在做的试点工程…</p><h2 id="3-1-构成"><a href="#3-1-构成" class="headerlink" title="3.1 构成"></a>3.1 构成</h2><ul><li>基本行政单位 图<ul><li>共100户<ul><li>每10户编成一甲，从中选出一户甲首来管理</li><li>共10甲首</li><li>选出一里长，负责掌管十个甲首，为一图的最高长官，直接向县级衙门汇报</li></ul></li></ul></li><li>规则！！！<ul><li>甲首 里长 不是由上级全权指派，也不是基层选出，而是—-轮换制</li><li>100户中前10的富户轮流做里长</li><li>每户任期1年</li><li>11-20，担任甲首，每户分管9户，任期一年，由甲内其他户来做替换</li></ul></li><li>徭役<ul><li>10甲排定次序，每年派出一甲去应徭役</li></ul></li><li>连坐制</li></ul><h2 id="3-2-里长-甲首职责"><a href="#3-2-里长-甲首职责" class="headerlink" title="3.2 里长 甲首职责"></a>3.2 里长 甲首职责</h2><ul><li>管理责任<ul><li>里长需要把赋税搞齐</li></ul></li><li>解决邻里纠纷</li><li>文书作保</li><li>治安巡检</li><li>徭役<ul><li>负担很重，三重负担<ul><li>自备干粮</li><li>损失劳动力，导致田地荒芜</li><li>税赋依旧</li></ul></li></ul></li></ul><h2 id="3-3-补缺"><a href="#3-3-补缺" class="headerlink" title="3.3 补缺"></a>3.3 补缺</h2><ul><li>老人制<ul><li>选取年龄大且德高望重的老人作为乡里争讼的裁决者</li></ul></li><li>hhhhh，里甲工作手册</li><li>粮长职务<ul><li>由当地丁粮多的富户充当</li><li>去京师领取文书，返回辖区</li><li>督促里长，甲首筹粮</li></ul></li></ul><h2 id="3-4-黄册内容"><a href="#3-4-黄册内容" class="headerlink" title="3.4 黄册内容"></a>3.4 黄册内容</h2><ul><li>类似户帖的</li><li>百眼图/ 编次格眼<ul><li>徭役的排班表</li></ul></li><li>四柱式记录<ul><li>旧管</li><li>新收</li><li>开除</li><li>实在</li></ul></li><li>田地大小一直有</li><li>但是还有税赋记录！ <ul><li>夏税</li><li>秋粮</li></ul></li></ul><h2 id="3-5-分析"><a href="#3-5-分析" class="headerlink" title="3.5 分析"></a>3.5 分析</h2><p>将政府让给绅权和族权的权利进行进一步的戏份，保证每一户人家都有机会掌握基层权力。看似让基层更加分散，实际上让中央的权威回来了！</p><p>对官府来说，还不用承担管理人员的成本了… </p><h1 id="4-鱼鳞图册"><a href="#4-鱼鳞图册" class="headerlink" title="4. 鱼鳞图册"></a>4. 鱼鳞图册</h1><p>在有了户帖制，里甲制保驾护航之后，开始了全国范围的丈量土地的工作</p><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h1><p>黄册和里甲制锁住了人口相关的税费和徭役，鱼鳞图册和粮长掌控了田地租赋，三个制度，三位一体，将百姓牢牢钉在了土地之上，化为稳固的税基，源源不断为朝廷输血。</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reading </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何做时间管理</title>
      <link href="/%E5%A6%82%E4%BD%95%E5%81%9A%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/"/>
      <url>/%E5%A6%82%E4%BD%95%E5%81%9A%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>逐渐发现时间开始不够用了，要做的followup有点多，不想每天仅仅忙工作上的事情，每天会拿出一些时间学技术，看文章，更新博客；也会拿出一部分时间来看书，阅读，希望能在专业领域和generic的方面都会有点点提升，但是，时间上… 确实越来越不够用了。</p><p>上网搜了一下，发现有几个小点是可以尝试着去变化，看看能不能整体有提升的。</p><h1 id="1-时间安排前移"><a href="#1-时间安排前移" class="headerlink" title="1. 时间安排前移"></a>1. 时间安排前移</h1><p>早晨的时间的利用  </p><p>起床以后不干杂事，先解决自己想要专注，今天必须解决的问题。</p><p>即起床以后先去解决你今天非常想处理的，你自己给自己安排的事情。邮件，微信实质上是别人给你安排的事情，这些事情的优先级不应该凌驾于你对于自己的安排。</p><h1 id="2-时间安排"><a href="#2-时间安排" class="headerlink" title="2. 时间安排"></a>2. 时间安排</h1><p>从时间维度和事务维度两个维度跟进，我使用的是timecamp + trello，实质上是记录在每个项目上所花费的时间以及你的待办事项(按照项目来进行划分)。</p><h1 id="3-tips"><a href="#3-tips" class="headerlink" title="3. tips"></a>3. tips</h1><p>进程切换非常昂贵，避免多任务，保持单进程 </p><p>每天能保证高效的时间是有限的，集中注意力，高效工作每天最多4小时。</p><p>划分任务的优先级，不要把急切当做重要。紧急和重要划分开，四象限工作法，从重要紧急做起，但重要不紧急，到不重要但紧急，到不重要不紧急。</p><p>起床以后，不要查看邮件和微信。</p><p>早起，假如4点起床，那么到了中午你就完成了一天的任务了。</p><p>你没空时不会做的事情，有空了也不会做的。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.ruanyifeng.com/blog/2009/01/stuff_that_matters.html" target="_blank" rel="noopener">https://www.ruanyifeng.com/blog/2009/01/stuff_that_matters.html</a></p><p><a href="https://www.ruanyifeng.com/blog/2016/05/time-management.html" target="_blank" rel="noopener">https://www.ruanyifeng.com/blog/2016/05/time-management.html</a></p><p><a href="https://www.ruanyifeng.com/blog/2011/01/never_check_email_first_thing_in_the_morning" target="_blank" rel="noopener">https://www.ruanyifeng.com/blog/2011/01/never_check_email_first_thing_in_the_morning</a>.</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thought </tag>
            
            <tag> time management </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习观 from Yjango</title>
      <link href="/%E5%AD%A6%E4%B9%A0%E8%A7%82-from-Yjango/"/>
      <url>/%E5%AD%A6%E4%B9%A0%E8%A7%82-from-Yjango/</url>
      
        <content type="html"><![CDATA[<p>机缘巧合，看到个Yjango的学习观系列视频，把如何学习，怎么学习讲得非常透彻，在这里做下整理，希望能对大家都有所裨益。</p><h1 id="1-什么是学习？"><a href="#1-什么是学习？" class="headerlink" title="1. 什么是学习？"></a>1. 什么是学习？</h1><p>记忆 vs 学习</p><p>学习：从有限的例子当中得到一般性的规律的过程，找出的规律叫做知识。</p><p>学习是在用知识来压缩信息的，我不需要记住无数种情况，但是我需要根据每次出现的情况，根据我的知识来做出相应的判断。</p><h1 id="2-如何学习？"><a href="#2-如何学习？" class="headerlink" title="2. 如何学习？"></a>2. 如何学习？</h1><p>在人脑中，学习是通过例子来找出问题和答案之间的关系，而后重塑大脑链接来完成的。</p><p><strong>信息是具体的情况，而知识不是单纯的信息，而是信息与信息之间的关系</strong></p><p>对于知识的描述能对学习起到之音的作用，而最终想要达到的目的一定是<strong>通过例子理清问题和答案的关系来重塑大脑连接</strong>。</p><p>先把书读厚，再把书读薄。<br>就是说：尽可能的<strong>搜集更多的例子帮助体会问题和答案之间的关系</strong>，当你真正学会之后，这些都会被压缩为知识的。</p><h1 id="3-学习误区"><a href="#3-学习误区" class="headerlink" title="3. 学习误区"></a>3. 学习误区</h1><h2 id="3-1-针对知识的类型做出不同的学习方案-知识构建方式"><a href="#3-1-针对知识的类型做出不同的学习方案-知识构建方式" class="headerlink" title="3.1 针对知识的类型做出不同的学习方案 - 知识构建方式"></a>3.1 针对知识的类型做出不同的学习方案 - 知识构建方式</h2><p>首先我们的学习可以分为两大类：思考类学习和运动类学习。</p><p>思考类：是很慢的，是需要显示的经过大脑思考，然后做出判断，然后给出输出的。擅长解决推断问题，但是慢，无法应对多因素的问题。</p><p>运动类：很快，完全不经过我们的意识处理，我们就可以对应的做出反应。非思考类，非意识能解决的问题。面对这种情况，我们必须进行大量训练，行程肌肉记忆。这类训练最重要的是要有正确的输入输出，没有正确的反馈将永远都学不会。</p><p>我们需要对两种类型的学习进行区分，而后做出对应的学习处理。</p><h2 id="3-2-错误的输入输出"><a href="#3-2-错误的输入输出" class="headerlink" title="3.2 错误的输入输出"></a>3.2 错误的输入输出</h2><p>比如说听说读写学英文，我们将应该使用运动类的方式进行学习的东西当成了思考类进行学习的东西，于是文字输入并做文字输出，结果就导致了学习很长时间但是就是学不好东西。</p><p>而正确的解决方式，对于听说读写来说，理应是：</p><ul><li>听： 声音 -&gt; 意思， 运动类</li><li>说:  想法 -&gt; 发声,  运动类</li><li>读:  文字 -&gt; 意思,  运动类</li><li>写:  想法 -&gt; 打字,  运动类</li></ul><h2 id="3-3-不通过例子，仅记忆知识"><a href="#3-3-不通过例子，仅记忆知识" class="headerlink" title="3.3 不通过例子，仅记忆知识"></a>3.3 不通过例子，仅记忆知识</h2><p>大量例子，来构建知识之间的联结 </p><h1 id="4-应用误区"><a href="#4-应用误区" class="headerlink" title="4. 应用误区"></a>4. 应用误区</h1><p>解决subtask，分而治之，因为人的大脑在进行思考类的学习或者说解决问题的时候，是无法同时触及多个领域的内容的。所以我们需要专注于一个方面的东西，深入研究，解决完这个小问题以后再接下来解决下一个小问题。将原来需要<strong>指数级</strong>解决的问题转化成了<strong>线性级</strong>可以解决的问题。</p><h1 id="5-思维导图"><a href="#5-思维导图" class="headerlink" title="5. 思维导图"></a>5. 思维导图</h1><p>为什么简单又强大？</p><p>帮助学习应用当中的误区</p><ul><li><p>列关键词</p></li><li><p>遍历联想</p></li><li><p>压缩信息</p></li><li><p>分析共同输入输出，找出规律</p></li><li><p>这个关键词是在代表着几者之间的关系的</p></li><li><p>思维导图的关键词  – 动宾结构，描述的是输入和输出之间的函数关系</p></li><li><p>对思维的拆分  拆成小知识的组合</p><ul><li>然后用例子来构建</li><li>知识的网络的好处就在于其重用性</li></ul></li><li><p>思维导图在描述的是二阶知识</p><ul><li>一般的是在描述信息与信息之间的关系</li><li>而思维导图是想描述知识与知识之间的关系</li></ul></li><li><p>学习原则</p><ul><li>明确任务输入输出</li><li>将信息压缩成知识</li><li>例子重塑大脑连接</li><li>二阶知识拆分知识</li></ul></li></ul><h1 id="6-费曼技巧"><a href="#6-费曼技巧" class="headerlink" title="6. 费曼技巧"></a>6. 费曼技巧</h1><p>学习 + 解释 </p><p>解释的过程达成的目的：</p><ul><li>提取压缩</li><li>转化为自己的语言<ul><li>明确任务</li><li>拆分知识<ul><li>子知识之间的输入输出，pipeline </li></ul></li></ul></li><li>是在验证自己学会了  即遇到从未遇到的情况的时候如何去解决</li><li>需要新例子，新角度 </li><li>思维导图在拆分知识，而费曼技巧则是在验证知识 </li></ul><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li>超智能体 公众号-YJango</li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reading </tag>
            
            <tag> thought </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如何成功(From Sam Altman)</title>
      <link href="/%E5%A6%82%E4%BD%95%E6%88%90%E5%8A%9F-From-Sam-Altman/"/>
      <url>/%E5%A6%82%E4%BD%95%E6%88%90%E5%8A%9F-From-Sam-Altman/</url>
      
        <content type="html"><![CDATA[<p>我观察了数以千计的创始人，关于这些人是怎么赚到那么多钱、怎么创造出重要东西的，我思考了很多很多。通常，他们一开始非常想赚大钱，后来变成想要创造出重要的东西。我最终总结了下面的13条，关于如何创造出常人无法企及的成就。</p><p>如果你已经达到了一定的成功（通过天赋或者努力），同时想通过努力把这基本的成功拓展成常人无法企及的成就，下面的这些对你就会容易很多。但其中大部分适用于所有人。</p><h1 id="1-让自己利滚利-复利自身"><a href="#1-让自己利滚利-复利自身" class="headerlink" title="1.让自己利滚利 - 复利自身"></a>1.让自己利滚利 - 复利自身</h1><p>利滚利是个奇迹。你需要随处留意它。指数曲线增长是创造财富的关键。</p><p>每年增长50％的中型企业在很短的时间内将会变得巨大。世界上很少有企业具有真正的网络效应（network effect）和极高的可扩展性。但随着技术的发展，越来越多的企业将会有这个可能。找到实现利滚利的企业，甚至创建出这种企业，是值得花费精力去做的。</p><p>你自己也要追求指数速度增长 - 你应该把不断增长的向上和向右的轨迹作为你人生的目标。选择一个可以实现利滚利的职业是很重要的 - 因为大多数职业都是线性增长的。</p><p>你不应该进入一个，那些做了两年的人可以和已经做了二十年的人一样的职业 – 你应该保持在一个一直不断高效学习的状态。随着职业发展，你所完成的每个工作单元都应该产生比以前多的成果。有很多方法可以获得这种杠杆作用，例如资本，技术，品牌，网络效应和人员管理。</p><p>不管你是用何种标准来衡量成功 - 金钱，地位，对世界的影响或其他任何基准，你都应该专注于如何可以把你自己定义的成功翻10倍。<strong>我愿意在项目之间，花费尽可能多的时间来寻找下一个项目</strong>。但我总是希望它成为这样一个项目：<strong>如果成功，将使我职业生涯的其余部分不值得一提</strong>。</p><p>大多数人会陷入寻找线性机会。专注于潜在的可以让你上一个台阶的变化，即使这意味着小机会的流失。</p><p>我认为，无论是对公司还是对个人的职业生涯而言，最大的竞争优势是，<strong>根据全球不同系统将如何融合在一起，做出的长远决定</strong>。关于复利增长，值得注意的一个方面是，<strong>最远的将来会是最重要的</strong>。</p><p>在这样一个几乎没有人真正的用长远的眼光来看待的世界里，市场会给那些这么做的人带来丰厚的回报。相信指数增长，耐心等待，惊喜会等着你。</p><h1 id="2-极度自信"><a href="#2-极度自信" class="headerlink" title="2. 极度自信"></a>2. 极度自信</h1><p>自信是非常强大的。我认识的最成功的人对自己自信得几乎到了妄想的程度。</p><p>尽早培养自信。<br>随着你得到更多可以证明自己判断力上佳的数据点，并且你可以不断地达到理想的结果，你会愈发地相信自己的。</p><p>如果你不相信自己，很难让自己对未来有跟别人不同的想法。但与别人有不同的想法是创造价值的关键所在。</p><p>我记得多年前Elon Musk带我参观了SpaceX工厂。他详细讲述了制造火箭的每一部分，但让我记忆最深刻的事情是他谈到向火星发射大型火箭时脸上的绝对自信。我离开时想“嗯，所以这就是拥有信念的标杆吧。”</p><p>管理自己的士气 - 以及团队的士气 - 是大多数努力中最大的挑战之一。如果没有很多的自信，这几乎是不可能的。不幸的是，你越雄心勃勃，世界就越会试图击垮你。</p><p>大多数极为成功的人，都在被大众质疑之前，对未来有至少一次非常正确的预期。以此来助自己坚定信念，度过这段时间；否则会经历更艰难的一段日子。</p><p>自信需要和自知保持平衡。我曾经讨厌任何形式的批评，并积极地避免他们。现在，我试着在假设这些批评说的是真的情况下，然后决定我是否要对它采取行动。寻求真理，很难并经常是痛苦的，但这是将自信与自我欺骗分开的原因。这种平衡可以帮你避免变得自傲和不接地气。</p><h1 id="3-学会独立思考"><a href="#3-学会独立思考" class="headerlink" title="3. 学会独立思考"></a>3. 学会独立思考</h1><p>创业很难教，因为原创思维很难教。学校的设立不是为了教这个 - 事实上，学校通常会奖励模仿。所以你需要自己去培养独立思考的能力。</p><p>从本质开始思考并尝试产生新想法很有趣，找人交流它们可以让你变得更擅长这件事。下一步需要做的就是找到简单，快速的方法来在现实世界中对其进行测试。</p><p>“我会失败很多次，但是我会有一次正确”，这是创业者的行为方式。你必须给自己很多机会以获得幸运。你需要学习的最重要的一课是，<strong>你可以在这个问题似乎无解的情况下弄清楚该怎么做</strong>。你这样做的次数越多，你就会越相信它。相信你可以在看似山穷水尽，无路可走的情况下，柳暗花明，寻到村庄。 Grit（充满激情的毅力）来自于，你知道你被打倒后可以重新站起来。</p><h1 id="4-擅长“销售”"><a href="#4-擅长“销售”" class="headerlink" title="4. 擅长“销售”"></a>4. 擅长“销售”</h1><p>仅靠自信是不够的 - 你还必须能够让别人相信你所相信的东西。</p><p>在某种程度上，所有成功的事业最后都成为销售工作。你必须向客户，潜在员工，媒体，投资者等宣传你的计划。这需要鼓舞人心的愿景、强大的沟通技巧、某种程度的魅力和证明有执行能力的证据。</p><p>善于沟通 - 特别是书面沟通 - 是值得投资的。我对明确沟通的建议是,首先确保你的思路清晰，然后使用简洁明了的语言。</p><p>擅长销售的最佳方式是<strong>真正相信你所销售的产品</strong>。卖你真正相信的东西感觉很棒，试图卖万金油感觉很糟糕。</p><p>提高销售技巧就像改善任何其他技能一样 - 任何人都可以通过刻意练习来改善它。但出于某种原因，也许是因为它令人反感，许多人认为销售技巧是天生的，无法后天学会的。</p><h1 id="5-把风险变的更容易承担"><a href="#5-把风险变的更容易承担" class="headerlink" title="5. 把风险变的更容易承担"></a>5. 把风险变的更容易承担</h1><p>大多数人高估风险并低估奖励。冒险很重要，因为不可能一直都是正确的 - 你必须尝试很多事情并在你学到更多东西时迅速适应。</p><p>在你的职业生涯早期，冒险往往更容易; 你没有太多损失，但是可能会有很多收获。</p><p>一旦你达到了要承担基本义务的程度，你就应该尽量让冒险的损失减小。去寻找如果赌错了会失去1倍，但是如果它有效的话可以翻100倍的小赌注。然后在获利后，在那个方向上做出更大的赌注。</p><p>但是，不要储蓄太久。在YC，我们经常注意到创始人有这样的问题，他们花了很多时间在谷歌或脸书工作。当人们习惯了舒适的生活，可预测到未来的工作，以及在他们在所做的事情上取得成功的声誉时，就变的非常难将这些抛在身后（而且，神奇的是，人们总是能够将他们的生活方式与明年的薪水相匹配）。即使他们离开，回归的诱惑也很大。因为人性，<strong>人们往往会将短期的收益和便利优先于长期的成就</strong>。</p><p>但是当你不在跑步机上被带着跑时，你可以追随你的灵感并花时间去做一些可能会非常有趣的事情。尽可能长时间地保持你的生活低成本和灵活是一种强有力的方法，但显然会有得失。</p><h1 id="6-专注"><a href="#6-专注" class="headerlink" title="6.专注"></a>6.专注</h1><p>专注可以让你事半功倍。</p><p>几乎所有我见过的人，如果他们花更多时间思考要专注在什么事情上，都会有更好的结果。</p><p>做对的事比花更多时间做事更重要。大多数人把大部分时间浪费在无关紧要的事情上。</p><p>一旦你弄清楚要做什么，就抛开一切，快速地完成那些优先级最高的任务。我还没有遇到一个行动缓慢的人非常成功。</p><h1 id="7-努力工作"><a href="#7-努力工作" class="headerlink" title="7.努力工作"></a>7.努力工作</h1><p>通过聪明或努力工作，你可以超过你所在领域的90%的人，这是一项伟大的成就。但要超过99%的人，你两个都需要 - 你的竞争对手将是非常有才能的人，他们有很好的想法，并愿意付出很多努力。</p><p>不同寻常的人得到不同寻常的结果。工作时间很长，意味着关于生活上的巨大的取舍，决定不这样做是完全理性的。但力行工作有很多优点。在大多数情况下，进步会累积，成功会带来更多的成功。</p><p>通常这个过程还是很有趣的。生活中最大的乐趣之一就是找到你的目标，并在这上面努力，然后发现你可以带来远比自己想象中更大的影响。一位YC创始人在离开一家大公司后，对力求获得最大影响的过程感到的愉快和满足感十分惊讶。追寻自己的目标，并为之努力，是极其值得的。</p><p>我不完全清楚为什么努力工作在美国的某些地方变成了坏事，但在世界其他地方肯定不是这样 - 美国以外的创业者所展示的能量和动力正在很快成为新的榜样。</p><p>你必须弄清楚如何努力工作而不会透支。不同的人有自己不同的方法，但几乎总是有效的方法是，找到你喜欢的工作，和你愿意长时间一起工作的人。</p><p>我认为那些，假装没有把大部分时间花在工作上，但是可以在从事的领域非常成功的人，是有害的。事实上，持之以恒的工作，从长期来看可能是可以成功的最重要的原因之一。</p><p>还有一个关于努力工作的想法：在你的事业刚开始时就要努力工作。努力工作就像复利，越早做，你就有越多时间获取收益。当你有更少其他责任时，也更容易专注于用心工作。者往往发生在你年轻的时候。</p><h1 id="8-大胆"><a href="#8-大胆" class="headerlink" title="8.大胆"></a>8.大胆</h1><p>我认为做一个难的创业公司比简单的创业公司更容易。人们希望成为令人兴奋的事物的一部分，并感受到他们的工作的重要性。</p><p>如果你在一个重要问题上取得进展，那么将不断的会有人想来帮助你。让自己变得更加有野心，不要害怕为你真正想要的工作而努力。</p><p>如果其他人都在创办互相模仿的公司，但是你想创办一家完全创新的公司，那么就这样做，不要辗转反侧。跟随你的好奇心。看起来令你兴奋的事情对其他人来说也常常令人兴奋。</p><h1 id="9-意志力"><a href="#9-意志力" class="headerlink" title="9. 意志力"></a>9. 意志力</h1><p>一个很大的秘密就是，大部分时间，这个世界会以你的意志为转移 - 大多数人甚至都不会尝试，只是接受现在世界的运行方式。</p><p>人们有巨大的能力来实现目标。自我怀疑，过早放弃，和没有尽全力推动，种种原因的结合，阻止了大多数人挖掘出他们的所有潜力。</p><p><strong>问问你自己想要什么</strong>。通常不会如意，而且这种求而不得往往非常痛苦的。但是当你努力想去实现自己的目标，往往你能够实现。</p><p>几乎所有时候，那些说“<strong>我将继续坚持直到成功，并且无论面临什么挑战，我都要搞定</strong>”并且认真这么说的人，都会变成功。他们的坚持不懈总会有一次碰到好运的。</p><blockquote><p>I am going to keep going until this works, and no matter what the challenges are I’m going to figure them out. </p></blockquote><p>爱彼迎是我的标杆。他们告诉我了很多故事，虽然我不建议大家模仿（刷爆很多信用卡，每餐吃一美元商店的麦片，不断的与根深蒂固的思维做斗争，等等，等等）但他们设法存活了足够长的时间以便运气找到他们。</p><p>要有梦想，有意志力，你必须保持乐观 - 这是一种可以通过练习而改善的人格特质。我从未见过一个非常成功的悲观主义者。</p><h1 id="10-让别人很难与你竞争"><a href="#10-让别人很难与你竞争" class="headerlink" title="10. 让别人很难与你竞争"></a>10. 让别人很难与你竞争</h1><p>大多数人都明白，如果一个公司在一个领域难以匹敌，那么这个公司就更有价值。这点很重要，也很明显着实是这样的。</p><p>但这对你个人来说也是如此。如果你做的事情可以由其他人完成，那么最终会变成谁要更少的钱来完成。 </p><p>变得难以与之竞争的最佳方式是<strong>建立话语权</strong>。例如，你可以通过建立<strong>强大的个人品牌</strong>，或通过<strong>擅长多个不同领域的交叉</strong>来实现个人关系。还有很多其他策略，但你必须找到一些方法来做到这一点。</p><p>物以类聚，人以群分。大部分人会被身边相处的人的行为方式所影响，这种模仿/影响行为通常是一个错误 - 如果你正在做其他人正在做的事情，与你竞争将不会很难。</p><h1 id="11-建立人脉"><a href="#11-建立人脉" class="headerlink" title="11. 建立人脉"></a>11. 建立人脉</h1><p>出色的工作需要团队。建立一个有才能的人才网络 - 有时是密切的，有时是松散的 - 是事业成功的重要组成部分。你认识的真正有才华的人的规模通常会成为你可以实现的目标的限制因素。</p><p>建立人脉的有效方法是尽可能多地帮助别人。长期的这么做，让我获得了我最好的职场机会和我四项最佳投资中的三项。让我不断惊讶的是，很多好事发生在我身上，竟然是因为多年前我帮助过一些创始人。</p><p>建立人脉的最佳方式之一是，建立一个与你合作的人<strong>都不会被亏待的名声</strong>。<strong>慷慨甚至过度的分享</strong>好处; 它会给你带来10倍的回报。此外，++学习如何评估人们的优点，并让他们做自己擅长的事情++。 （这是我学到的关于管理的最重要的事情，我并没有读过很多关于这方面的书。）<strong>你想要推动员工，并使他们达到的成就超出他们的预期，但同时并不会让员工感到透支</strong>。</p><p>每个人都有比其他人更擅长的事情。用你的优势而不是你的弱点来定义自己。++承认你的弱点并弄清楚如何解决它们++，但不要让它们阻止你去做你想做的事情。我很吃惊我经常从创业者口中听到 “我不能做A，因为我不擅长B”，这几乎总是能反映出这个创业者缺乏创造力。弥补你的弱点的最好方法是聘请互补的团队成员，而不是雇用跟你擅长同样事情的人。 </p><p>在建立人脉中，一个特别有用的方法是善于发现未被发掘的人才。通过练习，快速发掘高智商，有动力和有创造力的人才会变得越来越容易。最简单的学习方法就是与很多人见面，并持续记录谁让你佩服，印象深刻，谁让你觉得不会留下什么的印象。记住，你的目的是<strong>寻找进步速度最快</strong>的人，不要高估经验和目前的成就。</p><p>当我遇到一个新的人时，我总是会问自己“这个人有异于常人的能力吗？”这对于寻找有可能完成伟大事业的人来说是一个非常好的方法。</p><p>建立人脉的一个特别的方式就是，找到<strong>愿意在你身上下赌注的人</strong>，最好是在你职业生涯的早期。毫无疑问，做到这一点的最好方法就是<strong>尽全力</strong>。 （并且请记住，你必须在以后的某个时候回报！） 最后，记住要花时间与支持你抱负的积极的人在一起。</p><h1 id="12-你通过拥有东西来致富"><a href="#12-你通过拥有东西来致富" class="headerlink" title="12 你通过拥有东西来致富"></a>12 你通过拥有东西来致富</h1><p>童年时代，我对经济最大的误解是，人们利用高薪来致富。虽然有一些例外 - 例如艺人 - 但是在福布斯榜单的历史上，几乎没有任何人是靠工资上榜的。</p><p><strong>通过拥有价值可以迅速增长的东西</strong>，你变得真正富裕起来。 </p><p>这可以是一部分生意，房地产，自然资源，知识产权或其他类似东西。但不管怎样，你需要拥有这些东西的股份，而不仅仅是卖掉你的时间。<strong>时间只能线性增长</strong>。 使东西价值迅速增长的最好方法是<strong>大规模创造人们想要的东西</strong>。</p><h1 id="13-自我驱动"><a href="#13-自我驱动" class="headerlink" title="13. 自我驱动"></a>13. 自我驱动</h1><p>大多数人是主要靠外部驱动的;他们做事，是因为他们想要让别人佩服。这么做有很多不好的原因，但这有两个点最重要。</p><p>首先，你会去做大家达成共识的想法和达成共识的职业。你会非常关心 - 远比比你意识到的要多得多 - 其他人是否认为你做的是正确的事情。这可能会阻止你做一些真正有趣的工作，即使你最终决定这样做，其他人也可能早已这样做了。</p><p>其次，你通常会对风险判断错误。你会非常专注于跟上其他人，在对抗竞争中不至于落后，甚至难以容忍短期暂时性的落后。</p><p> 聪明的人似乎特别容易受到外部驱动行为的影响。要意识到这一点，它虽然是有帮助的，但是极其有限。你可能必须超级努力工作，才能不陷入模仿别人的陷阱。</p><p>我认识的最成功的人主要是自我驱动的；++<strong>他们做他们所做的事情，来让自己佩服(impress themselved)，因为他们觉得自己有使命去改变这个世界。</strong>++</p><p>当你赚到足够的钱，可以想买什么就买什么，并获得足够的社会地位后，拥有的更多就不再有趣了。</p><p>自我驱动是我所知道的唯一能够持续推动你达到更高水平的力量。</p><p>这就是为什么一个人的动机问题非常重要。这是我尝试了解一个人的第一件事。正确的动机很难用一套规则来定义，但是当你见到它时，你就会知道。</p><p>在这件事上，杰西卡·利文斯顿和保罗·格雷厄姆是我的标杆。 YC在最初几年被很多人嘲笑，在他们刚开始的时候，几乎没有人认为他们会取得成功。但是他们认为，如果做成了，这件事会对世界将非常有好处。他们喜欢帮助人们，他们相信他们的新模式比现有的模式更好。</p><p>最终，你对成功的定义将会是，在对你来说重要的领域中，作出出色的工作。你越早开始朝这个方向努力，你就能走的越远。如果你做的事情不让你痴迷，你将很难获得巨大的成功。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="http://blog.samaltman.com/how-to-be-successful" target="_blank" rel="noopener">http://blog.samaltman.com/how-to-be-successful</a></p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reading </tag>
            
            <tag> Sam Altman </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>创造估值上亿的公司的方式们(share)</title>
      <link href="/%E5%88%9B%E9%80%A0%E4%BC%B0%E5%80%BC%E4%B8%8A%E4%BA%BF%E7%9A%84%E5%85%AC%E5%8F%B8%E7%9A%84%E6%96%B9%E5%BC%8F%E4%BB%AC-share/"/>
      <url>/%E5%88%9B%E9%80%A0%E4%BC%B0%E5%80%BC%E4%B8%8A%E4%BA%BF%E7%9A%84%E5%85%AC%E5%8F%B8%E7%9A%84%E6%96%B9%E5%BC%8F%E4%BB%AC-share/</url>
      
        <content type="html"><![CDATA[<p>纯分享，只是觉得这几篇文章实在是太有意思，作者2014年10月份写了第一篇，11月写了第二篇，然后再2019年又再度思考，看了下自己的思路是否还是正确的，整个脉络超级清晰。</p><p>每篇文章基本上都是在自己的更为成熟的认知的基础上对于运作方式进行更细的拆分，假设我们要做一个每年收入一亿美元的公司，我们能够通过何种方式进行盈利呢？ </p><ul><li>1,000 个企业用户，每家每年付给你10万美元</li><li>10,000个中等大小公司，每年付1万美元</li><li>100,000个小商户，每年付1000美元</li><li>1,000,000个人用户，每年每人付100美元</li><li>10,000,000个人用户，通过广告从每人获得10美元</li></ul><p>Open questions: 哪一种更适合自己呢？lol</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>不断更新，尤其是五年以后的更新很发人身省啊！ </p><ol><li><p><a href="http://christophjanz.blogspot.com/2014/10/five-ways-to-build-100-million-business.html" target="_blank" rel="noopener">http://christophjanz.blogspot.com/2014/10/five-ways-to-build-100-million-business.html</a></p></li><li><p><a href="http://christophjanz.blogspot.com/2014/11/three-more-ways-to-build-100-million.html" target="_blank" rel="noopener">http://christophjanz.blogspot.com/2014/11/three-more-ways-to-build-100-million.html</a></p></li><li><p><a href="http://christophjanz.blogspot.com/2019/" target="_blank" rel="noopener">http://christophjanz.blogspot.com/2019/</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thought </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于2019</title>
      <link href="/%E5%85%B3%E4%BA%8E2019/"/>
      <url>/%E5%85%B3%E4%BA%8E2019/</url>
      
        <content type="html"><![CDATA[<p>写于2018年底</p><p>按照一般的节奏，每年年末总会有对于这一年的反思，哀婉/ 后悔/ 叹息/ 遗憾 或者是 对于闪光点的激动/ 自豪/ 喜悦。然后表一波决心，立一堆flag，期盼在2019年不知道怎么的自己就能够有翻天覆地的变化。 </p><p>这次倒是不想这么写了，感觉，我们对于成功或者失败的归因往往是我们希望看到的归因，往往和旁观者的认知/ 观点有很大的区别。习惯性地认为成功是因为努力，失败是因为客观因素的不可抗。亦或者，归的因还是浮于表面，拿着一个果当做因，自然无法改变真正的果了。问题来了，到底是自上而下，从你希望的大目标来开始想这些问题；还是自下而上，尽力去剖析自己来的实在？  </p><p>现在的自己，觉得是，自下而上(自己)是源，自然来得更实在，能够看清自己自然能把大部分问题都解决掉；只是因为缺乏这种面对本我的能力，不得不选择自上而下的方式——无法直接看清本我，那只能通过镜面隐隐约约窥探下自己到底是什么样子的吧。  </p><p>所以，在努力了N次剖析自己失败以后，选择写这样一篇文章，提出这样一些问题，明白自己内心的渴望，每周都看一看，是否走得近一些了。 </p><p>HHHHH，这里只列问题 😉 欢迎线下一起聊天，一起探索哇！ 很喜欢分享这些的感觉~ (Email: <a href="mailto:stone2paul@gmail.com">stone2paul@gmail.com</a>) </p><p>问题主要分为七个部分：职场、人际关系、健康、财务、个人发展、环境和生活方式。 </p><h1 id="1-职场"><a href="#1-职场" class="headerlink" title="1.职场"></a>1.职场</h1><h4 id="1-1-你将如何谋生？"><a href="#1-1-你将如何谋生？" class="headerlink" title="1.1 你将如何谋生？"></a>1.1 你将如何谋生？</h4><h4 id="1-2-在你的职业或事业中，你认为自己处于什么水平？"><a href="#1-2-在你的职业或事业中，你认为自己处于什么水平？" class="headerlink" title="1.2 在你的职业或事业中，你认为自己处于什么水平？"></a>1.2 在你的职业或事业中，你认为自己处于什么水平？</h4><h4 id="1-3-在未来的五年里，你会取得什么成就来证明你对自己水平的判断是合理的？"><a href="#1-3-在未来的五年里，你会取得什么成就来证明你对自己水平的判断是合理的？" class="headerlink" title="1.3 在未来的五年里，你会取得什么成就来证明你对自己水平的判断是合理的？"></a>1.3 在未来的五年里，你会取得什么成就来证明你对自己水平的判断是合理的？</h4><h4 id="1-4-你克服了哪些障碍？"><a href="#1-4-你克服了哪些障碍？" class="headerlink" title="1.4 你克服了哪些障碍？"></a>1.4 你克服了哪些障碍？</h4><h4 id="1-5-你的职业理想中还缺少什么？或者，你下一步想实现什么？"><a href="#1-5-你的职业理想中还缺少什么？或者，你下一步想实现什么？" class="headerlink" title="1.5 你的职业理想中还缺少什么？或者，你下一步想实现什么？"></a>1.5 你的职业理想中还缺少什么？或者，你下一步想实现什么？</h4><h1 id="2-人际关系"><a href="#2-人际关系" class="headerlink" title="2. 人际关系"></a>2. 人际关系</h1><h4 id="2-1-五年后你的感情状况如何？"><a href="#2-1-五年后你的感情状况如何？" class="headerlink" title="2.1 五年后你的感情状况如何？"></a>2.1 五年后你的感情状况如何？</h4><h4 id="2-2-从现在到五年后会发生什么来证明你对未来的预期是合理的？"><a href="#2-2-从现在到五年后会发生什么来证明你对未来的预期是合理的？" class="headerlink" title="2.2 从现在到五年后会发生什么来证明你对未来的预期是合理的？"></a>2.2 从现在到五年后会发生什么来证明你对未来的预期是合理的？</h4><h4 id="2-3-你交了哪些新朋友？他们是什么样的？是什么让你想和他们成为朋友？"><a href="#2-3-你交了哪些新朋友？他们是什么样的？是什么让你想和他们成为朋友？" class="headerlink" title="2.3 你交了哪些新朋友？他们是什么样的？是什么让你想和他们成为朋友？"></a>2.3 你交了哪些新朋友？他们是什么样的？是什么让你想和他们成为朋友？</h4><h4 id="2-4-你克服了哪些人际关系上的障碍？"><a href="#2-4-你克服了哪些人际关系上的障碍？" class="headerlink" title="2.4 你克服了哪些人际关系上的障碍？"></a>2.4 你克服了哪些人际关系上的障碍？</h4><h4 id="2-5-你的家庭关系是什么样的？"><a href="#2-5-你的家庭关系是什么样的？" class="headerlink" title="2.5 你的家庭关系是什么样的？"></a>2.5 你的家庭关系是什么样的？</h4><h4 id="2-6-你的各种关系中还缺少什么？"><a href="#2-6-你的各种关系中还缺少什么？" class="headerlink" title="2.6 你的各种关系中还缺少什么？"></a>2.6 你的各种关系中还缺少什么？</h4><h1 id="3-健康"><a href="#3-健康" class="headerlink" title="3. 健康"></a>3. 健康</h1><h4 id="3-1-为了保持或改善你的健康，你是如何安排自己的饮食结构的？"><a href="#3-1-为了保持或改善你的健康，你是如何安排自己的饮食结构的？" class="headerlink" title="3.1 为了保持或改善你的健康，你是如何安排自己的饮食结构的？"></a>3.1 为了保持或改善你的健康，你是如何安排自己的饮食结构的？</h4><h4 id="3-2-为了保持或改善你的健康，你是否进行了锻炼？"><a href="#3-2-为了保持或改善你的健康，你是否进行了锻炼？" class="headerlink" title="3.2 为了保持或改善你的健康，你是否进行了锻炼？"></a>3.2 为了保持或改善你的健康，你是否进行了锻炼？</h4><h4 id="3-3-你改善健康的愿望是如何影响你生活中的选择的？"><a href="#3-3-你改善健康的愿望是如何影响你生活中的选择的？" class="headerlink" title="3.3 你改善健康的愿望是如何影响你生活中的选择的？"></a>3.3 你改善健康的愿望是如何影响你生活中的选择的？</h4><h4 id="3-4-你克服了哪些主要障碍？"><a href="#3-4-你克服了哪些主要障碍？" class="headerlink" title="3.4 你克服了哪些主要障碍？"></a>3.4 你克服了哪些主要障碍？</h4><h4 id="3-5-就你的健康状况而言，你还需要达到哪些目标？或者，你下一步想要实现什么？"><a href="#3-5-就你的健康状况而言，你还需要达到哪些目标？或者，你下一步想要实现什么？" class="headerlink" title="3.5 就你的健康状况而言，你还需要达到哪些目标？或者，你下一步想要实现什么？"></a>3.5 就你的健康状况而言，你还需要达到哪些目标？或者，你下一步想要实现什么？</h4><h1 id="4-财务"><a href="#4-财务" class="headerlink" title="4. 财务"></a>4. 财务</h1><h4 id="4-1-你的个人资产状况（资产、负债、现金流）是什么样的？"><a href="#4-1-你的个人资产状况（资产、负债、现金流）是什么样的？" class="headerlink" title="4.1 你的个人资产状况（资产、负债、现金流）是什么样的？"></a>4.1 你的个人资产状况（资产、负债、现金流）是什么样的？</h4><h4 id="4-2-无论你的财务目标是什么（持有现金、应急基金、为退休做准备、为大学攒学费、再买一套房等等），你都采取了哪些措施？"><a href="#4-2-无论你的财务目标是什么（持有现金、应急基金、为退休做准备、为大学攒学费、再买一套房等等），你都采取了哪些措施？" class="headerlink" title="4.2 无论你的财务目标是什么（持有现金、应急基金、为退休做准备、为大学攒学费、再买一套房等等），你都采取了哪些措施？"></a>4.2 无论你的财务目标是什么（持有现金、应急基金、为退休做准备、为大学攒学费、再买一套房等等），你都采取了哪些措施？</h4><h4 id="4-3-你每个月赚多少钱？"><a href="#4-3-你每个月赚多少钱？" class="headerlink" title="4.3 你每个月赚多少钱？"></a>4.3 你每个月赚多少钱？</h4><h4 id="4-4-从现在到将来会发生什么来证明这些收入是合理的？"><a href="#4-4-从现在到将来会发生什么来证明这些收入是合理的？" class="headerlink" title="4.4 从现在到将来会发生什么来证明这些收入是合理的？"></a>4.4 从现在到将来会发生什么来证明这些收入是合理的？</h4><h4 id="4-5-从现在起的五年内，你会达到哪些重要的财务里程碑？"><a href="#4-5-从现在起的五年内，你会达到哪些重要的财务里程碑？" class="headerlink" title="4.5 从现在起的五年内，你会达到哪些重要的财务里程碑？"></a>4.5 从现在起的五年内，你会达到哪些重要的财务里程碑？</h4><h4 id="4-6-你还有哪些财务目标有待实现？"><a href="#4-6-你还有哪些财务目标有待实现？" class="headerlink" title="4.6 你还有哪些财务目标有待实现？"></a>4.6 你还有哪些财务目标有待实现？</h4><h1 id="5-个人发展"><a href="#5-个人发展" class="headerlink" title="5. 个人发展"></a>5. 个人发展</h1><h4 id="5-1-你每天或每周都会做哪些精神实践？它们有没有成为你生活中的一部分？"><a href="#5-1-你每天或每周都会做哪些精神实践？它们有没有成为你生活中的一部分？" class="headerlink" title="5.1 你每天或每周都会做哪些精神实践？它们有没有成为你生活中的一部分？"></a>5.1 你每天或每周都会做哪些精神实践？它们有没有成为你生活中的一部分？</h4><h4 id="5-2-你还学习了什么技能？"><a href="#5-2-你还学习了什么技能？" class="headerlink" title="5.2 你还学习了什么技能？"></a>5.2 你还学习了什么技能？</h4><h4 id="5-3-在未来的五年里，你有哪些学习机会？"><a href="#5-3-在未来的五年里，你有哪些学习机会？" class="headerlink" title="5.3 在未来的五年里，你有哪些学习机会？"></a>5.3 在未来的五年里，你有哪些学习机会？</h4><h4 id="5-4-你尝试过哪些个人发展实践，但不喜欢？"><a href="#5-4-你尝试过哪些个人发展实践，但不喜欢？" class="headerlink" title="5.4 你尝试过哪些个人发展实践，但不喜欢？"></a>5.4 你尝试过哪些个人发展实践，但不喜欢？</h4><h4 id="5-5-你进行个人发展实践的原因是什么？"><a href="#5-5-你进行个人发展实践的原因是什么？" class="headerlink" title="5.5 你进行个人发展实践的原因是什么？"></a>5.5 你进行个人发展实践的原因是什么？</h4><h4 id="5-6-你希望在个人发展方面取得什么成就？"><a href="#5-6-你希望在个人发展方面取得什么成就？" class="headerlink" title="5.6 你希望在个人发展方面取得什么成就？"></a>5.6 你希望在个人发展方面取得什么成就？</h4><h1 id="6-环境"><a href="#6-环境" class="headerlink" title="6. 环境"></a>6. 环境</h1><h4 id="6-1-你住在哪里？"><a href="#6-1-你住在哪里？" class="headerlink" title="6.1 你住在哪里？"></a>6.1 你住在哪里？</h4><h4 id="6-2-你住的地方气候怎么样？"><a href="#6-2-你住的地方气候怎么样？" class="headerlink" title="6.2 你住的地方气候怎么样？"></a>6.2 你住的地方气候怎么样？</h4><h4 id="6-3-描述一下你的家。是房子还是公寓？"><a href="#6-3-描述一下你的家。是房子还是公寓？" class="headerlink" title="6.3 描述一下你的家。是房子还是公寓？"></a>6.3 描述一下你的家。是房子还是公寓？</h4><h4 id="6-4-房子是怎么装修的？"><a href="#6-4-房子是怎么装修的？" class="headerlink" title="6.4 房子是怎么装修的？"></a>6.4 房子是怎么装修的？</h4><h4 id="6-5-如果你一直住在这间房子里，从未搬家过，你后面还做了哪些装修？"><a href="#6-5-如果你一直住在这间房子里，从未搬家过，你后面还做了哪些装修？" class="headerlink" title="6.5 如果你一直住在这间房子里，从未搬家过，你后面还做了哪些装修？"></a>6.5 如果你一直住在这间房子里，从未搬家过，你后面还做了哪些装修？</h4><h4 id="6-6-谁和你住在一起？"><a href="#6-6-谁和你住在一起？" class="headerlink" title="6.6 谁和你住在一起？"></a>6.6 谁和你住在一起？</h4><h1 id="7-生活方式"><a href="#7-生活方式" class="headerlink" title="7. 生活方式"></a>7. 生活方式</h1><h4 id="7-1-你周末、晚上、下班后都有什么娱乐或者消遣活动？"><a href="#7-1-你周末、晚上、下班后都有什么娱乐或者消遣活动？" class="headerlink" title="7.1 你周末、晚上、下班后都有什么娱乐或者消遣活动？"></a>7.1 你周末、晚上、下班后都有什么娱乐或者消遣活动？</h4><h4 id="7-2-你有汽车吗？哪种汽车？如果没有，你有什么打算？"><a href="#7-2-你有汽车吗？哪种汽车？如果没有，你有什么打算？" class="headerlink" title="7.2 你有汽车吗？哪种汽车？如果没有，你有什么打算？"></a>7.2 你有汽车吗？哪种汽车？如果没有，你有什么打算？</h4><h4 id="7-3-你平时上班、休息日或外出时的穿衣打扮是什么样的？"><a href="#7-3-你平时上班、休息日或外出时的穿衣打扮是什么样的？" class="headerlink" title="7.3 你平时上班、休息日或外出时的穿衣打扮是什么样的？"></a>7.3 你平时上班、休息日或外出时的穿衣打扮是什么样的？</h4><h4 id="7-4-你最珍视的物质财富是什么？"><a href="#7-4-你最珍视的物质财富是什么？" class="headerlink" title="7.4 你最珍视的物质财富是什么？"></a>7.4 你最珍视的物质财富是什么？</h4><h4 id="7-5-你去哪里度假了？"><a href="#7-5-你去哪里度假了？" class="headerlink" title="7.5 你去哪里度假了？"></a>7.5 你去哪里度假了？</h4><h4 id="7-6-如果你有孩子，你会和他们一起做什么活动？"><a href="#7-6-如果你有孩子，你会和他们一起做什么活动？" class="headerlink" title="7.6 如果你有孩子，你会和他们一起做什么活动？"></a>7.6 如果你有孩子，你会和他们一起做什么活动？</h4><h4 id="7-7-你养宠物了吗？如果养了，是什么宠物？"><a href="#7-7-你养宠物了吗？如果养了，是什么宠物？" class="headerlink" title="7.7 你养宠物了吗？如果养了，是什么宠物？"></a>7.7 你养宠物了吗？如果养了，是什么宠物？</h4><h4 id="7-8-你还想要什么样的生活方式？"><a href="#7-8-你还想要什么样的生活方式？" class="headerlink" title="7.8 你还想要什么样的生活方式？"></a>7.8 你还想要什么样的生活方式？</h4><h1 id="8-写下你的故事"><a href="#8-写下你的故事" class="headerlink" title="8. 写下你的故事"></a>8. 写下你的故事</h1><p>这么多问题，你回答的还开心吗？接下来才是超级有趣的部分——想象自己五年后的样子，然后把它写下来。假设今天是周五晚上——周五是一个有用的假设，因为它能有效地体现生活方式，这一天既包括工作，也包括了典型的休闲活动。<br>再假设你刚醒过来。你在哪里？你可以描述自己卧室的情况。房子是怎么装修的？接下来描述你的一天的时间记得多一点细节。想象一下你去洗手间刷牙，下楼倒杯咖啡的情景（你可能没这个习惯，但我确实每天都是这样的）。这是一个你如何思考“过程”的例子。一定要写一些关于你的感受的小事。也许两周后你会有一个假期，也许你今天就能拿到报酬。把你的想法写下来可以让你把一天中不一定会发生的事情记起来。<br>写下你如何去上班（除非你在家工作），写下你的每天工作的情况，包括与你打交道的人的轶事和他们的各种特点。这些花边新闻让你的故事感觉真实。如果你需要更多信息，可以参考前面问题的答案。确保你的故事里包含了所有7个类别的信息。你的故事要一直写到你一天结束的时候。</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> thought </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>今日简史-致敬充满未知的世界</title>
      <link href="/%E4%BB%8A%E6%97%A5%E7%AE%80%E5%8F%B2-%E8%87%B4%E6%95%AC%E5%85%85%E6%BB%A1%E6%9C%AA%E7%9F%A5%E7%9A%84%E4%B8%96%E7%95%8C/"/>
      <url>/%E4%BB%8A%E6%97%A5%E7%AE%80%E5%8F%B2-%E8%87%B4%E6%95%AC%E5%85%85%E6%BB%A1%E6%9C%AA%E7%9F%A5%E7%9A%84%E4%B8%96%E7%95%8C/</url>
      
        <content type="html"><![CDATA[<p>作者在这本书里探讨了很多现世的问题，也给出一些自己的探知觉察的方式，几个非常有意思的问题。</p><h1 id="1-科技会如何颠覆整个社会？"><a href="#1-科技会如何颠覆整个社会？" class="headerlink" title="1. 科技会如何颠覆整个社会？"></a>1. 科技会如何颠覆整个社会？</h1><p>逻辑链条： </p><ol><li>人工智能的飞速发展，大数据对于人的精确分析</li><li>自动驾驶 - 使驾驶员失业</li><li>大数据 - 精确的用户画像，使算法比人自己更了解自己。传统的广告业，投资行业的运行方式会发生改变，权威(决定权)转移给算法</li><li>大量低技术含量的职业消失，大量人失业</li><li>当技术再继续发展，会不会有一天可以推行出最针对个人的设计？最能刺激你某种情绪的出现的视频，文章，音乐，图像？ </li><li>如果5成立的话，某种程度上你失去了对自己的控制，因为你所构建判断的所有信息是被筛选出来有特定导向的。</li><li>被控制…     很像《美丽新世界》</li><li>政府如何解决安抚大量失业的人呢？减速技术的革新？给予人最基础的保障和服务（共产主义）？提供足够多的保障基本生活的资金？（芬兰正在做这样的实验）</li><li>基因生物技术的迅猛发展，会不会给少部分人改变自己的基因的机会？改变基因，改变性状，渐渐出现不同的物种，超级人和一般人？ </li></ol><p>上述一切都是推论，但是不能否认确实存在这种可能，而且技术的进步速度着实很快。谁能在2009年用着傻瓜机的时代想象到今日我们的技术水平呢？</p><h1 id="2-人工智能有可能控制人类么？"><a href="#2-人工智能有可能控制人类么？" class="headerlink" title="2. 人工智能有可能控制人类么？"></a>2. 人工智能有可能控制人类么？</h1><p>这里其实需要对大脑和意识做个区分。现在的机器做的事情是大脑做的事情，即通过各种神经元的连接，各种电信号的刺激，根据输入的事物的特征，给出针对性的反应。这其实是一个很有逻辑的过程。</p><p>但是人工智能控制人类这个问题，实质上是在问，人工智能有可能产生自己的意识么？ </p><p>答案在目前看，是不知道… 因为我们现在也并不知道大脑是如何产生各种情绪的，为什么大脑的这种活动热点区域(heatmap)能够喜悦，而另外一种能够生成愤怒？ 我们不知道，二者之间现在无法证明有着任何的因果关系，因为我们不知道意识是如何产生的，又是如何产生作用的。</p><p>现在为数不多的观察意识/心智的方式就是冥想，但是这也只是尽量直接的观察自己的意识的一种方式，我们无法直接观察他人心智来进行研究。</p><p>我们现在认为身边的人有意识更多是一种推己及人，因为我知道自己有意识，而身旁的人和我有很类似的行为特征，因此有理由认为大家都有意识。（但是是不是会很楚门的世界呢？？？？！！！）</p><h1 id="3-人生的意义？"><a href="#3-人生的意义？" class="headerlink" title="3. 人生的意义？"></a>3. 人生的意义？</h1><p>人生的意义？ 某种循环，而我们知识在执行某种赋予我们的角色，让这个循环一直稳定下去？ 我觉得更应该说不是个循环，因为这些都是螺旋上升的，无论是人的认知，还是整个社会的状态，科技环境，这种上升是会把我们所处的整个环境不断推向新的状态的，人与人之间的关系，龃龉，友善，倒是没有大的区别。</p><p>宗教在赋予每个人的人生特定的意义，是线性的生活/世界，还是一个循环的状态。</p><p>用故事来诉说自己的人生的意义，</p><p>循环的上一世下一世有什么意义呢？如果没有前人的肩膀，只能一切从头再来… </p><p>那如果我们给自己的家庭赋予一个特定的意义，用各种方式来验证这个世界是什么样子的，来思考世界发展的走向，用各种方式来证明，那会是一个好的选择么？？？？  </p><p>用几代人的时间，来详细的描述我们所经历的时代，从各个角度去研究探求我们的世界会变成什么样子？   —-&gt; 技术，工程，医学，艺术…. 诸如此类，在每个领域都研究的更深更深一些，这样子会好一些么</p><p>研究人性的边界？ 研究人类最终的归宿？ 研究人类如何能和技术和谐共处又不被技术控制？ </p><p>为什么要有故事，要让人活得不空虚啊，为了让人有目标；如何让人相信故事呢？ 靠各种仪式，将抽象变得具体，将虚构变得真实</p><p>献祭使信服，付出使信服。牺牲  — 沉没成本 </p><p>因为人们今日相信的任何神祗或事务，不论是耶和华，还是国家，革命，都并不完整，有很多问题解释不了，充满漏洞。正因为如此，人类很少把所有的信念都投注到单一的故事上，而是有个信念组合，里面有几个不同的故事，几个不同的身份认同可以配合需求任意切换。几乎所有的社会和运动，都有这种认知失调的情形。</p><p>谨慎欺骗，如果政客的话语开始掺杂一些神秘的词句，就该提高警惕。面对真实的痛苦，这些人可能会用某些空泛难解的表达来加以包装，作为申辩。比如<strong><em>牺牲、永恒、纯净、恢复</em></strong>。</p><p>如果真想知道宇宙的真相，人生的意义，自己的身份，最好的出发点是去观察痛苦，探索痛苦的本质。答案永远不会是一个故事。</p><h1 id="4-一些摘录"><a href="#4-一些摘录" class="headerlink" title="4. 一些摘录"></a>4. 一些摘录</h1><p>冥想是一种感受自己的意识的方式</p><p>道德的重点并不是遵守神圣的诫命，而是要减少痛苦。 </p><p>为什么人会关注他人的感受？是否愉快呢？</p><p>因为人是社交动物，自己的幸福与否，在很大程度上取决于与他人的关系。没有爱，没有友谊，没有群体的支持，谁能快乐得起来呢？如果过着孤独，以自我为中心的生活，肯定会感到痛苦。所以想要快乐你至少要关心你的家人、朋友，以及所属社群里的其他人。</p><p>世上所有的暴力行为，必然始于一个人心中的暴力欲望，这种欲望早在扰乱他人的平和幸福之前，就已经扰乱了自己的平和和幸福了。</p><p>我们的道德从哪里来？ 我们的信仰从哪里来？ 我们的智慧从哪里来？   我们解释不了的东西到底是神创造的，还是说，其实只是因为我们不知道呢？？ </p><p>到底是因为神说不应该做什么我们才不做什么？ 还是我们自己就不想那么做，恰好相信一下呢？ 譬如杀人，不做因为我们的道德还是神说不应该杀人呢？ 如果有一天神的现世代言者说，我们要杀光异教徒，信教的人会做出怎样的选择呢？？</p><p>其实站在这些信教的人的角度，好像并没有做错什么？到底前面没有出事情是因为恰巧道德层面的要求和信仰的要求一致，还是是在通过信仰的方式追求自己的道德呢？     颇有点道德信仰谁为第一性的意味。</p><p>正义来自绝对责任，还是结果导向呢？</p><p>可以用意图道德来回避这个问题，重要的是我的意图，而不是我的实际行动以及结果。但是在这个一切都紧密联系的世界中，最重要的道德义务就是人必须要知道各种事情。现代历史中最严重的罪行，不仅源自于仇恨和贪婪，还源自于无知和冷漠。</p><p>结构性偏见，我们只能听到一部分人的声音，而无法听到另外一部分人的。 </p><p>每个人的眼中开始有其自己认为的真相，而无法交融。</p><p>关于如何防止自己被洗脑的法则： </p><ol><li>如果你想得到可靠的消息，必然要付出昂贵的代价。如果你总是免费得到信息，有可能你才是整个商业世界的产品。</li><li>如果觉得某些问题似乎对你特别重要，就该真正努力阅读相关的科学文献。所谓的科学文献，指的是经过同行评审的论文，由知名学术出版社出版的书籍，以及知名教授的著作。</li></ol><p>美丽新世界：默然忍受命运的暴虐的毒箭，或是面对苦海，拿刀做个一了百了。你们既不是默然忍受，也不是一了百了，而只是取消了命运的毒箭，这样未免太简单化了。</p><p>学校或者说教育，现在最不应该教的是信息… 因为这个世界现在的信息实在太多了， 每个人都在接收不停的信息轰炸。这才是这个世界现在最可怕的问题，越来越多的人失去了持续学习，专注学习的能力。要知道想要深入学习一样东西，是需要进入深度专注地状态的，不是手机一震动就去看一眼，遇到不会的就刷刷微博，看看抖音再继续的那种状态。</p><p>学生，或者说教育，更应该教育学生去做的，是4C。</p><ul><li>批判性思考 critical thinking </li><li>沟通 communication </li><li>合作 collaboration </li><li>创意 creativity </li></ul><p>学校不应该太看重特定的工作技能，而要强调通用的生活技能。最重要的是<strong><em>能够随机应变，学习新事物，在不熟悉的环境里仍然能够保持心智平衡</em></strong>。想要跟上2050年的世界，人类不只需要发明新的想法和产品，最重要的是要一次又一次地重塑自己。</p><p>All that is solid melts into air </p><p>这必将是一个需要不断学习的社会了</p><p>工业革命让我们对于教育的想法就像是一条生产线。城镇的中心有一座大型混凝土建筑，每个房间都配有几排桌椅。铃声响起，你就和另外30个一般大的孩子一起走进某个房间。每个小时都会有一个大人走进了说话，而且政府付钱叫他们这么做的。</p><p>到底是我们在控制技术，还是技术在控制我们呢？ </p><p>大多数人其实并不了解自己，打算倾听自己内心的声音时，很容易遭到外部的操控。我们大脑中的那些声音绝对不值得信赖，因为这些声音反应的总是国家的政治宣言、意识形态的洗脑手段和商业广告的殷殷召唤，更别提人体生化机制本来就有缺陷。</p><p>冥想与内观，各种痛苦最深层的来源，就在于自己的心智。如果有什么是我想得到却不可得，心智的反应就是产生痛苦。痛苦并非外部世界的客观庆幸，而是自己心智产生的心理反应。了解这一点就是跨出了第一步，让人不再产生痛苦。</p><p>大脑与心智的奥秘。大脑是由神经元、突触和生化物质组成的实体网络组织，心智则是痛苦、愉快、爱和愤怒等主观体验的流动。</p><p>我们可以研究到大脑活动，但是我们无法研究他人的心智，或者说是意识。对于意识的研究，还是一个黑箱。（其实某种程度上，这是人工智能是否能有意识的决定性因素 – 即意识在人的大脑中是如何产生的)</p><p>如何直观的观察自己的心智，以及如何直观的观察他人的心智。</p><p>冥想实际上是一种直接观察自己的心智的一种方法</p><p>所谓的实际修行，就是要运用系统持续以及客观的方式，观察身体的感觉以及心智对这些感觉的反应，据此来找出心智的基本模式。内观禅修者都会被告诫，不要想去追求什么特殊的体验，而是要专注于了解自己的心智的真实状况，不论这个状况为何。</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reading </tag>
            
            <tag> society </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Food Rules</title>
      <link href="/Food-Rules/"/>
      <url>/Food-Rules/</url>
      
        <content type="html"><![CDATA[<p>Read a book recommended by Doctor, it tells about some food rules mainly focusing on what should we eat, how much should we eat, pretty funny, wanna share some rules here: </p><h1 id="1-What-should-I-eat"><a href="#1-What-should-I-eat" class="headerlink" title="1. What should I eat?"></a>1. What should I eat?</h1><ol><li>Eat food, not “edible foodlike sunstances”. </li><li>Don’t eat anything your great-grandmother wouldn’t recognize as food. </li><li>Avoid food products containing ingredients that no ordinary human would keep in the pantry. </li><li>Avoid food products that contain high-fructose corn syrup. </li><li>Avoid foods that have some form of suger(or sweetener) listed among the top three ingredients. </li><li>Avoid food products that contain more than five ingredients. </li><li>Avoid food products containing ingredients that a third grader connot pronounce. </li><li>Avoid food products that make health claims.</li><li>Avoid food products with the wordoid or the terms low fat or non fat in their names.</li><li>Avoid foods that are pretending to be something they are not. </li><li>Avoid foods you see advertisement on tv. </li><li>Shop the peripheries of the supermarket and stay out of the middle. </li><li>Eat only foods that will eventually rot. </li><li>Eat foods made from ingredients that you can picture in their raw state or growing in nature. </li><li>Get out of the supermarket whenever you can. </li><li>Buy your snacks at the farmers’ market.</li><li>Eat only foods that have been cooked by humans. </li><li>Don’t ingest foods made in places where everyone is required to wear a surgical cap. </li><li>If it came from a plant, eat it; if it was made in a plant, don’t. </li><li>It’s not food if it arrived through the window of your car. </li><li>It’s not food if it’s called by the same name in every language. </li></ol><h1 id="2-What-kind-of-food-should-I-eat"><a href="#2-What-kind-of-food-should-I-eat" class="headerlink" title="2. What kind of food should I eat?"></a>2. What kind of food should I eat?</h1><ol start="22"><li>Eat mostly plants, especially leaves. </li><li>Treat meat as a flavoring or special occasion food. </li><li>Eating waht stands on one leg(mushrooms, plant foods) is better than eating what stands on two legs(fowl), which is better than eating waht stands on four legs. </li><li>Eat your colors. </li><li>Drink the spinach water. </li><li>Eat animals that have themselves eaten well. </li><li>Eat like an omnivore. </li><li>Eat well grown food from healthy soil. </li><li>Eat wild foods when you can. </li><li>Don’t overlook the oily little fishes.</li><li>Eat some foods that have been predigested by bacteria or fungi. </li><li>Sweeten and salt your food yourself. </li><li>Eat sweet foods as you find them in nature. </li><li>Don’t eat breakfast cereals that change the color of the milk. </li><li>The whiter the bread, the sooner you’ll be dead. </li><li>Favor the kinds of oils and grains that have traditionally been stone ground. </li><li>Eat all the junk food you want as long as you cook it yourself. </li><li>Be the kind of person who takes supplements, then skip the supplements. </li><li>Regard nontraditional foods with skeptism.</li><li>Have a glass of win with dinner. </li></ol><h1 id="3-How-should-I-eat"><a href="#3-How-should-I-eat" class="headerlink" title="3. How should I eat?"></a>3. How should I eat?</h1><ol start="42"><li>Pay more, eat less </li><li>Stop eating before you are full. </li><li>Eat when you are hungry, not when you are bored. </li><li>Consult your gut. Eat slowly</li><li>The banquet is in the first bite. </li><li>Spend as much time enjoying the meal as it took to prepare it. </li><li>Buy smaller plates and glasses.</li><li>Serve a proper portion and don’t go back for seconds. </li><li>Breakfast like a king, lunch like a prince, dinner like a pauper. </li><li>Eat meals. </li><li>Limit your snacks to unprocessed plant foods. </li><li>Don’t get your fuel from the same place your car does. hhhhhh</li><li>Do all your eating at a table</li><li>Try not to eat alone. </li><li>Treat treats as treats. </li><li>Leave sth on your plate. </li></ol>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> food </tag>
            
            <tag> diet </tag>
            
            <tag> reading </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS essential(5) - Architecting</title>
      <link href="/AWS-essential-5-Architecting/"/>
      <url>/AWS-essential-5-Architecting/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Introduction-to-well-architected-framework"><a href="#1-Introduction-to-well-architected-framework" class="headerlink" title="1. Introduction to well-architected framework"></a>1. Introduction to well-architected framework</h1><ul><li>developed through reviewing customers’ architectures on AWS </li><li>build and deploy faster </li><li>lower or mitigate risks </li><li>make informed decision </li><li>learn aws best practices </li></ul><h2 id="1-1-Five-Pillars"><a href="#1-1-Five-Pillars" class="headerlink" title="1.1 Five Pillars"></a>1.1 Five Pillars</h2><h3 id="1-1-1-Operational-Excellence"><a href="#1-1-1-Operational-Excellence" class="headerlink" title="1.1.1 Operational Excellence"></a>1.1.1 Operational Excellence</h3><ul><li>Run and monitor systems to deliver business value </li><li>continually improve supporting processes and procedures </li></ul><p>Disign Principles </p><ul><li>perform operations as code </li><li>annotate documentation </li><li>make frequent, small, reversible changes </li><li>refine operations procedures frequently </li><li>anticipate failure </li><li>learn from all operational failures </li></ul><h3 id="1-1-2-Security"><a href="#1-1-2-Security" class="headerlink" title="1.1.2 Security"></a>1.1.2 Security</h3><ul><li>protect information, systems, assets </li><li>do risk assessments and mitigation strategies </li></ul><p>Design Principles </p><ul><li>Implement a strong identity foundation </li><li>enable traceability </li><li>apply security best practices </li><li>automate security best practices </li><li>protect data in transit and at rest </li><li>prepare for security events</li></ul><h3 id="1-1-3-Reliability"><a href="#1-1-3-Reliability" class="headerlink" title="1.1.3 Reliability"></a>1.1.3 Reliability</h3><ul><li>recover from infrastructure or service disruptions </li><li>dynamically acquire computing resources to meet demand </li><li>mitigate disruptions </li></ul><p>Design Principles:</p><ul><li>test recovery procedures </li><li>automatically recover from failure</li><li>scale horizontally to increase aggregate system availability </li><li>stop guessing capacity </li><li>manage change in automation </li></ul><h3 id="1-1-4-Performance-Efficiency"><a href="#1-1-4-Performance-Efficiency" class="headerlink" title="1.1.4 Performance Efficiency"></a>1.1.4 Performance Efficiency</h3><ul><li>use computing resources efficiently </li><li>maintain efficiency as demand changes and technologies evolve </li></ul><p>Design Principles </p><ul><li>Democratize advanced technologies </li><li>Go global in minutes </li><li>use serverless architectures </li><li>Experiment more often </li><li>mechanical sympathy </li></ul><h3 id="1-1-5-Cost-Optimization"><a href="#1-1-5-Cost-Optimization" class="headerlink" title="1.1.5  Cost Optimization"></a>1.1.5  Cost Optimization</h3><ul><li><p>avoid or eliminate unneeded cost or suboptimal resources<br>Design Principles </p></li><li><p>adopt a consumption model </p></li><li><p>measure overall efficiency </p></li><li><p>stop spending money on data center operations </p></li><li><p>analyze and attribute expenditure </p></li><li><p>use managed services to reduce cost of ownership </p></li></ul><h1 id="2-Fault-tolerance-and-highly-available-architecture"><a href="#2-Fault-tolerance-and-highly-available-architecture" class="headerlink" title="2. Fault tolerance and highly available architecture"></a>2. Fault tolerance and highly available architecture</h1><h2 id="2-1-Fault-tolerance"><a href="#2-1-Fault-tolerance" class="headerlink" title="2.1 Fault tolerance"></a>2.1 Fault tolerance</h2><ul><li>remain operational even if components fail </li><li>build-in redundancy of an application’s components</li></ul><h2 id="2-2-High-Availability"><a href="#2-2-High-Availability" class="headerlink" title="2.2 High Availability"></a>2.2 High Availability</h2><ul><li>always functioning and accessible </li><li>downtime is minimized </li><li>without human intervention </li></ul><h2 id="2-3-High-availability-tools"><a href="#2-3-High-availability-tools" class="headerlink" title="2.3 High availability tools"></a>2.3 High availability tools</h2><h3 id="2-3-1-elastic-load-balancers"><a href="#2-3-1-elastic-load-balancers" class="headerlink" title="2.3.1 elastic load balancers"></a>2.3.1 elastic load balancers</h3><p>elb - distribute income traffic to your hosts, also send metrics to cloudwatch </p><h3 id="2-3-2-elastic-IP-addresses"><a href="#2-3-2-elastic-IP-addresses" class="headerlink" title="2.3.2 elastic IP addresses"></a>2.3.2 elastic IP addresses</h3><p>static IP addresses designed for dynamic cloud computing, able to mask failures </p><p>applications still accessible </p><h3 id="2-3-3-amazon-route-53"><a href="#2-3-3-amazon-route-53" class="headerlink" title="2.3.3 amazon route 53"></a>2.3.3 amazon route 53</h3><p>Authorized DNS server, </p><h3 id="2-3-4-auto-scaling"><a href="#2-3-4-auto-scaling" class="headerlink" title="2.3.4 auto scaling"></a>2.3.4 auto scaling</h3><p>launches and terminates by specified conditions </p><p>can be adjusted/ modified </p><p>create new resources on demand </p><h3 id="2-3-5-amazon-cloudwatch"><a href="#2-3-5-amazon-cloudwatch" class="headerlink" title="2.3.5 amazon cloudwatch"></a>2.3.5 amazon cloudwatch</h3><p>collects and tracks infromations </p><h2 id="2-4-Fault-tolerant-tools"><a href="#2-4-Fault-tolerant-tools" class="headerlink" title="2.4 Fault tolerant tools"></a>2.4 Fault tolerant tools</h2><ol><li>Amazon simple queue service </li><li>Amazon simple storage service </li><li>Amazon simple DB </li><li>Amazon relational database service </li></ol><h1 id="3-Web-hosting"><a href="#3-Web-hosting" class="headerlink" title="3. Web hosting"></a>3. Web hosting</h1><h2 id="3-1-benefits"><a href="#3-1-benefits" class="headerlink" title="3.1 benefits"></a>3.1 benefits</h2><ul><li>cost effective<br>handle peak capacity </li></ul><p>do on demand provisioning </p><ul><li>scalable </li><li>on demand </li></ul><h2 id="3-2-Web-hosting-services"><a href="#3-2-Web-hosting-services" class="headerlink" title="3.2 Web hosting services"></a>3.2 Web hosting services</h2><p>Products to assist transition: </p><ol><li>Amazon Virtual Private Cloud </li><li>Amazon Route 53 </li><li>Amazon CloudFront </li><li>Elastic load balancing </li><li>Firewalls/ AWS shield</li><li>Auto scaling </li><li>App servers/ EC2 instances </li><li>Amazon ElasticCache </li><li>Amazon RDS/ Amazon DynamoDB </li></ol><h2 id="3-3-Key-Architectural-considerations"><a href="#3-3-Key-Architectural-considerations" class="headerlink" title="3.3 Key Architectural considerations"></a>3.3 Key Architectural considerations</h2><ol><li>No more physical network appliances </li><li>Firewalls everywhere </li><li>consider multiple data centers </li></ol>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS essential(4)-Security</title>
      <link href="/AWS-essential-4-Security/"/>
      <url>/AWS-essential-4-Security/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Introduction-to-AWS-security"><a href="#1-Introduction-to-AWS-security" class="headerlink" title="1. Introduction to AWS security"></a>1. Introduction to AWS security</h1><ul><li>Approach to security <ul><li>resilient infrastructure </li><li>high security </li><li>strong safeguards </li></ul></li><li>Controls </li><li>AWS products and features </li></ul><ul><li><p>Network Security </p><ul><li>build in firewalls </li><li>encryption in transit </li><li>private dedicated connections </li><li>ddos mitigation </li></ul></li><li><p>Data Encryption </p><ul><li>encrption capabilities for aws storage/ database </li><li>key management options </li><li>hardware based cryptographic key storage options </li></ul></li><li><p>Access Control and management </p><ul><li>Identity and access management </li><li>Multifactor authentication </li><li>integration and federation with corporate directories </li></ul></li><li><p>Monitoring and Logging </p><ul><li>deep visibility into API calls </li><li>log aggregation and options </li><li>alerts </li></ul></li></ul><h1 id="2-The-AWS-Shared-Responsibility-Model"><a href="#2-The-AWS-Shared-Responsibility-Model" class="headerlink" title="2. The AWS Shared Responsibility Model"></a>2. The AWS Shared Responsibility Model</h1><p>Share responsibility for securing data. </p><p>AWS responsible of — security of the cloud </p><ul><li>compute </li><li>storage </li><li>databse </li><li>networking </li></ul><p>Customer responsible of —- security in the cloud </p><ul><li>what to store </li><li>which aws services </li><li>location </li><li>content format </li></ul><h1 id="3-AWS-Access-Control-and-Management"><a href="#3-AWS-Access-Control-and-Management" class="headerlink" title="3. AWS Access Control and Management"></a>3. AWS Access Control and Management</h1><h2 id="3-1-IAM-overview"><a href="#3-1-IAM-overview" class="headerlink" title="3.1 IAM overview -"></a>3.1 IAM overview -</h2><h3 id="3-1-1-Functions"><a href="#3-1-1-Functions" class="headerlink" title="3.1.1 Functions"></a>3.1.1 Functions</h3><ul><li>Control access to AWS resources </li><li>authentication<ul><li>who can access resources</li><li>use AWS IAM policy </li></ul></li><li>Authorization <ul><li>how they can use resources </li></ul></li></ul><p>Manage accesses to: </p><ul><li>compute </li><li>storage </li><li>database </li><li>application services </li></ul><h3 id="3-1-2-Roles"><a href="#3-1-2-Roles" class="headerlink" title="3.1.2 Roles"></a>3.1.2 Roles</h3><ul><li>User</li><li>Group </li><li>Permissions </li><li>Role </li></ul><h3 id="3-1-3-Features"><a href="#3-1-3-Features" class="headerlink" title="3.1.3 Features"></a>3.1.3 Features</h3><ul><li>Shared access to your AWS account </li><li>Granular permissions </li></ul><p>You can grant different permissions to different people for different resources. </p><ul><li>secure access to AWS resources for applications that run on Amazon EC2 </li></ul><p>You can use IAM features to securely provide credentials for applications that run on EC2 instances. These credentials provide permissions for your application to access other AWS resources. </p><ul><li>Multi-factor authentication(MFA)</li><li>Identity federation </li></ul><p>You can allow users who already have passwords elsewhere—for example, in your corporate network or with an internet identity provider—to get temporary access to your AWS account.</p><h3 id="3-1-4-functionalities"><a href="#3-1-4-functionalities" class="headerlink" title="3.1.4 functionalities"></a>3.1.4 functionalities</h3><ul><li>manage users and their access </li><li>manage roles and their permissions </li><li>manage federated users and their permissions </li></ul><h2 id="3-2-How-IAM-works"><a href="#3-2-How-IAM-works" class="headerlink" title="3.2 How IAM works"></a>3.2 How IAM works</h2><h3 id="3-2-1-Elements-contained"><a href="#3-2-1-Elements-contained" class="headerlink" title="3.2.1 Elements contained"></a>3.2.1 Elements contained</h3><ul><li>Resources <ul><li>The user, role, group and policy objects that are stored in IAM. </li></ul></li><li>Identities <ul><li>The IAM resource objects taht are used to identofy and group.  </li></ul></li></ul><p><a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/intro-structure.html" target="_blank" rel="noopener">Understanding how IAM works</a></p>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Security </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS essentials(3) - Core Services</title>
      <link href="/AWS-essentials-3-Core-Services/"/>
      <url>/AWS-essentials-3-Core-Services/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AWS-global-infrastructure"><a href="#1-AWS-global-infrastructure" class="headerlink" title="1. AWS global infrastructure"></a>1. AWS global infrastructure</h1><h2 id="1-1-Regions"><a href="#1-1-Regions" class="headerlink" title="1.1 Regions"></a>1.1 Regions</h2><p>AWS Regions provide multiple, physically separated and isolated Availability Zones which are connected with low latency, high throughput, and highly redundant networking. </p><p><a href="https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/?p=gi&l=emea" target="_blank" rel="noopener">Region table</a></p><h2 id="1-2-Availability-Zones"><a href="#1-2-Availability-Zones" class="headerlink" title="1.2 Availability Zones"></a>1.2 Availability Zones</h2><p>These Availability Zones offer AWS customers an easier and more effective way to design and operate applications and databases, making them more highly available, fault tolerant, and scalable than traditional single datacenter infrastructures or multi-datacenter infrastructures. </p><p>Collection of data centers within a region. </p><p>isolate - protect from failures </p><p>AZs are pyhsically and logically seperated within a region. Own their own: </p><ol><li>uninterruptible power supply </li><li>cooling equipment </li><li>networking connectivity </li><li>backup generators </li></ol><h2 id="1-3-Edge-Locations"><a href="#1-3-Edge-Locations" class="headerlink" title="1.3 Edge Locations"></a>1.3 Edge Locations</h2><p>Content Delivery Network  —- Amazon CloudFront </p><p>Deliver content to customers </p><p>When a user requests content that you’re serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance.</p><p><a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html" target="_blank" rel="noopener">CloudFront Developer Guide</a></p><h2 id="1-4-Local-Regions"><a href="#1-4-Local-Regions" class="headerlink" title="1.4 Local Regions"></a>1.4 Local Regions</h2><p>An AWS Local Region is a single datacenter designed to complement an existing AWS Region. Like all AWS Regions, AWS Local Regions are completely isolated from other AWS Regions. </p><h1 id="2-Virtual-Private-Cloud-VPC"><a href="#2-Virtual-Private-Cloud-VPC" class="headerlink" title="2. Virtual Private Cloud (VPC)"></a>2. Virtual Private Cloud (VPC)</h1><h2 id="2-1-Introduction"><a href="#2-1-Introduction" class="headerlink" title="2.1 Introduction"></a>2.1 Introduction</h2><p>Amazon VPC enables you to launch AWS resources into a virtual network that you’ve defined. This virtual network closely resembles a traditional network that you’d operate in your own data center, with the benefits of using the scalable infrastructure of AWS.Consists of such features: </p><ul><li>A private, virtual network in the AWS Cloud <ul><li>Uses same concepts as on premise networking </li></ul></li><li>Allows complete control of network configuration<ul><li>Ability to isolate and expose resources inside VPC </li></ul></li><li>Offers several layers of security controls <ul><li>Ability to allow and deny specific internet and internal traffic </li></ul></li><li>Other AWS services deploy into VPC <ul><li>Services inherent security built into network </li></ul></li></ul><h2 id="2-2-Features"><a href="#2-2-Features" class="headerlink" title="2.2 Features"></a>2.2 Features</h2><ul><li><p>Build upon high availabilty of AWS regions and availability zones </p><ul><li>Amazon VPC lives within a region </li><li>Multiple VPCs per account </li></ul></li><li><p>Subnets   </p><ul><li>Used to divide Amazon VPC </li><li>Allow Amazon VPC to span multiple Azs </li><li>seperate public and private network </li></ul></li><li><p>Route tables </p><ul><li>Control traffic going out of the subnets </li></ul></li><li><p>Internet Gateway (IGW)</p><ul><li>Allows private subnet resources to access internet </li></ul></li><li><p>Network Access Control Lists(NACL)</p><ul><li>Control access to subnets; stateless </li></ul></li></ul><p><img src="https://i.loli.net/2020/01/30/3r4S8k2WYVHFqtf.png" alt="fig1.png"></p><h2 id="2-3-Subnets"><a href="#2-3-Subnets" class="headerlink" title="2.3 Subnets"></a>2.3 Subnets</h2><p>A subnet is a range of IP addresses in your VPC. You can launch AWS resources into a specified subnet. Use a public subnet for resources that must be connected to the internet, and a private subnet for resources that won’t be connected to the internet. </p><h1 id="3-AWS-Security"><a href="#3-AWS-Security" class="headerlink" title="3. AWS Security"></a>3. AWS Security</h1><h2 id="3-1-AWS-security-groups"><a href="#3-1-AWS-security-groups" class="headerlink" title="3.1 AWS security groups"></a>3.1 AWS security groups</h2><p>Filter traffic to your instances </p><p><img src="https://i.loli.net/2020/01/30/nzFWc4MZ86HimgC.png" alt="fig2.png"></p><p>Can configure the security rules, have multi rules. Web tier - application tier - database tier. </p><p>A security group acts as a virtual firewall for instances to control inbound and outbound traffic. Security group act at the instance level , not the subnet level. For each security group, you add rules that control the inbound traffic to instances, and a separate set of riles that control the outbound traffic. </p><h1 id="4-Compute-Services"><a href="#4-Compute-Services" class="headerlink" title="4. Compute Services"></a>4. Compute Services</h1><h2 id="4-1-Amazon-EC2"><a href="#4-1-Amazon-EC2" class="headerlink" title="4.1 Amazon EC2"></a>4.1 Amazon EC2</h2><p>Flexible configuration and control </p><p>maintain complete control of envs </p><p>EC2 overview </p><h3 id="4-1-1-What-is-EC2"><a href="#4-1-1-What-is-EC2" class="headerlink" title="4.1.1 What is EC2"></a>4.1.1 What is EC2</h3><p>EC2: <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/concepts.html" target="_blank" rel="noopener">Elastic compute cloud</a> </p><p>Compute: different thing you can do with servers </p><ul><li>Application server </li><li>Web server </li><li>Database server </li><li>Game server </li><li>Mail server </li><li>Media server </li><li>Catalog server </li><li>File server </li><li>Computing server </li><li>Proxy server </li></ul><h3 id="4-1-2-Amazon-EC2-instances-instructions"><a href="#4-1-2-Amazon-EC2-instances-instructions" class="headerlink" title="4.1.2 Amazon EC2 instances instructions"></a>4.1.2 Amazon EC2 instances instructions</h3><p>need to select AMI(Amazon Machine Image), present for software choices </p><p>Select instance type(hard ware)</p><p>Configure network, storage, key pairs (Use key value pair to access the instance)</p><h3 id="4-1-3-Features-of-EC2"><a href="#4-1-3-Features-of-EC2" class="headerlink" title="4.1.3 Features of EC2"></a>4.1.3 Features of EC2</h3><ol><li>virtual computing env. known as instances </li><li>various comfigurations of CPU, memory, and networking capacity for your instances </li><li>secure login information for your instances using key pairs(AWS stores the public key, and you store the private key)</li><li>Sotrage volumes(temporory) and persistent storage volumes – Amazon Elastic Block Store</li><li>Firewall that enables you to specify the protocols, ports and source IP ranges that can reach your instances using security groups </li><li>static IPv4 addresses for dynamic cloud computing, known as Elastic IP adddresses</li><li>metadata, known as tags, that you can create and assign to your Amazon EC2 resources </li><li>Virtual networks you can create that are logically isolated from the rest of the AWS cloud</li></ol><h3 id="4-1-4-Security-best-practices"><a href="#4-1-4-Security-best-practices" class="headerlink" title="4.1.4 Security best practices"></a>4.1.4 Security best practices</h3><ol><li>Use AWS identiry and access Management(IAM) to control access to AWS resources, including instances. You can create IAM users and groups under your AWS account, assign security credentials to each, and control the access that each has to resources and services in AWS. </li><li>Restrict access by only allowing trusted hosts or networks to access ports on your instance. For example, you can restrict SSH access by restricting incoming traffic on port 22.</li></ol><h3 id="4-1-5-Instance-types"><a href="#4-1-5-Instance-types" class="headerlink" title="4.1.5 Instance types"></a>4.1.5 Instance types</h3><p>Instance type you specify determines the hardware of the host computer used for your instance. Each instance is provided with a consistent and predictable amount of CPU capacity, memory, storage. </p><ul><li>general purpose </li><li>compute optimized </li><li>memory optimized </li><li>storage optimized </li><li>accelerated computing </li></ul><h2 id="4-2-Lambda"><a href="#4-2-Lambda" class="headerlink" title="4.2 Lambda"></a>4.2 Lambda</h2><h3 id="4-2-1-Overviews"><a href="#4-2-1-Overviews" class="headerlink" title="4.2.1 Overviews"></a>4.2.1 Overviews</h3><p>AWS Lambda is a compute service that lets you run code without provisioning or managing servers. Pay for the compute time you consume. AWS Lambda runs your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, <strong>including server and operating system maintenance, capacity provisioning and automatic scaling</strong>, code monitoring and logging.</p><p>fully managed serverless compute </p><p>event driven execution, respond to event </p><p>sub second metering </p><h3 id="4-2-2-benefits"><a href="#4-2-2-benefits" class="headerlink" title="4.2.2 benefits :"></a>4.2.2 benefits :</h3><ol><li>Lambda manages the compute fleet that offers a balance of memory, CPU, network and other resources. </li></ol><h3 id="4-2-3-Use-cases"><a href="#4-2-3-Use-cases" class="headerlink" title="4.2.3 Use cases"></a>4.2.3 Use cases</h3><ol><li>Run code in response to events, such as changes to data in an Amazon S3 bucket or an DynamoDB table</li><li>Run code in response to HTTP requests using Amazon API gateway</li><li>Invoke code using API calls made using AWS SDKs </li><li>Build serverless applications composed of functions that are triggered by events and automatically deploy them using AWS CodePipeline and AWS CodeBuild. </li></ol><p><img src="https://i.loli.net/2020/01/30/FND9g628EpyeMfG.png" alt="fig3.png"><br><img src="https://i.loli.net/2020/01/30/KMJhXORqAIUNBt3.png" alt="fig4.png"><br><img src="https://i.loli.net/2020/01/30/8bv7jq5etdTKH1W.png" alt="fig5.png"></p><h3 id="4-2-4-Lambda-Applications"><a href="#4-2-4-Lambda-Applications" class="headerlink" title="4.2.4 Lambda Applications"></a>4.2.4 Lambda Applications</h3><p>An AWS Lambda application is a combination of Lambda functions, event sources, and other resources that work together to perform tasks. You can use AWS CloudFormation and other tools to collect your application’s components into a single package that can be deployed and managed as one resource. </p><h3 id="4-2-5-Work-with-AWS-Lambda-Functions"><a href="#4-2-5-Work-with-AWS-Lambda-Functions" class="headerlink" title="4.2.5 Work with AWS Lambda Functions"></a>4.2.5 Work with AWS Lambda Functions</h3><ol><li><p><a href="https://docs.aws.amazon.com/lambda/latest/dg/best-practices.html" target="_blank" rel="noopener">Working with AWS Lambda Functions</a></p></li><li><p><a href="https://docs.aws.amazon.com/lambda/latest/dg/limits.html" target="_blank" rel="noopener">AWS Lambda Limits</a></p></li></ol><ul><li>Concurrent Executions limit: 1000 </li><li>function timeout: 15 minutes </li><li>execution threads: 1024 </li></ul><ol start="3"><li>[Building Lambda Functions]</li></ol><ul><li>Lifecycle for an AWS lambda-based application<ul><li>authoring code<ul><li><a href="https://docs.aws.amazon.com/lambda/latest/dg/programming-model-v2.html" target="_blank" rel="noopener">programing model</a> - the format of the code    </li></ul></li><li>deploying code<ul><li>Package code and dependencies in a deployment package</li><li>upload the package to AWS Lambda to create Lambda function</li></ul></li><li>monitoring<ul><li>CloudWatch    </li></ul></li><li>troubleshooting</li></ul></li></ul><ol start="4"><li><a href="https://docs.aws.amazon.com/lambda/latest/dg/use-cases.html" target="_blank" rel="noopener">Using AWS Lambda With Other Services</a></li></ol><h3 id="4-2-6-Lambda-Concepts"><a href="#4-2-6-Lambda-Concepts" class="headerlink" title="4.2.6 Lambda Concepts"></a>4.2.6 Lambda Concepts</h3><ul><li>Function - A script or program that runs in AWS Lambda. Lambda passes invocation events to your function. The function processes an event and returns a response. </li><li>Runtimes – Lambda runtimes allow functions in different languages to run in the same base execution environment. You configure your function to use a runtime that matches your programming language. The runtime sits in-between the Lambda service and your function code, relaying invocation events, context information, and responses between the two. You can use runtimes provided by Lambda, or build your own. </li><li>Layers – Lambda layers are a distribution mechanism for libraries, custom runtimes, and other function dependencies. Layers let you manage your in-development function code independently from the unchanging code and resources that it uses. You can configure your function to use layers that you create, layers provided by AWS, or layers from other AWS customers.</li></ul><p>A <a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html" target="_blank" rel="noopener">layer</a> is a ZIP archive that contains libraries, a custom runtime or other dependencies. With layers, you can use libraries in your function without needing to include them in your deployment package. Layers let you keep your deployment package small, which makes development easier. </p><ul><li>Event source – An AWS service, such as Amazon SNS, or a custom service, that triggers your function and executes its logic.</li><li>Downstream resources – An AWS service, such as DynamoDB tables or Amazon S3 buckets, that your Lambda function calls once it is triggered.</li><li>Log streams – While Lambda automatically monitors your function invocations and reports metrics to CloudWatch, you can annotate your function code with custom logging statements that allow you to analyze the execution flow and performance of your Lambda function to ensure it’s working properly.</li><li>AWS SAM – A model to define serverless applications. AWS SAM is natively supported by AWS CloudFormation and defines simplified syntax for expressing serverless resources. </li></ul><h2 id="4-3-AWS-Elastic-Beanstalk"><a href="#4-3-AWS-Elastic-Beanstalk" class="headerlink" title="4.3 AWS Elastic Beanstalk"></a>4.3 AWS Elastic Beanstalk</h2><h3 id="4-3-1-Overview"><a href="#4-3-1-Overview" class="headerlink" title="4.3.1 Overview"></a>4.3.1 Overview</h3><p>Quick get application into the cloud </p><p>Platform as a service </p><p>You can simply upload your code and Elastic Beanstalk automatically handles the deployment, from capacity provisioning, load balancing, auto-scaling to application health monitoring. At the same time, you retain full control over the AWS resources powering your application and can access the underlying resources at any time.</p><p>Allow quick deployment of your applications </p><p>Elastic Beanstalk provides:</p><ul><li>Application service</li><li>HTTP service</li><li>Operating system</li><li>Language interpreter </li><li>Host </li></ul><h1 id="5-Application-Load-Balancer"><a href="#5-Application-Load-Balancer" class="headerlink" title="5 Application Load Balancer"></a>5 Application Load Balancer</h1><h2 id="5-1-Service-Introduction"><a href="#5-1-Service-Introduction" class="headerlink" title="5.1 Service Introduction"></a>5.1 Service Introduction</h2><p>A load balancerr serves as the single point of contact for clients. The load balancer distributes incoming application traffic across multiple targets, such as EC2 instances in multiple Availability Zones. </p><p>A listener checks for connection requests from clients, using the protocol and port that you configure, and forwards requests to one or more target groups, based on the rules that you define. Each rule specifies a target group, condition, and priority. When the condition is met, the traffic is forwarded to the target group. You must define a default rule for each listener, and you can add rules that specify different target groups based on the content of the request </p><p>Each target group routes requests to one or more registered targets, such as EC2 instances, using the protocol and port number that you specify. You can register a target with multiple target groups. You can configure health checks on a per target group basis. Health checks are performed on all targets registered to a target group that is specified in a listener rule for your load balancer.</p><p>An Application Load Balancer functions at the application layer, <strong>the seventh layer</strong> of the Open Systems Interconnection (OSI) model. After the load balancer receives a request, it evaluates the listener rules in priority order to determine which rule to apply, and then selects a target from the target group for the rule action. You can configure listener rules to route requests to different target groups based on the content of the application traffic. Routing is performed independently for each target group, even when a target is registered with multiple target groups.</p><p>Part of the elastic load balancer service. Add some important features<br><img src="https://i.loli.net/2020/01/30/sHi7LhOGeYvw3Er.png" alt="fig6.png"></p><ol><li>Support more protocols  HTTP HTTPS HTTP/2 </li><li>cloudWatch Metrics   </li><li>Access logs </li><li>Health Checks </li></ol><h2 id="5-2-Key-Concepts"><a href="#5-2-Key-Concepts" class="headerlink" title="5.2 Key Concepts"></a>5.2 Key Concepts</h2><ol><li>Listeners: a process that cehcks for connection requests, using the protocol and port that you configure. Rules that you define for a listener determine how the load balancer routes requests to the targets in one or more target groups. </li><li>Target: A target is a destination for traffic based on the established listener rules </li><li>Target group: each target group routes requests to one or more registered targets using the protocol and port number specified. </li></ol><p><img src="https://i.loli.net/2020/01/30/8TBYo7tIHValjig.png" alt="fig7.png"></p><h2 id="5-3-Benefits-of-using-Application-load-balancer-instead-of-classic-load-balancer"><a href="#5-3-Benefits-of-using-Application-load-balancer-instead-of-classic-load-balancer" class="headerlink" title="5.3 Benefits of using Application load balancer instead of classic load balancer"></a>5.3 Benefits of using Application load balancer instead of classic load balancer</h2><ul><li>Support for path-based routing. You can configure rules for your listener that forward requests based on the URL in the request. This enables you to structure your application as smaller services, and route requests to the correct service based on the content of the URL.</li><li>Support for host-based routing. You can configure rules for your listener that forward requests based on the host field in the HTTP header. This enables you to route requests to multiple domains using a single load balancer.</li><li>Support for routing requests to multiple applications on a single EC2 instance. You can register each instance or IP address with the same target group using multiple ports.</li><li>Support for redirecting requests from one URL to another </li></ul><h2 id="5-4-Use-Cases"><a href="#5-4-Use-Cases" class="headerlink" title="5.4 Use Cases"></a>5.4 Use Cases</h2><ol><li>route request to different ports within a single instance.<br><img src="https://i.loli.net/2020/01/30/8125hJRUbkD3cwi.png" alt="fig8.png"></li></ol><h1 id="6-Elastic-Load-Balancer-classic-load-balancer"><a href="#6-Elastic-Load-Balancer-classic-load-balancer" class="headerlink" title="6. Elastic Load Balancer - classic load balancer"></a>6. Elastic Load Balancer - classic load balancer</h1><h2 id="6-1-Overview"><a href="#6-1-Overview" class="headerlink" title="6.1 Overview"></a>6.1 Overview</h2><p>A load balancer distributes workloads across multiple compute resources, such as virtual servers. Using a load balancer increases the availability and fault tolerance of your applications. </p><p>You can add and remove compute resources from your load balancer as your needs change, without disrupting the overall flow of requests to your applications.</p><p>You can <strong>configure health checks</strong>, which are used to monitor the health of the compute resources so that the load balancer can send requests only to the healthy ones. You can also <strong>offload the work of encryption and decryption to your load balancer</strong> so that your compute resources can focus on their main work.</p><p>Mainly consists of there types of load balancer: </p><ol><li>Application Load Balancer </li><li>Network Load Balancer</li><li>Classic Load Balancer </li></ol><p><a href="https://aws.amazon.com/elasticloadbalancing/features/#compare" target="_blank" rel="noopener">The comparison among those three</a></p><h2 id="6-2-How-does-it-work"><a href="#6-2-How-does-it-work" class="headerlink" title="6.2 How does it work?"></a>6.2 How does it work?</h2><p>A load balancer accepts incoming traffic from clients and routes requests to its registered targets. It also monitors the health of its registered targets and ensures that it routes traffic tonly to healthy targets. You configure your load balancer to accept incoming traffic by specifying one or more listeners. A listener is a process that checks for connection requests. It is configured with a protocol and port number for connections from clients to the load balancer and a protocol and port number for connections from the load balancer to the targets.</p><h3 id="6-2-1-Cross-zone-load-balancing"><a href="#6-2-1-Cross-zone-load-balancing" class="headerlink" title="6.2.1 Cross zone load balancing"></a>6.2.1 Cross zone load balancing</h3><p>The nodes for your load balancer distribute requests from clients to registered targets. When cross-zone load balancing is enabled, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones. When cross-zone load balancing is disabled, each load balancer node distributes traffic across the registered targets in its Availability Zone only.</p><h3 id="6-2-2-Request-Routing"><a href="#6-2-2-Request-Routing" class="headerlink" title="6.2.2 Request Routing"></a>6.2.2 Request Routing</h3><p>Before a client sends a request to your load balancer, it resolves the load balancer’s domain name using a Domain Name System (DNS) server. The DNS entry is controlled by Amazon, because your load balancers are in the amazonaws.com domain. The Amazon DNS servers return one or more IP addresses to the client, which are the IP addresses of the load balancer nodes for your load balancer. With Network Load Balancers, Elastic Load Balancing creates a network interface for each Availability Zone you enable. Each load balancer node in the Availability Zone uses this network interface to get a static IP address. You can optionally associate one Elastic IP address with each network interface when you create the load balancer.</p><p>As traffic to your application changes over time, Elastic Load Balancing scales your load balancer and updates the DNS entry. Note that the DNS entry also specifies the time-to-live (TTL) as 60 seconds, which ensures that the IP addresses can be remapped quickly in response to changing traffic.</p><p><img src="https://i.loli.net/2020/01/30/GRXtJqMcZyYvkAs.png" alt="fig9.png"></p><p><img src="https://i.loli.net/2020/01/30/oG3uYZ6OExWiQS4.png" alt="fig10.png"></p><p>Internet facing load balancers:<br><img src="https://i.loli.net/2020/01/30/OYdKufMSazqIbDQ.png" alt="fig11.png"></p><p>Internal Load Balancers: have DNS name only resolve private nodes<br><img src="https://i.loli.net/2020/01/30/IO24SbGetLaMAfo.png" alt="fig12.png"></p><h3 id="6-2-3-HTTP-Connections"><a href="#6-2-3-HTTP-Connections" class="headerlink" title="6.2.3 HTTP Connections"></a>6.2.3 HTTP Connections</h3><p>Classic Load Balancers use <strong>pre-open connections</strong> but Application Load Balancers do not. Both Classic Load Balancers and Application Load Balancers use <strong>connection multiplexing</strong>. This means that <strong>requests from multiple clients on multiple front-end connections can be routed to a given target through a single back-end connection</strong>. Connection multiplexing improves latency and reduces the load on your applications. To prevent connection multiplexing, disable HTTP keep-alives by setting the Connection: close header in your HTTP responses.</p><h2 id="6-3-Use-cases"><a href="#6-3-Use-cases" class="headerlink" title="6.3 Use cases"></a>6.3 Use cases</h2><ol><li>Access through single point </li><li>Decouple appliation environment </li><li>Provide high availability and fault tolerance </li><li>Increase elasticity and scalability </li></ol><h1 id="7-Auto-Scaling"><a href="#7-Auto-Scaling" class="headerlink" title="7. Auto Scaling"></a>7. Auto Scaling</h1><h2 id="7-1-Service-Introduction"><a href="#7-1-Service-Introduction" class="headerlink" title="7.1 Service Introduction"></a>7.1 Service Introduction</h2><p>Auto scaling helps you ensure you have the correct number of EC2 instances available to handle the load for your application. </p><p>Using cloudWatch to monitor </p><h3 id="7-1-1-Scaling-out-and-scaling-in"><a href="#7-1-1-Scaling-out-and-scaling-in" class="headerlink" title="7.1.1 Scaling out and scaling in"></a>7.1.1 Scaling out and scaling in</h3><p><img src="https://i.loli.net/2020/01/30/cHXtoB9IOURiL52.png" alt="fig13.png"></p><ul><li>Auto scaling components<ul><li>launch configuration </li><li>auto scaling group <ul><li>VPC and subnets </li><li>load balancer</li><li>minimum instances </li><li>maximum instances </li><li>desired capacity </li></ul></li><li>auto scaling policy <ul><li>scheduled</li><li>on demand </li><li>scale out policy</li><li>scale in policy </li></ul></li></ul></li></ul><h3 id="7-1-2-Dynamic-auto-scaling"><a href="#7-1-2-Dynamic-auto-scaling" class="headerlink" title="7.1.2 Dynamic auto scaling"></a>7.1.2 Dynamic auto scaling</h3><p><img src="https://i.loli.net/2020/01/30/pKFL5YWvHVOtuJw.png" alt="fig14.png"></p><p>CloudWatch detect the metrics and trigger auto scaling events. </p><h1 id="8-Amazon-Elastic-Block-Store-EBS"><a href="#8-Amazon-Elastic-Block-Store-EBS" class="headerlink" title="8. Amazon Elastic Block Store(EBS)"></a>8. Amazon Elastic Block Store(EBS)</h1><p>Amazon Elastic Block Store (Amazon EBS) provides block level storage volumes for use with EC2 instances. EBS volumes are highly available and reliable storage volumes that can be attached to any running instance that is in the same Availability Zone. </p><p>Amazon EBS is recommended when data must be quickly accessible and requires long-term persistence. EBS volumes are particularly well-suited for use as the primary storage for file systems, databases, or for any applications that require fine granular updates and access to raw, unformatted, block-level storage. </p><p>you can launch your EBS volumes as encrypted volumes.</p><p>There are three types of volumes in Amazon EBS. To understand the difference, you need to know what IOPS is. <strong>“IOPS” stands for input/output operations per second or, put it simply, the maximum amount of read/write operations you are able to perform per second.</strong> To <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html" target="_blank" rel="noopener">choose the right Amazon EBS volume type</a> you need to know IOPS requirements for your application.</p><h2 id="8-1-General-Purpose-Volumes"><a href="#8-1-General-Purpose-Volumes" class="headerlink" title="8.1 General Purpose Volumes"></a>8.1 General Purpose Volumes</h2><p>Designed for a broad range of tasks, General Purpose Volumes are backed with Solid State Drive (SSD). The baseline performance of 3 IOPS/GB and a possibility to burst up to 10,000 IOPS makes them a good fit for AWS databases that need a lot of read and write operations, like PostgreSQL, MS SQL or Oracle databases.</p><h2 id="8-2-Provisioned-IOPS-SSD-Volumes"><a href="#8-2-Provisioned-IOPS-SSD-Volumes" class="headerlink" title="8.2 Provisioned IOPS (SSD) Volumes"></a>8.2 Provisioned IOPS (SSD) Volumes</h2><p>By expanding the bandwidth bottleneck, Provisioned IOPS Volumes allow buying read/write operations on demand regardless of the volume capacity. This type of EBS volumes is backed with the same SSD but designed for heavy workloads from 30 IOPS/GB up to 20,000 IOPS. Multiple Provisioned IOPS volumes can be striped thus ensuring up to 48,000 IOPS or 800 MBps of throughput.</p><h2 id="8-3-Magnetic-Volumes"><a href="#8-3-Magnetic-Volumes" class="headerlink" title="8.3 Magnetic Volumes"></a>8.3 Magnetic Volumes</h2><p>The best way to think of the Magnetic Volumes type is as of a low-cost volume that can be used with testing and development environments on Amazon EC2. It can also be used with applications that don’t require a lot of read/write operations. Instead of SSD, this type is based on magnetic HDD drives, thus the IOPS baseline is within the range of 100 up to hundreds of IOPS. Magnetic Volumes can also become a starting point in working with Amazon EC2 — once you understand your IOPS demands, you can select the type of volume that fits best.</p><h1 id="9-Amazon-Simple-Storage-Service"><a href="#9-Amazon-Simple-Storage-Service" class="headerlink" title="9. Amazon Simple Storage Service"></a>9. Amazon Simple Storage Service</h1><h2 id="9-1-Introduction"><a href="#9-1-Introduction" class="headerlink" title="9.1 Introduction"></a>9.1 Introduction</h2><p>No need to manage any infrastructure yourself. S3 help you manage your storage, it can store unlimited number of objects, access any time, from anywhere; rich security controls. </p><p>Amazon Simple Storage Service (Amazon S3) is storage for the Internet. You can use Amazon S3 to store and retrieve any amount of data at any time, from anywhere on the web. You can accomplish these tasks using the AWS Management Console, which is a simple and intuitive web interface. </p><h3 id="9-1-1-steps"><a href="#9-1-1-steps" class="headerlink" title="9.1.1 steps"></a>9.1.1 steps</h3><ol><li>create a bucket </li><li>add an object to a bucket </li><li>view an object </li><li>move an object </li><li>delete an object and bucket </li></ol><h3 id="9-1-2-bucket"><a href="#9-1-2-bucket" class="headerlink" title="9.1.2 bucket"></a>9.1.2 bucket</h3><p>S3 stores data as objects within buckets. An object consists of a file and optionally any metadata that describes the file. </p><p>To store an object in Amazon S3, you upload the file you want to store to a bucket. When you upload a file, you can <strong>set permissions</strong> on the object as well as any metadata.</p><p>Buckets are the <strong>containers</strong> for objects. You can have one or more buckets. For each bucket, you can control access to it (who can create, delete, and list objects in the bucket), view access logs for it and its objects, and choose the geographical region where Amazon S3 will store the bucket and its contents.</p><p>Need a bucket to hold the data </p><p>associate in region, will make duplicate  </p><p>disigned for seamless scaling </p><h2 id="9-2-Use-cases"><a href="#9-2-Use-cases" class="headerlink" title="9.2 Use cases"></a>9.2 Use cases</h2><ol><li>store application assets </li><li>static web hosting </li><li>backup and disaster recovery </li><li>staging area for big data </li></ol><h1 id="10-Amazon-Glacier"><a href="#10-Amazon-Glacier" class="headerlink" title="10. Amazon Glacier"></a>10. Amazon Glacier</h1><h2 id="10-1-Overview"><a href="#10-1-Overview" class="headerlink" title="10.1 Overview"></a>10.1 Overview</h2><p>Data archiving solition </p><p>long tern storage at low cost </p><p>access limited by vault polocies </p><p>for data not accessed frequently </p><p><img src="https://i.loli.net/2020/01/30/gPXGKzaIuQBSpoy.png" alt="fig15.png"></p><p>It can take a really long time to retrieve data from glacier. bulk, standard, expedited. </p><p>Amazon Simple Storage Service Glacier (Amazon S3 Glacier) is a storage service optimized for infrequently used data, or “cold data.” The service provides durable and extremely low-cost storage with security features for data archiving and backup. With Amazon S3 Glacier, you can store your data cost effectively for months, years, or even decades. Amazon S3 Glacier enables you to offload the administrative burdens of operating and scaling storage to AWS, so you don’t have to worry about capacity planning, hardware provisioning, data replication, hardware failure detection and recovery, or time-consuming hardware migrations. </p><h2 id="10-2-Details"><a href="#10-2-Details" class="headerlink" title="10.2 Details"></a>10.2 Details</h2><h3 id="10-2-1-archive"><a href="#10-2-1-archive" class="headerlink" title="10.2.1 archive"></a>10.2.1 archive</h3><p>An archive can be any data such as a photo, video, or document and is a base unit of storage in glacier. </p><h3 id="10-2-2-vault"><a href="#10-2-2-vault" class="headerlink" title="10.2.2 vault"></a>10.2.2 vault</h3><p>Container to store archive. When creating a vault, you specify a name and choose an AWS region where you want to create the vault.  Within a Region, an account must use unique vault names. An AWS account can create same-named vaults in different Regions.</p><h3 id="10-2-3-access-policy"><a href="#10-2-3-access-policy" class="headerlink" title="10.2.3 access policy"></a>10.2.3 access policy</h3><p>who can access </p><h3 id="10-2-4-Job"><a href="#10-2-4-Job" class="headerlink" title="10.2.4 Job"></a>10.2.4 Job</h3><p>Glacier jobs can perform a select query on an archive, retrieve an archive, or get an inventory of a vault. When performing a query on an archive, you initiate a job providing a SQL query and list of Glacier archive objects. Glacier Select runs the query in place and writes the output results to Amazon S3.</p><h2 id="10-3-use-cases"><a href="#10-3-use-cases" class="headerlink" title="10.3 use cases"></a>10.3 use cases</h2><ol><li>archive database snapshots and log files </li><li>low cost enables more comprehensive backups </li><li>archive older documents, audio, video </li></ol><h1 id="11-Amazon-Relational-Database-Service-Amazon-RDS"><a href="#11-Amazon-Relational-Database-Service-Amazon-RDS" class="headerlink" title="11. Amazon Relational Database Service (Amazon RDS)"></a>11. Amazon Relational Database Service (Amazon RDS)</h1><h2 id="11-1-Overview"><a href="#11-1-Overview" class="headerlink" title="11.1 Overview"></a>11.1 Overview</h2><h3 id="11-1-1-Chanllenges-of-relational-databases"><a href="#11-1-1-Chanllenges-of-relational-databases" class="headerlink" title="11.1.1 Chanllenges of relational databases"></a>11.1.1 Chanllenges of relational databases</h3><ol><li>server maintenance and energy footprint </li><li>software install and patches </li><li>database backups and high availability </li><li>limits on scalability </li><li>data security </li><li>os install and patches </li></ol><h3 id="11-1-2-RDS-intro"><a href="#11-1-2-RDS-intro" class="headerlink" title="11.1.2 RDS intro"></a>11.1.2 RDS intro</h3><p>Amazon RDS is a managed service that sets up and operates a relational database in the cloud. </p><p>AWS help you manage: </p><ul><li>OS installation and patches </li><li>database software install and patches </li><li>database backups </li><li>high availability </li><li>scaling </li><li>power and rack &amp; stack </li><li>server maintenance </li></ul><p>It support mainstream relation databases: </p><p><img src="https://i.loli.net/2020/01/30/FZlbiXEhuYKSsJD.png" alt="fig16.png"></p><h2 id="11-2-Use-cases"><a href="#11-2-Use-cases" class="headerlink" title="11.2 Use cases"></a>11.2 Use cases</h2><p><img src="https://i.loli.net/2020/01/30/k1PfHQxg7EYmyNp.png" alt="fig17.png"></p><h1 id="12-Amazon-DynamoDB"><a href="#12-Amazon-DynamoDB" class="headerlink" title="12. Amazon DynamoDB"></a>12. Amazon DynamoDB</h1><h2 id="12-1-Overview"><a href="#12-1-Overview" class="headerlink" title="12.1 Overview"></a>12.1 Overview</h2><h3 id="12-1-1-Features"><a href="#12-1-1-Features" class="headerlink" title="12.1.1 Features"></a>12.1.1 Features</h3><ul><li>NoSQL databse tables as a service </li><li>store as many items as you want </li><li>items may have differing attributes </li><li>low latency queries </li><li>scalable read/ write throughput </li></ul><h3 id="12-1-2-Partitioning"><a href="#12-1-2-Partitioning" class="headerlink" title="12.1.2 Partitioning"></a>12.1.2 Partitioning</h3><p>as table grows, table partitioned by key </p><p>query by key to find items efficiently </p><p>scan to find items by any attribute, less efficient </p><h2 id="12-2-Use-cases"><a href="#12-2-Use-cases" class="headerlink" title="12.2 Use cases"></a>12.2 Use cases</h2><ul><li>web </li><li>mobile apps </li><li>internet of things </li><li>ad tech </li></ul><h1 id="13-Redshift"><a href="#13-Redshift" class="headerlink" title="13. Redshift"></a>13. Redshift</h1><h2 id="13-1-Redshift-introduction"><a href="#13-1-Redshift-introduction" class="headerlink" title="13.1 Redshift introduction"></a>13.1 Redshift introduction</h2><ul><li>data warehouse, to analyze the data with query. </li><li>parallel processing architecture </li></ul><p><img src="https://i.loli.net/2020/01/30/BJDCT718z9gPV3Q.png" alt="fig18.png"></p><p>Amazon Redshift is a fast, fully managed, petabyte-scale data warehouse service that makes it simple and cost-effective to efficiently analyze all your data using your existing business intelligence tools. It is optimized for datasets ranging from a few hundred gigabytes to a petabyte or more and costs less than $1,000 per terabyte per year, a tenth the cost of most traditional data warehousing solutions.</p><h2 id="13-2-Overview"><a href="#13-2-Overview" class="headerlink" title="13.2 Overview"></a>13.2 Overview</h2><h3 id="13-2-1-Cluster-management"><a href="#13-2-1-Cluster-management" class="headerlink" title="13.2.1 Cluster management"></a>13.2.1 Cluster management</h3><p>A cluster is a set of nodes, which consists of a leader node and one or more compute nodes, The type and number of compute nodes that you need depends on the size of your data, the number of queries you will execute, and the query execution performance that you need.</p><h2 id="13-3-use-cases"><a href="#13-3-use-cases" class="headerlink" title="13.3 use cases"></a>13.3 use cases</h2><ol><li><p>Enterprise Data Warehouse (EDW)</p></li><li><p>Big Data </p></li><li><p>Saas </p></li></ol><ul><li>scale the data warehouse capacity as demand grows </li><li>add analytic functionality to applications </li><li>reduce hardware and software costs by an order of magnitude </li></ul><h1 id="14-Amazon-Aurora"><a href="#14-Amazon-Aurora" class="headerlink" title="14. Amazon Aurora"></a>14. Amazon Aurora</h1><h2 id="14-1-Overview"><a href="#14-1-Overview" class="headerlink" title="14.1 Overview"></a>14.1 Overview</h2><p>mysql relational database </p><p>It is designed to deliver the speed and reliability of high-end commercial databases in a simple and cost-effective manner. Aurora is designed to be compatible with MySQL 5.6 and delivers five times the throughput of standard MySQL running on the same hardware. DBAs are able to save time on planning backup storage disks, as data is continuously backed up to AWS S3 in real time, with no performance impact to the end user. </p><h2 id="14-2-benefits"><a href="#14-2-benefits" class="headerlink" title="14.2 benefits"></a>14.2 benefits</h2><p><img src="https://i.loli.net/2020/01/30/FLU3aykfVqnptX8.png" alt="fig19.png"></p><p><img src="https://i.loli.net/2020/01/30/E6pSOTLwcXixBgP.png" alt="fig20.png"></p><h2 id="15-Trused-Advisor"><a href="#15-Trused-Advisor" class="headerlink" title="15. Trused Advisor"></a>15. Trused Advisor</h2><p>Used to keep track of aws resources. – a dashboard for all the risks and warnings that you can take actions to save money </p><p>Detect your usage in four categories: </p><ol><li>cost optimization </li><li>performance </li><li>security </li><li>fault tolerance </li></ol>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS essentials(2) - Cloud Concepts</title>
      <link href="/AWS-essentials-2-Cloud-Concepts/"/>
      <url>/AWS-essentials-2-Cloud-Concepts/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Cloud-computing"><a href="#1-Cloud-computing" class="headerlink" title="1. Cloud computing"></a>1. Cloud computing</h1><p>Before cloud, bring a lot of waste. Cause you have to build your own server. </p><p>After aws, initiated within seconds; treat these as temprorary and disposable; free from the inflexibility and constraints. </p><h1 id="2-strengths-of-cloud"><a href="#2-strengths-of-cloud" class="headerlink" title="2. strengths of cloud"></a>2. strengths of cloud</h1><h2 id="2-1-Agility"><a href="#2-1-Agility" class="headerlink" title="2.1 Agility"></a>2.1 Agility</h2><h3 id="2-1-1-speed"><a href="#2-1-1-speed" class="headerlink" title="2.1.1 speed"></a>2.1.1 speed</h3><ol><li><p>Global reach </p></li><li><p>Dramatic increase in agility </p></li></ol><h3 id="2-1-2-experimentation"><a href="#2-1-2-experimentation" class="headerlink" title="2.1.2. experimentation"></a>2.1.2. experimentation</h3><ol><li><p>operations as code </p></li><li><p>safely experiment </p></li></ol><p>can spin up servers in minutes for experimenting; can return or re-purpose servers </p><ol start="3"><li>Testing using different configurations </li><li>AWS cloudFormation enables templated environments </li></ol><h3 id="2-1-3-culture-of-innovation"><a href="#2-1-3-culture-of-innovation" class="headerlink" title="2.1.3. culture of innovation"></a>2.1.3. culture of innovation</h3><ol><li>Experiment quickly with low cost/ risk </li></ol><h3 id="2-1-4-AWS-Infrastructure"><a href="#2-1-4-AWS-Infrastructure" class="headerlink" title="2.1.4 AWS Infrastructure"></a>2.1.4 AWS Infrastructure</h3><p>To realize elasticity, scalability and reliability of computing resources, aws is build around region and availability zones. </p><ul><li><p>region </p><ul><li>physical location in the world </li><li>contains multiple AZs</li></ul></li><li><p>availability zones </p><ul><li>one or more discrete data centers </li><li>redundant power/ networking/ connectivity </li><li>housed in separate facilities </li><li>fault tolerance <ul><li>applications operational during component failure </li><li>build-in redundancy of components </li></ul></li><li>High availability <ul><li>systems always functioning and accessible </li><li>downtime is minimized as much as possible </li><li>without human intervention </li></ul></li></ul></li></ul><h2 id="2-2-Elasticity-scalability-and-high-performance"><a href="#2-2-Elasticity-scalability-and-high-performance" class="headerlink" title="2.2 Elasticity, scalability and high performance"></a>2.2 Elasticity, scalability and high performance</h2><ol><li>Tools to run a wide range of applications </li><li>auto scaling and elastic load balancing, scale up/ down based on demand </li><li>deploy your system in multiple regions, low latency and better experience</li><li>innocative services and cutting-edge technology </li><li>virtually any workload </li></ol><h2 id="2-3-Security-and-Compliance"><a href="#2-3-Security-and-Compliance" class="headerlink" title="2.3 Security and Compliance"></a>2.3 Security and Compliance</h2><ol><li>Customer retains control over region where data located </li><li>Security auditing often periodic and manual </li><li>AWS cloud provides governance capabilities </li></ol><h2 id="2-4-Reliability"><a href="#2-4-Reliability" class="headerlink" title="2.4 Reliability"></a>2.4 Reliability</h2><ol><li>Ability to recover from failures </li><li>Dynamically acquire resources to meet demand and mitigate disruptions </li></ol>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Security </tag>
            
            <tag> Agility </tag>
            
            <tag> Elasticity </tag>
            
            <tag> Reliability </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS essentials(1) - introduction</title>
      <link href="/AWS-essentials-1-introduction/"/>
      <url>/AWS-essentials-1-introduction/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AWS-Cloud-Concepts"><a href="#1-AWS-Cloud-Concepts" class="headerlink" title="1. AWS Cloud Concepts"></a>1. AWS Cloud Concepts</h1><ol><li>Introduction to cloud</li><li>Introduction to the AWS Cloud</li></ol><h1 id="2-AWS-Core-Services"><a href="#2-AWS-Core-Services" class="headerlink" title="2. AWS Core Services"></a>2. AWS Core Services</h1><ol><li>Overview of Services and Categories </li><li>Introduction to the AWS Global Infrastructure </li><li>Introduction to Amazon VPC </li><li>Introduction to Security Groups </li><li>Introduction to Amazon EC2</li><li>Introduction to Amazon Elastic Block Store </li><li>Introduction to Amazon S3</li><li>Introduction to AWS Database Solutions </li></ol><h1 id="3-AWS-Security"><a href="#3-AWS-Security" class="headerlink" title="3. AWS Security"></a>3. AWS Security</h1><ol><li>Introduction to AWS Security </li><li>The AWS Shared Responsibility Model </li><li>AWS Access Control and Management </li><li>AWS Security Compliance Programs </li><li>AWS Security Resources </li></ol><h1 id="4-AWS-architecting"><a href="#4-AWS-architecting" class="headerlink" title="4. AWS architecting"></a>4. AWS architecting</h1><ol><li>Introduction to the Well-Architected Framework </li><li>Reference Architecture: Fault Tolerance and High Availability </li><li>Reference Architecture: Web Hosting </li></ol><h1 id="5-AWS-Pricing-and-Support"><a href="#5-AWS-Pricing-and-Support" class="headerlink" title="5. AWS Pricing and Support"></a>5. AWS Pricing and Support</h1><ol><li>Fundamentals of Pricing </li><li>Pricing details for EC2, S3, EBS, RDS, CloudFront </li><li>TCO calculator Overview </li><li>AWS support Plans Overview </li></ol>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ECS - Elastic Container Service</title>
      <link href="/ECS-Elastic-Container-Service/"/>
      <url>/ECS-Elastic-Container-Service/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><ul><li>Highly scalable, fast, container management service that makes it easy to run, stop and maange docker containers on a cluster. </li></ul><p><img src="https://i.loli.net/2020/01/30/bgWNQv1M27fEza3.png" alt="fig1.png"></p><h1 id="2-Concepts"><a href="#2-Concepts" class="headerlink" title="2. Concepts"></a>2. Concepts</h1><ul><li><p>Containers</p><ul><li>Application components must be architected to run in containers </li><li>a standardized unit of development </li><li>contain everything application needs<ul><li>code </li><li>runtime </li><li>system tools </li><li>libraries </li></ul></li></ul></li><li><p>Images</p><ul><li>containers are created here</li><li>A read only templates</li></ul></li><li><p>Registry</p><ul><li>used to store images  </li></ul></li><li><p>Task </p><ul><li>text file in JSON </li><li>describes 1-10 containers to form your application </li></ul></li><li><p>Cluster </p><ul><li>logical group of resources  </li></ul></li><li><p>ECS Task scheduler</p><ul><li>responsible for placing tasks within cluster  <h1 id="3-Features"><a href="#3-Features" class="headerlink" title="3. Features"></a>3. Features</h1></li></ul></li><li><p>Regional service </p></li></ul><h1 id="4-Steps-for-starting-with-Fargate"><a href="#4-Steps-for-starting-with-Fargate" class="headerlink" title="4. Steps for starting with Fargate"></a>4. Steps for starting with Fargate</h1><ul><li>Create a task definition </li><li>Configure the service <ul><li>a service launches and maintains a specified number of copies of the task definition in cluster   </li></ul></li><li>configure the cluster </li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> ECS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Elasticsearch Overview</title>
      <link href="/Elasticsearch-Overview/"/>
      <url>/Elasticsearch-Overview/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><h2 id="1-1-Intro"><a href="#1-1-Intro" class="headerlink" title="1.1 Intro"></a>1.1 Intro</h2><ul><li>Full-text search</li><li>Analytics engine </li><li>Can analyze big volumes of data in near real time </li><li>used as the underlying engine/ tech that powers applications that have complex search features and requirements. </li></ul><h2 id="1-2-Use-cases"><a href="#1-2-Use-cases" class="headerlink" title="1.2 Use cases"></a>1.2 Use cases</h2><ol><li>online web store - allow customers to search for products. - use Elasticsearch to store entire product catelog and inventory. Provide search and autocomplete suggestions for them. </li><li>collect log or transaction data - mine data to look for trends, statistics, summarizations, or anomalies </li><li>price alert platform - scrape vendor prices, push them into Elasticsearch and use its reverse-search (Percolator) capability to match price movements against customer queries and eventually push the alerts out to the customer once matches are found</li><li>analytics/business-intelligence needs and want to quickly investigate, analyze, visualize, and ask ad-hoc questions on a lot of data (think millions or billions of records). In this case, you can use Elasticsearch to store data and then use Kibana to build custom dashboards that can visualize aspects of data. Additionally, you can use the Elasticsearch aggregations functionality to perform complex business intelligence queries against your data.</li></ol><h2 id="1-3-Basic-concepts"><a href="#1-3-Basic-concepts" class="headerlink" title="1.3 Basic concepts"></a>1.3 Basic concepts</h2><h3 id="1-3-1-NRT"><a href="#1-3-1-NRT" class="headerlink" title="1.3.1 NRT"></a>1.3.1 NRT</h3><p>Near Realtime: it only has a slight latency from the time you index a document until the time it becomes searchable. </p><h3 id="1-3-2-Cluster"><a href="#1-3-2-Cluster" class="headerlink" title="1.3.2 Cluster"></a>1.3.2 Cluster</h3><p>A cluster is a collection of one or more nodes <strong>(servers)</strong> that together <strong>holds your entire data</strong> and provides <strong>federated indexing and search capabilities</strong> across all nodes.</p><h3 id="1-3-3-Node"><a href="#1-3-3-Node" class="headerlink" title="1.3.3 Node"></a>1.3.3 Node</h3><p>A node is a single server that is part of your cluster, stores your data, and participates in the cluster’s indexing and search capabilities. </p><h3 id="1-3-4-Index"><a href="#1-3-4-Index" class="headerlink" title="1.3.4 Index"></a>1.3.4 Index</h3><p>An index is a collection of documents that have somewhat similar characteristics. For example, you can have an index for customer data, another index for a product catalog, and yet another index for order data. </p><p>An index is <strong>identified by a name</strong> (that must be all lowercase) and this name is used to refer to the index when performing indexing, search, update, and delete operations against the documents in it.</p><h3 id="1-3-5-Document"><a href="#1-3-5-Document" class="headerlink" title="1.3.5 Document"></a>1.3.5 Document</h3><p>A document is a basic unit of information that can be indexed. For example, you can have a document for a single customer, another document for a single product, and yet another for a single order. This document is expressed in JSON (JavaScript Object Notation) which is a ubiquitous internet data interchange format.</p><p>Within an index/type, you can store as many documents as you want. Note that although a document physically resides in an index, a document actually must be indexed/assigned to a type inside an index.</p><h3 id="1-3-6-Shards-amp-Replicas"><a href="#1-3-6-Shards-amp-Replicas" class="headerlink" title="1.3.6 Shards &amp; Replicas"></a>1.3.6 Shards &amp; Replicas</h3><p>An index can potentially store a large amount of data that can exceed the hardware limits of a single node. For example, a single index of a billion documents taking up 1TB of disk space may not fit on the disk of a single node or may be too slow to serve search requests from a single node alone.</p><p>To solve this problem, Elasticsearch provides the ability to <strong>subdivide your index into multiple pieces called shards.</strong> When you create an index, you can simply define the number of shards that you want. Each shard is in itself a fully-functional and independent “index” that can be hosted on any node in the cluster.</p><p>Sharding brings you several benefits: </p><ol><li>Allow you to horizontally <strong>split/ scale content volume</strong> </li><li>Allow you to <strong>distribute and parallelize</strong> operations across shards thus increasing performance/ throughput </li></ol><p>Mechanics of how a shard is distributed and how its documents are aggregated back into search reqeusts are completely managed by elasticSearch. </p><p>To summarize, each index can be split into multiple shards. An index can also be replicated zero (meaning no replicas) or more times. Once replicated, each index will have primary shards (the original shards that were replicated from) and replica shards (the copies of the primary shards).</p><h1 id="2-Benefits"><a href="#2-Benefits" class="headerlink" title="2. Benefits"></a>2. Benefits</h1><ol><li>search faster compared with database </li><li>During an indexing operation, Elasticsearch converts raw data such as log files or message files into internal documents and stores them in a basic data structure similar to a JSON object. Each document is a simple set of correlating keys and values: the keys are strings, and the values are one of numerous data types—strings, numbers, dates, or lists.</li></ol><h1 id="3-Where-do-the-Files-come-from"><a href="#3-Where-do-the-Files-come-from" class="headerlink" title="3. Where do the Files come from?"></a>3. Where do the Files come from?</h1><p>Elasticsearch uses Lucene under the hood to handle the indexing and querying on the shard level, the files in the data directory are written by both Elasticsearch and Lucene. </p><p>Lucene is responsible for writing and maintaining the L<strong>ucene index files while Elasticsearch writes metadata related to features on top of Lucene</strong>, such as field mappings, index settings and other cluster metadata – end user and supporting features that do not exist in the low-level Lucene but are provided by Elasticsearch.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/current/getting-started.html</a> </li><li><a href="http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html</a> </li><li><a href="https://www.elastic.co/blog/found-dive-into-elasticsearch-storage" target="_blank" rel="noopener">https://www.elastic.co/blog/found-dive-into-elasticsearch-storage</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elastic Search </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS X-Ray Intro(Java)</title>
      <link href="/AWS-X-Ray-Intro-Java/"/>
      <url>/AWS-X-Ray-Intro-Java/</url>
      
        <content type="html"><![CDATA[<p>Fancy tech! You now can trace the performance not only for request and response, also about calls that your application makes to downstream AWS resources, microservices, databases and HTTP web APIs with AWS X-ray! </p><h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><h2 id="1-1-What-does-X-ray-do"><a href="#1-1-What-does-X-ray-do" class="headerlink" title="1.1 What does X-ray do?"></a>1.1 What does X-ray do?</h2><ul><li>service that collects data about requests that your application serves</li><li>provide tools to view, filter, gain insights into that data </li><li>Can see detailed information not only about the request and response, but also about calls that your application makes to downstream AWS resources, microservices, databases and HTTP web APIs. </li></ul><h2 id="1-2-X-ray-SDK-provides"><a href="#1-2-X-ray-SDK-provides" class="headerlink" title="1.2 X-ray SDK provides"></a>1.2 X-ray SDK provides</h2><ul><li>Interceptors: add to your code to trace incoming HTTP requests </li><li>Client Handlers: instrument AWS SDK clients that your application uses to call other AWS services </li><li>An HTTP clinet to use to to instrument calls to other internal and external HTTP web services </li></ul><h2 id="1-3-Mechanism"><a href="#1-3-Mechanism" class="headerlink" title="1.3 Mechanism"></a>1.3 Mechanism</h2><p>SDK sends JSON segment documents to a daemon process listening for UDP traffic. <strong><em>The X-Ray daemon buffers segments in a queue and uploads them to X-Ray in batches</em></strong></p><p>X-Ray use the trace data to generate a detailed service graph, which shows the client, your front-end service, and backend services that your front-end service calls to process requests and persist data.</p><h1 id="2-Use-cases-and-requirement"><a href="#2-Use-cases-and-requirement" class="headerlink" title="2. Use cases and requirement"></a>2. Use cases and requirement</h1><ul><li><p>Use X-Ray SDK and AWS service integration to instrument requests to your applications that are running locally or on AWS compute services. </p></li><li><p>X-Ray SDK records data about <strong>incoming and outgoing requests</strong> and sends it to the X-Ray daemon(relays the data in batches to X-Ray)</p></li><li><p>When your application calls DDB to retrieve user information from a DDB table, the X-Ray SDK records data from both <strong>the client request and the downstream call</strong> to DynamoDB. </p></li><li><p>Service Integration </p><ul><li>Add tracing headers to incoming requests </li><li>send trace data to X-Ray </li><li>run the X-Ray daemon </li></ul></li><li><p>Java Integration </p><ul><li>Add a servlet filter </li></ul></li><li><p>Supported AWS services</p><ul><li>AWS lambda </li><li>Amazon API Gateway </li><li>Elastic Load Balancing </li><li>AWS Elastic ZBeanstalk </li></ul></li><li><p>Code and configuration changes </p><ul><li>Detailed tracing of front-end and downstream calls requires only <strong>minimal changes to build and deploy-time configuration</strong>.</li><li><strong>AWS resource configuration</strong>: Change AWS resource settings to <strong>instrument requests to a Lambda function</strong>. Run the X-Ray daemon on the instances in your Elastic Beanstalk environment by changing an option setting</li><li><strong>Build configuration</strong>: Take X-Ray SDK for Java submodules as a <strong>compile-time dependency</strong> to instrument all downstream requests to AWS services, and to resources such as Amazon DynamoDB tables, Amazon SQS queues, and Amazon S3 buckets.</li><li><strong>Application configuration</strong>: To instrument incoming HTTP requests, add a <strong>servlet filter</strong> to your Java application</li><li><strong>Class or object configuration</strong> – To instrument outgoing HTTP calls in Java, import the X-Ray SDK for Java version of HttpClientBuilder instead of the Apache.org version.</li><li><strong>Functional Changes</strong>: Add a *<em>request handler *</em>to an AWS SDK client to instrument calls that it makes to AWS services. Create subsegments to group downstream calls, and add debug information to segments with annotations and metadata.</li></ul></li></ul><h1 id="3-Concepts"><a href="#3-Concepts" class="headerlink" title="3. Concepts"></a>3. Concepts</h1><h2 id="3-1-Segments"><a href="#3-1-Segments" class="headerlink" title="3.1 Segments"></a>3.1 Segments</h2><p>The compute resources running your application logic send data about their work as <strong>segments</strong>. A segment provides the resource’s name, details about the request, and details about the work done. For example, when an HTTP request reaches your application, it can record the following data about:</p><ul><li>Host </li><li>Request </li><li>Response </li><li>Work done<ul><li>start time </li><li>end time</li><li>subsegments </li></ul></li><li>issues that occur </li></ul><h2 id="3-2-Subsegments"><a href="#3-2-Subsegments" class="headerlink" title="3.2 Subsegments"></a>3.2 Subsegments</h2><p>A segment can break down the data about the work done into subsegments. Subsegments provide more granular timing information and details about downstream calls that your application made to fulfill the original request. A subsegment can contain additional details about a call to an AWS service, an external HTTP API, or an SQL database. You can even define arbitrary subsegments to instrument specific functions or lines of code in your application.</p><h2 id="3-3-Service-Graph"><a href="#3-3-Service-Graph" class="headerlink" title="3.3 Service Graph"></a>3.3 Service Graph</h2><p>X-Ray uses the data that your application sends to generate a service graph. Each AWS resource that sends data to X-Ray appears as a service in the graph. Edges connect the services that work together to serve requests. Edges connect clients to your application, and your application to the downstream services and resources that it uses.</p><p>A service graph is <strong>a JSON document</strong> that contains information about the services and resources that make up your application. The X-Ray console uses the service graph to generate a visualization or service map.</p><h2 id="3-4-Traces"><a href="#3-4-Traces" class="headerlink" title="3.4 Traces"></a>3.4 Traces</h2><p>A trace ID <strong>tracks the path of a request through whole application</strong>. A trace collects all the segments generated by a single request. That request is typically an HTTP GET or POST request that travels through a load balancer, hits your application code, and generates downstream calls to other AWS services or external web APIs. </p><p>The <strong>first supported service</strong> that the HTTP request interacts with adds a trace ID header to the request, and propagates it downstream to track the latency, disposition, and other request data.</p><h2 id="3-5-Sampling"><a href="#3-5-Sampling" class="headerlink" title="3.5 Sampling"></a>3.5 Sampling</h2><p>To ensure efficient tracing and provide a representative sample of the requests that your application serves, the X-Ray SDK applies a sampling algorithm to determine which requests get traced. By default, the X-Ray SDK records the <strong>first request</strong> each second, and <strong>five percent</strong> of any additional requests.</p><h2 id="3-6-Tracing-Header"><a href="#3-6-Tracing-Header" class="headerlink" title="3.6 Tracing Header"></a>3.6 Tracing Header</h2><p>All requests are traced, up to a configurable minimum. After reaching that minimum, a percentage of requests are traced to avoid unnecessary cost. The sampling decision and trace ID are <strong>added to HTTP requests in tracing headers named X-Amzn-Trace-Id</strong>.</p><h1 id="4-AWS-X-Ray-Daemon"><a href="#4-AWS-X-Ray-Daemon" class="headerlink" title="4. AWS X-Ray Daemon"></a>4. AWS X-Ray Daemon</h1><p>Daemon is a software application, listening for traffic on UDP port 2000, gather <strong>raw segment data</strong>, and relays it to the AWS X-ray API. </p><p>You need give Daemon enough permissions to send data to X-Ray. </p><h1 id="5-Working-with-Java"><a href="#5-Working-with-Java" class="headerlink" title="5. Working with Java"></a>5. Working with Java</h1><p>The X-Ray SDK for Java provides a class named <strong>AWSXRay</strong> that provides the global recorder, a <strong>TracingHandler</strong> that you can use to instrument your code. You can configure the global recorder to customize the <strong>AWSXRayServletFilter</strong> that creates segments for incoming HTTP calls.</p><h2 id="5-1-Sampling-Rules"><a href="#5-1-Sampling-Rules" class="headerlink" title="5.1 Sampling Rules"></a>5.1 Sampling Rules</h2><p>SDK uses the sampling rules deined in the X-Ray console to determine which requests to record. The default rule traces the first request each second, and five percent of any additional requests across all services sending trances to X-Ray. </p><h2 id="5-2-Tracing-Incoming-requests-with-the-X-Ray-SDK"><a href="#5-2-Tracing-Incoming-requests-with-the-X-Ray-SDK" class="headerlink" title="5.2 Tracing Incoming requests with the X-Ray SDK"></a>5.2 Tracing Incoming requests with the X-Ray SDK</h2><p>Use the X-Ray SDK to *<em>trace incoming HTTP requests *</em>that your application serves on an EC2 instance in Amazon EC2, AWS Elastic Beanstalk, or Amazon ECS. </p><p>Use a <strong>Filter</strong> to instrument incoming HTTP requests. When you add the X-Ray servlet filter to your application, the X-Ray SDK for Java <strong>creates a segment for each sampled request</strong>. This segment includes timing, method, and disposition of the HTTP request. Additional instrumentation creates subsegments on this segment.</p><p>Each segment has a name that identifies your application in the service map. The segment can be named statically, or you can configure the SDK to name it dynamically based on the host header in the incoming request. Dynamic naming lets you group <strong>traces based on the domain name in the request</strong></p><p>The message handler creates a segment for each incoming request with an http block that contains the following information:</p><ul><li>HTTP method</li><li>Client address </li><li>Response code </li><li>Timing </li><li>User agent </li><li>Content length </li></ul><h2 id="5-3-Tracing-AWS-SDK-calls-with-the-X-Ray-SDK-for-Java"><a href="#5-3-Tracing-AWS-SDK-calls-with-the-X-Ray-SDK-for-Java" class="headerlink" title="5.3 Tracing AWS SDK calls with the X-Ray SDK for Java"></a>5.3 Tracing AWS SDK calls with the X-Ray SDK for Java</h2><p>When your application <strong>makes calls to AWS services to store data</strong>, write to a queue, or send notifications, the X-Ray SDK for Java <strong>tracks the calls downstream in subsegments</strong>. Traced AWS services and resources that you access within those services (for example, an Amazon S3 bucket or Amazon SQS queue), appear as downstream nodes on the service map in the X-Ray console.</p><p>The X-Ray SDK for Java <strong>automatically instruments all AWS SDK clients when you include the aws-sdk and aws-sdk-instrumentor submodules in your build</strong>. If you don’t include the Instrumentor submodule, you can choose to instrument some clients while excluding others.</p><p>E.G: instrument an AmazonDynamoDB client, pass a tracing handler to AmazonDynamoDBClientBuilder</p><pre><code>import com.amazonaws.xray.AWSXRay;import com.amazonaws.xray.handlers.TracingHandler;...public class MyModel {  private AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()        .withRegion(Regions.fromName(System.getenv(&quot;AWS_REGION&quot;)))        .withRequestHandlers(new TracingHandler(AWSXRay.getGlobalRecorder()))        .build();</code></pre><h2 id="5-4-Tracing-Calls-to-Downstream-HTTP-Web-Services-with-the-X-Ray-SDK-for-Java"><a href="#5-4-Tracing-Calls-to-Downstream-HTTP-Web-Services-with-the-X-Ray-SDK-for-Java" class="headerlink" title="5.4 Tracing Calls to Downstream HTTP Web Services with the X-Ray SDK for Java"></a>5.4 Tracing Calls to Downstream HTTP Web Services with the X-Ray SDK for Java</h2><p>When your application makes call to microservices or publis HTTP APIs, you can use the X-Ray SDK for java’s version of <strong>HTTPClient</strong> to instrument those calls and add the API to the service graph as a downstream service. ** Use the xray HttpClientBuilder **</p><h2 id="5-5-Custom-subsegments-with-the-X-Ray-SDK-for-Java"><a href="#5-5-Custom-subsegments-with-the-X-Ray-SDK-for-Java" class="headerlink" title="5.5 Custom subsegments with the X-Ray SDK for Java"></a>5.5 Custom subsegments with the X-Ray SDK for Java</h2><p>Subsegments extend a trace’s segment with details about work done in order to serve a request. Each time you make a call with an instrumented client, the X-Ray SDK records the information generated in a subsegment. You can create additional subsegments to group other subsegments, to measure the performance of a section of code, or to record annotations and metadata.</p><p>To manage subsegments, use the beginSubsegment and endSubsegment methods.</p><pre><code>import com.amazonaws.xray.AWSXRay;...  public void saveGame(Game game) throws SessionNotFoundException {    // wrap in subsegment    Subsegment subsegment = AWSXRay.beginSubsegment(&quot;Save Game&quot;);    try {      // check session      String sessionId = game.getSession();      if (sessionModel.loadSession(sessionId) == null ) {        throw new SessionNotFoundException(sessionId);      }      mapper.save(game);    } catch (Exception e) {      subsegment.addException(e);      throw e;    } finally {      AWSXRay.endSubsegment();    }  }</code></pre><h2 id="5-6-Add-Annotations-and-Metadata-to-Segments-with-the-X-Ray-SDK-for-Java"><a href="#5-6-Add-Annotations-and-Metadata-to-Segments-with-the-X-Ray-SDK-for-Java" class="headerlink" title="5.6 Add Annotations and Metadata to Segments with the X-Ray SDK for Java"></a>5.6 Add Annotations and Metadata to Segments with the X-Ray SDK for Java</h2><p> You can add annotations and metadata to the segments that the X-Ray SDK creates, or to custom subsegments that you create.</p><p> Annotations are key-value pairs with string, number, or Boolean values. Annotations are indexed for use with filter expressions. Use annotations to record data that you <strong>want to use to group traces</strong> in the console, or when calling the GetTraceSummaries API.</p><p> Metadata are key-value pairs that can have values of any type, including objects and lists, but are not indexed for use with filter expressions. <strong>Use metadata to record additional data that you want stored in the trace but don’t need to use with search</strong>.</p>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Distributed Tracing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS-VPC</title>
      <link href="/AWS-VPC/"/>
      <url>/AWS-VPC/</url>
      
        <content type="html"><![CDATA[<h1 id="1-What-is-a-VPC"><a href="#1-What-is-a-VPC" class="headerlink" title="1. What is a VPC?"></a>1. What is a VPC?</h1><p>A virtual private cloud (VPC) is a <strong>virtual network</strong> dedicated to your AWS account. It is logically isolated from other virtual networks in the AWS Cloud. Amazon Virtual Private Cloud (Amazon VPC) enables you to launch AWS resources into a virtual network that you’ve defined. This virtual network closely resembles a traditional network that you’d operate in your own data center, with the benefits of using the scalable infrastructure of AWS. </p><p><img src="https://i.loli.net/2020/01/30/iduxJISlrmp5h2s.jpg" alt="fig1.jpg"></p><p>It allows you to provision a <strong>logically isolated section</strong> of the AWS cloud, where you can launch AWS resources in a virtual network that you define. You have complete control over your virtual networking environment including: </p><ul><li>selection of your own IP address ranges</li><li>creation of subnets </li><li>configuration of route tables and network gateways </li><li>create a hardware Virtual Private Network(VPN) connection between your corporate datacenter and your VPC and leverage the AWS cloud as an extension of your corporate datacenter. </li></ul><p><img src="https://i.loli.net/2020/01/30/kjVFzSHfdcyUspB.jpg" alt="fig2.jpg"></p><h1 id="2-Protection-through-Security-Groups-and-Control-Lists"><a href="#2-Protection-through-Security-Groups-and-Control-Lists" class="headerlink" title="2. Protection through Security Groups and Control Lists"></a>2. Protection through Security Groups and Control Lists</h1><p>We can leverage multiple layers of security, including security groups and network access control lists, to help control access to Amazon EC2 instances in each subnet. <strong>Security groups</strong> act as a firewall for the Amazon EC2 instances controlling both inbound and outbound traffic <strong>at the instance level</strong>. <strong>Network Acess Control Lists</strong>(NACL’s) act as a firewall for associated subnets controlling both inbound and outbound traffic <strong>at the subnet level</strong>. </p><table><thead><tr><th><strong>Security Group</strong></th><th><strong>Network ACL</strong></th></tr></thead><tbody><tr><td>Operates at the instance level (first layer of defense).</td><td>Operates at the subnet level (second layer of defense)</td></tr><tr><td>Is stateful. Return traffic is automatically allowed, regardless of any rules.</td><td>Is stateless. Return traffic must be explicitly allowed by rules.</td></tr><tr><td>Applies to an instance only if someone specifies the security group when launching the instance, or associates the security group with the instance later on.</td><td>Automatically applies to all instances in the subnets associated with it (backup layer of defense, so you don’t have to rely on someone specifying the security group).</td></tr></tbody></table><h1 id="3-Primary-Components-needed-to-configure-networking-in-a-VPC"><a href="#3-Primary-Components-needed-to-configure-networking-in-a-VPC" class="headerlink" title="3. Primary Components needed to configure networking in a VPC"></a>3. Primary Components needed to configure networking in a VPC</h1><h2 id="3-1-Network-Interfaces"><a href="#3-1-Network-Interfaces" class="headerlink" title="3.1 Network Interfaces"></a>3.1 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_ElasticNetworkInterfaces.html" target="_blank" rel="noopener">Network Interfaces</a></h2><p>A logical networking component in a VPC that represents a virtual network card. Includes attributes as following: </p><ul><li><p>a primary private IPv4 address</p></li><li><p>one or more secondary private IPv4 addresses</p></li><li><p>one Elastic IP address per private IPv4 address</p></li><li><p>one public IPv4 address, which can be auto-assigned to the network interface for eth0 when you launch an instance</p></li><li><p>one or more IPv6 addresses</p></li><li><p>one or more security groups</p></li><li><p>a MAC address</p></li><li><p>a source/destination check flag</p></li><li><p>a description</p></li></ul><p>You can create a network interface, attach it to an instance, detach it from an instance, and attach it to another instance. A network interface’s attributes follow it as it is attached or detached from an instance and reattached to another instance. When you move a network interface from one instance to another, network traffic is redirected to the new instance.</p><h2 id="3-2-Route-Tables"><a href="#3-2-Route-Tables" class="headerlink" title="3.2 Route Tables"></a>3.2 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Route_Tables.html" target="_blank" rel="noopener">Route Tables</a></h2><p>A route table contains a set of rules, called routes, that are used to determine where network traffic is directed.</p><p>Each subnet in your VPC must be associated with a route table; the table controls the routing for the subnet. A subnet can only be associated with one route table at a time, but you can associate multiple subnets with the same route table.</p><h2 id="3-3-Internet-Gateway"><a href="#3-3-Internet-Gateway" class="headerlink" title="3.3 Internet Gateway"></a>3.3 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Internet_Gateway.html" target="_blank" rel="noopener">Internet Gateway</a></h2><p>A VPC component that allows communication between instances in your VPC and the Internet. In theory, it is what the traffic between your VPC and the public internet flows through.</p><h2 id="3-4-Egress-Only-Internet-Gateway"><a href="#3-4-Egress-Only-Internet-Gateway" class="headerlink" title="3.4 Egress-Only Internet Gateway"></a>3.4 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/egress-only-internet-gateway.html" target="_blank" rel="noopener">Egress-Only Internet Gateway</a></h2><p>An egress-only Internet gateway is a horizontally scaled, redundant, and highly available VPC component that allows outbound communication over IPv6 from instances in your VPC to the Internet, and prevents the Internet from initiating an IPv6 connection with your instances.</p><h2 id="3-5-DHCP-Options-Sets"><a href="#3-5-DHCP-Options-Sets" class="headerlink" title="3.5 DHCP Options Sets"></a>3.5 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_DHCP_Options.html" target="_blank" rel="noopener">DHCP Options Sets</a></h2><p>Dynamoc Host Configuration Protocol provides a standard for passing configuraion information to hosts on a TCP/IP network. The options field of a DHCP message contains the configuration parameters. Some of those parameters are the domain name, domain name server, and the netbios-node-type.</p><h2 id="3-6-Domain-Name-System"><a href="#3-6-Domain-Name-System" class="headerlink" title="3.6 Domain Name System"></a>3.6 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-dns.html" target="_blank" rel="noopener">Domain Name System</a></h2><p>Domain Name System (DNS) is a standard by which names used on the Internet are resolved to their corresponding IP addresses. A DNS hostname is a name that uniquely and absolutely names a computer; it’s composed of a host name and a domain name. DNS servers resolve DNS hostnames to their corresponding IP addresses.</p><p>Public IPv4 addresses enable communication over the Internet, while private IPv4 addresses enable communication within the network of the instance (either EC2-Classic or a VPC).</p><h2 id="3-7-Elastic-IP-Addresses"><a href="#3-7-Elastic-IP-Addresses" class="headerlink" title="3.7 Elastic IP Addresses"></a>3.7 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-eips.html" target="_blank" rel="noopener">Elastic IP Addresses</a></h2><p>An Elastic IP address is a static public IPv4 address designed for dynamic cloud computing. You can associate an Elastic IP address with any instance or network interface for any VPC in your account. </p><p>With an Elastic IP address, <strong>you can mask the failure of an instance by rapidly remapping the address to another instance in your VPC.</strong> Note that the advantage of associating the Elastic IP address with the network interface instead of directly with the instance is that you can move all the attributes of the network interface from one instance to another in a single step.</p><h2 id="3-8-VPC-Endpoints"><a href="#3-8-VPC-Endpoints" class="headerlink" title="3.8 VPC Endpoints"></a>3.8 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html" target="_blank" rel="noopener">VPC Endpoints</a></h2><p>Enables private connectivity to services hosted in AWS, from within your VPC without using an Internet Gateway, VPN, Network Address Translation (NAT) devices, or firewall proxies.</p><h2 id="3-9-NAT-Gateways"><a href="#3-9-NAT-Gateways" class="headerlink" title="3.9 NAT Gateways"></a>3.9 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-nat.html" target="_blank" rel="noopener">NAT Gateways</a></h2><p>A highly available, managed Network Address Translation (NAT) service for your resources in a private subnet to access the Internet. A NAT device forwards traffic from the instances in the private subnet to the internet or other AWS services, and then sends the response back to the instances. When traffic goes to the internet, the source IPv4 address is replaced with the NAT device’s address and similarly, when the response traffic goes to those instances, the NAT device translates the address back to those instances’ private IPv4 addresses.</p><h2 id="3-10-VPC-Peering"><a href="#3-10-VPC-Peering" class="headerlink" title="3.10 VPC Peering"></a>3.10 <a href="https://docs.aws.amazon.com/vpc/latest/userguide/vpc-peering.html" target="_blank" rel="noopener">VPC Peering</a></h2><p>A peering connection enables you to route traffic via private IP addresses between two peered VPCs.</p><p>A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them privately. Instances in either VPC can communicate with each other as if they are within the same network. You can create a VPC peering connection between your own VPCs, with a VPC in another AWS account, or with a VPC in a different AWS Region.</p><h1 id="4-Securing-VPCs"><a href="#4-Securing-VPCs" class="headerlink" title="4. Securing VPCs"></a>4. Securing VPCs</h1><h2 id="4-1-Security-Groups"><a href="#4-1-Security-Groups" class="headerlink" title="4.1 Security Groups"></a>4.1 Security Groups</h2><p>A firewall for associated Amazon EC2 instances, controlling both inbound and outbound traffic at the instance level</p><h2 id="4-2-Network-Access-Control-Lists"><a href="#4-2-Network-Access-Control-Lists" class="headerlink" title="4.2 Network Access Control Lists"></a>4.2 Network Access Control Lists</h2><p>A firewall for associated subnets, controlling both inbound and outbound traffic at the subnet level.</p><h2 id="4-3-Flow-Logs"><a href="#4-3-Flow-Logs" class="headerlink" title="4.3 Flow Logs"></a>4.3 Flow Logs</h2><p>Capture information about the IP traffic going to and from network interfaces in your VPC.</p><h2 id="4-4-Route-Tables"><a href="#4-4-Route-Tables" class="headerlink" title="4.4 Route Tables"></a>4.4 Route Tables</h2><p>A set of rules, called routes, that are used to determine where network traffic is directed</p><p>The following diagram illustrates the layers of security provided by security groups and network ACLs. In this example, traffic from an Internet gateway is routed to the appropriate subnet using the routes in the routing table. The rules of the network ACL associated with the subnet control which traffic is allowed to the subnet. The rules of the security group associated with an instance control which traffic is allowed to the instance.</p><p><img src="https://i.loli.net/2020/01/30/aeb1wYkCq2c9QXr.png" alt="fig3.png"></p><h1 id="5-Default-VPC"><a href="#5-Default-VPC" class="headerlink" title="5. Default VPC"></a>5. Default VPC</h1><p>The default VPC is suitable for getting started quickly, and for launching public instances such as a blog or simple website. With a default VPC, you don’t have to deal with VPC creation and configuration. You can immediately start launching Amazon EC2 instances into your default VPC. You can also use services such as Elastic Load Balancing, Amazon RDS, and Amazon EMR in your default VPC.</p><p>You can use a default VPC as you would use any other VPC by: </p><ul><li>Adding additional non-default subnets</li><li>Modifying the main route table </li><li>Adding additional route tables </li><li>Associating additional security groups </li><li>Updating the rules of the default security group</li><li>Adding VPN connections</li><li>Adding more IPv4 CIDR blocks </li></ul><p>The following figure illustrates the key components that we set up for a default VPC. </p><p><img src="https://i.loli.net/2020/01/30/ig6ZwzSrFmqojPk.png" alt="fig4.png"></p>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> VPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS Lambda</title>
      <link href="/AWS-Lambda/"/>
      <url>/AWS-Lambda/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><p>A compute service that lets you run code without provisioning or managing servers. It can executes your code thousands per second. You pay for the compute time you consume.</p><p>Lambda executes your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring and logging.</p><p>You can run AWS lambda to run your code in response to events, such as changes to data in an Amazon S3 bucket or an Amazon DynamoDB table; to run your code in response to HTTP requests using Amazon API gateway; or invoke your code using API calls made using AWS SDKs. </p><h1 id="2-Getting-started"><a href="#2-Getting-started" class="headerlink" title="2. Getting started"></a>2. Getting started</h1><h2 id="2-1-Configuration-on-console-page"><a href="#2-1-Configuration-on-console-page" class="headerlink" title="2.1 Configuration on console page"></a>2.1 Configuration on console page</h2><ul><li>environment variables: for Lambda functions enable you to dynamically pass settings to your function code and libraries, without making changes to your code.</li><li>Tags: are key-value pairs that you attach to AWS resources to better organize them. </li><li>Execution role: which allows you to administer security on your function, using defined roles and policies or creating new ones.</li><li>Basic settings: allows you to dictate the memory allocation and timeout limit for your Lambda function.</li><li>Network: allow you to select a VPC your function will access</li><li>Debugging and error handling: allow you to select a AWS <a href="https://docs.aws.amazon.com/lambda/latest/dg/dlq.html" target="_blank" rel="noopener">Lambda Function Dead Letter Queues</a> resource to analyze failed function invocation retries. </li><li>Concurrency: allows you to allocate a specific limit of concurrent executions allowed for this function</li><li>Auditing and compliance: logs function invocations for operational and risk auditing, governance and compliance. </li></ul><h2 id="2-2-Lambda-concept"><a href="#2-2-Lambda-concept" class="headerlink" title="2.2 Lambda concept"></a>2.2 Lambda concept</h2><p>Lambda can automatically scales up the number of instances of your function to handle high number of events. </p><ul><li>Function: A script or program that runs in AWS lambda. Lambda passes invocation events to your function. The function processes an event and returns a response</li><li>Runtimes: Lambda runtimes allow functions in different languages to run in the same base execution environment, you configure your function to use a runtime that matches your programming language. The runtime sits in between the Lambda service and your function code, relaying invocation events, context information and responses between the two. </li><li>Layers: Lambda layers are a distribution mechanism for libraries, custom runtimes and other function dependencies. Layers let you manage your in-development function code independently from the unchanging code and resources that it uses. You can configure your function to use layers that you create, layers provided by AWS, or layers from other AWS customers.</li><li>Event source: An AWS service that triggers your function and executes its logic. </li><li>Downstream resources: An AWS service that your lambda function calls once it is triggered</li><li>Log streams: While Lambda automatically monitors your function invocations and reports metrics to CloudWatch, you can annotate your function code with custom logging statements that allow you to analyze the execution flow and performance of your Lambda function to ensure it’s working properly.</li></ul><h2 id="2-3-Programming-Model"><a href="#2-3-Programming-Model" class="headerlink" title="2.3 Programming Model"></a>2.3 Programming Model</h2><p>Regardless of the language you choose, there is a common pattern ti write code for a Lambda Function includes concepts as follow:</p><h3 id="2-3-1-Handler"><a href="#2-3-1-Handler" class="headerlink" title="2.3.1 Handler"></a>2.3.1 Handler</h3><p>The function AWS Lambda calls to start execution of your lambda function. When a Lambda function is invoked, Lambda starts executing your code by calling the handler function</p><h3 id="2-3-2-Context"><a href="#2-3-2-Context" class="headerlink" title="2.3.2 Context"></a>2.3.2 Context</h3><p>Lambda also passes a context object to the handler function, as the second parameter. Via this context object your code can interact with Lambda</p><h3 id="2-3-3-Logging"><a href="#2-3-3-Logging" class="headerlink" title="2.3.3 Logging"></a>2.3.3 Logging</h3><p>Function can contain logging statements, it writes these logs to cloudWatch logs. </p><h3 id="2-3-4-Exceptions"><a href="#2-3-4-Exceptions" class="headerlink" title="2.3.4 Exceptions"></a>2.3.4 Exceptions</h3><p>Function needs to communicate the result of the function execution to AWS Lambda. Many ways to end a request or to notify AWS Lambda an error occured during execution</p><h3 id="2-3-5-Concurrency"><a href="#2-3-5-Concurrency" class="headerlink" title="2.3.5 Concurrency"></a>2.3.5 Concurrency</h3><p>When your function is invoked more quickly than a single instance of your function can process events, Lambda scales by running additional instances. Each instance of your function handles only one request at a time, so you don’t need to worry about synchronizing threads or processes. You can, however, use asynchronous language features to process batches of events in parallel, and save data to the /tmp directory for use in future invocations on the same instance. </p><h1 id="3-Building-Lambda-Functions-with-Java"><a href="#3-Building-Lambda-Functions-with-Java" class="headerlink" title="3. Building Lambda Functions with Java"></a>3. Building Lambda Functions with Java</h1><h2 id="3-1-Handler-Input-Output-Types"><a href="#3-1-Handler-Input-Output-Types" class="headerlink" title="3.1 Handler Input/ Output Types"></a>3.1 Handler Input/ Output Types</h2><p>When AWS lambda executes the Lambda function, it invokes the handler. First parameter is the input to the handler which can be event data (published by an event source) or custom input you provide such as a string or any custom data object. </p><p>AWS Lambda supports the following input/ output types for a handler: </p><ul><li><p>Simple Java types (AWS Lambda supports the String, Integer, Boolean, Map and List types )</p></li><li><p>POJO</p></li><li><p>stream type </p><h3 id="3-1-1-Handler-input-output-String-Type"><a href="#3-1-1-Handler-input-output-String-Type" class="headerlink" title="3.1.1 Handler input/ output: String Type"></a>3.1.1 Handler input/ output: String Type</h3><p>  package example;</p><p>  import com.amazonaws.services.lambda.runtime.Context; </p><p>  public class Hello {</p><pre><code>  public String myHandler(String name, Context context) {      return String.format(&quot;Hello %s.&quot;, name);  }</code></pre><p>  }</p></li></ul><p>When you invoke a Lambda function asynchronously, any return value by your Lambda function will be ignored. Therefore you might want to <strong><em>set the return type to void</em></strong> to make this clear in your code </p><h3 id="3-1-2-Handler-Input-Output-POJO"><a href="#3-1-2-Handler-Input-Output-POJO" class="headerlink" title="3.1.2 Handler Input/ Output: POJO"></a>3.1.2 Handler Input/ Output: POJO</h3><pre><code>package example;import com.amazonaws.services.lambda.runtime.Context; public class HelloPojo {    // Define two classes/POJOs for use with Lambda function.    public static class RequestClass {      ...    }    public static class ResponseClass {      ...    }    public static ResponseClass myHandler(RequestClass request, Context context) {        String greetingString = String.format(&quot;Hello %s, %s.&quot;, request.getFirstName(), request.getLastName());        return new ResponseClass(greetingString);    }}</code></pre><p>Suppose your application events generate data that includes first name and last name as shown:</p><pre><code>{ &quot;firstName&quot;: &quot;John&quot;, &quot;lastName&quot;: &quot;Doe&quot; }  </code></pre><p>For this example, the handler receives this JSON and returns the string “Hello John Doe”.</p><pre><code>public static ResponseClass handleRequest(RequestClass request, Context context){        String greetingString = String.format(&quot;Hello %s, %s.&quot;, request.firstName, request.lastName);        return new ResponseClass(greetingString);}</code></pre><p>To create a Lambda function with this handler, you must provide implementation of the input and output types as shown in the following Java example. The HelloPojo class defines the handler method.</p><pre><code>package example;import com.amazonaws.services.lambda.runtime.Context; import com.amazonaws.services.lambda.runtime.RequestHandler;public class HelloPojo implements RequestHandler&lt;RequestClass, ResponseClass&gt;{       public ResponseClass handleRequest(RequestClass request, Context context){        String greetingString = String.format(&quot;Hello %s, %s.&quot;, request.firstName, request.lastName);        return new ResponseClass(greetingString);    }}</code></pre><p>In order to implement the input type, add the following code to a separate file and name it RequestClass.java. Place it next to the HelloPojo.java class in your directory structure:</p><pre><code>package example;     public class RequestClass {        String firstName;        String lastName;        public String getFirstName() {            return firstName;        }        public void setFirstName(String firstName) {            this.firstName = firstName;        }        public String getLastName() {            return lastName;        }        public void setLastName(String lastName) {            this.lastName = lastName;        }        public RequestClass(String firstName, String lastName) {            this.firstName = firstName;            this.lastName = lastName;        }        public RequestClass() {        }    }</code></pre><p>In order to implement the output type, add the following code to a separate file and name it ResponseClass.java. Place it next to the HelloPojo.java class in your directory structure:</p><pre><code>package example; public class ResponseClass {    String greetings;    public String getGreetings() {        return greetings;    }    public void setGreetings(String greetings) {        this.greetings = greetings;    }    public ResponseClass(String greetings) {        this.greetings = greetings;    }    public ResponseClass() {    }}</code></pre><h2 id="3-2-Context-Object-in-Java"><a href="#3-2-Context-Object-in-Java" class="headerlink" title="3.2 Context Object in Java"></a>3.2 Context Object in Java</h2><p>When Lambda runs your function, it passes a context object to the handler. The object provides methods and properties that provide information about the invocation, function and execution environment. </p><ul><li>getRemainingTimeInMillis()</li><li>getFunctionName()</li><li>getFunctionVersion()</li><li>getInvokedFunctionArn() - Returns the Amazon Resource Name(ARN) used to invoke the function. Indicates if the invoker specified a version number or alias. </li><li>getMemoryLimitInMB()</li><li>getAwsRequestId()</li><li>getLogGroupName()</li><li>getIdentity()</li><li>getClientContext()</li><li>getLogger() </li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Lambda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AWS DynamoDBClient vs DynamoDBMapper</title>
      <link href="/AWS-DynamoDBClient-vs-DynamoDBMapper/"/>
      <url>/AWS-DynamoDBClient-vs-DynamoDBMapper/</url>
      
        <content type="html"><![CDATA[<p>Recently just did a project related with DynamoDB, use both DynamoDBClient and DynamoDBMapper in different circumstances. In this post, will compare those two, regarding with its convenience, latency, and their differences by nature. </p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>DynamoDBClient is Service client for accessing DynamoDB; while DynamoDBMapper use ORM (Object relational mapping) for converting data between incompatible type systems using object-oriented programming languages. </p><h2 id="1-1-How-to-use-DDBClient"><a href="#1-1-How-to-use-DDBClient" class="headerlink" title="1.1 How to use DDBClient"></a>1.1 How to use DDBClient</h2><pre><code>// Create POJO@Datapublic class Whitelist {    private String id;    private String content;    private String status;}// Create DDBClientAmazonDynamoDB ddbCLient = AmazonDynamoDBClientBuilder.standard()    .withCredentials(new AWSCredentialsProvider(KEY))    .withRegion(&quot;aaabbb&quot;)    .build();// Convert whitelist into MapMap&lt;String, AttributeValue&gt; whitelistMap = new HashMap&lt;&gt;();whitelistMap.put(&quot;id&quot;, &quot;123&quot;);whitelistMap.put(&quot;content&quot;, &quot;hello world&quot;);whitelistMap.put(&quot;status&quot;, &quot;onSale&quot;);// UpdateItem RequestUpdateItemRequest request = new UpdateItemRequest()    .withTableName(&quot;WhitelistTable&quot;)    .withItem(whitelistMap);// Use updateItem operationddbClient.updateItem(request);</code></pre><p>As you can see here, we need to build a String, AttributeValue map, which is a bit annoying. </p><h2 id="1-2-How-to-use-DynamoDBMapper"><a href="#1-2-How-to-use-DynamoDBMapper" class="headerlink" title="1.2 How to use DynamoDBMapper"></a>1.2 How to use DynamoDBMapper</h2><p>We can define the table schema when we define the POJO using DynamoDBMapper’s annotations. </p><pre><code>// Notice: lombok may not work well here, especially when you use GSI and LSI, it cannot retrive info correctly@DynamoDBTable(tableName = &quot;whitelistTable&quot;)public class Whitelist {    @DynamoDBHashKey    private String id;    @DynamoDBRangeKey    private String status;    @DynamoDBAttribute    private String content;}// Create DDBClientAmazonDynamoDB ddbCLient = AmazonDynamoDBClientBuilder.standard()    .withCredentials(new AWSCredentialsProvider(KEY))    .withRegion(&quot;aaabbb&quot;)    .build();//Create DDBMapperAmazonDynamoDBMapper ddbMapper = new AmazonDynamoDBMapper(ddbClient);// updateItemddbMapper.save(whitelistItem);</code></pre><p>Code looks much more succinct, isn’t it! As you can see above, you can think DDBMapper wraps DDBCLient in some way, and help you implement the String-AttributeValue map for you. </p><h1 id="2-Comparision"><a href="#2-Comparision" class="headerlink" title="2. Comparision"></a>2. Comparision</h1><ul><li>DynamoDBMapper <ul><li>Benefits<ul><li>Code look better</li><li>less dev work</li></ul></li><li>weakness<ul><li>it runs slower than using DDBClient<ul><li>E.G when using DDBClient::getItem, the average latency is about 2ms; whereas it comes to be around 8ms in DDBMapper.  </li></ul></li></ul></li></ul></li><li>DynamoDBClient<ul><li>Benefits<ul><li>As said above, run much faster</li></ul></li><li>weakness<ul><li>verbose code</li><li>easier for mistakes, typos </li></ul></li></ul></li></ul><p>So how to choose from those two – it depends. Suppose you have a daily job to put 100 millions items into one table and want to write faster, DDBClient should definitely be your choice in this situation. Otherwise, use DynamoDBMapper to save your life, lol. </p>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> DynamoDB </tag>
            
            <tag> Mapper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Distributed Tracing</title>
      <link href="/Distributed-Tracing/"/>
      <url>/Distributed-Tracing/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Why-we-need-it"><a href="#1-Why-we-need-it" class="headerlink" title="1. Why we need it?"></a>1. Why we need it?</h1><p>Short answer - due to disturbuted applications. </p><h2 id="1-1-Monolithis-software"><a href="#1-1-Monolithis-software" class="headerlink" title="1.1 Monolithis software"></a>1.1 Monolithis software</h2><p>Monolithis software is build upon a large and sprawling legacy code base that is often so tightly coupled that any changes in one small section often result in breaking one or several features that depend on it. In such app, high possibly it’ll break and we need to use tech - tracing to <strong>follw the course of a request or system event</strong> from its source to its ultimate destination. </p><p>In this way, each trace comes to be a narrative that tells the request’s story as it travels through system. </p><h2 id="2-2-Distributed-System"><a href="#2-2-Distributed-System" class="headerlink" title="2.2 Distributed System"></a>2.2 Distributed System</h2><p>Use distributed tracing to profile and monitor microservice-based apps/ architectures, locate failures, and improve performance. </p><h1 id="2-Key-Concepts"><a href="#2-Key-Concepts" class="headerlink" title="2. Key Concepts"></a>2. Key Concepts</h1><p>In general, distributed tracing start with a single request - the entity or event being traced. As the request makes its journey, it <strong>generates traces that record complete processing operations</strong> performed on it by entities within a distributed system/ network infrastructure. </p><p>Each trace is assigned with its own unique ID and passes through a segment that indicates a given activity that a host system performs on the request. Every segments represents a single step within the reqeust’s path and has a name, unique ID, and timestamp. A span(segment) can also carry additional metadata. </p><p>The idea is – specific request inflexion points mush be identified within a system and instrumented. All of the trace data mush be coordinated and collated to provide a meaningflow view of a request. </p><p>Challenge would be processing the volume of the data generated from increasingly large scale systems. </p><h1 id="3-Implementation"><a href="#3-Implementation" class="headerlink" title="3. Implementation"></a>3. Implementation</h1><p>Google created Dapper in the past as a middleware that supports using different language within the system. As said, the value of tracing is only realised through: </p><ul><li>ubiquitous deployment, and no parts of the system under observation are not instrumented </li><li>continuous monitoring <ul><li>system mush be monitoring constantly </li></ul></li></ul><h1 id="4-Why-we-need-distributed-tracing"><a href="#4-Why-we-need-distributed-tracing" class="headerlink" title="4. Why we need distributed tracing"></a>4. Why we need distributed tracing</h1><p>Greg Linden commented in 2006 that experiments ran by Amazon.com demonstrated a <a href="http://glinden.blogspot.com/2006/11/marissa-mayer-at-web-20.html" target="_blank" rel="noopener">significant drop in revenue</a> was experienced when 100ms delay to page load was added. Although understanding the flow of a web request through a system can be challenging, there can be significant commercial gains if performance bottlenecks are identified and eliminated.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ol><li><a href="https://epsagon.com/blog/introduction-to-distributed-tracing/" target="_blank" rel="noopener">https://epsagon.com/blog/introduction-to-distributed-tracing/</a></li><li><a href="https://www.infoq.com/articles/distributed-tracing-microservices/" target="_blank" rel="noopener">https://www.infoq.com/articles/distributed-tracing-microservices/</a></li><li><a href="https://www.javacodegeeks.com/microservices-distributed-tracing.html" target="_blank" rel="noopener">https://www.javacodegeeks.com/microservices-distributed-tracing.html</a></li><li><a href="https://ai.google/research/pubs/pub36356" target="_blank" rel="noopener">https://ai.google/research/pubs/pub36356</a> </li></ol>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Distributed Tracing </tag>
            
            <tag> System Design </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DynamoDB-Advanced</title>
      <link href="/DynamoDB-Advanced/"/>
      <url>/DynamoDB-Advanced/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Overview"><a href="#1-Overview" class="headerlink" title="1. Overview"></a>1. Overview</h1><h2 id="1-1-Features"><a href="#1-1-Features" class="headerlink" title="1.1 Features"></a>1.1 Features</h2><ul><li>Fully managed NoSQL database service </li><li>offer encryption at rest </li><li>on-demand backup capability <ul><li>allows you to create full backups of your tables for long-term retention and archival for regulatory compliance needs</li></ul></li><li>point-in-time recovery<ul><li>restore the table to any point in time during last 35 days  </li></ul></li><li>TTL <ul><li>delete expired items from tables automatically to reduce storage usage</li></ul></li></ul><h2 id="1-2-High-availability-and-durability"><a href="#1-2-High-availability-and-durability" class="headerlink" title="1.2 High availability and durability"></a>1.2 High availability and durability</h2><p>DynamoDB automatically spreads the data and traffic for your tables over a <strong>sufficient number of servers</strong>to handle your throughput and storage requirements, while maintaining consistent and fast performance. All of your data is stored on solid state disks (SSDs) and <strong>automatically replicated across multiple Availability Zones</strong> in an AWS region, providing built-in high availability and data durability. You can use <strong>global tables to keep DynamoDB tables in sync across AWS Regions</strong>. For more information, see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GlobalTables.html" target="_blank" rel="noopener">Global Tables</a>.</p><h1 id="2-How-it-works"><a href="#2-How-it-works" class="headerlink" title="2. How it works"></a>2. How it works</h1><h2 id="2-1-Core-Components"><a href="#2-1-Core-Components" class="headerlink" title="2.1 Core Components"></a>2.1 Core Components</h2><h3 id="2-1-1-Tables-Items-Attributes"><a href="#2-1-1-Tables-Items-Attributes" class="headerlink" title="2.1.1 Tables, Items, Attributes"></a>2.1.1 Tables, Items, Attributes</h3><blockquote><p>A table is a collection of items, each item is a collection of attributes.</p></blockquote><p>DynamoDB uses <strong>primary keys</strong> to uniquely identify each item in a table and <strong>secondary indexes</strong> to provide more querying flexibility. </p><p>Below is a diagram showing a table named People:</p><p><img src="https://i.loli.net/2020/01/29/jTZDz1AOoce26iq.png" alt="fig1.png"></p><p>Note about tables:</p><ul><li>Each item in the table has a unique identifier, or primary key, that distinguishes the item from all of the others in the table. In the People table, the primary key consists of one attribute (PersonID).</li><li>Other than the primary key, the People table is <strong>schemaless</strong>, which means that neither the attributes nor their data types need to be defined beforehand. Each item can have its own distinct attributes.</li><li>Some of the items have** a nested attribute **(Address). DynamoDB supports nested attributes up to 32 levels deep.</li></ul><h3 id="2-1-2-Primary-Key"><a href="#2-1-2-Primary-Key" class="headerlink" title="2.1.2 Primary Key"></a>2.1.2 Primary Key</h3><p>When creating tables, you must specify the primary key of the table. <strong><em>The primary key uniquely identifies each item in the table, so that no two items can have the same key</em></strong>. </p><p>DynamoDB supports two different kinds of primary keys: </p><ul><li>Partition Key </li></ul><p>DynamoDB uses the partition key’s value as input to an internal hash function. The output from the hash function determines the partition(Physical storage internal to DynamoDB) in which the item will be stored. </p><ul><li>Partition Key and sort key </li></ul><p>A composite primary key, composed of two attributes: partition key and sort key. </p><p>DynamoDB uses the partition key value as input to an internal hash function. The output from the hash function determines the partition (physical storage internal to DynamoDB) in which the item will be stored. All items with the same partition key value are stored together, in sorted order by sort key value.</p><p>In a table that has a partition key and a sort key, it’s possible for two items to have the same partition key value. However, those two items must have different sort key values.</p><h3 id="2-1-3-Secondary-Indexes"><a href="#2-1-3-Secondary-Indexes" class="headerlink" title="2.1.3 Secondary Indexes"></a>2.1.3 Secondary Indexes</h3><p>A secondary index lets you query the data in the table using an alternate key, in addtion to queries against the primary key. </p><p>After you create a secondary index on a table, you can read data from the index in much the same way as you do from the table. </p><ul><li>Global Secondary Index</li></ul><p>An index with a partition key and sort key that can be different from those on the table </p><ul><li>Local Secondary Index</li></ul><p>An index that has the same partition key as the table, but a different sort key </p><h2 id="2-2-Limitations"><a href="#2-2-Limitations" class="headerlink" title="2.2 Limitations"></a>2.2 Limitations</h2><h3 id="2-2-1-Capacity-unit-sizes-For-Provisioned-tables"><a href="#2-2-1-Capacity-unit-sizes-For-Provisioned-tables" class="headerlink" title="2.2.1 Capacity unit sizes(For Provisioned tables)"></a>2.2.1 Capacity unit sizes(For Provisioned tables)</h3><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html" target="_blank" rel="noopener">Link is here: </a></p><p>One read capacity unit = one strongly consistent read per second, or two eventually consistent reads per second, for items up to 4 KB in size.</p><p>One write capacity unit = one write per second, for items up to 1 KB in size.</p><p>Transactional read requests require two read capacity units to perform one read per second for items up to 4 KB.</p><p>Transactional write requests require two write capacity units to perform one write per second for items up to 1 KB.</p><h3 id="2-2-2-Request-Unit-Sizes-For-On-Demand-tables"><a href="#2-2-2-Request-Unit-Sizes-For-On-Demand-tables" class="headerlink" title="2.2.2 Request Unit Sizes(For On-Demand tables)"></a>2.2.2 Request Unit Sizes(For On-Demand tables)</h3><p>One read request unit = one strongly consistent read, or two eventually consistent reads, for items up to 4 KB in size.</p><p>One write request unit = one write, for items up to 1 KB in size.</p><p>Transactional read requests require two read request units to perform one read for items up to 4 KB.</p><p>Transactional write requests require two write request units to perform one write for items up to 1 KB.</p><h3 id="2-2-3-Throughtput-Default-Limits"><a href="#2-2-3-Throughtput-Default-Limits" class="headerlink" title="2.2.3 Throughtput Default Limits"></a>2.2.3 Throughtput Default Limits</h3><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Limits.html" target="_blank" rel="noopener">See link here:</a></p><h3 id="2-2-4-Tables"><a href="#2-2-4-Tables" class="headerlink" title="2.2.4 Tables"></a>2.2.4 Tables</h3><p>Tables are unconstrained in terms of the number of items or the number of bytes. </p><p>For any AWS account, there is an initial limit of 256 tables per region.</p><p>You can define a maximum of 5 local secondary indexes.</p><p>There is an initial limit of 20 global secondary indexes per table.</p><h3 id="2-2-5-API-specific-Limits"><a href="#2-2-5-API-specific-Limits" class="headerlink" title="2.2.5 API specific Limits"></a>2.2.5 API specific Limits</h3><ul><li>CreateTable/UpdateTable/DeleteTable</li></ul><p>In general, you can have up to 50 CreateTable, UpdateTable, and DeleteTable requests running simultaneously (in any combination). In other words, the total number of tables in the CREATING, UPDATING or DELETING state cannot exceed 50.</p><ul><li>BatchGetItem</li></ul><p>A single BatchGetItem operation can retrieve a maximum of 100 items. The total size of all the items retrieved cannot exceed 16 MB.</p><ul><li>BatchWriteItem</li></ul><p>A single BatchWriteItem operation can contain up to 25 PutItem or DeleteItem requests. The total size of all the items written cannot exceed 16 MB.</p><ul><li>DescribeLimits</li></ul><p>DescribeLimits should only be called periodically. You can expect throttling errors if you call it more than once in a minute.</p><ul><li>Query</li></ul><p>The result set from a Query is limited to 1 MB per call. You can use the LastEvaluatedKey from the query response to retrieve more results.</p><ul><li>Scan</li></ul><p>The result set from a Scan is limited to 1 MB per call. You can use the LastEvaluatedKey from the scan response to retrieve more results.</p><h2 id="2-3-The-DynamoDB-API"><a href="#2-3-The-DynamoDB-API" class="headerlink" title="2.3 The DynamoDB API"></a>2.3 The DynamoDB API</h2><p>See Instructions <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.API.html" target="_blank" rel="noopener">here</a></p><h3 id="2-3-1-Control-Plane"><a href="#2-3-1-Control-Plane" class="headerlink" title="2.3.1 Control Plane"></a>2.3.1 Control Plane</h3><ul><li>CreateTable </li><li>DescribeTable </li><li>ListTables </li><li>UpdateTable </li><li>DeleteTable </li></ul><h3 id="2-3-2-Data-Plane"><a href="#2-3-2-Data-Plane" class="headerlink" title="2.3.2 Data Plane"></a>2.3.2 Data Plane</h3><ul><li>Creating Data <ul><li>PutItem </li><li>BatchWriteItem </li></ul></li><li>Reading Data <ul><li>GetItem </li><li>BatchGetItem </li><li>Query </li><li>Scan </li></ul></li><li>Updating Data <ul><li>UpdateItem </li></ul></li><li>Deleting Data <ul><li>DeleteItem </li><li>BatchWriteItem </li></ul></li><li>DynamoDB streams <ul><li>listStreams</li><li>DescribeStream </li><li>GetShardIterator: return a shard iterator, which is a data structure that your application uses to retrieve the records from the stream. </li><li>GetRecords</li></ul></li></ul><h2 id="2-4-Consistency-and-capacity"><a href="#2-4-Consistency-and-capacity" class="headerlink" title="2.4 Consistency and capacity"></a>2.4 Consistency and capacity</h2><p>Region - Availability Zones</p><p>When your application writes data to a DynamoDB table and receives an HTTP 200 response, the write has occured and is durable. The data is eventually consistent across all storage locations, usually within one second or less. </p><p>DDB supports <strong>eventually consistent and strongly consistent reads</strong>. </p><h3 id="2-4-1-Eventually-Consistent-Reads"><a href="#2-4-1-Eventually-Consistent-Reads" class="headerlink" title="2.4.1 Eventually Consistent Reads"></a>2.4.1 Eventually Consistent Reads</h3><p>When you read data from a DynamoDB table, the response might not reflect the results of a recently completed write operation. The response might include some stale data. If you repeat your read request after a short time, the response should return the latest data.</p><h3 id="2-4-2-Strongly-Consistent-Reads"><a href="#2-4-2-Strongly-Consistent-Reads" class="headerlink" title="2.4.2 Strongly Consistent Reads"></a>2.4.2 Strongly Consistent Reads</h3><p>When you request a strongly consistent read, DynamoDB returns a response with the most up-to-date data, reflecting the updates from all prior write operations that were successful. A strongly consistent read might not be available if there is a network delay or outage. Consistent reads are not supported on global secondary indexes (GSI).</p><h3 id="2-4-3-Read-Write-Capacity-Mode-on-demand"><a href="#2-4-3-Read-Write-Capacity-Mode-on-demand" class="headerlink" title="2.4.3 Read/ Write Capacity Mode - on demand"></a>2.4.3 Read/ Write Capacity Mode - on demand</h3><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html" target="_blank" rel="noopener">See link here</a></p><p>When you choose on-demand mode, DynamoDB instantly accommodates your workloads as they ramp up or down to any previously reached traffic level. If a workload’s traffic level hits a new peak, DynamoDB adapts rapidly to accommodate the workload. Tables that use on-demand mode deliver the same single-digit millisecond latency, service-level agreement (SLA) commitment, and security that DynamoDB already offers. You can choose on-demand for both new and existing tables and you can continue using the existing DynamoDB APIs without changing code.</p><h3 id="2-4-4-Read-Write-Capacity-Mode-provisioned"><a href="#2-4-4-Read-Write-Capacity-Mode-provisioned" class="headerlink" title="2.4.4 Read/ Write Capacity Mode - provisioned"></a>2.4.4 Read/ Write Capacity Mode - provisioned</h3><p>If you choose provisioned mode, you specify the number of reads and writes per second that you require for your application. You can use auto scaling to adjust your table’s provisioned capacity automatically in response to traffic changes. This helps you govern your DynamoDB use to stay at or below a defined request rate in order to obtain cost predictability.</p><h3 id="2-4-5-Read-Write-request-units"><a href="#2-4-5-Read-Write-request-units" class="headerlink" title="2.4.5 Read/ Write request units"></a>2.4.5 Read/ Write request units</h3><p>For on-demand mode tables, you don’t need to specify how much read and write throughput you expect your application to perform. DynamoDB charges you for the reads and writes that your application performs on your tables in terms of read request units and write request units.</p><p>One read request unit represents one strongly consistent read request, or two eventually consistent read requests, for an item up to 4 KB in size. Transactional read requests require 2 read request units to perform one read for items up to 4 KB. If you need to read an item that is larger than 4 KB, DynamoDB needs additional read request units. The total number of read request units required depends on the item size, and whether you want an eventually consistent or strongly consistent read. For example, if your item size is 8 KB, you require 2 read request units to sustain one strongly consistent read, 1 read request unit if you choose eventually consistent reads, or 4 read request units for a transactional read request.</p><p>One write request unit represents one write for an item up to 1 KB in size. If you need to write an item that is larger than 1 KB, DynamoDB needs to consume additional write request units. Transactional write requests require 2 write request units to perform one write for items up to 1 KB. The total number of write request units required depends on the item size. For example, if your item size is 2 KB, you require 2 write request units to sustain one write request or 4 read request units for a transactional write request.</p><h3 id="2-4-6-DynamoDB-Auto-Scaling"><a href="#2-4-6-DynamoDB-Auto-Scaling" class="headerlink" title="2.4.6 DynamoDB Auto Scaling"></a>2.4.6 DynamoDB Auto Scaling</h3><p>Manage throughput capacity for tables and global secondary indexes. With auto scaling, you define a range for read and write capacity units. You also define a target utilization percentage within that range. DynamoDB auto scaling seeks to maintain your target utilization, even as your application workload increases or decreases.</p><h2 id="2-5-Partitions-and-Data-Distribution"><a href="#2-5-Partitions-and-Data-Distribution" class="headerlink" title="2.5 Partitions and Data Distribution"></a>2.5 Partitions and Data Distribution</h2><p>A partition is an allocation of storage for a table, backed by solid-state drives (SSDs) and automatically replicated across multiple Availability Zones within an AWS Region. Partition management is handled entirely by DynamoDB—you never have to manage partitions yourself.</p><p>DynamoDB allocates additional partitions to a table in the following situations:</p><ul><li>If you increase the table’s provisioned throughput settings beyond what the existing partitions can support.</li><li>If an existing partition fills to capacity and more storage space is required.</li></ul><p>Choose a partition key that can have a large number of distinct values relative to the number of items in the table. </p><h1 id="3-Java-Programming-with-DanamoDB"><a href="#3-Java-Programming-with-DanamoDB" class="headerlink" title="3. Java Programming with DanamoDB"></a>3. Java Programming with DanamoDB</h1><h2 id="3-1-Work-flow-using-Java"><a href="#3-1-Work-flow-using-Java" class="headerlink" title="3.1 Work flow using Java"></a>3.1 Work flow using Java</h2><h3 id="3-1-1-Create-a-table"><a href="#3-1-1-Create-a-table" class="headerlink" title="3.1.1 Create a table"></a>3.1.1 Create a table</h3><pre><code>public class MoviesCreateTable {    public static void main(String[] args) throws Exception {        AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()            .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;http://localhost:8000&quot;, &quot;us-west-2&quot;))            .build();        DynamoDB dynamoDB = new DynamoDB(client);        String tableName = &quot;Movies&quot;;        try {            System.out.println(&quot;Attempting to create table; please wait...&quot;);            Table table = dynamoDB.createTable(tableName,                Arrays.asList(new KeySchemaElement(&quot;year&quot;, KeyType.HASH), // Partition                                                                          // key                    new KeySchemaElement(&quot;title&quot;, KeyType.RANGE)), // Sort key                Arrays.asList(new AttributeDefinition(&quot;year&quot;, ScalarAttributeType.N),                    new AttributeDefinition(&quot;title&quot;, ScalarAttributeType.S)),                new ProvisionedThroughput(10L, 10L));            table.waitForActive();            System.out.println(&quot;Success.  Table status: &quot; + table.getDescription().getTableStatus());        }        catch (Exception e) {            System.err.println(&quot;Unable to create table: &quot;);            System.err.println(e.getMessage());        }    }}</code></pre><h3 id="3-1-2-Load-data"><a href="#3-1-2-Load-data" class="headerlink" title="3.1.2 Load data"></a>3.1.2 Load data</h3><pre><code>public class MoviesLoadData {    public static void main(String[] args) throws Exception {        AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()            .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;http://localhost:8000&quot;, &quot;us-west-2&quot;))            .build();        DynamoDB dynamoDB = new DynamoDB(client);        Table table = dynamoDB.getTable(&quot;Movies&quot;);        JsonParser parser = new JsonFactory().createParser(new File(&quot;moviedata.json&quot;));        JsonNode rootNode = new ObjectMapper().readTree(parser);        Iterator&lt;JsonNode&gt; iter = rootNode.iterator();        ObjectNode currentNode;        while (iter.hasNext()) {            currentNode = (ObjectNode) iter.next();            int year = currentNode.path(&quot;year&quot;).asInt();            String title = currentNode.path(&quot;title&quot;).asText();            try {                table.putItem(new Item().withPrimaryKey(&quot;year&quot;, year, &quot;title&quot;, title).withJSON(&quot;info&quot;,                    currentNode.path(&quot;info&quot;).toString()));                System.out.println(&quot;PutItem succeeded: &quot; + year + &quot; &quot; + title);            }            catch (Exception e) {                System.err.println(&quot;Unable to add movie: &quot; + year + &quot; &quot; + title);                System.err.println(e.getMessage());                break;            }        }        parser.close();    }}</code></pre><h3 id="3-1-3-Create-a-new-item"><a href="#3-1-3-Create-a-new-item" class="headerlink" title="3.1.3 Create a new item"></a>3.1.3 Create a new item</h3><pre><code>public class MoviesItemOps01 {    public static void main(String[] args) throws Exception {        AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()            .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;http://localhost:8000&quot;, &quot;us-west-2&quot;))            .build();        DynamoDB dynamoDB = new DynamoDB(client);        Table table = dynamoDB.getTable(&quot;Movies&quot;);        int year = 2015;        String title = &quot;The Big New Movie&quot;;        final Map&lt;String, Object&gt; infoMap = new HashMap&lt;String, Object&gt;();        infoMap.put(&quot;plot&quot;, &quot;Nothing happens at all.&quot;);        infoMap.put(&quot;rating&quot;, 0);        try {            System.out.println(&quot;Adding a new item...&quot;);            PutItemOutcome outcome = table                .putItem(new Item().withPrimaryKey(&quot;year&quot;, year, &quot;title&quot;, title).withMap(&quot;info&quot;, infoMap));            System.out.println(&quot;PutItem succeeded:\n&quot; + outcome.getPutItemResult());        }        catch (Exception e) {            System.err.println(&quot;Unable to add item: &quot; + year + &quot; &quot; + title);            System.err.println(e.getMessage());        }    }}</code></pre><h3 id="3-1-4-Read-an-Item"><a href="#3-1-4-Read-an-Item" class="headerlink" title="3.1.4 Read an Item"></a>3.1.4 Read an Item</h3><pre><code>public class MoviesItemOps02 {    public static void main(String[] args) throws Exception {        AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()            .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;http://localhost:8000&quot;, &quot;us-west-2&quot;))            .build();        DynamoDB dynamoDB = new DynamoDB(client);        Table table = dynamoDB.getTable(&quot;Movies&quot;);        int year = 2015;        String title = &quot;The Big New Movie&quot;;        GetItemSpec spec = new GetItemSpec().withPrimaryKey(&quot;year&quot;, year, &quot;title&quot;, title);        try {            System.out.println(&quot;Attempting to read the item...&quot;);            Item outcome = table.getItem(spec);            System.out.println(&quot;GetItem succeeded: &quot; + outcome);        }        catch (Exception e) {            System.err.println(&quot;Unable to read item: &quot; + year + &quot; &quot; + title);            System.err.println(e.getMessage());        }    }}</code></pre><h3 id="3-1-5-Update-an-Item"><a href="#3-1-5-Update-an-Item" class="headerlink" title="3.1.5 Update an Item"></a>3.1.5 Update an Item</h3><pre><code>public class MoviesItemOps03 {    public static void main(String[] args) throws Exception {        AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()            .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;http://localhost:8000&quot;, &quot;us-west-2&quot;))            .build();        DynamoDB dynamoDB = new DynamoDB(client);        Table table = dynamoDB.getTable(&quot;Movies&quot;);        int year = 2015;        String title = &quot;The Big New Movie&quot;;        UpdateItemSpec updateItemSpec = new UpdateItemSpec().withPrimaryKey(&quot;year&quot;, year, &quot;title&quot;, title)            .withUpdateExpression(&quot;set info.rating = :r, info.plot=:p, info.actors=:a&quot;)            .withValueMap(new ValueMap().withNumber(&quot;:r&quot;, 5.5).withString(&quot;:p&quot;, &quot;Everything happens all at once.&quot;)                .withList(&quot;:a&quot;, Arrays.asList(&quot;Larry&quot;, &quot;Moe&quot;, &quot;Curly&quot;)))            .withReturnValues(ReturnValue.UPDATED_NEW);        try {            System.out.println(&quot;Updating the item...&quot;);            UpdateItemOutcome outcome = table.updateItem(updateItemSpec);            System.out.println(&quot;UpdateItem succeeded:\n&quot; + outcome.getItem().toJSONPretty());        }        catch (Exception e) {            System.err.println(&quot;Unable to update item: &quot; + year + &quot; &quot; + title);            System.err.println(e.getMessage());        }    }}</code></pre><h3 id="3-1-6-Update-an-Item-conditionally"><a href="#3-1-6-Update-an-Item-conditionally" class="headerlink" title="3.1.6 Update an Item conditionally"></a>3.1.6 Update an Item conditionally</h3><pre><code>public class MoviesItemOps05 {    public static void main(String[] args) throws Exception {        AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()            .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;http://localhost:8000&quot;, &quot;us-west-2&quot;))            .build();        DynamoDB dynamoDB = new DynamoDB(client);        Table table = dynamoDB.getTable(&quot;Movies&quot;);        int year = 2015;        String title = &quot;The Big New Movie&quot;;        UpdateItemSpec updateItemSpec = new UpdateItemSpec()            .withPrimaryKey(new PrimaryKey(&quot;year&quot;, year, &quot;title&quot;, title)).withUpdateExpression(&quot;remove info.actors[0]&quot;)            .withConditionExpression(&quot;size(info.actors) &gt; :num&quot;).withValueMap(new ValueMap().withNumber(&quot;:num&quot;, 3))            .withReturnValues(ReturnValue.UPDATED_NEW);        // Conditional update (we expect this to fail)        try {            System.out.println(&quot;Attempting a conditional update...&quot;);            UpdateItemOutcome outcome = table.updateItem(updateItemSpec);            System.out.println(&quot;UpdateItem succeeded:\n&quot; + outcome.getItem().toJSONPretty());        }        catch (Exception e) {            System.err.println(&quot;Unable to update item: &quot; + year + &quot; &quot; + title);            System.err.println(e.getMessage());        }    }}</code></pre><h3 id="3-1-7-Delete-an-Item"><a href="#3-1-7-Delete-an-Item" class="headerlink" title="3.1.7 Delete an Item"></a>3.1.7 Delete an Item</h3><pre><code>public class MoviesItemOps06 {    public static void main(String[] args) throws Exception {        AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()            .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;http://localhost:8000&quot;, &quot;us-west-2&quot;))            .build();        DynamoDB dynamoDB = new DynamoDB(client);        Table table = dynamoDB.getTable(&quot;Movies&quot;);        int year = 2015;        String title = &quot;The Big New Movie&quot;;        DeleteItemSpec deleteItemSpec = new DeleteItemSpec()            .withPrimaryKey(new PrimaryKey(&quot;year&quot;, year, &quot;title&quot;, title)).withConditionExpression(&quot;info.rating &lt;= :val&quot;)            .withValueMap(new ValueMap().withNumber(&quot;:val&quot;, 5.0));        // Conditional delete (we expect this to fail)        try {            System.out.println(&quot;Attempting a conditional delete...&quot;);            table.deleteItem(deleteItemSpec);            System.out.println(&quot;DeleteItem succeeded&quot;);        }        catch (Exception e) {            System.err.println(&quot;Unable to delete item: &quot; + year + &quot; &quot; + title);            System.err.println(e.getMessage());        }    }}</code></pre><h3 id="3-1-8-Scan"><a href="#3-1-8-Scan" class="headerlink" title="3.1.8 Scan"></a>3.1.8 Scan</h3><p>The scan method reads every item in the entire table, and returns all the data in the table, you can provide an optional filter_expression so that only the items matching your criteria are returned. However, the filter is applied only after the entire table has been scanned. </p><pre><code>    public class MoviesScan {        public static void main(String[] args) throws Exception {            AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()                .withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(&quot;http://localhost:8000&quot;, &quot;us-west-2&quot;))                .build();            DynamoDB dynamoDB = new DynamoDB(client);            Table table = dynamoDB.getTable(&quot;Movies&quot;);            ScanSpec scanSpec = new ScanSpec().withProjectionExpression(&quot;#yr, title, info.rating&quot;)                .withFilterExpression(&quot;#yr between :start_yr and :end_yr&quot;).withNameMap(new NameMap().with(&quot;#yr&quot;, &quot;year&quot;))                .withValueMap(new ValueMap().withNumber(&quot;:start_yr&quot;, 1950).withNumber(&quot;:end_yr&quot;, 1959));            try {                ItemCollection&lt;ScanOutcome&gt; items = table.scan(scanSpec);                Iterator&lt;Item&gt; iter = items.iterator();                while (iter.hasNext()) {                    Item item = iter.next();                    System.out.println(item.toString());                }            }            catch (Exception e) {                System.err.println(&quot;Unable to scan the table:&quot;);                System.err.println(e.getMessage());            }        }    }</code></pre><h2 id="3-2-AWS-SDK-support"><a href="#3-2-AWS-SDK-support" class="headerlink" title="3.2 AWS SDK support"></a>3.2 AWS SDK support</h2><h3 id="3-2-1-AWS-SDK-support-workflow"><a href="#3-2-1-AWS-SDK-support-workflow" class="headerlink" title="3.2.1 AWS SDK support workflow"></a>3.2.1 AWS SDK support workflow</h3><p><img src="https://i.loli.net/2020/01/29/vTVb5WzqQkFaLYm.png" alt="fig2.png"></p><ol><li><p>You write an application using an AWS SDK for your programming language.</p></li><li><p>Each AWS SDK provides one or more programmatic interfaces for working with DynamoDB. The specific interfaces available depend on which programming language and AWS SDK you use.</p></li><li><p>The AWS SDK constructs HTTP(S) requests for use with the low-level DynamoDB API.</p></li><li><p>The AWS SDK sends the request to the DynamoDB endpoint.</p></li><li><p>DynamoDB executes the request. If the request is successful, DynamoDB returns an HTTP 200 response code (OK). If the request is unsuccessful, DynamoDB returns an HTTP error code and an error message.</p></li><li><p>The AWS SDK processes the response and propagates it back to your application.</p></li></ol><h3 id="3-2-2-Services-AWS-SDK-provides"><a href="#3-2-2-Services-AWS-SDK-provides" class="headerlink" title="3.2.2 Services AWS SDK provides"></a>3.2.2 Services AWS SDK provides</h3><ul><li>formatting HTTP(s) requests and serializing request parameters </li><li>generating a cryptographic signature for each request </li><li>forwarding request to a DynamoDB endpoint and receiving responses from DynamoDB </li><li>extracting the results from those responses </li><li>implementing basic retry logic in case of errors </li></ul><h3 id="3-2-3-Programmatic-Interfaces"><a href="#3-2-3-Programmatic-Interfaces" class="headerlink" title="3.2.3 Programmatic Interfaces"></a>3.2.3 Programmatic Interfaces</h3><ol><li>Low level interfaces<br>Need data type descriptors </li></ol><pre><code>result.getItem().getN() // get number </code></pre><ol start="2"><li>Document Interfaces</li></ol><p>Documnet interface, allowing to perform data plane operations(creat, read, update, delete) on tables and indexes. No need to specify the data type descriptors. Data types are implied by the semantics of the data itself. Also provide methods to easily convert JSON documents to and from native DDB data types. </p><ol start="3"><li>Object Persistence Interface </li></ol><p>Provid an object persistence interface where you do not directly perform data plane operations. Instead, you create objects that represent items in DynamoDB tables and indexes, and interact only with those objects. <strong><em>This allow you to write object-centric code, rather than database-centric code</em></strong>. </p><pre><code>@DynamoDBTable(tableName=&quot;Music&quot;)public class MusicItem {    private String artist;    private String songTitle;    private String albumTitle;    private int year;    @DynamoDBHashKey(attributeName=&quot;Artist&quot;)    public String getArtist() { return artist;}    public void setArtist(String artist) {this.artist = artist;}    @DynamoDBRangeKey(attributeName=&quot;SongTitle&quot;)    public String getSongTitle() { return songTitle;}    public void setSongTitle(String songTitle) {this.songTitle = songTitle;}    @DynamoDBAttribute(attributeName = &quot;AlbumTitle&quot;)    public String getAlbumTitle() { return albumTitle;}    public void setAlbumTitle(String albumTitle) {this.albumTitle = albumTitle;}    @DynamoDBAttribute(attributeName = &quot;Year&quot;)    public int getYear() { return year; }    public void setYear(int year) { this.year = year; }}</code></pre><h3 id="3-2-4-Low-level-API"><a href="#3-2-4-Low-level-API" class="headerlink" title="3.2.4 Low level API"></a>3.2.4 Low level API</h3><p>The DynamoDB low-level API is the protocol level interface for Amazon DynamoDB. At this level, every HTTP(s) request must be correctly formatted and carry a valid digital signature. </p><p>The low-level DynamoDB API uses JavaScript Object Notation (JSON) as a wire protocol format. JSON presents data in a hierarchy, so that both data values and data structure are conveyed simultaneously. Name-value pairs are defined in the format name:value. The data hierarchy is defined by nested brackets of name-value pairs.</p><p>DynamoDB uses JSON only as a transport protocol, not as a storage format. The AWS SDKs use JSON to send data to DynamoDB, and DynamoDB responds with JSON, but DynamoDB does not store data persistently in JSON format.</p><h4 id="3-2-4-1-Request-Format"><a href="#3-2-4-1-Request-Format" class="headerlink" title="3.2.4.1 Request Format"></a>3.2.4.1 Request Format</h4><p>The DynamoDB low-level API accepts HTTP(S) POST requests as input. The AWS SDKs construct these requests for you.</p><p>Suppose that you have a table named Pets, with a key schema consisting of AnimalType (partition key) and Name (sort key). Both of these attributes are of type string. To retrieve an item from Pets, the AWS SDK constructs a request as shown following:</p><pre><code>POST / HTTP/1.1Host: dynamodb.&lt;region&gt;.&lt;domain&gt;;Accept-Encoding: identityContent-Length: &lt;PayloadSizeBytes&gt;     User-Agent: &lt;UserAgentString&gt;Content-Type: application/x-amz-json-1.0Authorization: AWS4-HMAC-SHA256 Credential=&lt;Credential&gt;, SignedHeaders=&lt;Headers&gt;, Signature=&lt;Signature&gt;X-Amz-Date: &lt;Date&gt; X-Amz-Target: DynamoDB_20120810.GetItem{    &quot;TableName&quot;: &quot;Pets&quot;,    &quot;Key&quot;: {        &quot;AnimalType&quot;: {&quot;S&quot;: &quot;Dog&quot;},        &quot;Name&quot;: {&quot;S&quot;: &quot;Fido&quot;}    }}</code></pre><ul><li>The Authorization header contains information required for DynamoDB to authenticate the request.</li><li>The X-Amz-Target header contains the name of a DynamoDB operation: GetItem. (This is also accompanied by the low-level API version, in this case 20120810.)</li><li>The payload (body) of the request contains the parameters for the operation, in JSON format. For the GetItem operation, the parameters are TableName and Key.</li></ul><h4 id="3-2-4-2-Response-Format"><a href="#3-2-4-2-Response-Format" class="headerlink" title="3.2.4.2 Response Format"></a>3.2.4.2 Response Format</h4><p>Upon receipt of the request, DynamoDB processes it and returns a response. For the request shown above, the HTTP(S) response payload contains the results from the operation. </p><pre><code>HTTP/1.1 200 OKx-amzn-RequestId: &lt;RequestId&gt; x-amz-crc32: &lt;Checksum&gt;Content-Type: application/x-amz-json-1.0Content-Length: &lt;PayloadSizeBytes&gt;Date: &lt;Date&gt; {    &quot;Item&quot;: {        &quot;Age&quot;: {&quot;N&quot;: &quot;8&quot;},        &quot;Colors&quot;: {            &quot;L&quot;: [                {&quot;S&quot;: &quot;White&quot;},                {&quot;S&quot;: &quot;Brown&quot;},                {&quot;S&quot;: &quot;Black&quot;}            ]        },        &quot;Name&quot;: {&quot;S&quot;: &quot;Fido&quot;},        &quot;Vaccinations&quot;: {            &quot;M&quot;: {                &quot;Rabies&quot;: {                    &quot;L&quot;: [                        {&quot;S&quot;: &quot;2009-03-17&quot;},                        {&quot;S&quot;: &quot;2011-09-21&quot;},                        {&quot;S&quot;: &quot;2014-07-08&quot;}                    ]                },                &quot;Distemper&quot;: {&quot;S&quot;: &quot;2015-10-13&quot;}            }        },        &quot;Breed&quot;: {&quot;S&quot;: &quot;Beagle&quot;},        &quot;AnimalType&quot;: {&quot;S&quot;: &quot;Dog&quot;}    }}</code></pre><h4 id="3-2-4-3-Data-Type-Descriptors"><a href="#3-2-4-3-Data-Type-Descriptors" class="headerlink" title="3.2.4.3 Data Type Descriptors"></a>3.2.4.3 Data Type Descriptors</h4><p>The low-level DynamoDB API protocol requires each attribute to be accompanied by a data type descriptor. Data type descriptors are tokens that tell DynamoDB how to interpret each attribute.</p><p>The examples in Request Format and Response Format show examples of how data type descriptors are used. The GetItem request specifies S for the Pets key schema attributes (AnimalType and Name), which are of type string. The GetItem response contains a Pets item with attributes of type string (S), number (N), map (M), and list (L).</p><h2 id="3-3-Error-Handling"><a href="#3-3-Error-Handling" class="headerlink" title="3.3 Error Handling"></a>3.3 Error Handling</h2><h3 id="3-3-1-Error-Components"><a href="#3-3-1-Error-Components" class="headerlink" title="3.3.1 Error Components"></a>3.3.1 Error Components</h3><p>Unsuccessful: returns an error, which contains: </p><ul><li>An HTTP status code</li><li>An exception name</li><li>An error message</li></ul><p>The AWS SDK tale care of propagating errors to your application, so that you can take appropriate action. </p><h3 id="3-3-2-Error-Messages-and-Codes"><a href="#3-3-2-Error-Messages-and-Codes" class="headerlink" title="3.3.2 Error Messages and Codes"></a>3.3.2 Error Messages and Codes</h3><ul><li>HTTP status code 400<ul><li>AccessDeniedException <ul><li>The client did not correctly sign the request.</li></ul></li><li>ConditionalCheckFailedException<ul><li>You specified a condition that evaluated to false. </li></ul></li><li>IncompleteSignatureException <ul><li>The request signature did not include all of the required components.</li></ul></li><li>ItemCollectionSizeLimitExceededException<ul><li>For a table with a local secondary index, a group of items with the same partition key value has exceeded the maximum size limit of 10 GB. </li></ul></li><li>LimitExceededException<ul><li>There are too many concurrent control plane operations. The cumulative number of tables and indexes in the CREATING, DELETING, or UPDATING state cannot exceed 50.</li></ul></li><li>MissingAuthenticationTokenException<ul><li>The request did not include the required authorization header, or it was malformed. </li></ul></li><li>ProvisionedThroughputExceededException<ul><li>Your request rate is too high. The AWS SDKs for DynamoDB automatically retry requests that receive this exception. Your request is eventually successful, unless your retry queue is too large to finish. </li></ul></li><li>RequestLimitExceeded<ul><li>Throughput exceeds the current throughput limit for your account.</li></ul></li><li>ResourceInUseException<ul><li>The resource which you are attempting to change is in use.</li></ul></li></ul></li></ul><pre><code>Table table = dynamoDB.getTable(&quot;Movies&quot;);try {    Item item = table.getItem(&quot;year&quot;, 1978, &quot;title&quot;, &quot;Superman&quot;);    if (item != null) {        System.out.println(&quot;Result: &quot; + item);    } else {         //No such item exists in the table        System.out.println(&quot;Item not found&quot;);    }} catch (AmazonServiceException ase) {    System.err.println(&quot;Could not complete operation&quot;);    System.err.println(&quot;Error Message:  &quot; + ase.getMessage());    System.err.println(&quot;HTTP Status:    &quot; + ase.getStatusCode());    System.err.println(&quot;AWS Error Code: &quot; + ase.getErrorCode());    System.err.println(&quot;Error Type:     &quot; + ase.getErrorType());    System.err.println(&quot;Request ID:     &quot; + ase.getRequestId());} catch (AmazonClientException ace) {    System.err.println(&quot;Internal error occured communicating with DynamoDB&quot;);    System.out.println(&quot;Error Message:  &quot; + ace.getMessage());</code></pre><h3 id="3-3-3-Error-Retries-and-Expotential-Backoff"><a href="#3-3-3-Error-Retries-and-Expotential-Backoff" class="headerlink" title="3.3.3 Error Retries and Expotential Backoff"></a>3.3.3 Error Retries and Expotential Backoff</h3><p>Numerous components on a network, such as DNS servers, switches, load balancers, and others can generate errors anywhere in the life of a given request. The usual technique for dealing with these error responses in a networked environment is to implement retries in the client application. This technique increases the reliability of the application.</p><p>In addition to simple retries, each AWS SDK implements exponential backoff algorithm for better flow control. The concept behind exponential backoff is to use progressively longer waits between retries for consecutive error responses. For example, up to 50 milliseconds before the first retry, up to 100 milliseconds before the second, up to 200 milliseconds before third, and so on.</p><h3 id="3-3-4-Batch-Operations-and-Error-Handling"><a href="#3-3-4-Batch-Operations-and-Error-Handling" class="headerlink" title="3.3.4 Batch Operations and Error Handling"></a>3.3.4 Batch Operations and Error Handling</h3><p>The DynamoDB low-level API supports batch operations for reads and writes. BatchGetItem reads items from one or more tables, and BatchWriteItem puts or deletes items in one or more tables. These batch operations are implemented as wrappers around other non-batch DynamoDB operations. In other words, BatchGetItem invokes GetItem once for each item in the batch. Similarly,BatchWriteItem invokes DeleteItem or PutItem, as appropriate, for each item in the batch.</p><p>A batch operation can tolerate the failure of individual requests in the batch. For example, consider a BatchGetItem request to read five items. Even if some of the underlying GetItem requests fail, this does not cause the entire BatchGetItem operation to fail. On the other hand, if all of the five reads operations fail, then the entire BatchGetItem will fail.</p><p>The batch operations return information about individual requests that fail, so that you can diagnose the problem and retry the operation. For BatchGetItem, the tables and primary keys in question are returned in the UnprocessedKeys parameter of the request. For BatchWriteItem, similar information is returned in UnprocessedItems.</p><h1 id="4-High-level-programming-interfaces-for-DynamoDB-DynamoDBMapper"><a href="#4-High-level-programming-interfaces-for-DynamoDB-DynamoDBMapper" class="headerlink" title="4 High level programming interfaces for DynamoDB - DynamoDBMapper"></a>4 High level programming interfaces for DynamoDB - DynamoDBMapper</h1><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/HigherLevelInterfaces.html" target="_blank" rel="noopener">DynamoDBMapper</a></p><h2 id="4-1-Mapper-class-implementation"><a href="#4-1-Mapper-class-implementation" class="headerlink" title="4.1 Mapper class implementation"></a>4.1 Mapper class implementation</h2><p>With a low level database interface, developers must write methods for reading or writing object data to database tables and vice versa. The amount of extra code required for each combination of object type and database table can seem overwhelming. </p><p>The higher-level interfaces for DynamoDB let you define the relationships between objects in your program and the database tables that store those objects’ data. After you define this mapping, you call simple object methods such as save, load, or delete, and the underlying low-level DynamoDB operations are automatically invoked on your behalf. This allows you to write object-centric code, rather than database-centric code.</p><p>AWS SDK provides a DynamoDBMapper class, allowing you to map your client side classes to DynamoDB tables. To use DynamoDBMapper, you define the relationship between items in a DynamoDB table and their corresponding object instances in your code. </p><pre><code>@DynamoDBTable(tableName=&quot;ProductCatalog&quot;)public class CatalogItem {    private Integer id;    private String title;    private String ISBN;    private Set&lt;String&gt; bookAuthors;    private String someProp;    @DynamoDBHashKey(attributeName=&quot;Id&quot;)      public Integer getId() { return id; }    public void setId(Integer id) {this.id = id; }    @DynamoDBAttribute(attributeName=&quot;Title&quot;)      public String getTitle() {return title; }    public void setTitle(String title) { this.title = title; }    @DynamoDBAttribute(attributeName=&quot;ISBN&quot;)      public String getISBN() { return ISBN; }    public void setISBN(String ISBN) { this.ISBN = ISBN; }    @DynamoDBAttribute(attributeName=&quot;Authors&quot;)    public Set&lt;String&gt; getBookAuthors() { return bookAuthors; }    public void setBookAuthors(Set&lt;String&gt; bookAuthors) { this.bookAuthors = bookAuthors; }    @DynamoDBIgnore    public String getSomeProp() { return someProp; }    public void setSomeProp(String someProp) { this.someProp = someProp; }}</code></pre><h3 id="4-1-1-DynamoDBTable"><a href="#4-1-1-DynamoDBTable" class="headerlink" title="4.1.1 @DynamoDBTable"></a>4.1.1 @DynamoDBTable</h3><p>Maps the class CatalogItem to table ProductCatalog. You can store individual class instances as items in the table.  </p><h3 id="4-1-2-DynamoDBHashKey"><a href="#4-1-2-DynamoDBHashKey" class="headerlink" title="4.1.2 @DynamoDBHashKey"></a>4.1.2 @DynamoDBHashKey</h3><p>Maps the Id property to the primary key </p><h3 id="4-1-3-DynamoDBAttribute"><a href="#4-1-3-DynamoDBAttribute" class="headerlink" title="4.1.3 @DynamoDBAttribute"></a>4.1.3 @DynamoDBAttribute</h3><p>This annotation is optional when the name of the DynamoDB attribute matches the name of the property declared in the class. When they differ, use this annotation with the attributeName() parameter to specify which DynamoDB attribute this property corresponds to. </p><h3 id="4-1-4-DynamoDBIgnore"><a href="#4-1-4-DynamoDBIgnore" class="headerlink" title="4.1.4  @DynamoDBIgnore"></a>4.1.4  @DynamoDBIgnore</h3><p>Those properties will not be mapped to any attributes in the table</p><h2 id="4-2-Use-DynamoDBMapper-Method"><a href="#4-2-Use-DynamoDBMapper-Method" class="headerlink" title="4.2 Use DynamoDBMapper Method"></a>4.2 Use DynamoDBMapper Method</h2><p>Use Mapper method to write an instance of that class to a corresponding item in the Catalog table. </p><pre><code>AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();DynamoDBMapper mapper = new DynamoDBMapper(client);CatalogItem item = new CatalogItem();item.setId(102);item.setTitle(&quot;Book 102 Title&quot;);item.setISBN(&quot;222-2222222222&quot;);item.setBookAuthors(new HashSet&lt;String&gt;(Arrays.asList(&quot;Author 1&quot;, &quot;Author 2&quot;)));item.setSomeProp(&quot;Test&quot;);mapper.save(item);          </code></pre><p>Following code shows how to retrieve the item and access some of its attributes: </p><pre><code>CatalogItem partitionKey = new CatalogItem();partitionKey.setId(102);DynamoDBQueryExpression&lt;CatalogItem&gt; queryExpression = new DynamoDBQueryExpression&lt;CatalogItem&gt;()    .withHashKeyValues(partitionKey);List&lt;CatalogItem&gt; itemList = mapper.query(CatalogItem.class, queryExpression);for (int i = 0; i &lt; itemList.size(); i++) {    System.out.println(itemList.get(i).getTitle());    System.out.println(itemList.get(i).getBookAuthors());}</code></pre><h2 id="4-3-Java-Annotations-for-DynamoDB"><a href="#4-3-Java-Annotations-for-DynamoDB" class="headerlink" title="4.3 Java Annotations for DynamoDB"></a>4.3 Java Annotations for DynamoDB</h2><h3 id="4-3-1-DynamoDBAttribute"><a href="#4-3-1-DynamoDBAttribute" class="headerlink" title="4.3.1 DynamoDBAttribute"></a>4.3.1 DynamoDBAttribute</h3><ul><li>Maps a property to a table attribute. </li></ul><pre><code>@DynamoDBAttribute(attributeName = &quot;Authors&quot;)public List&lt;String&gt; getBookAuthors() { return BookAuthors; }public void setBookAuthors(List&lt;String&gt; BookAuthors) { this.BookAuthors = BookAuthors; }</code></pre><h3 id="4-3-2-DynamoDBAutoGeneratedKey"><a href="#4-3-2-DynamoDBAutoGeneratedKey" class="headerlink" title="4.3.2 DynamoDBAutoGeneratedKey"></a>4.3.2 DynamoDBAutoGeneratedKey</h3><ul><li>Marks a partition key or sort key property as being auto-generated. DynamoDBMapper will generate a random UUID when saving these attributes. Only String properties can be marked as auto-generated keys. </li></ul><pre><code>@DynamoDBTable(tableName=&quot;AutoGeneratedKeysExample&quot;)public class AutoGeneratedKeys {     private String id;    private String payload;    @DynamoDBHashKey(attributeName = &quot;Id&quot;)    @DynamoDBAutoGeneratedKey    public String getId() { return id; }    public void setId(String id) { this.id = id; }     @DynamoDBAttribute(attributeName=&quot;payload&quot;)    public String getPayload() { return this.payload; }    public void setPayload(String payload) { this.payload = payload; }        public static void saveItem() {        AutoGeneratedKeys obj = new AutoGeneratedKeys();        obj.setPayload(&quot;abc123&quot;);        // id field is null at this point               DynamoDBMapper mapper = new DynamoDBMapper(dynamoDBClient);        mapper.save(obj);        System.out.println(&quot;Object was saved with id &quot; + obj.getId());    }}</code></pre><h3 id="4-3-3-DynamoDBDocument"><a href="#4-3-3-DynamoDBDocument" class="headerlink" title="4.3.3 DynamoDBDocument"></a>4.3.3 DynamoDBDocument</h3><ul><li>indicates that a class can be serialized as a DynamoDB document </li></ul><p>For example, suppose you wanted to map a JSON document to a DynamoDB attribute of type Map (M). The following code snippet defines an item containing a nested attribute (Pictures) of type Map.</p><pre><code>public class ProductCatalogItem {    private Integer id;  //partition key    private Pictures pictures;    /* ...other attributes omitted... */    @DynamoDBHashKey(attributeName=&quot;Id&quot;)      public Integer getId() { return id;}    public void setId(Integer id) {this.id = id;}    @DynamoDBAttribute(attributeName=&quot;Pictures&quot;)      public Pictures getPictures() { return pictures;}    public void setPictures(Pictures pictures) {this.pictures = pictures;}    // Additional properties go here.     @DynamoDBDocument    public static class Pictures {        private String frontView;        private String rearView;        private String sideView;        @DynamoDBAttribute(attributeName = &quot;FrontView&quot;)        public String getFrontView() { return frontView; }        public void setFrontView(String frontView) { this.frontView = frontView; }        @DynamoDBAttribute(attributeName = &quot;RearView&quot;)        public String getRearView() { return rearView; }        public void setRearView(String rearView) { this.rearView = rearView; }        @DynamoDBAttribute(attributeName = &quot;SideView&quot;)        public String getSideView() { return sideView; }        public void setSideView(String sideView) { this.sideView = sideView; }     }}</code></pre><p>You could then save a new ProductCatalog item, with pictures, as shown in the following snippet: </p><pre><code>ProductCatalogItem item = new ProductCatalogItem();Pictures pix = new Pictures();pix.setFrontView(&quot;http://example.com/products/123_front.jpg&quot;);pix.setRearView(&quot;http://example.com/products/123_rear.jpg&quot;);pix.setSideView(&quot;http://example.com/products/123_left_side.jpg&quot;);item.setPictures(pix);item.setId(123);mapper.save(item); </code></pre><p>The resulting ProductCalalog item would look like this: </p><pre><code>{  &quot;Id&quot; : 123  &quot;Pictures&quot; : {    &quot;SideView&quot; : &quot;http://example.com/products/123_left_side.jpg&quot;,    &quot;RearView&quot; : &quot;http://example.com/products/123_rear.jpg&quot;,    &quot;FrontView&quot; : &quot;http://example.com/products/123_front.jpg&quot;  }} </code></pre><h3 id="4-3-4-DynamoDBHashKey"><a href="#4-3-4-DynamoDBHashKey" class="headerlink" title="4.3.4 DynamoDBHashKey"></a>4.3.4 DynamoDBHashKey</h3><ul><li>Maps a class property to the partition key of the table. The property must be one of the scalar string, number or binary types; it cannot be a collection type. </li></ul><pre><code>@DynamoDBTable(tableName=&quot;ProductCatalog&quot;) public class CatalogItem {     private Integer Id;      @DynamoDBHashKey(attributeName=&quot;Id&quot;)   public Integer getId() {        return Id;   }   public void setId(Integer Id) {        this.Id = Id;   }   // Additional properties go here. }</code></pre><h3 id="4-3-5-DynamoDBIgnore"><a href="#4-3-5-DynamoDBIgnore" class="headerlink" title="4.3.5 DynamoDBIgnore"></a>4.3.5 DynamoDBIgnore</h3><ul><li>Indicates to the DynamoDBMapper instance that the associated property should be ignored. When saving data to the table, the DynamoDBMapper does not save property to the table. </li></ul><h3 id="4-3-6-DynamoDBIndexHashKey"><a href="#4-3-6-DynamoDBIndexHashKey" class="headerlink" title="4.3.6 DynamoDBIndexHashKey"></a>4.3.6 DynamoDBIndexHashKey</h3><ul><li>Maps a class property to the partition key of a global secondary index. The property must be one of the scalar string, number or binary types; it cannot be a collection type.</li><li>Use this annotation if you need to Query a global secondary index. You must specify the index name (globalSecondaryIndexName). If the name of the class property is different from the index partition key, you must also specify the name of that index attribute (attributeName).</li><li>Global Secondary Indexes <ul><li>aims to speed up queries on non-key values </li></ul></li></ul><h3 id="4-3-7-DynamoDBRangeKey"><a href="#4-3-7-DynamoDBRangeKey" class="headerlink" title="4.3.7 DynamoDBRangeKey"></a>4.3.7 DynamoDBRangeKey</h3><ul><li>Maps a class property to the sort key of the table. The property mush be one of the scalar string, number or binary types; it cannot be a collection type. </li><li>If the primary key is composite (partition key and sort key), you can use this tag to map your class field to the sort key.</li></ul><pre><code>@DynamoDBTable(tableName=&quot;Reply&quot;)public class Reply {     private Integer id;    private String replyDateTime;    @DynamoDBHashKey(attributeName=&quot;Id&quot;)    public Integer getId() { return id; }    public void setId(Integer id) { this.id = id; }     @DynamoDBRangeKey(attributeName=&quot;ReplyDateTime&quot;)    public String getReplyDateTime() { return replyDateTime; }    public void setReplyDateTime(String replyDateTime) { this.replyDateTime = replyDateTime; }    // Additional properties go here. }</code></pre><h3 id="4-3-8-DynamoDBTable"><a href="#4-3-8-DynamoDBTable" class="headerlink" title="4.3.8 DynamoDBTable"></a>4.3.8 DynamoDBTable</h3><ul><li>Identifies the target table in DynamoDB. </li><li>The @DynamoDBTable annotation can be inherited. Any new class that inherits from the Developer class also maps to the People table. For example, assume that you create a Lead class that inherits from the Developer class. Because you mapped the Developer class to the People table, the Lead class objects are also stored in the same table.</li></ul><pre><code>@DynamoDBTable(tableName=&quot;People&quot;) public class Developer { ...} </code></pre><h3 id="4-3-9-DynamoDBTypeConverted"><a href="#4-3-9-DynamoDBTypeConverted" class="headerlink" title="4.3.9 DynamoDBTypeConverted"></a>4.3.9 DynamoDBTypeConverted</h3><pre><code>+ Annotation to mark a property as using a custom type-converter. + This interface lets you map your own arbitrary data types to a data type that is natively supported by DynamoDB</code></pre><h3 id="4-3-10-DynamoDBTyped"><a href="#4-3-10-DynamoDBTyped" class="headerlink" title="4.3.10 DynamoDBTyped"></a>4.3.10 DynamoDBTyped</h3><pre><code>+ Annotation to override the standard attribute type binding. Standard types do not require the annotation if applying the default attribute binding for that type. </code></pre><h3 id="4-3-11-DynamoDBVersionAttribute"><a href="#4-3-11-DynamoDBVersionAttribute" class="headerlink" title="4.3.11 DynamoDBVersionAttribute"></a>4.3.11 DynamoDBVersionAttribute</h3><ul><li>Identifies a class property for storing an optimistic locking version number. DynamoDBMapper assigns a version number to this property when it saves a new item, and increments it each time you update the item.  </li></ul><h2 id="4-4-The-DynamoDBMapper-Class"><a href="#4-4-The-DynamoDBMapper-Class" class="headerlink" title="4.4 The DynamoDBMapper Class"></a>4.4 The DynamoDBMapper Class</h2><p>The DynamoDBMapper class is the entry point to DynamoDB. It provides access to a DynamoDB endpoint and enables you to access data in various tables, perform various CRUD operations on items, and execute queries and scans against tables. </p><h3 id="4-4-1-save"><a href="#4-4-1-save" class="headerlink" title="4.4.1 save"></a>4.4.1 save</h3><p>Saves the specified object to the table. The object that you wish to save is the only required parameter for this method. You can provide optional configuration parameters using the <strong><em>DynamoDBMapperConfig</em></strong> object. </p><p>If an item that has the same primary key does not exist, this method creates a new item in the table. If an item that has the same primary key exists, it updates the existing item. If the partition key and sort key are of type String, and annotated with @DynamoDBAutoGeneratedKey, then they are given a random universally unique identifier (UUID) if left uninitialized. Version fields annotated with @DynamoDBVersionAttribute will be incremented by one. Additionally, if a version field is updated or a key generated, the object passed in is updated as a result of the operation.</p><p>By default, only attributes corresponding to mapped class properties are updated; any additional existing attributes on an item are unaffected. However, if you specify SaveBehavior.CLOBBER, you can force the item to be completely overwritten.</p><pre><code>mapper.save(obj, new DynamoDBMapperConfig(DynamoDBMapperConfig.SaveBehavior.CLOBBER));</code></pre><h3 id="4-4-2-load"><a href="#4-4-2-load" class="headerlink" title="4.4.2 load"></a>4.4.2 load</h3><p>Retrieves an item from a table. You must provide the primary key of the item that you wish to retrieve. You can provide optional configuration parameters using the DynamoDBMapperConfig object. </p><pre><code>CatalogItem item = mapper.load(CatalogItem.class, item.getId(),                 new DynamoDBMapperConfig(DynamoDBMapperConfig.ConsistentReads.CONSISTENT)); </code></pre><h3 id="4-4-3-delete"><a href="#4-4-3-delete" class="headerlink" title="4.4.3 delete"></a>4.4.3 delete</h3><p>Deletes an item from the table, must pass in an object instance of the mapped class. </p><h3 id="4-4-4-query"><a href="#4-4-4-query" class="headerlink" title="4.4.4 query"></a>4.4.4 query</h3><p>Queries a table or a secondary index. You can query a table or an index only if it has a composite primary key (partition key and sort key). This method requires you to provide a partition key value and a query filter that is applied on the sort key. A filter expression includes a condition and a value.</p><pre><code>String forumName = &quot;DynamoDB&quot;;String forumSubject = &quot;DynamoDB Thread 1&quot;;String partitionKey = forumName + &quot;#&quot; + forumSubject;long twoWeeksAgoMilli = (new Date()).getTime() - (14L*24L*60L*60L*1000L);Date twoWeeksAgo = new Date();twoWeeksAgo.setTime(twoWeeksAgoMilli);SimpleDateFormat df = new SimpleDateFormat(&quot;yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS&#39;Z&#39;&quot;);String twoWeeksAgoStr = df.format(twoWeeksAgo);Map&lt;String, AttributeValue&gt; eav = new HashMap&lt;String, AttributeValue&gt;();eav.put(&quot;:v1&quot;, new AttributeValue().withS(partitionKey));eav.put(&quot;:v2&quot;,new AttributeValue().withS(twoWeeksAgoStr.toString()));DynamoDBQueryExpression&lt;Reply&gt; queryExpression = new DynamoDBQueryExpression&lt;Reply&gt;()     .withKeyConditionExpression(&quot;Id = :v1 and ReplyDateTime &gt; :v2&quot;)    .withExpressionAttributeValues(eav);List&lt;Reply&gt; latestReplies = mapper.query(Reply.class, queryExpression);</code></pre><p>By default, the query method returns a “<strong>lazy-loaded</strong>“ collection. It initially returns only one page of results, and then makes a service call for the next page if needed. To obtain all the matching items, you only need to iterate over the latestReplies collection.</p><p>To query an index, you must first <strong><em>model the index as a mapper class</em></strong>, Suppose that the Reply table has a global secondary index named PostedBy-Message-Index. The partition key for this index is PostedBy, and the sort key is Message. The class definition for an item in the index would look like this:</p><pre><code>@DynamoDBTable(tableName=&quot;Reply&quot;)public class PostedByMessage {     private String postedBy;    private String message;    @DynamoDBIndexHashKey(globalSecondaryIndexName = &quot;PostedBy-Message-Index&quot;, attributeName = &quot;PostedBy&quot;)    public String getPostedBy() { return postedBy; }    public void setPostedBy(String postedBy) { this.postedBy = postedBy; }     @DynamoDBIndexRangeKey(globalSecondaryIndexName = &quot;PostedBy-Message-Index&quot;, attributeName = &quot;Message&quot;)    public String getMessage() { return message; }    public void setMessage(String message) { this.message = message; }    // Additional properties go here. }</code></pre><p>The @DynamoDBTable annotation indicates that this index is associated with the Reply table. The @DynamoDBIndexHashKey annotation denotes the partition key (PostedBy) of the index, and @DynamoDBIndexRangeKey denotes the sort key (Message) of the index.</p><p>Now you can use DynamoDBMapper to query the index, retrieving a subset of messages that were posted by a particular user. You must specify withIndexName so that DynamoDB knows which index to query. In the following code snippet, we are querying a global secondary index. Because global secondary indexes support eventually consistent reads, but not strongly consistent reads, we must specify withConsistentRead(false).</p><pre><code>HashMap&lt;String, AttributeValue&gt; eav = new HashMap&lt;String, AttributeValue&gt;();eav.put(&quot;:v1&quot;,  new AttributeValue().withS(&quot;User A&quot;));eav.put(&quot;:v2&quot;,  new AttributeValue().withS(&quot;DynamoDB&quot;));DynamoDBQueryExpression&lt;PostedByMessage&gt; queryExpression = new DynamoDBQueryExpression&lt;PostedByMessage&gt;()    .withIndexName(&quot;PostedBy-Message-Index&quot;)    .withConsistentRead(false)    .withKeyConditionExpression(&quot;PostedBy = :v1 and begins_with(Message, :v2)&quot;)    .withExpressionAttributeValues(eav);List&lt;PostedByMessage&gt; iList =  mapper.query(PostedByMessage.class, queryExpression);</code></pre><h2 id="4-5-Configuration-settings-for-DynamoDBMapper"><a href="#4-5-Configuration-settings-for-DynamoDBMapper" class="headerlink" title="4.5 Configuration settings for DynamoDBMapper"></a>4.5 Configuration settings for DynamoDBMapper</h2><p>When you create an instance of DynamoDBMapper, it has certain default behaviors; you can override these defaults by using the DynamoDBmapperConfig class. </p><pre><code>AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();DynamoDBMapperConfig mapperConfig = new DynamoDBMapperConfig(    DynamoDBMapperConfig.SaveBehavior.CLOBBER,    DynamoDBMapperConfig.ConsistentReads.CONSISTENT,    null, //TableNameOverride - leaving this at default setting    DynamoDBMapperConfig.PaginationLoadingStrategy.EAGER_LOADING    );DynamoDBMapper mapper = new DynamoDBMapper(client, mapperConfig, cp);</code></pre><p><a href="https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/services/dynamodbv2/datamodeling/DynamoDBMapperConfig.html" target="_blank" rel="noopener">API doc for DynamoDBMapperConfig</a></p><ul><li>DynamoDBMapperConfig.ConsistentReads<ul><li>EVENTUAL—the mapper instance uses an eventually consistent read request ++<strong>(default)</strong>++</li><li>CONSISTENT—the mapper instance uses a strongly consistent read request. You can use this optional setting with load, query, or scan operations. Strongly consistent reads have implications for performance and billing; see the DynamoDB product detail page for more information</li></ul></li><li>DynamoDBMapperConfig.PaginationLoadingStrategy - controls how the mapper instance processes a paginated list of data, such as results from a query or scan <ul><li>LAZY_LOADING—the mapper instance loads data when possible, and keeps all loaded results in memory ++<strong>(default)</strong>++</li><li>EAGER_LOADING—the mapper instance loads the data as soon as the list is initialized</li><li>ITERATION_ONLY—you can only use an Iterator to read from the list. During the iteration, the list will clear all the previous results before loading the next page, so that the list will keep at most one page of the loaded results in memory. This also means the list can only be iterated once. This strategy is recommended when handling large items, in order to reduce memory overhead</li></ul></li><li>DynamoDBMapperConfig.SaveBehavior enumeration value - Specifies how the mapper instance should deal with attributes during save operations<ul><li>UPDATE—during a save operation, all modeled attributes are updated, and unmodeled attributes are unaffected. Primitive number types (byte, int, long) are set to 0. Object types are set to null. ++<strong>(default)</strong>++</li><li>CLOBBER—clears and replaces all attributes, included unmodeled ones, during a save operation. This is done by deleting the item and re-creating it. Versioned field constraints are also disregarded.</li></ul></li><li>DynamoDBMapperConfig.TableNameOverride object—Instructs the mapper instance to ignore the table name specified by a class’s DynamoDBTable annotation, and instead use a different table name that you supply. This is useful when partitioning your data into multiple tables at run time.</li></ul><h2 id="4-6-Example-CRUD-Operations"><a href="#4-6-Example-CRUD-Operations" class="headerlink" title="4.6 Example: CRUD Operations"></a>4.6 Example: CRUD Operations</h2><p>The following Java code example declares a CatalogItem class that has Id, Title, ISBN and Authors properties. It uses the annotations to map these properties to the ProductCatalog table in DynamoDB. The code example then uses the DynamoDBMapper to save a book object, retrieve it, update it and delete the book item.</p><pre><code>package com.amazonaws.codesamples.datamodeling;import java.io.IOException;import java.util.Arrays;import java.util.HashSet;import java.util.Set;import com.amazonaws.services.dynamodbv2.AmazonDynamoDB;import com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAttribute;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBHashKey;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapper;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapperConfig;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTable;public class DynamoDBMapperCRUDExample {    static AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard().build();    public static void main(String[] args) throws IOException {        testCRUDOperations();        System.out.println(&quot;Example complete!&quot;);    }    @DynamoDBTable(tableName = &quot;ProductCatalog&quot;)    public static class CatalogItem {        private Integer id;        private String title;        private String ISBN;        private Set&lt;String&gt; bookAuthors;        // Partition key        @DynamoDBHashKey(attributeName = &quot;Id&quot;)        public Integer getId() {            return id;        }        public void setId(Integer id) {            this.id = id;        }        @DynamoDBAttribute(attributeName = &quot;Title&quot;)        public String getTitle() {            return title;        }        public void setTitle(String title) {            this.title = title;        }        @DynamoDBAttribute(attributeName = &quot;ISBN&quot;)        public String getISBN() {            return ISBN;        }        public void setISBN(String ISBN) {            this.ISBN = ISBN;        }        @DynamoDBAttribute(attributeName = &quot;Authors&quot;)        public Set&lt;String&gt; getBookAuthors() {            return bookAuthors;        }        public void setBookAuthors(Set&lt;String&gt; bookAuthors) {            this.bookAuthors = bookAuthors;        }        @Override        public String toString() {            return &quot;Book [ISBN=&quot; + ISBN + &quot;, bookAuthors=&quot; + bookAuthors + &quot;, id=&quot; + id + &quot;, title=&quot; + title + &quot;]&quot;;        }    }    private static void testCRUDOperations() {        CatalogItem item = new CatalogItem();        item.setId(601);        item.setTitle(&quot;Book 601&quot;);        item.setISBN(&quot;611-1111111111&quot;);        item.setBookAuthors(new HashSet&lt;String&gt;(Arrays.asList(&quot;Author1&quot;, &quot;Author2&quot;)));        // Save the item (book).        DynamoDBMapper mapper = new DynamoDBMapper(client);        mapper.save(item);        // Retrieve the item.        CatalogItem itemRetrieved = mapper.load(CatalogItem.class, 601);        System.out.println(&quot;Item retrieved:&quot;);        System.out.println(itemRetrieved);        // Update the item.        itemRetrieved.setISBN(&quot;622-2222222222&quot;);        itemRetrieved.setBookAuthors(new HashSet&lt;String&gt;(Arrays.asList(&quot;Author1&quot;, &quot;Author3&quot;)));        mapper.save(itemRetrieved);        System.out.println(&quot;Item updated:&quot;);        System.out.println(itemRetrieved);        // Retrieve the updated item.        DynamoDBMapperConfig config = new DynamoDBMapperConfig(DynamoDBMapperConfig.ConsistentReads.CONSISTENT);        CatalogItem updatedItem = mapper.load(CatalogItem.class, 601, config);        System.out.println(&quot;Retrieved the previously updated item:&quot;);        System.out.println(updatedItem);        // Delete the item.        mapper.delete(updatedItem);        // Try to retrieve deleted item.        CatalogItem deletedItem = mapper.load(CatalogItem.class, updatedItem.getId(), config);        if (deletedItem == null) {            System.out.println(&quot;Done - Sample item is deleted.&quot;);        }    }}</code></pre><h2 id="4-7-Examples-Batch-Write-Query-Scan-Optimistic-Locking-with-Version-Number"><a href="#4-7-Examples-Batch-Write-Query-Scan-Optimistic-Locking-with-Version-Number" class="headerlink" title="4.7 Examples: Batch Write + Query + Scan + Optimistic Locking with Version Number"></a>4.7 Examples: Batch Write + Query + Scan + Optimistic Locking with Version Number</h2><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.BatchWriteExample.html" target="_blank" rel="noopener">BatchWrite</a></p><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.QueryScanExample.html" target="_blank" rel="noopener">Query and Scan</a></p><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBMapper.OptimisticLocking.html" target="_blank" rel="noopener">Optimistic Locking With Version Number</a></p><h2 id="4-8-Example-Mapping-Arbitrary-Data"><a href="#4-8-Example-Mapping-Arbitrary-Data" class="headerlink" title="4.8 Example: Mapping Arbitrary Data"></a>4.8 Example: Mapping Arbitrary Data</h2><p>In addtion to the supported java types, you can use types in your application for which there is no direct mapping to the DynamoDB types. </p><blockquote><p> To map these types, you must provide an implementation that converts your complex type to a DynamoDB supported type and vice-versa, and annotate the complex type accessor method using the @DynamoDBTypeConverted annotation. </p></blockquote><p>The converter code transforms data when objects are saved or loaded. It is also used for all operations that consume complex types. Note that when comparing data during query and scan operations, the comparisons are made against the data stored in DynamoDB.</p><p>For example, consider the following CatalogItem class that defines a property, Dimension, that is of DimensionType. This property stores the item dimensions, as height, width, and thickness. Assume that you decide to store these item dimensions as a string (such as 8.5x11x.05) in DynamoDB. The following example provides converter code that converts the DimensionType object to a string and a string to the DimensionType.</p><pre><code>package com.amazonaws.codesamples.datamodeling;import java.io.IOException;import java.util.Arrays;import java.util.HashSet;import java.util.Set;import com.amazonaws.regions.Regions;import com.amazonaws.services.dynamodbv2.AmazonDynamoDB;import com.amazonaws.services.dynamodbv2.AmazonDynamoDBClientBuilder;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBAttribute;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBHashKey;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBMapper;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTypeConverted;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTypeConverter;import com.amazonaws.services.dynamodbv2.datamodeling.DynamoDBTable;public class DynamoDBMapperExample {    static AmazonDynamoDB client;    public static void main(String[] args) throws IOException {        // Set the AWS region you want to access.        Regions usWest2 = Regions.US_WEST_2;        client = AmazonDynamoDBClientBuilder.standard().withRegion(usWest2).build();        DimensionType dimType = new DimensionType();        dimType.setHeight(&quot;8.00&quot;);        dimType.setLength(&quot;11.0&quot;);        dimType.setThickness(&quot;1.0&quot;);        Book book = new Book();        book.setId(502);        book.setTitle(&quot;Book 502&quot;);        book.setISBN(&quot;555-5555555555&quot;);        book.setBookAuthors(new HashSet&lt;String&gt;(Arrays.asList(&quot;Author1&quot;, &quot;Author2&quot;)));        book.setDimensions(dimType);        DynamoDBMapper mapper = new DynamoDBMapper(client);        mapper.save(book);        Book bookRetrieved = mapper.load(Book.class, 502);        System.out.println(&quot;Book info: &quot; + &quot;\n&quot; + bookRetrieved);        bookRetrieved.getDimensions().setHeight(&quot;9.0&quot;);        bookRetrieved.getDimensions().setLength(&quot;12.0&quot;);        bookRetrieved.getDimensions().setThickness(&quot;2.0&quot;);        mapper.save(bookRetrieved);        bookRetrieved = mapper.load(Book.class, 502);        System.out.println(&quot;Updated book info: &quot; + &quot;\n&quot; + bookRetrieved);    }    @DynamoDBTable(tableName = &quot;ProductCatalog&quot;)    public static class Book {        private int id;        private String title;        private String ISBN;        private Set&lt;String&gt; bookAuthors;        private DimensionType dimensionType;        // Partition key        @DynamoDBHashKey(attributeName = &quot;Id&quot;)        public int getId() {            return id;        }        public void setId(int id) {            this.id = id;        }        @DynamoDBAttribute(attributeName = &quot;Title&quot;)        public String getTitle() {            return title;        }        public void setTitle(String title) {            this.title = title;        }        @DynamoDBAttribute(attributeName = &quot;ISBN&quot;)        public String getISBN() {            return ISBN;        }        public void setISBN(String ISBN) {            this.ISBN = ISBN;        }        @DynamoDBAttribute(attributeName = &quot;Authors&quot;)        public Set&lt;String&gt; getBookAuthors() {            return bookAuthors;        }        public void setBookAuthors(Set&lt;String&gt; bookAuthors) {            this.bookAuthors = bookAuthors;        }        @DynamoDBTypeConverted(converter = DimensionTypeConverter.class)        @DynamoDBAttribute(attributeName = &quot;Dimensions&quot;)        public DimensionType getDimensions() {            return dimensionType;        }        @DynamoDBAttribute(attributeName = &quot;Dimensions&quot;)        public void setDimensions(DimensionType dimensionType) {            this.dimensionType = dimensionType;        }        @Override        public String toString() {            return &quot;Book [ISBN=&quot; + ISBN + &quot;, bookAuthors=&quot; + bookAuthors + &quot;, dimensionType= &quot;                + dimensionType.getHeight() + &quot; X &quot; + dimensionType.getLength() + &quot; X &quot; + dimensionType.getThickness()                + &quot;, Id=&quot; + id + &quot;, Title=&quot; + title + &quot;]&quot;;        }    }    static public class DimensionType {        private String length;        private String height;        private String thickness;        public String getLength() {            return length;        }        public void setLength(String length) {            this.length = length;        }        public String getHeight() {            return height;        }        public void setHeight(String height) {            this.height = height;        }        public String getThickness() {            return thickness;        }        public void setThickness(String thickness) {            this.thickness = thickness;        }    }    // Converts the complex type DimensionType to a string and vice-versa.    static public class DimensionTypeConverter implements DynamoDBTypeConverter&lt;String, DimensionType&gt; {        @Override        public String convert(DimensionType object) {            DimensionType itemDimensions = (DimensionType) object;            String dimension = null;            try {                if (itemDimensions != null) {                    dimension = String.format(&quot;%s x %s x %s&quot;, itemDimensions.getLength(), itemDimensions.getHeight(),                        itemDimensions.getThickness());                }            }            catch (Exception e) {                e.printStackTrace();            }            return dimension;        }        @Override        public DimensionType unconvert(String s) {            DimensionType itemDimension = new DimensionType();            try {                if (s != null &amp;&amp; s.length() != 0) {                    String[] data = s.split(&quot;x&quot;);                    itemDimension.setLength(data[0].trim());                    itemDimension.setHeight(data[1].trim());                    itemDimension.setThickness(data[2].trim());                }            }            catch (Exception e) {                e.printStackTrace();            }            return itemDimension;        }    }}</code></pre><h1 id="5-Best-Practices"><a href="#5-Best-Practices" class="headerlink" title="5. Best Practices"></a>5. Best Practices</h1><h2 id="5-1-Partition-Key-Design"><a href="#5-1-Partition-Key-Design" class="headerlink" title="5.1 Partition Key Design"></a>5.1 Partition Key Design</h2><p>Generally speaking, you should design your application for <strong>uniform activity across all logical partition keys</strong> in the Table and its secondary indexes. You can determine the access patterns that your application requires, and estimate the total RCUs and WCUs that each table and secondary Index requires.</p><p>As traffic starts to flow, DynamoDB automatically supports your access patterns using the throughput you have provisioned, as long as the traffic against a given partition key does not exceed 3000 RCUs or 1000 WCUs.</p><h3 id="5-1-1-Using-Burst-Capacity-Effectively"><a href="#5-1-1-Using-Burst-Capacity-Effectively" class="headerlink" title="5.1.1 Using Burst Capacity Effectively"></a>5.1.1 Using Burst Capacity Effectively</h3><p>DynamoDB provides some flexibility in your per-partition throughput provisioning by providing burst capacity, as follows. Whenever you are not fully using a partition’s throughput, DynamoDB reserves a portion of that unused capacity for later bursts of throughput to handle usage spikes.</p><p>DynamoDB currently retains up to <strong>five minutes (300 seconds)</strong> of unused read and write capacity. During an occasional burst of read or write activity, these extra capacity units can be consumed quickly—even faster than the per-second provisioned throughput capacity that you’ve defined for your table.</p><h3 id="5-1-2-Adaptive-Capacity"><a href="#5-1-2-Adaptive-Capacity" class="headerlink" title="5.1.2 Adaptive Capacity"></a>5.1.2 Adaptive Capacity</h3><p>When data access is imbalanced, a “hot” partition can receive such a higher volume of read and write traffic compared to other partitions. In extreme cases, throttling can occur if a single partition receives more than 3,000 RCUs or 1,000 WCUs. </p><p>To better accommodate uneven access patterns, DynamoDB adaptive capacity enables your application to continue reading and writing to hot partitions without being throttled, provided that traffic does not exceed your table’s total provisioned capacity or the partition maximum capacity. Adaptive capacity works by automatically increasing throughput capacity for partitions that receive more traffic.</p><h1 id="6-Working-with-Stream"><a href="#6-Working-with-Stream" class="headerlink" title="6. Working with Stream"></a>6. Working with Stream</h1><p>DynamoDB streams captures a time-ordered sequence of item-level modifications in any DynamoDB table, and stores this information in a log for up to 24 hours. Applications can access this log and view the data items as they appeared before and after they were modified, in near real time.</p><blockquote><p>A DynamoDB stream is an ordered flow of information about changes to items in an Amazon DynamoDB table. When you enable a stream on a table, DynamoDB captures information about every modification to data items in the table. </p></blockquote><p>Whenever an application creates, updates, or deletes items in the table, DynamoDB Streams writes a stream record with the primary key attribute(s) of the items that were modified. A stream record contains information about a data modification to a single item in a DynamoDB table. You can configure the stream so that the stream records capture additional information, such as the “before” and “after” images of modified items.</p><p>DynamoDB Streams guarantees the following: </p><ul><li>Each stream record appears exactly once in the stream </li><li><strong>For each item that is modified in a DynamoDB table, the stream records appear in the same sequence as the actual modifications to the item.</strong></li></ul><p>DynamoDB Streams writes stream records in near real time, so that you can build applications that consume these streams and take action based on the contents.</p><p>Use one endpoint for accessing DynamoDB, and another endpoint within same region for accessing DynamoDB streams. </p><h2 id="6-1-Reading-and-Processing-a-Stream"><a href="#6-1-Reading-and-Processing-a-Stream" class="headerlink" title="6.1 Reading and Processing a Stream"></a>6.1 Reading and Processing a Stream</h2><p>To read and process a stream, your application will need to connect to a DynamoDB Streams endpoint and issue API requests. </p><p>A stream consists of stream records. Each stream record represents a single data modification in the DynamoDB table to which the stream belongs. Each stream record is assigned a sequence number, reflecting the order in which the record was published to the stream.</p><p>Stream records are organized into groups, or shards. Each shard acts as a container for multiple stream records, and contains information required for accessing and iterating through these records. The stream records within a shard are removed automatically after 24 hours.</p><p>Shards are ephemeral: They are created and deleted automatically, as needed. Any shard can also split into multiple new shards; this also occurs automatically. (Note that it is also possible for a parent shard to have just one child shard.) A shard might split in response to high levels of write activity on its parent table, so that applications can process records from multiple shards in parallel.</p><p>Because shards have a lineage (parent and children), an application must always process a parent shard before it processes a child shard. This will ensure that the stream records are also processed in the correct order. (If you use the DynamoDB Streams Kinesis Adapter, this is handled for you: Your application will process the shards and stream records in the correct order, and automatically handle new or expired shards, as well as shards that split while the application is running.</p><p>To access a stream and process the stream records within, you must do the following: </p><ul><li>Determine the unique Amazon Resource Name (ARN) of the stream that you want to access.</li><li>Determine which shard(s) in the stream contain the stream records that you are interested in.</li><li>Access the shard(s) and retrieve the stream records that you want</li></ul><h2 id="6-2-DynamoDB-Streams-API"><a href="#6-2-DynamoDB-Streams-API" class="headerlink" title="6.2 DynamoDB Streams API"></a>6.2 DynamoDB Streams API</h2><p><a href="https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Operations_Amazon_DynamoDB_Streams.html" target="_blank" rel="noopener">API Instructions</a></p><h3 id="6-2-1-ListStreams"><a href="#6-2-1-ListStreams" class="headerlink" title="6.2.1 ListStreams"></a>6.2.1 ListStreams</h3><p>returns a list of stream descriptors for the current account and endpoint. You can optionally request just the stream descriptors for a particular table name.</p><h3 id="6-2-2-DescribeStream"><a href="#6-2-2-DescribeStream" class="headerlink" title="6.2.2 DescribeStream"></a>6.2.2 DescribeStream</h3><p>returns detailed information about a given stream. The output includes a list of shards associated with the stream, including the shard IDs.</p><h3 id="6-2-3-GetShardIterator"><a href="#6-2-3-GetShardIterator" class="headerlink" title="6.2.3 GetShardIterator"></a>6.2.3 GetShardIterator</h3><p>returns a shard iterator, which describes a location within a shard. You can request that the iterator provide access to the oldest point, the newest point, or a particular point in the stream.</p><h3 id="6-2-4-GetRecords"><a href="#6-2-4-GetRecords" class="headerlink" title="6.2.4 GetRecords"></a>6.2.4 GetRecords</h3><p>returns the stream records from within a given shard. </p><h2 id="6-3-Using-the-DynamoDB-Streams-Kinesis-Adapter-to-Process-Stream-Records"><a href="#6-3-Using-the-DynamoDB-Streams-Kinesis-Adapter-to-Process-Stream-Records" class="headerlink" title="6.3 Using the DynamoDB Streams Kinesis Adapter to Process Stream Records"></a>6.3 Using the DynamoDB Streams Kinesis Adapter to Process Stream Records</h2><p><a href="https://aws.amazon.com/blogs/database/how-to-perform-ordered-data-replication-between-applications-by-using-amazon-dynamodb-streams/" target="_blank" rel="noopener">How to perform ordered data replication between applications by using Amazon DynamoDB Streams</a></p>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> DynamoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.11 Deploying Applications</title>
      <link href="/Developing-on-AWS-Note-11-Deploying-Applications/"/>
      <url>/Developing-on-AWS-Note-11-Deploying-Applications/</url>
      
        <content type="html"><![CDATA[<h1 id="1-DevOps"><a href="#1-DevOps" class="headerlink" title="1. DevOps"></a>1. DevOps</h1><ul><li>Application is the application plus all of the associated infrastructure</li><li>includes<ul><li>VPCs </li><li>load balancers</li><li>auto scaling groups </li><li>Amazon RDS databases</li><li>Amazon S3 bucket </li><li>elastiCache servers</li></ul></li><li>deploying in the cloud helps break down these traditional silos. Bugs due to different environment. </li><li>practices<ul><li>microservices</li><li>CI/ CD</li><li>Infrastructure as code </li></ul></li><li>Tools <ul><li>AWS Code Services </li></ul></li><li>Under a DevOps model, development and operations are no longer siloed. </li><li>Sometimes, those two functions are merged into a single team where engineers work across the entire application lifecycle, from development and test to deployment to operations, and develop a range of skills not limited to a single function. </li><li>Quality assurance and security teams could become more tightly integrated with development and operations throughout the application lifecycle. </li></ul><h1 id="2-Release-Processes-Major-Phases"><a href="#2-Release-Processes-Major-Phases" class="headerlink" title="2. Release Processes Major Phases"></a>2. Release Processes Major Phases</h1><p>Each steps can be automated without the entire release process being automated. </p><ul><li>Source<ul><li>Check in source code such as .java files </li><li>Code review</li></ul></li><li>Build<ul><li>Compile code </li><li>style checkers</li><li>code metrics</li><li>create container images </li></ul></li><li>Test <ul><li>Integration tests with other systems</li><li>load testing</li><li>UI tests</li><li>penetration testing </li></ul></li><li>Deploy<ul><li>Deployment to production environments </li></ul></li><li>Monitor<ul><li>Monitor in production to quickly detect unusual activity or errors</li></ul></li></ul><h1 id="3-Understanding-CI-amp-CD"><a href="#3-Understanding-CI-amp-CD" class="headerlink" title="3. Understanding CI &amp; CD"></a>3. Understanding CI &amp; CD</h1><ul><li><p>Continuous Integration </p><ul><li>The practice of checking code and verifying each change with an automated build and test process</li><li>Require teams to write automated tests which can improve the quality of the software being released and reduce the time it takes to validate that the new version of software is good. </li><li>Architecture for cloud Continuous Integration<ul><li>Developer commits changes to the central repo. Pre-commit hooks should run and verify that the code meets specified requirements</li><li>A CI server pulls the changes from the central repo and builds the code</li><li>The CI server runs all required tests against the new branch or mainline change. </li><li>The CI server returns a report to developer and stops the build job if a failure occurs. </li><li>If the changes pass the required tests, the CI server builds the artifacts</li><li>The CI server pushes artifacts to the package builder</li><li>The <strong>package builder</strong> gets configuration information from the version control system </li><li>The pacakge builder uses the configuration information and the artifacts to build the specified packages </li><li>the packages are stored in a repository </li><li>the repo uses a post-receive hook to deploy specific packages to staging. </li><li>Do not fear rollbacks. Errors will happen, mistakes will be made, and the benefit of employing version control systems is that when appropriate, you can always revert to a previously working state and save yourself the time and effort of trying to debug </li></ul></li></ul></li><li><p>Continuous Delivery</p><ul><li>It extends continuous Integration to include testing out to production-like stages and running verification testing against those deployments. </li><li>CD may extend all the way to a production deployment, but they have some form of manual intervention between a code check-in and when that code is available for customers to use</li></ul></li><li><p>Continuous Deployment </p><ul><li>extends continuous delivery and is the automated release of software to customers from check in through to production without human intervention.  </li></ul></li></ul><h1 id="4-How-do-you-deploy-all-infrastructure-along-with-your-application"><a href="#4-How-do-you-deploy-all-infrastructure-along-with-your-application" class="headerlink" title="4. How do you deploy all infrastructure along with your application?"></a>4. How do you deploy all infrastructure along with your application?</h1><ul><li>Infrastructure as code <ul><li>Define your AWS environment so that it can be created in a repeatable automated fashion </li><li>stand up identical dev/ test environments on demand </li><li>use the same code to create your production environment that you used to create your other environments</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> CI/ CD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.10 Docker, ECS, Security</title>
      <link href="/Developing-on-AWS-Note-10-Docker-ECS-Security/"/>
      <url>/Developing-on-AWS-Note-10-Docker-ECS-Security/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Why-Containers"><a href="#1-Why-Containers" class="headerlink" title="1. Why Containers?"></a>1. Why Containers?</h1><h2 id="1-1-Benefits"><a href="#1-1-Benefits" class="headerlink" title="1.1 Benefits"></a>1.1 Benefits</h2><ul><li>software development lifecycle<ul><li>source code</li><li>code repository </li><li>build env</li><li>artifact repository </li><li>test environment</li><li>deployment env</li></ul></li><li>Containers<ul><li>a method of <strong>operating system virtualization</strong> that allow you to run an application and its dependencies in resource-isolated processes. Containers allow you to easily package an application’s code, configurations, and dependencies into easy to use building blocks that deliver <strong>environmental consistency, operational efficiency, developer productivity, and version control</strong> </li><li>help resolve problems<ul><li>different application stacks</li><li>different hardware deployment environments</li><li>run applications across different envs</li><li>migration to different envs</li></ul></li><li>benefits<ul><li>allow you to easily package an application’s code, configurations, and dependencies into easy to use building blocks that deliver environmental consistency, operational efficiency, developer productivity, and version control</li></ul></li></ul></li><li>docker containers<ul><li>decouple applications from operating systems </li></ul></li><li>Containers vs VM <ul><li>Containers can run on any Linux system with appropriate kernel feature support and the Docker daemon present. This makes them extremely portable. Your laptop, your VM, your EC2 instance, and your bare metal server are all potential hosts.</li><li>The lack of a hypervisor requirement also results in almost no noticeable performance overhead. The processes are talking directly to the kernel and are largely unaware of their container silo. Most containers boot in just a couple of seconds.</li><li>Where VMs are isolated at the operating system level, containers are isolated at the kernel level. This means that several applications can run on a single host operating system, and yet still have their own file system, storage, RAM, libraries, essentially, their own “view” of the system. </li></ul></li></ul><h2 id="1-2-When-to-use-Docker-Containers"><a href="#1-2-When-to-use-Docker-Containers" class="headerlink" title="1.2 When to use Docker Containers"></a>1.2 When to use Docker Containers</h2><ul><li>Distributed apps and microservices<ul><li>breaking up monoliths </li><li>service oriented architecture</li></ul></li><li>Batch Jobs<ul><li>short lived jobs</li><li>variety and flexibility </li><li>elastic</li></ul></li><li>CI/ CD pipelins<ul><li>packaging your code in a Docker images</li><li>test</li><li>deploy in production </li></ul></li></ul><h2 id="1-3-Microservices-architecture-with-Containers"><a href="#1-3-Microservices-architecture-with-Containers" class="headerlink" title="1.3 Microservices architecture with Containers"></a>1.3 Microservices architecture with Containers</h2><p>Using Docker, all of the different tiers of your Web application architecture could be <strong>constructed as independent Docker containers</strong>. If you are deploying a microservices architecture, you could <strong>implement each service as its own separate Docker container</strong>. Such an approach has several advantages: </p><ul><li>You can distribute running services across instances on an Amazon EC2 fleet.</li><li>You can <strong>run multiple services on a single Amazon EC2 instance within your fleet</strong>. This allows maximizing the CPU and memory usage of your existing instances.</li><li>You can <strong>run multiple different versions of a service simultaneously</strong> - even on the same machine, assuming that they bind to different ports. This allows you to release breaking changes in services while retaining backward compatibility with applications that may not have yet been modified to work against the new version.</li></ul><h2 id="1-4-Docker-Image-Registry"><a href="#1-4-Docker-Image-Registry" class="headerlink" title="1.4 Docker Image Registry"></a>1.4 Docker Image Registry</h2><ul><li>Amazon Elastic Container Registry (Amazon ECR) is a fully-managed Docker container registry that makes it easy for you to store, manage, and deploy Docker container images. </li><li>Amazon ECR can be used standalone and also has deep integration with Amazon ECS, simplifying your development to production workflow. </li><li>Amazon ECR eliminates the need to operate your own container repositories or worry about scaling the underlying infrastructure. </li><li>Amazon ECR hosts your images in a highly available and scalable architecture, allowing you to reliably deploy containers for your applications.</li></ul><h1 id="2-Amazon-Container-Services"><a href="#2-Amazon-Container-Services" class="headerlink" title="2. Amazon Container Services"></a>2. Amazon Container Services</h1><ul><li>You need a way to intelligently place your containers on the hosts that have the resources and that means you need to know the state of everything in your system.</li><li>Amazon Container Services<ul><li>management <ul><li>deploy, schedule, scale,</li><li>Elastic Container Service (ECS)</li><li>Elastic Container Service for Kubernetes (EKS)</li></ul></li><li>hosting <ul><li>Amazon EC2</li><li>AWS Fargate</li></ul></li><li>Image Registry <ul><li>Amazon Elastic Container Registry (ECR)</li></ul></li></ul></li></ul><h1 id="3-Developing-Secure-Applications"><a href="#3-Developing-Secure-Applications" class="headerlink" title="3. Developing Secure Applications"></a>3. Developing Secure Applications</h1><h2 id="3-1-AWS-Certificates-Manager"><a href="#3-1-AWS-Certificates-Manager" class="headerlink" title="3.1 AWS Certificates Manager"></a>3.1 AWS Certificates Manager</h2><ul><li>AWS Certificate Manager is a service that lets you easily provision, manage, and deploy public and private Secure Sockets Layer/ Transport Layer Security (SSL/ TLS) certificates for use with AWS services and your internal connected resources. </li><li>SSL/ TLS are used to secure network communications and establish the identity of websites over the internet as well as resources on private networks. </li><li>With ACM, you can quickly request a certificate, deploy it on ACM-integrated AWS resources, such as Elastic Load Balancing, Amazon CloudFront distributions, and APIs on API Gateway, and let ACM handle certificate renewals. </li><li>It also enables you to create private certificates for your internal resources and manage the certificate lifecycle centrally. Public and private certificates provisioned through ACM for use with ACM-integrated services are free.</li></ul><h2 id="3-2-AWS-Secrets-Manager"><a href="#3-2-AWS-Secrets-Manager" class="headerlink" title="3.2 AWS Secrets Manager"></a>3.2 AWS Secrets Manager</h2><ul><li>Rotate, manage, and retrieve databse credentials, API keys, and other secrets throughout their lifecycle. </li><li>IT administrators<ul><li>store and manage access to secrets securely and at scale</li></ul></li><li>Security administrators<ul><li>audit and monitor the use of secrets, and rotate secrets without a risk of breaking applications </li><li>offer secret rotation with build-in integration for Amazon RDS for MySQL, PostgreSQL and Amazon Aurora. </li></ul></li><li>Developers<ul><li>avoid dealing with secrets in the applications </li></ul></li></ul><h2 id="3-3-AWS-Security-Token-Service"><a href="#3-3-AWS-Security-Token-Service" class="headerlink" title="3.3 AWS Security Token Service"></a>3.3 AWS Security Token Service</h2><ul><li>provides trusted users with temporary security credentials </li><li>configurable credential lifetime</li><li>once expired, cannot be reused</li><li>use IAM policies to control the privileges </li><li>no limit on the number of temporary credentials issued </li><li>Important points<ul><li>all calls go to the global endpoint, by default</li><li>global endpoint maps to the US East region </li><li>Regional endpoints are activated by default</li><li>use AWS cloudTrail to log SRS calls</li></ul></li></ul><h2 id="3-4-Identity-Providers"><a href="#3-4-Identity-Providers" class="headerlink" title="3.4 Identity Providers"></a>3.4 Identity Providers</h2><ul><li>an alternative to create IAM users in AWS account</li><li>can manage user identities outside of AWS, and you can give these external user identities permissions to use AWS resources in account </li><li>To use an identity provider, create an IAM identity provider entity to establish trust between your AWS account and the external identity provider.</li></ul><h2 id="3-5-Security-Assetion-Markup-Language-SAML"><a href="#3-5-Security-Assetion-Markup-Language-SAML" class="headerlink" title="3.5 Security Assetion Markup Language (SAML)"></a>3.5 Security Assetion Markup Language (SAML)</h2><ul><li>Use single sign-on to sign in to all of your SAML-enbabled applications by using a single set of credentials </li><li>Manage access to your applications centrally </li></ul><h2 id="3-6-Amazon-Cognito"><a href="#3-6-Amazon-Cognito" class="headerlink" title="3.6 Amazon Cognito"></a>3.6 Amazon Cognito</h2><ul><li>Allow saving and synchronizing user data on different devices</li><li>Allow access to AWS cloud services using <ul><li>public login providers</li><li>own user identity system </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Security </tag>
            
            <tag> Docker </tag>
            
            <tag> ECS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.9 Step Functions, ElasticCache</title>
      <link href="/Developing-on-AWS-Note-9-Step-Functions-ElasticCache/"/>
      <url>/Developing-on-AWS-Note-9-Step-Functions-ElasticCache/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Understanding-the-need-for-step-functions"><a href="#1-Understanding-the-need-for-step-functions" class="headerlink" title="1. Understanding the need for step functions"></a>1. Understanding the need for step functions</h1><ul><li><p>Step functions make it easy to coordinate components of distributed applications and microservices by using visual workflows. </p></li><li><p>Microservices are processes that communicate with each other over a network to complete a larger goal. </p></li><li><p>Applications built as a collections of microservices are more resilient and easier to scale. </p></li><li><p>Have cases that we begin to have more functions and they continue to grow</p></li><li><p>Need a mechanism to scale out, easily handle errors and timeouts, easily build and operate</p></li></ul><h1 id="2-Intro-to-AWS-Step-Functions"><a href="#2-Intro-to-AWS-Step-Functions" class="headerlink" title="2. Intro to AWS Step Functions"></a>2. Intro to AWS Step Functions</h1><ul><li>define a workflow called a state machine made up of states</li><li>each order is an execution through this state machine </li><li>each execution starts with an input and the states transform it</li><li>step functions keep track of the state of each execution </li><li>actually, it’s a web service that enables you to coordinate the components of distributed applications and microservices using visual workflows.</li><li>provides a reliable way to coordinate components and step through the functions of your application. </li><li>automatically triggers and tracks each step, and retries when there are errors</li><li>lifecycle<ul><li>define workflow as a series of steps and transitions between each step, also known as a state machine</li><li>step functions ingests your JSON template and turns it into a real-time graphical view , help you make sense of your state machine’s current state</li></ul></li><li>benefits <ul><li>productivity<ul><li>build applications quickly  </li></ul></li><li>agility<ul><li>scale and recover reliably </li></ul></li><li>resilience <ul><li>evolve applications easily </li></ul></li></ul></li><li>Terminology<ul><li>state machine - workflow template<ul><li>an object that has a set number of operating conditions that depend on its previous condition to determine output </li><li>AWS step functions allows you to create and automate state machines within the AWS env<ul><li>with the use of a JSON-based Amazon State Language</li><li>a collection states, that can to work (task states), determine which states to transition to next (Choicestates), stop an execution with an error</li></ul></li><li>state common features<ul><li>each state must have a type field indicating what type of state it is</li><li>each state can have an optinal comment field to hold a human readable comment about, or description of, the state</li><li>Each state (except a Succeed or Fail state) requires a Next field or, alternatively, can become a terminal state by specifying an End field.</li></ul></li><li>state types<ul><li>task </li><li>choise - adds branching logic</li><li>parallel </li><li>wait</li><li>fail</li><li>succeed </li><li>pass</li></ul></li></ul></li><li>execution - specific workflow based on template</li><li>task - lambda function or activity <ul><li>An activity consists of program code or a task that waits for <strong>an operator to perform</strong> an action or to provide input. You can host activities on Amazon EC2, on Amazon ECS, or even on mobile devices. Activities poll Step Functions using the <strong>GetActivityTask</strong> and <strong>SendTaskSuccess</strong>, <strong>SendTaskFailure</strong>, and <strong>SendTaskHeartbeat</strong> API actions. Activities represent workers (processes or threads), implemented and hosted by you, that perform a specific task.</li><li>A Lambda function is a cloud-native task that runs on AWS Lambda. You can write Lambda functions in a variety of programming languages, using the AWS Management Console or by uploading code to Lambda. Lambda functions execute a function using AWS Lambda. To specify a Lambda function, use the ARN of the Lambda function in the Resource field </li></ul></li><li>activity - handle for external compute</li><li>task token - ID for instance of activity </li><li>heartbeat - ping from task indicating that it is still running </li><li>failure </li><li>success </li></ul></li></ul><h1 id="3-Caching-for-scalibility"><a href="#3-Caching-for-scalibility" class="headerlink" title="3. Caching for scalibility"></a>3. Caching for scalibility</h1><h2 id="3-1-Caching-Overview"><a href="#3-1-Caching-Overview" class="headerlink" title="3.1 Caching Overview"></a>3.1 Caching Overview</h2><ul><li>Benefits<ul><li>Provides high throughput, low latency access to commonly accessed application data, <strong>by storing the data in memory</strong></li><li>imrpove the speed </li><li>reduce the response latency </li><li>the following types of information or applications can benefit from caching:<ul><li>results of database queries</li><li>results of intensive calculations</li><li>results of remote API calls </li></ul></li></ul></li></ul><ul><li>when to consider caching your data<ul><li>data that requires a slow and expensive query to acquire </li><li>relatively static and frequently accessed data </li><li>information that can afford to be stale for some time</li><li>data should be relatively static and frequently accessed</li><li>Cache data should always be considered and treated as stale</li></ul></li></ul><h2 id="3-2-Caching-Strategy"><a href="#3-2-Caching-Strategy" class="headerlink" title="3.2 Caching Strategy"></a>3.2 Caching Strategy</h2><h1 id="4-Amazon-ElastiCache"><a href="#4-Amazon-ElastiCache" class="headerlink" title="4. Amazon ElastiCache"></a>4. Amazon ElastiCache</h1><ul><li>a webservice that makes it easy to deploy, operate and scale an in-memory cache in the cloud</li><li>ElastiCache improves the performance of web applications by allowing you to retrieve information from fast, managed, in-memory caches, instead of relying entirely on slower disk-based databases </li><li>ElastiCache supports<ul><li>Memcached</li><li>Redis</li></ul></li></ul><h2 id="4-1-Memcached-vs-Redis"><a href="#4-1-Memcached-vs-Redis" class="headerlink" title="4.1 Memcached vs Redis"></a>4.1 Memcached vs Redis</h2><ul><li>Memcached<ul><li>multithreading </li><li>low maintenance </li><li>easy horizontal scalability with auto discovery </li><li>single AZ </li><li>lack persistence<ul><li>if you terminate node or scale it down, you lose the data stored in that cache memory  </li></ul></li></ul></li><li>Redis<ul><li>single thread </li><li>support for data structures <ul><li>strings</li><li>hashes</li><li>lists</li><li>sets</li><li>sorted sets with range queries</li><li>bitmaps</li><li>hypolog</li><li>geospatial indexes with radius queries</li></ul></li><li>persistence </li><li>atomic operations </li><li>pub/ sub messaging</li><li>read replicas/ failover</li><li>cluster mode/ sharded clusters</li><li>multiple AZ </li></ul></li></ul><h2 id="4-2-Terminology"><a href="#4-2-Terminology" class="headerlink" title="4.2 Terminology"></a>4.2 Terminology</h2><ul><li>node<ul><li>smallest building block of an ElastiCache deployment </li></ul></li><li>cluster<ul><li>a logical grouping of one or more nodes</li></ul></li><li>replication group<ul><li>a collection of Redis clusters</li><li>with one primary read-write cluster and up to five secondary, read only clusters, which are called read replicas. </li><li>each read replica maintains a copy of the data from the primary cluster</li><li>asynchronous replication mechanisms are used to keep the read-replicas synchronized with the primary cluster </li><li>applications can <strong>read from any cluster in the replication group</strong> </li><li>applications can write only to the primary cluster</li><li>read replicas enhance scalability and guard against data loss </li></ul></li></ul><h2 id="4-3-Cache-hit-amp-Cache-Miss-Scenarios"><a href="#4-3-Cache-hit-amp-Cache-Miss-Scenarios" class="headerlink" title="4.3 Cache hit &amp; Cache Miss Scenarios"></a>4.3 Cache hit &amp; Cache Miss Scenarios</h2><ul><li>cache hit occurs when the cache contains the information required</li><li>cache miss occurs when the cache does not contain the information requested</li><li>ElastiCache caches data as key-value pairs.</li><li>An application can retrieve a value corresponding to a specific key. </li><li>An application can store an item in cache by specifying a key, value, and an expiration time(TTL). </li></ul><h2 id="4-4-Cache-strategies"><a href="#4-4-Cache-strategies" class="headerlink" title="4.4 Cache strategies"></a>4.4 Cache strategies</h2><ul><li>Lazy loading<ul><li>Whenever your application requests data, it first makes the request to the ElastiCache cache. </li><li>If the data exists in the cache and is current, ElastiCache returns the data to your application. </li><li>If the data does not exist in the cache, or the data in the cache has expired, your application requests the data from your data store which returns the data to your application. </li><li>Your application then writes the data received from the store to the cache so it can be more quickly retrieved next time it is requested.</li><li>Lazy Loading is a caching strategy that loads data into the cache only when necessary. </li><li>Avoid filling up the cache with unnecessary data</li><li>advantages<ul><li>Only requested data is cached. Since most data is never requested, lazy loading avoids filling up the cache with data that isn’t requested.</li><li>Node failures are not fatal. </li><li>When a node fails and is replaced by a new, empty node the application continues to function, though with increased latency. As requests are made to the new node each cache miss results in a query of the database and adding the data copy to the cache so that subsequent requests are retrieved from the cache.</li></ul></li><li>disadvantages<ul><li>a cache miss penalty, each cache miss results in 3 trips<ul><li>initial request for data from the cache</li><li>query of the database for the data</li><li>write the data to the cache </li></ul></li><li>may receive stale data because another application may have updated the data in the database behind the scenes. </li></ul></li></ul></li><li>write through <ul><li>this strategy adds data or updates data in the cache whenever data is written to the database </li><li>advantages<ul><li>data in the cache is never stale, always current</li></ul></li><li>disadvantages<ul><li>write penalty, involve two trips<ul><li>a write to cache, and a write to the database</li><li>missing data: When a new node is created to scale up or to replace a failed node, the node does not contain all data. Data continues to be missing until it is added or updated in the database. In this scenario, you might choose to use a lazy caching approach to repopulate the cache</li><li>Unused data: Since most data is never read, there can be a lot of data in the cluster that is never read.</li><li>Cache churn: The cache may be updated often if certain records are updated repeatedly.</li></ul></li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Step Functions </tag>
            
            <tag> ElasticCache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.8 SQS, SNS</title>
      <link href="/Developing-on-AWS-Note-8-SQS-SNS/"/>
      <url>/Developing-on-AWS-Note-8-SQS-SNS/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Why-use-a-queuing-service"><a href="#1-Why-use-a-queuing-service" class="headerlink" title="1. Why use a queuing service?"></a>1. Why use a queuing service?</h1><p>Consider a scenario where an application produces messages that must be processed by a consumer downstream. The producer needs to know how to connect to the consumer. If the consumer fails for some reason, then messages may be lost. If new consumer instances are launched to recover from failure or to keep up with an increased workload, the producer needs to be explicitly made aware of the new consumer instances. In this scenario, the producer is tightly coupled with the consumers and the coupling is prone to brittleness.</p><p>In this way, there will be a strong interdependency between teh consumer and the producer, which is a <strong>tightly coupled system</strong>. which is not fault tolerant, if any one component in our system fails, the entire system will fail. </p><ul><li>Having a queue service decouples the producer from the consumer.<ul><li>queue is a temprary repositiory for messages that are awaiting processing. </li><li>acts as a buffer between the component producing data and the component receiving the data for processing. </li><li>A queue supports multiple producers and consumers interacting with the same queue. </li><li>A single queue can be used <strong>simultaneously</strong> by many distributed application components, with no need for those components to coordinate with each other to share the queue. A queue delivers each message at least once.</li><li>In this way, a producer can put messages on the queue regardless if they are being read by the consumer or not. </li></ul></li></ul><h1 id="2-Developing-with-Amazon-Simple-Queue-Service-Amazon-SQS"><a href="#2-Developing-with-Amazon-Simple-Queue-Service-Amazon-SQS" class="headerlink" title="2. Developing with Amazon Simple Queue Service (Amazon SQS)"></a>2. Developing with Amazon Simple Queue Service (Amazon SQS)</h1><h2 id="2-1-Types"><a href="#2-1-Types" class="headerlink" title="2.1 Types"></a>2.1 Types</h2><ul><li>Standard queues<ul><li>message ordering is not guranteed</li><li>message may be duplicated </li><li>maximum throughput </li></ul></li><li>FIFO queue<ul><li>message ordering is preserved</li><li>message only receive once</li><li>limited throughput (300 transactions per second)</li></ul></li></ul><h2 id="2-2-Used-to-solve-tightly-linked-systems"><a href="#2-2-Used-to-solve-tightly-linked-systems" class="headerlink" title="2.2 Used to solve tightly linked systems"></a>2.2 Used to solve tightly linked systems</h2><ul><li>problem to be solved<ul><li>An example of image processing: the sequential operations of uploading, storing, and encoding the image, creating a thumbnail, and copyrighting are tightly linked to each other. This tight linkage complicates the recovery operations when there has been a failure.</li></ul></li><li>queuing chain pattern<ul><li>Achieve loose coupling of systems by using queues between systems and exchanging messages that transfer jobs</li><li>This enables asynchronous linking of systems.</li><li>lets you increase the number of virtual servers that receive and process the messages in parallel. </li><li>If there is no image to process, you can configure auto scaling to terminate the servers that are in excess.</li></ul></li></ul><h2 id="2-3-Operations"><a href="#2-3-Operations" class="headerlink" title="2.3 Operations"></a>2.3 Operations</h2><h3 id="2-3-1-Client"><a href="#2-3-1-Client" class="headerlink" title="2.3.1 Client"></a>2.3.1 Client</h3><ul><li><p>sendMessage </p><ul><li>send message to a specific queue</li><li>max size: 256 KB </li><li>parameters of a sendMessage operation<ul><li>QueueUrl: specify the url of the queue that the message should be sent to</li><li>MessageBody: specify the message to send </li><li>DelaySeconds: specify the number of seconds to delay a specific message. Messages will become available for processing after the delay time is finished. </li><li>MessageAttributes <ul><li>specify structured metadata about the message<ul><li>timestamp</li><li>signature</li><li>geospatial data</li></ul></li></ul></li></ul></li></ul></li><li><p>receiveMessage</p><ul><li>specify short polling or long polling </li><li>When requesting to get a message from the queue, <strong>you cannot specify which message to get</strong>. You simply specify the maximum number of messages you want to get (up to 10), and Amazon SQS returns up to that maximum number.</li><li>parameters <ul><li>WaitTimeSeconds</li><li>MaxNumberOfMessages</li><li>VisibilityTimeout<ul><li>period of time that a message is invisible to the rest of your application after an application component gets it from the queue.</li><li>prevents multiple components from processing the same message </li><li>during the visibility time, the component that received the message usually processes it and then delete it from the queue. </li><li>this prevents multiple components from processing the same message </li></ul></li></ul></li><li>polling types<ul><li>short polling<ul><li>Amazon SQS samples a subset of the servers (based on a weighted random distribution) and returns messages from only the sampled servers</li><li>if you keep retrieving from your queues, SQS samples all the servers, and you will eventually receive all of your messages. </li><li>occurs when the WaitTimeSeconds parameter of a ReceiveMessage call is set to 0 or the queue attribute ReceiveMessageWaitTimeSeconds is 0</li></ul></li><li>long polling<ul><li>better and preferred way to retrieve messages </li><li>if your application has a single thread polling multiple queues, switching from short polling to long polling will likely not work, because the single thread will wait for the long poll timeout on any empty queues, delaying the processing of any queues which may contain messages. </li><li>Amazon SQS long polling doesn’t return a response until a message arrives in the queue or the long poll times out </li><li>inexpensive </li><li>unless the connection time out, the response to the ReceiveMessage request will contain at least one of the available messages. </li><li>Reduce the cost of using Amazon SQS by reducing the number of empty responsed and false empty responses. </li></ul></li></ul></li></ul></li></ul><ul><li>deleteMessage<ul><li>When you receive the message, you <strong>must delete it from the queue</strong> to acknowledge that you processed the message and no longer need it. </li><li>You specify which message to delete by providing the <strong>receipt handle</strong> that Amazon SQS returned when you received the message.</li></ul></li><li>deleteMessageBatch</li><li>PuregeQueue<ul><li>delete all the messages in an AmazonSQS queue without deleting the queue itself.  </li></ul></li></ul><h3 id="2-3-2-Basic-Queue-Operations"><a href="#2-3-2-Basic-Queue-Operations" class="headerlink" title="2.3.2 Basic Queue Operations"></a>2.3.2 Basic Queue Operations</h3><ul><li>CreateQueue <ul><li>attributes<ul><li>delaySeconds<ul><li>the delivery of all messages in the queue will be delayed </li><li>default 0, maximum 15 min</li></ul></li><li>maximumMessageSize<ul><li>the limit of how many bytes a message can contain before Amazon SQS rejects it </li><li>max 256 KB</li></ul></li><li>messageRetentionPeriod<ul><li>seconds SQS retains a message </li></ul></li><li>ReceiveMessageWaitTimeSeconds<ul><li>time for which a ReceiveMessage call will wait for a message to arrive </li><li>max configurable wait time is 20 seconds </li><li>default 0</li></ul></li><li>VisibilityTimeout<ul><li>period of time that a message is invisbile to the rest of your application  </li></ul></li></ul></li></ul></li><li>SetQueueAttributes</li><li>GetQueueAttributes</li><li>GetQueueUrl</li><li>ListQueues</li><li>DeleteQueue</li></ul><h2 id="2-4-Message-Lifecycle"><a href="#2-4-Message-Lifecycle" class="headerlink" title="2.4 Message Lifecycle"></a>2.4 Message Lifecycle</h2><ul><li>Immediately after a message is received, it <strong>remains in the queue</strong>. To prevent other consumers from processing the message again, Amazon SQS sets a visibility timeout, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. </li><li>The default visibility timeout for a message is 30 seconds. The maximum is 12 hours.</li><li>Or consumer could send a separate request which acknowledges that you no longer need the message because you have successfully received and processed it </li><li>Maximum message retention period<ul><li>SQS automatically deletes messages that have been in a queue for more than maximum message retension period</li><li>default is 4 days </li><li>can be set from 60 seconds to 14 days </li></ul></li></ul><h2 id="2-5-Queue-and-Message-Identifiers"><a href="#2-5-Queue-and-Message-Identifiers" class="headerlink" title="2.5 Queue and Message Identifiers"></a>2.5 Queue and Message Identifiers</h2><ul><li>Queue URL <ul><li>when creating a new queue, must provide a queue name that is unique within the scope of all your queues. </li><li>AWS assgin each queue an identifier called a <strong>queue URL</strong>, which includes the queue name and other components that Amazon SQS determines. </li></ul></li><li>Message ID<ul><li>For each message, Amazon SQS returns a system-assigned message ID in the SendMessage response. </li></ul></li><li>Receipt Handle<ul><li>Each time you receive a message from a queue, you receive a receipt handle for that message. </li><li>The handle is assoiciated with the act of receiving the message, not with the message itself. </li><li>To delete a message, you need the message’s receipt handle instead of the message ID. </li></ul></li></ul><h2 id="2-6-Dead-letter-queues"><a href="#2-6-Dead-letter-queues" class="headerlink" title="2.6 Dead letter queues"></a>2.6 Dead letter queues</h2><ul><li>A queue of messages that were not able to be processed </li><li>Use dead-letter queues with standard queues.</li><li>Dead letter queues help you troubleshoot incorrect message transmission operations </li></ul><h2 id="2-7-Sharing-a-Queue"><a href="#2-7-Sharing-a-Queue" class="headerlink" title="2.7 Sharing a Queue"></a>2.7 Sharing a Queue</h2><ul><li>Shared queues<ul><li>Queue can be shared with other AWS accounts</li><li>Queue can be shared anonymously </li><li>A permission gives access to another person to use your queue in some particular way</li><li>A policy is the actual document that contains the permissions you granted </li></ul></li></ul><h2 id="2-8-Use-cases"><a href="#2-8-Use-cases" class="headerlink" title="2.8 Use cases"></a>2.8 Use cases</h2><ul><li>Work queues<ul><li>decouple components of a distributed application that may not all process the same amount of work simultaneourly </li></ul></li><li>Buffer and batch operations<ul><li>add scalability and reliability to your architecture and smooth out temporary volume spikes without losing messages or increasing latency </li></ul></li><li>request offloading<ul><li>move slow operations off of interactive request paths by enqueuing the request</li></ul></li><li>Auto scaling<ul><li>Use queue to help determine the load on an application, and when combined with auto sclaing, you can sclae the numebr of Amazon Ec3 intances out or in, depending on the volumne of traffic </li></ul></li><li>fan out<ul><li>combine SQS with SNS to send identical copies of a message to multiple queues in parallel for simultaneous processing  </li></ul></li></ul><h1 id="3-Amazon-Simple-Notification-Service"><a href="#3-Amazon-Simple-Notification-Service" class="headerlink" title="3. Amazon Simple Notification Service"></a>3. Amazon Simple Notification Service</h1><h2 id="3-1-Introduction"><a href="#3-1-Introduction" class="headerlink" title="3.1 Introduction"></a>3.1 Introduction</h2><ul><li>A web service that makes it easy to set up, operate and send notifications from the cloud.</li><li>Follow the publish-subscribe messaging paradigm, with notifications being delivered to clients using a push mechanism that eliminates the need to periodically check or poll for new information and updates </li><li>When using Amazon SNS, you (as the owner) create a <strong>topic</strong> and <strong>control access to it by defining policies</strong> that determine which publishers and subscribers can communicate with the topic. </li><li>A publisher sends messages to topics they have created or to topics they have permission to publish to. </li><li>Instead of including a specific destination address in each message, a publisher sends a message to the topic. </li><li>Amazon SNS matches the topic to a list of subscribers who have subscribed to that topic and delivers the message to each of those subscribers. </li><li>Each topic has a <strong>unique name</strong> that identifies the Amazon SNS endpoint for <strong>publishers to post messages and subscribers to register for notifications</strong>. Subscribers receive all messages published to the topics that they subscribe to, and all subscribers to a topic receive the same messages.</li><li>Subscriber<ul><li>Web servers </li><li>email addresses</li><li>amazon sqs queues</li><li>aws lambda</li></ul></li><li>topic <ul><li>an access point for allowing recipients to dynamically subscribe for identical copies of the same notification </li></ul></li></ul><h2 id="3-2-Use-case-Fan-out"><a href="#3-2-Use-case-Fan-out" class="headerlink" title="3.2 Use case: Fan out"></a>3.2 Use case: Fan out</h2><ul><li>An Amazon SNS message is sent to a topic and then replicated and pushed to multiple Amazon SQS queues, HTTP endpoints, or email addresses. </li><li>Allow for parallel asynchronous processing</li><li>All subscribers get identical information </li></ul><h2 id="3-3-Operations"><a href="#3-3-Operations" class="headerlink" title="3.3 Operations"></a>3.3 Operations</h2><ul><li>CreateTopic<ul><li>Input: Topic name </li><li>Output: ARN of topic </li><li>creates a topic to which notifications can be published </li><li>action is idempotent, so if the requester already owns a topic with the specified name, that topic’s ARN is returned without creating a new topic </li></ul></li><li>Subscribe<ul><li>Input<ul><li>subscriber’s endpoint</li><li>protocol </li><li>ARN of topic </li></ul></li><li>prepare to subscribe an endpoint by sending the endpoint a confirmation message</li><li>to actually create a subscription, the endpoint owner must call the confirmSubscription action with the token from the confirmation message. </li><li>The ConfirmSubscription request verify an endpoint owner’s intent to receive messages by validating the token sent to the endpoint by an earlier Subscribe action. </li><li>If the token is valid, the action creates a new subscription and returns its ARN </li></ul></li><li>DeleteTopic <ul><li>Input<ul><li>ARN of topic  </li></ul></li><li>Deleting a topic might prevent some messages previously sent to the topic being delivered to subscribers</li><li>Action is idempotent, will not result in an error if the topic doesn’t exist</li></ul></li><li>Publish <ul><li>Input <ul><li>Message</li><li>Messsage attributes</li><li>Message structure : json</li><li>subject </li><li>ARN of topic </li></ul></li><li>output <ul><li>message ID </li></ul></li><li>Sends a message to all of a topic’s subscribed endpoints.</li><li>When a messageId is returned, the message has been saved and Amazon SNS will attempt to deliver it to the topic’s subscribers shortly. </li><li>The format of the outgoing message to each subscribed endpoint depends on the notification protocol selected.</li></ul></li></ul><h2 id="3-4-Best-practices"><a href="#3-4-Best-practices" class="headerlink" title="3.4 Best practices"></a>3.4 Best practices</h2><h3 id="3-4-1-Characteristics-of-Amazon-SNS"><a href="#3-4-1-Characteristics-of-Amazon-SNS" class="headerlink" title="3.4.1 Characteristics of Amazon SNS"></a>3.4.1 Characteristics of Amazon SNS</h3><ul><li>Each notification message contains a single published message</li><li>Message order is not guaranteed</li><li>A message cannot be deleted after it has been published </li><li>Amazon SNS delivery policy can be used to control retries in case of message delivery failure</li><li>Message can contain up to 256 kb of text data</li></ul><h3 id="3-4-2-Manage-Access-to-Amazon-SNS"><a href="#3-4-2-Manage-Access-to-Amazon-SNS" class="headerlink" title="3.4.2 Manage Access to Amazon SNS"></a>3.4.2 Manage Access to Amazon SNS</h3><ul><li>which endpoints</li><li>who can publish notifications</li><li>who can subscribe to notifications</li></ul><h3 id="3-4-3-SQS-vs-SNS"><a href="#3-4-3-SQS-vs-SNS" class="headerlink" title="3.4.3 SQS vs SNS"></a>3.4.3 SQS vs SNS</h3><ul><li>both messaging services within AWS</li><li>SNS<ul><li>allow applications to send time-critical messages to multiple subscribers through a push mechanism</li><li>eliminate the need to periodically check or poll for updates </li></ul></li><li>SQS <ul><li>message queue service used by distributed applications to exchange messages through a polling model, and it can be used to decouple sending and receiving components. </li><li>provides flexibility for distributed components of applications to send and receive messages without requiring each component to be concurrently available</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> SQS </tag>
            
            <tag> SNS </tag>
            
            <tag> Notification Service </tag>
            
            <tag> Queue </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.7 API Gateway</title>
      <link href="/Developing-on-AWS-Note-7-API-Gateway/"/>
      <url>/Developing-on-AWS-Note-7-API-Gateway/</url>
      
        <content type="html"><![CDATA[<h1 id="1-What-is-Amazon-API-Gateway"><a href="#1-What-is-Amazon-API-Gateway" class="headerlink" title="1. What is Amazon API Gateway?"></a>1. What is Amazon API Gateway?</h1><h2 id="1-1-Functionalities"><a href="#1-1-Functionalities" class="headerlink" title="1.1 Functionalities"></a>1.1 Functionalities</h2><ul><li>enables developers to create, publish, maintain, monitor and secure APIs</li><li>allow you to connect your applications to AWS services and other public or private websites</li><li>provides consistent RESTFUL APIs for mobile and web applications to access AWS services and other resources hosted outside of AWS</li><li>Handles all the tasks involved in <strong>accepting and processing</strong> up to hundreds of thousands of concurrent API calls, including <strong>traffic management, authorization and access control, monitoring and API version management</strong></li></ul><h2 id="1-2-Use-cases"><a href="#1-2-Use-cases" class="headerlink" title="1.2 Use cases"></a>1.2 Use cases</h2><ul><li><p>Create a unified API frontend for multiple microservices</p></li><li><p>DDoS protection and throttling for backend </p></li><li><p>Authenticate and authorize requests to a backend</p></li><li><p>Throttle, meter, and monetize API usage by third party developers </p></li><li><p>message transformation and validation</p><ul><li><strong>models</strong> can be created to define a schema for reqeust/ response messages</li><li>A <strong>Mapping Template</strong> can then be used to transform data from one model to another</li><li>request/ response payload and header can be validated against the model</li><li>message transformation and mapping can be done using API Gateway</li><li>customers will often map request messages to a canonical format for downstream applications using API Gateway.  –&gt; <strong>transform a response body from the backend data format to the frontend data format</strong></li></ul></li><li><p>Expose backend resources</p><ul><li>allow you to create an API that acts as a front door for applications to access data, business logic or functionality from your backend service</li><li>expose<ul><li>HTTP endpoints</li><li>AWS services</li><li>AWS Lambda functions</li></ul></li></ul></li><li><p>Increase API performance : Cache</p><ul><li>eploy APIs to Regional or Edge-optimized endpoints to bring them closer to their clients. Cache API responses to the API Gateway response cache.</li><li>You can also enable API caching in Amazon API Gateway to cache your endpoint’s response. </li><li>With caching, you can reduce the number of calls made to your endpoint and also improve the latency of the requests to your API. When you enable caching for a stage, API Gateway caches responses from your endpoint for a specified time-to-live (TTL) period, in seconds. </li><li>API Gateway then responds to the request by looking up the endpoint response from the cache instead of making a request to your endpoint</li></ul></li><li><p>Control Access to APIs</p><ul><li>method level throttling </li><li>client usage throttling and quota limits sepcified in a usage plan </li><li>help prevent one customer from consuming all of your backend system’s capacity</li></ul></li><li><p>Secure API method invocations</p><ul><li>creating a resource policy <ul><li>a JSON policy document that you attach to an API to control whether a specified principal(IAM user or role) can invoke the API </li><li>You can use a resource policy to enable users from a different AWS account to securely access your API or to allow the API to be invoked only from specified source IP address ranges or Classless Inter-Domain Routing (CIDR) blocks.</li></ul></li><li>Creating IAM permission policy, can protect: <ul><li>the creation, deployment, and management of an API</li><li>the invocation of the methods in the API and refresh of its cache</li></ul></li><li>Creating a Private API endpoint that can only be accessed by a VPC client</li><li>Integrating with Amazon Cognito or Lambda authorizers to authenticate and authorize clients before accessing backend resources</li><li>Resource policy and IAM permission capabilities offer flexible and robust access controls that can be applied to an entire API set or individual methods. <h1 id="2-Best-practices"><a href="#2-Best-practices" class="headerlink" title="2. Best practices"></a>2. Best practices</h1></li></ul></li></ul><h2 id="2-1-Developing-an-API"><a href="#2-1-Developing-an-API" class="headerlink" title="2.1 Developing an API"></a>2.1 Developing an API</h2><ul><li>WHen API client requests come from the same region where the API is deployed, choose a regional API endpoint type</li><li>Test invking the API before deploying it</li><li>Use HTTP 500 error code for error handling </li><li>Cache only GET methods </li></ul><h1 id="3-Serverless-Application-Model-SAM"><a href="#3-Serverless-Application-Model-SAM" class="headerlink" title="3. Serverless Application Model (SAM)"></a>3. Serverless Application Model (SAM)</h1><p>Template driven development model for defining serverless apps</p><ul><li>supports <ul><li>Lambda</li><li>API Gateway</li><li>DynamoDB table</li><li>Any resource that AWS CloudFormation supports </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RESTFul </tag>
            
            <tag> AWS </tag>
            
            <tag> Gateway </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.6 AWS Serverless platform, Lambda</title>
      <link href="/Developing-on-AWS-Note-6-AWS-Serverless-platform-Lambda/"/>
      <url>/Developing-on-AWS-Note-6-AWS-Serverless-platform-Lambda/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Serverless-Computing"><a href="#1-Serverless-Computing" class="headerlink" title="1. Serverless Computing"></a>1. Serverless Computing</h1><h2 id="1-1-Benefits"><a href="#1-1-Benefits" class="headerlink" title="1.1 Benefits"></a>1.1 Benefits</h2><ul><li>with serverless deployment and operation, only need to<ul><li>build and deploy apps</li><li>monitor and maintain apps</li></ul></li><li>no need to provision, scale and manage any servers </li></ul><h2 id="1-2-Use-cases"><a href="#1-2-Use-cases" class="headerlink" title="1.2 Use cases"></a>1.2 Use cases</h2><ul><li>web applications <ul><li>automatically scale up and down </li><li>run in a highly available configuration across multiple data centers </li></ul></li><li>backends<ul><li>build serverless backends using AWS lambda to handle web, mobile, internet of Things(IoT), and 3rd party APR requests </li></ul></li><li>mobile backends</li><li>data processing <ul><li>execute code in response to triggers <ul><li>changes in data </li><li>shifts in system state</li><li>actions by users</li></ul></li></ul></li></ul><h1 id="2-AWS-serverless-Platform"><a href="#2-AWS-serverless-Platform" class="headerlink" title="2. AWS serverless Platform"></a>2. AWS serverless Platform</h1><ul><li>Compute<ul><li>AWS lambda</li><li>AWS Fargate</li></ul></li><li>API Proxy<ul><li>Amazon API Gateway</li><li>AWS AppSync</li></ul></li><li>Storage<ul><li>Amazon S3</li></ul></li><li>Database<ul><li>Amazon DynamoDB</li><li>Amazon Aurora</li></ul></li><li>Interprocess Messaging<ul><li>Amazon SNS</li><li>Amazon SQS</li></ul></li><li>Orchetration<ul><li>AWS Step Functions </li></ul></li><li>Analytics<ul><li>Amazon Kinesis</li><li>Amazon Athena</li></ul></li><li>Developer Tools<ul><li>Frameworks</li><li>SDKs</li><li>Libraries</li></ul></li></ul><p>Serverless applications don’t require provisioning, maintaining, and administering servers for backend components such as compute, databases, storage, stream processing, message queueing, and more. You also no longer need to worry about ensuring application fault tolerance and availability.</p><h1 id="3-AWS-Lambda"><a href="#3-AWS-Lambda" class="headerlink" title="3. AWS Lambda"></a>3. AWS Lambda</h1><h2 id="3-1-What-is-AWS-Lambda"><a href="#3-1-What-is-AWS-Lambda" class="headerlink" title="3.1 What is AWS Lambda?"></a>3.1 What is AWS Lambda?</h2><ul><li>Compute service that enables you to run code without provisioning or managing servers. </li><li>Pay only for the compute time you consume </li><li>Run code for virtually any type of application or backend service, all with zero administration. </li><li>can set up code to automatically trigger from other AWS services or call it directly from any web or mobile app</li></ul><h2 id="3-2-Concepts"><a href="#3-2-Concepts" class="headerlink" title="3.2 Concepts"></a>3.2 Concepts</h2><ul><li>Event source - what triggers the call<ul><li>Used to pass in event data to the handler </li><li>java/C# supports simple data types and stream input/ output</li><li>includes all of the data and metadata Lambda needs</li></ul></li><li>Context object<ul><li>provides handler runtime information </li><li>interact with Lambda execution environment </li><li>contain<ul><li>AWS requestId - Used to track specific invocations of a Lambda function</li><li>Remaining time - The amount of time in milliseconds that remain before your function timeout occurs</li><li>logging - Each language runtime provides the ability to stream log statements to Amazon CloudWatch Logs.</li></ul></li></ul></li><li>Language choice</li><li>Execution environment - permissions and resources</li><li>Runtime <ul><li>a program that runs a lambda function’s handler method when the function is invoked</li><li>can include a runtime in your function’s deployment package in the form of an executable file named bootstrap</li><li>responsible for running the function’s setup code</li><li>read the handler name</li><li>read invocation events from the runtime API</li><li>runtime passes the event data to the function handler, and posts response from the handler back to Lambda</li></ul></li><li>handler function<ul><li>When a Lambda function is invoked, code execution begins at what is called the handler. The handler is a specific code method (Java, C#) or function (Node.js, Python) that you’ve created and included in your package. </li></ul></li></ul><h2 id="3-3-Using-Lambda"><a href="#3-3-Using-Lambda" class="headerlink" title="3.3 Using Lambda"></a>3.3 Using Lambda</h2><ul><li>Bring own code <ul><li>bring own libraries</li><li>custom runtimes </li></ul></li><li>Simple resource model <ul><li>CPU and network allocated proportionately</li></ul></li><li>Flexible Use<ul><li>Synchronous/ Asynchronous</li><li>Integrated with other AWS services</li></ul></li><li>Flexible Authorization<ul><li>securely grant access to resources and VPCs </li><li>Fine grained control for invoking your functions </li></ul></li></ul><h2 id="3-4-How-it-works"><a href="#3-4-How-it-works" class="headerlink" title="3.4 How it works"></a>3.4 How it works</h2><p>Function can be invoked by</p><ul><li>push model<ul><li>event based invocation </li><li>event sources invoke your Lambda function </li><li>e.g<ul><li>S3, SNS, Cognito, Echo </li></ul></li></ul></li><li>request-response invocation <ul><li>causes Lambda to execute the function <strong>synchronously</strong> and returns the response immediately to the calling application. This invocation type is available for custom applications</li></ul></li><li>pull event model<ul><li>Lambda polls the event source and invokes function when it detects an event</li><li>E.G<ul><li>DynamoDB, SQS, Kinesis </li></ul></li></ul></li></ul><h2 id="3-5-Develop-and-deploy-workflow"><a href="#3-5-Develop-and-deploy-workflow" class="headerlink" title="3.5 Develop and deploy workflow"></a>3.5 Develop and deploy workflow</h2><ul><li>create a lambda handler class in code</li><li>create lambda function </li><li>allow Lambda to assume an IAM role</li><li>upload the code</li><li>invoke the AWS Lambda Function </li><li>Monitor function </li></ul><h2 id="3-6-Lambda-Layers"><a href="#3-6-Lambda-Layers" class="headerlink" title="3.6 Lambda Layers"></a>3.6 Lambda Layers</h2><ul><li><p>Centrally manage code and data that is shared across multiple functions</p><ul><li>reduce size of deployments</li><li>speed up deployment </li><li>Limits<ul><li>5 layers</li><li>250 MB</li></ul></li></ul></li><li><p>Layer</p><ul><li>ZIP archive that contain libraries, a custom runtime, or other dependencies</li><li>with layers, you can use libraries in your function without needing to include them in deployment package</li><li>extracted to the /opt directory in the function execution env </li><li>use AWS Serverless Application Model (AWS SAM) to manage layers and your function’s layer configuration</li></ul></li></ul><h2 id="3-7-Best-practices"><a href="#3-7-Best-practices" class="headerlink" title="3.7 Best practices"></a>3.7 Best practices</h2><ul><li>Function Code<ul><li>Separate the Lambda handler (entry point) from your core logic <ul><li>can make a more unit-testable function </li></ul></li><li>take advantage of Execution Context reuse<ul><li>make sure any externalized configuration or dependencies that your code retrieves are stored and referenced locally after initial execution</li><li>Limit the re-initialization of variables/objects on every invocation. Instead use static initialization/constructor, global/static variables and singletons. Keep alive and reuse connections (HTTP, database, etc.) that were established during a previous invocation.</li></ul></li><li>use environment variables</li><li>control the dependencies in your function’s deployment package</li><li>minimize the complexity of your dependencies <ul><li>Prefer simpler Java dependency injection frameworks like Dagger or Guice, over more complex ones like Spring Framework</li></ul></li><li>avoid using recursive code </li><li>share common dependencies with layers</li></ul></li><li>Function Configuration<ul><li>performance testing your Lambda function for memory<ul><li>crucial part in ensuring you pick the optimum memory size configuration</li><li>Any increase in memory size triggers an equivalent increase in CPU available to your function. </li><li>The memory usage for your function is determined per-invoke and can be viewed in AWS CloudWatch logs.</li></ul></li><li>Load test Lambda Function<ul><li>Determine an optimum timeout value</li><li>Important to analyze how long your function runs so that you can better determine any problems with a dependency service that may increase the concurrency of the function beyond what you expect</li><li>This is especially important when your Lambda function makes network calls to resources that may not handle Lambda’s scaling.</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Lambda </tag>
            
            <tag> Serverless </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.5 DynamoDB</title>
      <link href="/Developing-on-AWS-Note-5-DynamoDB/"/>
      <url>/Developing-on-AWS-Note-5-DynamoDB/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AWS-Database-Options"><a href="#1-AWS-Database-Options" class="headerlink" title="1. AWS Database Options"></a>1. AWS Database Options</h1><h2 id="1-1-SQL-vs-NoSQL-database"><a href="#1-1-SQL-vs-NoSQL-database" class="headerlink" title="1.1 SQL vs NoSQL database"></a>1.1 SQL vs NoSQL database</h2><table><thead><tr><th>Attr</th><th>SQL</th><th>NoSQL</th></tr></thead><tbody><tr><td>Data Storage</td><td>rows and columns</td><td>key-value, document, wide-column, graph</td></tr><tr><td>Schemas</td><td>fixed</td><td>dynamic</td></tr><tr><td>Querying</td><td>Using SQL</td><td>Focused on collection of documents</td></tr><tr><td>Scalability</td><td>Vertical</td><td>Horizontal</td></tr><tr><td>Transactions</td><td>Supported</td><td>Support varies</td></tr><tr><td>Consistency</td><td>Strong</td><td>Eventual and strong</td></tr></tbody></table><ul><li>Relational Database supports vertical scaling which means that a single server must be made more powerful </li><li>Relational Database support ACID transactions<ul><li>atomicity</li><li>consistency</li><li>isolation </li><li>durability</li></ul></li><li>Relational databases automatically support strong data consistency due to ACID properties of transactions.</li></ul><h2 id="1-2-AWS-database-Options"><a href="#1-2-AWS-database-Options" class="headerlink" title="1.2 AWS database Options"></a>1.2 AWS database Options</h2><table><thead><tr><th>Type</th><th>SQL</th><th>NoSQL</th></tr></thead><tbody><tr><td>Transactional Databses</td><td>Amazon RDS</td><td>Amazon DynamoDB</td></tr><tr><td>Data Analytics/ Relationshiups</td><td>Amazon Redshift</td><td>Amazon Neptune</td></tr><tr><td>In-memory Data Store and Cache</td><td></td><td>Amazon ElastiCache</td></tr></tbody></table><ul><li>Amazon Relational Database Service(RDS): provides relational database services in the cloud with support for the following db engines: <ul><li>AMazon Aurora</li><li>PostgreSQL</li><li>MySQL</li><li>MariaDB</li><li>Oracle</li><li>Microsoft SQL server </li></ul></li><li>Amazon Redshift: fast, fully managed data warehouse<ul><li>includes Redshift Spectrum, allowing you to directly run SQL queries against exabytes of unstructured data in Amazon S3. </li></ul></li><li>Amazon DynamoDB: NoSQL db that supports both document and key-value store models </li><li>Amazon Neptune: fully managed graph databse service<ul><li>fully manged graoh databse service </li><li>purpose-built, high-performance <strong>graph database engine</strong> optimized for storing billions of <strong>relationships</strong> and querying the graph with milliseconds latency.</li><li>A graph database is ideal when you need to create relationships between data and quickly query these relationships. </li><li>This type of requirement is challenging to satisfy using a relational database because you would need multiple tables with multiple foreign keys. </li><li>In addition, SQL queries to navigate this data would require nested queries and complex joins that could quickly become complex and inefficient as your data size grows over time. </li><li>Neptune uses graph structures such as nodes (data entities), edges (relationships), and properties to represent and store data. </li><li>The relationships are stored as first order citizens of the data model. </li><li>This allows data in nodes to be directly linked, dramatically improving the performance of queries that navigate relationships in the data.</li></ul></li><li>Amazon ElastiCache: <strong>in-memory data cache</strong> that supports a fully managed Redis or Memcached engine<ul><li>easier to deploy, operate, and scale an in-memory data store or cache in the cloud. </li><li>improve the performance of web applications by allowing you to retrieve information from fast, managed, in memory caches</li><li>provides <ul><li>redis</li><li>memcached</li></ul></li></ul></li></ul><h1 id="2-DynamoDB"><a href="#2-DynamoDB" class="headerlink" title="2. DynamoDB"></a>2. DynamoDB</h1><h2 id="2-1-Intro"><a href="#2-1-Intro" class="headerlink" title="2.1 Intro"></a>2.1 Intro</h2><p>Amazon DynamoDB is a fast and flexible non-relational database service for all applications that need consistent, <strong>single-digit millisecond latency</strong> at any scale. It is a fully managed cloud database and supports both document and key-value store models.</p><h2 id="2-2-Components"><a href="#2-2-Components" class="headerlink" title="2.2 Components"></a>2.2 Components</h2><ul><li>Table <ul><li>data is stored in tables </li><li>contain<ul><li>item with attributes </li></ul></li></ul></li><li>Partition<ul><li>ddb can divide a table’s items into multiple partitions based on the primary key value. </li><li>an allocation of storage for a table</li><li>backed by SSDs and automatically replicated across multiple Availability Zones within an AWS region</li><li>partition key (hashkey), ddb use this to do partition </li></ul></li><li>sort key (range key) A sort key can be defined to store all of the items with the same partition key value <strong>physically close together and order them by sort key value in the partition</strong>. It represents a one-to-many relationship based on the partition key and enables querying on the sort key attribute.</li><li>Primary key - uniquely identify an Item<ul><li>types<ul><li>partition primary key</li><li>partition and sort primary key</li></ul></li></ul></li><li>item (400 KB at most)<ul><li>collection of attributes </li><li>not cosntrained by a predefined schema</li><li>items in a table can have different types of attributes </li></ul></li><li>attribute<ul><li>name</li><li>data type<ul><li>scalar<ul><li>number, string, binary, boolean, null</li></ul></li><li>multi-valued types <ul><li>string set</li><li>number set</li><li>binary set</li></ul></li><li>Document types<ul><li>List</li><li>Map</li></ul></li></ul></li><li>value</li></ul></li><li>Read/ Write Consistency<ul><li>Read<ul><li>eventually consistent</li><li>strongly consistent: return most up-to-date data</li><li>transactional: provides ACID consistency</li></ul></li><li>write<ul><li>standard</li><li>transactional </li></ul></li></ul></li><li>Read/ write Throughput<ul><li>RCU: number of strongly consistent reads per second of items up to <strong>4KB</strong> in size </li><li>WCU: number of <strong>1KB</strong> writes per second</li></ul></li><li>Secondary Indexes<ul><li>allow you to query data based on non-primary key attributes</li><li>contain<ul><li>alternate key attributes</li><li>primary key attributes</li><li>optinal subset of other attributes from the base table </li></ul></li><li>type<ul><li>GSI<ul><li>queries on this index can span all the data in a table, across all partitions</li><li>can have different partition key and sort key from original table</li><li>key values do not to be unique</li><li>can be deleted </li><li>supports eventually consistent only </li><li>its own provisioned WCU and RCU</li><li>*<em>queries only return attributes that are projected into the index *</em></li></ul></li><li>LSI<ul><li>index is located on the same table partition</li><li>sort key can be any scalar attribute </li><li>cannot be deleted </li><li>support eventually consitent and strong consistent </li><li>use table’s read and write capacity units</li></ul></li></ul></li></ul></li><li>Streams<ul><li>Ordered flow of information about changes to a table </li><li>contains changes to items in a single table </li><li>When you make an update to a table, DynamoDB first <strong>persists the data durably</strong> to the table. </li><li>It then asynchronously updates the corresponding stream with information about the changes made. </li><li>The asynchronous update is made to the stream with <strong>sub-second latency</strong>. </li><li>The update to the stream does not affect the write throughput of the table</li><li><strong>stricly in the order</strong> </li><li>each change contains exactly one stream record, available for 24 hours</li><li>streams scale by splitting data across shards </li><li>shards in detail<ul><li>A shard is created per partition in your DynamoDB table. If a partition split is required due to too many items in the same partition, the shard gets split into children as well.</li><li>DynamoDB Streams captures a time-ordered sequence of item-level modifications in your DynamoDB table. This time-ordered sequence is preserved at a per shard level. In other words, the order within a shard is established based on the order in which items were created, updated or deleted. </li></ul></li><li>configuration<ul><li>StreamEnabled: specify whether a stream is enabled or disabled </li><li>StreamViewType: specify the information that will be written to the stream whenever data in the table is modified<ul><li>KEYS_ONLY: only the key attributes </li><li>NEW_IMAGE: entire item, as it appears after modified</li><li>OLD_IMAGE: entire item, as it appears before modified</li><li>NEW_AND_OLD_IMAGES: both the new and old images of the item</li></ul></li></ul></li><li>when a stream is created, DDB assigns an ARN(Amazon Resource Name) that can be used to retrieve information about a stream. </li></ul></li><li>Global table<ul><li>A collection of one or more DynamoDB tables, all ownd by a single AWS account, identified as replica tables </li><li>A replica table (or replica, for short) is a single DynamoDB table that functions as a part of a global table. Each replica stores the same set of data items.</li><li>data replication<ul><li>Any changes made to any item in any replica table will be replicated to all of the other replicas within the same global table. </li><li>propagate within seconds </li></ul></li><li>concurrent updates <ul><li>all replicas agree on the latest update, and converge toward a state in which they all have identical data</li></ul></li><li>Read Consistency <ul><li>An application can read and write data to any replica table. </li><li>If your application only uses eventually consistent reads, and only issues reads against one AWS region, then it will work without any modification. </li><li>However, if your application requires strongly consistent reads, then it must perform all of its strongly consistent reads and writes in the same region. DynamoDB does not support strongly consistent reads across AWS regions; </li><li>therefore, if you write to one region and read from another region, the read response might include stale data that doesn’t reflect the results of recently-completed writes in the other region. </li></ul></li></ul></li><li>Backup and Restore<ul><li>on-demand backup and restore capabilities </li><li>all backups in DDB work without consuming any provisioned throughput on the table </li><li>point-in-time recovery can restore the table to any point in time during last 35 days</li></ul></li></ul><h2 id="2-3-APIs-and-operations"><a href="#2-3-APIs-and-operations" class="headerlink" title="2.3 APIs and operations"></a>2.3 APIs and operations</h2><h3 id="2-3-1-Control-operations"><a href="#2-3-1-Control-operations" class="headerlink" title="2.3.1 Control operations"></a>2.3.1 Control operations</h3><p>Create and manage DynamoDB tables. Let you work with indexes, streams, and other objects that are dependent on tables. </p><h3 id="2-3-2-Data-operations"><a href="#2-3-2-Data-operations" class="headerlink" title="2.3.2 Data operations"></a>2.3.2 Data operations</h3><p>Perform CRUD actions on data in a table. Also let you read data from a secondary index. </p><ul><li>PutItem<ul><li>create a new item or replace an existing item </li></ul></li><li>GetItem<ul><li>reads an item from a table</li></ul></li><li>UpdateItem<ul><li>edit an existing item’s attributes, or adds a new item to the table</li><li>can perform a conditional update on an existing item </li><li>can only bring some attributes instead of all comparing with putItem</li></ul></li><li>deleteItem<ul><li>can delete an item in a table using its primary key  </li></ul></li></ul><h3 id="2-3-3-Stream-operations"><a href="#2-3-3-Stream-operations" class="headerlink" title="2.3.3 Stream operations"></a>2.3.3 Stream operations</h3><p>Enable or disable a stream on a table, and allow access to the data modification records contained in a stream. </p><h3 id="2-3-4-Object-persistence-Model"><a href="#2-3-4-Object-persistence-Model" class="headerlink" title="2.3.4 Object persistence Model"></a>2.3.4 Object persistence Model</h3><ul><li>Allow you to persist client-side objects in DynamoDB<ul><li>supports the mapping of objects to tables</li></ul></li><li>Provides higher-level programming interfaces to:<ul><li>connect to DynamoDB</li><li>perform CRUD operations</li><li>execute queries</li></ul></li></ul><h3 id="2-3-5-Batch-Operations"><a href="#2-3-5-Batch-Operations" class="headerlink" title="2.3.5 Batch Operations"></a>2.3.5 Batch Operations</h3><ul><li>BatchGetItem<ul><li>Read up to 16MB of data consisting of up to 100 items from multiple tables</li></ul></li><li>BatchWriteItem<ul><li>write up to 16MB of data consisting of up to 25 put or delete requests in multiple tables </li></ul></li><li>retry <ul><li>if one request in a batch fails, the entire operation does not fail</li><li>retry with failed keys and data returned </li></ul></li></ul><h3 id="2-3-6-Transactional-Operations"><a href="#2-3-6-Transactional-Operations" class="headerlink" title="2.3.6 Transactional Operations"></a>2.3.6 Transactional Operations</h3><ul><li>TransactWriteItems<ul><li>contains a write set </li><li>includes one or more PutItem, updateItem, and DeleteItem operations across</li></ul></li><li>TransactGetItems<ul><li>contains a read set </li><li>includes one or more getItem operations across multiple tables</li></ul></li></ul><h2 id="2-4-On-demand-mode"><a href="#2-4-On-demand-mode" class="headerlink" title="2.4 On-demand mode"></a>2.4 On-demand mode</h2><p>Amazon DynamoDB on-demand is a flexible billing option capable of serving thousands of requests per second without capacity planning. DynamoDB on-demand offers pay-per-request pricing for read and write requests so that you pay only for what you use. </p><h2 id="2-5-Query-and-Scan"><a href="#2-5-Query-and-Scan" class="headerlink" title="2.5 Query and Scan"></a>2.5 Query and Scan</h2><ul><li>Query <ul><li>reads from a table or secondary index only the items that match the primary key specified in the key condition expression.  </li><li>parameters<ul><li>tableName</li><li>KeyContditionExpression<ul><li>must specify partition key name and value</li></ul></li><li>ProjectExpression </li><li>ConsistentRead</li><li>FilterExpression<ul><li>a string that contains conditions that DDB applies after the query operation, but before the data is returned to you </li><li>all other records are discarded </li></ul></li></ul></li></ul></li><li>Scan <ul><li>reads all items from the table or index </li><li>parameters <ul><li>tableName</li><li>ProjectionExpression <ul><li>a string that identify one or more attributes to retrieve from the table </li></ul></li><li>consistentRead</li><li>filterExpression </li></ul></li></ul></li></ul><h2 id="2-6-Best-Practices"><a href="#2-6-Best-Practices" class="headerlink" title="2.6 Best Practices"></a>2.6 Best Practices</h2><ul><li>Uniform workloads</li><li>One-To-Many tables<ul><li>If your table has items that store a large number of values in an attribute of set type, such as string set or number set, consider removing the set attribute from the table and splitting it as separate items in another table.</li><li>If you frequently access large items in a table but do not use the large attribute values, consider storing frequently accessed smaller attributes in a separate table</li></ul></li><li>Optimistic Locking with Version Number <ul><li>Use optimistic locking with a version number to make sure that an item has not changed since the last time you read it. </li><li>Maintain a version number to check that the item has not been updated between the last read and update </li></ul></li></ul><h2 id="2-7-DynamoDB-Accelerator-DAX"><a href="#2-7-DynamoDB-Accelerator-DAX" class="headerlink" title="2.7 DynamoDB Accelerator (DAX)"></a>2.7 DynamoDB Accelerator (DAX)</h2><ul><li>deliver fast response times for accessing eventually consistent data </li><li>DAX is a DynamoDB compatible caching service that enables you to benefit from fast in memory performance for demanding applications. It addresses three core scenarios: <ul><li>reduce the response times of eventually consistent read workloads by an order of magnitude, from single-digit milliseconds to microsends</li><li>reduce operational and application complexity by providing a managed service that is API-compatible with Amazon DynamoDB</li><li>DAX provides increased throughput and potential operational cost savings by reducing the need to over-provision read capacity units</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> DynamoDB </tag>
            
            <tag> NoSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.4 Storage Options, S3 in detail</title>
      <link href="/Developing-on-AWS-Note-4-Storage-Options-S3-in-detail/"/>
      <url>/Developing-on-AWS-Note-4-Storage-Options-S3-in-detail/</url>
      
        <content type="html"><![CDATA[<h1 id="1-AWS-Storage-Options"><a href="#1-AWS-Storage-Options" class="headerlink" title="1. AWS Storage Options"></a>1. AWS Storage Options</h1><ul><li>Amazon S3<ul><li>Scalable, highly durable object storage in the cloud</li></ul></li><li>Amazon Glacier<ul><li>Low-cost, highly durable <strong>archive</strong> storage in the cloud</li></ul></li><li>Amazon EFS<ul><li>Scalable network file storage for Amazon EC2 instances</li><li>network file system that can grow to petabytes </li><li>allows massively parallel access from EC2 instances to your data within a region</li><li>designed to <strong>meet the performance needs of big data and analytics</strong></li></ul></li><li>Amazon EBS<ul><li>Network attached volumes that provide durable block-level storage for Amazon EC2 instances </li></ul></li><li>AWS storage gateway<ul><li>change to hybrid later </li><li>connects an on-premises software appliance with cloud-based storage to provide seamless and secure storage integration between an organization’s on-premises IT environment and the AWS storage infrastructure like Amazon S3, Amazon Glacier and EBS.</li></ul></li></ul><h1 id="2-Amazon-S3"><a href="#2-Amazon-S3" class="headerlink" title="2. Amazon S3"></a>2. Amazon S3</h1><p>Amazon Simple Storage Service provides develipers with <strong>high secure, durable, and scalable object storage</strong>. </p><h2 id="2-1-Use-cases"><a href="#2-1-Use-cases" class="headerlink" title="2.1 Use cases"></a>2.1 Use cases</h2><ul><li>storage solution <ul><li>content storage and distribution</li></ul></li><li>backup</li><li>archiving </li><li>big data analytics</li><li>static web site hosting</li><li>disaster recovery <ul><li>cross region replication(CRR) automatically replicates every S3 object to a destination bucket located in a different AWS Region. </li></ul></li></ul><h2 id="2-2-Components"><a href="#2-2-Components" class="headerlink" title="2.2 Components"></a>2.2 Components</h2><ul><li>bucket<ul><li>global unique</li><li>use only lower case letters, numbers and hyphens</li><li>associated with a region<ul><li>choose region by considering<ul><li>latency</li><li>cost</li><li>regulatory requirements </li></ul></li></ul></li></ul></li><li>Object<ul><li>S3 refers to files as objects </li><li>you can store any number of objects inside bucket</li><li>each object is <strong>identified by a unique key</strong></li><li>object metadata</li><li>version<ul><li>each object has a version ID if you enable this feature</li><li>Object locking supported on versioned buckets<ul><li>use object lock to prevent data from being changed, overwritten, or deleted </li></ul></li></ul></li><li>URLs for S3 Objects<ul><li>Path style URL<ul><li><code>http://&lt;region-specific endpoint&gt;/&lt;bucket name&gt;/&lt;object name&gt;</code></li></ul></li><li>virtual hosted-style URL<ul><li><code>http://&lt;bucket name&gt;.s3.amazonaws.com/&lt;object key&gt;</code> </li></ul></li></ul></li></ul></li><li>Key<ul><li>unique identifier for each object in an S3 bucket </li></ul></li><li>Object Url<ul><li>specify region, bucket name, object name(key)</li></ul></li></ul><h2 id="2-3-Operations"><a href="#2-3-Operations" class="headerlink" title="2.3 Operations"></a>2.3 Operations</h2><h3 id="2-3-1-put"><a href="#2-3-1-put" class="headerlink" title="2.3.1 put"></a>2.3.1 put</h3><ul><li>upload object</li><li>copy object <ul><li>create copies of an object </li><li>rename obejcts by creating a copy and deleting the original object </li><li>move objects across S3 locations </li><li>update object metadata </li></ul></li><li>limits<ul><li>5 GB at most in a single PUT operation </li><li>recommened: use multipart upload if size &gt; 100MB<ul><li>Multipart upload allows you to upload a single object as a set of parts. </li><li>You can upload each part separately. </li><li>If one of the parts fails to upload, you can retransmit that particular part without retransmitting the remaining parts. After all the parts of your object are uploaded to the server, you must send a complete multipart upload request that indicates that multipart upload has been completed. </li><li>Amazon S3 then assembles these parts and creates the complete object. </li><li>Amazon S3 retains all parts on the server until you complete or abort the upload.</li><li>You can upload parts in parallel to improve throughput, recover quickly from network issues, pause and resume object uploads </li></ul></li></ul></li></ul><h3 id="2-3-2-Get"><a href="#2-3-2-Get" class="headerlink" title="2.3.2 Get"></a>2.3.2 Get</h3><ul><li>retrieve a complete object in a single GET request </li><li>You can also retrieve an object in parts by specifying the range of bytes needed. This is useful in scenarios where network connectivity is poor or your application can or must process only subsets of object data.</li></ul><h3 id="2-3-3-Select"><a href="#2-3-3-Select" class="headerlink" title="2.3.3 Select"></a>2.3.3 Select</h3><ul><li>Select content from Object instead of retrieving Object </li><li>filter of content handled at S3 service level <ul><li>works by providing the ability to retrieve a subset of data from an object in Amazon S3 using simple SQL expressions </li><li>simply change API from get to select </li></ul></li></ul><h3 id="2-3-4-Delete"><a href="#2-3-4-Delete" class="headerlink" title="2.3.4 Delete"></a>2.3.4 Delete</h3><ul><li>can delete a single object or delete multiple objects in a single delete request <ul><li>versioning disabled <ul><li>can permanently delete an object by specifying the key that you want to delete</li></ul></li><li>versioning enabled <ul><li>can permanently delete an object by invoking a delete request with a key and version ID</li><li>must delete each individual version to completely remove an object </li></ul></li></ul></li></ul><h3 id="2-3-5-Listing-Keys"><a href="#2-3-5-Listing-Keys" class="headerlink" title="2.3.5 Listing Keys"></a>2.3.5 Listing Keys</h3><ul><li>There is no hierarchy of objects in S3 buckets. You can use prefixes in key names to group similar items. </li><li>You can use delimiters (any string such as / or _) in key names to organize your keys and create a logical hierarchy</li></ul><h2 id="2-4-Features"><a href="#2-4-Features" class="headerlink" title="2.4 Features"></a>2.4 Features</h2><h3 id="2-4-1-Pre-Signed-URLs"><a href="#2-4-1-Pre-Signed-URLs" class="headerlink" title="2.4.1 Pre-Signed URLs"></a>2.4.1 Pre-Signed URLs</h3><ul><li>Provide access to PUT/ GET objects without opening permissions to do anything else </li><li>Use permissions of the user who creates the URL</li><li>Provide security credentials, a bucket name, an object key, HTTP method and expiration date and time </li><li>onlu valid until expiration time </li></ul><h3 id="2-4-2-Date-Encryption"><a href="#2-4-2-Date-Encryption" class="headerlink" title="2.4.2 Date Encryption"></a>2.4.2 Date Encryption</h3><ul><li>Securing data in transit <ul><li>SSL-encrypted endpoints with HTTPS</li><li>client-side encryption - via SDKs</li><li>server-side encryption<ul><li>S3 encrypts your data at the object level  </li></ul></li></ul></li><li>Securing data at rest on server<ul><li>Amazon S3 managed keys (SSE-S3)</li><li>AWS KMS-managed keys (SSE-KMS)</li><li>Customer-provided keys (SSE-C)</li></ul></li></ul><h3 id="2-4-3-Corss-Origin-Resource-Sharing-CORS"><a href="#2-4-3-Corss-Origin-Resource-Sharing-CORS" class="headerlink" title="2.4.3 Corss Origin Resource Sharing (CORS)"></a>2.4.3 Corss Origin Resource Sharing (CORS)</h3><ul><li>defines a way for client web applications that are loaded in one domain to interact with resources in a different domain.</li></ul><h2 id="2-5-Best-practices"><a href="#2-5-Best-practices" class="headerlink" title="2.5 Best practices"></a>2.5 Best practices</h2><ul><li>Avoid unnecessary requests <ul><li>handle noSuchBucket errors instead of checking for existence of fixed buckets </li><li>set the object metadata before uploading an object </li><li>avoid using the copy operation to update metadata</li><li>cache bucket and key names if your application design allows it </li></ul></li><li>Network latency<ul><li>choose the bucket region closest to latency-sensitive customers </li><li>consider compressing data stored in Amazon S3 to reduce the size of data transferred and storage used</li><li>use a CDN to distribute content </li></ul></li><li>Data integrity<ul><li>ensure the data has not been corrupted in transit</li><li>check MD5 checksum of the object retrieved from the GET and PUT operation <ul><li>AWS SDK automatically specifies MD5 checksum in a PUT operation. Amazon S3 recalculates MD5 checksum and compares it with the specified value. </li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> S3 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.3  - CloudWatch, CloudTrail, server-design for fail</title>
      <link href="/Developing-on-AWS-Note-3-CloudWatch-CloudTrail-server-design-for-fail/"/>
      <url>/Developing-on-AWS-Note-3-CloudWatch-CloudTrail-server-design-for-fail/</url>
      
        <content type="html"><![CDATA[<h1 id="1-CloudWatch"><a href="#1-CloudWatch" class="headerlink" title="1. CloudWatch"></a>1. CloudWatch</h1><h2 id="Why-use-Amazon-CloudWatch"><a href="#Why-use-Amazon-CloudWatch" class="headerlink" title="Why use Amazon CloudWatch?"></a>Why use Amazon CloudWatch?</h2><p>Need it to: </p><ul><li>monitor CPU, memory, disk I/O, network  -&gt; metrics</li><li>react to application log events and availability -&gt; logs/ event</li><li>automatically scale ec2 instance fleet -&gt; logs/ event</li><li>view operational status and identify issues -&gt; alarms, dashboard </li></ul><p>Actually, we could use Amazon CloudWatch to gain <strong>system-wide visibility</strong> into <strong>resource utilization</strong>, <strong>application performance</strong>, and <strong>operational health</strong>. You can use these insights to react and keep your application running smoothly. Amazon CloudWatch monitors your AWS Cloud resources and your cloud-powered applications. It tracks the metrics so that you can visualize and review them. You can also set alarms that will fire when a metric goes beyond a limit that you specified. CloudWatch gives you visibility into resource utilization, application performance, and operational health.</p><h1 id="2-CloudTrail"><a href="#2-CloudTrail" class="headerlink" title="2. CloudTrail"></a>2. CloudTrail</h1><p>CloudTrail is integrated with several AWS services. </p><ul><li>EC2</li><li>VPC</li><li>S3</li><li>EBS</li><li>DDB</li><li>RDS</li><li>Redshift</li><li>CloudFormation </li><li>IAM</li><li>…etc. </li></ul><p>AWS CloudTrail is an AWS service that generates logs of calls to the AWS API. AWS CloudTrail can <strong>record all activity</strong> against the services it monitors. Here are questions that you can answer using CloudTrail logs: <strong>who, when, what, which, where</strong>? While the coverage is extensive, not all services are covered in CloudTrail logs. You can use the AWS API <strong>call history produced by CloudTrail to track changes to AWS resources</strong>, including creation, modification, and deletion of AWS resources such as Amazon EC2 instances, Amazon VPC security groups, and Amazon EBS volumes.</p><p>You can use the CloudTrail console to view the last 90 days of recorded API activity and events in an AWS region. You can also download a file with that info, or a subset of info based on the filter and time range you choose</p><h1 id="3-Best-practices-of-developing-cloud-apps"><a href="#3-Best-practices-of-developing-cloud-apps" class="headerlink" title="3. Best practices of developing cloud apps"></a>3. Best practices of developing cloud apps</h1><ul><li>consider designing applications that are <strong>loosely coupled</strong>. <ul><li>think of your application as a consumer and provider of services </li><li>design and develop app as <strong>granular components</strong> that can be delivered and scaled independently. </li></ul></li><li>Architect for resilience; <ul><li>Set up your servers to scale automatically based on the number of users concurrently visiting your application.</li><li>Autoscaling would enable your application to handle a surge in volumn during a sale or propmotion and go back to normal </li><li>set up a <strong>cluster of nodes</strong> such that when one node fails, another node automatically picks up all the traffic. </li><li>Consider setting up <strong>read replicas for your database</strong>. </li></ul></li><li>design for failure<ul><li>In case of service failure, your application may log the failure and retry at a later time.</li><li>If the service is slow to respond, your application could retry by using an exponential backoff algorithm: retry after increasing amounts of time between attempts.<ul><li>This approach attempts to <strong>reach the service without overwhelming it</strong> with repeated requests and potentially aggravating the latency issue. </li></ul></li></ul></li><li>log metrics and monitor performance </li><li>implement a strong DevOps model<ul><li>Operationalize the development and deployment process for your application</li><li>Develop a <strong>modular, automated, and continuous build</strong> process. </li><li>Ensure <strong>consistency</strong> in the development, staging, and production environments. Set up scripts or use robust tools to consistently configure your environments.</li></ul></li><li>implement security in every layer <ul><li>infrastructure</li><li>application</li><li>data at transit and at rest </li><li>user authentication and authorization</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> CloudWatch </tag>
            
            <tag> CloudTrail </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.2  - IAM</title>
      <link href="/Developing-on-AWS-Note-2-IAM/"/>
      <url>/Developing-on-AWS-Note-2-IAM/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Why-need-IAM"><a href="#1-Why-need-IAM" class="headerlink" title="1. Why need IAM?"></a>1. Why need IAM?</h1><p>IAM: AWS Identity and Access Management</p><ul><li><p>web service that helps you securely control access to AWS resources for your users. </p></li><li><p>You use IAM to control <strong>who</strong> can use your AWS resources (<strong>authentication</strong>) and <strong>what resources</strong> they can use and in what ways (<strong>authorization</strong>).</p></li><li><p>To set up your dev env to wrok with the AWS SDK. </p><ul><li>Need an AWS acount and AWS credentials </li><li>Use an IAM user to provide access credentials to <strong><em>increase the security of your AWS account</em></strong>. </li></ul></li><li><p>grant least privilege - <strong>grant only permissions required to perform a task</strong></p></li></ul><h1 id="2-Concepts"><a href="#2-Concepts" class="headerlink" title="2. Concepts"></a>2. Concepts</h1><p><img src="https://i.loli.net/2020/01/29/TbyX6r1jtKR2VuJ.png" alt="fig1.png"></p><ul><li>User<ul><li>we can set up a user account for every developer in organization </li><li>each user has credentials that they <strong>must</strong> use to access AWS services. </li></ul></li><li>groups </li><li>roles <ul><li>trusted entities </li><li>A role has policies granting access to specific services and operations </li><li>create role like developer, and associate it with each developer user account</li><li>developer role can be configured with policies that control which services and operations that role has access to </li><li>a role does not have standard long-term credentials(pwd or access keys) associated with it</li></ul></li><li>Policy<ul><li>contain permissions which specify which actions an entity can perform and on which resources </li><li>a JSON document that defines effect, actions, resources, and optional conditions for what API calls an entity can invoke </li><li>Type<ul><li>Managed policy<ul><li>standablon policies that you can attach to multiplke users, groups and roles </li><li>reusability </li><li>central change management </li><li>version</li><li>rollback </li></ul></li><li>Inline policy<ul><li>embedded in a principal entity like a user, group, or role. </li><li>you can use the same policy across multiple entities, but those entities are not sharing the policy </li></ul></li></ul></li></ul></li><li>Resources <ul><li>The user, role, group, and policy objects that are stored in IAM</li><li>you can add, edit, and remove resources from IAM</li></ul></li><li>Identities <ul><li>The IAM resource objects that are used to identify and group. These include users, groups, and roles.</li></ul></li><li>Entities<ul><li>The IAM resource objects that AWS uses for authentication</li><li>includes users and roles </li></ul></li><li>Principles<ul><li>a person or application that uses an entity to sign in and make requests </li></ul></li><li>Authentication<ul><li>As a principal, you must be authenticated (signed in to AWS) using an IAM entity to send a request to AWS.</li><li>Must provide your access key and secret key when accessing by CLI</li></ul></li><li>Authorization <ul><li>Must be authorized to complete request </li><li>AWS uses values from the request context to check for policies that apply to the request. </li></ul></li></ul><h1 id="3-Features"><a href="#3-Features" class="headerlink" title="3. Features"></a>3. Features</h1><ul><li>management<ul><li>user, role, federated users </li></ul></li><li>Shared access to your AWS account </li><li>Granular permissions <ul><li>grant different permissions to different people for different resources</li></ul></li><li>secire access tp AWS respirces for applications that run on Amazon EC2 </li><li>multi factor authentication </li><li>eventually consistent </li><li>identity based permissions<ul><li>attached to the IAM user and indicate what the user is permitted to do.</li><li>attached to a resource and indicate what a specified user (or group of users) is permitted to do with it. <strong>Amazon S3, Amazon Simple Queue Service (Amazon SQS), Amazon Simple Notification Service (Amazon SNS), and AWS OpsWorks are the only services that support resource-based permissions</strong>.</li></ul></li><li>resource based permissions</li><li>IAM Evaluation logic (In order)<ul><li>By default, all requests are denied. (In general, requests made using the account/root credentials for resources in the account are always allowed.)</li><li>An explicit allow overrides this default.</li><li>An explicit deny overrides any allows</li></ul></li></ul><h1 id="4-IAM-best-practice"><a href="#4-IAM-best-practice" class="headerlink" title="4. IAM best practice"></a>4. IAM best practice</h1><ul><li>IAM policies are specified with JSON-formatted text.</li><li>Policies are used to control access permissions for AWS APIs and other AWS resources. </li><li>They are not used for operating system permissions or application permissions. For those, use LDAP or Active Directory/Active Directory Federation Services (AD FS).</li><li>When you create IAM policies, follow the standard security advice of granting least privilege; <ul><li>i.e., grant only the permissions required to perform a task. </li><li>Determine what users need to do, and then craft policies for them that let the users perform only those tasks. </li><li>Similarly, create policies for individual resources that identify precisely who is allowed to access the resource, and allow only the minimal permissions for those users. </li></ul></li></ul><h1 id="5-Amazon-Shared-Responsibility-Model"><a href="#5-Amazon-Shared-Responsibility-Model" class="headerlink" title="5. Amazon Shared Responsibility Model"></a>5. Amazon Shared Responsibility Model</h1><p>Customer and AWS table the responsibility together: </p><ul><li>customer<ul><li>responsible for what you implement using AWS and for the applications you connect to AWS</li></ul></li><li>AWS<ul><li>goes from the ground up to the hypervisor. </li><li>secure the hardware, software, facilities, and networks that run all of our products and services. Customers are responsible for securely configuring the services they sign up for and anything they put on those services. </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Identity and Access Management </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Developing on AWS Note.1  - AWS Models, EC2, ELB, autoScaling</title>
      <link href="/Developing-on-AWS-Note-1-AWS-Models-EC2-ELB-autoScaling/"/>
      <url>/Developing-on-AWS-Note-1-AWS-Models-EC2-ELB-autoScaling/</url>
      
        <content type="html"><![CDATA[<h1 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h1><p>We use SDKs to interract with Application Programing Interface(API), and then connect to all AWS services. </p><h1 id="1-Cloud-computing-definition"><a href="#1-Cloud-computing-definition" class="headerlink" title="1.  Cloud computing definition"></a>1.  Cloud computing definition</h1><ul><li>enable you to stop thinking of your infrastructure as hardware, and instead think of it and use it as software. </li></ul><h1 id="2-Models-of-Cloud-Computing"><a href="#2-Models-of-Cloud-Computing" class="headerlink" title="2. Models of Cloud Computing"></a>2. Models of Cloud Computing</h1><ul><li><p>IaaS (Infrastructure as a Service)</p><ul><li>basic buiding blocks for Cloud IT <ul><li>Networking features </li><li>Computers </li><li>Data storage space </li></ul></li><li>PaaS (Platform as a Service)<ul><li>enables you to run applications without the need to manage underlying infrastructure(hardware and operating systems)</li></ul></li><li>SaaS (Software as a Service)<ul><li>A complete product that is run and managed by the service provider<h1 id="3-AWS-Service-Stack"><a href="#3-AWS-Service-Stack" class="headerlink" title="3. AWS Service Stack"></a>3. AWS Service Stack</h1></li></ul></li></ul></li><li><p>Infrastructure </p><ul><li>Regions </li><li>Availability Zones </li><li>Edge Locations </li></ul></li><li><p>Foundation Services </p><ul><li>Compute<ul><li>virtual instances </li><li>auto scaling </li><li>load balancing </li></ul></li><li>networking </li><li>storage <ul><li>object </li><li>block </li><li>archive </li></ul></li></ul></li><li><p>Platform Services </p><ul><li>Compute<ul><li>AWS Lambda</li><li>AWS Elastic Beanstalk </li><li>Amazon ECS</li><li>Amazon EKS </li></ul></li><li>database<ul><li>relational </li><li>No SQL </li><li>Caching </li><li>Products <ul><li>DynamoDB</li><li>RDS - relational database service </li><li>Elastic Cache </li><li>Redshift - data warehouse, for analysis and migration </li></ul></li></ul></li><li>Analytics <ul><li>Cluster computing </li><li>real time </li><li>data warehouse </li><li>data workflows </li><li>Products <ul><li>EMR - managed hadoop framework </li><li>Kinesis </li><li>CloudSearch </li><li>ElasticSearch </li></ul></li></ul></li><li>App services <ul><li>Queuing </li><li>Orchestration </li><li>App streaming </li><li>Transcoding </li><li>Email </li><li>Search </li><li>Products <ul><li>SQS </li><li>SNS </li><li>SES </li><li>Amazon Step Functions </li></ul></li></ul></li><li>Deployment and management <ul><li>containers </li><li>Dev/ ops tools </li><li>resource templates </li><li>usage tracking </li><li>monitoring and logs </li><li>products <ul><li>CodeCommit </li><li>CodeDeploy </li><li>CodePipeline </li><li>CodeBuild </li><li>X-Ray </li></ul></li></ul></li><li>Mobile Services <ul><li>identity </li><li>sync </li><li>mobile analytics </li><li>notifications </li><li>products <ul><li>Cognito </li><li>Pinpoint </li><li>API gateway </li></ul></li></ul></li></ul></li><li><p>Applications </p><ul><li>Virtual Desktops </li><li>Collaboration and Sharing </li></ul></li></ul><h1 id="4-Compute-services"><a href="#4-Compute-services" class="headerlink" title="4. Compute services"></a>4. Compute services</h1><h2 id="4-1-EC2"><a href="#4-1-EC2" class="headerlink" title="4.1 EC2"></a>4.1 EC2</h2><ul><li>Computers in the cloud. </li><li>Can create images of your servers at any time with a few clicks or simple API call. </li><li>different instance type for different use cases:<ul><li>low traffic websites </li><li>small database </li><li>high performance web services </li><li>high performance databases </li><li>distributed memory caches </li><li>data warehousing </li><li>log or data-processing applications </li><li>3D visualizations </li><li>Machine learning </li></ul></li><li>Pricing <ul><li>on demand </li><li>reserved instances </li><li>spot instances </li></ul></li></ul><h2 id="4-2-ELB-Elastic-Load-Balancing"><a href="#4-2-ELB-Elastic-Load-Balancing" class="headerlink" title="4.2 ELB - Elastic Load Balancing"></a>4.2 ELB - Elastic Load Balancing</h2><ul><li><p>distribute traffic across multiple EC2 instances, in multiple Availability Zones </p></li><li><p>Support health checks to detect unhealthy Amazon EC2 instances </p><ul><li>To discover the availability of instances, a ELB periodically sends pings, attempts connections or sends requests to test the EC2 instances.  </li></ul></li><li><p>Supports the routing and load balancing of traffic to Amazon EC2 instances. </p></li><li><p>when the LB determins that an instance is unhealthy, it stops routing requests to that instance. </p></li><li><p>sticky sessions</p><ul><li>enables the load balancer to bind a user’s session to a <strong>specific server instance</strong>. </li></ul></li><li><p>we should get rid of sticky sessions since: </p><ul><li>limit application’s scalability </li><li>lead to unequal load across servers </li><li>affect end-user response time since a single user’s load isn’t even spread across servers. </li></ul></li><li><p>Instead of using sticky sessions: cache </p><ul><li>manage user sessions by<ul><li>store locally to the node responding to the HTTP request </li><li>designate a layer which can store those sessions in a scalable and robust manner. </li></ul></li><li>Duration based session stickiness<ul><li>LB uses a special LB generated cookie to rack the application instance for each request. <strong>When the load balancer reveives a request, it first checks to see whether this cookie is present in the request</strong>.  If so, the reqeust is sent to the application instance specified in the cookie. If not, the LB chooses an application instance based on the existing load balancing algo. <strong>A cookie is inserted into the response for binding subsequent requests from the same user to that application instance</strong>. The stickiness policy configuration defines a cookie expiration, which establishes the duration of validity for each cookie. Cookie will be automatically updated after its duration expires. </li></ul></li><li>Application base session stickiness <ul><li>LB uses a <strong>special cookie</strong> to associate the session with the original server that handled the reqeust. But follows the lifetime of the application-generated cookie corresponding to the cookie name specified in the policy configuration. </li><li>The LB only inserts a new stickiness cookie if the application response includes a new application cookie. </li><li>The load balancer stickiness cookie does not update with each request. If the application cookie is explicitly removed or expires, the session stops being sticky until a new application cookie is issued.</li><li>Application often store session data in memory, but this approach does not scale well</li></ul></li></ul></li><li><p>Methods available to manage session data without sticky sessions include: </p><ul><li>using ElasticCache to store session data </li><li>using Amazon DynamoDB to store session data </li></ul></li></ul><h2 id="4-3-Auto-Scaling"><a href="#4-3-Auto-Scaling" class="headerlink" title="4.3 Auto Scaling"></a>4.3 Auto Scaling</h2><p>Auto Scaling helps you ensure that you have the correct number of EC2 instances available to handle the load for your application. Auto Scaling is particularly well-suited for applications that experience hourly, daily, or weekly variability in usage.</p><h1 id="5-Exceptions-and-Errors-handle"><a href="#5-Exceptions-and-Errors-handle" class="headerlink" title="5. Exceptions and Errors handle"></a>5. Exceptions and Errors handle</h1><ul><li>400 series: handle error in application </li><li>500 series: retry operations </li></ul><p>Java SDK throes the following unchecked(runtime) exceptions when error occur:</p><ul><li>AmazonServiceException<ul><li>indicates that the reqeust was correctly transmitted to the service, but for some reason, the service was not able to process it, and returned an error response instead. </li></ul></li><li>AmazonClientException <ul><li>indicates that a problem occured inside the hava client code <ul><li>try to send a request to AWS </li><li>try to parse a response from AWS </li></ul></li></ul></li><li>IllegalArgumentException <ul><li>throw if you pass an illegal argument when performing an operation on a service  </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Cloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> EC2 </tag>
            
            <tag> ELB </tag>
            
            <tag> AutoScaling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么要合并HTTP请求?</title>
      <link href="/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%90%88%E5%B9%B6HTTP%E8%AF%B7%E6%B1%82/"/>
      <url>/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%90%88%E5%B9%B6HTTP%E8%AF%B7%E6%B1%82/</url>
      
        <content type="html"><![CDATA[<p>思考路径：<br>为什么要实现batch call? -&gt; 减少网络中的传输损耗 -&gt; 如何减少的? -&gt; 通过合并HTTP请求 -&gt; 合并HTTP请求是如何减少网络损耗的？ </p><p>本文将解决这个问题。一起看看单个请求携载大量信息和多个请求携载小量信息对于整个时间的影响。</p><h1 id="1-Client发出请求"><a href="#1-Client发出请求" class="headerlink" title="1. Client发出请求"></a>1. Client发出请求</h1><h2 id="1-1-HTTP-1-1"><a href="#1-1-HTTP-1-1" class="headerlink" title="1.1 HTTP 1.1"></a>1.1 HTTP 1.1</h2><p>可以保持长连接，但是每个不同的请求之间，client要向server发一个请求头</p><p>请求无法并行执行的，在一个连接里面</p><p>假设如果不合并的话需要建立N个连接，那么合并就可以省去(N-1)*RTT的时间，RTT指网络延迟（在传输介质中传输所用的时间，即从报文开始进入网络到它开始离开网络之间的时间）。</p><h2 id="1-2-TCP丢包问题"><a href="#1-2-TCP丢包问题" class="headerlink" title="1.2 TCP丢包问题"></a>1.2 TCP丢包问题</h2><p>慢启动，拥塞控制窗口</p><p>TCP报文乱序到达，合并后的文件可以允许队首丢包以后在队中补上来，但是分开资源的时候，前一个资源未加载完成后面的资源是不能加载的，会有更严重的队首阻塞问题，丢包率会严重影响Keep alive情况下多个文件的传输速率。</p><h2 id="1-3-浏览器线程数限制"><a href="#1-3-浏览器线程数限制" class="headerlink" title="1.3 浏览器线程数限制"></a>1.3 浏览器线程数限制</h2><p>多为2-6个线程，会在每个连接上串行发送若干个请求。TCP连接太多，会给服务器造成很大的压力的。</p><h2 id="1-4-DNS缓存问题"><a href="#1-4-DNS缓存问题" class="headerlink" title="1.4 DNS缓存问题"></a>1.4 DNS缓存问题</h2><p> 每次请求都需要找DNS缓存，多个请求就需要查找多次，而且缓存有可能被无故清空</p><h1 id="2-服务器处理请求"><a href="#2-服务器处理请求" class="headerlink" title="2. 服务器处理请求"></a>2. 服务器处理请求</h1><p>每个请求需要使用一个连接，建立一个线程，分配一部分CPU, 对于CPU而言，是种负担，尤其是一般来说建立了连接以后，哪怕发回了请求，这个连接还会保持一段时间才会timeout。这种时候，维持连接是对服务器资源的一种巨大的浪费。</p><h1 id="3-HTTP-2-0"><a href="#3-HTTP-2-0" class="headerlink" title="3. HTTP 2.0"></a>3. HTTP 2.0</h1><p>上面描述的所有都是基于HTTP/1.1的一些特性，或者说弊端，有长连接但是无法并行处理请求，TCP的慢启动和拥塞控制，队首阻塞问题都给整个性能带来很多弊端，因此我们有了HTTP2.0来做针对性的改进。很有意思的东西，直接看图： </p><ul><li><p>HTTP/1.1 network的请求图<br><img src="https://i.loli.net/2020/01/29/JPaxGAR2lrnKh6b.png" alt="http1-waterfall.png"></p></li><li><p>HTTP/2 network的请求图<br><img src="https://i.loli.net/2020/01/29/C64pmQAVzZrtyus.png" alt="http2-waterfall.png"></p></li></ul><p>就是这么酷炫，HTTP/2多了很多特性来解决HTTP/1.1的很多问题</p><h2 id="3-1-Fully-multiplexed"><a href="#3-1-Fully-multiplexed" class="headerlink" title="3.1 Fully multiplexed"></a>3.1 Fully multiplexed</h2><p>解决了队首阻塞的问题。对于同一个TCP连接，现在可以发送多个请求，接收多个回应了！在HTTP/1.1里面，如果在一个连接里上一个请求发生了丢包，那么后面的所有请求都必须等第一个请求补上包，收到回应以后才能继续执行。而在HTTP/2里面，可以直接并行处理。</p><h2 id="3-2-Header-Compression"><a href="#3-2-Header-Compression" class="headerlink" title="3.2 Header Compression"></a>3.2 Header Compression</h2><p>所有的HTTP request和response都有header，但是header里很可能包含缓存信息，导致他的大小会迅速增大的。但是在一个连接里大部分请求的请求头其实携带的信息都很类似，所以HTTP/2使用了索引表，存储了第一次出现的请求的请求头，然后后面的类似的请求只需要携带这个索引的数字就好了。头部压缩平均减少了30%的头部大小，加快了整体的网络中传输的速度。</p><p>这两点是和本文关系最大的，有了这两点，实质上合并HTTP请求的好处在HTTP/2的协议下，已经基本上消失了。合并不合并请求，更多的是看业务上的需求，后端的一些配置。</p><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><p>It’s a trade-off. 其实最重要的是看你传输什么东西，因为合并HTTP请求实质上是减少了网络延时，但是如果你在服务器上处理的时间远远大于网络延时的时间的时候，那么合并HTTP请求并不会给你带来很多性能上的提升。而且大数据量的传输一定会降低浏览器的cache hit rate,对于缓存的利用率会降低很多。但是对于HTTP请求携带的数据量比较少的情况，合并请求带来的性能提升会是显而易见的。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.zhihu.com/question/34689035" target="_blank" rel="noopener">1. 网络延迟</a></p><p><a href="https://www.zhihu.com/question/34401250" target="_blank" rel="noopener">2.知乎:合并HTTP请求是否真的有意义？</a></p><p><a href="https://deliciousbrains.com/performance-best-practices-http2/" target="_blank" rel="noopener">3. HTTP/2 Intro</a></p><p><a href="https://www.tutorialdocs.com/article/merge-parallel-http-request.html" target="_blank" rel="noopener">4. Merge parallel htto requests</a></p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> HTTP </tag>
            
            <tag> Network </tag>
            
            <tag> Batch Processing </tag>
            
            <tag> Web Development </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java-Synchronized方法</title>
      <link href="/Java-Synchronized%E6%96%B9%E6%B3%95/"/>
      <url>/Java-Synchronized%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="1-synchronized-type"><a href="#1-synchronized-type" class="headerlink" title="1. synchronized type"></a>1. synchronized type</h1><ol><li>Synchronized methods</li><li>Synchronized statements </li></ol><h1 id="2-Synchronized-Methods"><a href="#2-Synchronized-Methods" class="headerlink" title="2. Synchronized Methods"></a>2. Synchronized Methods</h1><p>修饰实例方法，作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁。修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁。 </p><h2 id="2-1-不可插入"><a href="#2-1-不可插入" class="headerlink" title="2.1 不可插入"></a>2.1 不可插入</h2><p>It is not possible for two invocations of synchronized methods on the same object to interleave. When one thread is executing a synchronized method for an object, all other threads that invoke synchronized methods for the same object block (suspend execution) until the first thread is done with the object.</p><p>当一个方法是同步的时候，当前线程在执行时，其他线程都会停止运行，直到线程完成工作，下一个线程继续执行。</p><h2 id="2-2-自动传递状态"><a href="#2-2-自动传递状态" class="headerlink" title="2.2 自动传递状态"></a>2.2 自动传递状态</h2><p>when a synchronized method exits, it automatically establishes a happens-before relationship with any subsequent invocation of a synchronized method for the same object. This guarantees that changes to the state of the object are visible to all threads.</p><p>保证状态可见，上个线程对对象的操作结果会作为输入给下一个线程来使用。 </p><h1 id="3-Synchronized-Statements"><a href="#3-Synchronized-Statements" class="headerlink" title="3. Synchronized Statements"></a>3. Synchronized Statements</h1><p>修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。</p><p>Synchronized statements must specify the object that provides the intrinsic lock. </p><pre><code>public void addName(String name) {    synchronized(this) {        lastName = name;        nameCount++;    }    nameList.add(name);}</code></pre><p>这里lastname 和namecount都要改变，是同步的。但要注意在声明里不可以调用其他对象的方法。</p><h1 id="4-底层实现原理"><a href="#4-底层实现原理" class="headerlink" title="4. 底层实现原理"></a>4. 底层实现原理</h1><p>可以锁代码块，也可以锁方法。如果锁的是类的实例对象，那么就是锁这个。如果锁的是类对象，那么尽管new多个实例对象，他们仍然属于同一个类，依然会被锁住，即线程之间保证同步关系。</p><p><code>synchronized</code> 同步语句块的实现使用的是 <code>monitorenter</code> 和 <code>monitorexit</code> 指令，其中 <code>monitorenter</code> 指令指向同步代码块的开始位置，<code>monitorexit</code> 指令则指明同步代码块的结束位置。</p><p>当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权.当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。</p><p>最开始的Synchronized是调用OS的mutex lock，要完成context switch ，映射到原生操作系统里，从用户态转到内核态。现在从JVM层面做了大量的优化，减少了锁开销。</p><h1 id="5-synchronized-优化"><a href="#5-synchronized-优化" class="headerlink" title="5. synchronized 优化"></a>5. synchronized 优化</h1><p>synchronized是互斥的，我们需要找方法加快中间过程，比如传统的零售交钱排队，找零到扫码付费的转变。这里介绍轻量级锁，偏向锁。</p><h2 id="5-1-CAS操作"><a href="#5-1-CAS操作" class="headerlink" title="5.1 CAS操作"></a>5.1 CAS操作</h2><p>使用锁的时候，线程获取锁是一种悲观锁，即认为每一次执行临界区的代码都会产生冲突，所以当前线程获取锁的时候同时会堵塞其他线程获取锁。而CAS是一种乐观锁策略，<strong>假设所有线程访问共享资源的时候不会出现冲突</strong>。出现了冲突以后采取CAS(compare and swap) 策略，用来比较交换，看线程之间是否出现了冲突。</p><h3 id="5-1-1-操作过程"><a href="#5-1-1-操作过程" class="headerlink" title="5.1.1 操作过程"></a>5.1.1 操作过程</h3><p>CAS比较交换的过程可以通俗的理解为CAS(V,O,N)，包含三个值分别为：V 内存地址存放的实际值；O 预期的值（旧值）；N 更新的新值。当V和O相同时，也就是说旧值和内存中实际的值相同表明该值没有被其他线程更改过，即该旧值O就是目前来说最新的值了，自然而然可以将新值N赋值给V。反之，V和O不相同，表明该值已经被其他线程改过了则该旧值O不是最新版本的值了，所以不能将新值N赋给V，返回V即可。当多个线程使用CAS操作一个变量是，只有一个线程会成功，并成功更新，其余会失败。失败的线程会重新尝试，当然也可以选择挂起线程。</p><p>It compares the contents of a memory location with a given value and, only if they are the same, modifies the contents of that memory location to a new given value. This is done as a single atomic operation. The atomicity guarantees that the new value is calculated based on up-to-date information; if the value had been updated by another thread in the meantime, the write would fail.</p><p>非阻塞同步。</p><h3 id="5-1-2-存在的问题"><a href="#5-1-2-存在的问题" class="headerlink" title="5.1.2 存在的问题"></a>5.1.2 存在的问题</h3><ol><li>ABA问题</li></ol><p>发生了变化，但又变了回去。（加上序号来解决）</p><ol start="2"><li>自旋时间过长</li><li>只能保证一个共享变量的原子操作</li></ol><h2 id="5-2-对象头"><a href="#5-2-对象头" class="headerlink" title="5.2 对象头"></a>5.2 对象头</h2><p>对象的锁 -&gt;  对象的标记，存在java对象的对象头里面。存放有</p><ol><li>锁状态<ul><li>无锁状态</li><li>偏向锁状态</li><li>轻量级锁状态</li><li>重量级锁状态</li></ul></li><li>对象的hashcode</li><li>对象分代年龄</li><li>是否是偏向锁</li><li>锁标志位</li></ol><blockquote><p>Tips: 级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率。</p></blockquote><h2 id="5-3-偏向锁"><a href="#5-3-偏向锁" class="headerlink" title="5.3 偏向锁"></a>5.3 偏向锁</h2><p>大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。</p><p>当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程</p><p>偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。</p><h2 id="5-4-轻量级锁"><a href="#5-4-轻量级锁" class="headerlink" title="5.4 轻量级锁"></a>5.4 轻量级锁</h2><p>线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。</p><p>轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。</p><h2 id="5-5-比较"><a href="#5-5-比较" class="headerlink" title="5.5 比较"></a>5.5 比较</h2><p><img src="https://i.loli.net/2020/01/29/meDvzPd6g24ITU9.png" alt="锁比较.png"></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://en.wikipedia.org/wiki/Compare-and-swap" target="_blank" rel="noopener">1. Wiki: Compare and swap</a></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Concurrency </tag>
            
            <tag> Synchronized </tag>
            
            <tag> Lock </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Volatile关键字</title>
      <link href="/Volatile%E5%85%B3%E9%94%AE%E5%AD%97/"/>
      <url>/Volatile%E5%85%B3%E9%94%AE%E5%AD%97/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Synchronized-vs-volatile"><a href="#1-Synchronized-vs-volatile" class="headerlink" title="1. Synchronized vs volatile"></a>1. Synchronized vs volatile</h1><p>synchronized是阻塞式同步，在线程竞争激烈的情况下会升级为重量级锁。而volatile是java虚拟机提供的最轻量级的同步机制。而针对volatile修饰的变量给java虚拟机特殊的约定，线程对volatile变量的修改会立刻被其他线程所感知，即不会出现数据脏读的现象，从而保证数据的“可见性”。</p><p><strong>被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象。</strong></p><h1 id="2-实现原理"><a href="#2-实现原理" class="headerlink" title="2. 实现原理"></a>2. 实现原理</h1><p>生成汇编代码时会在Volatile修饰的共享变量进行写操作的时候多出lock前缀的指令：<strong>该指令会将当前处理器缓存行的数据写会系统内存；这个写回内存的操作会使得其他CPU里缓存了该内存地址的数据无效</strong></p><p>为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到<strong>内部缓存（L1，L2或其他</strong>）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现<strong>缓存一致性协</strong>议，<strong>每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。</strong>因此，经过分析我们可以得出如下结论：</p><ol><li>lock前缀的指令会引起处理器缓存写回内存</li><li>一个处理器的缓存回写到内存会导致其他处理器的缓存失效</li><li>当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获得当前最新值</li></ol><h1 id="3-volatile的happen-before关系"><a href="#3-volatile的happen-before关系" class="headerlink" title="3. volatile的happen before关系"></a>3. volatile的happen before关系</h1><p>写后读，线程A改本地内存的变量，同步到主内存，线程B的本地内存废弃，到主内存中拿到更新的数据。</p><h1 id="4-volatile的内存语义实现"><a href="#4-volatile的内存语义实现" class="headerlink" title="4. volatile的内存语义实现"></a>4. volatile的内存语义实现</h1><p>为了性能优化，JMM在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序，那如果想阻止重排序要怎么办了？答案是可以添加内存屏障。</p><p>内存屏障类型： </p><p><img src="https://i.loli.net/2020/01/29/kIQaATpeCf56nxs.png" alt="内存屏障.png"></p><p><img src="https://i.loli.net/2020/01/29/RKDH1XxFAJeQVjY.png" alt="重排序.png"></p><p>“NO”表示禁止重排序。为了实现volatile内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM采取了保守策略：</p><ol><li>在每个volatile写操作的前面插入一个StoreStore屏障；</li><li>在每个volatile写操作的后面插入一个StoreLoad屏障；</li><li>在每个volatile读操作的后面插入一个LoadLoad屏障；</li><li>在每个volatile读操作的后面插入一个LoadStore屏障。</li></ol><p><img src="https://i.loli.net/2020/01/29/8JCkKYZg2NfMzP5.png" alt="volatile内存屏障.png"><br><img src="https://i.loli.net/2020/01/29/uY9qUvorMLK5a1V.png" alt="volatile读插入内存屏障示意图.png"></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Concurrency </tag>
            
            <tag> BackEnd </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java并发图谱</title>
      <link href="/Java%E5%B9%B6%E5%8F%91%E5%9B%BE%E8%B0%B1/"/>
      <url>/Java%E5%B9%B6%E5%8F%91%E5%9B%BE%E8%B0%B1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>在网上看到的描述Java并发的非常棒的知识图谱，分享/标注一波。</p></blockquote><p>包含： </p><ol><li>并发理论</li><li>并发关键字</li><li>Lock体系</li><li>并发容器</li></ol><p><img src="https://i.loli.net/2020/01/29/neDuY6XEaA2FsV9.png" alt="java-concurrency.png"></p>]]></content>
      
      
      <categories>
          
          <category> BackEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Concurrency </tag>
            
            <tag> BackEnd </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浏览器输入url以后都发生了什么</title>
      <link href="/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E4%BB%A5%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/"/>
      <url>/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BE%93%E5%85%A5url%E4%BB%A5%E5%90%8E%E9%83%BD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88/</url>
      
        <content type="html"><![CDATA[<p>从输入一个网址开始，都调用了哪些服务，经历了哪些步骤，深度解析。以输入<a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a> 为例。</p><h1 id="1-Client端"><a href="#1-Client端" class="headerlink" title="1. Client端"></a>1. Client端</h1><p>一般来说，这里的Client指用户，即browser浏览器。这里我们以输入google.com为例。</p><h2 id="1-1-输入提示"><a href="#1-1-输入提示" class="headerlink" title="1.1 输入提示"></a>1.1 输入提示</h2><p>浏览器会根据历史访问，书签等信息给出输入建议。</p><p>还会根据默认搜索引擎的搜索记录，去匹配最近的搜索记录。</p><h2 id="1-2-url解析"><a href="#1-2-url解析" class="headerlink" title="1.2 url解析"></a>1.2 url解析</h2><p>如果是不合法的地址，会转给默认的搜索引擎,例如如果你正在使用chrome，可以在url输入框输入你想要搜索的内容，然后搜索引擎会根据关键字进行搜索。</p><p>HSTS列表 安全策略机制，强行使用https</p><h2 id="1-3-DNS解析"><a href="#1-3-DNS解析" class="headerlink" title="1.3 DNS解析"></a>1.3 DNS解析</h2><p>域名通过DNS转化为ip地址，这个转化主要是为了人机交互的友好型。没有人喜欢记一堆数字来访问一个网站。DNS做的事情就是把你输入的<a href="http://www.google.com翻译成计算机可以理解的IP地址，类似于192.188.1.1这种样子。" target="_blank" rel="noopener">www.google.com翻译成计算机可以理解的IP地址，类似于192.188.1.1这种样子。</a></p><h3 id="1-3-1查询过程"><a href="#1-3-1查询过程" class="headerlink" title="1.3.1查询过程"></a>1.3.1查询过程</h3><p>在解析的过程中，浏览器会由近及远寻找是否有缓存信息，即存没存从域名到地址的映射，整个查询过程分为如下几步，值得注意的是一旦查询到，就会立刻返回，不会再继续执行下去了。</p><ol><li>查看浏览器内部缓存</li></ol><p>浏览器内会会存有在一段时间内你曾经访问过的网站的域名地址的映射。</p><ol start="2"><li>系统缓存</li></ol><p>操作系统的缓存。浏览器会发出system call， 去询问操作系统是否存有相应的映射。</p><ol start="3"><li>路由器缓存， ISP缓存</li></ol><p>查询路由器的缓存。如果在路由器缓存中没有找到映射，就会去ISP(Internet Service Provider)处去寻找</p><ol start="4"><li><p>本地DNS服务器</p></li><li><p>域名服务器  根域服务器  -&gt; 顶级域名服务器</p></li></ol><p>寻找方式类似于一个树状结构，从最底层的子叶开始向上遍历，不停向更高级的域名服务器发出请求。这个过程会不停发送携带有请求和IP地址的数据包，会经过在client和server之间的多个网路设备直到其到达正确的DNS服务器。</p><h1 id="2-网络"><a href="#2-网络" class="headerlink" title="2 网络"></a>2 网络</h1><p>找到了正确的IP地址以后就要开始建立连接了，建立连接的过程一般会使用TCP协议，通过三次握手建立连接。</p><h2 id="2-1-TCP连接"><a href="#2-1-TCP连接" class="headerlink" title="2.1 TCP连接"></a>2.1 TCP连接</h2><p>会用TCP，建立连接。并在Client和Server之间传递数据包。</p><h3 id="2-1-1-IP封装-socket"><a href="#2-1-1-IP封装-socket" class="headerlink" title="2.1.1 IP封装  socket"></a>2.1.1 IP封装  socket</h3><h3 id="2-1-2-TCP-三次握手"><a href="#2-1-2-TCP-三次握手" class="headerlink" title="2.1.2 TCP 三次握手"></a>2.1.2 TCP 三次握手</h3><ol><li>Client 发出建立连接的请求。数据包携带有<code>SYN</code>。</li><li>如果Server有开放的端口，可以接受并建立连接，那么server会返回<code>SYN</code> + <code>ACK</code>, 告诉Client我可以接受你的请求。</li><li>Client收到Server的回应，发送<code>ACK</code>给Server。 连接建立。</li></ol><p>给一个知乎连接，<a href="https://www.zhihu.com/question/24853633" target="_blank" rel="noopener">为什么是三次握手，不是两次或者四次？</a>  非常有意思的例子。</p><h3 id="2-1-3-TCP-四次挥手"><a href="#2-1-3-TCP-四次挥手" class="headerlink" title="2.1.3 TCP 四次挥手"></a>2.1.3 TCP 四次挥手</h3><ol><li>Client发起中断请求，发送<code>FIN</code>到server</li><li>Server收到请求，可能数据还没有发完。这个时候不会关闭socket，而是回复<code>ACK</code>，告诉Client知道了</li><li>Client进入<code>Fin_Wait</code>状态，继续等待Server端的<code>FIN</code>报文。Server端发送完毕后，会向Client发送<code>FIN</code></li><li>Client收到后就回复<code>ACK</code>，并关闭连接</li></ol><h1 id="3-Server"><a href="#3-Server" class="headerlink" title="3 Server"></a>3 Server</h1><p>这里主要描述TCP连接建立和断开之间发生的一些事情。</p><p>TCP/IP是个协议组，是网络层和传输层的协议。Client首先建立一条与服务器的TCP连接（上文中的三次握手）。而后Client发送HTTP请求，这里为了获得页面，会发送一个GET请求给服务器。请求会包含浏览器ID，用户数据头，连接头（包含额外信息，比如是否需要保持TCP连接等），从cookie获取的数据等。</p><p>Server收到Client的Request，会将请求传递给Request Handler，去处理请求（从数据库查找数据，处理数据，构建Response）。构建完毕后会返回一个Response。值得注意的是这个Response里会含有状态信息： </p><ul><li>1xx informational message only  —— 包含信息</li><li>2xx success of some kind  ——成功信息</li><li>3xx redirects the client to another URL  ——将Client转到其他URL</li><li>4xx indicates an error on the client’s part  ——Client端错误 </li><li>5xx indicates an error on the server’s part  ——Server端错误</li></ul><h1 id="4-页面渲染"><a href="#4-页面渲染" class="headerlink" title="4 页面渲染"></a>4 页面渲染</h1><p>浏览器根据Resonse返回数据，渲染出DOM树，将返回的数据呈现在页面上。</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://github.com/sunyongjian/blog/issues/34" target="_blank" rel="noopener">https://github.com/sunyongjian/blog/issues/34</a></p>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> Browser </tag>
            
            <tag> CDN </tag>
            
            <tag> network </tag>
            
            <tag> TCP/ IP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>React初探</title>
      <link href="/React%E5%88%9D%E6%8E%A2/"/>
      <url>/React%E5%88%9D%E6%8E%A2/</url>
      
        <content type="html"><![CDATA[<p>初探React,很喜欢Component这种方式，很大程度提高了复用性，如果抛除C/S的区别，感觉有点像mason，毕竟刚刚弃掉mason的坑，很有意思的React。</p><h1 id="1-Hello-World"><a href="#1-Hello-World" class="headerlink" title="1. Hello World"></a>1. Hello World</h1><p>React.Component   A component takes in parameters, called props and returns a hierarchy of views to display via the render method. </p><p>To collect data from multiple children, or to have two child components communicate with each other, you need to declare the shared state in their parent component instead. <strong>The parent component can pass the state back down to the children by using props; this keeps the child components in sync with each other and with the parent component.</strong> </p><pre><code>ReactDOM.render(    &lt;h1&gt;Hello, world!&lt;/h1&gt;,    document.getElementById(&#39;root&#39;));</code></pre><h1 id="2-JSX"><a href="#2-JSX" class="headerlink" title="2. JSX"></a>2. JSX</h1><p>jsx, 一种JavaScript的语法扩展。用来声明React当中的元素。可以任意在<strong>大括号{}</strong>里面使用<strong>JS表达式</strong>.</p><h2 id="2-1-JS表达式"><a href="#2-1-JS表达式" class="headerlink" title="2.1 JS表达式"></a>2.1 JS表达式</h2><blockquote><p>Any valid unit of code that resolves to a value. </p></blockquote><h3 id="2-1-1-分类"><a href="#2-1-1-分类" class="headerlink" title="2.1.1 分类"></a>2.1.1 分类</h3><ul><li><p>Arithmetic</p></li><li><p>String </p></li><li><p>Logical</p></li><li><p>Primary Expressions</p></li></ul><p>Basic keywords and general expressions in JS.</p><ol><li><p>this: refer to the current object.</p></li><li><p>grouping operator() : controls the precedence of evaluation in expressions. </p></li><li><p>new: to create an instance of a user-defined object type </p></li><li><p>super: call functions on an object’s parent.</p></li><li><p>spread operator: allow an expression to be expanded in places where multiple arguments or multiple elements are expected. </p><pre><code>  function f(x, y, z) { } var args = [0, 1, 2]; f(...args);</code></pre></li></ol><ul><li>Left hand side expressions</li></ul><h2 id="2-2-JSX-属性"><a href="#2-2-JSX-属性" class="headerlink" title="2.2 JSX 属性"></a>2.2 JSX 属性</h2><p>编译之后，会被转化为普通的JS对象。这意味着可以在if 或者for语句里使用JSX，将其赋值给变量，当做参数传入或者作为返回值都可以。</p><pre><code>// 使用引号定义以字符串为值得属性const element = &lt;div tabIndex=&quot;0&quot;&gt;&lt;/div&gt;;// 使用大括号来定义以js表达式为值得属性const element = &lt;img src={user.avatarUrl}&gt;&lt;/img&gt;;</code></pre><p>JSX代表Objects, Babel转译器会把JSX转换成一个名为React.createEliment()的方法来调用</p><h2 id="2-3-嵌套与防注入攻击"><a href="#2-3-嵌套与防注入攻击" class="headerlink" title="2.3 嵌套与防注入攻击"></a>2.3 嵌套与防注入攻击</h2><pre><code>const element = (  &lt;div&gt;    &lt;h1&gt;Hello!&lt;/h1&gt;    &lt;h2&gt;Good to see you here.&lt;/h2&gt;  &lt;/div&gt;);React DOM在渲染之前会过滤所有传入的值，可以确保应用不会被注入攻击，因为所有内容渲染之前都已经被转化为了字符串，有效防止XSS。 </code></pre><h1 id="3-元素渲染"><a href="#3-元素渲染" class="headerlink" title="3. 元素渲染"></a>3. 元素渲染</h1><p>React中的元素实际上是普通的对象，React DOM可以确保浏览器DOM的数据内容与React元素保持一致。<br>寻找React 根节点，渲染在根节点上</p><pre><code>const element = &lt;h1&gt;Hello, world&lt;/h1&gt;;ReactDOM.render(element, document.getElementById(&#39;root&#39;));</code></pre><h2 id="3-1-更新元素渲染"><a href="#3-1-更新元素渲染" class="headerlink" title="3.1 更新元素渲染"></a>3.1 更新元素渲染</h2><p>React 元素都是immutable的，更新界面的方式就是创建一个新的元素，然后将其传入<code>ReactDOM.render()</code> </p><p>React DOM 会比较元素的内容的先后的不同，而在渲染过程中只会更新改变了的部分。</p><h1 id="4-组件-amp-props"><a href="#4-组件-amp-props" class="headerlink" title="4. 组件 &amp; props"></a>4. 组件 &amp; props</h1><p>组件将UI切分成一些独立的，可复用的部件，这样就可以专注于构建每一个单独的部件。概念上像<strong>函数</strong>一样，可以接受任意的输入值(props)，并返回一个在页面上展示的React元素。</p><h2 id="4-1-函数定义组件"><a href="#4-1-函数定义组件" class="headerlink" title="4.1 函数定义组件"></a>4.1 函数定义组件</h2><pre><code>function Welcome(props) {    return &lt;h1&gt;Hello, {props.name}&lt;/h1&gt;;}</code></pre><h2 id="4-2-ES6-class-定义组件"><a href="#4-2-ES6-class-定义组件" class="headerlink" title="4.2 ES6 class 定义组件"></a>4.2 ES6 class 定义组件</h2><pre><code>class Welcome extends React.Component {    render() {        return &lt;h1&gt;Hello, {this.props.name}&lt;/h1&gt;    }}</code></pre><h2 id="4-3-组件渲染"><a href="#4-3-组件渲染" class="headerlink" title="4.3 组件渲染"></a>4.3 组件渲染</h2><pre><code>// React 元素可以使用户自定义的组件const element = &lt;Welcome name=&quot;Sara&quot; /&gt;;</code></pre><p><strong>当React遇到的元素是用户自定义的组件，它会将JSX属性作为单个对象传递给该组件，这个对象被称为”props”</strong></p><blockquote><p>组件名称必须大写</p></blockquote><h2 id="4-4-组合组件"><a href="#4-4-组合组件" class="headerlink" title="4.4 组合组件"></a>4.4 组合组件</h2><p>组件可以在它的输出中引用其他组件，这样我们就可以用同一组件来抽象出任意层次的细节。</p><blockquote><p>一个新的React应用程序的顶部是一个App组件。但是，如果要将React集成到现有应用程序中，则可以从下而上使用像Button这样的小组件作为开始，并逐渐运用到视图层的顶部。</p></blockquote><blockquote><p>组件的返回值只能有一个根元素。这也是我们要用一个<div>来包裹所有<Welcome />元素的原因。</p></blockquote><h2 id="4-5-提取组件"><a href="#4-5-提取组件" class="headerlink" title="4.5 提取组件"></a>4.5 提取组件</h2><p>分割组件，</p><h2 id="4-6-Props的只读性"><a href="#4-6-Props的只读性" class="headerlink" title="4.6 Props的只读性"></a>4.6 Props的只读性</h2><p>所有的React组件必须像纯函数那样使用它们的props</p><h1 id="5-State-amp-生命周期"><a href="#5-State-amp-生命周期" class="headerlink" title="5. State &amp; 生命周期"></a>5. State &amp; 生命周期</h1><p>更新UI的方法： <code>ReactDOM.render()</code></p><p>还可以通过更新状态来更新UI，<strong>状态是私有的，完全受控于当前组件</strong></p><h2 id="5-1-将函数转换为类"><a href="#5-1-将函数转换为类" class="headerlink" title="5.1 将函数转换为类"></a>5.1 将函数转换为类</h2><p>定义为类的组件有状态这个特性，还有生命周期钩子。</p><p>函数转换为类的步骤： </p><ol><li>创建一个名称扩展为<code>React.Component</code>的类</li><li>创建一个<code>render()</code>空方法</li><li>将函数体移动到render()方法中</li><li>在render()方法中，使用this.props替换props</li><li>删除剩余的空函数声明</li></ol><h2 id="5-2-为类添加局部状态"><a href="#5-2-为类添加局部状态" class="headerlink" title="5.2 为类添加局部状态"></a>5.2 为类添加局部状态</h2><pre><code>Class Clock extends React.Component {    constructor(props) {        super(props);        this.state = {date: new Date()};    }    render() {        return (            &lt;div&gt;                &lt;h1&gt;Hello, world!&lt;/h1&gt;                &lt;h2&gt;It is {this.state.date.toLocaleTimeString()}.&lt;/h2&gt;            &lt;/div&gt;        );    }}ReactDOM.render(    &lt;Clock/&gt;    document.getElementById(&#39;root&#39;));</code></pre><h2 id="5-3-添加生命周期方法到类中"><a href="#5-3-添加生命周期方法到类中" class="headerlink" title="5.3 添加生命周期方法到类中"></a>5.3 添加生命周期方法到类中</h2><p>当组件第一次加载到DOM中时，生成定时器，挂载</p><pre><code>componentDidMount() {}</code></pre><p>当Clock生成的这个DOM被移除时，清除定时器，卸载</p><pre><code>componentWillUnmount() {}</code></pre><p>一个完整的Clock的例子： </p><pre><code>class Clock extends React.Component {    constructor(props) {        super(props);        this.state = {date: new Date()};    }    // 3. Called when Clock&#39;s output is injected into DOM     componentDidMount() {        this.timerID = setInterval(            () =&gt; this.tick(),                1000        );    }    componentWillUnmount() {        clearInterval(this.timerID);    }    // 4. when setState() is being called, render() is called     tick() {        this.setState({            date: new Date()        });    }    // 2. Call render(), react know what need to be shown on screen. Update DOM     render() {        return (          &lt;div&gt;            &lt;h1&gt;Hello, world!&lt;/h1&gt;            &lt;h2&gt;It is {this.state.date.toLocaleTimeString()}.&lt;/h2&gt;          &lt;/div&gt;        );    }}ReactDOM.render(// 1. call Clock&#39;s constructor  &lt;Clock /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><h2 id="5-4-如何使用状态"><a href="#5-4-如何使用状态" class="headerlink" title="5.4 如何使用状态"></a>5.4 如何使用状态</h2><ol><li><p>不要直接更新状态</p><p> use: this.setState({comment: ‘hi’});</p></li></ol><blockquote><p>构造函数是唯一能够初始化this.state的地方</p></blockquote><ol start="2"><li>状态更新可能是异步的</li></ol><p>React可以将多个<code>setState()</code>调用合并成一个来提高性能</p><pre><code>// Wrongthis.setState({  counter: this.state.counter + this.props.increment,});// Correctthis.setState((prevState, props) =&gt; ({  counter: prevState.counter + props.increment}));// Correctthis.setState(function(prevState, props) {  return {    counter: prevState.counter + props.increment  };});</code></pre><ol start="3"><li>当调用<code>setState()</code>的时候，React会将你提供的对象合并到当前状态。可以只提供state的一部分。</li></ol><h2 id="5-5-数据流动方向：-自顶向下"><a href="#5-5-数据流动方向：-自顶向下" class="headerlink" title="5.5 数据流动方向： 自顶向下"></a>5.5 数据流动方向： 自顶向下</h2><p>父组件或子组件都不知道某个组件是否有状态，组件可以选择将其状态作为属性传递给其子组件。</p><h1 id="6-事件处理"><a href="#6-事件处理" class="headerlink" title="6. 事件处理"></a>6. 事件处理</h1><p>React事件绑定属性的命名采用驼峰式写法</p><p>采用jsx的语法你需要传入一个函数作为事件处理函数，而不是一个字符串。</p><pre><code>&lt;button onClick={activateLasers}&gt;    Activate Lasers&lt;/button&gt;</code></pre><h2 id="6-1-Toggle"><a href="#6-1-Toggle" class="headerlink" title="6.1 Toggle"></a>6.1 Toggle</h2><pre><code>class Toggle extends React.Component {    constructor(props) {    super(props);    this.state = {isToggleOn: true};    // This binding is necessary to make `this` work in the callback    this.handleClick = this.handleClick.bind(this);    }    handleClick() {        this.setState(prevState =&gt; ({            isToggleOn: !prevState.isToggleOn        }));    }    render() {        return (        // &lt;button onClick={(e) =&gt; this.handleClick(e)}&gt;         // 问题L每次渲染的时候都会创建一个不同的回调函数            &lt;button onClick={this.handleClick}&gt;                {this.state.isToggleOn ? &#39;ON&#39; : &#39;OFF&#39;}            &lt;/button&gt;        );    }}ReactDOM.render(    &lt;Toggle /&gt;,    document.getElementById(&#39;root&#39;));</code></pre><p>必须谨慎对待JSX回调函数中的this，类的方法默认不会绑定this的。如果你忘记绑定 <code>this.handleClick</code> 并把它传入 <code>onClick</code>, 当你调用这个函数的时候 <code>this</code> 的值会是 <code>undefined</code>。</p><h2 id="6-2-Todolist"><a href="#6-2-Todolist" class="headerlink" title="6.2 Todolist"></a>6.2 Todolist</h2><pre><code>class TodoApp extends React.Component {    constructor(props) {        super(props);        this.state = { items: [], text: &#39;&#39; };        this.handleChange = this.handleChange.bind(this);        this.handleSubmit = this.handleSubmit.bind(this);    }    render() {        return (            &lt;div&gt;                &lt;h3&gt;TODO&lt;/h3&gt;                &lt;TodoList items={this.state.items} /&gt;                &lt;form onSubmit={this.handleSubmit}&gt;                  &lt;input                    onChange={this.handleChange}                    value={this.state.text}                  /&gt;                  &lt;button&gt;                    Add #{this.state.items.length + 1}                  &lt;/button&gt;                &lt;/form&gt;            &lt;/div&gt;        );    }    handleChange(e) {        this.setState({ text: e.target.value });    }    handleSubmit(e) {        e.preventDefault();        if (!this.state.text.length) {            return;        }        const newItem = {            text: this.state.text,            id: Date.now()        };        this.setState(prevState =&gt; ({            items: prevState.items.concat(newItem),            text: &#39;&#39;        }));    }}class TodoList extends React.Component {    render() {        return (            &lt;ul&gt;                {this.props.items.map(item =&gt; (                  &lt;li key={item.id}&gt;{item.text}&lt;/li&gt;                ))}            &lt;/ul&gt;        );    }}ReactDOM.render(&lt;TodoApp /&gt;, mountNode);</code></pre><h2 id="6-3-向事件处理程序传递参数"><a href="#6-3-向事件处理程序传递参数" class="headerlink" title="6.3 向事件处理程序传递参数"></a>6.3 向事件处理程序传递参数</h2><pre><code>&lt;button onClick={(e) =&gt; this.deleteRow(id, e)}&gt;Delete Row&lt;/button&gt;&lt;button onClick={this.deleteRow.bind(this, id)}&gt;Delete Row&lt;/button&gt;</code></pre><p>参数 e 作为 React 事件对象将会被作为第二个参数进行传递。通过箭头函数的方式，事件对象必须显式的进行传递，但是通过 bind 的方式，事件对象以及更多的参数将会被隐式的进行传递。</p><h2 id="6-4-bind-向监听函数传参，-事件对象e需要放在最后"><a href="#6-4-bind-向监听函数传参，-事件对象e需要放在最后" class="headerlink" title="6.4 bind 向监听函数传参， 事件对象e需要放在最后"></a>6.4 bind 向监听函数传参， 事件对象e需要放在最后</h2><pre><code>class Popper extends React.Component{    constructor(){        super();        this.state = {name:&#39;Hello world!&#39;};    }    preventPop(name, e){    //事件对象e要放在最后        e.preventDefault();        alert(name);    }    render(){        return (            &lt;div&gt;                &lt;p&gt;hello&lt;/p&gt;                {/* Pass params via bind() method. */}                &lt;a href=&quot;https://reactjs.org&quot; onClick={this.preventPop.bind(this,this.state.name)}&gt;Click&lt;/a&gt;            &lt;/div&gt;        );    }}</code></pre><h1 id="7-条件渲染"><a href="#7-条件渲染" class="headerlink" title="7. 条件渲染"></a>7. 条件渲染</h1><p>可以创建不同的组件来封装各种你需要的行为。然后根据应用的状态变化只渲染其中的一部分。(if)</p><pre><code>function Greeting(props) {    const isLoggedIn = props.isLoggedIn;    if (isLoggedIn) {        return &lt;UserGreeting /&gt;;    }    return &lt;GuestGreeting /&gt;;}ReactDOM.render(  // Try changing to isLoggedIn={true}:  &lt;Greeting isLoggedIn={false} /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><h2 id="7-1-与运算符-amp-amp"><a href="#7-1-与运算符-amp-amp" class="headerlink" title="7.1 与运算符 &amp;&amp;"></a>7.1 与运算符 &amp;&amp;</h2><pre><code>function Mailbox(props) {    const unreadMessages = props.unreadMessages;    return (        &lt;div&gt;          &lt;h1&gt;Hello!&lt;/h1&gt;          {unreadMessages.length &gt; 0 &amp;&amp;            &lt;h2&gt;              You have {unreadMessages.length} unread messages.            &lt;/h2&gt;          }        &lt;/div&gt;    );}const messages = [&#39;React&#39;, &#39;Re: React&#39;, &#39;Re:Re: React&#39;];ReactDOM.render(  &lt;Mailbox unreadMessages={messages} /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><p><strong>在 JavaScript 中，true &amp;&amp; expression 总是返回 expression，而 false &amp;&amp; expression 总是返回 false。</strong></p><h2 id="7-2-阻止组件渲染"><a href="#7-2-阻止组件渲染" class="headerlink" title="7.2 阻止组件渲染"></a>7.2 阻止组件渲染</h2><pre><code>function WarningBanner(props) {    if (!props.warn) {        return null;    }    return (        &lt;div className=&quot;warning&quot;&gt;            Warning!        &lt;/div&gt;    );}class Page extends React.Component {    constructor(props) {        super(props);        this.state = {showWarning: true}        this.handleToggleClick = this.handleToggleClick.bind(this);    }    handleToggleClick() {        this.setState(prevState =&gt; ({            showWarning: !prevState.showWarning        }));    }    render() {        return (            &lt;div&gt;                &lt;WarningBanner warn={this.state.showWarning} /&gt;                &lt;button onClick={this.handleToggleClick}&gt;                {this.state.showWarning ? &#39;Hide&#39; : &#39;Show&#39;}                &lt;/button&gt;            &lt;/div&gt;        );    }}ReactDOM.render(  &lt;Page /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><h1 id="8-列表-amp-Keys"><a href="#8-列表-amp-Keys" class="headerlink" title="8. 列表 &amp; Keys"></a>8. 列表 &amp; Keys</h1><h2 id="8-1-渲染多个组件"><a href="#8-1-渲染多个组件" class="headerlink" title="8.1 渲染多个组件"></a>8.1 渲染多个组件</h2><pre><code>const numbers = [1, 2, 3, 4, 5];const listItems = numbers.map(    (number) =&gt; &lt;li&gt;{number}&lt;/li&gt;);ReactDOM.render(    &lt;ul&gt;{listItems}&lt;/ul&gt;    documnet.getElementById(&#39;root&#39;));</code></pre><h2 id="8-2-基础列表组件"><a href="#8-2-基础列表组件" class="headerlink" title="8.2 基础列表组件"></a>8.2 基础列表组件</h2><pre><code>function NumberList(props) {    const numbers = props.numbers;    const listItems = numbers.map((number) =&gt;        &lt;li key={number.toString()}&gt;            {number}        &lt;/li&gt;    );    return (        &lt;ul&gt;{listItems}&lt;/ul&gt;    );}const numbers = [1, 2, 3, 4, 5];ReactDOM.render(  &lt;NumberList numbers={numbers} /&gt;,  document.getElementById(&#39;root&#39;));</code></pre><h2 id="8-3-Keys"><a href="#8-3-Keys" class="headerlink" title="8.3 Keys"></a>8.3 Keys</h2><p>Keys可以在DOM中的某些元素被增加或删除的时候帮助React识别哪些元素发生了变化。最好是该元素在列表中拥有的独一无二的字符串。使用来自数据的id作为元素的key</p><p>元素的key只有在它和它的兄弟节点对比时才有意义。</p><h1 id="9-表单"><a href="#9-表单" class="headerlink" title="9.表单"></a>9.表单</h1><p>HTML 表单元素与React中其他DOM元素有所不同，因为表单元素本来就保留一些内部状态了。会构造一个处理提交表单并可访问用户输入表单数据的函数。标准方法是使用受控组件。</p><h2 id="9-1-受控组件"><a href="#9-1-受控组件" class="headerlink" title="9.1 受控组件"></a>9.1 受控组件</h2><p>在HTML当中，像<code>&lt;input&gt;,&lt;textarea&gt;, 和 &lt;select&gt;</code>这类表单元素会维持自身状态，并根据用户输入进行更新。但在React中，可变的状态通常保存在组件的状态属性中，并且只能用 setState() 方法进行更新。</p><pre><code>class NameForm extends React.Component {    constructor(props) {        super(props);        this.state = {value: &#39;&#39;};        this.handleChange = this.handleChange.bind(this);        this.handleSubmit = this.handleSubmit.bind(this);    }    handleChange(event) {        this.setState({value: event.target.value});    }    handleSubmit(event) {        alert(&#39;A name was submitted: &#39; + this.state.value);        event.preventDefault();    }    render() {        return (            &lt;form onSubmit={this.handleSubmit}&gt;                &lt;label&gt;                  Name:                  &lt;input type=&quot;text&quot; value={this.state.value} onChange={this.handleChange} /&gt;                &lt;/label&gt;                &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;            &lt;/form&gt;        );    }}</code></pre><h2 id="9-2-textarea标签"><a href="#9-2-textarea标签" class="headerlink" title="9.2 textarea标签"></a>9.2 textarea标签</h2><pre><code>class EssayForm extends React.Component {    constructor(props) {        super(props);        this.state = {          value: &#39;Please write an essay about your favorite DOM element.&#39;        };        this.handleChange = this.handleChange.bind(this);        this.handleSubmit = this.handleSubmit.bind(this);    }    handleChange(event) {        this.setState({value: event.target.value});    }    handleSubmit(event) {        alert(&#39;An essay was submitted: &#39; + this.state.value);        event.preventDefault();    }    render() {        return (            &lt;form onSubmit={this.handleSubmit}&gt;                &lt;label&gt;                Name:                &lt;textarea value={this.state.value} onChange={this.handleChange} /&gt;                &lt;/label&gt;                &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;            &lt;/form&gt;        );    }}</code></pre><h2 id="9-3-select标签"><a href="#9-3-select标签" class="headerlink" title="9.3 select标签"></a>9.3 select标签</h2><p>React中，不适用selected属性表明选中项，而是在根select标签上用value属性来表示选中项。这在受控组件中更方便，因为只需要在一个地方更新组件。</p><pre><code>class FlavorForm extends React.Component {    constructor(props) {    super(props);    this.state = {value: &#39;coconut&#39;};    this.handleChange = this.handleChange.bind(this);    this.handleSubmit = this.handleSubmit.bind(this);}handleChange(event) {    this.setState({value: event.target.value});}handleSubmit(event) {    alert(&#39;Your favorite flavor is: &#39; + this.state.value);    event.preventDefault();}    render() {        return (            &lt;form onSubmit={this.handleSubmit}&gt;                &lt;label&gt;                    Pick your favorite La Croix flavor:                    &lt;select value={this.state.value} onChange={this.handleChange}&gt;                    &lt;option value=&quot;grapefruit&quot;&gt;Grapefruit&lt;/option&gt;                    &lt;option value=&quot;lime&quot;&gt;Lime&lt;/option&gt;                    &lt;option value=&quot;coconut&quot;&gt;Coconut&lt;/option&gt;                    &lt;option value=&quot;mango&quot;&gt;Mango&lt;/option&gt;                    &lt;/select&gt;                &lt;/label&gt;                &lt;input type=&quot;submit&quot; value=&quot;Submit&quot; /&gt;            &lt;/form&gt;        );    }}</code></pre><h2 id="9-4-多个输入的解决方法"><a href="#9-4-多个输入的解决方法" class="headerlink" title="9.4 多个输入的解决方法"></a>9.4 多个输入的解决方法</h2><p>通过给每个元素添加一个name属性，来让处理函数根据event.target.name的值来选择做什么</p><pre><code>class Reservation extends React.Component {    constructor(props) {        super(props);        this.state = {            isGoing: true,            numberOfGuests: 2        };        this.handleInputChange = this.handleInputChange.bind(this);    }    handleInputChange(event) {        const target = event.target;        const value = target.type === &#39;checkbox&#39; ? target.checked : target.value;        const name = target.name;        this.setState({            [name]: value        });    }    render() {        return (            &lt;form&gt;                &lt;label&gt;                    Is going:                    &lt;input                        name=&quot;isGoing&quot;                        type=&quot;checkbox&quot;                        checked={this.state.isGoing}                        onChange={this.handleInputChange} /&gt;                &lt;/label&gt;                &lt;br /&gt;                &lt;label&gt;                    Number of guests:                    &lt;input                        name=&quot;numberOfGuests&quot;                        type=&quot;number&quot;                        value={this.state.numberOfGuests}                        onChange={this.handleInputChange} /&gt;                &lt;/label&gt;            &lt;/form&gt;        );    }}</code></pre><h1 id="10-状态提升"><a href="#10-状态提升" class="headerlink" title="10. 状态提升"></a>10. 状态提升</h1><h2 id="10-1-摄氏度华氏度的例子"><a href="#10-1-摄氏度华氏度的例子" class="headerlink" title="10.1 摄氏度华氏度的例子"></a>10.1 摄氏度华氏度的例子</h2><p>状态分享是通过将state数据提升至离需要这些数据的组件最近的父组件来完成的</p><pre><code>class Calculator extends React.Component {    constructor(props) {        super(props);        this.handleCelsiusChange = this.handleCelsiusChange.bind(this);        this.handleFahrenheitChange = this.handleFahrenheitChange.bind(this);        this.state = {temperature: &#39;&#39;, scale: &#39;c&#39;};    }    handleCelsiusChange(temperature) {        this.setState({scale: &#39;c&#39;, temperature});    }    handleFahrenheitChange(temperature) {        this.setState({scale: &#39;f&#39;, temperature});    }    render() {        const scale = this.state.scale;        const temperature = this.state.temperature;        const celsius = scale === &#39;f&#39; ? tryConvert(temperature, toCelsius) : temperature;        const fahrenheit = scale === &#39;c&#39; ? tryConvert(temperature, toFahrenheit) : temperature;        return (          &lt;div&gt;            &lt;TemperatureInput              scale=&quot;c&quot;              temperature={celsius}              onTemperatureChange={this.handleCelsiusChange} /&gt;            &lt;TemperatureInput              scale=&quot;f&quot;              temperature={fahrenheit}              onTemperatureChange={this.handleFahrenheitChange} /&gt;            &lt;BoilingVerdict              celsius={parseFloat(celsius)} /&gt;          &lt;/div&gt;        );    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> FrontEnd </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FrontEnd </tag>
            
            <tag> React </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二战时间线</title>
      <link href="/%E4%BA%8C%E6%88%98%E6%97%B6%E9%97%B4%E7%BA%BF/"/>
      <url>/%E4%BA%8C%E6%88%98%E6%97%B6%E9%97%B4%E7%BA%BF/</url>
      
        <content type="html"><![CDATA[<!--toc--><blockquote><p>对二战很感兴趣，依旧在不断了解中。未了解前完全没想到在不到80年前，我们这个世界因为战争在短短十多年间死去了7000万人。中间有太多的泯灭人性，亦有很多人性的光辉。不知道列宁格勒，如今的圣彼得堡的居民，在两年半的被围城中是如何活下来的，每个人，都真的是挺直了腰背，这一刻，尊严比命重要。有太多的细节可以探寻，也有很多微妙的节点，好多次盟军的胜利是因为一些不期而遇的变化，小人物的选择，天气的突然放晴。每每读到这种时候，心里总会长舒一口气，庆幸啊。（PS: 有部美剧，就特地开了脑洞，讲二战轴心国胜利以后的世界的样子… 一个真的敢拍，一个真的敢播，hhh ）Anyway，铭记历史~ </p></blockquote><h1 id="时间线（欧洲战场-and-太平洋战场）"><a href="#时间线（欧洲战场-and-太平洋战场）" class="headerlink" title="时间线（欧洲战场 and 太平洋战场）"></a>时间线（欧洲战场 and 太平洋战场）</h1><p>二战整个过程，德国东征波兰，北伐北欧、西吞法国、南并巴尔干，在欧洲大陆上大杀四方，无人可挡。但到了第二阶段，苏联以强大的力量阻遏了德国的闪电攻势，而年底日本对美国的偷袭更将可怕的敌人拉入了战争。在第三阶段，同盟国在太平洋战场、北非战场、东线战场相继赢得转折点性质的胜利。在第四阶段，扫清了北非的盟军开始进攻西欧大陆，苏联在东面的战场大举反攻。到第五阶段，轴心国崩溃，德国、日本相继投降（意大利早在上一阶段就已投降），战争结束。</p><h2 id="1939-1940"><a href="#1939-1940" class="headerlink" title="1939 - 1940"></a>1939 - 1940</h2><ul><li>1939.9 </li></ul><p>德国进攻波兰，闪电战，波兰迅速崩溃。波兰盟友英法向德国宣战，却没有采取大规模行动，形成了西线无战事的奇怪的战争。与德国签订有《德苏互不侵犯条约》的苏联更是趁机从东面入侵了波兰，一个月，战争结束，波兰被德苏两国瓜分。</p><ul><li>1940.11</li></ul><p>苏联入侵芬兰，在芬兰人的抵抗下，苏联损失惨重。两方面原因，芬兰人英勇抵抗，苏联在大清洗中洗掉了大量的优秀军官。最终苏联惨胜，签订《莫斯科和平协定》。</p><ul><li>1940.5 </li></ul><p>德国德国兵锋西指，几天内就攻陷了荷兰和比利时，驻守在<strong><em>马其诺防线</em></strong>北侧的英军、法军北上迎击，这落入了曼施坦因的圈套，德军出其不意地从<strong>阿登山区</strong>突入，“闪击战之父”古德里安率领坦克部队果断前进，切入到盟军侧背，形成围歼之势。盟军被迫在敦刻尔克乘英国的大小船只撤退到英国，这就是代号为“发电机行动”的敦刻尔克大撤退。无力抵抗的法国在德军的继续进攻下被迫投降，一部分国土被德国和意大利占领，另一部分国土则由贝当的“维希法国”管理。戴高乐在伦敦发表演说，不承认维希法国的合法性，组织自由法国继续抗争。几乎与此同时，苏联吞并了位于波罗的海的三个国家——爱沙尼亚、拉脱维亚和立陶宛。</p><ul><li>1940.8</li></ul><p>攻占法国后，希特勒开始着眼于英国，制定了“海狮计划”准备登陆英国。为了争夺登陆作战的制空权，德国空军从8月份开始对英国的空中攻势，英国军民在丘吉尔的领导下奋勇抵抗 —— 不列颠空战。1941年不列颠空战中，英国取得了最终胜利。</p><ul><li>1940.9</li></ul><p>利比亚的意大利军队入侵埃及，而后被英军击败并在12月反推至利比亚。10月，意大利入侵希腊，却迅速失败反而被希腊军队反推到阿尔巴尼亚。德国被迫卷入战争，入侵南斯拉夫和希腊。经过一系列战役后，巴尔干半岛上的战争最终以轴心国的胜利结束，整个巴尔干半岛都落入了轴心国的掌控之内。希特勒在次年又将隆美尔派往北非营救意大利。隆美尔取得了一系列胜利，赢得了“沙漠之狐”的美誉。轴心国在地中海、北非战场取得了一定进展，但德军因此推迟了入侵苏联的时间，希特勒后来为之懊恼不已。</p><h2 id="1941"><a href="#1941" class="headerlink" title="1941"></a>1941</h2><ul><li>1941.6</li></ul><p>德国巴巴罗萨行动，三路大军入侵苏联。北方集团军群攻占波罗的海三国，保卫列宁格勒，列宁格勒保卫战开始。中央集团军攻克斯摩棱斯克，直指莫斯科。南方军团在基辅大胜苏军，完成了历史上最大规模的歼灭战。</p><ul><li>1941.7</li></ul><p>英美冻结日本的资产，美国对日本实施了石油禁运政策，釜底抽薪之策啊。</p><ul><li>1941.12</li></ul><p>日本在太平洋上对英美发起了进攻。山本五十六偷袭珍珠港（12.7），美国从孤立主义转向参战。美国总统罗斯福对日本宣战，半年内日军依旧在太平洋战场占据优势。德军潜艇部队在邓尼茨的指挥下，运用狼群战术，对盟军航运船只造成了巨大的伤害。 </p><h2 id="1942"><a href="#1942" class="headerlink" title="1942"></a>1942</h2><ul><li>1942.5 </li></ul><p>太平洋珊瑚海，日军对抗盟军航母，日军航母祥凤号被击沉，翔鹤号受到重创，瑞鹤号飞机损耗严重。美军航母列星顿号沉没，约克城号受伤。这是日本在太平洋战场上的扩张势头第一次受到阻遏，盟军保住了美国到澳大利亚间的交通线。</p><ul><li>1942.6 </li></ul><p>中途岛海战爆发。酷炫的圈套和反圈套作战，最终日军四艘航母全沉没了。此战后，日军在太平洋战场上的优势不复存在。</p><ul><li>1942.5-6</li></ul><p>北非战场，“沙漠之狐”隆美尔率领轴心国军队在加查拉战役中战胜了奥金莱克指挥的盟军，盟军向东退守阿拉曼防线。7月，隆美尔进攻阿拉曼防线，奥金莱克率军抵抗，两军打成了消耗战。8月，奥金莱克的指挥职务被蒙哥马利取代。10月，第二次阿拉曼战役打响，在拥有制空权和后勤方面的优势条件下，蒙哥马利击败了隆美尔，一路追到了突尼斯。</p><ul><li>1942.7</li></ul><p>斯大林格勒战役打响，德军攻入了斯大林格勒，但是与苏军展开巷战，遭到英勇抵抗。11月，天王星计划，完成了反包围。德军在整个战争过程中第一个大规模失败，被俘90，000余人。转折点，盟军进入战略反攻阶段。</p><h2 id="1943"><a href="#1943" class="headerlink" title="1943"></a>1943</h2><ul><li>1942.11 </li></ul><p>北非火炬行动，在阿尔及利亚和摩洛哥登陆后，向突尼斯的轴心国军队进攻。到1943年5月，在实力雄厚的盟军的两面夹击之下，轴心国的部队完全失败，除了一部分逃走外，全部向盟军投降。至此盟军取得了在北非战场上的全面胜利，他们可以把目光投向地中海对面的意大利了。</p><ul><li>1943.7 </li></ul><p>盟军进攻西西里岛，取得胜利。</p><p>东线，德军元帅曼施坦因对阵苏军元帅朱可夫。曼施坦因想用钳形攻势攻击突出的库尔斯克地区，却被朱可夫抵挡住。战争发展成了历史上规模最大的坦克大会战，苏联人的损失比德国更大，但他们能承受这些。最后，由于盟军在西西里岛的入侵，希特勒急需从东线抽调兵力，曼施坦因被迫撤退。从此苏联人开始大规模收复失地，德国人节节败退。</p><ul><li>1943.9</li></ul><p>盟军入侵意大利本土，墨索里尼下台，意大利政府投降。</p><ul><li>1943.11</li></ul><p>开罗会议 - 英美中</p><p>德黑兰会议 - 苏美英  商讨进攻轴心国的战略和战后的安排</p><h1 id="1944-1945"><a href="#1944-1945" class="headerlink" title="1944 - 1945"></a>1944 - 1945</h1><ul><li>1944.1 </li></ul><p>长达两年四个月的列宁格勒围城战终于结束了。苏联法功十次斯大林突进。到年底，收回了全部领土，更控制了东欧大部分国家。</p><ul><li>1944.6</li></ul><p>盟军霸王行动，诺曼底登陆，三百万士兵横渡英吉利海峡。巴顿将军率部横扫法兰西。8月，法国解放。</p><ul><li>1944.12</li></ul><p>12月，德国进行最后的挣扎，在阿登地区向盟军发动攻势，莫德尔成功地在布莱德利的防线上打出了一个“突出部”，所以这场战役被称为突出部战役。德军将小股盟军包围在巴斯托尼。在守军即将崩溃的时候，天气放晴，盟军的空军优势得以发挥，他们对德军进行了猛烈的轰炸，并将物资空投到巴斯托尼。巴顿的援军迅速北上，德军大势已去。希特勒终于同意了莫德尔的撤军请求，他的孤注一掷失败了。</p><ul><li>1945.2 </li></ul><p>雅尔塔会议 —— 苏美英</p><ul><li>1945.4</li></ul><p>朱可夫率领苏军攻占柏林，占领国会大厦，希特勒自杀。</p><p>太平洋战场，盟军在麦克阿瑟的率领下，用蛙跳式跃岛战术。冲绳岛作战。</p><ul><li>1945.7 </li></ul><p>波茨坦会议 —— 苏美英，商讨战后欧洲问题及对日本作战的问题</p><ul><li>1945.8 </li></ul><p>广岛长崎原子弹</p><p>苏联红军攻进中国东北，击溃关东军。</p><p>日本宣布接收《波茨坦公告》公告，无条件投降。</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> history </tag>
            
            <tag> world war </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读懂财报</title>
      <link href="/%E8%AF%BB%E6%87%82%E8%B4%A2%E6%8A%A5/"/>
      <url>/%E8%AF%BB%E6%87%82%E8%B4%A2%E6%8A%A5/</url>
      
        <content type="html"><![CDATA[<h1 id="1-资产负债表"><a href="#1-资产负债表" class="headerlink" title="1 资产负债表"></a>1 资产负债表</h1><h2 id="1-1-资产负债表-分类"><a href="#1-1-资产负债表-分类" class="headerlink" title="1.1 资产负债表 分类"></a>1.1 资产负债表 分类</h2><p>企业需要做三张报表，分别是</p><ul><li>资产负债表</li><li>利润表</li><li>现金流</li></ul><h2 id="1-2-财务报表是用来做什么的？"><a href="#1-2-财务报表是用来做什么的？" class="headerlink" title="1.2 财务报表是用来做什么的？"></a>1.2 财务报表是用来做什么的？</h2><p>企业从事的经营活动的种类有：</p><ul><li>经营活动</li></ul><p>比如一个企业需要生产产品、销售产品、回收货款等等</p><ul><li>投资活动</li></ul><p>如果一个企业想要到一个新的地区去开展业务，想进入一个新的业务领域，或者想设计生产一个新的产品</p><ul><li>融资活动</li></ul><p>在经营和投资的过程中，当缺钱了的时候，需要去银行借钱，或者找别人来投资自己</p><p>可以这样子说，企业一辈子只做这三件事，经营，投资以及融资。在这整个过程中，无论其处在什么发展阶段，其日常经济活动都可以抽象成这样一个过程，从现金开始，转了一圈再搞到现金的过程。</p><h2 id="1-3-资产负债表详解"><a href="#1-3-资产负债表详解" class="headerlink" title="1.3 资产负债表详解"></a>1.3 资产负债表详解</h2><p>分为如下几个部分： </p><ul><li>资产 - 流动资产</li><li>资产 - 非流动资产</li><li>负债 - 流动负债</li><li>负债 - 非流动负债</li><li>股东权益</li></ul><h3 id="1-3-1-流动资产"><a href="#1-3-1-流动资产" class="headerlink" title="1.3.1 流动资产"></a>1.3.1 流动资产</h3><ul><li>货币资金</li></ul><p>放在银行里面或者放在公司里面的钱。包括库存现金，银行贷款，和其他货币资金三个项目的期末余额。</p><ul><li>应收账款</li></ul><p>销售产品的时候，发生的卖掉产品但是收不到钱的情况。<br>即需要核算的企业因为销售商品、提供劳务等经营活动应收取的款项。</p><ul><li>其他应收款</li></ul><p>企业除了存出保证金（租房子时交付的未来将退回的保证金、押金等）、买入返售的金融资产、应收票据、应收账款、预付账款、应收股利、应收利息、应收代位追偿款、应收分保账款、应收分包合同准备金、长期应收款等以外的其他各种应收及暂付款项。</p><ul><li>预付账款</li></ul><p>基本发生在货品很紧缺，带了一种向卖方收款的权利。预付账款也是一种资产。</p><ul><li>存货</li></ul><p>生产产品所需的原材料，生产出来的产成品，以及尚且处在生产过程中的没有完成的在产品</p><ul><li>待摊费用</li></ul><p>资产 vs 费用。 如果这笔钱可以换来对将来有用的东西，就是资产。如果画完就完了，就是费用。</p><p>各项流动资产在资产负债表中是按照<strong>各自转换为现金的速度</strong>来排序的。</p><h3 id="1-3-2-非流动资产"><a href="#1-3-2-非流动资产" class="headerlink" title="1.3.2 非流动资产"></a>1.3.2 非流动资产</h3><p>返回现金的时间长度，无法在一个循环内完成的。</p><ul><li>长期投资</li></ul><p>指不满足短期投资条件的投资，即不准备在一年或长于一年的经营周期之内转变为现金的投资。可以分为长期股票投资，长期债券投资，其他长期投资</p><ul><li>固定资产</li></ul><p>指同时具有以下特征的有形资产： （1）为生产商品、提供劳务、出租或经营管理而持有的； （2）使用寿命超过了一个会计年度</p><ul><li>无形资产</li></ul><p>专利权，版权等，还有土地使用权</p><p>指企业拥有或者控制的没有实物形态的可辨认的非货币性的资产。包括专利权、非专利技术、商标权、著作权、土地使用权等。</p><h3 id="1-3-3-资产-gt-企业"><a href="#1-3-3-资产-gt-企业" class="headerlink" title="1.3.3 资产 -&gt; 企业"></a>1.3.3 资产 -&gt; 企业</h3><p> 固定资产多，应收账款多，可能是有经营压力的传统企业</p><p> 生物资产，指有生命的动物和植物，生物资产分为消耗性生物资产，生产性生物资产和公益性生物资产。</p><p> 资产的结构会告诉你这家公司是什么样子的。 </p><h3 id="1-3-4-资产如何计价？"><a href="#1-3-4-资产如何计价？" class="headerlink" title="1.3.4 资产如何计价？"></a>1.3.4 资产如何计价？</h3><p> 会计们会用原来购买的资产价格当做这个资产的价值。</p><blockquote><p>历史成本</p></blockquote><blockquote><p>资产在其取得时为其所支付的现金或现金等价物的金额。负债在正常经营活动中为交换而收到或为偿付将要支付的现金或现金等价物的金额。</p></blockquote><blockquote><p>Bug: 历史成本无法体现出资产的变化。故解决方案为： 如果资产价值减小了，就把减值记下来。因为资产计价体系是一个历史成本的体系，一定要在历史成本的基础上扣除这个资产的减值。 </p></blockquote><ul><li>历史成本的含义</li></ul><ol><li>只有花了的钱才能记在账上。</li><li>在历史成本的计价体系下，增加资产价值的唯一途径是发生一个新的交易。</li></ol><h3 id="1-3-5-负债"><a href="#1-3-5-负债" class="headerlink" title="1.3.5 负债"></a>1.3.5 负债</h3><blockquote><p>负债：由于过去的交易或事务所引起的公司企业的现有债务，这种债务需要企业在将来以转移资产或提供劳务加以清偿，从而引起未来经济利益的流出。<br>其他：是为了简化，欠员工的工资，因为是月底发钱； 欠税务局的钱。这些都是流动负债。非流动负债： 应付债券。</p></blockquote><blockquote><p>应付债券：企业为了筹集资金而对外发行的期限在一年以上的长期借款性质的书面证明，约定在一定期限内还本付息的一种书面承诺。</p></blockquote><h3 id="1-3-6-股东权益"><a href="#1-3-6-股东权益" class="headerlink" title="1.3.6 股东权益"></a>1.3.6 股东权益</h3><blockquote><p>股东权益： 公司总资产中扣除负债剩余的部分，也成为净资产，反映了公司的自有资本。</p></blockquote><blockquote><p>股本： 股本金额相当于公司的注册资本。股本的总额体现了这个公司对外承担法律责任的上限。股本的组成则确定了多个股东之间的权利义务关系。</p></blockquote><blockquote><p>资本公积： 企业收到的投资者的超出其在企业注册资本所占份额，以及直接计入所有者权益的利得和损失等。</p></blockquote><blockquote><p>股东权益 + 负债 = 资产</p></blockquote><p>注意资产负债表是一个时间点的概念，是状态，不是过程。</p><h1 id="2-利润表"><a href="#2-利润表" class="headerlink" title="2. 利润表"></a>2. 利润表</h1><p>资产负债表： 可以看到投入的本金是否得到保障。利润表，则能得知投入的本金有没有赚钱。</p><p>毛利 = 营业收入 - 营业成本</p><h2 id="2-1-税种"><a href="#2-1-税种" class="headerlink" title="2.1 税种"></a>2.1 税种</h2><ul><li>营业税</li></ul><p>国家对工商营利事业按照营业额征收的税</p><ul><li>营业税金及附加</li></ul><p>企业经营活动应负担的相关税费，包括营业税、消费税、城市维护建设税、资源税、教育费附加等。不是所得税，是流转税，只要是有业务的企业就得缴纳流转税。</p><ul><li>常见的流转税： 营业税（价内税） + 增值税（价外税）</li><li>价内税： 税金包含在商品价值或价格之内</li><li>价外税： 税款不包括在价格内</li><li>增值税： 一种销售税，是消费者承担的税费，属于累退税，是基于商品或服务的增值而增税的一种间接税</li></ul><h2 id="2-2-其他项目"><a href="#2-2-其他项目" class="headerlink" title="2.2 其他项目"></a>2.2 其他项目</h2><ul><li>补贴收入<br>中国特色： 政府为一些企业提供的补贴。</li></ul><h2 id="2-3-利润表的分析"><a href="#2-3-利润表的分析" class="headerlink" title="2.3 利润表的分析"></a>2.3 利润表的分析</h2><p>告诉了是否赚钱，在哪些方面赚钱的基本信息。同时因为将可持续的和不可持续的营业收入分开，就可以帮助企业推断出自己未来一段时间以内的收益。</p>]]></content>
      
      
      <categories>
          
          <category> Notes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reading </tag>
            
            <tag> finance </tag>
            
            <tag> stock </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
